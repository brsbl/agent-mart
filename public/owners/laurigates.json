{
  "owner": {
    "id": "laurigates",
    "display_name": "Lauri Gates",
    "type": "User",
    "avatar_url": "https://avatars.githubusercontent.com/u/13014001?u=8ada73fddfb90e920b8241fe72b32382b7ee4087&v=4",
    "url": "https://github.com/laurigates",
    "bio": "Linux enthusiast, cloud engineer, neovim addict, electronics hobbyist.",
    "stats": {
      "total_repos": 1,
      "total_plugins": 24,
      "total_commands": 24,
      "total_skills": 97,
      "total_stars": 1,
      "total_forks": 0
    }
  },
  "repos": [
    {
      "full_name": "laurigates/claude-plugins",
      "url": "https://github.com/laurigates/claude-plugins",
      "description": "Claude Code plugins for development workflows",
      "homepage": null,
      "signals": {
        "stars": 1,
        "forks": 0,
        "pushed_at": "2026-01-12T12:05:51Z",
        "created_at": "2025-12-16T11:24:04Z",
        "license": null
      },
      "file_tree": [
        {
          "path": ".claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude-plugin/marketplace.json",
          "type": "blob",
          "size": 8408
        },
        {
          "path": ".claude",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude/rules",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude/rules/agentic-optimization.md",
          "type": "blob",
          "size": 2864
        },
        {
          "path": ".claude/rules/command-naming.md",
          "type": "blob",
          "size": 2160
        },
        {
          "path": ".claude/rules/plugin-structure.md",
          "type": "blob",
          "size": 2986
        },
        {
          "path": ".claude/rules/release-please.md",
          "type": "blob",
          "size": 2128
        },
        {
          "path": ".claude/rules/skill-development.md",
          "type": "blob",
          "size": 3362
        },
        {
          "path": ".github",
          "type": "tree",
          "size": null
        },
        {
          "path": ".github/workflows",
          "type": "tree",
          "size": null
        },
        {
          "path": ".github/workflows/release-please.yml",
          "type": "blob",
          "size": 1977
        },
        {
          "path": ".gitignore",
          "type": "blob",
          "size": 9
        },
        {
          "path": ".release-please-manifest.json",
          "type": "blob",
          "size": 886
        },
        {
          "path": "CLAUDE.md",
          "type": "blob",
          "size": 3768
        },
        {
          "path": "MIGRATION.md",
          "type": "blob",
          "size": 20511
        },
        {
          "path": "README.md",
          "type": "blob",
          "size": 2638
        },
        {
          "path": "accessibility-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "accessibility-plugin/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "accessibility-plugin/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 278
        },
        {
          "path": "accessibility-plugin/CHANGELOG.md",
          "type": "blob",
          "size": 866
        },
        {
          "path": "accessibility-plugin/README.md",
          "type": "blob",
          "size": 6279
        },
        {
          "path": "accessibility-plugin/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "accessibility-plugin/commands/.gitkeep",
          "type": "blob",
          "size": null
        },
        {
          "path": "accessibility-plugin/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "accessibility-plugin/skills/accessibility-implementation",
          "type": "tree",
          "size": null
        },
        {
          "path": "accessibility-plugin/skills/accessibility-implementation/SKILL.md",
          "type": "blob",
          "size": 11846
        },
        {
          "path": "accessibility-plugin/skills/design-tokens",
          "type": "tree",
          "size": null
        },
        {
          "path": "accessibility-plugin/skills/design-tokens/SKILL.md",
          "type": "blob",
          "size": 12380
        },
        {
          "path": "agent-patterns-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "agent-patterns-plugin/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "agent-patterns-plugin/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 283
        },
        {
          "path": "agent-patterns-plugin/CHANGELOG.md",
          "type": "blob",
          "size": 1087
        },
        {
          "path": "agent-patterns-plugin/README.md",
          "type": "blob",
          "size": 7860
        },
        {
          "path": "agent-patterns-plugin/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "agent-patterns-plugin/commands/check-negative-examples.md",
          "type": "blob",
          "size": 5719
        },
        {
          "path": "agent-patterns-plugin/commands/delegate.md",
          "type": "blob",
          "size": 6566
        },
        {
          "path": "agent-patterns-plugin/commands/meta",
          "type": "tree",
          "size": null
        },
        {
          "path": "agent-patterns-plugin/commands/meta/assimilate.md",
          "type": "blob",
          "size": 532
        },
        {
          "path": "agent-patterns-plugin/commands/meta/audit.md",
          "type": "blob",
          "size": 5809
        },
        {
          "path": "agent-patterns-plugin/commands/workflow-primer.md",
          "type": "blob",
          "size": 2852
        },
        {
          "path": "agent-patterns-plugin/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "agent-patterns-plugin/skills/agent-coordination-patterns",
          "type": "tree",
          "size": null
        },
        {
          "path": "agent-patterns-plugin/skills/agent-coordination-patterns/SKILL.md",
          "type": "blob",
          "size": 8464
        },
        {
          "path": "agent-patterns-plugin/skills/agent-file-coordination",
          "type": "tree",
          "size": null
        },
        {
          "path": "agent-patterns-plugin/skills/agent-file-coordination/SKILL.md",
          "type": "blob",
          "size": 1834
        },
        {
          "path": "agent-patterns-plugin/skills/agent-handoff-markers",
          "type": "tree",
          "size": null
        },
        {
          "path": "agent-patterns-plugin/skills/agent-handoff-markers/SKILL.md",
          "type": "blob",
          "size": 11973
        },
        {
          "path": "agent-patterns-plugin/skills/command-context-patterns",
          "type": "tree",
          "size": null
        },
        {
          "path": "agent-patterns-plugin/skills/command-context-patterns/SKILL.md",
          "type": "blob",
          "size": 887
        },
        {
          "path": "agent-patterns-plugin/skills/mcp-management",
          "type": "tree",
          "size": null
        },
        {
          "path": "agent-patterns-plugin/skills/mcp-management/SKILL.md",
          "type": "blob",
          "size": 609
        },
        {
          "path": "agent-patterns-plugin/skills/multi-agent-workflows",
          "type": "tree",
          "size": null
        },
        {
          "path": "agent-patterns-plugin/skills/multi-agent-workflows/SKILL.md",
          "type": "blob",
          "size": 527
        },
        {
          "path": "agents-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "agents-plugin/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "agents-plugin/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 388
        },
        {
          "path": "agents-plugin/README.md",
          "type": "blob",
          "size": 1038
        },
        {
          "path": "agents-plugin/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "agents-plugin/agents/ci.md",
          "type": "blob",
          "size": 2549
        },
        {
          "path": "agents-plugin/agents/debug.md",
          "type": "blob",
          "size": 2905
        },
        {
          "path": "agents-plugin/agents/docs.md",
          "type": "blob",
          "size": 2407
        },
        {
          "path": "agents-plugin/agents/review.md",
          "type": "blob",
          "size": 2908
        },
        {
          "path": "agents-plugin/agents/test.md",
          "type": "blob",
          "size": 2220
        },
        {
          "path": "api-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "api-plugin/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "api-plugin/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 280
        },
        {
          "path": "api-plugin/README.md",
          "type": "blob",
          "size": 8738
        },
        {
          "path": "api-plugin/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "api-plugin/commands/api-tests.md",
          "type": "blob",
          "size": 25566
        },
        {
          "path": "api-plugin/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "api-plugin/skills/api-testing",
          "type": "tree",
          "size": null
        },
        {
          "path": "api-plugin/skills/api-testing/SKILL.md",
          "type": "blob",
          "size": 19294
        },
        {
          "path": "bevy-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "bevy-plugin/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "bevy-plugin/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 224
        },
        {
          "path": "bevy-plugin/README.md",
          "type": "blob",
          "size": 4348
        },
        {
          "path": "bevy-plugin/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "bevy-plugin/skills/bevy-ecs-patterns",
          "type": "tree",
          "size": null
        },
        {
          "path": "bevy-plugin/skills/bevy-ecs-patterns/skill.md",
          "type": "blob",
          "size": 10790
        },
        {
          "path": "bevy-plugin/skills/bevy-game-engine",
          "type": "tree",
          "size": null
        },
        {
          "path": "bevy-plugin/skills/bevy-game-engine/skill.md",
          "type": "blob",
          "size": 8607
        },
        {
          "path": "blog-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "blog-plugin/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "blog-plugin/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 275
        },
        {
          "path": "blog-plugin/README.md",
          "type": "blob",
          "size": 2210
        },
        {
          "path": "blog-plugin/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "blog-plugin/commands/blog-post.md",
          "type": "blob",
          "size": 9833
        },
        {
          "path": "blog-plugin/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "blog-plugin/skills/blog-post-writing",
          "type": "tree",
          "size": null
        },
        {
          "path": "blog-plugin/skills/blog-post-writing/skill.md",
          "type": "blob",
          "size": 7950
        },
        {
          "path": "blueprint-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "blueprint-plugin/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "blueprint-plugin/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 843
        },
        {
          "path": "blueprint-plugin/CHANGELOG.md",
          "type": "blob",
          "size": 2321
        },
        {
          "path": "blueprint-plugin/README.md",
          "type": "blob",
          "size": 5867
        },
        {
          "path": "blueprint-plugin/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "blueprint-plugin/commands/blueprint-adr.md",
          "type": "blob",
          "size": 8339
        },
        {
          "path": "blueprint-plugin/commands/blueprint-claude-md.md",
          "type": "blob",
          "size": 5995
        },
        {
          "path": "blueprint-plugin/commands/blueprint-curate-docs.md",
          "type": "blob",
          "size": 6775
        },
        {
          "path": "blueprint-plugin/commands/blueprint-feature-tracker-status.md",
          "type": "blob",
          "size": 5477
        },
        {
          "path": "blueprint-plugin/commands/blueprint-feature-tracker-sync.md",
          "type": "blob",
          "size": 5283
        },
        {
          "path": "blueprint-plugin/commands/blueprint-generate-commands.md",
          "type": "blob",
          "size": 6173
        },
        {
          "path": "blueprint-plugin/commands/blueprint-generate-rules.md",
          "type": "blob",
          "size": 5100
        },
        {
          "path": "blueprint-plugin/commands/blueprint-init.md",
          "type": "blob",
          "size": 10975
        },
        {
          "path": "blueprint-plugin/commands/blueprint-prd.md",
          "type": "blob",
          "size": 7905
        },
        {
          "path": "blueprint-plugin/commands/blueprint-promote.md",
          "type": "blob",
          "size": 2947
        },
        {
          "path": "blueprint-plugin/commands/blueprint-prp-create.md",
          "type": "blob",
          "size": 7122
        },
        {
          "path": "blueprint-plugin/commands/blueprint-prp-execute.md",
          "type": "blob",
          "size": 6735
        },
        {
          "path": "blueprint-plugin/commands/blueprint-rules.md",
          "type": "blob",
          "size": 5811
        },
        {
          "path": "blueprint-plugin/commands/blueprint-status.md",
          "type": "blob",
          "size": 8052
        },
        {
          "path": "blueprint-plugin/commands/blueprint-sync.md",
          "type": "blob",
          "size": 3883
        },
        {
          "path": "blueprint-plugin/commands/blueprint-upgrade.md",
          "type": "blob",
          "size": 11687
        },
        {
          "path": "blueprint-plugin/commands/blueprint-work-order.md",
          "type": "blob",
          "size": 8380
        },
        {
          "path": "blueprint-plugin/schemas",
          "type": "tree",
          "size": null
        },
        {
          "path": "blueprint-plugin/schemas/feature-tracker.schema.json",
          "type": "blob",
          "size": 6377
        },
        {
          "path": "blueprint-plugin/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "blueprint-plugin/skills/blueprint-development",
          "type": "tree",
          "size": null
        },
        {
          "path": "blueprint-plugin/skills/blueprint-development/SKILL.md",
          "type": "blob",
          "size": 21028
        },
        {
          "path": "blueprint-plugin/skills/blueprint-development/templates",
          "type": "tree",
          "size": null
        },
        {
          "path": "blueprint-plugin/skills/blueprint-development/templates/architecture-skill-template.md",
          "type": "blob",
          "size": 6775
        },
        {
          "path": "blueprint-plugin/skills/blueprint-development/templates/implementation-skill-template.md",
          "type": "blob",
          "size": 3111
        },
        {
          "path": "blueprint-plugin/skills/blueprint-development/templates/quality-skill-template.md",
          "type": "blob",
          "size": 7323
        },
        {
          "path": "blueprint-plugin/skills/blueprint-development/templates/testing-skill-template.md",
          "type": "blob",
          "size": 11468
        },
        {
          "path": "blueprint-plugin/skills/blueprint-migration",
          "type": "tree",
          "size": null
        },
        {
          "path": "blueprint-plugin/skills/blueprint-migration/migrations",
          "type": "tree",
          "size": null
        },
        {
          "path": "blueprint-plugin/skills/blueprint-migration/migrations/v1.0-to-v1.1.md",
          "type": "blob",
          "size": 1894
        },
        {
          "path": "blueprint-plugin/skills/blueprint-migration/migrations/v1.x-to-v2.0.md",
          "type": "blob",
          "size": 6093
        },
        {
          "path": "blueprint-plugin/skills/blueprint-migration/migrations/v2.x-to-v3.0.md",
          "type": "blob",
          "size": 12440
        },
        {
          "path": "blueprint-plugin/skills/blueprint-migration/skill.md",
          "type": "blob",
          "size": 2973
        },
        {
          "path": "blueprint-plugin/skills/confidence-scoring",
          "type": "tree",
          "size": null
        },
        {
          "path": "blueprint-plugin/skills/confidence-scoring/SKILL.md",
          "type": "blob",
          "size": 8863
        },
        {
          "path": "blueprint-plugin/skills/document-detection",
          "type": "tree",
          "size": null
        },
        {
          "path": "blueprint-plugin/skills/document-detection/skill.md",
          "type": "blob",
          "size": 9885
        },
        {
          "path": "blueprint-plugin/skills/feature-tracking",
          "type": "tree",
          "size": null
        },
        {
          "path": "blueprint-plugin/skills/feature-tracking/SKILL.md",
          "type": "blob",
          "size": 6290
        },
        {
          "path": "blueprint-plugin/skills/feature-tracking/templates",
          "type": "tree",
          "size": null
        },
        {
          "path": "blueprint-plugin/skills/feature-tracking/templates/feature-tracker-template.json",
          "type": "blob",
          "size": 678
        },
        {
          "path": "blueprint-plugin/templates",
          "type": "tree",
          "size": null
        },
        {
          "path": "blueprint-plugin/templates/blueprint-readme.md",
          "type": "blob",
          "size": 3455
        },
        {
          "path": "blueprint-plugin/templates/document-management-rule.md",
          "type": "blob",
          "size": 4539
        },
        {
          "path": "code-quality-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "code-quality-plugin/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "code-quality-plugin/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 503
        },
        {
          "path": "code-quality-plugin/CHANGELOG.md",
          "type": "blob",
          "size": 410
        },
        {
          "path": "code-quality-plugin/README.md",
          "type": "blob",
          "size": 3435
        },
        {
          "path": "code-quality-plugin/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "code-quality-plugin/commands/code",
          "type": "tree",
          "size": null
        },
        {
          "path": "code-quality-plugin/commands/code/antipatterns.md",
          "type": "blob",
          "size": 5560
        },
        {
          "path": "code-quality-plugin/commands/code/refactor.md",
          "type": "blob",
          "size": 1907
        },
        {
          "path": "code-quality-plugin/commands/code/review.md",
          "type": "blob",
          "size": 2095
        },
        {
          "path": "code-quality-plugin/commands/docs",
          "type": "tree",
          "size": null
        },
        {
          "path": "code-quality-plugin/commands/docs/quality-check.md",
          "type": "blob",
          "size": 12607
        },
        {
          "path": "code-quality-plugin/commands/lint",
          "type": "tree",
          "size": null
        },
        {
          "path": "code-quality-plugin/commands/lint/check.md",
          "type": "blob",
          "size": 2317
        },
        {
          "path": "code-quality-plugin/commands/refactor.md",
          "type": "blob",
          "size": 1384
        },
        {
          "path": "code-quality-plugin/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "code-quality-plugin/skills/ast-grep-search",
          "type": "tree",
          "size": null
        },
        {
          "path": "code-quality-plugin/skills/ast-grep-search/SKILL.md",
          "type": "blob",
          "size": 28620
        },
        {
          "path": "code-quality-plugin/skills/code-antipatterns-analysis",
          "type": "tree",
          "size": null
        },
        {
          "path": "code-quality-plugin/skills/code-antipatterns-analysis/REFERENCE.md",
          "type": "blob",
          "size": 13239
        },
        {
          "path": "code-quality-plugin/skills/code-antipatterns-analysis/SKILL.md",
          "type": "blob",
          "size": 10492
        },
        {
          "path": "code-quality-plugin/skills/code-review-checklist",
          "type": "tree",
          "size": null
        },
        {
          "path": "code-quality-plugin/skills/code-review-checklist/SKILL.md",
          "type": "blob",
          "size": 3317
        },
        {
          "path": "code-quality-plugin/skills/debugging-methodology",
          "type": "tree",
          "size": null
        },
        {
          "path": "code-quality-plugin/skills/debugging-methodology/SKILL.md",
          "type": "blob",
          "size": 4750
        },
        {
          "path": "code-quality-plugin/skills/documentation-quality",
          "type": "tree",
          "size": null
        },
        {
          "path": "code-quality-plugin/skills/documentation-quality/SKILL.md",
          "type": "blob",
          "size": 13975
        },
        {
          "path": "code-quality-plugin/skills/linter-autofix",
          "type": "tree",
          "size": null
        },
        {
          "path": "code-quality-plugin/skills/linter-autofix/SKILL.md",
          "type": "blob",
          "size": 2734
        },
        {
          "path": "command-analytics-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "command-analytics-plugin/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "command-analytics-plugin/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 658
        },
        {
          "path": "command-analytics-plugin/CHANGELOG.md",
          "type": "blob",
          "size": 312
        },
        {
          "path": "command-analytics-plugin/README.md",
          "type": "blob",
          "size": 6623
        },
        {
          "path": "command-analytics-plugin/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "command-analytics-plugin/commands/analytics-clear.md",
          "type": "blob",
          "size": 1757
        },
        {
          "path": "command-analytics-plugin/commands/analytics-export.md",
          "type": "blob",
          "size": 4287
        },
        {
          "path": "command-analytics-plugin/commands/analytics-report.md",
          "type": "blob",
          "size": 6315
        },
        {
          "path": "command-analytics-plugin/commands/analytics-unused.md",
          "type": "blob",
          "size": 3950
        },
        {
          "path": "command-analytics-plugin/scripts",
          "type": "tree",
          "size": null
        },
        {
          "path": "command-analytics-plugin/scripts/track-usage.sh",
          "type": "blob",
          "size": 2341
        },
        {
          "path": "communication-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "communication-plugin/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "communication-plugin/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 217
        },
        {
          "path": "communication-plugin/README.md",
          "type": "blob",
          "size": 7301
        },
        {
          "path": "communication-plugin/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "communication-plugin/skills/google-chat-formatting",
          "type": "tree",
          "size": null
        },
        {
          "path": "communication-plugin/skills/google-chat-formatting/skill.md",
          "type": "blob",
          "size": 11422
        },
        {
          "path": "communication-plugin/skills/ticket-drafting-guidelines",
          "type": "tree",
          "size": null
        },
        {
          "path": "communication-plugin/skills/ticket-drafting-guidelines/skill.md",
          "type": "blob",
          "size": 10807
        },
        {
          "path": "configure-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "configure-plugin/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "configure-plugin/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 525
        },
        {
          "path": "configure-plugin/CHANGELOG.md",
          "type": "blob",
          "size": 1135
        },
        {
          "path": "configure-plugin/README.md",
          "type": "blob",
          "size": 4507
        },
        {
          "path": "configure-plugin/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "configure-plugin/commands/configure",
          "type": "tree",
          "size": null
        },
        {
          "path": "configure-plugin/commands/configure/all.md",
          "type": "blob",
          "size": 9309
        },
        {
          "path": "configure-plugin/commands/configure/api-tests.md",
          "type": "blob",
          "size": 25566
        },
        {
          "path": "configure-plugin/commands/configure/cache-busting.md",
          "type": "blob",
          "size": 25755
        },
        {
          "path": "configure-plugin/commands/configure/container.md",
          "type": "blob",
          "size": 16402
        },
        {
          "path": "configure-plugin/commands/configure/coverage.md",
          "type": "blob",
          "size": 13825
        },
        {
          "path": "configure-plugin/commands/configure/dead-code.md",
          "type": "blob",
          "size": 12731
        },
        {
          "path": "configure-plugin/commands/configure/dockerfile.md",
          "type": "blob",
          "size": 5740
        },
        {
          "path": "configure-plugin/commands/configure/docs.md",
          "type": "blob",
          "size": 12795
        },
        {
          "path": "configure-plugin/commands/configure/editor.md",
          "type": "blob",
          "size": 15896
        },
        {
          "path": "configure-plugin/commands/configure/feature-flags.md",
          "type": "blob",
          "size": 19460
        },
        {
          "path": "configure-plugin/commands/configure/formatting.md",
          "type": "blob",
          "size": 14764
        },
        {
          "path": "configure-plugin/commands/configure/github-pages.md",
          "type": "blob",
          "size": 9794
        },
        {
          "path": "configure-plugin/commands/configure/integration-tests.md",
          "type": "blob",
          "size": 19757
        },
        {
          "path": "configure-plugin/commands/configure/justfile.md",
          "type": "blob",
          "size": 7362
        },
        {
          "path": "configure-plugin/commands/configure/linting.md",
          "type": "blob",
          "size": 11524
        },
        {
          "path": "configure-plugin/commands/configure/load-tests.md",
          "type": "blob",
          "size": 24844
        },
        {
          "path": "configure-plugin/commands/configure/makefile.md",
          "type": "blob",
          "size": 6191
        },
        {
          "path": "configure-plugin/commands/configure/mcp.md",
          "type": "blob",
          "size": 7834
        },
        {
          "path": "configure-plugin/commands/configure/memory-profiling.md",
          "type": "blob",
          "size": 24132
        },
        {
          "path": "configure-plugin/commands/configure/package-management.md",
          "type": "blob",
          "size": 12683
        },
        {
          "path": "configure-plugin/commands/configure/pre-commit.md",
          "type": "blob",
          "size": 4890
        },
        {
          "path": "configure-plugin/commands/configure/readme.md",
          "type": "blob",
          "size": 11801
        },
        {
          "path": "configure-plugin/commands/configure/release-please.md",
          "type": "blob",
          "size": 4814
        },
        {
          "path": "configure-plugin/commands/configure/security.md",
          "type": "blob",
          "size": 18094
        },
        {
          "path": "configure-plugin/commands/configure/select.md",
          "type": "blob",
          "size": 7763
        },
        {
          "path": "configure-plugin/commands/configure/sentry.md",
          "type": "blob",
          "size": 8380
        },
        {
          "path": "configure-plugin/commands/configure/skaffold.md",
          "type": "blob",
          "size": 8669
        },
        {
          "path": "configure-plugin/commands/configure/status.md",
          "type": "blob",
          "size": 4587
        },
        {
          "path": "configure-plugin/commands/configure/tests.md",
          "type": "blob",
          "size": 13862
        },
        {
          "path": "configure-plugin/commands/configure/ux-testing.md",
          "type": "blob",
          "size": 17358
        },
        {
          "path": "configure-plugin/commands/configure/workflows.md",
          "type": "blob",
          "size": 6464
        },
        {
          "path": "configure-plugin/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "configure-plugin/skills/fvh-ci-workflows",
          "type": "tree",
          "size": null
        },
        {
          "path": "configure-plugin/skills/fvh-ci-workflows/SKILL.md",
          "type": "blob",
          "size": 5878
        },
        {
          "path": "configure-plugin/skills/fvh-pre-commit",
          "type": "tree",
          "size": null
        },
        {
          "path": "configure-plugin/skills/fvh-pre-commit/SKILL.md",
          "type": "blob",
          "size": 5806
        },
        {
          "path": "configure-plugin/skills/fvh-readme",
          "type": "tree",
          "size": null
        },
        {
          "path": "configure-plugin/skills/fvh-readme/SKILL.md",
          "type": "blob",
          "size": 10808
        },
        {
          "path": "configure-plugin/skills/fvh-release-please",
          "type": "tree",
          "size": null
        },
        {
          "path": "configure-plugin/skills/fvh-release-please/SKILL.md",
          "type": "blob",
          "size": 5055
        },
        {
          "path": "configure-plugin/skills/fvh-skaffold",
          "type": "tree",
          "size": null
        },
        {
          "path": "configure-plugin/skills/fvh-skaffold/SKILL.md",
          "type": "blob",
          "size": 8567
        },
        {
          "path": "configure-plugin/skills/go-feature-flag",
          "type": "tree",
          "size": null
        },
        {
          "path": "configure-plugin/skills/go-feature-flag/SKILL.md",
          "type": "blob",
          "size": 15592
        },
        {
          "path": "configure-plugin/skills/openfeature",
          "type": "tree",
          "size": null
        },
        {
          "path": "configure-plugin/skills/openfeature/SKILL.md",
          "type": "blob",
          "size": 11049
        },
        {
          "path": "container-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "container-plugin/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "container-plugin/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 429
        },
        {
          "path": "container-plugin/CHANGELOG.md",
          "type": "blob",
          "size": 938
        },
        {
          "path": "container-plugin/README.md",
          "type": "blob",
          "size": 8727
        },
        {
          "path": "container-plugin/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "container-plugin/commands/deploy",
          "type": "tree",
          "size": null
        },
        {
          "path": "container-plugin/commands/deploy/handoff.md",
          "type": "blob",
          "size": 6361
        },
        {
          "path": "container-plugin/commands/deploy/release.md",
          "type": "blob",
          "size": 470
        },
        {
          "path": "container-plugin/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "container-plugin/skills/container-development",
          "type": "tree",
          "size": null
        },
        {
          "path": "container-plugin/skills/container-development/REFERENCE.md",
          "type": "blob",
          "size": 19927
        },
        {
          "path": "container-plugin/skills/container-development/SKILL.md",
          "type": "blob",
          "size": 5409
        },
        {
          "path": "container-plugin/skills/skaffold-orbstack",
          "type": "tree",
          "size": null
        },
        {
          "path": "container-plugin/skills/skaffold-orbstack/SKILL.md",
          "type": "blob",
          "size": 8746
        },
        {
          "path": "container-plugin/skills/skaffold-testing",
          "type": "tree",
          "size": null
        },
        {
          "path": "container-plugin/skills/skaffold-testing/skill.md",
          "type": "blob",
          "size": 13060
        },
        {
          "path": "docs",
          "type": "tree",
          "size": null
        },
        {
          "path": "docs/adrs",
          "type": "tree",
          "size": null
        },
        {
          "path": "docs/adrs/0001-plugin-based-architecture.md",
          "type": "blob",
          "size": 4079
        },
        {
          "path": "docs/adrs/0002-domain-driven-plugin-organization.md",
          "type": "blob",
          "size": 4380
        },
        {
          "path": "docs/adrs/0003-auto-discovery-component-pattern.md",
          "type": "blob",
          "size": 4449
        },
        {
          "path": "docs/adrs/0004-marketplace-registry-model.md",
          "type": "blob",
          "size": 4110
        },
        {
          "path": "docs/adrs/0005-blueprint-development-methodology.md",
          "type": "blob",
          "size": 4561
        },
        {
          "path": "docs/adrs/0006-fvh-standards-enforcement.md",
          "type": "blob",
          "size": 4599
        },
        {
          "path": "docs/adrs/0007-namespace-based-command-organization.md",
          "type": "blob",
          "size": 3729
        },
        {
          "path": "docs/adrs/0008-semantic-versioning-with-manifest.md",
          "type": "blob",
          "size": 4011
        },
        {
          "path": "docs/adrs/0009-task-focused-agent-consolidation.md",
          "type": "blob",
          "size": 5369
        },
        {
          "path": "docs/adrs/0010-proactive-document-detection.md",
          "type": "blob",
          "size": 6353
        },
        {
          "path": "docs/adrs/0011-blueprint-state-in-docs-directory.md",
          "type": "blob",
          "size": 9346
        },
        {
          "path": "docs/adrs/0012-blog-plugin-for-project-documentation.md",
          "type": "blob",
          "size": 6702
        },
        {
          "path": "docs/adrs/README.md",
          "type": "blob",
          "size": 3877
        },
        {
          "path": "docs/prds",
          "type": "tree",
          "size": null
        },
        {
          "path": "docs/prds/automatic-document-management.md",
          "type": "blob",
          "size": 17360
        },
        {
          "path": "docs/prps",
          "type": "tree",
          "size": null
        },
        {
          "path": "docs/prps/automatic-document-management.md",
          "type": "blob",
          "size": 29056
        },
        {
          "path": "documentation-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "documentation-plugin/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "documentation-plugin/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 247
        },
        {
          "path": "documentation-plugin/README.md",
          "type": "blob",
          "size": 3444
        },
        {
          "path": "documentation-plugin/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "documentation-plugin/commands/docs",
          "type": "tree",
          "size": null
        },
        {
          "path": "documentation-plugin/commands/docs/decommission.md",
          "type": "blob",
          "size": 4438
        },
        {
          "path": "documentation-plugin/commands/docs/generate.md",
          "type": "blob",
          "size": 2353
        },
        {
          "path": "documentation-plugin/commands/docs/knowledge-graph.md",
          "type": "blob",
          "size": 1881
        },
        {
          "path": "documentation-plugin/commands/docs/sync.md",
          "type": "blob",
          "size": 6469
        },
        {
          "path": "documentation-plugin/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "documentation-plugin/skills/claude-blog-sources",
          "type": "tree",
          "size": null
        },
        {
          "path": "documentation-plugin/skills/claude-blog-sources/SKILL.md",
          "type": "blob",
          "size": 5574
        },
        {
          "path": "dotfiles-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "dotfiles-plugin/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "dotfiles-plugin/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 238
        },
        {
          "path": "dotfiles-plugin/README.md",
          "type": "blob",
          "size": 2928
        },
        {
          "path": "dotfiles-plugin/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "dotfiles-plugin/skills/chezmoi-expert",
          "type": "tree",
          "size": null
        },
        {
          "path": "dotfiles-plugin/skills/chezmoi-expert/REFERENCE.md",
          "type": "blob",
          "size": 6376
        },
        {
          "path": "dotfiles-plugin/skills/chezmoi-expert/SKILL.md",
          "type": "blob",
          "size": 3964
        },
        {
          "path": "dotfiles-plugin/skills/neovim-configuration",
          "type": "tree",
          "size": null
        },
        {
          "path": "dotfiles-plugin/skills/neovim-configuration/SKILL.md",
          "type": "blob",
          "size": 5615
        },
        {
          "path": "dotfiles-plugin/skills/obsidian-bases",
          "type": "tree",
          "size": null
        },
        {
          "path": "dotfiles-plugin/skills/obsidian-bases/SKILL.md",
          "type": "blob",
          "size": 9616
        },
        {
          "path": "first-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "first-plugin/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "first-plugin/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 148
        },
        {
          "path": "git-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "git-plugin/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "git-plugin/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 454
        },
        {
          "path": "git-plugin/CHANGELOG.md",
          "type": "blob",
          "size": 1988
        },
        {
          "path": "git-plugin/README.md",
          "type": "blob",
          "size": 2213
        },
        {
          "path": "git-plugin/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "git-plugin/commands/git",
          "type": "tree",
          "size": null
        },
        {
          "path": "git-plugin/commands/git/commit.md",
          "type": "blob",
          "size": 5478
        },
        {
          "path": "git-plugin/commands/git/fix-pr.md",
          "type": "blob",
          "size": 2429
        },
        {
          "path": "git-plugin/commands/git/issue.md",
          "type": "blob",
          "size": 2949
        },
        {
          "path": "git-plugin/commands/git/issues.md",
          "type": "blob",
          "size": 2454
        },
        {
          "path": "git-plugin/commands/git/maintain.md",
          "type": "blob",
          "size": 2512
        },
        {
          "path": "git-plugin/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "git-plugin/skills/git-branch-pr-workflow",
          "type": "tree",
          "size": null
        },
        {
          "path": "git-plugin/skills/git-branch-pr-workflow/SKILL.md",
          "type": "blob",
          "size": 13591
        },
        {
          "path": "git-plugin/skills/git-commit-workflow",
          "type": "tree",
          "size": null
        },
        {
          "path": "git-plugin/skills/git-commit-workflow/SKILL.md",
          "type": "blob",
          "size": 12521
        },
        {
          "path": "git-plugin/skills/git-repo-detection",
          "type": "tree",
          "size": null
        },
        {
          "path": "git-plugin/skills/git-repo-detection/SKILL.md",
          "type": "blob",
          "size": 11937
        },
        {
          "path": "git-plugin/skills/git-security-checks",
          "type": "tree",
          "size": null
        },
        {
          "path": "git-plugin/skills/git-security-checks/SKILL.md",
          "type": "blob",
          "size": 9407
        },
        {
          "path": "git-plugin/skills/github-labels",
          "type": "tree",
          "size": null
        },
        {
          "path": "git-plugin/skills/github-labels/SKILL.md",
          "type": "blob",
          "size": 1573
        },
        {
          "path": "git-plugin/skills/release-please-configuration",
          "type": "tree",
          "size": null
        },
        {
          "path": "git-plugin/skills/release-please-configuration/SKILL.md",
          "type": "blob",
          "size": 9025
        },
        {
          "path": "git-plugin/skills/release-please-pr-workflow",
          "type": "tree",
          "size": null
        },
        {
          "path": "git-plugin/skills/release-please-pr-workflow/skill.md",
          "type": "blob",
          "size": 7548
        },
        {
          "path": "git-plugin/skills/release-please-protection",
          "type": "tree",
          "size": null
        },
        {
          "path": "git-plugin/skills/release-please-protection/SKILL.md",
          "type": "blob",
          "size": 9837
        },
        {
          "path": "git-plugin/skills/release-please-protection/patterns.md",
          "type": "blob",
          "size": 8362
        },
        {
          "path": "git-plugin/skills/release-please-protection/workflow.md",
          "type": "blob",
          "size": 13926
        },
        {
          "path": "github-actions-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "github-actions-plugin/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "github-actions-plugin/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 360
        },
        {
          "path": "github-actions-plugin/CHANGELOG.md",
          "type": "blob",
          "size": 666
        },
        {
          "path": "github-actions-plugin/README.md",
          "type": "blob",
          "size": 9912
        },
        {
          "path": "github-actions-plugin/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "github-actions-plugin/commands/workflow",
          "type": "tree",
          "size": null
        },
        {
          "path": "github-actions-plugin/commands/workflow/dev-zen.md",
          "type": "blob",
          "size": 8013
        },
        {
          "path": "github-actions-plugin/commands/workflow/dev.md",
          "type": "blob",
          "size": 7793
        },
        {
          "path": "github-actions-plugin/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "github-actions-plugin/skills/claude-code-github-workflows",
          "type": "tree",
          "size": null
        },
        {
          "path": "github-actions-plugin/skills/claude-code-github-workflows/skill.md",
          "type": "blob",
          "size": 8095
        },
        {
          "path": "github-actions-plugin/skills/github-actions-auth-security",
          "type": "tree",
          "size": null
        },
        {
          "path": "github-actions-plugin/skills/github-actions-auth-security/skill.md",
          "type": "blob",
          "size": 10003
        },
        {
          "path": "github-actions-plugin/skills/github-actions-inspection",
          "type": "tree",
          "size": null
        },
        {
          "path": "github-actions-plugin/skills/github-actions-inspection/skill.md",
          "type": "blob",
          "size": 14739
        },
        {
          "path": "github-actions-plugin/skills/github-actions-mcp-config",
          "type": "tree",
          "size": null
        },
        {
          "path": "github-actions-plugin/skills/github-actions-mcp-config/skill.md",
          "type": "blob",
          "size": 7873
        },
        {
          "path": "github-actions-plugin/skills/github-issue-search",
          "type": "tree",
          "size": null
        },
        {
          "path": "github-actions-plugin/skills/github-issue-search/skill.md",
          "type": "blob",
          "size": 14385
        },
        {
          "path": "github-actions-plugin/skills/github-social-preview",
          "type": "tree",
          "size": null
        },
        {
          "path": "github-actions-plugin/skills/github-social-preview/skill.md",
          "type": "blob",
          "size": 7110
        },
        {
          "path": "graphiti-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "graphiti-plugin/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "graphiti-plugin/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 399
        },
        {
          "path": "graphiti-plugin/README.md",
          "type": "blob",
          "size": 5873
        },
        {
          "path": "graphiti-plugin/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "graphiti-plugin/commands/docs",
          "type": "tree",
          "size": null
        },
        {
          "path": "graphiti-plugin/commands/docs/knowledge-graph.md",
          "type": "blob",
          "size": 1881
        },
        {
          "path": "graphiti-plugin/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "graphiti-plugin/skills/graphiti-episode-storage",
          "type": "tree",
          "size": null
        },
        {
          "path": "graphiti-plugin/skills/graphiti-episode-storage/SKILL.md",
          "type": "blob",
          "size": 9713
        },
        {
          "path": "graphiti-plugin/skills/graphiti-learning-workflows",
          "type": "tree",
          "size": null
        },
        {
          "path": "graphiti-plugin/skills/graphiti-learning-workflows/SKILL.md",
          "type": "blob",
          "size": 10878
        },
        {
          "path": "graphiti-plugin/skills/graphiti-memory-retrieval",
          "type": "tree",
          "size": null
        },
        {
          "path": "graphiti-plugin/skills/graphiti-memory-retrieval/SKILL.md",
          "type": "blob",
          "size": 9732
        },
        {
          "path": "kubernetes-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "kubernetes-plugin/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "kubernetes-plugin/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 219
        },
        {
          "path": "kubernetes-plugin/README.md",
          "type": "blob",
          "size": 8731
        },
        {
          "path": "kubernetes-plugin/SETUP.md",
          "type": "blob",
          "size": 5262
        },
        {
          "path": "kubernetes-plugin/install-skills.sh",
          "type": "blob",
          "size": 1381
        },
        {
          "path": "kubernetes-plugin/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "kubernetes-plugin/skills/argocd-login",
          "type": "tree",
          "size": null
        },
        {
          "path": "kubernetes-plugin/skills/argocd-login/SKILL.md",
          "type": "blob",
          "size": 4567
        },
        {
          "path": "kubernetes-plugin/skills/helm-chart-development",
          "type": "tree",
          "size": null
        },
        {
          "path": "kubernetes-plugin/skills/helm-chart-development/SKILL.md",
          "type": "blob",
          "size": 18040
        },
        {
          "path": "kubernetes-plugin/skills/helm-debugging",
          "type": "tree",
          "size": null
        },
        {
          "path": "kubernetes-plugin/skills/helm-debugging/SKILL.md",
          "type": "blob",
          "size": 18500
        },
        {
          "path": "kubernetes-plugin/skills/helm-release-management",
          "type": "tree",
          "size": null
        },
        {
          "path": "kubernetes-plugin/skills/helm-release-management/SKILL.md",
          "type": "blob",
          "size": 14053
        },
        {
          "path": "kubernetes-plugin/skills/helm-release-recovery",
          "type": "tree",
          "size": null
        },
        {
          "path": "kubernetes-plugin/skills/helm-release-recovery/SKILL.md",
          "type": "blob",
          "size": 16434
        },
        {
          "path": "kubernetes-plugin/skills/helm-values-management",
          "type": "tree",
          "size": null
        },
        {
          "path": "kubernetes-plugin/skills/helm-values-management/SKILL.md",
          "type": "blob",
          "size": 16512
        },
        {
          "path": "kubernetes-plugin/skills/kubectl-debugging",
          "type": "tree",
          "size": null
        },
        {
          "path": "kubernetes-plugin/skills/kubectl-debugging/REFERENCE.md",
          "type": "blob",
          "size": 16936
        },
        {
          "path": "kubernetes-plugin/skills/kubectl-debugging/SKILL.md",
          "type": "blob",
          "size": 6459
        },
        {
          "path": "kubernetes-plugin/skills/kubernetes-operations",
          "type": "tree",
          "size": null
        },
        {
          "path": "kubernetes-plugin/skills/kubernetes-operations/REFERENCE.md",
          "type": "blob",
          "size": 23082
        },
        {
          "path": "kubernetes-plugin/skills/kubernetes-operations/SKILL.md",
          "type": "blob",
          "size": 4327
        },
        {
          "path": "langchain-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "langchain-plugin/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "langchain-plugin/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 458
        },
        {
          "path": "langchain-plugin/CHANGELOG.md",
          "type": "blob",
          "size": 390
        },
        {
          "path": "langchain-plugin/README.md",
          "type": "blob",
          "size": 2208
        },
        {
          "path": "langchain-plugin/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "langchain-plugin/commands/langchain-init.md",
          "type": "blob",
          "size": 3359
        },
        {
          "path": "langchain-plugin/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "langchain-plugin/skills/deep-agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "langchain-plugin/skills/deep-agents/skill.md",
          "type": "blob",
          "size": 8671
        },
        {
          "path": "langchain-plugin/skills/langchain-development",
          "type": "tree",
          "size": null
        },
        {
          "path": "langchain-plugin/skills/langchain-development/skill.md",
          "type": "blob",
          "size": 8454
        },
        {
          "path": "langchain-plugin/skills/langgraph-agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "langchain-plugin/skills/langgraph-agents/skill.md",
          "type": "blob",
          "size": 9609
        },
        {
          "path": "networking-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "networking-plugin/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "networking-plugin/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 971
        },
        {
          "path": "networking-plugin/CHANGELOG.md",
          "type": "blob",
          "size": 332
        },
        {
          "path": "networking-plugin/README.md",
          "type": "blob",
          "size": 2574
        },
        {
          "path": "networking-plugin/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "networking-plugin/skills/dns-tools",
          "type": "tree",
          "size": null
        },
        {
          "path": "networking-plugin/skills/dns-tools/skill.md",
          "type": "blob",
          "size": 5995
        },
        {
          "path": "networking-plugin/skills/http-load-testing",
          "type": "tree",
          "size": null
        },
        {
          "path": "networking-plugin/skills/http-load-testing/skill.md",
          "type": "blob",
          "size": 8358
        },
        {
          "path": "networking-plugin/skills/layer2-discovery",
          "type": "tree",
          "size": null
        },
        {
          "path": "networking-plugin/skills/layer2-discovery/skill.md",
          "type": "blob",
          "size": 8533
        },
        {
          "path": "networking-plugin/skills/network-diagnostics",
          "type": "tree",
          "size": null
        },
        {
          "path": "networking-plugin/skills/network-diagnostics/skill.md",
          "type": "blob",
          "size": 9058
        },
        {
          "path": "networking-plugin/skills/network-discovery",
          "type": "tree",
          "size": null
        },
        {
          "path": "networking-plugin/skills/network-discovery/skill.md",
          "type": "blob",
          "size": 6750
        },
        {
          "path": "networking-plugin/skills/network-monitoring",
          "type": "tree",
          "size": null
        },
        {
          "path": "networking-plugin/skills/network-monitoring/skill.md",
          "type": "blob",
          "size": 5345
        },
        {
          "path": "project-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "project-plugin/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "project-plugin/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 419
        },
        {
          "path": "project-plugin/CHANGELOG.md",
          "type": "blob",
          "size": 956
        },
        {
          "path": "project-plugin/README.md",
          "type": "blob",
          "size": 7357
        },
        {
          "path": "project-plugin/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "project-plugin/commands/project",
          "type": "tree",
          "size": null
        },
        {
          "path": "project-plugin/commands/project/continue.md",
          "type": "blob",
          "size": 3588
        },
        {
          "path": "project-plugin/commands/project/init.md",
          "type": "blob",
          "size": 4142
        },
        {
          "path": "project-plugin/commands/project/test-loop.md",
          "type": "blob",
          "size": 4724
        },
        {
          "path": "project-plugin/copy-remaining-files.sh",
          "type": "blob",
          "size": 666
        },
        {
          "path": "project-plugin/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "project-plugin/skills/project-discovery",
          "type": "tree",
          "size": null
        },
        {
          "path": "project-plugin/skills/project-discovery/SKILL.md",
          "type": "blob",
          "size": 16423
        },
        {
          "path": "python-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "python-plugin/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "python-plugin/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 403
        },
        {
          "path": "python-plugin/README.md",
          "type": "blob",
          "size": 2185
        },
        {
          "path": "python-plugin/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "python-plugin/skills/basedpyright-type-checking",
          "type": "tree",
          "size": null
        },
        {
          "path": "python-plugin/skills/basedpyright-type-checking/SKILL.md",
          "type": "blob",
          "size": 14007
        },
        {
          "path": "python-plugin/skills/pytest-advanced",
          "type": "tree",
          "size": null
        },
        {
          "path": "python-plugin/skills/pytest-advanced/SKILL.md",
          "type": "blob",
          "size": 27721
        },
        {
          "path": "python-plugin/skills/python-code-quality",
          "type": "tree",
          "size": null
        },
        {
          "path": "python-plugin/skills/python-code-quality/REFERENCE.md",
          "type": "blob",
          "size": 1504
        },
        {
          "path": "python-plugin/skills/python-code-quality/SKILL.md",
          "type": "blob",
          "size": 3247
        },
        {
          "path": "python-plugin/skills/python-development",
          "type": "tree",
          "size": null
        },
        {
          "path": "python-plugin/skills/python-development/REFERENCE.md",
          "type": "blob",
          "size": 6444
        },
        {
          "path": "python-plugin/skills/python-development/SKILL.md",
          "type": "blob",
          "size": 8422
        },
        {
          "path": "python-plugin/skills/python-packaging",
          "type": "tree",
          "size": null
        },
        {
          "path": "python-plugin/skills/python-packaging/REFERENCE.md",
          "type": "blob",
          "size": 2283
        },
        {
          "path": "python-plugin/skills/python-packaging/SKILL.md",
          "type": "blob",
          "size": 4466
        },
        {
          "path": "python-plugin/skills/python-testing",
          "type": "tree",
          "size": null
        },
        {
          "path": "python-plugin/skills/python-testing/REFERENCE.md",
          "type": "blob",
          "size": 2217
        },
        {
          "path": "python-plugin/skills/python-testing/SKILL.md",
          "type": "blob",
          "size": 5761
        },
        {
          "path": "python-plugin/skills/ruff-formatting",
          "type": "tree",
          "size": null
        },
        {
          "path": "python-plugin/skills/ruff-formatting/SKILL.md",
          "type": "blob",
          "size": 11952
        },
        {
          "path": "python-plugin/skills/ruff-integration",
          "type": "tree",
          "size": null
        },
        {
          "path": "python-plugin/skills/ruff-integration/SKILL.md",
          "type": "blob",
          "size": 15412
        },
        {
          "path": "python-plugin/skills/ruff-linting",
          "type": "tree",
          "size": null
        },
        {
          "path": "python-plugin/skills/ruff-linting/SKILL.md",
          "type": "blob",
          "size": 10631
        },
        {
          "path": "python-plugin/skills/uv-advanced-dependencies",
          "type": "tree",
          "size": null
        },
        {
          "path": "python-plugin/skills/uv-advanced-dependencies/REFERENCE.md",
          "type": "blob",
          "size": 7951
        },
        {
          "path": "python-plugin/skills/uv-advanced-dependencies/SKILL.md",
          "type": "blob",
          "size": 5142
        },
        {
          "path": "python-plugin/skills/uv-project-management",
          "type": "tree",
          "size": null
        },
        {
          "path": "python-plugin/skills/uv-project-management/REFERENCE.md",
          "type": "blob",
          "size": 14324
        },
        {
          "path": "python-plugin/skills/uv-project-management/SKILL.md",
          "type": "blob",
          "size": 3877
        },
        {
          "path": "python-plugin/skills/uv-python-versions",
          "type": "tree",
          "size": null
        },
        {
          "path": "python-plugin/skills/uv-python-versions/REFERENCE.md",
          "type": "blob",
          "size": 15371
        },
        {
          "path": "python-plugin/skills/uv-python-versions/SKILL.md",
          "type": "blob",
          "size": 4669
        },
        {
          "path": "python-plugin/skills/uv-run",
          "type": "tree",
          "size": null
        },
        {
          "path": "python-plugin/skills/uv-run/SKILL.md",
          "type": "blob",
          "size": 4774
        },
        {
          "path": "python-plugin/skills/uv-tool-management",
          "type": "tree",
          "size": null
        },
        {
          "path": "python-plugin/skills/uv-tool-management/REFERENCE.md",
          "type": "blob",
          "size": 12888
        },
        {
          "path": "python-plugin/skills/uv-tool-management/SKILL.md",
          "type": "blob",
          "size": 4765
        },
        {
          "path": "python-plugin/skills/uv-workspaces",
          "type": "tree",
          "size": null
        },
        {
          "path": "python-plugin/skills/uv-workspaces/REFERENCE.md",
          "type": "blob",
          "size": 11960
        },
        {
          "path": "python-plugin/skills/uv-workspaces/SKILL.md",
          "type": "blob",
          "size": 5035
        },
        {
          "path": "python-plugin/skills/vulture-dead-code",
          "type": "tree",
          "size": null
        },
        {
          "path": "python-plugin/skills/vulture-dead-code/SKILL.md",
          "type": "blob",
          "size": 14534
        },
        {
          "path": "release-please-config.json",
          "type": "blob",
          "size": 15416
        },
        {
          "path": "rust-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "rust-plugin/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "rust-plugin/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 198
        },
        {
          "path": "rust-plugin/README.md",
          "type": "blob",
          "size": 8091
        },
        {
          "path": "rust-plugin/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "rust-plugin/skills/cargo-llvm-cov",
          "type": "tree",
          "size": null
        },
        {
          "path": "rust-plugin/skills/cargo-llvm-cov/SKILL.md",
          "type": "blob",
          "size": 9966
        },
        {
          "path": "rust-plugin/skills/cargo-machete",
          "type": "tree",
          "size": null
        },
        {
          "path": "rust-plugin/skills/cargo-machete/SKILL.md",
          "type": "blob",
          "size": 9097
        },
        {
          "path": "rust-plugin/skills/cargo-nextest",
          "type": "tree",
          "size": null
        },
        {
          "path": "rust-plugin/skills/cargo-nextest/SKILL.md",
          "type": "blob",
          "size": 7706
        },
        {
          "path": "rust-plugin/skills/clippy-advanced",
          "type": "tree",
          "size": null
        },
        {
          "path": "rust-plugin/skills/clippy-advanced/SKILL.md",
          "type": "blob",
          "size": 14178
        },
        {
          "path": "rust-plugin/skills/rust-development",
          "type": "tree",
          "size": null
        },
        {
          "path": "rust-plugin/skills/rust-development/REFERENCE.md",
          "type": "blob",
          "size": 13083
        },
        {
          "path": "rust-plugin/skills/rust-development/SKILL.md",
          "type": "blob",
          "size": 6123
        },
        {
          "path": "sync-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "sync-plugin/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "sync-plugin/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 979
        },
        {
          "path": "sync-plugin/README.md",
          "type": "blob",
          "size": 8151
        },
        {
          "path": "sync-plugin/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "sync-plugin/commands/sync",
          "type": "tree",
          "size": null
        },
        {
          "path": "sync-plugin/commands/sync/daily.md",
          "type": "blob",
          "size": 11060
        },
        {
          "path": "sync-plugin/commands/sync/github-podio.md",
          "type": "blob",
          "size": 7882
        },
        {
          "path": "terraform-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "terraform-plugin/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "terraform-plugin/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 191
        },
        {
          "path": "terraform-plugin/README.md",
          "type": "blob",
          "size": 2091
        },
        {
          "path": "terraform-plugin/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "terraform-plugin/skills/infrastructure-terraform",
          "type": "tree",
          "size": null
        },
        {
          "path": "terraform-plugin/skills/infrastructure-terraform/REFERENCE.md",
          "type": "blob",
          "size": 22683
        },
        {
          "path": "terraform-plugin/skills/infrastructure-terraform/SKILL.md",
          "type": "blob",
          "size": 3878
        },
        {
          "path": "terraform-plugin/skills/tfc-list-runs",
          "type": "tree",
          "size": null
        },
        {
          "path": "terraform-plugin/skills/tfc-list-runs/SKILL.md",
          "type": "blob",
          "size": 6527
        },
        {
          "path": "terraform-plugin/skills/tfc-plan-json",
          "type": "tree",
          "size": null
        },
        {
          "path": "terraform-plugin/skills/tfc-plan-json/SKILL.md",
          "type": "blob",
          "size": 8015
        },
        {
          "path": "terraform-plugin/skills/tfc-run-logs",
          "type": "tree",
          "size": null
        },
        {
          "path": "terraform-plugin/skills/tfc-run-logs/SKILL.md",
          "type": "blob",
          "size": 4373
        },
        {
          "path": "terraform-plugin/skills/tfc-run-status",
          "type": "tree",
          "size": null
        },
        {
          "path": "terraform-plugin/skills/tfc-run-status/SKILL.md",
          "type": "blob",
          "size": 6384
        },
        {
          "path": "terraform-plugin/skills/tfc-workspace-runs",
          "type": "tree",
          "size": null
        },
        {
          "path": "terraform-plugin/skills/tfc-workspace-runs/SKILL.md",
          "type": "blob",
          "size": 7523
        },
        {
          "path": "testing-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "testing-plugin/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "testing-plugin/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 413
        },
        {
          "path": "testing-plugin/CHANGELOG.md",
          "type": "blob",
          "size": 1121
        },
        {
          "path": "testing-plugin/README.md",
          "type": "blob",
          "size": 3017
        },
        {
          "path": "testing-plugin/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "testing-plugin/commands/test",
          "type": "tree",
          "size": null
        },
        {
          "path": "testing-plugin/commands/test/analyze.md",
          "type": "blob",
          "size": 7761
        },
        {
          "path": "testing-plugin/commands/test/consult.md",
          "type": "blob",
          "size": 2257
        },
        {
          "path": "testing-plugin/commands/test/full.md",
          "type": "blob",
          "size": 2492
        },
        {
          "path": "testing-plugin/commands/test/quick.md",
          "type": "blob",
          "size": 2104
        },
        {
          "path": "testing-plugin/commands/test/report.md",
          "type": "blob",
          "size": 2324
        },
        {
          "path": "testing-plugin/commands/test/run.md",
          "type": "blob",
          "size": 2265
        },
        {
          "path": "testing-plugin/commands/test/setup.md",
          "type": "blob",
          "size": 1893
        },
        {
          "path": "testing-plugin/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "testing-plugin/skills/hypothesis-testing",
          "type": "tree",
          "size": null
        },
        {
          "path": "testing-plugin/skills/hypothesis-testing/SKILL.md",
          "type": "blob",
          "size": 23245
        },
        {
          "path": "testing-plugin/skills/mutation-testing",
          "type": "tree",
          "size": null
        },
        {
          "path": "testing-plugin/skills/mutation-testing/SKILL.md",
          "type": "blob",
          "size": 14440
        },
        {
          "path": "testing-plugin/skills/playwright-testing",
          "type": "tree",
          "size": null
        },
        {
          "path": "testing-plugin/skills/playwright-testing/SKILL.md",
          "type": "blob",
          "size": 16504
        },
        {
          "path": "testing-plugin/skills/property-based-testing",
          "type": "tree",
          "size": null
        },
        {
          "path": "testing-plugin/skills/property-based-testing/SKILL.md",
          "type": "blob",
          "size": 19017
        },
        {
          "path": "testing-plugin/skills/test-quality-analysis",
          "type": "tree",
          "size": null
        },
        {
          "path": "testing-plugin/skills/test-quality-analysis/SKILL.md",
          "type": "blob",
          "size": 16851
        },
        {
          "path": "testing-plugin/skills/test-tier-selection",
          "type": "tree",
          "size": null
        },
        {
          "path": "testing-plugin/skills/test-tier-selection/SKILL.md",
          "type": "blob",
          "size": 3148
        },
        {
          "path": "testing-plugin/skills/vitest-testing",
          "type": "tree",
          "size": null
        },
        {
          "path": "testing-plugin/skills/vitest-testing/SKILL.md",
          "type": "blob",
          "size": 14480
        },
        {
          "path": "tools-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "tools-plugin/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "tools-plugin/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 472
        },
        {
          "path": "tools-plugin/CHANGELOG.md",
          "type": "blob",
          "size": 1800
        },
        {
          "path": "tools-plugin/README.md",
          "type": "blob",
          "size": 3789
        },
        {
          "path": "tools-plugin/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "tools-plugin/commands/deps",
          "type": "tree",
          "size": null
        },
        {
          "path": "tools-plugin/commands/deps/install.md",
          "type": "blob",
          "size": 3132
        },
        {
          "path": "tools-plugin/commands/generate-image.md",
          "type": "blob",
          "size": 2867
        },
        {
          "path": "tools-plugin/commands/handoffs.md",
          "type": "blob",
          "size": 5656
        },
        {
          "path": "tools-plugin/commands/tools",
          "type": "tree",
          "size": null
        },
        {
          "path": "tools-plugin/commands/tools/vectorcode.md",
          "type": "blob",
          "size": 7919
        },
        {
          "path": "tools-plugin/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "tools-plugin/skills/binary-analysis",
          "type": "tree",
          "size": null
        },
        {
          "path": "tools-plugin/skills/binary-analysis/SKILL.md",
          "type": "blob",
          "size": 5560
        },
        {
          "path": "tools-plugin/skills/d2-diagrams",
          "type": "tree",
          "size": null
        },
        {
          "path": "tools-plugin/skills/d2-diagrams/skill.md",
          "type": "blob",
          "size": 7786
        },
        {
          "path": "tools-plugin/skills/fd-file-finding",
          "type": "tree",
          "size": null
        },
        {
          "path": "tools-plugin/skills/fd-file-finding/SKILL.md",
          "type": "blob",
          "size": 7091
        },
        {
          "path": "tools-plugin/skills/imagemagick-conversion",
          "type": "tree",
          "size": null
        },
        {
          "path": "tools-plugin/skills/imagemagick-conversion/SKILL.md",
          "type": "blob",
          "size": 7498
        },
        {
          "path": "tools-plugin/skills/jq-json-processing",
          "type": "tree",
          "size": null
        },
        {
          "path": "tools-plugin/skills/jq-json-processing/SKILL.md",
          "type": "blob",
          "size": 10422
        },
        {
          "path": "tools-plugin/skills/justfile-expert",
          "type": "tree",
          "size": null
        },
        {
          "path": "tools-plugin/skills/justfile-expert/REFERENCE.md",
          "type": "blob",
          "size": 12737
        },
        {
          "path": "tools-plugin/skills/justfile-expert/SKILL.md",
          "type": "blob",
          "size": 6845
        },
        {
          "path": "tools-plugin/skills/mermaid-diagrams",
          "type": "tree",
          "size": null
        },
        {
          "path": "tools-plugin/skills/mermaid-diagrams/skill.md",
          "type": "blob",
          "size": 6088
        },
        {
          "path": "tools-plugin/skills/nushell-data-processing",
          "type": "tree",
          "size": null
        },
        {
          "path": "tools-plugin/skills/nushell-data-processing/skill.md",
          "type": "blob",
          "size": 7049
        },
        {
          "path": "tools-plugin/skills/rg-code-search",
          "type": "tree",
          "size": null
        },
        {
          "path": "tools-plugin/skills/rg-code-search/SKILL.md",
          "type": "blob",
          "size": 9490
        },
        {
          "path": "tools-plugin/skills/shell-expert",
          "type": "tree",
          "size": null
        },
        {
          "path": "tools-plugin/skills/shell-expert/REFERENCE.md",
          "type": "blob",
          "size": 8801
        },
        {
          "path": "tools-plugin/skills/shell-expert/SKILL.md",
          "type": "blob",
          "size": 5311
        },
        {
          "path": "tools-plugin/skills/vectorcode-init",
          "type": "tree",
          "size": null
        },
        {
          "path": "tools-plugin/skills/vectorcode-init/SKILL.md",
          "type": "blob",
          "size": 6153
        },
        {
          "path": "tools-plugin/skills/vectorcode-init/patterns.md",
          "type": "blob",
          "size": 5776
        },
        {
          "path": "tools-plugin/skills/vectorcode-search",
          "type": "tree",
          "size": null
        },
        {
          "path": "tools-plugin/skills/vectorcode-search/SKILL.md",
          "type": "blob",
          "size": 14225
        },
        {
          "path": "tools-plugin/skills/yq-yaml-processing",
          "type": "tree",
          "size": null
        },
        {
          "path": "tools-plugin/skills/yq-yaml-processing/SKILL.md",
          "type": "blob",
          "size": 13576
        },
        {
          "path": "typescript-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "typescript-plugin/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "typescript-plugin/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 457
        },
        {
          "path": "typescript-plugin/CHANGELOG.md",
          "type": "blob",
          "size": 1730
        },
        {
          "path": "typescript-plugin/README.md",
          "type": "blob",
          "size": 1894
        },
        {
          "path": "typescript-plugin/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "typescript-plugin/commands/bun",
          "type": "tree",
          "size": null
        },
        {
          "path": "typescript-plugin/commands/bun/add.md",
          "type": "blob",
          "size": 953
        },
        {
          "path": "typescript-plugin/commands/bun/build.md",
          "type": "blob",
          "size": 1123
        },
        {
          "path": "typescript-plugin/commands/bun/install.md",
          "type": "blob",
          "size": 864
        },
        {
          "path": "typescript-plugin/commands/bun/outdated.md",
          "type": "blob",
          "size": 823
        },
        {
          "path": "typescript-plugin/commands/bun/publish.md",
          "type": "blob",
          "size": 1851
        },
        {
          "path": "typescript-plugin/commands/bun/test.md",
          "type": "blob",
          "size": 1137
        },
        {
          "path": "typescript-plugin/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "typescript-plugin/skills/biome-tooling",
          "type": "tree",
          "size": null
        },
        {
          "path": "typescript-plugin/skills/biome-tooling/SKILL.md",
          "type": "blob",
          "size": 11914
        },
        {
          "path": "typescript-plugin/skills/bun-development",
          "type": "tree",
          "size": null
        },
        {
          "path": "typescript-plugin/skills/bun-development/skill.md",
          "type": "blob",
          "size": 5021
        },
        {
          "path": "typescript-plugin/skills/bun-lockfile-update",
          "type": "tree",
          "size": null
        },
        {
          "path": "typescript-plugin/skills/bun-lockfile-update/SKILL.md",
          "type": "blob",
          "size": 9387
        },
        {
          "path": "typescript-plugin/skills/bun-package-manager",
          "type": "tree",
          "size": null
        },
        {
          "path": "typescript-plugin/skills/bun-package-manager/skill.md",
          "type": "blob",
          "size": 3611
        },
        {
          "path": "typescript-plugin/skills/bun-publishing",
          "type": "tree",
          "size": null
        },
        {
          "path": "typescript-plugin/skills/bun-publishing/skill.md",
          "type": "blob",
          "size": 7059
        },
        {
          "path": "typescript-plugin/skills/knip-dead-code",
          "type": "tree",
          "size": null
        },
        {
          "path": "typescript-plugin/skills/knip-dead-code/SKILL.md",
          "type": "blob",
          "size": 13184
        },
        {
          "path": "typescript-plugin/skills/nodejs-development",
          "type": "tree",
          "size": null
        },
        {
          "path": "typescript-plugin/skills/nodejs-development/REFERENCE.md",
          "type": "blob",
          "size": 14954
        },
        {
          "path": "typescript-plugin/skills/nodejs-development/SKILL.md",
          "type": "blob",
          "size": 3989
        },
        {
          "path": "typescript-plugin/skills/typescript-strict",
          "type": "tree",
          "size": null
        },
        {
          "path": "typescript-plugin/skills/typescript-strict/SKILL.md",
          "type": "blob",
          "size": 15367
        }
      ],
      "marketplace": {
        "name": "lgates-claude-plugins",
        "version": null,
        "description": null,
        "owner_info": {
          "name": "Lauri Gates"
        },
        "keywords": [],
        "plugins": [
          {
            "name": "blueprint-plugin",
            "description": "Blueprint Development methodology - PRD/PRP workflow with version tracking, modular rules, and CLAUDE.md management",
            "source": "./blueprint-plugin",
            "category": "development",
            "version": "3.0.0",
            "author": null,
            "install_commands": [
              "/plugin marketplace add laurigates/claude-plugins",
              "/plugin install blueprint-plugin@lgates-claude-plugins"
            ],
            "signals": {
              "stars": 1,
              "forks": 0,
              "pushed_at": "2026-01-12T12:05:51Z",
              "created_at": "2025-12-16T11:24:04Z",
              "license": null
            },
            "commands": [
              {
                "name": "/blueprint-adr",
                "description": "Generate Architecture Decision Records from existing project structure and documentation",
                "path": "blueprint-plugin/commands/blueprint-adr.md",
                "frontmatter": {
                  "created": "2025-12-22T00:00:00.000Z",
                  "modified": "2026-01-09T00:00:00.000Z",
                  "reviewed": "2025-12-22T00:00:00.000Z",
                  "description": "Generate Architecture Decision Records from existing project structure and documentation",
                  "allowed_tools": [
                    "Read",
                    "Write",
                    "Glob",
                    "Grep",
                    "Bash",
                    "AskUserQuestion",
                    "Task"
                  ]
                },
                "content": "Generate Architecture Decision Records (ADRs) for an existing project by analyzing code structure, dependencies, and documentation.\n\n**Use Case**: Onboarding existing projects to Blueprint Development system, documenting implicit architecture decisions.\n\n**Prerequisites**:\n- Blueprint Development initialized (`docs/blueprint/` exists)\n- Ideally PRD exists (run `/blueprint:prd` first)\n\n**Steps**:\n\n## Phase 1: Discovery\n\n### 1.1 Check Prerequisites\n```bash\nls docs/blueprint/manifest.json\nls docs/prds/\n```\nIf blueprint not initialized  suggest `/blueprint:init`\nIf no PRD  suggest `/blueprint:prd` first (recommended, not required)\n\n### 1.2 Create ADR Directory\n```bash\nmkdir -p docs/adrs\n```\n\n### 1.3 Analyze Project Structure\nExplore the codebase to identify architectural patterns:\n\nUse Explore agent:\n```\n<Task subagent_type=\"Explore\" prompt=\"Analyze project architecture: directory structure, major components, frameworks used, design patterns\">\n```\n\nKey areas to examine:\n- **Directory structure**: How code is organized\n- **Entry points**: Main files, index files\n- **Configuration**: Config files, environment handling\n- **Dependencies**: Package manifests, imports\n- **Data layer**: Database, ORM, data models\n- **API layer**: Routes, controllers, handlers\n- **Testing**: Test structure and frameworks\n\n## Phase 2: Identify Architecture Decisions\n\n### 2.1 Common Decision Categories\n\n| Category | What to Look For | Example Decisions |\n|----------|-----------------|-------------------|\n| **Framework** | package.json, imports | React vs Vue, Express vs Fastify |\n| **Language** | File extensions, tsconfig | TypeScript vs JavaScript |\n| **State Management** | Store patterns, context | Redux vs Zustand vs Context |\n| **Styling** | CSS files, styled imports | Tailwind vs CSS-in-JS vs SCSS |\n| **Testing** | Test files, test config | Vitest vs Jest, Playwright vs Cypress |\n| **Build** | Build config, bundlers | Vite vs Webpack, esbuild |\n| **Database** | ORM config, migrations | PostgreSQL vs MongoDB, Prisma vs Drizzle |\n| **API Style** | Route patterns, schemas | REST vs GraphQL, tRPC |\n| **Deployment** | Docker, CI config | Container vs serverless |\n| **Monorepo** | Workspace config | Turborepo vs Nx vs none |\n\n### 2.2 Infer Decisions from Code\nFor each identified technology choice:\n1. Note the current implementation\n2. Consider common alternatives\n3. Infer rationale from context/comments\n\n### 2.3 Confirm with User\nUse AskUserQuestion for key decisions:\n\n```\nquestion: \"I found the project uses {technology}. Why was this chosen over alternatives?\"\noptions:\n  - \"Performance requirements\"  document performance rationale\n  - \"Team familiarity\"  document team expertise factor\n  - \"Ecosystem/community\"  document ecosystem benefits\n  - \"Specific feature needs\"  ask for details\n  - \"Legacy/inherited decision\"  document as inherited\n  - \"Other\"  custom rationale\n```\n\n```\nquestion: \"Are there any architecture decisions you'd like to document that aren't visible in the code?\"\noptions:\n  - \"Yes, let me describe\"  capture additional decisions\n  - \"No, the inferred decisions are sufficient\"  proceed\n```\n\n## Phase 3: ADR Generation\n\n### 3.1 ADR Template (MADR format)\nFor each significant decision, create an ADR:\n\n```markdown\n# ADR-{number}: {Title}\n\n**Date**: {date}\n**Status**: Accepted | Superseded | Deprecated\n**Deciders**: {who made the decision}\n\n## Context\n\n{Describe the issue motivating this decision}\n{What is the problem we're trying to solve?}\n{What constraints exist?}\n\n## Decision Drivers\n\n- {driver 1, e.g., \"Performance under high load\"}\n- {driver 2, e.g., \"Developer experience\"}\n- {driver 3, e.g., \"Maintainability\"}\n\n## Considered Options\n\n1. **{Option 1}** - {brief description}\n2. **{Option 2}** - {brief description}\n3. **{Option 3}** - {brief description}\n\n## Decision Outcome\n\n**Chosen option**: \"{Option X}\" because {justification}.\n\n### Positive Consequences\n\n- {positive outcome 1}\n- {positive outcome 2}\n\n### Negative Consequences\n\n- {negative outcome / tradeoff 1}\n- {negative outcome / tradeoff 2}\n\n## Pros and Cons of Options\n\n### {Option 1}\n\n-  {pro 1}\n-  {pro 2}\n-  {con 1}\n\n### {Option 2}\n\n-  {pro 1}\n-  {con 1}\n-  {con 2}\n\n## Links\n\n- {Related ADRs}\n- {External documentation}\n- {Discussion threads}\n\n---\n*Generated from project analysis via /blueprint:adr*\n```\n\n### 3.2 Standard ADRs to Generate\n\nGenerate ADRs for these common decisions (if applicable):\n\n| ADR | When to Create |\n|-----|----------------|\n| `0001-project-language.md` | Language/runtime choice |\n| `0002-framework-choice.md` | Main framework selection |\n| `0003-testing-strategy.md` | Test framework and approach |\n| `0004-styling-approach.md` | CSS/styling methodology |\n| `0005-state-management.md` | State handling (if applicable) |\n| `0006-database-choice.md` | Database and ORM (if applicable) |\n| `0007-api-design.md` | API style and patterns |\n| `0008-deployment-strategy.md` | Deployment approach |\n\n### 3.3 Create Index\nGenerate an ADR index file:\n\n```markdown\n# Architecture Decision Records\n\nThis directory contains Architecture Decision Records (ADRs) documenting significant technical decisions for this project.\n\n## Index\n\n| ADR | Title | Status | Date |\n|-----|-------|--------|------|\n| [0001](0001-project-language.md) | {Title} | Accepted | {date} |\n| [0002](0002-framework-choice.md) | {Title} | Accepted | {date} |\n\n## Template\n\nNew ADRs should follow the [MADR template](https://adr.github.io/madr/).\n\n## Creating New ADRs\n\nUse `/blueprint:adr` or the `architecture-decisions` agent to create new ADRs.\n```\n\n## Phase 4: Validation & Follow-up\n\n### 4.1 Present Summary\n```\n ADRs Generated: {count} records\n\n**Location**: `docs/adrs/`\n\n**Decisions documented**:\n- ADR-0001: {title} - {status}\n- ADR-0002: {title} - {status}\n...\n\n**Sources analyzed**:\n- {list of analyzed files/patterns}\n\n**Confidence levels**:\n- High confidence: {list - clear from code}\n- Inferred: {list - reasonable assumptions}\n- Needs review: {list - uncertain}\n\n**Recommended next steps**:\n1. Review generated ADRs for accuracy\n2. Add rationale where marked as \"inferred\"\n3. Run `/blueprint:prp-create` for feature implementation\n4. Run `/blueprint:generate-skills` for project skills\n```\n\n### 4.2 Suggest Next Steps\n- If PRD missing  suggest `/blueprint:prd`\n- If ready for implementation  suggest `/blueprint:prp-create`\n- If architecture evolving  explain how to add new ADRs\n\n## Phase 5: Update Manifest\n\nUpdate `docs/blueprint/manifest.json`:\n- Add `has_adrs: true` to structure\n- Add ADRs to `generated_artifacts`\n- Update `updated_at` timestamp\n\n**Tips**:\n- Focus on decisions with real alternatives (not obvious choices)\n- Document inherited/legacy decisions as such\n- Mark uncertain rationales for user review\n- Keep ADRs concise - focus on \"why\", not implementation details\n- Reference related ADRs when decisions are connected\n\n### 4.3 Prompt for next action (use AskUserQuestion):\n\n```\nquestion: \"ADRs generated. What would you like to do next?\"\noptions:\n  - label: \"Create a PRP for feature work (Recommended)\"\n    description: \"Start implementing a specific feature with /blueprint:prp-create\"\n  - label: \"Generate project skills\"\n    description: \"Create skills from PRDs for Claude context\"\n  - label: \"Review and add rationale\"\n    description: \"Edit ADRs marked as 'inferred' or 'needs rationale'\"\n  - label: \"Document another architecture decision\"\n    description: \"Manually add a new ADR\"\n  - label: \"I'm done for now\"\n    description: \"Exit - ADRs are saved\"\n```\n\n**Based on selection:**\n- \"Create a PRP\"  Run `/blueprint:prp-create` (ask for feature name)\n- \"Generate project skills\"  Run `/blueprint:generate-skills`\n- \"Review and add rationale\"  Show ADR files needing attention\n- \"Document another decision\"  Restart Phase 2 for a specific decision\n- \"I'm done\"  Exit\n\n**Error Handling**:\n- If minimal codebase  create fewer, broader ADRs\n- If conflicting patterns  ask user which is intentional\n- If rationale unclear  mark as \"needs rationale\" for user input"
              },
              {
                "name": "/blueprint-claude-md",
                "description": "Generate or update CLAUDE.md from project context and blueprint artifacts",
                "path": "blueprint-plugin/commands/blueprint-claude-md.md",
                "frontmatter": {
                  "created": "2025-12-17T00:00:00.000Z",
                  "modified": "2026-01-09T00:00:00.000Z",
                  "reviewed": "2025-12-17T00:00:00.000Z",
                  "description": "Generate or update CLAUDE.md from project context and blueprint artifacts",
                  "allowed_tools": [
                    "Read",
                    "Write",
                    "Edit",
                    "Bash",
                    "Glob",
                    "Grep",
                    "AskUserQuestion"
                  ]
                },
                "content": "Generate or update the project's CLAUDE.md file based on blueprint artifacts, PRDs, and project structure.\n\n**Steps**:\n\n1. **Check current state**:\n   - Look for existing `CLAUDE.md` in project root\n   - Read `docs/blueprint/manifest.json` for configuration\n   - Determine `claude_md_mode` (single, modular, or both)\n\n2. **Determine action** (use AskUserQuestion):\n   ```\n   {If CLAUDE.md exists:}\n   question: \"CLAUDE.md already exists. What would you like to do?\"\n   options:\n     - \"Update with latest project info\"  merge updates\n     - \"Regenerate completely\"  overwrite (backup first)\n     - \"Add missing sections only\"  append new content\n     - \"Convert to modular rules\"  split into .claude/rules/\n     - \"View current structure\"  analyze and display\n\n   {If CLAUDE.md doesn't exist:}\n   question: \"No CLAUDE.md found. How would you like to create it?\"\n   options:\n     - \"Generate from project analysis\"  auto-generate\n     - \"Generate from PRDs\"  use blueprint PRDs\n     - \"Start with template\"  use starter template\n     - \"Use modular rules instead\"  skip CLAUDE.md, use rules/\n   ```\n\n3. **Gather project context**:\n   - **Project structure**: Detect language, framework, build tools\n   - **PRDs**: Read `docs/prds/*.md` for requirements\n   - **Work overview**: Current phase and progress\n   - **Existing rules**: Content from `.claude/rules/` if present\n   - **Git history**: Recent patterns and conventions\n   - **Dependencies**: Package managers, key libraries\n\n4. **Generate CLAUDE.md sections**:\n\n   **Standard sections**:\n   ```markdown\n   # Project: {name}\n\n   ## Overview\n   {Brief project description from PRDs or detection}\n\n   ## Tech Stack\n   - Language: {detected}\n   - Framework: {detected}\n   - Build: {detected}\n   - Test: {detected}\n\n   ## Development Workflow\n\n   ### Getting Started\n   {Setup commands}\n\n   ### Running Tests\n   {Test commands}\n\n   ### Building\n   {Build commands}\n\n   ## Architecture\n   {Key architectural decisions from PRDs}\n\n   ## Conventions\n\n   ### Code Style\n   {Detected or from PRDs}\n\n   ### Commit Messages\n   {Conventional commits if detected}\n\n   ### Testing Requirements\n   {From PRDs or rules}\n\n   ## Current Focus\n   {From work-overview.md}\n\n   ## Key Files\n   {Important files and their purposes}\n\n   ## See Also\n   {If modular rules enabled:}\n   - `.claude/rules/` - Detailed rules by domain\n   - `docs/prds/` - Product requirements\n   ```\n\n5. **If modular rules mode = \"both\"**:\n   - Keep CLAUDE.md as high-level overview\n   - Reference `.claude/rules/` for details:\n     ```markdown\n     ## Detailed Rules\n     See `.claude/rules/` for domain-specific guidelines:\n     - `development.md` - Development workflow\n     - `testing.md` - Testing requirements\n     - `frontend/` - Frontend-specific rules\n     - `backend/` - Backend-specific rules\n     ```\n\n6. **If modular rules mode = \"modular\"**:\n   - Create minimal CLAUDE.md with references\n   - Move detailed content to `.claude/rules/`\n\n7. **Smart update** (for existing CLAUDE.md):\n   - Parse existing sections\n   - Identify outdated content (compare with PRDs, structure)\n   - Offer section-by-section updates:\n     ```\n     question: \"Found outdated sections. Which would you like to update?\"\n     options: [list of sections]\n     allowMultiSelect: true\n     ```\n\n8. **Sync with modular rules**:\n   - If rules exist in `.claude/rules/`\n   - Detect duplicated content\n   - Offer to deduplicate:\n     ```\n     question: \"Found duplicate content between CLAUDE.md and rules/. How to resolve?\"\n     options:\n       - \"Keep in CLAUDE.md, remove from rules\"\n       - \"Keep in rules, reference from CLAUDE.md\"\n       - \"Keep both (may cause confusion)\"\n     ```\n\n9. **Update manifest**:\n   - Record CLAUDE.md generation/update\n   - Track which PRDs contributed\n   - Update timestamp\n\n10. **Report**:\n    ```\n     CLAUDE.md updated!\n\n    {Created | Updated}: CLAUDE.md\n\n    Sections:\n    - Overview \n    - Tech Stack \n    - Development Workflow \n    - Architecture \n    - Conventions \n    - Current Focus \n\n    Sources used:\n    - PRDs: {list}\n    - Rules: {list}\n    - Project detection: {what was detected}\n\n    {If modular mode:}\n    Note: Detailed rules are in .claude/rules/\n    CLAUDE.md serves as overview and quick reference.\n\n    Run `/blueprint-status` to see full configuration.\n    ```\n\n**CLAUDE.md Best Practices**:\n- Keep it concise (< 500 lines ideally)\n- Focus on \"what Claude needs to know\"\n- Reference modular rules for details\n- Update when PRDs change significantly\n- Include current focus/phase for context\n\n11. **Prompt for next action** (use AskUserQuestion):\n    ```\n    question: \"CLAUDE.md updated. What would you like to do next?\"\n    options:\n      - label: \"Check blueprint status (Recommended)\"\n        description: \"Run /blueprint:status to verify configuration\"\n      - label: \"Manage modular rules\"\n        description: \"Add or edit rules in .claude/rules/\"\n      - label: \"Continue development\"\n        description: \"Run /project:continue to work on next task\"\n      - label: \"I'm done for now\"\n        description: \"Exit - CLAUDE.md is saved\"\n    ```\n\n    **Based on selection:**\n    - \"Check blueprint status\"  Run `/blueprint:status`\n    - \"Manage modular rules\"  Run `/blueprint:rules`\n    - \"Continue development\"  Run `/project:continue`\n    - \"I'm done\"  Exit\n\n**Template Sections** (customize per project type):\n\n| Project Type | Key Sections |\n|--------------|--------------|\n| Python | Virtual env, pytest, type hints |\n| Node.js | Package manager, test runner, build |\n| Rust | Cargo, clippy, unsafe usage rules |\n| Monorepo | Workspace structure, shared deps |\n| API | Endpoints, auth, error handling |\n| Frontend | Components, state, styling |"
              },
              {
                "name": "/blueprint-curate-docs",
                "description": "Curate library or project documentation for ai_docs to optimize AI context",
                "path": "blueprint-plugin/commands/blueprint-curate-docs.md",
                "frontmatter": {
                  "created": "2025-12-16T00:00:00.000Z",
                  "modified": "2026-01-09T00:00:00.000Z",
                  "reviewed": "2025-12-16T00:00:00.000Z",
                  "description": "Curate library or project documentation for ai_docs to optimize AI context",
                  "allowed_tools": [
                    "Read",
                    "Write",
                    "Glob",
                    "Bash",
                    "WebFetch",
                    "WebSearch",
                    "AskUserQuestion"
                  ]
                },
                "content": "Curate documentation for a library or project pattern into an ai_docs entry.\n\n**Usage**: `/blueprint:curate-docs [library-name]` or `/blueprint:curate-docs project:[pattern-name]`\n\n**What is ai_docs?**\nai_docs are curated documentation entries optimized for AI agents. Unlike raw documentation, they are:\n- **Concise**: < 200 lines, only essential information\n- **Actionable**: Code snippets that can be directly used\n- **Gotcha-aware**: Common pitfalls with solutions\n- **Version-specific**: Tied to specific library versions\n\n**Prerequisites**:\n- Blueprint Development initialized\n- `docs/blueprint/ai_docs/` directory exists\n\n## Phase 1: Research\n\n### 1.1 For Library Documentation\n\n**Identify the library**:\n```bash\n# Check if already documented\nls docs/blueprint/ai_docs/libraries/\n\n# Check project dependencies for version\ncat package.json | grep \"[library-name]\"\n# or\ncat pyproject.toml | grep \"[library-name]\"\n# or\ncat requirements.txt | grep \"[library-name]\"\n```\n\n**Gather documentation**:\n1. Search for official documentation\n2. Find the specific sections relevant to project use cases\n3. Look for known issues and gotchas\n4. Search for common problems on Stack Overflow/GitHub\n\nUse WebSearch:\n```\n[library-name] documentation [specific topic]\n[library-name] common issues\n[library-name] gotchas\n[library-name] best practices\n```\n\nUse WebFetch to extract key sections:\n```\nFetch: [library documentation URL]\nExtract: [specific pattern or topic]\n```\n\n### 1.2 For Project Patterns\n\n**Identify existing patterns**:\n```bash\n# Search for pattern implementations\ngrep -r \"[pattern keyword]\" src/\ngrep -r \"[pattern keyword]\" lib/\n```\n\n**Analyze the pattern**:\n- Where is it used?\n- What are the conventions?\n- What gotchas have been encountered?\n\n## Phase 2: Extract Key Information\n\n### 2.1 Determine Use Cases\n\nIdentify how this library/pattern is used in this project:\n- What features depend on it?\n- What are the common operations?\n- What integrations exist?\n\n### 2.2 Extract Patterns\n\nFrom documentation and codebase:\n- **Quick reference**: Most common operations\n- **Patterns we use**: Project-specific implementations\n- **Configuration**: How it's configured in this project\n\n### 2.3 Document Gotchas\n\nCompile known issues:\n- Version-specific behaviors\n- Common mistakes\n- Performance pitfalls\n- Security considerations\n\nSources for gotchas:\n- Official documentation warnings\n- GitHub issues\n- Stack Overflow discussions\n- Team experience\n\n## Phase 3: Create ai_docs Entry\n\n### 3.1 Choose Location\n\n**For libraries**:\n```\ndocs/blueprint/ai_docs/libraries/[library-name].md\n```\n\n**For project patterns**:\n```\ndocs/blueprint/ai_docs/project/[pattern-name].md\n```\n\n### 3.2 Write Entry\n\nUse the ai_docs template:\n\n```markdown\n# [Library/Pattern Name]\n\n**Version:** X.Y.Z\n**Last Updated:** YYYY-MM-DD\n**Use Case:** [Why we use this in this project]\n\n## Quick Reference\n\n### [Common Operation 1]\n```[language]\n# Code snippet that can be directly copied\n```\n\n### [Common Operation 2]\n```[language]\n# Code snippet that can be directly copied\n```\n\n## Patterns We Use\n\n### [Pattern Name]\n[When to use this pattern]\n\n```[language]\n# Full example as used in this project\n```\n\n## Configuration\n\n### Environment Variables\n```bash\nVAR_NAME=value\n```\n\n### Our Config Pattern\n```[language]\n# How we configure this in the project\n```\n\n## Gotchas\n\n### Gotcha 1: [Title]\n**Issue:** [What can go wrong]\n**Solution:**\n```[language]\n# Correct approach\n```\n\n### Gotcha 2: [Title]\n**Issue:** [What can go wrong]\n**Solution:**\n```[language]\n# Correct approach\n```\n\n## Anti-Patterns\n\n### Don't Do This\n```[language]\n# Bad example\n```\n\n### Do This Instead\n```[language]\n# Good example\n```\n\n## Testing\n\n### How to Mock\n```[language]\n# Mocking pattern for tests\n```\n\n## References\n\n- [Official Docs - Specific Section](url)\n- [Relevant GitHub Issue](url)\n```\n\n### 3.3 Quality Checks\n\nBefore saving, verify:\n- [ ] Entry is < 200 lines\n- [ ] Code snippets are directly usable\n- [ ] Gotchas include solutions\n- [ ] Version is specified\n- [ ] Use cases are clear\n- [ ] Anti-patterns are shown\n\n## Phase 4: Integrate\n\n### 4.1 Save Entry\n\n```bash\n# Write to ai_docs\ncat > docs/blueprint/ai_docs/[type]/[name].md << 'EOF'\n[content]\nEOF\n```\n\n### 4.2 Update References\n\nIf PRPs reference this library/pattern:\n- Add ai_docs reference to PRP\n- Update context sections\n\n### 4.3 Report\n\n```markdown\n## ai_docs Entry Created: [Name]\n\n**Location:** `docs/blueprint/ai_docs/[type]/[name].md`\n\n**Version:** X.Y.Z\n\n**Content Summary:**\n- Quick Reference: [N operations]\n- Patterns: [N patterns]\n- Gotchas: [N documented]\n- Anti-patterns: [N shown]\n\n**Lines:** [count] (target: < 200)\n\n**Use in PRPs:**\nReference with:\n```markdown\n### ai_docs References\n- See `ai_docs/[type]/[name].md` - [Section]\n```\n\n**Linked PRPs:**\n- [List any PRPs that should reference this]\n```\n\n## Templates by Type\n\n### Library Template\nBest for: External dependencies (Redis, Pydantic, FastAPI, etc.)\n\nFocus on:\n- Version-specific behavior\n- Connection/initialization patterns\n- Error handling\n- Performance gotchas\n\n### Framework Template\nBest for: Web frameworks, ORMs, testing frameworks\n\nFocus on:\n- Project structure conventions\n- Configuration patterns\n- Extension points\n- Testing integration\n\n### Project Pattern Template\nBest for: Internal patterns (Repository, Service Layer, etc.)\n\nFocus on:\n- When to use this pattern\n- How it's implemented in this codebase\n- Integration with other patterns\n- Common mistakes\n\n### 4.4 Prompt for next action (use AskUserQuestion):\n\n```\nquestion: \"ai_docs entry created. What would you like to do next?\"\noptions:\n  - label: \"Curate another library/pattern\"\n    description: \"Create additional ai_docs entries\"\n  - label: \"Create PRP using this context\"\n    description: \"Use this ai_docs in a feature implementation\"\n  - label: \"Update linked PRPs\"\n    description: \"Add ai_docs reference to existing PRPs\"\n  - label: \"I'm done for now\"\n    description: \"Exit - ai_docs is saved and ready\"\n```\n\n**Based on selection:**\n- \"Curate another\"  Run `/blueprint:curate-docs` (ask for library/pattern name)\n- \"Create PRP using this context\"  Run `/blueprint:prp-create` (ask for feature name)\n- \"Update linked PRPs\"  List PRPs that could benefit from this ai_docs reference\n- \"I'm done\"  Exit\n\n**Tips**:\n- Be ruthless about conciseness - every line uses tokens\n- Include actual line numbers from codebase examples\n- Document gotchas immediately when discovered\n- Update entries as patterns evolve\n- Link to official docs for rarely-used features"
              },
              {
                "name": "/blueprint-feature-tracker-status",
                "description": "Display feature tracker statistics and completion summary",
                "path": "blueprint-plugin/commands/blueprint-feature-tracker-status.md",
                "frontmatter": {
                  "created": "2026-01-02T00:00:00.000Z",
                  "modified": "2026-01-09T00:00:00.000Z",
                  "reviewed": "2026-01-02T00:00:00.000Z",
                  "description": "Display feature tracker statistics and completion summary",
                  "allowed_tools": [
                    "Read",
                    "Bash",
                    "AskUserQuestion"
                  ]
                },
                "content": "Display feature tracker statistics, phase progress, and completion summary.\n\n**Steps**:\n\n1. **Check if feature tracking is enabled**:\n   - Look for `docs/blueprint/feature-tracker.json`\n   - If not found, report:\n     ```\n     Feature tracking not enabled in this project.\n     Run `/blueprint-init` and enable feature tracking to get started.\n     ```\n\n2. **Load tracker data**:\n   - Read `feature-tracker.json`\n   - Extract project name, source document, last_updated\n   - Get statistics section\n   - Get phase information\n   - Get PRD status\n\n3. **Calculate derived metrics** (if not in statistics):\n   - Count features by status at all nesting levels\n   - Calculate completion percentage\n   - Count features per phase\n   - Count PRDs by status\n\n4. **Display status report**:\n   ```\n   Feature Tracker Status\n   ======================\n   Project: {project}\n   Source: {source_document}\n   Last Updated: {last_updated}\n\n   Overall Progress:\n   ==================\n   {progress_bar} {completion_percentage}% ({complete}/{total_features})\n\n   Complete:     {complete}\n   Partial:      {partial}\n   In Progress:  {in_progress}\n   Not Started:  {not_started}\n   Blocked:      {blocked}\n\n   Phase Progress:\n   ===============\n   {For each phase:}\n   Phase {N}: {name}\n   Status: {status}\n   Features: {complete}/{total} complete\n\n   PRD Coverage:\n   =============\n   {For each PRD:}\n   {PRD_NAME}: {status}\n     Features: {features_implemented count}\n     {If tests_passing:} Tests: {tests_passing} passing\n\n   {If blocked features exist:}\n   Blocked Features:\n   =================\n   {For each blocked feature:}\n   - {FR code}: {name}\n     Reason: {implementation.notes or \"No reason documented\"}\n\n   {If not_started features exist and count <= 10:}\n   Ready to Start:\n   ===============\n   {List first 10 not_started features by phase order}\n   - {FR code}: {name} (Phase {N})\n   ```\n\n5. **Display visual progress bar**:\n   Create ASCII progress bar:\n   ```\n   [##########----------] 52.4%\n   ```\n   - `#` for complete percentage\n   - `-` for remaining\n   - 20 characters wide\n\n6. **Check for staleness**:\n   - If `last_updated` is more than 7 days old, warn:\n     ```\n     Note: Tracker hasn't been synced in {N} days.\n     Run `/blueprint-feature-tracker-sync` to update.\n     ```\n   - If work-overview.md is newer than tracker, warn:\n     ```\n     Note: work-overview.md has been modified since last sync.\n     Run `/blueprint-feature-tracker-sync` to reconcile.\n     ```\n\n7. **Prompt for next action** (use AskUserQuestion):\n   Build options dynamically based on state:\n   - If stale  Include \"Sync feature tracker\"\n   - If not_started features exist  Include \"Start next feature\"\n   - If in_progress features exist  Include \"Continue current work\"\n   - Always include \"View detailed breakdown\" and \"Exit\"\n\n   ```\n   question: \"What would you like to do?\"\n   options:\n     {Dynamic options based on state}\n     - label: \"Sync feature tracker\" (if stale)\n       description: \"Update tracker from project state\"\n     - label: \"Start next feature\" (if not_started exist)\n       description: \"Begin work on the next pending feature\"\n     - label: \"Continue current work\" (if in_progress exist)\n       description: \"Resume work on in-progress features\"\n     - label: \"View features by status\"\n       description: \"List all features filtered by status\"\n     - label: \"Exit\"\n       description: \"Done viewing status\"\n   ```\n\n   **Based on selection:**\n   - \"Sync\"  Run `/blueprint-feature-tracker-sync`\n   - \"Start next\"  Show next not_started feature details, suggest starting\n   - \"Continue\"  Show in_progress features, suggest continuing\n   - \"View by status\"  Ask which status, then list matching features\n   - \"Exit\"  End command\n\n**Example Output**:\n```\nFeature Tracker Status\n======================\nProject: gooho\nSource: REQUIREMENTS.md\nLast Updated: 2026-01-01\n\nOverall Progress:\n==================\n[##########----------] 52.4% (22/42)\n\nComplete:     22\nPartial:      4\nIn Progress:  2\nNot Started:  14\nBlocked:      0\n\nPhase Progress:\n===============\nPhase 0: Foundation\nStatus: complete\nFeatures: 4/4 complete\n\nPhase 1: Core Gameplay\nStatus: complete\nFeatures: 8/8 complete\n\nPhase 2: Advanced Features\nStatus: in_progress\nFeatures: 10/14 complete\n\nPhase 3-8: Future Development\nStatus: not_started\nFeatures: 0/16 complete\n\nPRD Coverage:\n=============\nPRD_GAME_SETUP_FLOW: complete\n  Features: 4\n  Tests: 45 passing\n\nPRD_TERRAIN_VISUAL_ENHANCEMENT: complete\n  Features: 6\n  Tests: 107 passing\n\nPRD_ENTITY_BEHAVIOR_SYSTEM: complete\n  Features: 8\n  Tests: 187 passing\n\nPRD_UI_CONTROLS_SYSTEM: partial\n  Features: 3/5\n\nReady to Start:\n===============\n- FR3.1: Resource Types (Phase 3)\n- FR3.2: Resource Gathering (Phase 3)\n- FR3.3: Resource Storage (Phase 3)\n- FR4.1: Basic Crafting (Phase 4)\n- FR4.2: Recipe System (Phase 4)\n\nNote: 14 features ready to start. Run `/blueprint-feature-tracker-sync` before beginning new work.\n```\n\n**Quick Commands** (shown at end):\n```\nQuick commands for feature tracker:\n- jq '.statistics' docs/blueprint/feature-tracker.json\n- jq '.. | objects | select(.status == \"not_started\") | .name' docs/blueprint/feature-tracker.json\n- jq '.prds | to_entries | .[] | \"\\(.key): \\(.value.status)\"' docs/blueprint/feature-tracker.json\n```"
              },
              {
                "name": "/blueprint-feature-tracker-sync",
                "description": "Synchronize feature tracker with work-overview.md, TODO.md, and PRDs",
                "path": "blueprint-plugin/commands/blueprint-feature-tracker-sync.md",
                "frontmatter": {
                  "created": "2026-01-02T00:00:00.000Z",
                  "modified": "2026-01-09T00:00:00.000Z",
                  "reviewed": "2026-01-02T00:00:00.000Z",
                  "description": "Synchronize feature tracker with work-overview.md, TODO.md, and PRDs",
                  "allowed_tools": [
                    "Read",
                    "Write",
                    "Bash",
                    "Glob",
                    "AskUserQuestion"
                  ]
                },
                "content": "Synchronize the feature tracker JSON with work-overview.md and TODO.md to maintain consistency.\n\n**Steps**:\n\n1. **Check if feature tracking is enabled**:\n   - Look for `docs/blueprint/feature-tracker.json`\n   - If not found, report:\n     ```\n     Feature tracking not enabled in this project.\n     Run `/blueprint-init` and enable feature tracking to get started.\n     ```\n\n2. **Load current state**:\n   - Read `docs/blueprint/feature-tracker.json` for current feature status\n   - Read `docs/blueprint/work-overview.md` for completed/pending sections\n   - Read `TODO.md` for checkbox states\n   - Read manifest for `sync_targets` configuration\n\n3. **Analyze each feature**:\n   For each feature in the tracker:\n\n   a. **Verify status consistency**:\n      - `complete`: Check TODO.md has `[x]`, work-overview lists in \"Completed\"\n      - `partial`: Some checkboxes checked, some not\n      - `in_progress`: Listed in \"In Progress\" section\n      - `not_started`: Check TODO.md has `[ ]`, not in \"Completed\"\n      - `blocked`: Note if blocking reason is documented\n\n   b. **Check implementation evidence** (optional, for thorough sync):\n      - Look for files listed in `implementation.files`\n      - Check if tests exist in `implementation.tests`\n      - Verify commits in `implementation.commits`\n\n4. **Detect discrepancies**:\n   Look for inconsistencies:\n   - Feature marked `complete` in tracker but unchecked in TODO.md\n   - Feature checked in TODO.md but not `complete` in tracker\n   - Feature in work-overview.md \"Completed\" but tracker says `not_started`\n   - PRD status doesn't match feature implementation status\n\n5. **Ask user about discrepancies** (use AskUserQuestion):\n   If discrepancies found:\n   ```\n   question: \"Found {N} discrepancies. How should they be resolved?\"\n   options:\n     - label: \"Update tracker from TODO.md/work-overview.md\"\n       description: \"Trust the documentation, update tracker to match\"\n     - label: \"Update TODO.md/work-overview.md from tracker\"\n       description: \"Trust the tracker, update documentation to match\"\n     - label: \"Review each discrepancy\"\n       description: \"Show each discrepancy and decide individually\"\n     - label: \"Skip - don't resolve discrepancies\"\n       description: \"Report discrepancies but don't change anything\"\n   ```\n\n6. **Recalculate statistics**:\n   - Count features by status across all nested levels\n   - Calculate completion percentage: `(complete / total) * 100`\n   - Update phase status based on contained features:\n     - `complete` if all features complete\n     - `in_progress` if any feature in_progress\n     - `partial` if some complete, some not\n     - `not_started` if no features started\n\n7. **Update feature-tracker.json**:\n   - Apply resolved discrepancies\n   - Update `statistics` section\n   - Update `last_updated` to today's date\n   - Update PRD status if features changed\n\n8. **Update sync targets**:\n\n   **work-overview.md:**\n   - Add newly completed features to \"Completed\" section\n   - Move features from \"Pending\" to \"In Progress\" or \"Completed\" as appropriate\n   - Update PRD completion status if shown\n\n   **TODO.md:**\n   - Ensure checkbox states match feature status\n   - `[x]` for `complete` features\n   - `[ ]` for `not_started` features\n   - Note partial completion in task text if needed\n\n9. **Output sync report**:\n   ```\n   Feature Tracker Sync Report\n   ===========================\n   Last Updated: {date}\n\n   Statistics:\n   - Total Features: {total}\n   - Complete: {complete} ({percentage}%)\n   - Partial: {partial}\n   - In Progress: {in_progress}\n   - Not Started: {not_started}\n   - Blocked: {blocked}\n\n   Phase Status:\n   - Phase 0: {status}\n   - Phase 1: {status}\n   ...\n\n   Changes Made:\n   {If changes made:}\n   - {feature}: {old_status} -> {new_status}\n   - Updated work-overview.md: added {N} to Completed\n   - Updated TODO.md: checked {N} items\n   {If no changes:}\n   - No changes needed, all in sync\n\n   {If discrepancies skipped:}\n   Unresolved Discrepancies:\n   - {feature}: tracker says {status}, TODO.md shows {checkbox_state}\n   ```\n\n10. **Prompt for next action** (use AskUserQuestion):\n    ```\n    question: \"Sync complete. What would you like to do next?\"\n    options:\n      - label: \"View detailed status\"\n        description: \"Run /blueprint-feature-tracker-status for full breakdown\"\n      - label: \"Continue development\"\n        description: \"Run /project:continue to work on next task\"\n      - label: \"I'm done\"\n        description: \"Exit sync\"\n    ```\n\n**Example Output**:\n```\nFeature Tracker Sync Report\n===========================\nLast Updated: 2026-01-02\n\nStatistics:\n- Total Features: 42\n- Complete: 22 (52.4%)\n- Partial: 4\n- In Progress: 2\n- Not Started: 14\n- Blocked: 0\n\nPhase Status:\n- Phase 0: complete\n- Phase 1: complete\n- Phase 2: in_progress\n- Phase 3-8: not_started\n\nChanges Made:\n- FR2.6.1 (Skill Progression): partial -> complete\n- FR2.6.2 (Experience Points): not_started -> complete\n- Updated work-overview.md: added 2 features to Completed\n- Updated TODO.md: checked 2 items\n\nAll sync targets updated successfully.\n```"
              },
              {
                "name": "/blueprint-generate-commands",
                "description": "Generate workflow commands based on project structure and PRDs",
                "path": "blueprint-plugin/commands/blueprint-generate-commands.md",
                "frontmatter": {
                  "created": "2025-12-16T00:00:00.000Z",
                  "modified": "2025-01-09T00:00:00.000Z",
                  "reviewed": "2025-01-09T00:00:00.000Z",
                  "description": "Generate workflow commands based on project structure and PRDs",
                  "allowed_tools": [
                    "Read",
                    "Write",
                    "Bash",
                    "Glob",
                    "AskUserQuestion"
                  ]
                },
                "content": "Generate workflow commands customized for this project.\n\nCommands are generated to `.claude/commands/` directory.\n\n**Prerequisites**:\n- Project has recognizable structure (package.json, Makefile, etc.)\n- PRDs exist in `docs/prds/`\n\n**Steps**:\n\n1. **Detect project type and stack**:\n   - Check for `package.json` -> Node.js project\n   - Check for `pyproject.toml` / `setup.py` -> Python project\n   - Check for `Cargo.toml` -> Rust project\n   - Check for `go.mod` -> Go project\n   - Check for `Makefile` -> Check make targets\n\n2. **Detect test runner and commands**:\n   - Node.js: Check `package.json` scripts for `test`, `test:unit`, `test:integration`\n   - Python: Check for pytest, unittest\n   - Rust: `cargo test`\n   - Go: `go test`\n\n3. **Detect build and dev commands**:\n   - Check `package.json` scripts\n   - Check `Makefile` targets\n   - Check project-specific tools\n\n4. **Check for existing generated commands**:\n   ```bash\n   ls .claude/commands/ 2>/dev/null\n   ```\n   - If commands exist, check manifest for content hashes\n   - Compare current content hash vs stored hash\n   - If modified, offer options: overwrite, skip, or backup\n\n5. **Generate `/project:continue` command**:\n\n   Create file at `.claude/commands/project-continue.md`:\n   ```markdown\n   ---\n   description: \"Continue development on [project-name] (project-specific)\"\n   allowed_tools: [Read, Bash, Grep, Glob, Edit, Write]\n   ---\n\n   Continue project development (customized for this project).\n\n   **Project-specific configuration**:\n   - Test command: `[detected_test_command]`\n   - Build command: `[detected_build_command]`\n   - Dev command: `[detected_dev_command]`\n\n   1. **Check current state**:\n      - Run `git status` (branch, uncommitted changes)\n      - Run `git log -5 --oneline` (recent commits)\n\n   2. **Read context**:\n      - All PRDs in `docs/prds/`\n      - `work-overview.md` (current phase and progress)\n      - Recent work-orders (completed and pending)\n\n   3. **Identify next task**:\n      - Based on PRD requirements\n      - Based on work-overview progress\n      - Based on git status (resume if in progress)\n\n   4. **Begin work following TDD**:\n      - Apply project-specific rules automatically\n      - Follow RED -> GREEN -> REFACTOR workflow\n      - Commit incrementally with conventional commits\n\n   Report before starting:\n   - Current project status summary\n   - Next task identified\n   - Approach and plan\n   ```\n\n6. **Generate `/project:test-loop` command**:\n\n   Create file at `.claude/commands/project-test-loop.md`:\n   ```markdown\n   ---\n   description: \"TDD loop for [project-name] using [test-runner]\"\n   allowed_tools: [Read, Edit, Bash]\n   ---\n\n   Run TDD cycle (customized for this project).\n\n   **Project-specific configuration**:\n   - Test command: `[detected_test_command]`\n   - Watch mode: `[detected_watch_command]` (if available)\n\n   1. **Run test suite**: `[detected_test_command]`\n   2. **If tests fail**:\n      - Analyze failure output\n      - Identify root cause\n      - Make minimal fix to pass the test\n      - Re-run tests to confirm\n   3. **If tests pass**:\n      - Check for refactoring opportunities\n      - Refactor while keeping tests green\n      - Re-run tests to confirm still passing\n   4. **Repeat until**:\n      - All tests pass\n      - No obvious refactoring needed\n      - User intervention required\n\n   Report:\n   - Test results summary\n   - Fixes applied\n   - Refactorings performed\n   - Current status (all pass / needs work / blocked)\n   ```\n\n7. **Generate project-specific commands** (optional):\n   - If web app: Commands for starting dev server, running migrations\n   - If CLI: Commands for building, testing CLI\n   - If library: Commands for building, publishing\n\n8. **Update manifest with generation tracking**:\n   ```json\n   {\n     \"project\": {\n       \"detected_stack\": [\"typescript\", \"bun\", \"react\"]\n     },\n     \"generated\": {\n       \"commands\": {\n         \"project-continue\": {\n           \"source\": \"auto-detection\",\n           \"detected_stack\": \"[detected stack]\",\n           \"generated_at\": \"[ISO timestamp]\",\n           \"plugin_version\": \"3.0.0\",\n           \"content_hash\": \"sha256:...\",\n           \"status\": \"current\"\n         },\n         \"project-test-loop\": { ... }\n       }\n     }\n   }\n   ```\n\n9. **Report**:\n   ```\n   Workflow commands generated!\n\n   Created in .claude/commands/:\n   - project-continue.md -> /project:continue\n   - project-test-loop.md -> /project:test-loop\n   [- Additional project-specific commands]\n\n   Detected configuration:\n   - Project type: [Node.js / Python / Rust / etc.]\n   - Stack: [detected libraries/frameworks]\n   - Test command: [detected command]\n   - Build command: [detected command]\n   - Dev command: [detected command]\n   ```\n\n10. **Prompt for next action** (use AskUserQuestion):\n    ```\n    question: \"Workflow commands ready. What would you like to do?\"\n    options:\n      - label: \"Start development (Recommended)\"\n        description: \"Run /project:continue to begin working on next task\"\n      - label: \"Create a work-order\"\n        description: \"Package a task for isolated subagent execution\"\n      - label: \"Update CLAUDE.md\"\n        description: \"Regenerate project overview with new commands\"\n      - label: \"I'm done for now\"\n        description: \"Exit - commands are ready to use anytime\"\n    ```\n\n    **Based on selection:**\n    - \"Start development\" -> Run `/project:continue`\n    - \"Create a work-order\" -> Run `/blueprint:work-order`\n    - \"Update CLAUDE.md\" -> Run `/blueprint:claude-md`\n    - \"I'm done for now\" -> Exit\n\n**Important**:\n- Detect actual project commands (detect dynamically from project structure)\n- Include project-specific test commands\n- Commands should be immediately usable\n- Report what was detected for transparency\n\n**Error Handling**:\n- If project type unclear -> Ask user for clarification\n- If no test command found -> Ask user how to run tests\n- If commands already exist and modified -> Offer to backup before overwriting"
              },
              {
                "name": "/blueprint-generate-rules",
                "description": "Generate project-specific rules from PRDs",
                "path": "blueprint-plugin/commands/blueprint-generate-rules.md",
                "frontmatter": {
                  "created": "2025-12-16T00:00:00.000Z",
                  "modified": "2025-01-09T00:00:00.000Z",
                  "reviewed": "2025-01-09T00:00:00.000Z",
                  "description": "Generate project-specific rules from PRDs",
                  "allowed_tools": [
                    "Read",
                    "Write",
                    "Glob",
                    "Bash",
                    "AskUserQuestion"
                  ]
                },
                "content": "Generate project-specific rules from Product Requirements Documents.\n\nRules are generated to `.claude/rules/` directory.\n\n**Prerequisites**:\n- `docs/prds/` directory exists\n- At least one PRD file in `docs/prds/`\n\n**Steps**:\n\n1. **Find and read all PRDs**:\n   - Use Glob to find all `.md` files in `docs/prds/`\n   - Read each PRD file\n   - If no PRDs found, report error and suggest writing PRDs first\n\n2. **Check for existing generated rules**:\n   ```bash\n   ls .claude/rules/ 2>/dev/null\n   ```\n   - If rules exist, check manifest for content hashes\n   - Compare current content hash vs stored hash\n   - If modified, offer options: overwrite, skip, or backup\n\n3. **Analyze PRDs and extract** (aggregated from all PRDs):\n\n   **Architecture Patterns**:\n   - Project structure and organization\n   - Architectural style (MVC, layered, hexagonal, etc.)\n   - Design patterns\n   - Dependency injection approach\n   - Error handling strategy\n   - Code organization conventions\n   - Integration patterns\n\n   **Testing Strategies**:\n   - TDD workflow requirements\n   - Test types (unit, integration, e2e)\n   - Mocking patterns\n   - Coverage requirements\n   - Test structure and organization\n   - Test commands\n\n   **Implementation Guides**:\n   - How to implement APIs/endpoints\n   - How to implement UI components (if applicable)\n   - Database operation patterns\n   - External service integration patterns\n   - Background job patterns (if applicable)\n\n   **Quality Standards**:\n   - Code review checklist\n   - Performance baselines\n   - Security requirements (OWASP, validation, auth)\n   - Code style and formatting\n   - Documentation requirements\n   - Dependency management\n\n4. **Generate four aggregated domain rules**:\n\n   Create in `.claude/rules/`:\n\n   **`architecture-patterns.md`**:\n   - Aggregated patterns from all PRDs\n   - Fill in project-specific patterns extracted from PRDs\n   - Include code examples where possible\n   - Reference specific files/directories\n\n   **`testing-strategies.md`**:\n   - Aggregated testing requirements from all PRDs\n   - Fill in TDD requirements from PRDs\n   - Include coverage requirements\n   - Include test commands for the project\n\n   **`implementation-guides.md`**:\n   - Aggregated implementation patterns from all PRDs\n   - Fill in step-by-step patterns for feature types\n   - Include code examples\n\n   **`quality-standards.md`**:\n   - Aggregated quality requirements from all PRDs\n   - Fill in performance baselines from PRDs\n   - Fill in security requirements from PRDs\n   - Create project-specific checklist\n\n5. **Update manifest with generation tracking**:\n   ```json\n   {\n     \"generated\": {\n       \"rules\": {\n         \"architecture-patterns\": {\n           \"source\": \"docs/prds/*\",\n           \"source_hash\": \"sha256:...\",\n           \"generated_at\": \"[ISO timestamp]\",\n           \"plugin_version\": \"3.0.0\",\n           \"content_hash\": \"sha256:...\",\n           \"status\": \"current\"\n         },\n         \"testing-strategies\": { ... },\n         \"implementation-guides\": { ... },\n         \"quality-standards\": { ... }\n       }\n     }\n   }\n   ```\n\n6. **Report**:\n   ```\n   Rules generated from PRDs!\n\n   Created in .claude/rules/:\n   - architecture-patterns.md\n   - testing-strategies.md\n   - implementation-guides.md\n   - quality-standards.md\n\n   PRDs analyzed:\n   - docs/prds/[List PRD files]\n\n   Key patterns extracted:\n   - Architecture: [Brief summary]\n   - Testing: [Brief summary]\n   - Implementation: [Brief summary]\n   - Quality: [Brief summary]\n\n   Rules are immediately available - Claude auto-discovers them based on context!\n   ```\n\n7. **Prompt for next action** (use AskUserQuestion):\n   ```\n   question: \"Rules generated. What would you like to do next?\"\n   options:\n     - label: \"Generate workflow commands (Recommended)\"\n       description: \"Create /project:continue and /project:test-loop commands\"\n     - label: \"Update CLAUDE.md\"\n       description: \"Regenerate project overview document with new rules\"\n     - label: \"Review generated rules\"\n       description: \"I'll examine and refine the rules manually\"\n     - label: \"I'm done for now\"\n       description: \"Exit - rules are already available\"\n   ```\n\n   **Based on selection:**\n   - \"Generate workflow commands\" -> Run `/blueprint:generate-commands`\n   - \"Update CLAUDE.md\" -> Run `/blueprint:claude-md`\n   - \"Review generated rules\" -> Show rule file locations and exit\n   - \"I'm done for now\" -> Exit\n\n**Important**:\n- Rules should be markdown files with clear headings\n- Keep rule content specific and focused\n- Include code examples to make patterns concrete\n- Reference PRD sections for traceability\n- Rules should be actionable, not just documentation\n\n**Error Handling**:\n- If no PRDs found -> Guide user to write PRDs first (`/blueprint:prd`)\n- If PRDs incomplete -> Generate rules with TODO markers for missing sections\n- If rules already exist and modified -> Offer to backup before overwriting"
              },
              {
                "name": "/blueprint-init",
                "description": "Initialize Blueprint Development structure in current project",
                "path": "blueprint-plugin/commands/blueprint-init.md",
                "frontmatter": {
                  "created": "2025-12-16T00:00:00.000Z",
                  "modified": "2026-01-09T00:00:00.000Z",
                  "reviewed": "2026-01-09T00:00:00.000Z",
                  "description": "Initialize Blueprint Development structure in current project",
                  "allowed_tools": [
                    "Bash",
                    "Write",
                    "Read",
                    "AskUserQuestion",
                    "Glob"
                  ]
                },
                "content": "Initialize Blueprint Development in this project.\n\n**Steps**:\n\n1. **Check if already initialized**:\n   - Look for `docs/blueprint/manifest.json`\n   - If exists, read version and ask user:\n     ```\n     Use AskUserQuestion:\n     question: \"Blueprint already initialized (v{version}). What would you like to do?\"\n     options:\n       - \"Check for upgrades\"  run /blueprint:upgrade\n       - \"Reinitialize (will reset manifest)\"  continue with step 2\n       - \"Cancel\"  exit\n     ```\n\n2. **Gather project context** (use AskUserQuestion):\n   ```\n   question: \"What type of project is this?\"\n   options:\n     - \"Personal/Solo project\"  recommend .gitignore for .claude/\n     - \"Team project\"  recommend committing .claude/ for sharing\n     - \"Open source\"  recommend .claude/rules/ for contributor guidelines\n   ```\n\n3. **Ask about modular rules**:\n   ```\n   question: \"How would you like to organize project instructions?\"\n   options:\n     - \"Single CLAUDE.md file\"  traditional approach\n     - \"Modular rules (.claude/rules/)\"  create rules directory structure\n     - \"Both\"  CLAUDE.md for overview, rules/ for specifics\n   allowMultiSelect: false\n   ```\n\n4. **Ask about feature tracking** (use AskUserQuestion):\n   ```\n   question: \"Would you like to enable feature tracking?\"\n   options:\n     - label: \"Yes - Track implementation against requirements\"\n       description: \"Creates feature-tracker.json to track FR codes from a requirements document\"\n     - label: \"No - Skip feature tracking\"\n       description: \"Can be added later with /blueprint-feature-tracker-sync\"\n   ```\n\n   **If \"Yes\" selected:**\n   a. Ask for source document:\n      ```\n      question: \"Which document contains your feature requirements?\"\n      options:\n        - label: \"REQUIREMENTS.md\"\n          description: \"Standard requirements document (most common)\"\n        - label: \"README.md\"\n          description: \"Use README as requirements source\"\n        - label: \"Other\"\n          description: \"Specify a different document\"\n      ```\n   b. Create `docs/blueprint/feature-tracker.json` from template\n   c. Set `has_feature_tracker: true` in manifest\n\n5. **Ask about document detection** (use AskUserQuestion):\n   ```\n   question: \"Would you like to enable automatic document detection?\"\n   options:\n     - label: \"Yes - Detect PRD/ADR/PRP opportunities\"\n       description: \"Claude will prompt when conversations should become documents\"\n     - label: \"No - Manual commands only\"\n       description: \"Use /blueprint:prd, /blueprint:adr, /blueprint:prp-create explicitly\"\n   ```\n\n   Set `has_document_detection` in manifest based on response.\n\n   **If modular rules enabled and document detection enabled:**\n   Copy `document-management-rule.md` template to `.claude/rules/document-management.md`\n\n6. **Check for root documentation to migrate**:\n   ```bash\n   # Find markdown files in root that look like documentation (not standard files)\n   fd -d 1 -e md . | grep -viE '^\\./(README|CHANGELOG|CONTRIBUTING|LICENSE|CODE_OF_CONDUCT|SECURITY)'\n   ```\n\n   **If documentation files found in root** (e.g., REQUIREMENTS.md, ARCHITECTURE.md, DESIGN.md):\n   ```\n   Use AskUserQuestion:\n   question: \"Found documentation files in root directory: {file_list}. Would you like to organize them?\"\n   options:\n     - label: \"Yes, move to docs/\"\n       description: \"Migrate existing docs to proper structure (recommended)\"\n     - label: \"No, leave them\"\n       description: \"Keep files in current location\"\n   ```\n\n   **If \"Yes\" selected:**\n   a. Analyze each file to determine type:\n      - Contains requirements, features, user stories  `docs/prds/`\n      - Contains architecture decisions, trade-offs  `docs/adrs/`\n      - Contains implementation plans  `docs/prps/`\n      - General documentation  `docs/`\n   b. Move files to appropriate `docs/` subdirectory\n   c. Rename to kebab-case if needed (REQUIREMENTS.md  requirements.md)\n   d. Report migration results:\n      ```\n      Migrated documentation:\n      - REQUIREMENTS.md  docs/prds/requirements.md\n      - ARCHITECTURE.md  docs/adrs/0001-initial-architecture.md\n      ```\n\n7. **Create directory structure**:\n\n   **Blueprint structure (in docs/blueprint/):**\n   ```\n   docs/\n    blueprint/\n       manifest.json            # Version tracking and configuration\n       work-overview.md         # Progress tracking\n       work-orders/             # Task packages for subagents\n          completed/\n          archived/\n       ai_docs/                 # Curated documentation (on-demand)\n          libraries/\n          project/\n       README.md                # Blueprint documentation\n    prds/                        # Product Requirements Documents\n    adrs/                        # Architecture Decision Records\n    prps/                        # Product Requirement Prompts\n   ```\n\n   **Claude configuration (in .claude/):**\n   ```\n   .claude/\n    rules/                       # Modular rules (including generated)\n       development.md           # Development workflow rules\n       testing.md               # Testing requirements\n       document-management.md   # Document organization rules (if detection enabled)\n    skills/                      # Custom skill overrides (optional)\n    commands/                    # Custom command overrides (optional)\n   ```\n\n8. **Create `manifest.json`** (v3.0.0 schema):\n   ```json\n   {\n     \"format_version\": \"3.0.0\",\n     \"created_at\": \"[ISO timestamp]\",\n     \"updated_at\": \"[ISO timestamp]\",\n     \"created_by\": {\n       \"blueprint_plugin\": \"3.0.0\"\n     },\n     \"project\": {\n       \"name\": \"[detected or asked]\",\n       \"type\": \"[personal|team|opensource]\",\n       \"detected_stack\": []\n     },\n     \"structure\": {\n       \"has_prds\": true,\n       \"has_adrs\": true,\n       \"has_prps\": true,\n       \"has_work_orders\": true,\n       \"has_ai_docs\": false,\n       \"has_modular_rules\": \"[based on user choice]\",\n       \"has_feature_tracker\": \"[based on user choice]\",\n       \"has_document_detection\": \"[based on user choice]\",\n       \"claude_md_mode\": \"[single|modular|both]\"\n     },\n     \"feature_tracker\": {\n       \"file\": \"feature-tracker.json\",\n       \"source_document\": \"[user selection]\",\n       \"sync_targets\": [\"work-overview.md\", \"TODO.md\"]\n     },\n     \"generated\": {\n       \"rules\": {},\n       \"commands\": {}\n     },\n     \"custom_overrides\": {\n       \"skills\": [],\n       \"commands\": []\n     }\n   }\n   ```\n\n   Note: Include `feature_tracker` section only if feature tracking is enabled.\n\n9. **Create `work-overview.md`**:\n   ```markdown\n   # Work Overview: [Project Name]\n\n   ## Current Phase: [Phase name - e.g., \"Planning\", \"Phase 1\", \"MVP\"]\n\n   ### Completed\n   - (none yet)\n\n   ### In Progress\n   - (none yet)\n\n   ### Pending\n   - (none yet)\n\n   ## Next Steps\n   1. Create a PRD to define project requirements\n   2. Generate project-specific skills from PRDs\n   3. Generate workflow commands for your stack\n   ```\n\n10. **Create initial rules** (if modular rules selected):\n   - `development.md`: TDD workflow, commit conventions\n   - `testing.md`: Test requirements, coverage expectations\n   - `document-management.md`: Document organization rules (if document detection enabled)\n\n11. **Handle `.gitignore`** based on project type:\n   - Personal: Add `.claude/` to `.gitignore`\n   - Team: Commit `.claude/` (ask about secrets)\n   - Open source: Commit `docs/`, `.claude/rules/`, gitignore `docs/blueprint/work-orders/`\n\n12. **Report**:\n   ```\n   Blueprint Development initialized! (v3.0.0)\n\n   Blueprint structure created:\n   - docs/blueprint/manifest.json\n   - docs/blueprint/work-overview.md\n   - docs/blueprint/work-orders/\n   - docs/blueprint/ai_docs/\n   - docs/blueprint/README.md\n   [- docs/blueprint/feature-tracker.json (if feature tracking enabled)]\n\n   Project documentation:\n   - docs/prds/           (Product Requirements Documents)\n   - docs/adrs/           (Architecture Decision Records)\n   - docs/prps/           (Product Requirement Prompts)\n\n   Claude configuration:\n   - .claude/rules/       (modular rules, including generated)\n   - .claude/skills/      (custom skill overrides)\n   - .claude/commands/    (custom command overrides)\n\n   Configuration:\n   - Project type: [personal|team|opensource]\n   - Rules mode: [single|modular|both]\n   [- Feature tracking: enabled (source: {source_document})]\n   [- Document detection: enabled (Claude will prompt for PRD/ADR/PRP creation)]\n\n   [Migrated documentation:]\n   [- {original}  {destination} (for each migrated file)]\n\n   Architecture:\n   - Plugin layer: Generic commands from blueprint-plugin (auto-updated)\n   - Generated layer: Rules/commands regeneratable from docs/prds/\n   - Custom layer: Your overrides in .claude/skills/ and .claude/commands/\n   ```\n\n13. **Prompt for next action** (use AskUserQuestion):\n    ```\n    question: \"Blueprint initialized. What would you like to do next?\"\n    options:\n      - label: \"Create a PRD\"\n        description: \"Write requirements for a feature (recommended first step)\"\n      - label: \"Generate project commands\"\n        description: \"Detect project type and create /project:continue, /project:test-loop\"\n      - label: \"Add modular rules\"\n        description: \"Create .claude/rules/ for domain-specific guidelines\"\n      - label: \"I'm done for now\"\n        description: \"Exit - you can run /blueprint:status anytime to see options\"\n    ```\n\n    **Based on selection:**\n    - \"Create a PRD\"  Run `/blueprint:prd`\n    - \"Generate project commands\"  Run `/blueprint:generate-commands`\n    - \"Add modular rules\"  Run `/blueprint:rules`\n    - \"I'm done for now\"  Show quick reference and exit\n\n**Quick Reference** (show if user selects \"I'm done for now\"):\n```\nManagement commands:\n- /blueprint:status          - Check version and configuration\n- /blueprint:upgrade         - Upgrade to latest format version\n- /blueprint:prd             - Create a Product Requirements Document\n- /blueprint:adr             - Create an Architecture Decision Record\n- /blueprint:prp-create      - Create a Product Requirement Prompt\n- /blueprint:generate-skills - Generate skills from PRDs\n- /blueprint:generate-commands - Create workflow commands\n- /blueprint:sync            - Check for stale generated content\n- /blueprint:promote         - Move generated content to custom layer\n- /blueprint:rules           - Manage modular rules\n- /blueprint:claude-md       - Update CLAUDE.md\n- /blueprint:feature-tracker-status  - View feature completion stats\n- /blueprint:feature-tracker-sync    - Sync tracker with project files\n```"
              },
              {
                "name": "/blueprint-prd",
                "description": "Generate initial PRD from existing project documentation during onboarding",
                "path": "blueprint-plugin/commands/blueprint-prd.md",
                "frontmatter": {
                  "created": "2025-12-22T00:00:00.000Z",
                  "modified": "2026-01-09T00:00:00.000Z",
                  "reviewed": "2025-12-22T00:00:00.000Z",
                  "description": "Generate initial PRD from existing project documentation during onboarding",
                  "allowed_tools": [
                    "Read",
                    "Write",
                    "Glob",
                    "Grep",
                    "Bash",
                    "AskUserQuestion",
                    "Task"
                  ]
                },
                "content": "Generate a Product Requirements Document (PRD) for an existing project by analyzing README, documentation, and project structure.\n\n**Use Case**: Onboarding existing projects to Blueprint Development system.\n\n**Prerequisites**:\n- Blueprint Development initialized (`docs/blueprint/` exists)\n- Project has some existing documentation (README.md, docs/, etc.)\n\n**Steps**:\n\n## Phase 1: Discovery\n\n### 1.1 Check Prerequisites\n```bash\nls docs/blueprint/manifest.json\n```\nIf not found  suggest running `/blueprint:init` first.\n\n### 1.2 Gather Project Documentation\nSearch for existing documentation:\n```bash\nfd -e md -d 3 . | head -20\n```\n\nKey files to look for:\n- `README.md` - Primary project description\n- `docs/` - Documentation directory\n- `CONTRIBUTING.md` - Contribution guidelines\n- `ARCHITECTURE.md` - Architecture overview\n- `package.json` / `pyproject.toml` / `Cargo.toml` - Project metadata\n\n### 1.3 Read Primary Documentation\nRead and analyze:\n- README.md for project purpose, features, and usage\n- Package manifest for dependencies and scripts\n- Any existing architecture or design docs\n\n## Phase 2: Analysis & Extraction\n\n### 2.1 Extract Project Context\nFrom documentation, identify:\n\n| Aspect | Source | Questions if Missing |\n|--------|--------|---------------------|\n| Project name | Package manifest, README | Ask user |\n| Purpose/Problem | README intro | \"What problem does this project solve?\" |\n| Target users | README, docs | \"Who are the primary users?\" |\n| Core features | README features section | \"What are the main capabilities?\" |\n| Tech stack | Dependencies, file extensions | Infer from files |\n\n### 2.2 Ask Clarifying Questions\nUse AskUserQuestion for unclear items:\n\n```\nquestion: \"What is the primary problem this project solves?\"\noptions:\n  - \"[Inferred from docs]: {description}\"  confirm inference\n  - \"Let me describe it\"  free text input\n```\n\n```\nquestion: \"Who are the target users?\"\noptions:\n  - \"Developers\"  technical documentation focus\n  - \"End users\"  user experience focus\n  - \"Both developers and end users\"  balanced approach\n  - \"Other\"  custom description\n```\n\n```\nquestion: \"What is the current project phase?\"\noptions:\n  - \"Early development / MVP\"  focus on core features\n  - \"Active development\"  feature expansion\n  - \"Maintenance mode\"  stability and bug fixes\n  - \"Planning major changes\"  architectural considerations\n```\n\n### 2.3 Identify Stakeholders\nAsk about stakeholders:\n```\nquestion: \"Who are the key stakeholders for this project?\"\noptions:\n  - \"Solo project (just me)\"  simplified RACI\n  - \"Small team (2-5 people)\"  team collaboration\n  - \"Larger organization\"  formal stakeholder matrix\n  - \"Open source community\"  contributor-focused\n```\n\n## Phase 3: PRD Generation\n\n### 3.1 Create PRD File\nCreate the PRD in `docs/prds/`:\n```\ndocs/prds/project-overview.md\n```\n\n### 3.2 PRD Template\nGenerate PRD with this structure:\n\n```markdown\n# {Project Name} - Product Requirements Document\n\n**Created**: {date}\n**Status**: Draft\n**Version**: 1.0\n\n## Executive Summary\n\n### Problem Statement\n{Extracted or confirmed problem description}\n\n### Proposed Solution\n{Project description and approach}\n\n### Business Impact\n{Value proposition and expected outcomes}\n\n## Stakeholders & Personas\n\n### Stakeholder Matrix\n| Role | Name/Team | Responsibility | Contact |\n|------|-----------|----------------|---------|\n| {role} | {name} | {responsibility} | {contact} |\n\n### User Personas\n\n#### Primary: {Persona Name}\n- **Description**: {who they are}\n- **Needs**: {what they need}\n- **Pain Points**: {current frustrations}\n- **Goals**: {what success looks like}\n\n## Functional Requirements\n\n### Core Features\n{List of main capabilities extracted from docs}\n\n| ID | Feature | Description | Priority |\n|----|---------|-------------|----------|\n| FR-001 | {feature} | {description} | {P0/P1/P2} |\n\n### User Stories\n{User stories derived from features}\n\n- As a {user type}, I want to {action} so that {benefit}\n\n## Non-Functional Requirements\n\n### Performance\n- {Response time expectations}\n- {Throughput requirements}\n\n### Security\n- {Authentication requirements}\n- {Data protection needs}\n\n### Accessibility\n- {Accessibility standards to follow}\n\n### Compatibility\n- {Browser/platform/version support}\n\n## Technical Considerations\n\n### Architecture\n{High-level architecture from docs or inferred}\n\n### Dependencies\n{Key dependencies from package manifest}\n\n### Integration Points\n{External services, APIs, databases}\n\n## Success Metrics\n\n| Metric | Current | Target | Measurement |\n|--------|---------|--------|-------------|\n| {metric} | {baseline} | {goal} | {how to measure} |\n\n## Scope\n\n### In Scope\n- {Included features and capabilities}\n\n### Out of Scope\n- {Explicitly excluded items}\n- {Future considerations}\n\n## Timeline & Phases\n\n### Current Phase: {phase name}\n{Description of current work focus}\n\n### Roadmap\n| Phase | Focus | Status |\n|-------|-------|--------|\n| {phase} | {focus areas} | {status} |\n\n---\n*Generated from existing documentation via /blueprint:prd*\n*Review and update as project evolves*\n```\n\n## Phase 4: Validation & Follow-up\n\n### 4.1 Present Summary\nShow the user:\n```\n PRD Generated: {Project Name}\n\n**Location**: `docs/prds/project-overview.md`\n\n**Extracted from**:\n- {list of source documents}\n\n**Key sections**:\n- Executive Summary: {status}\n- Stakeholders: {count} identified\n- Functional Requirements: {count} features\n- Non-Functional Requirements: {status}\n\n**Confidence**: {High/Medium/Low}\n- {High confidence areas}\n- {Areas needing review}\n\n**Recommended next steps**:\n1. Review and refine the generated PRD\n2. Run `/blueprint:adr` to document architecture decisions\n3. Run `/blueprint:prp-create` for specific features\n4. Run `/blueprint:generate-skills` to create project skills\n```\n\n### 4.2 Suggest Follow-up\nBased on what was generated:\n- If architecture unclear  suggest `/blueprint:adr`\n- If features identified  suggest `/blueprint:prp-create` for key features\n- If PRD complete  suggest `/blueprint:generate-skills`\n\n## Phase 5: Update Manifest\n\nUpdate `docs/blueprint/manifest.json`:\n- Add PRD to `generated_artifacts`\n- Update `has_prds` to true\n- Update `updated_at` timestamp\n\n**Tips**:\n- Be thorough in reading existing docs - they often contain valuable context\n- Ask clarifying questions for ambiguous or missing information\n- Infer from code structure when documentation is sparse\n- Mark uncertain sections for user review\n- Keep PRD focused on \"what\" and \"why\", not \"how\"\n\n### 4.3 Prompt for next action (use AskUserQuestion):\n\n```\nquestion: \"PRD generated. What would you like to do next?\"\noptions:\n  - label: \"Document architecture decisions (Recommended)\"\n    description: \"Run /blueprint:adr to capture technical decisions\"\n  - label: \"Generate project skills\"\n    description: \"Extract skills from PRD for Claude context\"\n  - label: \"Create a PRP for a feature\"\n    description: \"Start implementing a specific feature\"\n  - label: \"Review and refine PRD\"\n    description: \"I want to edit the generated PRD first\"\n  - label: \"I'm done for now\"\n    description: \"Exit - PRD is saved\"\n```\n\n**Based on selection:**\n- \"Document architecture decisions\"  Run `/blueprint:adr`\n- \"Generate project skills\"  Run `/blueprint:generate-skills`\n- \"Create a PRP\"  Run `/blueprint:prp-create` (ask for feature name)\n- \"Review and refine\"  Show PRD file location and key sections needing attention\n- \"I'm done\"  Exit\n\n**Error Handling**:\n- If no README.md  ask user for project description\n- If blueprint not initialized  suggest `/blueprint:init`\n- If conflicting information in docs  ask user to clarify"
              },
              {
                "name": "/blueprint-promote",
                "description": "Move generated artifact to custom layer to preserve modifications",
                "path": "blueprint-plugin/commands/blueprint-promote.md",
                "frontmatter": {
                  "created": "2025-12-22T00:00:00.000Z",
                  "modified": "2026-01-09T00:00:00.000Z",
                  "reviewed": "2025-12-22T00:00:00.000Z",
                  "description": "Move generated artifact to custom layer to preserve modifications",
                  "args": "[skill-name|command-name]",
                  "allowed_tools": [
                    "Read",
                    "Write",
                    "Bash",
                    "AskUserQuestion"
                  ],
                  "argument-hint": "Name of the skill or command to promote"
                },
                "content": "Copy a generated rule to the custom rules layer for preservation.\n\n**Purpose**:\n- Copy generated content from `.claude/rules/` to preserve modifications\n- Mark as acknowledged in manifest to prevent overwrite warnings\n- Generated rules in `.claude/rules/` are the standard location (v3.0)\n\n**Usage**: `/blueprint:promote [name]`\n\n**Examples**:\n- `/blueprint:promote testing-strategies` - Acknowledge a rule's modifications\n\n**Steps**:\n\n1. **Parse argument**:\n   - Extract `name` from arguments\n   - If no name provided, list available generated rules and ask user to choose\n\n2. **Locate the rule**:\n   ```bash\n   # Check if it's a generated rule\n   test -f .claude/rules/{name}.md\n   ```\n\n   If not found:\n   ```\n   Rule '{name}' not found in generated content.\n\n   Available rules:\n   - architecture-patterns\n   - testing-strategies\n   - implementation-guides\n   - quality-standards\n   ```\n\n3. **Check if already acknowledged**:\n   - Read manifest for `custom_overrides.rules`\n   - If already in list, report \"Already acknowledged\"\n\n4. **Confirm acknowledgment**:\n   ```\n   question: \"Acknowledge modifications to {name}?\"\n   description: |\n     This will:\n     1. Mark {name} as user-modified in manifest\n     2. Prevent overwrite warnings during sync\n     3. Keep the rule in .claude/rules/\n\n   options:\n     - label: \"Yes, acknowledge\"\n       description: \"Mark as user-modified and preserve changes\"\n     - label: \"No, keep as generated\"\n       description: \"Leave as regeneratable (may show warnings)\"\n   ```\n\n5. **Update manifest**:\n   - Add to `custom_overrides.rules`\n   - Update `updated_at` timestamp\n\n   Example manifest update:\n   ```json\n   {\n     \"generated\": {\n       \"rules\": {\n         // testing-strategies still listed\n       }\n     },\n     \"custom_overrides\": {\n       \"rules\": [\"testing-strategies\"]  // added\n     }\n   }\n   ```\n\n6. **Report**:\n   ```\n   Rule modifications acknowledged!\n\n   testing-strategies.md:\n   - Location: .claude/rules/testing-strategies.md\n   - Status: User-modified (acknowledged)\n\n   This rule will now:\n   - Not show modification warnings in /blueprint:sync\n   - Still be tracked in manifest\n   - Be your responsibility to maintain\n\n   To edit: .claude/rules/testing-strategies.md\n   ```\n\n**Architecture note (v3.0)**:\nGenerated content now goes directly to `.claude/rules/` instead of a separate generated layer.\nThe manifest tracks which rules are user-modified vs auto-generated.\n\n**Tips**:\n- Acknowledge rules you want to customize\n- Unacknowledged modified rules will show warnings in /blueprint:sync\n- You can regenerate by removing from custom_overrides and running `/blueprint:generate-rules`"
              },
              {
                "name": "/blueprint-prp-create",
                "description": "Create a PRP (Product Requirement Prompt) with systematic research, curated context, and validation gates",
                "path": "blueprint-plugin/commands/blueprint-prp-create.md",
                "frontmatter": {
                  "created": "2025-12-16T00:00:00.000Z",
                  "modified": "2026-01-09T00:00:00.000Z",
                  "reviewed": "2025-12-16T00:00:00.000Z",
                  "description": "Create a PRP (Product Requirement Prompt) with systematic research, curated context, and validation gates",
                  "allowed_tools": [
                    "Read",
                    "Write",
                    "Glob",
                    "Bash",
                    "WebFetch",
                    "WebSearch",
                    "Task",
                    "AskUserQuestion"
                  ]
                },
                "content": "Create a comprehensive PRP (Product Requirement Prompt) for a feature or component.\n\n**What is a PRP?**\nA PRP is PRD + Curated Codebase Intelligence + Implementation Blueprint + Validation Gates - the minimum viable packet an AI agent needs to deliver production code successfully on first attempt.\n\n**Prerequisites**:\n- Blueprint Development initialized (`docs/blueprint/` exists)\n- Clear understanding of the feature to implement\n\n**Steps**:\n\n## Phase 1: Research\n\n### 1.1 Understand Requirements\nAsk the user or analyze context to understand:\n- **Goal**: What needs to be accomplished?\n- **Why**: What problem does this solve?\n- **Success Criteria**: How do we know it's done?\n\n### 1.2 Research Codebase\nExplore the existing codebase to understand:\n- **Existing patterns**: How similar features are implemented\n- **Integration points**: Where this feature connects\n- **Testing patterns**: How similar features are tested\n- **File locations**: Where new code should go\n\nUse the Explore agent:\n```\n<Task subagent_type=\"Explore\" prompt=\"Research patterns for [feature type] implementation\">\n```\n\n### 1.3 Research External Documentation\nFor any libraries/frameworks involved:\n- Search for relevant documentation sections\n- Look for known issues and gotchas\n- Find best practices and patterns\n\nUse WebSearch/WebFetch to gather:\n- Official documentation for key libraries\n- Stack Overflow discussions about common issues\n- GitHub issues for known problems\n\n### 1.4 Check/Create ai_docs\nLook for existing ai_docs:\n```bash\nls docs/blueprint/ai_docs/libraries/\nls docs/blueprint/ai_docs/project/\n```\n\nIf relevant ai_docs don't exist, create them:\n- Extract key patterns from documentation\n- Document gotchas discovered in research\n- Create curated, concise entries (< 200 lines)\n\n## Phase 2: Draft PRP\n\n### 2.1 Create PRP File\nCreate the PRP in `docs/prps/`:\n```\ndocs/prps/[feature-name].md\n```\n\n### 2.2 Fill Sections\n\n**Goal & Why**:\n- One sentence goal\n- Business justification\n- Target users\n- Priority\n\n**Success Criteria**:\n- Specific, testable acceptance criteria\n- Performance baselines with metrics\n- Security requirements\n\n**Context**:\n- **Documentation References**: URLs with specific sections\n- **ai_docs References**: Links to curated docs\n- **Codebase Intelligence**:\n  - Relevant files with line numbers\n  - Code snippets showing patterns to follow\n  - Integration points\n- **Known Gotchas**: Critical warnings with mitigations\n\n**Implementation Blueprint**:\n- Architecture decision with rationale\n- Task breakdown with pseudocode\n- Implementation order\n\n**TDD Requirements**:\n- Test strategy (unit, integration, e2e)\n- Critical test cases with code templates\n\n**Validation Gates**:\n- Executable commands for each quality gate\n- Expected outcomes\n\n## Phase 3: Assess Confidence\n\n### 3.1 Score Each Dimension\n\n| Dimension | Scoring Criteria |\n|-----------|------------------|\n| Context Completeness | 10: All file paths, snippets explicit. 7: Most provided. 4: Significant gaps |\n| Implementation Clarity | 10: Pseudocode covers all cases. 7: Main path clear. 4: High-level only |\n| Gotchas Documented | 10: All known pitfalls. 7: Major gotchas. 4: Some mentioned |\n| Validation Coverage | 10: All gates have commands. 7: Main commands. 4: Incomplete |\n\n### 3.2 Calculate Overall Score\n- Average of all dimensions\n- Target: 7+ for execution, 9+ for subagent delegation\n\n### 3.3 If Score < 7\n- [ ] Research missing context\n- [ ] Add ai_docs entries\n- [ ] Document more gotchas\n- [ ] Add validation commands\n- [ ] Clarify pseudocode\n\n## Phase 4: Review\n\n### 4.1 Self-Review Checklist\n- [ ] Goal is clear and specific\n- [ ] Success criteria are testable\n- [ ] All file paths are explicit (not \"somewhere in...\")\n- [ ] Code snippets show actual patterns (with line references)\n- [ ] Gotchas include mitigations\n- [ ] Validation commands are executable\n- [ ] Confidence score is honest\n\n### 4.2 Present to User\nShow the user:\n- PRP summary\n- Key implementation approach\n- Confidence score\n- Any areas needing clarification\n\n**Output Template**:\n```\n## PRP Created: [Feature Name]\n\n**Location:** `docs/prps/[feature-name].md`\n\n**Summary:**\n[1-2 sentence summary of what will be implemented]\n\n**Approach:**\n- [Key architectural decision]\n- [Main implementation pattern]\n\n**Context Collected:**\n- [X] ai_docs entries: [list]\n- [X] Codebase patterns identified\n- [X] External documentation referenced\n- [X] Known gotchas documented\n\n**Validation Gates:**\n- Gate 1: [Linting command]\n- Gate 2: [Type checking command]\n- Gate 3: [Unit tests command]\n- Gate 4: [Integration tests command]\n\n**Confidence Score:** X/10\n- Context: X/10\n- Implementation: X/10\n- Gotchas: X/10\n- Validation: X/10\n\n**Needs attention (if score < 7):**\n- [List any gaps to address]\n```\n\n### 4.3 Prompt for next action (use AskUserQuestion):\n\n**If confidence score >= 7:**\n```\nquestion: \"PRP ready (confidence: X/10). What would you like to do?\"\noptions:\n  - label: \"Execute PRP now (Recommended)\"\n    description: \"Implement the feature with TDD workflow and validation gates\"\n  - label: \"Create work-order for subagent\"\n    description: \"Package this PRP for isolated execution by a subagent\"\n  - label: \"Review and refine first\"\n    description: \"I want to improve the PRP before executing\"\n  - label: \"I'm done for now\"\n    description: \"Save PRP and exit - execute later with /blueprint:prp-execute\"\n```\n\n**If confidence score < 7:**\n```\nquestion: \"PRP needs work (confidence: X/10). What would you like to do?\"\noptions:\n  - label: \"Research more context\"\n    description: \"Explore codebase and documentation to fill gaps\"\n  - label: \"Create ai_docs entries\"\n    description: \"Curate library documentation to improve context\"\n  - label: \"Execute anyway (risky)\"\n    description: \"Proceed with implementation despite low confidence\"\n  - label: \"I'm done for now\"\n    description: \"Save incomplete PRP and return later\"\n```\n\n**Based on selection:**\n- \"Execute PRP now\"  Run `/blueprint:prp-execute [feature-name]`\n- \"Create work-order\"  Run `/blueprint:work-order`\n- \"Review and refine\"  Show PRP file location and key gaps\n- \"Research more context\"  Use Explore agent on identified gaps\n- \"Create ai_docs entries\"  Run `/blueprint:curate-docs` for relevant libraries\n- \"Execute anyway\"  Run `/blueprint:prp-execute [feature-name]` with warning\n- \"I'm done\"  Exit\n\n**Tips**:\n- Be thorough in research phase - it saves implementation time\n- Include code snippets with actual line numbers\n- Document gotchas as you discover them\n- Validation gates should be copy-pasteable commands\n- Honest confidence scoring helps decide next steps\n\n**Error Handling**:\n- If `docs/blueprint/` doesn't exist  Run `/blueprint:init` first\n- If libraries unfamiliar  Research documentation thoroughly\n- If codebase patterns unclear  Use Explore agent extensively"
              },
              {
                "name": "/blueprint-prp-execute",
                "description": "Execute a PRP with validation loop, TDD workflow, and quality gates",
                "path": "blueprint-plugin/commands/blueprint-prp-execute.md",
                "frontmatter": {
                  "created": "2025-12-16T00:00:00.000Z",
                  "modified": "2026-01-09T00:00:00.000Z",
                  "reviewed": "2025-12-16T00:00:00.000Z",
                  "description": "Execute a PRP with validation loop, TDD workflow, and quality gates",
                  "allowed_tools": [
                    "Read",
                    "Write",
                    "Edit",
                    "Glob",
                    "Bash",
                    "Task",
                    "AskUserQuestion"
                  ]
                },
                "content": "Execute a PRP (Product Requirement Prompt) with systematic implementation and validation.\n\n**Usage**: `/blueprint:prp-execute [prp-name]`\n\n**Prerequisites**:\n- PRP exists in `docs/prps/[prp-name].md`\n- Confidence score >= 7 (if lower, suggest `/blueprint:prp-create` refinement)\n\n**Execution Phases**:\n\n## Phase 1: Load Context\n\n### 1.1 Read PRP\n```bash\ncat docs/prps/$PRP_NAME.md\n```\n\n### 1.2 Verify Confidence Score\n- If score >= 9: Ready for autonomous execution\n- If score 7-8: Proceed with some discovery expected\n- If score < 7: **STOP** - Recommend refinement first\n\n### 1.3 Read ai_docs References\nLoad all referenced ai_docs entries for context:\n- `ai_docs/libraries/*.md`\n- `ai_docs/project/patterns.md`\n\n### 1.4 Plan Execution\nBased on the Implementation Blueprint:\n1. Create TodoWrite entries for each task\n2. Order by dependencies\n3. Identify validation checkpoints\n\n## Phase 2: Run Initial Validation Gates\n\n### 2.1 Pre-Implementation Validation\nRun validation gates to establish baseline:\n\n```bash\n# Gate 1: Ensure linting passes before changes\n[linting command from PRP]\n\n# Gate 2: Ensure existing tests pass\n[test command from PRP]\n```\n\n**Expected**: All gates pass (clean starting state)\n\n**If gates fail**:\n- Document existing issues\n- Decide whether to fix first or proceed\n- Update PRP notes if needed\n\n## Phase 3: TDD Implementation\n\nFor each task in Implementation Blueprint:\n\n### 3.1 Write Tests First (RED)\n\nFollowing TDD Requirements from PRP:\n\n```bash\n# Create test file if needed\n# Write test case as specified in PRP\n```\n\nRun tests:\n```bash\n[test command]\n```\n\n**Expected**: New test FAILS (proves test is meaningful)\n\n### 3.2 Implement Minimal Code (GREEN)\n\nWrite minimum code to pass the test:\n- Follow patterns from Codebase Intelligence\n- Apply patterns from ai_docs\n- Watch for Known Gotchas\n\nRun tests:\n```bash\n[test command]\n```\n\n**Expected**: Test PASSES\n\n### 3.3 Refactor (REFACTOR)\n\nImprove code while keeping tests green:\n- Extract common patterns\n- Improve naming\n- Add type hints\n- Follow project conventions\n\nRun tests:\n```bash\n[test command]\n```\n\n**Expected**: Tests STILL PASS\n\n### 3.4 Run Validation Gates\n\nAfter each significant change:\n\n```bash\n# Gate 1: Linting\n[linting command]\n\n# Gate 2: Type checking\n[type check command]\n\n# Gate 3: Unit tests\n[test command]\n```\n\n**If any gate fails**:\n1. Fix the issue\n2. Re-run the gate\n3. Continue only when passing\n\n### 3.5 Update Progress\nMark task as complete in TodoWrite:\n```\n Task N: [Description]\n```\n\n## Phase 4: Final Validation\n\n### 4.1 Run All Validation Gates\n\nExecute every gate from the PRP:\n\n```bash\n# Gate 1: Linting\n[linting command]\n# Expected: No errors\n\n# Gate 2: Type Checking\n[type check command]\n# Expected: No errors\n\n# Gate 3: Unit Tests\n[unit test command]\n# Expected: All pass\n\n# Gate 4: Integration Tests (if applicable)\n[integration test command]\n# Expected: All pass\n\n# Gate 5: Coverage Check\n[coverage command]\n# Expected: Meets threshold\n\n# Gate 6: Security Scan (if applicable)\n[security command]\n# Expected: No high/critical issues\n```\n\n### 4.2 Verify Success Criteria\n\nCheck each success criterion from PRP:\n- [ ] Criterion 1: [verified how]\n- [ ] Criterion 2: [verified how]\n- [ ] Criterion 3: [verified how]\n\n### 4.3 Check Performance Baselines\n\nIf performance baselines defined:\n```bash\n# Run performance test\n[performance command]\n```\n\nCompare results to baseline targets.\n\n## Phase 5: Report\n\n### 5.1 Execution Summary\n\nGenerate completion report:\n\n```markdown\n## PRP Execution Complete: [Feature Name]\n\n### Implementation Summary\n- **Tasks completed**: X/Y\n- **Tests added**: N\n- **Files modified**: [list]\n\n### Validation Results\n\n| Gate | Command | Result |\n|------|---------|--------|\n| Linting | `[cmd]` |  Pass |\n| Type Check | `[cmd]` |  Pass |\n| Unit Tests | `[cmd]` |  Pass (N tests) |\n| Integration | `[cmd]` |  Pass |\n| Coverage | `[cmd]` |  85% (target: 80%) |\n\n### Success Criteria\n\n- [x] Criterion 1: Verified via [method]\n- [x] Criterion 2: Verified via [method]\n- [x] Criterion 3: Verified via [method]\n\n### New Gotchas Discovered\n[Document any new gotchas for future reference]\n\n### Recommendations\n- [Any follow-up work suggested]\n- [Updates to ai_docs recommended]\n\n### Ready for:\n- [ ] Code review\n- [ ] Merge to main branch\n```\n\n### 5.2 Update ai_docs\n\nIf new patterns or gotchas discovered:\n- Update relevant ai_docs entries\n- Create new entries if needed\n- Document lessons learned\n\n### 5.3 Mark PRP Complete\n\nMove or annotate PRP as executed:\n```markdown\n## Status: EXECUTED\n**Executed on**: [date]\n**Commit**: [hash]\n**Notes**: [any notes]\n```\n\n## Error Handling\n\n### Validation Gate Failure\n1. Identify the failing check\n2. Analyze the error message\n3. Fix the issue\n4. Re-run the gate\n5. Continue when passing\n\n### Test Failure Loop\nIf stuck in RED phase (test keeps failing):\n1. Review Known Gotchas in PRP\n2. Check ai_docs for patterns\n3. Search codebase for similar implementations\n4. Ask user for clarification if blocked\n\n### Low Confidence Areas\nWhen encountering areas not covered by PRP:\n1. Document the gap\n2. Research as needed\n3. Update PRP for future reference\n4. Proceed with best judgment\n\n### Blocked Progress\nIf unable to proceed:\n1. Document the blocker\n2. Create work-order for blocker resolution\n3. Report to user with options\n\n### 5.4 Prompt for next action (use AskUserQuestion):\n\n```\nquestion: \"PRP execution complete. What would you like to do next?\"\noptions:\n  - label: \"Commit changes (Recommended)\"\n    description: \"Create a commit with conventional message for this feature\"\n  - label: \"Create work-order for follow-up\"\n    description: \"Package remaining work or enhancements\"\n  - label: \"Update ai_docs\"\n    description: \"Document new patterns or gotchas discovered\"\n  - label: \"Continue to next PRP\"\n    description: \"If there are more PRPs to execute\"\n  - label: \"I'm done for now\"\n    description: \"Exit - changes are saved locally\"\n```\n\n**Based on selection:**\n- \"Commit changes\"  Run `/git:commit` or guide through commit\n- \"Create work-order\"  Run `/blueprint:work-order`\n- \"Update ai_docs\"  Run `/blueprint:curate-docs` for relevant patterns\n- \"Continue to next PRP\"  List available PRPs and run `/blueprint:prp-execute [next]`\n- \"I'm done\"  Exit\n\n**Tips**:\n- Trust the PRP - it was researched for a reason\n- Run validation gates frequently (not just at the end)\n- Document any new gotchas discovered\n- Update ai_docs with lessons learned\n- Commit after each passing validation cycle"
              },
              {
                "name": "/blueprint-rules",
                "description": "Manage modular rules in .claude/rules/ directory",
                "path": "blueprint-plugin/commands/blueprint-rules.md",
                "frontmatter": {
                  "created": "2025-12-17T00:00:00.000Z",
                  "modified": "2026-01-09T00:00:00.000Z",
                  "reviewed": "2025-12-17T00:00:00.000Z",
                  "description": "Manage modular rules in .claude/rules/ directory",
                  "allowed_tools": [
                    "Read",
                    "Write",
                    "Edit",
                    "Bash",
                    "Glob",
                    "AskUserQuestion"
                  ]
                },
                "content": "Manage modular rules for the project. Rules are markdown files in `.claude/rules/` that provide context-specific instructions to Claude.\n\n**Steps**:\n\n1. **Check blueprint status**:\n   - Read `docs/blueprint/manifest.json`\n   - Check if modular rules are enabled\n   - If not enabled, offer to enable:\n     ```\n     Use AskUserQuestion:\n     question: \"Modular rules are not enabled. Would you like to enable them?\"\n     options:\n       - \"Yes, create .claude/rules/ structure\"  enable and continue\n       - \"No, use single CLAUDE.md\"  exit\n     ```\n\n2. **Determine action** (use AskUserQuestion):\n   ```\n   question: \"What would you like to do with modular rules?\"\n   options:\n     - \"List existing rules\"  show current rules\n     - \"Add a new rule\"  create new rule file\n     - \"Edit existing rule\"  modify rule\n     - \"Generate rules from PRDs\"  auto-generate from requirements\n     - \"Sync rules with CLAUDE.md\"  bidirectional sync\n     - \"Validate rules\"  check for issues\n   ```\n\n3. **List existing rules**:\n   - Scan `.claude/rules/` recursively for `.md` files\n   - Parse frontmatter for `paths` field (if scoped)\n   - Display:\n     ```\n      Modular Rules\n\n     Global Rules (apply to all files):\n     - development.md - TDD workflow and conventions\n     - testing.md - Test requirements\n\n     Scoped Rules (apply to specific paths):\n     - frontend/react.md - paths: [\"src/components/**/*.tsx\"]\n     - backend/api.md - paths: [\"src/api/**/*.ts\"]\n\n     Total: 4 rules\n     ```\n\n4. **Add a new rule** (use AskUserQuestion):\n   ```\n   question: \"What type of rule would you like to create?\"\n   options:\n     - \"Development workflow\"  development.md template\n     - \"Testing requirements\"  testing.md template\n     - \"Code style/conventions\"  code-style.md template\n     - \"Architecture patterns\"  architecture.md template\n     - \"Language-specific\"  prompt for language\n     - \"Framework-specific\"  prompt for framework\n     - \"Custom\"  blank template with guidance\n   ```\n\n   Then ask:\n   ```\n   question: \"Should this rule apply to all files or specific paths?\"\n   options:\n     - \"All files (global)\"  no paths frontmatter\n     - \"Specific file patterns\"  prompt for glob patterns\n   ```\n\n5. **Rule file templates**:\n\n   **Global rule template**:\n   ```markdown\n   # {Rule Name}\n\n   ## Overview\n   {Brief description of when this rule applies}\n\n   ## Requirements\n   - {Requirement 1}\n   - {Requirement 2}\n\n   ## Examples\n   {Code examples if applicable}\n   ```\n\n   **Scoped rule template**:\n   ```markdown\n   ---\n   paths:\n     - \"src/components/**/*.tsx\"\n     - \"src/components/**/*.ts\"\n   ---\n\n   # {Rule Name}\n\n   ## Overview\n   {Brief description - applies only to matched paths}\n\n   ## Requirements\n   - {Requirement 1}\n   - {Requirement 2}\n   ```\n\n6. **Generate rules from PRDs**:\n   - Read all PRDs in `docs/prds/`\n   - Extract key requirements and constraints\n   - Group by domain (testing, architecture, coding standards)\n   - Generate rule files:\n     - `rules/from-prd-testing.md` - Test requirements from PRDs\n     - `rules/from-prd-architecture.md` - Architecture decisions\n     - `rules/from-prd-conventions.md` - Coding conventions\n\n7. **Sync rules with CLAUDE.md**:\n   - Parse existing CLAUDE.md sections\n   - Compare with rules in `.claude/rules/`\n   - Offer sync options:\n     ```\n     question: \"How would you like to sync?\"\n     options:\n       - \"CLAUDE.md  rules (split into modular files)\"\n       - \"Rules  CLAUDE.md (consolidate)\"\n       - \"Merge both (combine unique content)\"\n     ```\n\n8. **Validate rules**:\n   - Check for syntax errors in frontmatter\n   - Validate glob patterns in `paths` field\n   - Check for conflicting rules\n   - Warn about overly broad or narrow scopes\n   - Report:\n     ```\n      Rule Validation\n\n     Checked: 4 rules\n     Valid: 4\n     Warnings: 1\n       - frontend/react.md: paths pattern may be too broad\n\n     No errors found.\n     ```\n\n9. **Update manifest**:\n   - Add created/modified rules to `generated_artifacts.rules`\n   - Update `updated_at` timestamp\n\n10. **Report**:\n    ```\n     Rule management complete!\n\n    {Action summary}\n\n    Current rules: {count} files\n    - Global: {count}\n    - Scoped: {count}\n\n    Run `/blueprint-status` to see full configuration.\n    ```\n\n11. **Prompt for next action** (use AskUserQuestion):\n    ```\n    question: \"Rules updated. What would you like to do next?\"\n    options:\n      - label: \"Update CLAUDE.md (Recommended)\"\n        description: \"Regenerate overview to reflect rule changes\"\n      - label: \"Add another rule\"\n        description: \"Create additional domain-specific rules\"\n      - label: \"Check blueprint status\"\n        description: \"Run /blueprint:status to see full configuration\"\n      - label: \"I'm done for now\"\n        description: \"Exit - rules are active immediately\"\n    ```\n\n    **Based on selection:**\n    - \"Update CLAUDE.md\"  Run `/blueprint:claude-md`\n    - \"Add another rule\"  Restart at step 4 (Add a new rule)\n    - \"Check blueprint status\"  Run `/blueprint:status`\n    - \"I'm done\"  Exit\n\n**Common Rule Patterns**:\n\n| Rule Type | Suggested Path | Scope Pattern |\n|-----------|---------------|---------------|\n| React components | `rules/frontend/react.md` | `[\"**/*.tsx\", \"**/*.jsx\"]` |\n| API handlers | `rules/backend/api.md` | `[\"src/api/**/*\", \"src/routes/**/*\"]` |\n| Database models | `rules/backend/models.md` | `[\"src/models/**/*\", \"src/db/**/*\"]` |\n| Test files | `rules/testing.md` | `[\"**/*.test.*\", \"**/*.spec.*\"]` |\n| Documentation | `rules/docs.md` | `[\"**/*.md\", \"docs/**/*\"]` |"
              },
              {
                "name": "/blueprint-status",
                "description": "Show blueprint version, configuration, and check for available upgrades",
                "path": "blueprint-plugin/commands/blueprint-status.md",
                "frontmatter": {
                  "created": "2025-12-17T00:00:00.000Z",
                  "modified": "2026-01-09T00:00:00.000Z",
                  "reviewed": "2025-12-22T00:00:00.000Z",
                  "description": "Show blueprint version, configuration, and check for available upgrades",
                  "allowed_tools": [
                    "Read",
                    "Bash",
                    "Glob",
                    "AskUserQuestion"
                  ]
                },
                "content": "Display the current blueprint configuration status with three-layer architecture breakdown.\n\n**Steps**:\n\n1. **Check if blueprint is initialized**:\n   - Look for `docs/blueprint/manifest.json`\n   - If not found, report:\n     ```\n     Blueprint not initialized in this project.\n     Run `/blueprint:init` to get started.\n     ```\n\n2. **Read manifest and gather information**:\n   - Parse `manifest.json` for version and configuration\n   - Count PRDs in `docs/prds/`\n   - Count ADRs in `docs/adrs/`\n   - Count PRPs in `docs/prps/`\n   - Count work-orders (pending, completed, archived)\n   - Count generated rules in `.claude/rules/`\n   - Count custom skills in `.claude/skills/`\n   - Count custom commands in `.claude/commands/`\n   - Check for `.claude/rules/` directory\n   - Check for `CLAUDE.md` file\n   - Check for `docs/blueprint/feature-tracker.json`\n   - If feature tracker exists, read statistics and last_updated\n\n3. **Check for upgrade availability**:\n   - Compare `format_version` in manifest with current plugin version\n   - Current format version: **3.0.0**\n   - If manifest version < current  upgrade available\n\n4. **Check generated content status**:\n   - For each generated rule in manifest:\n     - Hash current file content\n     - Compare with stored `content_hash`\n     - Status: `current` (unchanged), `modified` (user edited), `stale` (source PRDs changed)\n\n5. **Display status report**:\n   ```\n   Blueprint Status\n\n   Version: v{format_version} {upgrade_indicator}\n   Initialized: {created_at}\n   Last Updated: {updated_at}\n\n   Project Configuration:\n   - Name: {project.name}\n   - Type: {project.type}\n   - Stack: {project.detected_stack}\n   - Rules Mode: {structure.claude_md_mode}\n\n   Project Documentation (docs/):\n   - PRDs: {count} in docs/prds/\n   - ADRs: {count} in docs/adrs/\n   - PRPs: {count} in docs/prps/\n\n   Work Orders (docs/blueprint/work-orders/):\n   - Pending: {count}\n   - Completed: {count}\n   - Archived: {count}\n\n   Three-Layer Architecture:\n\n   Layer 1: Plugin (blueprint-plugin)\n   - Commands: /blueprint:* (auto-updated with plugin)\n   - Skills: blueprint-development, blueprint-migration, confidence-scoring\n   - Agents: requirements-documentation, architecture-decisions, prp-preparation\n\n   Layer 2: Generated (.claude/rules/)\n   - Rules: {count} ({status_summary})\n     {list each with status indicator:  current,  modified,  stale}\n\n   Layer 3: Custom (.claude/skills/, .claude/commands/)\n   - Skills: {count} (user-maintained)\n   - Commands: {count} (user-maintained)\n\n   {If feature_tracker enabled:}\n   Feature Tracker:\n   - Status: Enabled\n   - Source: {feature_tracker.source_document}\n   - Progress: {statistics.complete}/{statistics.total_features} ({statistics.completion_percentage}%)\n   - Last Sync: {last_updated}\n   - Phases: {count in_progress} active, {count complete} complete\n\n   Structure:\n    docs/blueprint/manifest.json\n   {|} docs/prds/\n   {|} docs/adrs/\n   {|} docs/prps/\n   {|} docs/blueprint/work-orders/\n   {|} docs/blueprint/ai_docs/\n   {|} docs/blueprint/feature-tracker.json\n   {|} .claude/rules/\n   {|} CLAUDE.md\n\n   {If upgrade available:}\n   Upgrade available: v{current}  v{latest}\n      Run `/blueprint:upgrade` to upgrade.\n\n   {If modified generated content:}\n   Modified content detected: {count} files\n      Run `/blueprint:sync` to review changes.\n      Run `/blueprint:promote [name]` to move to custom layer.\n\n   {If stale generated content:}\n   Stale content detected: {count} files (PRDs changed since generation)\n      Run `/blueprint:generate-skills` to regenerate.\n\n   {If up to date:}\n   Blueprint is up to date.\n   ```\n\n6. **Additional checks**:\n   - Warn if work-overview.md is stale (older than latest work-order)\n   - Warn if PRDs exist but no generated rules\n   - Warn if modular rules enabled but `.claude/rules/` is empty\n   - Warn if generated content is modified or stale\n   - Warn if feature-tracker.json is older than 7 days (needs sync)\n   - Warn if feature-tracker sync targets have been modified since last sync\n\n7. **Prompt for next action** (use AskUserQuestion):\n\n   **Build options dynamically based on state:**\n   - If upgrade available  Include \"Upgrade to v{latest}\"\n   - If modified content  Include \"Sync generated content\"\n   - If stale content  Include \"Regenerate skills\"\n   - If PRDs exist but no generated skills  Include \"Generate skills from PRDs\"\n   - If skills exist but no commands  Include \"Generate workflow commands\"\n   - If CLAUDE.md stale  Include \"Update CLAUDE.md\"\n   - If feature tracker exists but stale  Include \"Sync feature tracker\"\n   - Always include \"Continue development\" and \"I'm done\"\n\n   ```\n   question: \"What would you like to do?\"\n   options:\n     # Dynamic - include based on state detected above\n     - label: \"Upgrade to v{latest}\" (if upgrade available)\n       description: \"Upgrade blueprint format to latest version\"\n     - label: \"Sync generated content\" (if modified)\n       description: \"Review changes to generated skills/commands\"\n     - label: \"Regenerate from PRDs\" (if stale)\n       description: \"Update generated content from changed PRDs\"\n     - label: \"Generate rules from PRDs\" (if PRDs exist, no rules)\n       description: \"Extract project-specific rules from your PRDs\"\n     - label: \"Update CLAUDE.md\" (if stale or missing)\n       description: \"Regenerate project overview document\"\n     - label: \"Sync feature tracker\" (if feature tracker stale)\n       description: \"Synchronize tracker with work-overview.md and TODO.md\"\n     # Always include these:\n     - label: \"Continue development\"\n       description: \"Run /project:continue to work on next task\"\n     - label: \"I'm done for now\"\n       description: \"Exit status check\"\n   ```\n\n   **Based on selection:**\n   - \"Upgrade\"  Run `/blueprint:upgrade`\n   - \"Sync\"  Run `/blueprint:sync`\n   - \"Regenerate\"  Run `/blueprint:generate-rules`\n   - \"Generate rules\"  Run `/blueprint:generate-rules`\n   - \"Update CLAUDE.md\"  Run `/blueprint:claude-md`\n   - \"Sync feature tracker\"  Run `/blueprint:feature-tracker-sync`\n   - \"Continue development\"  Run `/project:continue`\n   - \"I'm done\"  Exit\n\n**Example Output**:\n```\nBlueprint Status\n\nVersion: v3.0.0\nInitialized: 2024-01-10T09:00:00Z\nLast Updated: 2024-01-15T14:30:00Z\n\nProject Configuration:\n- Name: my-awesome-project\n- Type: team\n- Stack: typescript, bun, react\n- Rules Mode: modular\n\nProject Documentation (docs/):\n- PRDs: 3 in docs/prds/\n- ADRs: 5 in docs/adrs/\n- PRPs: 2 in docs/prps/\n\nWork Orders (docs/blueprint/work-orders/):\n- Pending: 5\n- Completed: 12\n- Archived: 2\n\nThree-Layer Architecture:\n\nLayer 1: Plugin (blueprint-plugin)\n- Commands: 13 /blueprint:* commands (auto-updated)\n- Skills: 3 (blueprint-development, blueprint-migration, confidence-scoring)\n- Agents: 3 (requirements-documentation, architecture-decisions, prp-preparation)\n\nLayer 2: Generated (.claude/rules/)\n- Rules: 4 (3 current, 1 modified)\n  -  architecture-patterns.md (current)\n  -  testing-strategies.md (modified locally)\n  -  implementation-guides.md (current)\n  -  quality-standards.md (current)\n\nLayer 3: Custom (.claude/skills/, .claude/commands/, .claude/rules/)\n- Skills: 1 (my-custom-skill)\n- Commands: 0\n- Rules: 0 (user-maintained)\n\nFeature Tracker:\n- Status: Enabled\n- Source: REQUIREMENTS.md\n- Progress: 22/42 (52.4%)\n- Last Sync: 2024-01-14\n- Phases: 1 active, 2 complete\n\nStructure:\n docs/blueprint/manifest.json\n docs/prds/\n docs/adrs/\n docs/prps/\n docs/blueprint/work-orders/\n docs/blueprint/ai_docs/\n docs/blueprint/feature-tracker.json\n .claude/rules/\n CLAUDE.md\n\nModified content detected: 1 file\n   Run `/blueprint:sync` to review or `/blueprint:promote testing-strategies` to preserve.\n\nBlueprint is up to date.\n```"
              },
              {
                "name": "/blueprint-sync",
                "description": "Check for stale generated content and offer regeneration or promotion",
                "path": "blueprint-plugin/commands/blueprint-sync.md",
                "frontmatter": {
                  "created": "2025-12-22T00:00:00.000Z",
                  "modified": "2026-01-09T00:00:00.000Z",
                  "reviewed": "2025-12-22T00:00:00.000Z",
                  "description": "Check for stale generated content and offer regeneration or promotion",
                  "allowed_tools": [
                    "Read",
                    "Bash",
                    "Glob",
                    "AskUserQuestion"
                  ]
                },
                "content": "Check the status of generated content and offer options for modified or stale files.\n\n**Purpose**:\n- Detect when generated skills/commands have been manually modified\n- Detect when source PRDs have changed (making generated content stale)\n- Offer appropriate actions: regenerate, promote to custom, or keep as-is\n\n**Steps**:\n\n1. **Read manifest**:\n   ```bash\n   cat docs/blueprint/manifest.json\n   ```\n   - Extract `generated.rules` section\n   - If no generated content, report \"Nothing to sync\"\n\n2. **Check each generated rule**:\n   For each rule in `manifest.generated.rules`:\n\n   a. **Verify file exists**:\n      ```bash\n      test -f .claude/rules/{name}.md\n      ```\n\n   b. **Hash current content**:\n      ```bash\n      sha256sum .claude/rules/{name}.md | cut -d' ' -f1\n      ```\n\n   c. **Compare hashes**:\n      - If `content_hash` matches  status: `current`\n      - If `content_hash` differs  status: `modified`\n\n   d. **Check source freshness** (for rules from PRDs):\n      - Hash current PRD content\n      - Compare with `source_hash` in manifest\n      - If differs  status: `stale`\n\n3. **Display sync report**:\n   ```\n   Generated Content Sync Status\n\n   Rules (.claude/rules/):\n    architecture-patterns.md: Current\n    testing-strategies.md: Modified locally\n    implementation-guides.md: Stale (PRDs changed)\n    quality-standards.md: Current\n\n   Summary:\n   - Current: 3 files\n   - Modified: 1 file (user edited)\n   - Stale: 1 file (source changed)\n   ```\n\n4. **For modified content**, offer options:\n   ```\n   question: \"{name} has been modified locally. What would you like to do?\"\n   options:\n     - label: \"Keep modifications\"\n       description: \"Mark as acknowledged, preserve your changes\"\n     - label: \"Discard modifications (regenerate)\"\n       description: \"Overwrite with fresh generation from PRDs\"\n     - label: \"View diff\"\n       description: \"See what changed before deciding\"\n     - label: \"Skip this file\"\n       description: \"Leave as-is for now\"\n   ```\n\n   **Based on selection:**\n   - \"Keep modifications\"  Update `content_hash` to current, mark as acknowledged\n   - \"Regenerate\"  Regenerate this rule from PRDs\n   - \"View diff\"  Show diff then re-ask\n   - \"Skip\"  Continue to next file\n\n5. **For stale content**, offer options:\n   ```\n   question: \"{name} is stale (PRDs have changed). What would you like to do?\"\n   options:\n     - label: \"Regenerate from PRDs (Recommended)\"\n       description: \"Update with latest patterns from docs/prds/\"\n     - label: \"Keep current version\"\n       description: \"Mark as current without regenerating\"\n     - label: \"View what changed in PRDs\"\n       description: \"See PRD changes before deciding\"\n     - label: \"Skip this file\"\n       description: \"Leave stale for now\"\n   ```\n\n   **Based on selection:**\n   - \"Regenerate\"  Regenerate this rule from PRDs\n   - \"Keep\"  Update `source_hash` to current, mark as current\n   - \"View\"  Show PRD diff then re-ask\n   - \"Skip\"  Continue to next file\n\n6. **Update manifest** after changes:\n   - Update `content_hash` for regenerated files\n   - Update `source_hash` if PRD changes acknowledged\n   - Update `status` field appropriately\n\n7. **Final report**:\n   ```\n   Sync Complete\n\n   Actions taken:\n   - testing-strategies.md: Modifications acknowledged\n   - implementation-guides.md: Regenerated from PRDs\n\n   Current state:\n   - 4 generated rules (all current)\n\n   Manifest updated.\n   ```\n\n**Tips**:\n- Run `/blueprint:sync` periodically to check for drift\n- Acknowledge modifications you want to keep\n- Regenerating will overwrite local changes\n- Stale content still works, but may miss new patterns from PRDs"
              },
              {
                "name": "/blueprint-upgrade",
                "description": "Upgrade blueprint structure to the latest format version",
                "path": "blueprint-plugin/commands/blueprint-upgrade.md",
                "frontmatter": {
                  "created": "2025-12-17T00:00:00.000Z",
                  "modified": "2026-01-09T00:00:00.000Z",
                  "reviewed": "2026-01-09T00:00:00.000Z",
                  "description": "Upgrade blueprint structure to the latest format version",
                  "allowed_tools": [
                    "Read",
                    "Write",
                    "Edit",
                    "Bash",
                    "Glob",
                    "AskUserQuestion"
                  ]
                },
                "content": "Upgrade the blueprint structure to the latest format version.\n\n**Current Format Version**: 3.0.0\n\nThis command delegates version-specific migration logic to the `blueprint-migration` skill.\n\n**Steps**:\n\n1. **Check current state**:\n   - Read `docs/blueprint/.manifest.json` (v3.0 location) or `.claude/blueprints/.manifest.json` (v1.x/v2.x location)\n   - If not found in either location, suggest running `/blueprint:init` instead\n   - Extract current `format_version` (default to \"1.0.0\" if field missing)\n\n2. **Determine upgrade path**:\n   ```bash\n   # Read current version - check both old and new locations\n   if [[ -f docs/blueprint/.manifest.json ]]; then\n     current=$(jq -r '.format_version // \"3.0.0\"' docs/blueprint/.manifest.json)\n   elif [[ -f .claude/blueprints/.manifest.json ]]; then\n     current=$(jq -r '.format_version // \"1.0.0\"' .claude/blueprints/.manifest.json)\n   fi\n   target=\"3.0.0\"\n   ```\n\n   **Version compatibility matrix**:\n   | From Version | To Version | Migration Document |\n   |--------------|------------|-------------------|\n   | 1.0.x        | 1.1.x      | `migrations/v1.0-to-v1.1.md` |\n   | 1.x.x        | 2.0.0      | `migrations/v1.x-to-v2.0.md` |\n   | 2.x.x        | 3.0.0      | `migrations/v2.x-to-v3.0.md` |\n   | 3.0.0        | 3.0.0      | Already up to date |\n\n3. **Display upgrade plan**:\n   ```\n   Blueprint Upgrade\n\n   Current version: v{current}\n   Target version: v3.0.0\n\n   Major changes in v3.0:\n   - Blueprint state moves from .claude/blueprints/ to docs/blueprint/\n   - Generated skills become rules in .claude/rules/\n   - No more generated/ subdirectory - cleaner structure\n   - All blueprint-related files consolidated under docs/blueprint/\n\n   (For v2.0 changes when upgrading from v1.x:)\n   - PRDs, ADRs, PRPs move to docs/ (project documentation)\n   - Custom overrides in .claude/skills/ and .claude/commands/\n   - Content hashing for modification detection\n   ```\n\n4. **Confirm with user** (use AskUserQuestion):\n   ```\n   question: \"Ready to upgrade blueprint from v{current} to v3.0.0?\"\n   options:\n     - \"Yes, upgrade now\"  proceed\n     - \"Show detailed migration steps\"  display migration document\n     - \"Create backup first\"  run git stash or backup then proceed\n     - \"Cancel\"  exit\n   ```\n\n5. **Load and execute migration document**:\n   - Read the appropriate migration document from `blueprint-migration` skill\n   - For v1.x  v2.0: Load `migrations/v1.x-to-v2.0.md`\n   - For v2.x  v3.0: Load `migrations/v2.x-to-v3.0.md`\n   - Execute each step with user confirmation for destructive operations\n\n6. **v1.x  v2.0 migration overview** (from migration document):\n\n   a. **Create docs/ structure**:\n      ```bash\n      mkdir -p docs/prds docs/adrs docs/prps\n      ```\n\n   b. **Move documentation to docs/**:\n      - `.claude/blueprints/prds/*`  `docs/prds/`\n      - `.claude/blueprints/adrs/*`  `docs/adrs/`\n      - `.claude/blueprints/prps/*`  `docs/prps/`\n\n   c. **Create generated/ structure**:\n      ```bash\n      mkdir -p .claude/blueprints/generated/skills\n      mkdir -p .claude/blueprints/generated/commands\n      ```\n\n   d. **Relocate generated content**:\n      - For each skill in `manifest.generated_artifacts.skills`:\n        - Hash current content\n        - If modified: offer to promote to `.claude/skills/` (custom layer)\n        - Otherwise: move to `.claude/blueprints/generated/skills/`\n\n   e. **Update manifest to v2.0.0 schema**:\n      - Add `generated` section with content tracking\n      - Add `custom_overrides` section\n      - Add `project.detected_stack` field\n      - Bump `format_version` to \"2.0.0\"\n\n   f. **Enable document detection option** (new in v2.1):\n      ```\n      Use AskUserQuestion:\n      question: \"Would you like to enable automatic document detection? (New feature)\"\n      options:\n        - label: \"Yes - Detect PRD/ADR/PRP opportunities\"\n          description: \"Claude will prompt when conversations should become documents\"\n        - label: \"No - Keep manual commands only\"\n          description: \"Continue using explicit /blueprint: commands\"\n      ```\n\n      If enabled:\n      - Set `has_document_detection: true` in manifest\n      - If modular rules enabled, copy `document-management-rule.md` template to `.claude/rules/document-management.md`\n\n   g. **Migrate root documentation** (if any found):\n      ```bash\n      # Find documentation files in root (excluding standard files)\n      fd -d 1 -e md . | grep -viE '^\\./(README|CHANGELOG|CONTRIBUTING|LICENSE|CODE_OF_CONDUCT|SECURITY)'\n      ```\n\n      If documentation files found (e.g., REQUIREMENTS.md, ARCHITECTURE.md, DESIGN.md):\n      ```\n      Use AskUserQuestion:\n      question: \"Found documentation files in root: {file_list}. Would you like to migrate them to docs/?\"\n      options:\n        - label: \"Yes, migrate to docs/\"\n          description: \"Move to appropriate docs/ subdirectory\"\n        - label: \"No, leave in root\"\n          description: \"Keep files in current location\"\n      ```\n\n      If \"Yes\" selected:\n      - Analyze each file to determine document type\n      - Move to appropriate `docs/` subdirectory\n      - Record migration in upgrade_history\n\n7. **v2.x  v3.0 migration overview** (from migration document):\n\n   a. **Create docs/blueprint/ structure**:\n      ```bash\n      mkdir -p docs/blueprint/work-orders\n      mkdir -p docs/blueprint/ai_docs\n      ```\n\n   b. **Move state files from .claude/blueprints/ to docs/blueprint/**:\n      ```bash\n      # Move manifest\n      mv .claude/blueprints/.manifest.json docs/blueprint/.manifest.json\n\n      # Move work overview if exists\n      [[ -f .claude/blueprints/work-overview.md ]] && \\\n        mv .claude/blueprints/work-overview.md docs/blueprint/work-overview.md\n\n      # Move feature tracker if exists\n      [[ -f .claude/blueprints/feature-tracker.md ]] && \\\n        mv .claude/blueprints/feature-tracker.md docs/blueprint/feature-tracker.md\n\n      # Move work orders if exist\n      [[ -d .claude/blueprints/work-orders ]] && \\\n        mv .claude/blueprints/work-orders/* docs/blueprint/work-orders/ 2>/dev/null\n\n      # Move ai_docs if exist\n      [[ -d .claude/blueprints/ai_docs ]] && \\\n        mv .claude/blueprints/ai_docs/* docs/blueprint/ai_docs/ 2>/dev/null\n      ```\n\n   c. **Move generated skills to .claude/rules/**:\n      ```bash\n      # Create rules directory if needed\n      mkdir -p .claude/rules\n\n      # Move each generated skill to rules\n      for skill in .claude/blueprints/generated/skills/*.md; do\n        [[ -f \"$skill\" ]] || continue\n        name=$(basename \"$skill\" .md)\n        mv \"$skill\" \".claude/rules/${name}.md\"\n      done\n      ```\n\n   d. **Copy README template to docs/blueprint/**:\n      ```bash\n      # Create docs/blueprint/README.md with overview of blueprint structure\n      cat > docs/blueprint/README.md << 'EOF'\n      # Blueprint Documentation\n\n      This directory contains the blueprint state and documentation for this project.\n\n      ## Contents\n\n      - `.manifest.json` - Blueprint configuration and generated content tracking\n      - `work-overview.md` - Current work focus and priorities\n      - `feature-tracker.md` - Feature requirements and status\n      - `work-orders/` - Detailed work order documents\n      - `ai_docs/` - AI-generated documentation\n\n      ## Related Directories\n\n      - `docs/prds/` - Product Requirements Documents\n      - `docs/adrs/` - Architecture Decision Records\n      - `docs/prps/` - Problem Resolution Plans\n      - `.claude/rules/` - Generated rules (from blueprint)\n      EOF\n      ```\n\n   e. **Update manifest to v3.0.0 schema**:\n      - Change `generated.skills` to `generated.rules`\n      - Update all path references from `.claude/blueprints/` to `docs/blueprint/`\n      - Bump `format_version` to \"3.0.0\"\n\n   f. **Remove old .claude/blueprints/ directory**:\n      ```bash\n      # Verify all content has been moved\n      if [[ -d .claude/blueprints ]]; then\n        # Remove empty directories\n        rm -rf .claude/blueprints/generated\n        rm -rf .claude/blueprints/work-orders\n        rm -rf .claude/blueprints/ai_docs\n        # Remove the blueprints directory if empty\n        rmdir .claude/blueprints 2>/dev/null || \\\n          echo \"Warning: .claude/blueprints/ not empty, manual cleanup may be needed\"\n      fi\n      ```\n\n8. **Update manifest** (v3.0.0 schema):\n   ```json\n   {\n     \"format_version\": \"3.0.0\",\n     \"created_at\": \"[preserved]\",\n     \"updated_at\": \"[now]\",\n     \"created_by\": {\n       \"blueprint_plugin\": \"3.0.0\"\n     },\n     \"project\": {\n       \"name\": \"[preserved]\",\n       \"type\": \"[preserved]\",\n       \"detected_stack\": []\n     },\n     \"structure\": {\n       \"has_prds\": true,\n       \"has_adrs\": \"[detected]\",\n       \"has_prps\": \"[detected]\",\n       \"has_work_orders\": true,\n       \"has_ai_docs\": \"[detected]\",\n       \"has_modular_rules\": \"[preserved]\",\n       \"has_document_detection\": \"[based on user choice]\",\n       \"claude_md_mode\": \"[preserved]\"\n     },\n     \"generated\": {\n       \"rules\": {\n         \"[rule-name]\": {\n           \"source\": \"docs/prds/...\",\n           \"source_hash\": \"sha256:...\",\n           \"generated_at\": \"[now]\",\n           \"plugin_version\": \"3.0.0\",\n           \"content_hash\": \"sha256:...\",\n           \"status\": \"current\"\n         }\n       },\n       \"commands\": {}\n     },\n     \"custom_overrides\": {\n       \"rules\": [\"[any promoted rules]\"],\n       \"commands\": []\n     },\n     \"upgrade_history\": [\n       {\n         \"from\": \"{previous}\",\n         \"to\": \"3.0.0\",\n         \"date\": \"[now]\",\n         \"changes\": [\"Moved state to docs/blueprint/\", \"Converted skills to rules\", \"...\"]\n       }\n     ]\n   }\n   ```\n\n9. **Report**:\n   ```\n   Blueprint upgraded successfully!\n\n   v{previous}  v3.0.0\n\n   State files moved to docs/blueprint/:\n   - .manifest.json\n   - work-overview.md\n   - feature-tracker.md\n   - work-orders/ directory\n   - ai_docs/ directory\n\n   Generated rules (.claude/rules/):\n   - {n} rules (converted from skills)\n\n   Custom layer (.claude/skills/, .claude/commands/):\n   - {n} promoted rules (preserved modifications)\n   - {n} promoted commands\n\n   [Document detection: enabled (if selected)]\n\n   New v3.0 architecture:\n   - Blueprint state: docs/blueprint/ (version-controlled with project)\n   - Generated rules: .claude/rules/ (project-specific context)\n   - Custom layer: Your overrides, never auto-modified\n   - Removed: .claude/blueprints/generated/ (no longer needed)\n   ```\n\n10. **Prompt for next action** (use AskUserQuestion):\n   ```\n   question: \"Upgrade complete. What would you like to do next?\"\n   options:\n     - label: \"Check status (Recommended)\"\n       description: \"Run /blueprint:status to see updated configuration\"\n     - label: \"Regenerate rules from PRDs\"\n       description: \"Update generated rules with new tracking\"\n     - label: \"Update CLAUDE.md\"\n       description: \"Reflect new architecture in project docs\"\n     - label: \"Commit changes\"\n       description: \"Stage and commit the migration\"\n   ```\n\n   **Based on selection:**\n   - \"Check status\"  Run `/blueprint:status`\n   - \"Regenerate rules\"  Run `/blueprint:generate-rules`\n   - \"Update CLAUDE.md\"  Run `/blueprint:claude-md`\n   - \"Commit changes\"  Run `/git:commit` with migration message\n\n**Rollback**:\nIf upgrade fails:\n- Check git status for changes made\n- Use `git checkout -- .claude/` and `git checkout -- docs/blueprint/` to restore original structure\n- Manually move content back if needed\n- Report specific failure point for debugging"
              },
              {
                "name": "/blueprint-work-order",
                "description": "Create work-order with minimal context for isolated subagent execution, optionally linked to GitHub issue",
                "path": "blueprint-plugin/commands/blueprint-work-order.md",
                "frontmatter": {
                  "created": "2025-12-16T00:00:00.000Z",
                  "modified": "2026-01-09T00:00:00.000Z",
                  "reviewed": "2025-12-26T00:00:00.000Z",
                  "description": "Create work-order with minimal context for isolated subagent execution, optionally linked to GitHub issue",
                  "args": "[--no-publish] [--from-issue N]",
                  "argument-hint": "--no-publish for local-only, --from-issue 123 to create from existing issue",
                  "allowed_tools": [
                    "Read",
                    "Write",
                    "Glob",
                    "Bash",
                    "AskUserQuestion"
                  ]
                },
                "content": "Generate a work-order document for isolated subagent execution with optional GitHub issue integration.\n\n## Flags\n\n| Flag | Description |\n|------|-------------|\n| `--no-publish` | Create local work-order only, skip GitHub issue creation |\n| `--from-issue N` | Create work-order from existing GitHub issue #N |\n\n**Default behavior**: Creates both local work-order AND GitHub issue with `work-order` label.\n\n## Prerequisites\n\n- Blueprint Development initialized (`docs/blueprint/` exists)\n- At least one PRD exists (unless using `--from-issue`)\n- `docs/blueprint/work-overview.md` exists\n- `gh` CLI authenticated (unless using `--no-publish`)\n\n---\n\n## Mode: Create from Existing Issue (`--from-issue N`)\n\nWhen `--from-issue N` is provided:\n\n1. **Fetch issue**:\n   ```bash\n   gh issue view N --json title,body,labels,number\n   ```\n\n2. **Parse issue content**:\n   - Extract objective from title/body\n   - Extract any TDD requirements or success criteria if present\n   - Note existing labels\n\n3. **Generate work-order**:\n   - Number matches issue number (e.g., issue #42  work-order `042-...`)\n   - Pre-populate from issue content\n   - Add context sections (files, PRD reference, etc.)\n\n4. **Update issue with link**:\n   ```bash\n   gh issue comment N --body \"Work-order created: \\`docs/blueprint/work-orders/NNN-task-name.md\\`\"\n   gh issue edit N --add-label \"work-order\"\n   ```\n\n5. **Continue to save and report** (skip to Step 6 below)\n\n---\n\n## Mode: Create New Work-Order (Default)\n\n### Step 1: Analyze Current State\n\n- Read `docs/blueprint/work-overview.md` to understand current phase\n- Run `git status` to check uncommitted work\n- Run `git log -5 --oneline` to see recent work\n- Find existing work-orders (count them for numbering)\n\n### Step 2: Read Relevant PRDs\n\n- Read PRD files to understand requirements\n- Identify next logical work unit based on:\n  * Work-overview progress\n  * PRD phase/section ordering\n  * Git history (what's been done)\n\n### Step 3: Determine Next Work Unit\n\nShould be:\n* **Specific**: Single feature/component/fix\n* **Isolated**: Minimal dependencies\n* **Testable**: Clear success criteria\n* **Focused**: 1-4 hours of work\n\n**Good examples**:\n- \"Implement JWT token generation methods\"\n- \"Add input validation to registration endpoint\"\n- \"Create database migration for users table\"\n\n**Bad examples** (too broad):\n- \"Implement authentication\"\n- \"Fix bugs\"\n\n### Step 4: Determine Minimal Context\n\n- **Files to modify/create** (only relevant ones)\n- **PRD sections** (only specific requirements for this task)\n- **Existing code** (only relevant excerpts, not full files)\n- **Dependencies** (external libraries, environment variables)\n\n### Step 5: Generate Work-Order\n\n- Number: Find highest existing work-order number + 1 (001, 002, etc.)\n- Name: `NNN-brief-task-description.md`\n\n**Work-order structure**:\n\n```markdown\n# Work-Order NNN: [Task Name]\n\n**GitHub Issue**: #N\n**Status**: pending\n\n## Objective\n[One sentence describing what needs to be accomplished]\n\n## Context\n\n### Required Files\n[Only files needed - list with purpose]\n\n### PRD Reference\n[Link to specific PRD section, not entire PRD]\n\n### Technical Decisions\n[Only decisions relevant to this specific task]\n\n### Existing Code\n[Only relevant code excerpts needed for integration]\n\n## TDD Requirements\n\n### Test 1: [Test Description]\n[Exact test to write, with code template]\n**Expected Outcome**: Test should fail\n\n### Test 2: [Test Description]\n[Exact test to write]\n**Expected Outcome**: Test should fail\n\n[More tests as needed]\n\n## Implementation Steps\n\n1. **Write Test 1** - Run: `[test_command]` - Expected: **FAIL**\n2. **Implement Test 1** - Run: `[test_command]` - Expected: **PASS**\n3. **Refactor (if needed)** - Run: `[test_command]` - Expected: **STILL PASS**\n[Repeat for all tests]\n\n## Success Criteria\n- [ ] All specified tests written and passing\n- [ ] [Specific functional requirement met]\n- [ ] [Performance/security baseline met]\n- [ ] No regressions (existing tests pass)\n\n## Notes\n[Additional context, gotchas, considerations]\n\n## Related Work-Orders\n- **Depends on**: Work-Order NNN (if applicable)\n- **Blocks**: Work-Order NNN (if applicable)\n```\n\n---\n\n### Step 6: Save Work-Order\n\nSave to `docs/blueprint/work-orders/NNN-task-name.md`\nEnsure zero-padded numbering (001, 002, 010, 100)\n\n### Step 7: Create GitHub Issue (unless `--no-publish`)\n\n```bash\ngh issue create \\\n  --title \"Work-Order NNN: [Task Name]\" \\\n  --body \"## Work Order: [Task Name]\n\n**Local Context**: \\`docs/blueprint/work-orders/NNN-task-name.md\\`\n\n### Objective\n[One-line objective from work order]\n\n### TDD Requirements\n- [ ] Test 1: [description]\n- [ ] Test 2: [description]\n\n### Success Criteria\n- [ ] [Criterion 1]\n- [ ] [Criterion 2]\n\n---\n*AI-assisted development work order. See linked file for full execution context.*\" \\\n  --label \"work-order\"\n```\n\nCapture issue number and update work-order file:\n```bash\n# Extract issue number from gh output\ngh issue create ... 2>&1 | grep -oE '#[0-9]+' | head -1\n```\n\nUpdate the `**GitHub Issue**:` line in the work-order file with the issue number.\n\n### Step 8: Update `docs/blueprint/work-overview.md`\n\n- Add new work-order to \"Pending\" section\n- Include GitHub issue reference if created\n- Keep overview current\n\n### Step 9: Report\n\n```\nWork-order created!\n\nWork-Order: 003-jwt-token-generation.md\nLocation: docs/blueprint/work-orders/003-jwt-token-generation.md\nGitHub Issue: #42 (or \"Local only\" if --no-publish)\n\nObjective: [Brief objective]\n\nContext included:\n- Files: [List files]\n- Tests: [Number of tests specified]\n- Dependencies: [Key dependencies]\n\nReady for execution:\n- Can be executed by subagent with isolated context\n- TDD workflow enforced (tests specified first)\n- Clear success criteria defined\n- PR should use \"Fixes #42\" to auto-close issue\n```\n\n### Step 10: Prompt for Next Action\n\nUse AskUserQuestion:\n```\nquestion: \"Work-order ready. What would you like to do?\"\noptions:\n  - label: \"Execute this work-order (Recommended)\"\n    description: \"Start working on the task with TDD workflow\"\n  - label: \"Create another work-order\"\n    description: \"Generate the next task from pending items\"\n  - label: \"Delegate to subagent\"\n    description: \"Hand off for isolated execution\"\n  - label: \"I'm done for now\"\n    description: \"Exit - work-order is saved and ready\"\n```\n\n**Based on selection:**\n- \"Execute this work-order\"  Run `/project:continue` with work-order context\n- \"Create another work-order\"  Run `/blueprint:work-order` again\n- \"Delegate to subagent\"  Provide handoff instructions for subagent execution\n- \"I'm done\"  Exit\n\n---\n\n## Key Principles\n\n- **Minimal context**: Only what's needed, not full files/PRDs\n- **Specific tests**: Exact test cases, not vague descriptions\n- **TDD enforced**: Tests specified before implementation\n- **Clear criteria**: Unambiguous success checkboxes\n- **Isolated**: Task should be doable with only provided context\n- **Transparent**: GitHub issue provides visibility to collaborators\n\n---\n\n## Error Handling\n\n| Condition | Action |\n|-----------|--------|\n| No PRDs exist | Guide to write PRDs first |\n| `work-overview.md` empty | Ask for current phase/status |\n| Task unclear | Ask user what to work on next |\n| `gh` not authenticated | Warn and fallback to `--no-publish` behavior |\n| Issue already has `work-order` label | Warn, ask to update or create new |\n\n---\n\n## GitHub Integration Notes\n\n### Completion Flow\n1. Work completed on work-order\n2. PR created with `Fixes #N` in body/title\n3. Work-order moved to `completed/` directory\n4. Issue auto-closes when PR merges\n\n### Label Convention\nThe `work-order` label identifies issues created from this workflow. Create it in your repo if it doesn't exist:\n```bash\ngh label create work-order --description \"AI-assisted work order\" --color \"0E8A16\"\n```\n\n### Offline Mode\nUse `--no-publish` when:\n- Working offline\n- Private experimentation\n- Issue visibility not needed\n\nCan publish later by manually creating issue and updating work-order file."
              }
            ],
            "skills": [
              {
                "name": "blueprint-development",
                "description": "Generate project-specific rules and commands from PRDs for Blueprint Development methodology. Use when generating behavioral rules for architecture patterns, testing strategies, implementation guides, or quality standards from requirements documents.",
                "path": "blueprint-plugin/skills/blueprint-development/SKILL.md",
                "frontmatter": {
                  "created": "2025-12-16T00:00:00.000Z",
                  "modified": "2026-01-09T00:00:00.000Z",
                  "reviewed": "2025-12-26T00:00:00.000Z",
                  "name": "blueprint-development",
                  "description": "Generate project-specific rules and commands from PRDs for Blueprint Development methodology. Use when generating behavioral rules for architecture patterns, testing strategies, implementation guides, or quality standards from requirements documents."
                },
                "content": "# Blueprint Development Rule Generator\n\nThis skill teaches Claude how to generate project-specific behavioral rules and commands from Product Requirements Documents (PRDs) as part of the Blueprint Development methodology.\n\n## When to Use This Skill\n\nActivate this skill when:\n- User runs `/blueprint:generate-rules` command\n- User runs `/blueprint:generate-commands` command\n- User asks to \"generate rules from PRDs\"\n- User asks to \"create project-specific rules\"\n- User initializes Blueprint Development in a project\n\n## Rule Generation Process\n\n### Step 1: Analyze PRDs\n\nRead all PRD files in `docs/prds/` and extract:\n\n**Architecture Patterns**:\n- Project structure and organization\n- Dependency injection patterns\n- Error handling approaches\n- Module boundaries and layering\n- Code organization conventions\n\n**Testing Strategies**:\n- TDD workflow (RED  GREEN  REFACTOR)\n- Test types (unit, integration, e2e)\n- Mocking patterns\n- Coverage requirements\n- Test structure and organization\n\n**Implementation Guides**:\n- How to implement specific feature types (API endpoints, UI components, etc.)\n- Step-by-step patterns for common tasks\n- Integration with external services\n- Data flow patterns\n\n**Quality Standards**:\n- Code review checklist items\n- Performance baselines and targets\n- Security requirements (OWASP, validation, etc.)\n- Style and formatting standards\n\n### Step 2: Generate Four Domain Rules\n\nCreate project-specific behavioral rules in `.claude/rules/` alongside manual rules.\n\n**Two-Layer Architecture**:\n1. **Plugin layer**: Generic skills from blueprint-plugin (auto-updated)\n2. **Rules layer**: Behavioral rules from PRDs in `.claude/rules/` (project-specific, can be manually edited)\n\nGenerated rules are behavioral guidelines that Claude follows during development:\n\n#### 1. Architecture Patterns Rule\n\n**Location**: `.claude/rules/architecture-patterns.md`\n\n**Structure**:\n```markdown\n# Architecture Patterns\n\n> Architecture patterns and code organization for [project name]. Defines how code is structured, organized, and modularized in this project.\n\n## Project Structure\n[Describe directory organization, module boundaries, layering]\n\n## Design Patterns\n[Document architectural patterns used: MVC, layered, hexagonal, etc.]\n\n## Dependency Management\n[How dependencies are injected, managed, and organized]\n\n## Error Handling\n[Centralized error handling, error types, error propagation]\n\n## Code Organization\n[File naming conventions, module boundaries, separation of concerns]\n\n## Integration Patterns\n[How external services, databases, APIs are integrated]\n```\n\n**Guidelines**:\n- Extract architecture decisions from PRD \"Technical Decisions\" sections\n- Include code examples showing the patterns\n- Reference specific directories and file structures\n- Document rationale for architectural choices\n\n#### 2. Testing Strategies Rule\n\n**Location**: `.claude/rules/testing-strategies.md`\n\n**Structure**:\n```markdown\n# Testing Strategies\n\n> TDD workflow, testing patterns, and coverage requirements for [project name]. Enforces test-first development and defines testing standards.\n\n## TDD Workflow\nFollow strict RED  GREEN  REFACTOR:\n1. Write failing test describing desired behavior\n2. Run test suite to confirm failure\n3. Write minimal implementation to pass\n4. Run test suite to confirm success\n5. Refactor while keeping tests green\n\n## Test Structure\n[Directory organization, naming conventions, test types]\n\n## Test Types\n### Unit Tests\n[What to unit test, mocking patterns, isolation strategies]\n\n### Integration Tests\n[What to integration test, test database setup, external service handling]\n\n### End-to-End Tests\n[User flows to test, test environment setup, data seeding]\n\n## Mocking Patterns\n[When to mock, what to mock, mocking libraries and conventions]\n\n## Coverage Requirements\n[Minimum coverage percentages, critical path requirements, edge case coverage]\n\n## Test Commands\n[How to run tests, watch mode, coverage reports, debugging tests]\n```\n\n**Guidelines**:\n- Extract TDD requirements from PRD \"TDD Requirements\" sections\n- Extract coverage requirements from \"Success Criteria\"\n- Include specific test commands for the project\n- Document mocking patterns for external dependencies\n\n#### 3. Implementation Guides Rule\n\n**Location**: `.claude/rules/implementation-guides.md`\n\n**Structure**:\n```markdown\n# Implementation Guides\n\n> Step-by-step guides for implementing specific feature types in [project name]. Provides patterns for APIs, UI, data access, and integrations.\n\n## API Endpoint Implementation\n### Step 1: Write Integration Test\n[Template for API test]\n\n### Step 2: Create Route\n[Route definition pattern]\n\n### Step 3: Implement Controller\n[Controller pattern with error handling]\n\n### Step 4: Implement Service Logic\n[Service layer pattern with business logic]\n\n### Step 5: Add Data Access\n[Repository/data access pattern]\n\n## UI Component Implementation\n[Pattern for UI components if relevant]\n\n## Database Operations\n[Pattern for database queries, transactions, migrations]\n\n## External Service Integration\n[Pattern for integrating with third-party APIs/services]\n\n## Background Jobs\n[Pattern for async jobs, queues, scheduled tasks if relevant]\n```\n\n**Guidelines**:\n- Extract implementation patterns from PRD \"API Design\", \"Data Model\" sections\n- Provide step-by-step TDD workflow for each feature type\n- Include code examples showing the pattern\n- Reference project-specific libraries and frameworks\n\n#### 4. Quality Standards Rule\n\n**Location**: `.claude/rules/quality-standards.md`\n\n**Structure**:\n```markdown\n# Quality Standards\n\n> Code review criteria, performance baselines, security standards, and quality gates for [project name]. Enforces project quality requirements.\n\n## Code Review Checklist\n- [ ] All functions have tests (unit and/or integration)\n- [ ] Input validation on all external inputs\n- [ ] Error handling doesn't leak sensitive information\n- [ ] No hardcoded credentials or secrets\n- [ ] [Project-specific checklist items]\n\n## Performance Baselines\n[Specific performance targets from PRD]\n- [Metric 1]: [Target]\n- [Metric 2]: [Target]\n\n## Security Standards\n[Security requirements from PRD]\n- [Security requirement 1]\n- [Security requirement 2]\n\n## Code Style\n[Formatting, naming conventions, documentation standards]\n\n## Documentation Requirements\n[When and what to document]\n\n## Dependency Management\n[Versioning, security updates, license compliance]\n```\n\n**Guidelines**:\n- Extract performance baselines from PRD \"Performance Baselines\"\n- Extract security requirements from PRD \"Security Compliance\"\n- Extract quality criteria from PRD \"Success Criteria\"\n- Create specific, actionable checklist items\n\n### Step 3: Track Generated Rules in Manifest\n\nTrack which rules were generated from PRDs in `docs/blueprint/manifest.json`:\n\n```json\n{\n  \"generated\": {\n    \"rules\": [\n      \"architecture-patterns.md\",\n      \"testing-strategies.md\",\n      \"implementation-guides.md\",\n      \"quality-standards.md\"\n    ],\n    \"commands\": [...]\n  },\n  \"source_prds\": [...],\n  \"last_generated\": \"2026-01-09T...\"\n}\n```\n\nThis allows regeneration without losing track of what was auto-generated vs. manually created.\n\n## Command Generation Process\n\n### Step 1: Analyze Project Structure\n\nDetermine:\n- Project type (web app, CLI, library, etc.)\n- Programming language and framework\n- Test runner and commands\n- Build and development commands\n- Git workflow conventions\n\n### Step 2: Generate Workflow Commands\n\nCreate commands in `.claude/commands/` for project-specific workflows.\n\n#### 1. `/blueprint:init` Command\n\n**Location**: `.claude/commands/blueprint-init.md`\n\n**Purpose**: Initialize Blueprint Development structure in a project\n\n**Generated Content**:\n```markdown\n---\ndescription: \"Initialize Blueprint Development in this project\"\nallowed_tools: [Bash, Write]\n---\n\nInitialize Blueprint Development structure:\n\n1. Create `docs/blueprint/` directory\n2. Create `docs/prds/` for requirements\n3. Create `docs/blueprint/work-orders/` for task packages\n4. Create `docs/blueprint/work-orders/completed/` for completed work-orders\n5. Create placeholder `docs/blueprint/work-overview.md`\n6. Add `docs/blueprint/work-orders/` to `.gitignore` (optional - ask user)\n\nReport:\n- Directories created\n- Next steps: Write PRDs, then run `/blueprint:generate-rules`\n```\n\n#### 2. `/blueprint:generate-rules` Command\n\n**Location**: `.claude/commands/blueprint-generate-rules.md`\n\n**Purpose**: Generate project-specific behavioral rules from PRDs\n\n**Generated Content**:\n```markdown\n---\ndescription: \"Generate project-specific behavioral rules from PRDs in docs/prds/\"\nallowed_tools: [Read, Write, Glob]\n---\n\nGenerate project-specific rules:\n\n1. Read all PRD files in `docs/prds/`\n2. Analyze PRDs to extract:\n   - Architecture patterns and decisions\n   - Testing strategies and requirements\n   - Implementation guides and patterns\n   - Quality standards and baselines\n3. Generate four behavioral rules in `.claude/rules/`:\n   - `architecture-patterns.md`\n   - `testing-strategies.md`\n   - `implementation-guides.md`\n   - `quality-standards.md`\n4. Update manifest tracking in `docs/blueprint/manifest.json`\n\nReport:\n- Rules generated\n- Key patterns extracted\n- Next steps: Review rules, run `/project:continue` to start development\n```\n\n#### 3. `/blueprint:generate-commands` Command\n\n**Location**: `.claude/commands/blueprint-generate-commands.md`\n\n**Purpose**: Generate workflow commands from project structure\n\n**Generated Content**:\n```markdown\n---\ndescription: \"Generate workflow commands based on project structure and PRDs\"\nallowed_tools: [Read, Write, Bash, Glob]\n---\n\nGenerate workflow commands:\n\n1. Analyze project structure (package.json, Makefile, etc.)\n2. Detect test runner and commands\n3. Detect build and development commands\n4. Generate workflow commands:\n   - `/project:continue` - Resume development\n   - `/project:test-loop` - Run TDD cycle\n   - [Project-specific commands based on stack]\n\nReport:\n- Commands generated\n- Detected commands and tools\n- Next steps: Review rules, then use `/project:continue` to start work\n```\n\n#### 4. `/blueprint:work-order` Command\n\n**Location**: `.claude/commands/blueprint-work-order.md`\n\n**Purpose**: Generate isolated work-order for subagent execution with GitHub visibility\n\n**Flags**:\n- `--no-publish`: Create local work-order only, skip GitHub issue\n- `--from-issue N`: Create work-order from existing GitHub issue #N\n\n**Default behavior**: Creates BOTH local work-order AND GitHub issue with `work-order` label.\n\n**Generated Content**:\n```markdown\n---\ndescription: \"Create work-order with minimal context for isolated subagent execution\"\nargs: \"[--no-publish] [--from-issue N]\"\nallowed_tools: [Read, Write, Glob, Bash]\n---\n\nGenerate work-order:\n\n1. Analyze current project state:\n   - Read work-overview.md\n   - Check git status\n   - Read relevant PRDs\n2. Identify next logical work unit\n3. Determine minimal required context:\n   - Only files that need to be created/modified\n   - Only relevant code excerpts (not full files)\n   - Only relevant PRD sections\n4. Generate work-order document:\n   - Sequential number (find highest existing + 1)\n   - Clear objective\n   - Minimal context\n   - TDD requirements (tests specified)\n   - Implementation steps\n   - Success criteria\n   - GitHub Issue reference\n5. Save to `docs/blueprint/work-orders/NNN-task-name.md`\n6. Create GitHub issue (unless --no-publish):\n   - Title: \"Work-Order NNN: [Task Name]\"\n   - Label: `work-order`\n   - Body: Summary with link to local file\n7. Update work-order with issue number\n\nReport:\n- Work-order created\n- Work-order number and objective\n- GitHub issue number (if created)\n- Ready for subagent execution\n```\n\n**GitHub Integration Flow**:\n1. Work-order created  GitHub issue created (visibility)\n2. Work completed  PR created with `Fixes #N`\n3. PR merged  Issue auto-closes\n4. Work-order moved to `completed/`\n\n#### 5. `/project:continue` Command\n\n**Location**: `.claude/commands/project-continue.md`\n\n**Purpose**: Analyze state and resume development\n\n**Generated Content**:\n```markdown\n---\ndescription: \"Analyze project state and continue development where left off\"\nallowed_tools: [Read, Bash, Grep, Glob, Edit, Write]\n---\n\nContinue project development:\n\n1. Check current state:\n   - Run `git status` (branch, uncommitted changes)\n   - Run `git log -5 --oneline` (recent commits)\n2. Read context:\n   - All PRDs in `docs/prds/`\n   - `work-overview.md` (current phase and progress)\n   - Recent work-orders (completed and pending)\n3. Identify next task:\n   - Based on PRD requirements\n   - Based on work-overview progress\n   - Based on git status (resume if in progress)\n4. Begin work following TDD:\n   - Apply project-specific rules (architecture, testing, implementation, quality)\n   - Follow RED  GREEN  REFACTOR workflow\n   - Commit incrementally\n\nReport before starting:\n- Current project status summary\n- Next task identified\n- Approach and plan\n```\n\n#### 6. `/project:test-loop` Command\n\n**Location**: `.claude/commands/project-test-loop.md`\n\n**Purpose**: Run automated TDD cycle\n\n**Generated Content**:\n```markdown\n---\ndescription: \"Run test  fix  refactor loop with TDD workflow\"\nallowed_tools: [Read, Edit, Bash]\n---\n\nRun TDD cycle:\n\n1. Run test suite: [project-specific test command]\n2. If tests fail:\n   - Analyze failure output\n   - Identify root cause\n   - Make minimal fix to pass the test\n   - Re-run tests to confirm\n3. If tests pass:\n   - Check for refactoring opportunities\n   - Refactor while keeping tests green\n   - Re-run tests to confirm still passing\n4. Repeat until:\n   - All tests pass\n   - No obvious refactoring needed\n   - User intervention required\n\nReport:\n- Test results summary\n- Fixes applied\n- Refactorings performed\n- Current status (all pass / needs work / blocked)\n```\n\n### Step 3: Customize Commands for Project\n\nAdapt command templates based on:\n- **Programming language**: Adjust test commands, build commands\n- **Framework**: Include framework-specific patterns\n- **Project type**: CLI, web app, library have different workflows\n- **Team conventions**: Match existing git workflow, commit conventions\n\n## Rule Generation Guidelines\n\n### Extract, Don't Invent\n\n**DO**: Extract patterns, decisions, and requirements from PRDs\n**DON'T**: Invent patterns not specified in PRDs\n\nIf PRDs don't specify a pattern, ask user or use sensible defaults.\n\n### Be Specific, Not Generic\n\n**DON'T**: \"Write good code\"\n**DO**: \"Use constructor injection for services, following the pattern in `services/authService.js:15-20`\"\n\n**DON'T**: \"Test your code\"\n**DO**: \"All API endpoints must have integration tests with valid input, invalid input, and authorization test cases\"\n\n### Include Code Examples\n\nEvery pattern should include a code example showing:\n- What the pattern looks like in practice\n- File location reference\n- Line number reference (if applicable)\n\n### Document Rationale\n\nFor architecture and technical decisions, include:\n- Why this pattern was chosen\n- What alternatives were considered\n- What trade-offs were made\n- When to deviate from the pattern\n\n### Make Rules Clear and Actionable\n\nRules should be behavioral guidelines that Claude follows:\n- Use imperative language (\"Use...\", \"Follow...\", \"Ensure...\")\n- Be specific about when the rule applies\n- Include examples of correct behavior\n\n**Good rule content**: \"Use constructor injection for services. All service dependencies must be passed via constructor, not imported directly.\"\n\n**Bad rule content**: \"Dependency injection stuff\"\n\n### Keep Rules Focused\n\nEach rule file should have a single concern:\n- **Architecture patterns**: Structure and organization\n- **Testing strategies**: How to test\n- **Implementation guides**: How to implement features\n- **Quality standards**: What defines quality\n\nDon't mix concerns across rule files.\n\n## Command Generation Guidelines\n\n### Make Commands Autonomous\n\nCommands should:\n- Run without user input (except explicit prompts)\n- Read necessary context automatically\n- Report clearly what was done\n- Suggest next steps\n\n### Use Appropriate Tools\n\nSpecify `allowed_tools` in command frontmatter:\n- `/blueprint:init`: [Bash, Write]\n- `/blueprint:generate-rules`: [Read, Write, Glob]\n- `/project:continue`: [Read, Bash, Grep, Glob, Edit, Write]\n- `/project:test-loop`: [Read, Edit, Bash]\n\n### Provide Clear Output\n\nCommands should report:\n1. What was analyzed\n2. What was done\n3. What the results are\n4. What to do next\n\n### Handle Errors Gracefully\n\nCommands should detect common issues:\n- Missing files or directories\n- No PRDs found\n- Invalid project structure\n- Test command not found\n\nReport errors clearly and suggest fixes.\n\n## Testing Generated Rules and Commands\n\nAfter generating rules and commands:\n\n### 1. Verify Rules Are Applied\n\nTest that Claude applies rules in relevant contexts:\n- When discussing architecture  architecture-patterns rule should guide behavior\n- When writing tests  testing-strategies rule should guide behavior\n- When implementing features  implementation-guides rule should guide behavior\n- When reviewing code  quality-standards rule should guide behavior\n\n### 2. Verify Commands Work\n\nTest each command:\n```bash\n/blueprint:init              # Should create directory structure\n/blueprint:generate-rules    # Should create four rules in .claude/rules/\n/blueprint:generate-commands # Should create workflow commands\n/project:continue            # Should analyze state and resume work\n/blueprint:work-order        # Should create work-order document\n/project:test-loop           # Should run tests and report\n```\n\n### 3. Verify Rules Guide Correctly\n\nManually check that:\n- Architecture patterns match PRD technical decisions\n- Testing strategies match PRD TDD requirements\n- Implementation guides match PRD API/feature designs\n- Quality standards match PRD success criteria\n\n### 4. Refine as Needed\n\nDuring initial project development:\n- Rules may need refinement as patterns emerge\n- Commands may need adjustment based on actual workflow\n- Update rules and commands iteratively\n\n## Examples\n\nSee `.claude/docs/blueprint-development/` for complete workflow documentation and examples.\n\n## Integration with Blueprint Development\n\nThis skill enables the core Blueprint Development workflow:\n\n**PRDs** (requirements)  **Rules** (behavioral guidelines)  **Commands** (workflow automation)  **Work-orders** (isolated tasks)\n\nBy generating project-specific rules and commands from PRDs, Blueprint Development creates a self-documenting, AI-native development environment where behavioral guidelines, patterns, and quality standards are first-class citizens.\n\n## GitHub Work Order Integration\n\nWork orders can be linked to GitHub issues for transparency and cooperative development.\n\n### Why GitHub Integration?\n\n| Benefit | Description |\n|---------|-------------|\n| **Transparency** | Team members see work in progress via GitHub issues |\n| **Collaboration** | Comments, mentions, and discussions on issues |\n| **Traceability** | Commits and PRs link to issues automatically |\n| **Project management** | Issues integrate with GitHub Projects, milestones |\n\n### Workflow Modes\n\n**Default (GitHub-first)**:\n```bash\n/blueprint:work-order\n# Creates local markdown + GitHub issue\n# Issue has `work-order` label\n# Work-order links to issue number\n```\n\n**Local-only (offline/private)**:\n```bash\n/blueprint:work-order --no-publish\n# Creates local markdown only\n# Can publish later manually\n```\n\n**From existing issue**:\n```bash\n/blueprint:work-order --from-issue 123\n# Fetches issue #123\n# Creates local work-order with context\n# Updates issue with work-order link\n```\n\n### Label Setup\n\nCreate the `work-order` label in repositories using this methodology:\n```bash\ngh label create work-order --description \"AI-assisted work order\" --color \"0E8A16\"\n```\n\n### Completion Workflow\n\n1. **Execute work-order** following TDD workflow\n2. **Create PR** with `Fixes #N` in title/body (where N = issue number)\n3. **Merge PR**  Issue auto-closes\n4. **Move work-order** to `completed/` directory\n\n### Work Order File Format\n\n```markdown\n# Work-Order 003: [Task Name]\n\n**GitHub Issue**: #42\n**Status**: pending | in-progress | completed\n\n## Objective\n[One sentence]\n\n## Context\n[Minimal context for isolated execution]\n\n## TDD Requirements\n[Specific tests]\n\n## Success Criteria\n[Checkboxes]\n```\n\n### When to Use Each Mode\n\n| Scenario | Mode |\n|----------|------|\n| Team project, need visibility | Default (creates issue) |\n| Solo exploration, quick prototype | `--no-publish` |\n| Issue already exists from discussion | `--from-issue N` |\n| Offline development | `--no-publish` |"
              },
              {
                "name": "confidence-scoring",
                "description": "Assess quality of PRPs and work-orders using systematic confidence scoring. Use when evaluating readiness for execution or subagent delegation.",
                "path": "blueprint-plugin/skills/confidence-scoring/SKILL.md",
                "frontmatter": {
                  "created": "2025-12-16T00:00:00.000Z",
                  "modified": "2025-12-16T00:00:00.000Z",
                  "reviewed": "2025-12-16T00:00:00.000Z",
                  "name": "confidence-scoring",
                  "description": "Assess quality of PRPs and work-orders using systematic confidence scoring. Use when evaluating readiness for execution or subagent delegation."
                },
                "content": "# Confidence Scoring for PRPs and Work-Orders\n\nThis skill provides systematic evaluation of PRPs (Product Requirement Prompts) and work-orders to determine their readiness for execution or delegation.\n\n## When to Use This Skill\n\nActivate this skill when:\n- Creating a new PRP (`/prp:create`)\n- Generating a work-order (`/blueprint:work-order`)\n- Deciding whether to execute or refine a PRP\n- Evaluating whether a task is ready for subagent delegation\n- Reviewing PRPs/work-orders for quality\n\n## Scoring Dimensions\n\n### 1. Context Completeness (1-10)\n\nEvaluates whether all necessary context is explicitly provided.\n\n| Score | Criteria |\n|-------|----------|\n| **10** | All file paths explicit with line numbers, all code snippets included, library versions specified, integration points documented |\n| **8-9** | Most context provided, minor gaps that can be inferred from codebase |\n| **6-7** | Key context present but some discovery required |\n| **4-5** | Significant context missing, will need exploration |\n| **1-3** | Minimal context, extensive discovery needed |\n\n**Checklist**:\n- [ ] File paths are absolute or clearly relative to project root\n- [ ] Code snippets include actual line numbers (e.g., `src/auth.py:45-60`)\n- [ ] Library versions are specified\n- [ ] Integration points are documented\n- [ ] Patterns from codebase are shown with examples\n\n### 2. Implementation Clarity (1-10)\n\nEvaluates how clear the implementation approach is.\n\n| Score | Criteria |\n|-------|----------|\n| **10** | Pseudocode covers all cases, step-by-step clear, edge cases addressed |\n| **8-9** | Main path clear, most edge cases covered |\n| **6-7** | Implementation approach clear, some details need discovery |\n| **4-5** | High-level only, significant ambiguity |\n| **1-3** | Vague requirements, unclear approach |\n\n**Checklist**:\n- [ ] Task breakdown is explicit\n- [ ] Pseudocode is provided for complex logic\n- [ ] Implementation order is specified\n- [ ] Edge cases are identified\n- [ ] Error handling approach is documented\n\n### 3. Gotchas Documented (1-10)\n\nEvaluates whether known pitfalls are documented with mitigations.\n\n| Score | Criteria |\n|-------|----------|\n| **10** | All known pitfalls documented, each has mitigation, library-specific issues covered |\n| **8-9** | Major gotchas covered, mitigations clear |\n| **6-7** | Some gotchas documented, may discover more |\n| **4-5** | Few gotchas mentioned, incomplete coverage |\n| **1-3** | No gotchas documented |\n\n**Checklist**:\n- [ ] Library-specific gotchas documented\n- [ ] Version-specific behaviors noted\n- [ ] Common mistakes identified\n- [ ] Each gotcha has a mitigation\n- [ ] Race conditions/concurrency issues addressed\n\n### 4. Validation Coverage (1-10)\n\nEvaluates whether executable validation commands are provided.\n\n| Score | Criteria |\n|-------|----------|\n| **10** | All quality gates have executable commands, expected outcomes specified |\n| **8-9** | Main validation commands present, most outcomes specified |\n| **6-7** | Some validation commands, gaps in coverage |\n| **4-5** | Minimal validation commands |\n| **1-3** | No executable validation |\n\n**Checklist**:\n- [ ] Linting command provided and executable\n- [ ] Type checking command provided (if applicable)\n- [ ] Unit test command with specific test files\n- [ ] Integration test command (if applicable)\n- [ ] Coverage check command with threshold\n- [ ] Security scan command (if applicable)\n- [ ] All commands include expected outcomes\n\n### 5. Test Coverage (1-10) - Work-Orders Only\n\nEvaluates whether test cases are specified.\n\n| Score | Criteria |\n|-------|----------|\n| **10** | All test cases specified with assertions, edge cases covered |\n| **8-9** | Main test cases specified, most assertions included |\n| **6-7** | Key test cases present, some gaps |\n| **4-5** | Few test cases, minimal detail |\n| **1-3** | No test cases specified |\n\n**Checklist**:\n- [ ] Each test case has code template\n- [ ] Assertions are explicit\n- [ ] Happy path tested\n- [ ] Error cases tested\n- [ ] Edge cases tested\n\n## Calculating Overall Score\n\n### For PRPs\n```\nOverall = (Context + Implementation + Gotchas + Validation) / 4\n```\n\n### For Work-Orders\n```\nOverall = (Context + Gotchas + TestCoverage + Validation) / 4\n```\n\n## Score Thresholds\n\n| Score | Readiness | Recommendation |\n|-------|-----------|----------------|\n| **9-10** | Excellent | Ready for autonomous subagent execution |\n| **7-8** | Good | Ready for execution with some discovery |\n| **5-6** | Fair | Needs refinement before execution |\n| **3-4** | Poor | Significant gaps, recommend research phase |\n| **1-2** | Inadequate | Restart with proper research |\n\n## Response Templates\n\n### High Confidence (7+)\n\n```markdown\n## Confidence Score: X.X/10\n\n| Dimension | Score | Notes |\n|-----------|-------|-------|\n| Context Completeness | X/10 | [specific observation] |\n| Implementation Clarity | X/10 | [specific observation] |\n| Gotchas Documented | X/10 | [specific observation] |\n| Validation Coverage | X/10 | [specific observation] |\n| **Overall** | **X.X/10** | |\n\n**Assessment:** Ready for execution\n\n**Strengths:**\n- [Key strength 1]\n- [Key strength 2]\n\n**Recommendations (optional):**\n- [Minor improvement 1]\n```\n\n### Low Confidence (<7)\n\n```markdown\n## Confidence Score: X.X/10\n\n| Dimension | Score | Notes |\n|-----------|-------|-------|\n| Context Completeness | X/10 | [specific gap] |\n| Implementation Clarity | X/10 | [specific gap] |\n| Gotchas Documented | X/10 | [specific gap] |\n| Validation Coverage | X/10 | [specific gap] |\n| **Overall** | **X.X/10** | |\n\n**Assessment:** Needs refinement before execution\n\n**Gaps to Address:**\n- [ ] [Gap 1 with suggested action]\n- [ ] [Gap 2 with suggested action]\n- [ ] [Gap 3 with suggested action]\n\n**Next Steps:**\n1. [Specific research action]\n2. [Specific documentation action]\n3. [Specific validation action]\n```\n\n## Examples\n\n### Example 1: Well-Prepared PRP\n\n```markdown\n## Confidence Score: 8.5/10\n\n| Dimension | Score | Notes |\n|-----------|-------|-------|\n| Context Completeness | 9/10 | All files explicit, code snippets with line refs |\n| Implementation Clarity | 8/10 | Pseudocode covers main path, one edge case unclear |\n| Gotchas Documented | 8/10 | Redis connection pool, JWT format issues covered |\n| Validation Coverage | 9/10 | All gates have commands, outcomes specified |\n| **Overall** | **8.5/10** | |\n\n**Assessment:** Ready for execution\n\n**Strengths:**\n- Comprehensive codebase intelligence with actual code snippets\n- Validation gates are copy-pasteable\n- Known library gotchas well-documented\n\n**Recommendations:**\n- Consider documenting concurrent token refresh edge case\n```\n\n### Example 2: Needs Work\n\n```markdown\n## Confidence Score: 5.0/10\n\n| Dimension | Score | Notes |\n|-----------|-------|-------|\n| Context Completeness | 4/10 | File paths vague (\"somewhere in auth/\") |\n| Implementation Clarity | 6/10 | High-level approach clear, no pseudocode |\n| Gotchas Documented | 3/10 | No library-specific gotchas |\n| Validation Coverage | 7/10 | Test command present, missing lint/type check |\n| **Overall** | **5.0/10** | |\n\n**Assessment:** Needs refinement before execution\n\n**Gaps to Address:**\n- [ ] Add explicit file paths (use `grep` to find them)\n- [ ] Add pseudocode for token generation logic\n- [ ] Research jsonwebtoken gotchas (check GitHub issues)\n- [ ] Add linting and type checking commands\n\n**Next Steps:**\n1. Run `/prp:curate-docs jsonwebtoken` to create ai_docs entry\n2. Use Explore agent to find exact file locations\n3. Add validation gate commands from project's package.json\n```\n\n## Integration with Blueprint Development\n\nThis skill is automatically applied when:\n- `/prp:create` generates a new PRP\n- `/blueprint:work-order` generates a work-order\n- Reviewing existing PRPs for execution readiness\n\nThe confidence score determines:\n- **9+**: Proceed with subagent delegation\n- **7-8**: Proceed with direct execution\n- **< 7**: Refine before execution\n\n## Tips for Improving Scores\n\n### Context Completeness\n- Use `grep` to find exact file locations\n- Include actual line numbers in code snippets\n- Reference ai_docs entries for library patterns\n\n### Implementation Clarity\n- Write pseudocode before describing approach\n- Enumerate edge cases explicitly\n- Define error handling strategy\n\n### Gotchas Documented\n- Search GitHub issues for library gotchas\n- Check Stack Overflow for common problems\n- Document team experience from past projects\n\n### Validation Coverage\n- Copy commands from project's config (package.json, pyproject.toml)\n- Include specific file paths in test commands\n- Specify expected outcomes for each gate"
              },
              {
                "name": "feature-tracking",
                "description": "Track feature implementation status against requirements documents. Provides hierarchical FR code tracking, phase management, and sync with work-overview.md and TODO.md.",
                "path": "blueprint-plugin/skills/feature-tracking/SKILL.md",
                "frontmatter": {
                  "created": "2026-01-02T00:00:00.000Z",
                  "modified": "2026-01-09T00:00:00.000Z",
                  "reviewed": "2026-01-02T00:00:00.000Z",
                  "name": "feature-tracking",
                  "description": "Track feature implementation status against requirements documents. Provides hierarchical FR code tracking, phase management, and sync with work-overview.md and TODO.md."
                },
                "content": "# Feature Tracking Skill\n\nTrack feature implementation status against requirements documents using hierarchical FR codes.\n\n## Overview\n\nThe feature tracker maintains a JSON file that maps requirements from a source document (e.g., REQUIREMENTS.md) to implementation status. It supports:\n\n- **Hierarchical FR codes**: FR1, FR2.1, FR2.1.1, etc.\n- **Phase-based development**: Group features by development phase\n- **PRD integration**: Link features to Product Requirements Documents\n- **Sync targets**: Keep work-overview.md and TODO.md in sync\n\n## When to Use\n\nRun feature tracking operations when:\n- Feature implementation status changes\n- New PRD is added or completed\n- After major development milestones\n- Before generating status reports\n- Starting a new development phase\n\n## Core Concepts\n\n### Feature Status\n\nEach feature has one of five statuses:\n- `complete`: Implementation files exist, tests pass, TODO item checked\n- `partial`: Some implementation exists, not all sub-features done\n- `in_progress`: Active work, files modified recently\n- `not_started`: No implementation files, TODO unchecked\n- `blocked`: Missing dependencies or explicitly marked\n\n### Hierarchical Structure\n\nFeatures are organized hierarchically:\n```\nFR1 (Game Setup & Configuration)\n FR1.1 (Window Configuration)\n FR1.2 (Game Mode Selection)\n    FR1.2.1 (Versus Mode)\n    FR1.2.2 (Cooperative Mode)\n FR1.3 (Scenario Setup)\n```\n\n### Phase Organization\n\nFeatures are grouped by development phase:\n- `phase-0`: Foundation\n- `phase-1`: Core gameplay\n- `phase-2`: Advanced features\n- etc.\n\n## File Structure\n\n```\ndocs/blueprint/\n feature-tracker.json       # Main tracker file\n work-overview.md           # Sync target: progress overview\n schemas/                   # Optional: local schema copy\n     feature-tracker.schema.json\n```\n\nThe project's `TODO.md` is also a sync target.\n\n## Quick Commands\n\n### View completion stats\n```bash\njq '.statistics' docs/blueprint/feature-tracker.json\n```\n\n### List incomplete features\n```bash\njq -r '.. | objects | select(.status == \"not_started\") | .name' docs/blueprint/feature-tracker.json\n```\n\n### Show PRD completion\n```bash\njq '.prds | to_entries | .[] | \"\\(.key): \\(.value.status)\"' docs/blueprint/feature-tracker.json\n```\n\n### List features by phase\n```bash\njq -r '.. | objects | select(.phase == \"phase-1\") | .name' docs/blueprint/feature-tracker.json\n```\n\n### Count features by status\n```bash\njq '[.. | objects | select(.status?) | .status] | group_by(.) | map({(.[0]): length}) | add' docs/blueprint/feature-tracker.json\n```\n\n## Schema\n\nThe feature tracker uses a JSON Schema for validation. The schema is bundled with the blueprint-plugin at:\n```\nschemas/feature-tracker.schema.json\n```\n\nKey schema features:\n- Strict FR code validation: `^FR\\d+(\\.\\d+)*$`\n- Phase pattern validation: `^phase-\\d+$`\n- Recursive feature definitions for nesting\n- PRD naming pattern: `^PRD_[A-Z_]+$`\n\n### Validate tracker\n```bash\n# Using ajv-cli or similar JSON schema validator\najv validate -s schemas/feature-tracker.schema.json \\\n             -d docs/blueprint/feature-tracker.json\n```\n\n## Integration Points\n\n### Manifest Integration\n\nThe `manifest.json` references the feature tracker:\n```json\n{\n  \"structure\": {\n    \"has_feature_tracker\": true\n  },\n  \"feature_tracker\": {\n    \"file\": \"feature-tracker.json\",\n    \"source_document\": \"REQUIREMENTS.md\",\n    \"sync_targets\": [\"work-overview.md\", \"TODO.md\"]\n  }\n}\n```\n\n### PRD Mapping\n\nFeatures link to PRDs via the `prd` field:\n```json\n{\n  \"name\": \"Terrain Visual Enhancement\",\n  \"status\": \"complete\",\n  \"prd\": \"PRD_TERRAIN_VISUAL_ENHANCEMENT\"\n}\n```\n\nPRDs track which features they implement:\n```json\n{\n  \"PRD_TERRAIN_VISUAL_ENHANCEMENT\": {\n    \"name\": \"Terrain Visual Enhancement\",\n    \"status\": \"complete\",\n    \"features_implemented\": [\"FR2.8.1\", \"FR2.8.2\", \"FR2.8.3\"],\n    \"tests_passing\": 107\n  }\n}\n```\n\n### Work Order Integration\n\nWork orders can reference specific FR codes. When a work order is completed, update the corresponding feature status in the tracker.\n\n## Sync Process\n\nThe sync process ensures consistency between:\n1. `feature-tracker.json` (source of truth)\n2. `work-overview.md` (human-readable summary)\n3. `TODO.md` (checkbox-based task list)\n\n### Sync Steps\n\n1. **Load current state** from feature-tracker.json\n2. **Compare** with work-overview.md and TODO.md\n3. **Verify** implementation status for each feature\n4. **Recalculate** statistics\n5. **Update** sync targets with changes\n6. **Report** what was synchronized\n\n### Status Verification\n\nFor each feature, verify:\n- `complete`: Files exist, tests pass (if applicable), TODO checked\n- `partial`: Some files exist, not all sub-features complete\n- `in_progress`: Recent commits touch feature files\n- `not_started`: No implementation evidence\n- `blocked`: Documented dependency issues\n\n## Commands\n\nRelated blueprint commands:\n- `/blueprint-feature-tracker-status`: Display statistics and completion summary\n- `/blueprint-feature-tracker-sync`: Synchronize tracker with sync targets\n\n## Example: Updating Feature Status\n\nWhen completing a feature:\n\n1. Update feature status in `feature-tracker.json`:\n   ```json\n   {\n     \"name\": \"Unit Selection\",\n     \"status\": \"complete\",\n     \"phase\": \"phase-2\",\n     \"implementation\": {\n       \"files\": [\"src/systems/selection.rs\"],\n       \"notes\": \"Box selection and click selection\",\n       \"tests\": [\"tests/selection_tests.rs\"]\n     }\n   }\n   ```\n\n2. Run `/blueprint-feature-tracker-sync` to update:\n   - work-overview.md \"Completed\" section\n   - TODO.md checkboxes\n   - Statistics recalculation\n\n3. Commit all changes together for consistency\n\n## Statistics\n\nThe tracker maintains aggregate statistics:\n```json\n{\n  \"statistics\": {\n    \"total_features\": 42,\n    \"complete\": 22,\n    \"partial\": 4,\n    \"in_progress\": 2,\n    \"not_started\": 14,\n    \"blocked\": 0,\n    \"completion_percentage\": 52.4\n  }\n}\n```\n\nThese are recalculated during sync operations."
              }
            ]
          },
          {
            "name": "configure-plugin",
            "description": "FVH infrastructure standards - pre-commit, CI/CD, Docker, testing configuration",
            "source": "./configure-plugin",
            "category": "infrastructure",
            "version": "1.1.1",
            "author": null,
            "install_commands": [
              "/plugin marketplace add laurigates/claude-plugins",
              "/plugin install configure-plugin@lgates-claude-plugins"
            ],
            "signals": {
              "stars": 1,
              "forks": 0,
              "pushed_at": "2026-01-12T12:05:51Z",
              "created_at": "2025-12-16T11:24:04Z",
              "license": null
            },
            "commands": [],
            "skills": [
              {
                "name": "fvh-ci-workflows",
                "description": "FVH (Forum Virium Helsinki) GitHub Actions workflow standards. Use when configuring\nCI/CD workflows, checking workflow compliance, or when the user mentions FVH workflows,\nGitHub Actions, container builds, or CI/CD automation.\n",
                "path": "configure-plugin/skills/fvh-ci-workflows/SKILL.md",
                "frontmatter": {
                  "created": "2025-12-16T00:00:00.000Z",
                  "modified": "2025-12-16T00:00:00.000Z",
                  "reviewed": "2025-12-16T00:00:00.000Z",
                  "name": "fvh-ci-workflows",
                  "description": "FVH (Forum Virium Helsinki) GitHub Actions workflow standards. Use when configuring\nCI/CD workflows, checking workflow compliance, or when the user mentions FVH workflows,\nGitHub Actions, container builds, or CI/CD automation.\n"
                },
                "content": "# FVH CI Workflow Standards\n\n## Version: 2025.1\n\nFVH standard GitHub Actions workflows for CI/CD automation.\n\n## Required Workflows\n\n### 1. Container Build Workflow\n\n**File**: `.github/workflows/container-build.yml`\n\nMulti-platform container build with GHCR publishing:\n\n```yaml\nname: Build Container\n\non:\n  push:\n    branches: [main]\n  pull_request:\n    branches: [main]\n  release:\n    types: [published]\n\nenv:\n  REGISTRY: ghcr.io\n  IMAGE_NAME: ${{ github.repository }}\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n    permissions:\n      contents: read\n      packages: write\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Set up Docker Buildx\n        uses: docker/setup-buildx-action@v3\n\n      - name: Log in to Container Registry\n        if: github.event_name != 'pull_request'\n        uses: docker/login-action@v3\n        with:\n          registry: ${{ env.REGISTRY }}\n          username: ${{ github.actor }}\n          password: ${{ secrets.GITHUB_TOKEN }}\n\n      - name: Extract metadata\n        id: meta\n        uses: docker/metadata-action@v5\n        with:\n          images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}\n          tags: |\n            type=ref,event=branch\n            type=ref,event=pr\n            type=semver,pattern={{version}}\n            type=semver,pattern={{major}}.{{minor}}\n\n      - name: Build and push\n        uses: docker/build-push-action@v6\n        with:\n          context: .\n          platforms: linux/amd64,linux/arm64\n          push: ${{ github.event_name != 'pull_request' }}\n          tags: ${{ steps.meta.outputs.tags }}\n          labels: ${{ steps.meta.outputs.labels }}\n          cache-from: type=gha\n          cache-to: type=gha,mode=max\n          build-args: |\n            SENTRY_AUTH_TOKEN=${{ secrets.SENTRY_AUTH_TOKEN }}\n```\n\n**Key features:**\n- Multi-platform builds (amd64, arm64)\n- GitHub Container Registry (GHCR)\n- Semantic version tagging\n- Build caching with GitHub Actions cache\n- Sentry integration for source maps\n\n### 2. Release Please Workflow\n\n**File**: `.github/workflows/release-please.yml`\n\nSee `fvh-release-please` skill for details.\n\n### 3. Test Workflow (Recommended)\n\n**File**: `.github/workflows/test.yml`\n\n```yaml\nname: Tests\n\non:\n  push:\n    branches: [main]\n  pull_request:\n    branches: [main]\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Setup Node.js\n        uses: actions/setup-node@v4\n        with:\n          node-version: '22'\n          cache: 'npm'\n\n      - name: Install dependencies\n        run: npm ci\n\n      - name: Run linter\n        run: npm run lint\n\n      - name: Run type check\n        run: npm run typecheck\n\n      - name: Run tests\n        run: npm run test:coverage\n\n      - name: Upload coverage\n        uses: codecov/codecov-action@v4\n        with:\n          files: ./coverage/lcov.info\n```\n\n## Workflow Standards\n\n### Action Versions\n\n| Action | Version | Purpose |\n|--------|---------|---------|\n| actions/checkout | v4 | Repository checkout |\n| docker/setup-buildx-action | v3 | Multi-platform builds |\n| docker/login-action | v3 | Registry authentication |\n| docker/metadata-action | v5 | Image tagging |\n| docker/build-push-action | v6 | Container build/push |\n| actions/setup-node | v4 | Node.js setup |\n| googleapis/release-please-action | v4 | Release automation |\n\n### Permissions\n\nMinimal permissions required:\n\n```yaml\npermissions:\n  contents: read      # Default for most jobs\n  packages: write     # For container push to GHCR\n  pull-requests: write  # For release-please PR creation\n```\n\n### Triggers\n\nStandard trigger patterns:\n\n```yaml\n# Build on push and PR to main\non:\n  push:\n    branches: [main]\n  pull_request:\n    branches: [main]\n\n# Also build on release\non:\n  release:\n    types: [published]\n```\n\n### Build Caching\n\nUse GitHub Actions cache for Docker layers:\n\n```yaml\ncache-from: type=gha\ncache-to: type=gha,mode=max\n```\n\n### Multi-Platform Builds\n\nBuild for both amd64 and arm64:\n\n```yaml\nplatforms: linux/amd64,linux/arm64\n```\n\n## Compliance Requirements\n\n### Required Workflows\n\n| Workflow | Purpose | Required |\n|----------|---------|----------|\n| container-build | Container builds | Yes (if Dockerfile) |\n| release-please | Automated releases | Yes |\n| test | Testing and linting | Recommended |\n\n### Required Elements\n\n| Element | Requirement |\n|---------|-------------|\n| checkout action | v4 |\n| build-push action | v6 |\n| Multi-platform | amd64 + arm64 |\n| Caching | GHA cache enabled |\n| Permissions | Explicit and minimal |\n\n## Status Levels\n\n| Status | Condition |\n|--------|-----------|\n| PASS | All required workflows present with compliant config |\n| WARN | Workflows present but using older action versions |\n| FAIL | Missing required workflows |\n| SKIP | Not applicable (no Dockerfile = no container-build) |\n\n## Secrets Required\n\n| Secret | Purpose | Required |\n|--------|---------|----------|\n| GITHUB_TOKEN | Container registry auth | Auto-provided |\n| SENTRY_AUTH_TOKEN | Source map upload | If using Sentry |\n| MY_RELEASE_PLEASE_TOKEN | Release PR creation | For release-please |\n\n## Troubleshooting\n\n### Build Failing\n\n- Check Dockerfile syntax\n- Verify build args are passed correctly\n- Check cache invalidation issues\n\n### Multi-Platform Issues\n\n- Ensure Dockerfile is platform-agnostic\n- Use official multi-arch base images\n- Avoid architecture-specific binaries\n\n### Cache Not Working\n\n- Verify `cache-from` and `cache-to` are set\n- Check GitHub Actions cache limits (10GB)\n- Consider registry-based caching for large images"
              },
              {
                "name": "fvh-pre-commit",
                "description": "FVH (Forum Virium Helsinki) pre-commit hook standards and configuration. Use when\nconfiguring pre-commit hooks in FVH repositories, checking hook compliance, or when\nthe user mentions FVH pre-commit, conventional commits, or hook configuration.\n",
                "path": "configure-plugin/skills/fvh-pre-commit/SKILL.md",
                "frontmatter": {
                  "created": "2025-12-16T00:00:00.000Z",
                  "modified": "2025-12-16T00:00:00.000Z",
                  "reviewed": "2025-12-16T00:00:00.000Z",
                  "name": "fvh-pre-commit",
                  "description": "FVH (Forum Virium Helsinki) pre-commit hook standards and configuration. Use when\nconfiguring pre-commit hooks in FVH repositories, checking hook compliance, or when\nthe user mentions FVH pre-commit, conventional commits, or hook configuration.\n"
                },
                "content": "# FVH Pre-commit Standards\n\n## Version: 2025.1\n\nFVH standard pre-commit configuration for repository compliance.\n\n## Standard Versions (2025.1)\n\n| Hook | Version | Purpose |\n|------|---------|---------|\n| pre-commit-hooks | v5.0.0 | Core hooks (trailing-whitespace, check-yaml, etc.) |\n| conventional-pre-commit | v4.3.0 | Conventional commit message validation |\n| biome | v0.4.0 | Code formatting and linting (JS, TS, JSON) |\n| gruntwork pre-commit | v0.1.29 | helmlint, tflint (infrastructure only) |\n| actionlint | v1.7.7 | GitHub Actions validation (infrastructure only) |\n| helm-docs | v1.14.2 | Helm documentation (infrastructure only) |\n| detect-secrets | v1.5.0 | Secret scanning (recommended) |\n\n## Project Type Configurations\n\n### Frontend App (Vue/React)\n\nRequired hooks for frontend applications:\n\n```yaml\ndefault_install_hook_types:\n  - pre-commit\n  - commit-msg\n\nrepos:\n  - repo: https://github.com/pre-commit/pre-commit-hooks\n    rev: v5.0.0\n    hooks:\n      - id: trailing-whitespace\n      - id: end-of-file-fixer\n      - id: check-yaml\n        exclude: ^(helm/templates/|skaffold/|k8s/).*\\.ya?ml$\n      - id: check-json\n        exclude: tsconfig\\.json$\n      - id: check-added-large-files\n        args: ['--maxkb=1000']\n      - id: check-merge-conflict\n      - id: detect-private-key\n\n  - repo: https://github.com/compilerla/conventional-pre-commit\n    rev: v4.3.0\n    hooks:\n      - id: conventional-pre-commit\n        stages: [commit-msg]\n\n  - repo: https://github.com/biomejs/pre-commit\n    rev: v0.4.0\n    hooks:\n      - id: biome-check\n        additional_dependencies: [\"@biomejs/biome@1.9.4\"]\n\n  # Optional: If project has Helm charts\n  - repo: https://github.com/gruntwork-io/pre-commit\n    rev: v0.1.29\n    hooks:\n      - id: helmlint\n        files: ^helm/\n```\n\n### Infrastructure Repository\n\nRequired hooks for infrastructure (Terraform, Helm, ArgoCD):\n\n```yaml\ndefault_install_hook_types:\n  - pre-commit\n  - commit-msg\n\nrepos:\n  - repo: https://github.com/pre-commit/pre-commit-hooks\n    rev: v5.0.0\n    hooks:\n      - id: trailing-whitespace\n      - id: end-of-file-fixer\n      - id: check-yaml\n        args: [--allow-multiple-documents]\n        exclude: argocd/.*templates/|helm/[^/]+/templates/\n      - id: check-json\n      - id: check-merge-conflict\n      - id: check-symlinks\n      - id: check-toml\n      - id: check-added-large-files\n\n  - repo: https://github.com/compilerla/conventional-pre-commit\n    rev: v4.3.0\n    hooks:\n      - id: conventional-pre-commit\n        stages: [commit-msg]\n\n  - repo: https://github.com/gruntwork-io/pre-commit\n    rev: v0.1.29\n    hooks:\n      - id: tflint\n      - id: helmlint\n\n  - repo: https://github.com/rhysd/actionlint\n    rev: v1.7.7\n    hooks:\n      - id: actionlint\n\n  - repo: https://github.com/norwoodj/helm-docs\n    rev: v1.14.2\n    hooks:\n      - id: helm-docs\n        args:\n          - --chart-search-root=helm\n\n  - repo: https://github.com/Yelp/detect-secrets\n    rev: v1.5.0\n    hooks:\n      - id: detect-secrets\n        args: ['--baseline', '.secrets.baseline']\n```\n\n### Python Service\n\nRequired hooks for Python projects:\n\n```yaml\ndefault_install_hook_types:\n  - pre-commit\n  - commit-msg\n\nrepos:\n  - repo: https://github.com/pre-commit/pre-commit-hooks\n    rev: v5.0.0\n    hooks:\n      - id: trailing-whitespace\n      - id: end-of-file-fixer\n      - id: check-yaml\n      - id: check-json\n      - id: check-toml\n      - id: check-added-large-files\n      - id: check-merge-conflict\n      - id: detect-private-key\n\n  - repo: https://github.com/compilerla/conventional-pre-commit\n    rev: v4.3.0\n    hooks:\n      - id: conventional-pre-commit\n        stages: [commit-msg]\n\n  - repo: https://github.com/astral-sh/ruff-pre-commit\n    rev: v0.8.4\n    hooks:\n      - id: ruff\n        args: [--fix]\n      - id: ruff-format\n\n  - repo: https://github.com/Yelp/detect-secrets\n    rev: v1.5.0\n    hooks:\n      - id: detect-secrets\n        args: ['--baseline', '.secrets.baseline']\n```\n\n## Compliance Checking\n\n### Required Base Hooks (All Projects)\n\nEvery FVH repository MUST have these hooks:\n\n1. **pre-commit-hooks** (v5.0.0+)\n   - `trailing-whitespace`\n   - `end-of-file-fixer`\n   - `check-yaml`\n   - `check-json`\n   - `check-merge-conflict`\n   - `check-added-large-files`\n\n2. **conventional-pre-commit** (v4.3.0+)\n   - `conventional-pre-commit` in `commit-msg` stage\n\n### Status Levels\n\n| Status | Meaning |\n|--------|---------|\n| PASS | Hook present with compliant version |\n| WARN | Hook present but version outdated |\n| FAIL | Required hook missing |\n| SKIP | Hook not applicable for project type |\n\n### Version Comparison\n\nWhen checking versions:\n- Exact match or newer: PASS\n- Older by patch version: WARN (functional but should update)\n- Missing entirely: FAIL (must add)\n\n## Exclusion Patterns\n\n### Frontend Apps\n\nExclude Kubernetes/Helm templates from YAML/prettier checks:\n\n```yaml\nexclude: ^(helm/templates/|skaffold/|k8s/).*\\.ya?ml$\n```\n\n### Infrastructure\n\nExclude ArgoCD and Helm templates:\n\n```yaml\nexclude: argocd/.*templates/|helm/[^/]+/templates/\n```\n\n### Python\n\nNo special exclusions needed for standard Python projects.\n\n## Installation\n\nAfter configuring `.pre-commit-config.yaml`:\n\n```bash\npre-commit install\npre-commit install --hook-type commit-msg\n```\n\nOr simply:\n\n```bash\npre-commit install --install-hooks\n```\n\n## Updating\n\nTo update all hooks to latest versions:\n\n```bash\npre-commit autoupdate\n```\n\nThen verify versions match FVH standards."
              },
              {
                "name": "fvh-release-please",
                "description": "FVH (Forum Virium Helsinki) release-please standards and configuration. Use when\nconfiguring release-please workflows, checking release automation compliance, or\nwhen the user mentions FVH release-please, automated releases, or version management.\n",
                "path": "configure-plugin/skills/fvh-release-please/SKILL.md",
                "frontmatter": {
                  "created": "2025-12-16T00:00:00.000Z",
                  "modified": "2025-12-16T00:00:00.000Z",
                  "reviewed": "2025-12-16T00:00:00.000Z",
                  "name": "fvh-release-please",
                  "description": "FVH (Forum Virium Helsinki) release-please standards and configuration. Use when\nconfiguring release-please workflows, checking release automation compliance, or\nwhen the user mentions FVH release-please, automated releases, or version management.\n"
                },
                "content": "# FVH Release-Please Standards\n\n## Version: 2025.1\n\nFVH standard release-please configuration for automated semantic versioning and changelog generation.\n\n## Standard Configuration\n\n### GitHub Actions Workflow\n\n**File**: `.github/workflows/release-please.yml`\n\n```yaml\nname: Release Please\n\non:\n  push:\n    branches:\n      - main\n\npermissions:\n  contents: write\n  pull-requests: write\n\njobs:\n  release-please:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: googleapis/release-please-action@v4\n        with:\n          token: ${{ secrets.MY_RELEASE_PLEASE_TOKEN }}\n```\n\n### Configuration Files\n\n**File**: `release-please-config.json`\n\n```json\n{\n  \"packages\": {\n    \".\": {\n      \"release-type\": \"node\",\n      \"changelog-sections\": [\n        {\"type\": \"feat\", \"section\": \"Features\"},\n        {\"type\": \"fix\", \"section\": \"Bug Fixes\"},\n        {\"type\": \"perf\", \"section\": \"Performance\"},\n        {\"type\": \"deps\", \"section\": \"Dependencies\"},\n        {\"type\": \"docs\", \"section\": \"Documentation\", \"hidden\": true},\n        {\"type\": \"chore\", \"section\": \"Miscellaneous\", \"hidden\": true}\n      ]\n    }\n  },\n  \"plugins\": [\"node-workspace\"]\n}\n```\n\n**File**: `.release-please-manifest.json`\n\n```json\n{\n  \".\": \"0.0.0\"\n}\n```\n\nNote: Version `0.0.0` is a placeholder - release-please updates this automatically.\n\n## Project Type Variations\n\n### Node.js Frontend/Backend\n\n- release-type: `node`\n- plugins: `node-workspace`\n- Updates: `package.json` version field\n\n### Python Service\n\n- release-type: `python`\n- Updates: `pyproject.toml` version field, `__version__` in code\n\n### Infrastructure (Helm)\n\n- release-type: `helm`\n- Updates: `Chart.yaml` version field\n\n### Multi-package Repository\n\n```json\n{\n  \"packages\": {\n    \"packages/frontend\": {\n      \"release-type\": \"node\",\n      \"component\": \"frontend\"\n    },\n    \"packages/backend\": {\n      \"release-type\": \"node\",\n      \"component\": \"backend\"\n    }\n  },\n  \"plugins\": [\n    \"node-workspace\",\n    {\n      \"type\": \"linked-versions\",\n      \"groupName\": \"workspace\",\n      \"components\": [\"frontend\", \"backend\"]\n    }\n  ]\n}\n```\n\n## Required Components\n\n### Minimum Requirements\n\n1. **Workflow file**: `.github/workflows/release-please.yml`\n   - Uses `googleapis/release-please-action@v4`\n   - Token: `MY_RELEASE_PLEASE_TOKEN` secret\n   - Triggers on push to `main`\n\n2. **Config file**: `release-please-config.json`\n   - Valid release-type for project\n   - changelog-sections defined\n\n3. **Manifest file**: `.release-please-manifest.json`\n   - Lists all packages with current versions\n\n### Token Configuration\n\nThe workflow uses `MY_RELEASE_PLEASE_TOKEN` secret (not `GITHUB_TOKEN`) because:\n- Allows release PRs to trigger other workflows\n- Enables CI checks on release PRs\n- Maintains proper audit trail\n\n## Compliance Checking\n\n### Status Levels\n\n| Status | Condition |\n|--------|-----------|\n| PASS | All three files present with valid configuration |\n| WARN | Files present but using deprecated action version |\n| FAIL | Missing required files or invalid configuration |\n\n### Validation Rules\n\n1. **Workflow validation**:\n   - Action version: `v4` (warn if older)\n   - Token: Must use secret, not hardcoded\n   - Trigger: Must include `push` to `main`\n\n2. **Config validation**:\n   - release-type: Must be valid (node, python, helm, simple)\n   - changelog-sections: Must include feat and fix\n\n3. **Manifest validation**:\n   - Must be valid JSON\n   - Packages must match config\n\n## Protected Files\n\n**IMPORTANT**: Release-please manages these files automatically:\n- `CHANGELOG.md` - Never edit manually\n- Version fields in `package.json`, `pyproject.toml`, `Chart.yaml`\n- `.release-please-manifest.json` - Only edit for initial setup\n\nSee `release-please-protection` skill for enforcement.\n\n## Conventional Commits\n\nRelease-please requires conventional commit messages:\n\n| Prefix | Release Type | Example |\n|--------|--------------|---------|\n| `feat:` | Minor | `feat: add user authentication` |\n| `fix:` | Patch | `fix: correct login timeout` |\n| `feat!:` | Major | `feat!: redesign API` |\n| `BREAKING CHANGE:` | Major | In commit body |\n\n## Installation\n\n1. Create workflow file\n2. Create config file\n3. Create manifest file\n4. Add `MY_RELEASE_PLEASE_TOKEN` to repository secrets\n5. Ensure pre-commit has conventional-pre-commit hook\n\n## Troubleshooting\n\n### Release PR Not Created\n\n- Check conventional commit format\n- Verify workflow has correct permissions\n- Ensure token has write access\n\n### Version Not Updated\n\n- Check manifest file is valid JSON\n- Verify release-type matches project\n- Review release-please logs in Actions\n\n### CI Not Running on Release PR\n\n- Token must be PAT, not GITHUB_TOKEN\n- Verify workflow trigger includes pull_request"
              },
              {
                "name": "fvh-skaffold",
                "description": "FVH (Forum Virium Helsinki) Skaffold configuration standards for local Kubernetes\ndevelopment with OrbStack and dotenvx. Use when configuring Skaffold, setting up local\nK8s development, or when the user mentions FVH Skaffold, local development, Kubernetes\nprofiles, or dotenvx secrets.\n",
                "path": "configure-plugin/skills/fvh-skaffold/SKILL.md",
                "frontmatter": {
                  "created": "2025-12-16T00:00:00.000Z",
                  "modified": "2025-12-16T00:00:00.000Z",
                  "reviewed": "2025-12-16T00:00:00.000Z",
                  "name": "fvh-skaffold",
                  "description": "FVH (Forum Virium Helsinki) Skaffold configuration standards for local Kubernetes\ndevelopment with OrbStack and dotenvx. Use when configuring Skaffold, setting up local\nK8s development, or when the user mentions FVH Skaffold, local development, Kubernetes\nprofiles, or dotenvx secrets.\n"
                },
                "content": "# FVH Skaffold Standards\n\n## Version: 2025.1\n\nFVH standard Skaffold configuration for local Kubernetes development workflows using OrbStack and dotenvx.\n\n## Standard Configuration\n\n### API Version\n\n```yaml\napiVersion: skaffold/v4beta13\nkind: Config\n```\n\nAlways use the latest stable API version. Currently: `skaffold/v4beta13`\n\n### Build Configuration\n\n```yaml\nbuild:\n  local:\n    push: false           # Never push to registry for local dev\n    useDockerCLI: true    # Use Docker CLI (better caching)\n    useBuildkit: true     # Enable BuildKit for performance\n    concurrency: 0        # Unlimited parallel builds\n  # Generate secrets from encrypted .env files before building\n  hooks:\n    before:\n      - command: ['sh', '-c', 'dotenvx run -- sh scripts/generate-secrets.sh']\n        os: [darwin, linux]\n  artifacts:\n    - image: app-name\n      context: .\n      docker:\n        dockerfile: Dockerfile\n    # Optional: init container for database migrations\n    - image: app-db-init\n      context: .\n      docker:\n        dockerfile: Dockerfile.db-init\n```\n\n### Port Forwarding (Security)\n\n**IMPORTANT**: Always bind to localhost only:\n\n```yaml\nportForward:\n  - resourceType: service\n    resourceName: app-name\n    port: 80\n    localPort: 8080\n    address: 127.0.0.1    # REQUIRED: Bind to localhost only\n```\n\nNever use `0.0.0.0` or omit the address field.\n\n### Deploy Configuration\n\n```yaml\ndeploy:\n  kubeContext: orbstack  # OrbStack for local development\n  kubectl:\n    defaultNamespace: app-name\n    # Optional: validation before deploy\n    hooks:\n      before:\n        - host:\n            command: [\"sh\", \"-c\", \"echo 'Deploying...'\"]\n            os: [darwin, linux]\n  statusCheck: true\n  # Extended timeout for init containers (db migrations, seeding)\n  statusCheckDeadlineSeconds: 180\n  tolerateFailuresUntilDeadline: true\n  # Parse JSON logs from applications for cleaner output\n  logs:\n    jsonParse:\n      fields: [\"message\", \"level\", \"timestamp\"]\n```\n\n## Standard Profiles\n\n### Profile: `db-only`\n\nDatabase only - for running app dev server locally with hot-reload:\n\n```yaml\nprofiles:\n  - name: db-only\n    build:\n      artifacts: []  # Don't build app\n    manifests:\n      rawYaml:\n        - k8s/namespace.yaml\n        - k8s/postgresql-secret.yaml\n        - k8s/postgresql-configmap.yaml\n        - k8s/postgresql-service.yaml\n        - k8s/postgresql-statefulset.yaml\n    portForward:\n      - resourceType: service\n        resourceName: postgresql\n        namespace: app-name\n        port: 5432\n        localPort: 5435\n        address: 127.0.0.1\n```\n\n**Use case**: Run `skaffold dev -p db-only` + `bun run dev` for hot-reload development\n\n### Profile: `services-only`\n\nBackend services only (database, APIs) - use with local frontend dev:\n\n```yaml\nprofiles:\n  - name: services-only\n    build:\n      artifacts: []  # Don't build frontend\n    manifests:\n      rawYaml:\n        - k8s/namespace.yaml\n        - k8s/database/*.yaml\n        - k8s/api/*.yaml\n    portForward:\n      - resourceType: service\n        resourceName: postgresql\n        port: 5432\n        localPort: 5435\n        address: 127.0.0.1\n```\n\n**Use case**: Run `skaffold dev -p services-only` + `bun run dev` for hot-reload frontend\n\n### Profile: `e2e` or `e2e-with-prod-data`\n\nFull stack for end-to-end testing:\n\n```yaml\nprofiles:\n  - name: e2e\n    manifests:\n      rawYaml:\n        - k8s/*.yaml  # All manifests\n```\n\n### Profile: `migration-test`\n\nDatabase migration testing:\n\n```yaml\nprofiles:\n  - name: migration-test\n    manifests:\n      rawYaml:\n        - k8s/database/*.yaml\n    test:\n      - image: migration-tester\n        custom:\n          - command: \"run-migrations.sh\"\n```\n\n## Compliance Requirements\n\n### Cluster Context (CRITICAL)\n\n**Always specify `kubeContext: orbstack`** in deploy configuration. This is the FVH standard local development context.\n\n```yaml\ndeploy:\n  kubeContext: orbstack\n  kubectl: {}\n```\n\nWhen using Skaffold commands, always include `--kube-context=orbstack`:\n\n```bash\nskaffold dev --kube-context=orbstack\nskaffold run --kube-context=orbstack\nskaffold delete --kube-context=orbstack\n```\n\nOnly use a different context if explicitly requested by the user.\n\n### Required Elements\n\n| Element | Requirement |\n|---------|-------------|\n| API version | `skaffold/v4beta13` |\n| deploy.kubeContext | `orbstack` (default) |\n| local.push | `false` |\n| portForward.address | `127.0.0.1` |\n| statusCheck | `true` recommended |\n| dotenvx hooks | Recommended for secrets |\n\n### Recommended Profiles\n\nDepending on project type:\n\n| Profile | Purpose | Required |\n|---------|---------|----------|\n| `db-only` | Database only + local app dev | Recommended |\n| `services-only` | Backend services + local frontend | Recommended |\n| `minimal` | Without optional features | Optional |\n| `e2e` | Full stack testing | Optional |\n\n## Project Type Variations\n\n### Frontend with Backend Services\n\n```yaml\n# Default: Full stack\nmanifests:\n  rawYaml:\n    - k8s/namespace.yaml\n    - k8s/frontend/*.yaml\n    - k8s/backend/*.yaml\n    - k8s/database/*.yaml\n\nprofiles:\n  - name: services-only\n    build:\n      artifacts: []\n    manifests:\n      rawYaml:\n        - k8s/namespace.yaml\n        - k8s/backend/*.yaml\n        - k8s/database/*.yaml\n```\n\n### API Service Only\n\n```yaml\n# Simpler configuration\nmanifests:\n  rawYaml:\n    - k8s/*.yaml\n\n# No profiles needed for simple services\n```\n\n### Infrastructure Testing\n\nSkaffold may not be applicable for pure infrastructure repos. Use Terraform/Helm directly.\n\n## dotenvx Integration\n\nFVH projects use [dotenvx](https://dotenvx.com/) for encrypted secrets management in local development.\n\n### How It Works\n\n1. **Encrypted .env files**: `.env` files contain encrypted values, safe to commit\n2. **Private key**: `DOTENV_PRIVATE_KEY` decrypts values at runtime\n3. **Hooks**: Skaffold hooks run `dotenvx run -- script` to inject secrets\n4. **Generated secrets**: Scripts create Kubernetes Secret manifests from .env\n\n### Build Hooks with dotenvx\n\n```yaml\nbuild:\n  hooks:\n    before:\n      - command: ['sh', '-c', 'dotenvx run -- sh scripts/generate-secrets.sh']\n        os: [darwin, linux]\n```\n\n### Deploy Hooks with dotenvx\n\n```yaml\ndeploy:\n  kubectl:\n    hooks:\n      before:\n        - host:\n            command: [\"sh\", \"-c\", \"dotenvx run -- sh scripts/generate-secrets.sh\"]\n```\n\n### Generate Secrets Script\n\nCreate `scripts/generate-secrets.sh`:\n\n```bash\n#!/bin/bash\n# Generate Kubernetes secrets from .env using dotenvx\nset -euo pipefail\n\n# Validate required env vars are set\n: \"${DATABASE_URL:?DATABASE_URL must be set}\"\n: \"${SECRET_KEY:?SECRET_KEY must be set}\"\n\n# Generate app secrets manifest\ncat > k8s/app-secrets.yaml << EOF\napiVersion: v1\nkind: Secret\nmetadata:\n  name: app-secrets\n  namespace: app-name\ntype: Opaque\nstringData:\n  DATABASE_URL: \"${DATABASE_URL}\"\n  SECRET_KEY: \"${SECRET_KEY}\"\nEOF\n\necho \"Generated k8s/app-secrets.yaml\"\n```\n\n### dotenvx Setup\n\n```bash\n# Install dotenvx\ncurl -sfS https://dotenvx.sh | sh\n\n# Create encrypted .env\ndotenvx set DATABASE_URL \"postgresql://...\"\ndotenvx set SECRET_KEY \"...\"\n\n# Encrypt existing .env\ndotenvx encrypt\n\n# Store private key securely (NOT in git)\necho \"DOTENV_PRIVATE_KEY=...\" >> ~/.zshrc\n```\n\n## Build Hooks (Validation)\n\nPre-build hooks for validation (in addition to dotenvx):\n\n```yaml\nbuild:\n  artifacts:\n    - image: app\n      hooks:\n        before:\n          - command: ['bun', 'run', 'check']\n            os: [darwin, linux]\n```\n\n## Status Levels\n\n| Status | Condition |\n|--------|-----------|\n| PASS | Compliant configuration |\n| WARN | Present but missing recommended elements |\n| FAIL | Security issue (e.g., portForward without localhost) |\n| SKIP | Not applicable (e.g., infrastructure repo) |\n\n## Troubleshooting\n\n### Pods Not Starting\n\n- Check `statusCheckDeadlineSeconds` (increase if needed)\n- Enable `tolerateFailuresUntilDeadline: true`\n- Review pod logs: `kubectl logs -f <pod>`\n\n### Port Forwarding Issues\n\n- Ensure port is not already in use\n- Check service name matches deployment\n- Verify `address: 127.0.0.1` is set\n\n### Build Caching\n\n- Enable BuildKit: `useBuildkit: true`\n- Use Docker CLI: `useDockerCLI: true`\n- Set `concurrency: 0` for parallel builds"
              },
              {
                "name": "go-feature-flag",
                "description": "GO Feature Flag (GOFF) self-hosted feature flag solution with OpenFeature\nintegration. Covers flag configuration, relay proxy, targeting rules, rollouts.\nUse when user mentions GO Feature Flag, GOFF, gofeatureflag, self-hosted\nfeature flags, or flags.goff.yaml configuration.\n",
                "path": "configure-plugin/skills/go-feature-flag/SKILL.md",
                "frontmatter": {
                  "created": "2025-12-16T00:00:00.000Z",
                  "modified": "2025-12-16T00:00:00.000Z",
                  "reviewed": "2025-12-16T00:00:00.000Z",
                  "name": "go-feature-flag",
                  "description": "GO Feature Flag (GOFF) self-hosted feature flag solution with OpenFeature\nintegration. Covers flag configuration, relay proxy, targeting rules, rollouts.\nUse when user mentions GO Feature Flag, GOFF, gofeatureflag, self-hosted\nfeature flags, or flags.goff.yaml configuration.\n"
                },
                "content": "# GO Feature Flag\n\nOpen-source feature flag solution with file-based configuration and OpenFeature integration. Use when setting up self-hosted feature flags, configuring flag files, or deploying the relay proxy.\n\n## When to Use\n\n**Automatic activation triggers:**\n- User mentions \"GO Feature Flag\", \"GOFF\", or \"gofeatureflag\"\n- Project has `@openfeature/go-feature-flag-provider` dependency\n- Project has `flags.goff.yaml` or similar flag configuration\n- User asks about self-hosted feature flags\n- Docker/K8s configuration includes `gofeatureflag/go-feature-flag` image\n\n**Related skills:**\n- `openfeature` - OpenFeature SDK usage patterns\n- `container-development` - Docker/K8s deployment\n\n## Architecture Overview\n\n```\n\n                     Application                              \n                                                             \n                   OpenFeature SDK                            \n                                                             \n              GO Feature Flag Provider                        \n\n                          \n                          \n\n                 GO Feature Flag Relay Proxy                  \n  \n                      Retriever                            \n    (File, S3, GitHub, HTTP, K8s ConfigMap, etc.)         \n  \n  \n                      Exporter                             \n    (Webhook, S3, Kafka, PubSub, etc.)                    \n  \n  \n                     Notifier                              \n    (Slack, Discord, Teams, Webhook)                      \n  \n\n                          \n                          \n\n                   Flag Configuration                         \n                    (flags.goff.yaml)                         \n\n```\n\n## Flag Configuration Format\n\n### Basic Structure\n\n```yaml\n# flags.goff.yaml\nflag-name:\n  variations:       # All possible values\n    variation1: value1\n    variation2: value2\n  defaultRule:      # Rule when no targeting matches\n    variation: variation1\n  targeting:        # Optional: targeting rules\n    - name: rule-name\n      query: 'expression'\n      variation: variation2\n```\n\n### Boolean Flags\n\n```yaml\n# Simple on/off flag\nnew-feature:\n  variations:\n    enabled: true\n    disabled: false\n  defaultRule:\n    variation: disabled\n```\n\n### String Flags\n\n```yaml\n# Theme selection\napp-theme:\n  variations:\n    light: \"light\"\n    dark: \"dark\"\n    system: \"system\"\n  defaultRule:\n    variation: system\n```\n\n### Number Flags\n\n```yaml\n# Configuration value\nrate-limit:\n  variations:\n    low: 100\n    medium: 500\n    high: 1000\n  defaultRule:\n    variation: medium\n```\n\n### Object/JSON Flags\n\n```yaml\n# Complex configuration\nfeature-config:\n  variations:\n    v1:\n      maxItems: 10\n      enableCache: true\n      timeout: 5000\n    v2:\n      maxItems: 50\n      enableCache: true\n      timeout: 3000\n  defaultRule:\n    variation: v1\n```\n\n## Targeting Rules\n\n### Query Syntax\n\nGO Feature Flag uses a CEL-like query syntax for targeting:\n\n```yaml\ntargeting:\n  - name: beta-users\n    query: 'groups co \"beta\"'  # contains\n    variation: enabled\n\n  - name: specific-user\n    query: 'targetingKey eq \"user-123\"'  # equals\n    variation: enabled\n\n  - name: email-domain\n    query: 'email ew \"@company.com\"'  # ends with\n    variation: enabled\n\n  - name: premium-tier\n    query: 'plan in [\"pro\", \"enterprise\"]'  # in list\n    variation: enabled\n```\n\n### Operators\n\n| Operator | Description | Example |\n|----------|-------------|---------|\n| `eq` | Equals | `email eq \"test@example.com\"` |\n| `ne` | Not equals | `plan ne \"free\"` |\n| `co` | Contains | `groups co \"admin\"` |\n| `sw` | Starts with | `email sw \"admin\"` |\n| `ew` | Ends with | `email ew \"@company.com\"` |\n| `in` | In list | `country in [\"US\", \"CA\"]` |\n| `gt`, `ge`, `lt`, `le` | Comparisons | `age gt 18` |\n| `and`, `or` | Logical | `plan eq \"pro\" and country eq \"US\"` |\n\n### Priority\n\nRules are evaluated top-to-bottom. First matching rule wins:\n\n```yaml\ntargeting:\n  # Highest priority: specific user override\n  - name: test-user\n    query: 'targetingKey eq \"test-user-id\"'\n    variation: enabled\n\n  # Second: admin group\n  - name: admins\n    query: 'groups co \"admin\"'\n    variation: enabled\n\n  # Third: beta users\n  - name: beta\n    query: 'groups co \"beta\"'\n    variation: enabled\n\n  # Fallback is defaultRule\ndefaultRule:\n  variation: disabled\n```\n\n## Rollout Strategies\n\n### Percentage Rollout\n\n```yaml\nnew-checkout:\n  variations:\n    enabled: true\n    disabled: false\n  defaultRule:\n    percentage:\n      enabled: 20   # 20% of users\n      disabled: 80  # 80% of users\n```\n\n### Progressive Rollout\n\n```yaml\napi-v2:\n  variations:\n    enabled: true\n    disabled: false\n  defaultRule:\n    variation: disabled\n  experimentation:\n    start: 2024-11-01T00:00:00Z\n    end: 2024-12-01T00:00:00Z\n    progressiveRollout:\n      initial:\n        variation: enabled\n        percentage: 0\n      end:\n        variation: enabled\n        percentage: 100\n```\n\n### Scheduled Changes\n\n```yaml\nholiday-theme:\n  variations:\n    enabled: true\n    disabled: false\n  defaultRule:\n    variation: disabled\n  scheduledRollout:\n    - date: 2024-12-01T00:00:00Z\n      variation: enabled\n    - date: 2025-01-02T00:00:00Z\n      variation: disabled\n```\n\n### A/B Testing\n\n```yaml\nbutton-color:\n  variations:\n    blue: \"#0066CC\"\n    green: \"#00CC66\"\n    red: \"#CC0066\"\n  defaultRule:\n    percentage:\n      blue: 34\n      green: 33\n      red: 33\n  experimentation:\n    start: 2024-11-01T00:00:00Z\n    end: 2024-11-15T00:00:00Z\n```\n\n## Relay Proxy Configuration\n\n### Docker Compose (Development)\n\n```yaml\n# docker-compose.yaml\nservices:\n  goff-relay:\n    image: gofeatureflag/go-feature-flag:latest\n    ports:\n      - \"1031:1031\"  # API\n      - \"1032:1032\"  # Health/metrics\n    volumes:\n      - ./flags.goff.yaml:/goff/flags.yaml:ro\n    environment:\n      # Retriever configuration\n      - RETRIEVER_KIND=file\n      - RETRIEVER_PATH=/goff/flags.yaml\n\n      # Polling interval (ms)\n      - POLLING_INTERVAL_MS=10000\n\n      # Logging\n      - LOG_LEVEL=info\n    healthcheck:\n      test: [\"CMD\", \"wget\", \"-q\", \"--spider\", \"http://localhost:1032/health\"]\n      interval: 10s\n      timeout: 5s\n      retries: 3\n```\n\n### Environment Variables\n\n```bash\n# Retriever (choose one)\nRETRIEVER_KIND=file|s3|http|github|gitlab|googlecloud|azureblob|k8s\n\n# File retriever\nRETRIEVER_PATH=/path/to/flags.yaml\n\n# S3 retriever\nRETRIEVER_BUCKET=my-bucket\nRETRIEVER_ITEM=flags/production.yaml\nAWS_REGION=us-east-1\n\n# GitHub retriever\nRETRIEVER_REPOSITORY_SLUG=owner/repo\nRETRIEVER_FILE_PATH=flags/production.yaml\nRETRIEVER_BRANCH=main\nGITHUB_TOKEN=ghp_xxxx\n\n# HTTP retriever\nRETRIEVER_URL=https://api.example.com/flags.yaml\nRETRIEVER_HEADERS=Authorization=Bearer xxx\n\n# Polling\nPOLLING_INTERVAL_MS=30000\n\n# Server\nHTTP_PORT=1031\nADMIN_PORT=1032\nLOG_LEVEL=info|debug|warn|error\n```\n\n### Kubernetes Deployment\n\n```yaml\n# k8s/deployment.yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: goff-relay\n  labels:\n    app: goff-relay\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: goff-relay\n  template:\n    metadata:\n      labels:\n        app: goff-relay\n    spec:\n      containers:\n        - name: relay\n          image: gofeatureflag/go-feature-flag:v1.25.0\n          ports:\n            - name: api\n              containerPort: 1031\n            - name: admin\n              containerPort: 1032\n          env:\n            - name: RETRIEVER_KIND\n              value: \"file\"\n            - name: RETRIEVER_PATH\n              value: \"/config/flags.yaml\"\n          volumeMounts:\n            - name: flags\n              mountPath: /config\n          livenessProbe:\n            httpGet:\n              path: /health\n              port: admin\n            initialDelaySeconds: 5\n            periodSeconds: 10\n          readinessProbe:\n            httpGet:\n              path: /health\n              port: admin\n            initialDelaySeconds: 5\n            periodSeconds: 5\n          resources:\n            requests:\n              memory: \"64Mi\"\n              cpu: \"100m\"\n            limits:\n              memory: \"256Mi\"\n              cpu: \"500m\"\n      volumes:\n        - name: flags\n          configMap:\n            name: feature-flags\n---\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: feature-flags\ndata:\n  flags.yaml: |\n    new-feature:\n      variations:\n        enabled: true\n        disabled: false\n      defaultRule:\n        variation: disabled\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: goff-relay\nspec:\n  selector:\n    app: goff-relay\n  ports:\n    - name: api\n      port: 1031\n      targetPort: api\n    - name: admin\n      port: 1032\n      targetPort: admin\n```\n\n## Exporters\n\nExport flag evaluation data for analytics:\n\n```yaml\n# Environment variables\nEXPORTER_KIND=webhook|s3|googlecloud|kafka|pubsub|log\n\n# Webhook exporter\nEXPORTER_ENDPOINT_URL=https://analytics.example.com/events\nEXPORTER_FLUSH_INTERVAL_MS=60000\nEXPORTER_MAX_EVENTS_IN_MEMORY=10000\n\n# S3 exporter\nEXPORTER_BUCKET=my-analytics-bucket\nEXPORTER_PATH=flag-events/\n```\n\n## Notifiers\n\nSend notifications on flag changes:\n\n```yaml\n# Slack\nNOTIFIER_KIND=slack\nNOTIFIER_SLACK_WEBHOOK_URL=https://hooks.slack.com/services/xxx\n\n# Discord\nNOTIFIER_KIND=discord\nNOTIFIER_DISCORD_WEBHOOK_URL=https://discord.com/api/webhooks/xxx\n\n# Microsoft Teams\nNOTIFIER_KIND=teams\nNOTIFIER_TEAMS_WEBHOOK_URL=https://outlook.office.com/webhook/xxx\n```\n\n## CLI Tools\n\n### Validate Configuration\n\n```bash\n# Install CLI\ngo install github.com/thomaspoignant/go-feature-flag/cmd/goff@latest\n\n# Validate flag file\ngoff lint --config flags.goff.yaml\n\n# Output format\ngoff lint --config flags.goff.yaml --format json\n```\n\n### Testing Flags Locally\n\n```bash\n# Start relay in foreground\ndocker run -p 1031:1031 -p 1032:1032 \\\n  -v $(pwd)/flags.goff.yaml:/goff/flags.yaml:ro \\\n  -e RETRIEVER_KIND=file \\\n  -e RETRIEVER_PATH=/goff/flags.yaml \\\n  gofeatureflag/go-feature-flag:latest\n\n# Test flag evaluation\ncurl -X POST http://localhost:1031/v1/feature/new-feature/eval \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"evaluationContext\": {\"targetingKey\": \"user-123\"}}'\n```\n\n## Best Practices\n\n### 1. Use GitOps for Flag Configuration\n\n```yaml\n# Store flags in git, sync to S3/ConfigMap\n# .github/workflows/deploy-flags.yaml\non:\n  push:\n    paths:\n      - 'flags/**'\njobs:\n  deploy:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - name: Validate flags\n        run: goff lint --config flags/production.yaml\n      - name: Sync to S3\n        run: aws s3 cp flags/production.yaml s3://flags-bucket/\n```\n\n### 2. Environment-Specific Flags\n\n```yaml\n# flags/base.yaml - shared defaults\n# flags/development.yaml - dev overrides\n# flags/production.yaml - production config\n\n# Use includes (if using file retriever with multiple files)\n# Or separate retrievers per environment\n```\n\n### 3. Flag Naming Convention\n\n```yaml\n# Namespace by feature/team\ncheckout.new-payment-form\ndashboard.beta-widgets\napi.v2-endpoints\n\n# Use consistent suffixes\n*.enabled      # boolean toggles\n*.config       # object/JSON config\n*.percentage   # rollout percentage\n```\n\n### 4. Track Flag Lifecycle\n\n```yaml\n# Add metadata comments (YAML supports comments)\nnew-feature:\n  # Created: 2024-11-01\n  # Owner: team-checkout\n  # Jira: PROJ-123\n  # Target removal: 2025-01-15\n  variations:\n    enabled: true\n    disabled: false\n```\n\n### 5. Monitor and Clean Up\n\n- Export evaluation data to track usage\n- Set up alerts for flags at 100% (ready for removal)\n- Review flags quarterly for cleanup\n\n## Troubleshooting\n\n### Flag Not Evaluating Correctly\n\n```bash\n# Check relay logs\ndocker logs goff-relay\n\n# Test evaluation directly\ncurl -X POST http://localhost:1031/v1/feature/my-flag/eval \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"evaluationContext\": {\"targetingKey\": \"test\", \"email\": \"test@example.com\"}}'\n```\n\n### Provider Connection Issues\n\n```typescript\n// Check provider initialization\nconst provider = new GoFeatureFlagProvider({\n  endpoint: process.env.GOFF_RELAY_URL,\n  timeout: 5000, // Increase timeout\n});\n\n// Handle events\nprovider.on('PROVIDER_READY', () => console.log('Provider ready'));\nprovider.on('PROVIDER_ERROR', (e) => console.error('Provider error', e));\n```\n\n### Configuration Not Updating\n\n```bash\n# Check polling interval\nPOLLING_INTERVAL_MS=10000  # 10 seconds\n\n# Verify file is readable\ndocker exec goff-relay cat /goff/flags.yaml\n\n# Check retriever status\ncurl http://localhost:1032/info\n```\n\n## Documentation\n\n- **Official Docs**: https://gofeatureflag.org/docs\n- **Flag Format**: https://gofeatureflag.org/docs/configure_flag/flag_format\n- **Relay Proxy**: https://gofeatureflag.org/docs/relay-proxy\n- **OpenFeature SDKs**: https://gofeatureflag.org/docs/sdk\n\n## Related Commands\n\n- `/configure:feature-flags` - Set up complete feature flag infrastructure\n- `/configure:dockerfile` - Container configuration best practices"
              },
              {
                "name": "openfeature",
                "description": "OpenFeature vendor-agnostic feature flag SDK with standardized API across\nlanguages. Covers SDK installation, flag evaluation, providers, and hooks.\nUse when implementing feature flags, A/B testing, canary releases, or when\nuser mentions OpenFeature, feature toggles, or progressive rollouts.\n",
                "path": "configure-plugin/skills/openfeature/SKILL.md",
                "frontmatter": {
                  "created": "2025-12-16T00:00:00.000Z",
                  "modified": "2025-12-16T00:00:00.000Z",
                  "reviewed": "2025-12-16T00:00:00.000Z",
                  "name": "openfeature",
                  "description": "OpenFeature vendor-agnostic feature flag SDK with standardized API across\nlanguages. Covers SDK installation, flag evaluation, providers, and hooks.\nUse when implementing feature flags, A/B testing, canary releases, or when\nuser mentions OpenFeature, feature toggles, or progressive rollouts.\n"
                },
                "content": "# OpenFeature SDK Integration\n\nVendor-agnostic feature flag SDK providing standardized API across languages and providers. Use when implementing feature flags, A/B testing, canary releases, or progressive rollouts with any feature flag backend.\n\n## When to Use\n\n**Automatic activation triggers:**\n- User mentions \"feature flags\", \"feature toggles\", or \"feature management\"\n- User asks about A/B testing or canary releases\n- User wants to implement progressive rollouts\n- Project has OpenFeature SDK dependencies\n- User mentions OpenFeature, flagd, or vendor-agnostic flags\n\n**Related skills:**\n- `go-feature-flag` - Specific GO Feature Flag provider details\n- `launchdarkly` - LaunchDarkly provider integration\n\n## Core Concepts\n\n### Architecture\n\n```\n\n                    Application Code                          \n\n                  OpenFeature SDK (API)                       \n   \n    getBool()    getString()   getNumber()  getObject() \n   \n\n                       Provider                               \n   \n    GO Feature Flag  flagd  LaunchDarkly  Split  etc   \n   \n\n                    Flag Source                               \n   \n     File      S3     GitHub    API    ConfigMap       \n   \n\n```\n\n### Key Components\n\n1. **API** - Standardized interface for flag evaluation\n2. **Provider** - Backend-specific implementation\n3. **Evaluation Context** - User/request data for targeting\n4. **Hooks** - Lifecycle extensions for logging, telemetry\n\n## SDK Installation\n\n### Node.js (Server)\n\n```bash\n# Core SDK\nnpm install @openfeature/server-sdk\n\n# Providers (choose one)\nnpm install @openfeature/go-feature-flag-provider  # GO Feature Flag\nnpm install @openfeature/flagd-provider            # flagd\nnpm install @openfeature/in-memory-provider        # Testing\n```\n\n### Node.js (Browser/React)\n\n```bash\n# Web SDK\nnpm install @openfeature/web-sdk\n\n# React integration\nnpm install @openfeature/react-sdk\n\n# Web providers\nnpm install @openfeature/go-feature-flag-web-provider\n```\n\n### Python\n\n```bash\nuv add openfeature-sdk\nuv add openfeature-provider-go-feature-flag  # GO Feature Flag provider\n```\n\n### Go\n\n```bash\ngo get github.com/open-feature/go-sdk\ngo get github.com/open-feature/go-sdk-contrib/providers/go-feature-flag\n```\n\n### Java\n\n```xml\n<dependency>\n    <groupId>dev.openfeature</groupId>\n    <artifactId>sdk</artifactId>\n    <version>1.7.0</version>\n</dependency>\n```\n\n### Rust\n\n```toml\n[dependencies]\nopen-feature = \"0.2\"\n```\n\n## Basic Usage Patterns\n\n### Initialization\n\n```typescript\n// TypeScript/Node.js\nimport { OpenFeature } from '@openfeature/server-sdk';\nimport { GoFeatureFlagProvider } from '@openfeature/go-feature-flag-provider';\n\n// Initialize provider\nconst provider = new GoFeatureFlagProvider({\n  endpoint: process.env.GOFF_RELAY_URL || 'http://localhost:1031',\n});\n\n// Set provider (awaitable for ready state)\nawait OpenFeature.setProviderAndWait(provider);\n\n// Get client\nconst client = OpenFeature.getClient('my-app');\n```\n\n### Flag Evaluation\n\n```typescript\n// Boolean flag\nconst isEnabled = await client.getBooleanValue('new-feature', false);\n\n// String flag\nconst buttonColor = await client.getStringValue('button-color', '#000000');\n\n// Number flag\nconst maxItems = await client.getNumberValue('max-items', 10);\n\n// Object/JSON flag\nconst config = await client.getObjectValue('feature-config', {});\n\n// With evaluation context\nconst context = { targetingKey: userId, email: userEmail, groups: ['beta'] };\nconst isEnabled = await client.getBooleanValue('new-feature', false, context);\n```\n\n### Evaluation Context\n\n```typescript\n// Creating context\nconst context: EvaluationContext = {\n  // Required: unique identifier for targeting\n  targetingKey: user.id,\n\n  // Optional: additional attributes for targeting rules\n  email: user.email,\n  groups: user.roles,\n  plan: user.subscription,\n\n  // Custom attributes\n  country: request.geoip.country,\n  browser: request.headers['user-agent'],\n};\n\n// Set global context (applies to all evaluations)\nOpenFeature.setContext(context);\n\n// Or per-evaluation context\nawait client.getBooleanValue('feature', false, context);\n```\n\n### Hooks\n\n```typescript\nimport { Hook, HookContext, EvaluationDetails } from '@openfeature/server-sdk';\n\n// Logging hook\nconst loggingHook: Hook = {\n  before: (hookContext: HookContext) => {\n    console.log(`Evaluating flag: ${hookContext.flagKey}`);\n  },\n  after: (hookContext: HookContext, details: EvaluationDetails<unknown>) => {\n    console.log(`Flag ${hookContext.flagKey} = ${details.value}`);\n  },\n  error: (hookContext: HookContext, error: Error) => {\n    console.error(`Error evaluating ${hookContext.flagKey}:`, error);\n  },\n};\n\n// Register globally\nOpenFeature.addHooks(loggingHook);\n\n// Or per-client\nclient.addHooks(loggingHook);\n```\n\n### React Integration\n\n```tsx\nimport { OpenFeatureProvider, useFlag, useBooleanFlagValue } from '@openfeature/react-sdk';\nimport { GoFeatureFlagWebProvider } from '@openfeature/go-feature-flag-web-provider';\n\n// Provider setup\nconst provider = new GoFeatureFlagWebProvider({\n  endpoint: import.meta.env.VITE_GOFF_RELAY_URL,\n});\n\nfunction App() {\n  return (\n    <OpenFeatureProvider provider={provider}>\n      <MyComponent />\n    </OpenFeatureProvider>\n  );\n}\n\n// Using flags in components\nfunction MyComponent() {\n  // Simple boolean value\n  const isEnabled = useBooleanFlagValue('new-feature', false);\n\n  // Full flag details\n  const { value, isLoading, error } = useFlag('button-color', '#000');\n\n  if (isLoading) return <Spinner />;\n\n  return (\n    <div>\n      {isEnabled && <NewFeature />}\n      <Button color={value}>Click me</Button>\n    </div>\n  );\n}\n```\n\n## Testing\n\n### In-Memory Provider\n\n```typescript\nimport { OpenFeature } from '@openfeature/server-sdk';\nimport { InMemoryProvider } from '@openfeature/in-memory-provider';\n\n// Configure test flags\nconst testProvider = new InMemoryProvider({\n  'new-feature': {\n    variants: {\n      on: true,\n      off: false,\n    },\n    defaultVariant: 'off',\n    disabled: false,\n  },\n  'button-color': {\n    variants: {\n      blue: '#0066CC',\n      green: '#00CC66',\n    },\n    defaultVariant: 'blue',\n    disabled: false,\n  },\n});\n\n// Use in tests\nbeforeAll(async () => {\n  await OpenFeature.setProviderAndWait(testProvider);\n});\n\nafterAll(async () => {\n  await OpenFeature.close();\n});\n```\n\n### Mocking in Unit Tests\n\n```typescript\nimport { vi } from 'vitest';\nimport { OpenFeature } from '@openfeature/server-sdk';\n\n// Mock the entire SDK\nvi.mock('@openfeature/server-sdk', () => ({\n  OpenFeature: {\n    getClient: vi.fn().mockReturnValue({\n      getBooleanValue: vi.fn().mockResolvedValue(true),\n      getStringValue: vi.fn().mockResolvedValue('test-value'),\n    }),\n  },\n}));\n```\n\n## Best Practices\n\n### 1. Initialize Early\n\n```typescript\n// Initialize before app starts handling requests\nasync function bootstrap() {\n  await initializeFeatureFlags();  // First\n  await initializeDatabase();\n  await startServer();\n}\n```\n\n### 2. Use Meaningful Flag Names\n\n```typescript\n// Good: descriptive, namespaced\n'checkout.new-payment-flow'\n'dashboard.beta-analytics'\n'api.rate-limit-v2'\n\n// Bad: vague, unclear\n'feature1'\n'test-flag'\n'enabled'\n```\n\n### 3. Always Provide Defaults\n\n```typescript\n// Good: safe default that works if provider fails\nconst isEnabled = await client.getBooleanValue('risky-feature', false);\n\n// Consider: what's the safe behavior if flags fail?\nconst maxItems = await client.getNumberValue('max-items', 100); // Safe limit\n```\n\n### 4. Handle Provider Errors\n\n```typescript\ntry {\n  const value = await client.getBooleanValue('feature', false);\n} catch (error) {\n  // Log but don't crash - use default\n  logger.error('Feature flag evaluation failed', { error });\n  return defaultBehavior();\n}\n```\n\n### 5. Clean Up Old Flags\n\n```typescript\n// Track flag usage with hooks\nconst flagUsageHook: Hook = {\n  after: (context, details) => {\n    metrics.increment(`feature_flag.${context.flagKey}.evaluations`);\n  },\n};\n\n// Regularly review and remove flags with 100% rollout\n// or flags that haven't been evaluated in months\n```\n\n## Documentation\n\n- **OpenFeature Specification**: https://openfeature.dev/specification\n- **SDK Reference**: https://openfeature.dev/docs/reference/concepts/evaluation-api\n- **Providers List**: https://openfeature.dev/ecosystem\n- **Hooks Guide**: https://openfeature.dev/docs/reference/concepts/hooks\n\n## Related Commands\n\n- `/configure:feature-flags` - Set up feature flag infrastructure\n- `/configure:sentry` - Error tracking (for feature flag rollback monitoring)"
              }
            ]
          },
          {
            "name": "git-plugin",
            "description": "Git workflows - commits, branches, PRs, and repository management",
            "source": "./git-plugin",
            "category": "version-control",
            "version": "1.2.0",
            "author": null,
            "install_commands": [
              "/plugin marketplace add laurigates/claude-plugins",
              "/plugin install git-plugin@lgates-claude-plugins"
            ],
            "signals": {
              "stars": 1,
              "forks": 0,
              "pushed_at": "2026-01-12T12:05:51Z",
              "created_at": "2025-12-16T11:24:04Z",
              "license": null
            },
            "commands": [],
            "skills": [
              {
                "name": "git-branch-pr-workflow",
                "description": "Branch management, pull request workflows, and GitHub integration. Main-branch\ndevelopment pattern (push main to remote feature branches), modern Git commands\n(switch, restore), branch naming conventions, linear history, and GitHub MCP tools.\nUse when user mentions creating branches, opening PRs, git switch, git restore,\nfeature branches, pull requests, or GitHub PR workflows.\n",
                "path": "git-plugin/skills/git-branch-pr-workflow/SKILL.md",
                "frontmatter": {
                  "created": "2025-12-16T00:00:00.000Z",
                  "modified": "2025-12-16T00:00:00.000Z",
                  "reviewed": "2025-12-16T00:00:00.000Z",
                  "name": "git-branch-pr-workflow",
                  "description": "Branch management, pull request workflows, and GitHub integration. Main-branch\ndevelopment pattern (push main to remote feature branches), modern Git commands\n(switch, restore), branch naming conventions, linear history, and GitHub MCP tools.\nUse when user mentions creating branches, opening PRs, git switch, git restore,\nfeature branches, pull requests, or GitHub PR workflows.\n",
                  "allowed-tools": "Bash, Read, mcp__github__create_pull_request, mcp__github__list_pull_requests, mcp__github__update_pull_request"
                },
                "content": "# Git Branch PR Workflow\n\nExpert guidance for branch management, pull request workflows, and GitHub integration using modern Git commands and linear history practices.\n\n## Core Expertise\n\n- **Main-Branch Development**: Work on main locally, push to remote feature branches for PRs\n- **Modern Git Commands**: Use `git switch` and `git restore` instead of checkout\n- **Branch Naming**: Structured conventions (feat/, fix/, chore/, hotfix/)\n- **Linear History**: Rebase-first workflow, squash merging, clean history\n- **GitHub MCP Integration**: Use mcp__github__* tools instead of gh CLI\n\n## Main-Branch Development (Preferred)\n\nDevelop directly on main, push to remote feature branches for PRs. This eliminates local branch management overhead.\n\n### Basic Workflow\n\n```bash\n# All work happens on main\ngit switch main\ngit pull origin main\n\n# Make changes, commit on main\ngit add file.ts\ngit commit -m \"feat(auth): add OAuth2 support\"\n\n# Push to remote feature branch (creates PR target)\ngit push origin main:feat/auth-oauth2\n\n# Create PR using GitHub MCP (head: feat/auth-oauth2, base: main)\n```\n\n### Multi-PR Workflow (Sequential Commits)\n\nWhen you have commits for multiple PRs on main, push specific commit ranges to different remote branches:\n\n```bash\n# Commits on main:\n# abc1234 feat(auth): add OAuth2 support       <- PR #1\n# def5678 feat(auth): add token refresh        <- PR #1\n# ghi9012 fix(api): handle timeout edge case   <- PR #2\n\n# Push first 2 commits to auth feature branch\ngit push origin abc1234^..def5678:feat/auth-oauth2\n\n# Push remaining commit to fix branch\ngit push origin ghi9012^..ghi9012:fix/api-timeout\n\n# Alternative: push from a specific commit to HEAD\ngit push origin def5678..HEAD:fix/api-timeout\n```\n\n**Commit range patterns:**\n- `git push origin <start>^..<end>:<remote-branch>` - Push commit range (inclusive)\n- `git push origin <commit>..<commit>:<remote-branch>` - Push range (exclusive start)\n- `git push origin <commit>..HEAD:<remote-branch>` - Push from commit to current HEAD\n- `git push origin main:<remote-branch>` - Push entire main to remote branch\n\n### Benefits\n\n- **No local branch juggling** - Always on main\n- **Always on latest main** - No branch drift\n- **Clean local state** - No stale branches to clean up\n- **Remote branches are ephemeral** - Deleted after PR merge\n- **Simpler mental model** - One local branch, many remote targets\n\n## Modern Git Commands (2025)\n\n### Switch vs Checkout\n\nModern Git uses specialized commands instead of multi-purpose `git checkout`:\n\n```bash\n# Branch switching - NEW WAY (Git 2.23+)\ngit switch feature-branch          # vs git checkout feature-branch\ngit switch -c new-feature          # vs git checkout -b new-feature\ngit switch -                       # vs git checkout -\n\n# Creating branches with tracking\ngit switch -c feature --track origin/feature\ngit switch -C force-recreate-branch\n```\n\n### Restore vs Reset/Checkout\n\nFile restoration is now handled by `git restore`:\n\n```bash\n# Unstaging files - NEW WAY\ngit restore --staged file.txt      # vs git reset HEAD file.txt\ngit restore --staged .             # vs git reset HEAD .\n\n# Discarding changes - NEW WAY\ngit restore file.txt               # vs git checkout -- file.txt\ngit restore .                      # vs git checkout -- .\n\n# Restore from specific commit\ngit restore --source=HEAD~2 file.txt    # vs git checkout HEAD~2 -- file.txt\ngit restore --source=main --staged .    # vs git reset main .\n```\n\n### Command Migration Guide\n\n| Legacy Command                | Modern Alternative                 | Purpose             |\n| ----------------------------- | ---------------------------------- | ------------------- |\n| `git checkout branch`         | `git switch branch`                | Switch branches     |\n| `git checkout -b new`         | `git switch -c new`                | Create & switch     |\n| `git checkout -- file`        | `git restore file`                 | Discard changes     |\n| `git reset HEAD file`         | `git restore --staged file`        | Unstage file        |\n| `git checkout HEAD~1 -- file` | `git restore --source=HEAD~1 file` | Restore from commit |\n\n## Branch Naming Conventions\n\n### Structured Branch Names\n\n```bash\n# Feature development\ngit switch -c feat/payment-integration\ngit switch -c feat/user-dashboard\ngit switch -c feat/api-v2\n\n# Bug fixes\ngit switch -c fix/login-validation\ngit switch -c fix/memory-leak-auth\ngit switch -c fix/broken-tests\n\n# Maintenance and refactoring\ngit switch -c chore/update-dependencies\ngit switch -c chore/cleanup-tests\ngit switch -c refactor/auth-service\n\n# Hotfixes (for production)\ngit switch -c hotfix/security-patch\ngit switch -c hotfix/critical-bug-fix\n```\n\n### Branch Naming Format\n\n`{type}/{description}-{YYYYMMDD}` (date optional but recommended for clarity)\n\n**Types:**\n- `feat/` - New features\n- `fix/` - Bug fixes\n- `chore/` - Maintenance, dependencies, linter fixes\n- `docs/` - Documentation changes\n- `refactor/` - Code restructuring\n- `hotfix/` - Emergency production fixes\n\n## Linear History Workflow\n\n### Trunk-Based Development\n\n**Preferred: Main-branch development** (see above) - no local feature branches needed.\n\n**Alternative: Local feature branches** for complex multi-day work:\n\n```bash\n# Feature branch lifecycle (max 2 days)\ngit switch main\ngit pull origin main\ngit switch -c feat/user-auth\n\n# Daily rebase to stay current\ngit switch main && git pull\ngit switch feat/user-auth\ngit rebase main\n\n# Interactive cleanup before PR\ngit rebase -i main\n# Squash, fixup, reword commits for clean history\n\n# Push and create PR\ngit push -u origin feat/user-auth\n```\n\nUse local branches only when:\n- Multi-day complex features requiring isolation\n- Experimental work that might be abandoned\n- Need to switch contexts frequently between unrelated work\n\n### Squash Merge Strategy\n\nMaintain linear main branch history:\n\n```bash\n# Manual squash merge\ngit switch main\ngit merge --squash feat/user-auth\ngit commit -m \"feat: add user authentication system\n\n- Implement JWT token validation\n- Add login/logout endpoints\n- Create user session management\n\nCloses #123\"\n```\n\n### Interactive Rebase Workflow\n\nClean up commits before sharing:\n\n```bash\n# Rebase last 3 commits\ngit rebase -i HEAD~3\n\n# Common rebase commands:\n# pick   = use commit as-is\n# squash = combine with previous commit\n# fixup  = squash without editing message\n# reword = change commit message\n# drop   = remove commit entirely\n\n# Example rebase todo list:\npick a1b2c3d feat: add login form\nfixup d4e5f6g fix typo in login form\nsquash g7h8i9j add form validation\nreword j1k2l3m implement JWT tokens\n```\n\n## GitHub MCP Integration\n\nUse GitHub MCP tools for all GitHub operations:\n\n```python\n# Get repository information\nmcp__github__get_me()  # Get authenticated user info\n\n# List and create PRs\nmcp__github__list_pull_requests(owner=\"owner\", repo=\"repo\")\nmcp__github__create_pull_request(\n  owner=\"owner\",\n  repo=\"repo\",\n  title=\"feat: add authentication\",\n  head=\"feat/auth\",\n  base=\"main\",\n  body=\"## Summary\\n- JWT authentication\\n- OAuth support\\n\\nCloses #123\"\n)\n\n# Update PRs\nmcp__github__update_pull_request(\n  owner=\"owner\",\n  repo=\"repo\",\n  pullNumber=42,\n  title=\"Updated title\",\n  state=\"open\"\n)\n\n# List and create issues\nmcp__github__list_issues(owner=\"owner\", repo=\"repo\")\n```\n\n## Best Practices\n\n### Daily Integration Workflow\n\n```bash\n# Start of day: sync with main\ngit switch main\ngit pull origin main\ngit switch feat/current-work\ngit rebase main\n\n# End of day: push progress\ngit add . && git commit -m \"wip: daily progress checkpoint\"\ngit push origin feat/current-work\n\n# Before PR: clean up history\ngit rebase -i main\ngit push --force-with-lease origin feat/current-work\n```\n\n### Conflict Resolution with Rebase\n\n```bash\n# When rebase conflicts occur\ngit rebase main\n# Fix conflicts in editor\ngit add resolved-file.txt\ngit rebase --continue\n\n# If rebase gets messy, abort and merge instead\ngit rebase --abort\ngit merge main\n```\n\n### Safe Force Pushing\n\n```bash\n# Always use --force-with-lease to prevent overwriting others' work\ngit push --force-with-lease origin feat/branch-name\n\n# Never force push to main/shared branches\n# Use this alias for safety:\ngit config alias.pushf 'push --force-with-lease'\n```\n\n## Main Branch Protection\n\nConfigure branch rules for linear history via GitHub MCP:\n\n```bash\n# Require linear history (disable merge commits)\n# Configure via GitHub settings or MCP tools\n# - Require pull request reviews\n# - Require status checks to pass\n# - Enforce linear history (squash merge only)\n```\n\n## Pull Request Workflow\n\n### PR Title Format\n\nUse conventional commit format in PR titles:\n\n- `feat: add user authentication`\n- `fix: resolve login validation bug`\n- `docs: update API documentation`\n- `chore: update dependencies`\n\n### PR Body Template\n\n```markdown\n## Summary\nBrief description of changes\n\n## Changes\n- Bullet points of key changes\n- Link related work\n\n## Testing\nHow changes were tested\n\n## Issue References\n<!-- Use GitHub autolink format - ALWAYS include relevant issues -->\nCloses #123\n<!-- Or use: Fixes #N, Resolves #N, Refs #N -->\n```\n\n**Issue Reference Guidelines:**\n- Use `Closes #N` / `Fixes #N` / `Resolves #N` to auto-close issues on merge\n- Use `Refs #N` / `Related to #N` for context without auto-closing\n- Cross-repo: `Fixes owner/repo#N`\n- Multiple: `Fixes #1, fixes #2, fixes #3` (repeat keyword)\n\n### PR Creation Best Practices\n\n- **One focus per PR** - Single logical change\n- **Small PRs** - Easier to review (< 400 lines preferred)\n- **ALWAYS link issues** - Use GitHub autolink format for traceability:\n  - Closing keywords: `Closes #123`, `Fixes #456`, `Resolves #789`\n  - Reference without closing: `Refs #234`, `Related to #567`\n  - Cross-repository: `Fixes owner/repo#123`\n  - Multiple issues: `Fixes #1, fixes #2` (repeat keyword for each)\n- **Add labels** - Use GitHub labels for categorization\n- **Request reviewers** - Tag specific reviewers when needed\n\n## Troubleshooting\n\n### Branch Diverged from Remote\n\n```bash\n# Pull with rebase to maintain linear history\ngit pull --rebase origin feat/branch-name\n\n# Or reset if local changes can be discarded\ngit fetch origin\ngit reset --hard origin/feat/branch-name\n```\n\n### Committed to Main (Expected Workflow)\n\nWith main-branch development, committing to main is the expected workflow:\n\n```bash\n# Commits are already on main - just push to remote feature branch\ngit push origin main:feat/new-feature\n\n# Create PR using GitHub MCP (head: feat/new-feature, base: main)\n\n# After PR is merged, local main is behind - sync it:\ngit pull origin main  # Fast-forward merge handles this cleanly\n```\n\n**Why this works:**\n- Commits exist on both local main and remote feature branch\n- When PR merges to remote main, your local main is behind by same commits\n- `git pull` recognizes the commits and fast-forwards cleanly\n- No history rewriting, no data loss, no merge conflicts\n\n### Rebase Conflicts Are Too Complex\n\n```bash\n# Abort rebase and use merge instead\ngit rebase --abort\ngit merge main\n```\n\n## Safe Operations\n\n### Recognizing Normal States\n\nThese states are expected during development - proceed confidently:\n\n| State | Meaning | Action |\n|-------|---------|--------|\n| Unstaged changes after pre-commit | Formatters modified files | Stage with `git add -u` and continue |\n| Modified files after running formatters | Expected auto-fix behavior | Stage before committing |\n| Pre-commit exit code 1 | Files were modified | Stage modifications, re-run pre-commit |\n| Branch behind remote | Remote has newer commits | Pull or rebase as appropriate |\n\n### Confirmation-Required Commands\n\nRequest user confirmation before running destructive commands:\n\n```bash\n# These require explicit user approval:\ngit branch -d/-D       # \"Delete local branch X?\"\ngit push origin --delete  # \"Delete remote branch X?\"\ngit reset --hard       # \"Discard uncommitted changes?\"\ngit clean -fd          # \"Remove untracked files?\"\n```\n\n### When State is Unclear\n\nWhen encountering unexpected state:\n1. Run diagnostic commands (`git status`, `git log --oneline -5`)\n2. Report findings clearly\n3. Present options and wait for guidance\n\n## Recovery Workflows\n\n### Pre-commit Modifies Files\n\nThis is normal formatter/linter behavior:\n\n```bash\n# 1. Check what changed\ngit status\n\n# 2. Stage modified files\ngit add -u\n\n# 3. Continue with commit\ngit commit -m \"feat(feature): description\"\n```\n\n### Push Rejected (Non-Fast-Forward)\n\nRemote has newer commits:\n\n```bash\n# Option 1: Rebase local changes on top (preferred for linear history)\ngit pull --rebase origin <branch>\n\n# Option 2: Merge remote changes\ngit pull origin <branch>\n\n# Option 3: Overwrite remote (your branch only, use cautiously)\ngit push --force-with-lease\n```\n\n### Commit Fails\n\n1. Read the error message\n2. Common causes:\n   - Pre-commit hooks failed  Fix issues and retry\n   - No staged changes  Stage files first\n   - Empty commit message  Provide message\n3. Fix the underlying issue and retry"
              },
              {
                "name": "git-commit-workflow",
                "description": "Commit message conventions, staging practices, and commit best practices.\nCovers conventional commits, explicit staging workflow, logical change grouping,\nand humble fact-based communication style.\nUse when user mentions committing changes, writing commit messages, git add,\ngit commit, staging files, or conventional commit format.\n",
                "path": "git-plugin/skills/git-commit-workflow/SKILL.md",
                "frontmatter": {
                  "created": "2025-12-16T00:00:00.000Z",
                  "modified": "2025-12-16T00:00:00.000Z",
                  "reviewed": "2025-12-16T00:00:00.000Z",
                  "name": "git-commit-workflow",
                  "description": "Commit message conventions, staging practices, and commit best practices.\nCovers conventional commits, explicit staging workflow, logical change grouping,\nand humble fact-based communication style.\nUse when user mentions committing changes, writing commit messages, git add,\ngit commit, staging files, or conventional commit format.\n",
                  "allowed-tools": "Bash, Read"
                },
                "content": "# Git Commit Workflow\n\nExpert guidance for commit message conventions, staging practices, and commit best practices using conventional commits and explicit staging workflows.\n\n## Core Expertise\n\n- **Conventional Commits**: Standardized format for automation and clarity\n- **Explicit Staging**: Always stage files individually with clear visibility\n- **Logical Grouping**: Group related changes into focused commits\n- **Communication Style**: Humble, factual, concise commit messages\n- **Pre-commit Integration**: Run checks before committing\n\n**Note:** Commits are made on main branch and pushed to remote feature branches for PRs. See **git-branch-pr-workflow** skill for the main-branch development pattern.\n\n## Conventional Commit Format\n\n### Standard Format\n\n```\ntype(scope): description\n\n[optional body]\n\n[optional footer(s)]\n```\n\n### Commit Types\n\n- **feat**: New feature for the user\n- **fix**: Bug fix for the user\n- **docs**: Documentation changes\n- **style**: Formatting, missing semicolons, etc (no code change)\n- **refactor**: Code restructuring without changing behavior\n- **test**: Adding or updating tests\n- **chore**: Maintenance tasks, dependency updates, linter fixes\n- **perf**: Performance improvements\n- **ci**: CI/CD changes\n\n### Examples\n\n```bash\n# Feature with scope\ngit commit -m \"feat(auth): implement OAuth2 integration\"\n\n# Bug fix with body\ngit commit -m \"fix(api): resolve null pointer in user service\n\nFixed race condition where user object could be null during\nconcurrent authentication requests.\"\n\n# Documentation update\ngit commit -m \"docs(readme): update installation instructions\"\n\n# Breaking change\ngit commit -m \"feat(api)!: migrate to GraphQL endpoints\n\nBREAKING CHANGE: REST endpoints removed in favor of GraphQL.\nSee migration guide at docs/migration.md\"\n\n# Multiple fixes\ngit commit -m \"fix(auth): resolve login validation issues\n\n- Handle empty email addresses\n- Validate password strength requirements\n- Add rate limiting to prevent brute force\n\nFixes #123, #124\"\n```\n\n### Commit Message Best Practices\n\n**DO:**\n- Use imperative mood (\"add feature\" not \"added feature\")\n- Keep first line under 72 characters\n- Be concise and factual\n- **ALWAYS reference related issues** - every commit should link to relevant issues\n- Use GitHub closing keywords: `Fixes #123`, `Closes #456`, `Resolves #789`\n- Use `Refs #N` for related issues that shouldn't auto-close\n- Use lowercase for type and scope\n- Be humble and modest\n\n**DON'T:**\n- Use past tense (\"added\" or \"fixed\")\n- Include unnecessary details in subject line\n- Use vague descriptions (\"update stuff\", \"fix bug\")\n- **Omit issue references** - always link commits to their context\n- Use closing keywords (`Fixes`) when you only mean to reference (`Refs`)\n\n### Scope Guidelines\n\nCommon scopes by area:\n\n```bash\n# Feature areas\nfeat(auth): login system changes\nfeat(api): API endpoint changes\nfeat(ui): user interface changes\nfeat(db): database schema changes\n\n# Component-specific\nfix(header): navigation menu bug\nfix(footer): copyright date\nfix(sidebar): responsive layout\n\n# Infrastructure\nchore(deps): dependency updates\nchore(ci): CI/CD configuration\nchore(docker): container configuration\n```\n\n## Explicit Staging Workflow\n\n### Always Stage Files Individually\n\n```bash\n# Show current status\ngit status --porcelain\n\n# Stage files one by one for visibility\ngit add src/auth/login.ts\ngit add src/auth/oauth.ts\ngit status  # Verify what's staged\n\n# Show what will be committed\ngit diff --cached --stat\ngit diff --cached  # Review actual changes\n\n# Commit with conventional message\ngit commit -m \"feat(auth): add OAuth2 support\"\n```\n\n### Pre-commit Hook Integration\n\nPre-commit hooks often AUTO-MODIFY files (formatters, linters with autofix). This is expected behavior.\n\n```bash\n# 1. Run pre-commit checks\npre-commit run --all-files --show-diff-on-failure\n\n# 2. Check if pre-commit modified any files\ngit status --porcelain\n# M  src/file.ts     <- Modified by pre-commit (formatting)\n\n# 3. Stage modified tracked files (original + pre-commit modifications)\ngit add -u\n\n# 4. Verify pre-commit passes now\npre-commit run --all-files  # Should exit 0\n\n# 5. Commit with all changes\ngit commit -m \"feat(feature): add feature with formatting fixes\"\n```\n\n**Understanding Pre-commit Exit Codes:**\n- Exit 0: All hooks passed\n- Exit 1: Hook failed OR files were modified (re-stage and re-run)\n\nPre-commit file modifications are normal - stage them and proceed with the commit.\n\n### Explicit Staging Best Practices\n\n```bash\n#  Explicit staging with review\ngit status\ngit add src/feature/new-file.ts\ngit add tests/feature.test.ts\ngit diff --cached --stat\ngit commit -m \"feat(feature): add new feature with tests\"\n```\n\n## Logical Change Grouping\n\n### Group Related Changes\n\n```bash\n# Example: Authentication feature with multiple files\n# Group 1: Core implementation\ngit add src/auth/oauth.ts\ngit add src/auth/token.ts\ngit commit -m \"feat(auth): implement OAuth2 token handling\"\n\n# Group 2: Tests\ngit add tests/auth/oauth.test.ts\ngit add tests/auth/token.test.ts\ngit commit -m \"test(auth): add OAuth2 integration tests\"\n\n# Group 3: Documentation\ngit add docs/api/authentication.md\ngit add README.md\ngit commit -m \"docs(auth): document OAuth2 flow\"\n```\n\n### Separate Concerns\n\n```bash\n# Example: Mixed changes\n# Separate linter fixes from feature work\n\n# Group 1: Linter/formatting (chore commit)\ngit add src/**/*.ts  # (only formatting changes)\ngit add .eslintrc\ngit commit -m \"chore(lint): apply ESLint fixes and update config\"\n\n# Group 2: Feature implementation (feat commit)\ngit add src/feature/implementation.ts\ngit add tests/feature.test.ts\ngit commit -m \"feat(feature): add new user management feature\"\n```\n\n### Change Classification\n\n**Linter/Formatting Group:**\n- Whitespace-only changes\n- Lock files (package-lock.json, Cargo.lock)\n- Auto-generated linter configs\n- Commit type: `chore`\n\n**Feature/Fix Groups:**\n- Implementation code\n- Related tests\n- Relevant documentation\n- Commit type: `feat`, `fix`, `refactor`\n\n**Documentation Group:**\n- README updates\n- API documentation\n- User guides\n- Commit type: `docs`\n\n## Communication Style\n\n### Humble, Fact-Based Messages\n\n```bash\n#  GOOD: Concise, factual, modest\ngit commit -m \"fix(auth): handle edge case in token refresh\"\n\ngit commit -m \"feat(api): add pagination support\n\nImplements cursor-based pagination for list endpoints.\nIncludes tests and documentation.\"\n\n#  BAD: Vague, verbose, or overly confident\ngit commit -m \"fix stuff\"\ngit commit -m \"AMAZING new feature that revolutionizes everything!!!\"\ngit commit -m \"Updated some files to make things work better and faster\"\n```\n\n### Focus on Facts\n\n- **What changed**: Describe the change objectively\n- **Why it changed**: Explain the reason if non-obvious\n- **Impact**: Note breaking changes or important effects\n\n```bash\n# Example with context\ngit commit -m \"perf(db): optimize user query with index\n\nAdded composite index on (user_id, created_at) to improve\nquery performance for user activity feeds.\n\nReduces query time from 800ms to 45ms for typical workloads.\"\n```\n\n## Workflow Examples\n\n### Complete Staging and Commit Flow\n\n```bash\n# 1. Check current state\ngit status\n\n# 2. Run pre-commit checks\npre-commit run --all-files\n\n# 3. Stage files explicitly\ngit add src/feature.ts\ngit add tests/feature.test.ts\n\n# 4. Review what's staged\ngit status\ngit diff --cached --stat\n\n# 5. Commit with conventional message\ngit commit -m \"feat(feature): add new capability\n\nImplements X feature with Y functionality.\nIncludes unit tests and integration tests.\n\nCloses #123\"\n\n# 6. Verify commit\ngit log -1 --stat\n```\n\n### Amending Commits\n\n```bash\n# Fix last commit (before pushing)\ngit add forgotten-file.ts\ngit commit --amend --no-edit\n\n# Update commit message\ngit commit --amend -m \"feat(auth): improved OAuth2 implementation\"\n```\n\n### Interactive Staging\n\n```bash\n# Stage parts of a file\ngit add -p file.ts\n\n# Review hunks and choose:\n# y - stage this hunk\n# n - do not stage\n# s - split into smaller hunks\n# e - manually edit hunk\n```\n\n## Best Practices\n\n### Commit Frequency\n\n- **Commit early and often**: Small, focused commits\n- **One logical change per commit**: Easier to review and revert\n- **Keep commits atomic**: Each commit should be a complete, working state\n\n### Commit Message Length\n\n```bash\n# Subject line:  72 characters\nfeat(auth): add OAuth2 support\n\n# Body:  72 characters per line (wrap)\n# Use blank line between subject and body\n```\n\n### GitHub Issue References (Autolink Format)\n\n**ALWAYS reference related GitHub issues in commit messages.** This creates traceability, enables project management, and provides context for future code archaeology.\n\n#### Autolink Reference Formats\n\nGitHub automatically converts these patterns into clickable links:\n\n| Format | Example | Use Case |\n|--------|---------|----------|\n| `#N` | `#123` | Same repository issue/PR |\n| `GH-N` | `GH-123` | Alternative same-repo format |\n| `owner/repo#N` | `octo-org/api#456` | Cross-repository reference |\n\n#### Closing Keywords\n\nGitHub recognizes **9 keywords** to automatically close issues when commits merge to the default branch:\n\n| Keyword | Variants | Effect |\n|---------|----------|--------|\n| close | `close`, `closes`, `closed` | Closes the issue |\n| fix | `fix`, `fixes`, `fixed` | Closes the issue |\n| resolve | `resolve`, `resolves`, `resolved` | Closes the issue |\n\n#### Reference Syntax Patterns\n\n```bash\n# Close issue in same repository\nFixes #123\nCloses #456\nResolves #789\n\n# Close issue in different repository\nFixes octo-org/octo-repo#100\n\n# Close multiple issues (use full keyword for each)\nFixes #123, fixes #456, fixes #789\n\n# Reference without closing (for related context)\nRefs #234\nRelated to #567\nSee #890\n```\n\n#### Formatting Flexibility\n\n- **Case insensitive:** `FIXES #123`, `Fixes #123`, `fixes #123`\n- **Optional colon:** `Fixes: #123`, `Fixes #123`\n- **Whitespace:** `Fixes #123` or `Fixes#123` (space optional)\n\n#### When to Use Each Pattern\n\n| Scenario | Pattern | Example |\n|----------|---------|---------|\n| Bug fix that resolves an issue | `Fixes #N` | `Fixes #123` |\n| Feature that completes an issue | `Closes #N` | `Closes #456` |\n| Work related to but not completing issue | `Refs #N` | `Refs #789` |\n| Partial progress on larger issue | `Refs #N` | `Refs #101` |\n| Breaking change with migration guide | `See #N` | `See #202` |\n\n**Important:** Keywords only auto-close issues when merged to the **default branch**. PRs targeting other branches link but don't auto-close.\n\n### Issue Reference Examples\n\n```bash\n# Fix with auto-close (single issue)\ngit commit -m \"fix(api): handle timeout\n\nFixes #123\"\n\n# Feature linked to multiple issues\ngit commit -m \"feat(ui): redesign dashboard\n\nImplements designs from #456\nCloses #457, closes #458\"\n\n# Cross-repository reference\ngit commit -m \"fix(shared): resolve validation bug\n\nFixes org/shared-lib#42\"\n\n# Breaking change with migration reference\ngit commit -m \"feat(api)!: change authentication\n\nBREAKING CHANGE: API key format changed.\nSee migration guide: #789\"\n\n# Reference without closing (use \"Refs\" or \"Related to\")\ngit commit -m \"refactor(auth): extract token validation\n\nRefs #234\"\n```\n\n## Troubleshooting\n\n### Accidentally Staged Wrong Files\n\n```bash\n# Unstage specific file\ngit restore --staged wrong-file.ts\n\n# Unstage all\ngit restore --staged .\n```\n\n### Wrong Commit Message\n\n```bash\n# Amend last commit message (before push)\ngit commit --amend -m \"corrected message\"\n\n# After push (prefer pre-push correction when possible)\ngit commit --amend -m \"corrected message\"\ngit push --force-with-lease origin branch-name\n```\n\n### Forgot to Add File to Last Commit\n\n```bash\n# Add file and amend\ngit add forgotten-file.ts\ngit commit --amend --no-edit\n```\n\n### Need to Split Last Commit\n\n```bash\n# Undo last commit but keep changes staged\ngit reset --soft HEAD~1\n\n# Unstage all\ngit restore --staged .\n\n# Stage and commit in groups\ngit add group1-file.ts\ngit commit -m \"first logical group\"\n\ngit add group2-file.ts\ngit commit -m \"second logical group\"\n```"
              },
              {
                "name": "Git Repository Detection",
                "description": "Detect GitHub repository name and owner from git remotes. Use when needing repo identifier for GitHub CLI, API calls, or when working with multiple repositories. Automatically extracts owner/repo format.",
                "path": "git-plugin/skills/git-repo-detection/SKILL.md",
                "frontmatter": {
                  "created": "2025-12-16T00:00:00.000Z",
                  "modified": "2025-12-16T00:00:00.000Z",
                  "reviewed": "2025-12-16T00:00:00.000Z",
                  "name": "Git Repository Detection",
                  "description": "Detect GitHub repository name and owner from git remotes. Use when needing repo identifier for GitHub CLI, API calls, or when working with multiple repositories. Automatically extracts owner/repo format.",
                  "allowed-tools": "Bash, Read, Grep"
                },
                "content": "# Git Repository Detection\n\nExpert knowledge for detecting and extracting GitHub repository information from git remotes, including repository name, owner, and full identifiers.\n\n## Core Expertise\n\n**Repository Identification**\n- Extract owner and repository name from git remotes\n- Parse GitHub URLs (HTTPS and SSH)\n- Handle GitHub Enterprise URLs\n- Format as `owner/repo` for CLI/API usage\n\n**URL Parsing**\n- Parse HTTPS URLs: `https://github.com/owner/repo.git`\n- Parse SSH URLs: `git@github.com:owner/repo.git`\n- Handle custom domains: `https://github.enterprise.com/owner/repo.git`\n- Clean `.git` suffix and extra paths\n\n## Essential Commands\n\n### Get Remote URLs\n\n```bash\n# List all remotes\ngit remote -v\n\n# Get origin URL\ngit remote get-url origin\n\n# Get specific remote\ngit remote get-url upstream\n\n# Show remote details\ngit remote show origin\n```\n\n### Extract Repository Name\n\n```bash\n# From HTTPS URL\ngit remote get-url origin | sed 's/.*\\/\\([^/]*\\)\\.git/\\1/'\n\n# From SSH URL\ngit remote get-url origin | sed 's/.*:\\([^/]*\\/[^/]*\\)\\.git/\\1/' | cut -d'/' -f2\n\n# From any URL (owner/repo format)\ngit remote get-url origin | sed 's/.*[:/]\\([^/]*\\/[^/]*\\)\\.git/\\1/'\n\n# Just repository name (no owner)\nbasename $(git remote get-url origin) .git\n```\n\n### Extract Owner\n\n```bash\n# From any URL\ngit remote get-url origin | sed 's/.*[:/]\\([^/]*\\)\\/[^/]*\\.git/\\1/'\n\n# Alternative with awk\ngit remote get-url origin | awk -F '[:/]' '{print $(NF-1)}'\n```\n\n### Get Full Identifier (owner/repo)\n\n```bash\n# Standard format for GitHub CLI/API\ngit remote get-url origin | sed 's/.*[:/]\\([^/]*\\/[^/]*\\)\\.git/\\1/'\n\n# With validation\nREPO=$(git remote get-url origin 2>/dev/null | sed 's/.*[:/]\\([^/]*\\/[^/]*\\)\\.git/\\1/')\necho \"${REPO:-Unknown}\"\n\n# Store in variable\nREPO_FULL=$(git remote get-url origin | sed 's/.*[:/]\\([^/]*\\/[^/]*\\)\\.git/\\1/')\necho \"Repository: $REPO_FULL\"\n```\n\n## URL Format Examples\n\n### HTTPS URLs\n\n```bash\n# Standard GitHub\nhttps://github.com/owner/repo.git\n# Extract: owner/repo\n\n# Without .git suffix\nhttps://github.com/owner/repo\n# Extract: owner/repo\n\n# GitHub Enterprise\nhttps://github.company.com/owner/repo.git\n# Extract: owner/repo\n```\n\n### SSH URLs\n\n```bash\n# Standard SSH\ngit@github.com:owner/repo.git\n# Extract: owner/repo\n\n# Custom SSH port\nssh://git@github.com:443/owner/repo.git\n# Extract: owner/repo\n\n# Enterprise SSH\ngit@github.company.com:owner/repo.git\n# Extract: owner/repo\n```\n\n## Parsing Patterns\n\n### Universal Parser (HTTPS or SSH)\n\n```bash\n# Works for both HTTPS and SSH\nparse_repo() {\n  local url=\"$1\"\n  # Remove .git suffix\n  url=\"${url%.git}\"\n  # Extract owner/repo\n  if [[ \"$url\" =~ github\\.com[:/]([^/]+/[^/]+) ]]; then\n    echo \"${BASH_REMATCH[1]}\"\n  elif [[ \"$url\" =~ :([^/]+/[^/]+)$ ]]; then\n    echo \"${BASH_REMATCH[1]}\"\n  fi\n}\n\nREPO=$(parse_repo \"$(git remote get-url origin)\")\necho \"$REPO\"\n```\n\n### Robust Extraction with sed\n\n```bash\n# Handle both HTTPS and SSH, with or without .git\ngit remote get-url origin \\\n  | sed -E 's#.*github\\.com[:/]##; s#\\.git$##'\n```\n\n### Using awk\n\n```bash\n# Split by : or / and get last two components\ngit remote get-url origin \\\n  | awk -F'[/:]' '{print $(NF-1)\"/\"$NF}' \\\n  | sed 's/\\.git$//'\n```\n\n## Real-World Usage\n\n### With GitHub CLI\n\n```bash\n# Get repo identifier for gh commands\nREPO=$(git remote get-url origin | sed 's/.*[:/]\\([^/]*\\/[^/]*\\)\\.git/\\1/')\n\n# Use with gh\ngh repo view \"$REPO\"\ngh issue list --repo \"$REPO\"\ngh pr list --repo \"$REPO\"\n\n# Or use current directory (gh auto-detects)\ngh repo view\n```\n\n### With GitHub API\n\n```bash\n# Extract for API calls\nREPO=$(git remote get-url origin | sed 's/.*[:/]\\([^/]*\\/[^/]*\\)\\.git/\\1/')\nOWNER=$(echo \"$REPO\" | cut -d'/' -f1)\nREPO_NAME=$(echo \"$REPO\" | cut -d'/' -f2)\n\n# API request\ncurl -H \"Authorization: token $GITHUB_TOKEN\" \\\n  \"https://api.github.com/repos/$OWNER/$REPO_NAME\"\n\n# Or use full identifier\ncurl -H \"Authorization: token $GITHUB_TOKEN\" \\\n  \"https://api.github.com/repos/$REPO\"\n```\n\n### Check Multiple Remotes\n\n```bash\n# List all remotes with parsed names\ngit remote | while read remote; do\n  url=$(git remote get-url \"$remote\")\n  repo=$(echo \"$url\" | sed 's/.*[:/]\\([^/]*\\/[^/]*\\)\\.git/\\1/')\n  echo \"$remote: $repo\"\ndone\n\n# Output:\n# origin: owner/repo\n# upstream: original-owner/repo\n```\n\n### Validate Repository Exists\n\n```bash\n# Extract and validate\nREPO=$(git remote get-url origin | sed 's/.*[:/]\\([^/]*\\/[^/]*\\)\\.git/\\1/')\n\n# Check if repo exists on GitHub\nif gh repo view \"$REPO\" &>/dev/null; then\n  echo \"Repository exists: $REPO\"\nelse\n  echo \"Repository not found or not accessible: $REPO\"\nfi\n```\n\n### Clone URL from Identifier\n\n```bash\n# Given owner/repo, construct URLs\nREPO=\"owner/repo\"\n\n# HTTPS\necho \"https://github.com/${REPO}.git\"\n\n# SSH\necho \"git@github.com:${REPO}.git\"\n```\n\n## Common Patterns\n\n### Script Integration\n\n```bash\n#!/bin/bash\n# Get repository info for current directory\n\nget_repo_info() {\n  local origin_url=$(git remote get-url origin 2>/dev/null)\n\n  if [[ -z \"$origin_url\" ]]; then\n    echo \"Error: Not a git repository or no origin remote\" >&2\n    return 1\n  fi\n\n  # Extract owner/repo\n  local repo=$(echo \"$origin_url\" | sed 's/.*[:/]\\([^/]*\\/[^/]*\\)\\.git/\\1/')\n\n  # Split into owner and name\n  local owner=$(echo \"$repo\" | cut -d'/' -f1)\n  local name=$(echo \"$repo\" | cut -d'/' -f2)\n\n  echo \"Full: $repo\"\n  echo \"Owner: $owner\"\n  echo \"Name: $name\"\n}\n\nget_repo_info\n```\n\n### Environment Variables\n\n```bash\n# Set repo variables for scripts\nexport REPO_FULL=$(git remote get-url origin | sed 's/.*[:/]\\([^/]*\\/[^/]*\\)\\.git/\\1/')\nexport REPO_OWNER=$(echo \"$REPO_FULL\" | cut -d'/' -f1)\nexport REPO_NAME=$(echo \"$REPO_FULL\" | cut -d'/' -f2)\n\n# Use in scripts\ngh issue create --repo \"$REPO_FULL\" --title \"Bug Report\"\n```\n\n### Aliases\n\n```bash\n# Add to ~/.gitconfig or ~/.bashrc\n\n# Git alias\ngit config --global alias.repo-name \"!git remote get-url origin | sed 's/.*[\\\\/:]\\\\([^\\\\/]*\\\\/[^\\\\/]*\\\\)\\\\.git/\\\\1/'\"\n\n# Usage\ngit repo-name\n\n# Shell alias\nalias repo='git remote get-url origin | sed \"s/.*[:/]\\([^/]*\\/[^/]*\\)\\.git/\\1/\"'\n\n# Usage\nrepo\n```\n\n## Edge Cases and Error Handling\n\n### No Remote\n\n```bash\n# Check if remote exists\nif git remote get-url origin &>/dev/null; then\n  REPO=$(git remote get-url origin | sed 's/.*[:/]\\([^/]*\\/[^/]*\\)\\.git/\\1/')\n  echo \"Repository: $REPO\"\nelse\n  echo \"Error: No origin remote configured\"\nfi\n```\n\n### Multiple Remotes\n\n```bash\n# Use specific remote (origin, upstream, etc.)\nREMOTE=\"${1:-origin}\"\n\nif git remote get-url \"$REMOTE\" &>/dev/null; then\n  REPO=$(git remote get-url \"$REMOTE\" | sed 's/.*[:/]\\([^/]*\\/[^/]*\\)\\.git/\\1/')\n  echo \"Repository ($REMOTE): $REPO\"\nelse\n  echo \"Error: Remote '$REMOTE' not found\"\nfi\n```\n\n### Non-GitHub Remotes\n\n```bash\n# Check if it's a GitHub URL\nURL=$(git remote get-url origin)\n\nif [[ \"$URL\" =~ github\\.com ]]; then\n  REPO=$(echo \"$URL\" | sed 's/.*[:/]\\([^/]*\\/[^/]*\\)\\.git/\\1/')\n  echo \"GitHub Repository: $REPO\"\nelse\n  echo \"Not a GitHub repository: $URL\"\nfi\n```\n\n### Submodules\n\n```bash\n# Get parent repo\nPARENT_REPO=$(git -C \"$(git rev-parse --show-toplevel)\" remote get-url origin \\\n  | sed 's/.*[:/]\\([^/]*\\/[^/]*\\)\\.git/\\1/')\n\n# Get submodule repo\nSUBMODULE_REPO=$(git remote get-url origin | sed 's/.*[:/]\\([^/]*\\/[^/]*\\)\\.git/\\1/')\n```\n\n## Integration Examples\n\n### With Makefile\n\n```makefile\n# Makefile\nREPO := $(shell git remote get-url origin | sed 's/.*[:/]\\([^\\/]*\\/[^\\/]*\\)\\.git/\\1/')\nOWNER := $(shell echo $(REPO) | cut -d'/' -f1)\nNAME := $(shell echo $(REPO) | cut -d'/' -f2)\n\n.PHONY: info\ninfo:\n\t@echo \"Repository: $(REPO)\"\n\t@echo \"Owner: $(OWNER)\"\n\t@echo \"Name: $(NAME)\"\n\n.PHONY: open\nopen:\n\t@open \"https://github.com/$(REPO)\"\n```\n\n### With Shell Scripts\n\n```bash\n#!/bin/bash\n# deploy.sh\n\nset -e\n\n# Get repository identifier\nREPO=$(git remote get-url origin | sed 's/.*[:/]\\([^/]*\\/[^/]*\\)\\.git/\\1/')\n\nif [[ -z \"$REPO\" ]]; then\n  echo \"Error: Could not determine repository\" >&2\n  exit 1\nfi\n\necho \"Deploying $REPO...\"\n\n# Use repo identifier\ngh workflow run deploy.yml --repo \"$REPO\"\n```\n\n### With Python Scripts\n\n```python\n#!/usr/bin/env python3\nimport subprocess\nimport re\n\ndef get_repo_name():\n    \"\"\"Extract GitHub repository owner/name from git remote.\"\"\"\n    try:\n        result = subprocess.run(\n            ['git', 'remote', 'get-url', 'origin'],\n            capture_output=True,\n            text=True,\n            check=True\n        )\n        url = result.stdout.strip()\n\n        # Parse owner/repo from URL\n        match = re.search(r'github\\.com[:/](.+/.+?)(?:\\.git)?$', url)\n        if match:\n            return match.group(1)\n        return None\n    except subprocess.CalledProcessError:\n        return None\n\nif __name__ == '__main__':\n    repo = get_repo_name()\n    if repo:\n        print(f\"Repository: {repo}\")\n    else:\n        print(\"Error: Could not determine repository\")\n```\n\n## Quick Reference\n\n### One-Liners\n\n```bash\n# Full identifier (owner/repo)\ngit remote get-url origin | sed 's/.*[:/]\\([^/]*\\/[^/]*\\)\\.git/\\1/'\n\n# Owner only\ngit remote get-url origin | sed 's/.*[:/]\\([^/]*\\)\\/[^/]*\\.git/\\1/'\n\n# Name only\nbasename $(git remote get-url origin) .git\n\n# Check if GitHub repo\ngit remote get-url origin | grep -q github.com && echo \"GitHub\" || echo \"Not GitHub\"\n```\n\n### Common Commands\n\n```bash\n# View on GitHub (macOS)\nopen \"https://github.com/$(git remote get-url origin | sed 's/.*[:/]\\([^/]*\\/[^/]*\\)\\.git/\\1/')\"\n\n# View on GitHub (Linux)\nxdg-open \"https://github.com/$(git remote get-url origin | sed 's/.*[:/]\\([^/]*\\/[^/]*\\)\\.git/\\1/')\"\n\n# Copy to clipboard (macOS)\ngit remote get-url origin | sed 's/.*[:/]\\([^/]*\\/[^/]*\\)\\.git/\\1/' | pbcopy\n\n# Copy to clipboard (Linux)\ngit remote get-url origin | sed 's/.*[:/]\\([^/]*\\/[^/]*\\)\\.git/\\1/' | xclip -selection clipboard\n```\n\n### Validation\n\n```bash\n# Ensure in git repo\ngit rev-parse --git-dir &>/dev/null || { echo \"Not a git repository\"; exit 1; }\n\n# Ensure origin exists\ngit remote get-url origin &>/dev/null || { echo \"No origin remote\"; exit 1; }\n\n# Ensure it's GitHub\ngit remote get-url origin | grep -q github.com || { echo \"Not a GitHub repo\"; exit 1; }\n```\n\n## Troubleshooting\n\n### Remote Not Found\n```bash\n# Check configured remotes\ngit remote -v\n\n# Add origin if missing\ngit remote add origin git@github.com:owner/repo.git\n```\n\n### Wrong Remote\n```bash\n# Use different remote\ngit remote get-url upstream\n\n# Set correct origin\ngit remote set-url origin git@github.com:owner/repo.git\n```\n\n### Parse Failure\n```bash\n# Debug: Show raw URL\ngit remote get-url origin\n\n# Check format matches expected pattern\n# HTTPS: https://github.com/owner/repo.git\n# SSH:   git@github.com:owner/repo.git\n```\n\n## Best Practices\n\n**Caching**\n- Cache repository identifier in scripts\n- Don't repeatedly call git commands\n- Store in environment variables\n\n**Error Handling**\n- Always check if remote exists\n- Validate URL format before parsing\n- Provide fallback values\n\n**Portability**\n- Use portable sed/awk syntax\n- Test on different shells (bash, zsh, etc.)\n- Handle both HTTPS and SSH URLs\n\n**Security**\n- Don't expose tokens in URLs\n- Use SSH for private repositories\n- Validate repository access\n\n## Integration with Other Skills\n\n**Combine with:**\n- **github MCP** - Use extracted repo name with GitHub API\n- **github-actions-inspection** - Pass repo to gh CLI commands\n- **git-workflow** - Identify repo for workflow operations\n\n**Workflow:**\n1. Detect repository (this skill)\n2. Use identifier with GitHub CLI/API\n3. Perform operations on correct repository\n\n## Resources\n\n- **git remote documentation**: `man git-remote`\n- **GitHub CLI**: Uses repository detection automatically\n- **GitHub API**: Requires `owner/repo` format"
              },
              {
                "name": "git-security-checks",
                "description": "Pre-commit security validation and secret detection. Runs detect-secrets scan\nand audit workflow, validates secrets baseline, and integrates with pre-commit\nhooks to prevent credential leaks.\nUse when user mentions scanning for secrets, detect-secrets, secret detection,\ncredential scanning, pre-commit security, or .secrets.baseline.\n",
                "path": "git-plugin/skills/git-security-checks/SKILL.md",
                "frontmatter": {
                  "created": "2025-12-16T00:00:00.000Z",
                  "modified": "2025-12-16T00:00:00.000Z",
                  "reviewed": "2025-12-16T00:00:00.000Z",
                  "name": "git-security-checks",
                  "description": "Pre-commit security validation and secret detection. Runs detect-secrets scan\nand audit workflow, validates secrets baseline, and integrates with pre-commit\nhooks to prevent credential leaks.\nUse when user mentions scanning for secrets, detect-secrets, secret detection,\ncredential scanning, pre-commit security, or .secrets.baseline.\n",
                  "allowed-tools": "Bash, Read"
                },
                "content": "# Git Security Checks\n\nExpert guidance for pre-commit security validation and secret detection using detect-secrets and pre-commit hooks.\n\n## Core Expertise\n\n- **detect-secrets**: Scan for hardcoded secrets and credentials\n- **Pre-commit Hooks**: Automated security validation before commits\n- **Secrets Baseline**: Manage false positives and legitimate secrets\n- **Security-First Workflow**: Prevent credential leaks before they happen\n\n## detect-secrets Workflow\n\n### Initial Setup\n\n```bash\n# Install detect-secrets\npip install detect-secrets\n\n# Create initial baseline\ndetect-secrets scan > .secrets.baseline\n\n# Audit baseline for false positives\ndetect-secrets audit .secrets.baseline\n```\n\n### Pre-commit Scan Workflow\n\nRun detect-secrets before every commit:\n\n```bash\n# Scan for new secrets (using existing baseline)\ndetect-secrets scan --baseline .secrets.baseline\n\n# If new secrets detected, audit them\ndetect-secrets audit .secrets.baseline\n\n# Stage the updated baseline\ngit add .secrets.baseline\n```\n\n### Audit Process\n\nWhen new secrets are detected:\n\n```bash\n# Run audit to review flagged items\ndetect-secrets audit .secrets.baseline\n\n# For each detected secret:\n# - Press 'y' if it's a real secret (DON'T COMMIT)\n# - Press 'n' if it's a false positive (safe to commit)\n# - Press 's' to skip for now\n\n# After audit, re-scan to update baseline\ndetect-secrets scan --baseline .secrets.baseline\n```\n\n### Complete Pre-commit Security Flow\n\n```bash\n# 1. Scan for secrets with baseline\ndetect-secrets scan --baseline .secrets.baseline\n\n# 2. If baseline updated, audit new findings\ndetect-secrets audit .secrets.baseline\n\n# 3. Stage the updated baseline\ngit add .secrets.baseline\n\n# 4. Run all pre-commit hooks\npre-commit run --all-files --show-diff-on-failure\n\n# 5. Stage your actual changes\ngit add src/file.ts\n\n# 6. Show what's staged\ngit status\ngit diff --cached --stat\n\n# 7. Commit if everything passes\ngit commit -m \"feat(auth): add authentication module\"\n```\n\n## Pre-commit Hook Integration\n\n### .pre-commit-config.yaml\n\nExample configuration with detect-secrets:\n\n```yaml\nrepos:\n  - repo: https://github.com/Yelp/detect-secrets\n    rev: v1.4.0\n    hooks:\n      - id: detect-secrets\n        args: ['--baseline', '.secrets.baseline']\n        exclude: package-lock.json\n```\n\n### Running Pre-commit Hooks\n\n```bash\n# Run all hooks on all files\npre-commit run --all-files\n\n# Run all hooks on staged files only\npre-commit run\n\n# Run specific hook\npre-commit run detect-secrets\n\n# Show diff on failure for debugging\npre-commit run --all-files --show-diff-on-failure\n\n# Install hooks to run automatically on commit\npre-commit install\n```\n\n## Common Secret Patterns\n\ndetect-secrets scans for:\n\n- **API Keys**: AWS, GitHub, Stripe, etc.\n- **Authentication Tokens**: JWT, OAuth tokens, session tokens\n- **Passwords**: Hardcoded passwords in config files\n- **Private Keys**: RSA, SSH, PGP private keys\n- **Database Credentials**: Connection strings with passwords\n- **Generic Secrets**: High-entropy strings that look like secrets\n\n### Examples of What Gets Detected\n\n```bash\n#  DETECTED: Hardcoded API key\nAPI_KEY = \"sk_live_abc123def456ghi789\"  # pragma: allowlist secret\n\n#  DETECTED: AWS credentials\naws_access_key_id = AKIAIOSFODNN7EXAMPLE  # pragma: allowlist secret\n\n#  DETECTED: Database password\nDB_URL = \"postgresql://user:Pa$$w0rd@localhost/db\"  # pragma: allowlist secret\n\n#  DETECTED: Private key  # pragma: allowlist secret\n-----BEGIN RSA PRIVATE KEY-----  # pragma: allowlist secret\nMIIEpAIBAAKCAQEA...  # pragma: allowlist secret\n```\n\n## Managing False Positives\n\n### Excluding Files\n\nIn `.secrets.baseline`:\n\n```bash\n# Exclude specific files from scanning\ndetect-secrets scan --exclude-files 'package-lock\\.json' > .secrets.baseline\ndetect-secrets scan --exclude-files '.*\\.lock$' > .secrets.baseline\ndetect-secrets scan --exclude-files 'test/.*\\.py' > .secrets.baseline\n```\n\n### Inline Ignore Comments\n\n```python\n# In code, mark false positives  # pragma: allowlist secret\napi_key = \"test-key-1234\"  # pragma: allowlist secret\n\n# Or use detect-secrets specific pragma  # pragma: allowlist secret\npassword = \"fake-password\"  # pragma: allowlist secret\n```\n\n### Baseline Management\n\n```bash\n# Update baseline to include current state\ndetect-secrets scan --baseline .secrets.baseline --update\n\n# Re-audit all secrets in baseline\ndetect-secrets audit .secrets.baseline\n\n# Show secrets in baseline\ncat .secrets.baseline | jq '.results'\n```\n\n## Security Best Practices\n\n### Never Commit Secrets\n\n- **Use environment variables**: Store secrets in .env files (gitignored)\n- **Use secret managers**: AWS Secrets Manager, HashiCorp Vault, etc.\n- **Use CI/CD secrets**: GitHub Secrets, GitLab CI/CD variables\n- **Rotate leaked secrets**: If accidentally committed, rotate immediately\n\n### Secrets File Management\n\n```bash\n# Example .gitignore for secrets\n.env\n.env.local\n.env.*.local\n*.pem\n*.key\ncredentials.json\nconfig/secrets.yml\n.api_tokens\n```\n\n### Handling Legitimate Secrets in Repo\n\nFor test fixtures or examples:\n\n```bash\n# 1. Use obviously fake values\nAPI_KEY = \"fake-key-for-testing-only\"  # pragma: allowlist secret\n\n# 2. Use placeholders\nAPI_KEY = \"<your-api-key-here>\"  # pragma: allowlist secret\n\n# 3. Mark in baseline as false positive\ndetect-secrets audit .secrets.baseline  # mark as 'n'\n```\n\n## Emergency: Secret Leaked to Git History\n\nIf a secret is committed and pushed:\n\n### Immediate Actions\n\n```bash\n# 1. ROTATE THE SECRET IMMEDIATELY\n# - Change passwords, revoke API keys, regenerate tokens\n# - Do this BEFORE cleaning git history\n\n# 2. Remove from current commit (if just committed)\ngit reset --soft HEAD~1\n# Remove secret from files\ngit add .\ngit commit -m \"fix(security): remove leaked credentials\"\n\n# 3. Force push (if not shared widely)\ngit push --force-with-lease origin branch-name\n```\n\n### Full History Cleanup\n\n```bash\n# Use git-filter-repo to remove from all history\npip install git-filter-repo\n\n# Remove specific file from all history\ngit filter-repo --path path/to/secret/file --invert-paths\n\n# Remove specific string from all files\ngit filter-repo --replace-text <(echo \"SECRET_KEY=abc123==>SECRET_KEY=REDACTED\")\n```\n\n### Prevention\n\n```bash\n# Always run security checks before committing\npre-commit run detect-secrets\n\n# Check what's being committed\ngit diff --cached\n\n# Use .gitignore for sensitive files\necho \".env\" >> .gitignore\necho \".api_tokens\" >> .gitignore\n```\n\n## Workflow Integration\n\n### Daily Development Flow\n\n```bash\n# Before staging any files\ndetect-secrets scan --baseline .secrets.baseline\npre-commit run --all-files\n\n# If secrets detected\ndetect-secrets audit .secrets.baseline\n# Review and mark false positives\n\n# Stage changes\ngit add .secrets.baseline  # If updated\ngit add src/feature.ts\n\n# Final check before commit\ngit diff --cached  # Review changes\ndetect-secrets scan --baseline .secrets.baseline  # One more scan\n\n# Commit\ngit commit -m \"feat(feature): add new capability\"\n```\n\n### CI/CD Integration\n\n```yaml\n# Example GitHub Actions workflow\nname: Security Checks\n\non: [push, pull_request]\n\njobs:\n  security:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - name: Install detect-secrets\n        run: pip install detect-secrets\n      - name: Scan for secrets\n        run: detect-secrets scan --baseline .secrets.baseline --fail-on-unaudited\n```\n\n## Troubleshooting\n\n### Baseline Out of Sync\n\n```bash\n# Re-generate baseline from scratch\ndetect-secrets scan > .secrets.baseline.new\ndetect-secrets audit .secrets.baseline.new\nmv .secrets.baseline.new .secrets.baseline\n```\n\n### Too Many False Positives\n\n```bash\n# Exclude file patterns\ndetect-secrets scan --exclude-files 'test/.*' > .secrets.baseline\n\n# Reduce sensitivity (use cautiously)\ndetect-secrets scan --base64-limit 4.5 > .secrets.baseline\n```\n\n### Pre-commit Hook Failing\n\n```bash\n# Run pre-commit in verbose mode\npre-commit run detect-secrets --verbose\n\n# Check baseline file exists\nls -la .secrets.baseline\n\n# Update pre-commit hooks\npre-commit autoupdate\n```\n\n### Secret Detected But File Not Changed\n\n```bash\n# Baseline may be stale\ndetect-secrets scan --baseline .secrets.baseline --update\n\n# Audit to clear false positives\ndetect-secrets audit .secrets.baseline\n```\n\n## Tools Reference\n\n### detect-secrets Commands\n\n```bash\n# Scan for secrets\ndetect-secrets scan\n\n# Scan with baseline\ndetect-secrets scan --baseline .secrets.baseline\n\n# Audit baseline\ndetect-secrets audit .secrets.baseline\n\n# Update baseline\ndetect-secrets scan --baseline .secrets.baseline --update\n\n# Exclude files\ndetect-secrets scan --exclude-files 'pattern'\n\n# Custom plugins\ndetect-secrets scan --list-all-plugins\n```\n\n### pre-commit Commands\n\n```bash\n# Install hooks\npre-commit install\n\n# Run all hooks\npre-commit run --all-files\n\n# Run specific hook\npre-commit run detect-secrets\n\n# Update hook versions\npre-commit autoupdate\n\n# Uninstall hooks\npre-commit uninstall\n```"
              },
              {
                "name": "release-please-configuration",
                "description": "Configures release-please for monorepos and single-package repos. Handles\nmanifest files, component tagging, changelog sections, and extra-files setup.\nUse when setting up automated releases, fixing release workflow issues, or\nconfiguring version bump automation.\n",
                "path": "git-plugin/skills/release-please-configuration/SKILL.md",
                "frontmatter": {
                  "created": "2025-12-28T00:00:00.000Z",
                  "modified": "2025-12-28T00:00:00.000Z",
                  "reviewed": "2025-12-28T00:00:00.000Z",
                  "name": "release-please-configuration",
                  "description": "Configures release-please for monorepos and single-package repos. Handles\nmanifest files, component tagging, changelog sections, and extra-files setup.\nUse when setting up automated releases, fixing release workflow issues, or\nconfiguring version bump automation.\n",
                  "allowed-tools": "Read, Write, Edit, Bash, Grep, Glob, TodoWrite"
                },
                "content": "# Release-Please Configuration\n\nExpert knowledge for configuring Google's release-please for automated releases.\n\n## Core Files\n\n| File | Purpose |\n|------|---------|\n| `release-please-config.json` | Package configuration, changelog sections, extra-files |\n| `.release-please-manifest.json` | Current versions for each package |\n| `.github/workflows/release-please.yml` | GitHub Actions workflow |\n\n## Monorepo Configuration\n\n### Critical Settings for Monorepos\n\n```json\n{\n  \"$schema\": \"https://raw.githubusercontent.com/googleapis/release-please/main/schemas/config.json\",\n  \"include-component-in-tag\": true,\n  \"separate-pull-requests\": true,\n  \"packages\": {\n    \"package-a\": {\n      \"component\": \"package-a\",\n      \"release-type\": \"simple\",\n      \"extra-files\": [\"package-a/version.json\"]\n    }\n  }\n}\n```\n\n**Key Fields:**\n\n| Field | Required | Purpose |\n|-------|----------|---------|\n| `include-component-in-tag` | Yes (monorepo) | Creates `package-a-v1.0.0` tags instead of `v1.0.0` |\n| `component` | Yes (monorepo) | Unique identifier for each package; **must be set for every package** |\n| `separate-pull-requests` | Recommended | Creates per-package release PRs instead of combined |\n\n### Common Failure: Duplicate Release Tags\n\n**Symptom:** Workflow fails with `Duplicate release tag: v2.0.0`\n\n**Cause:** All packages try to create the same tag (e.g., `v2.0.0`) because:\n1. Missing `include-component-in-tag: true` at root level\n2. Missing `component` field in each package\n\n**Fix:**\n```json\n{\n  \"include-component-in-tag\": true,\n  \"packages\": {\n    \"my-package\": {\n      \"component\": \"my-package\",  // Add this to every package\n      ...\n    }\n  }\n}\n```\n\n### Common Failure: Multiple Paths Warning\n\n**Symptom:** `Multiple paths for : package-a, package-b`\n\n**Cause:** Empty `component` field (the `:` with nothing after it indicates empty string)\n\n**Fix:** Ensure every package has `\"component\": \"package-name\"` set\n\n## Release Types\n\n| Type | Use Case | Version File |\n|------|----------|--------------|\n| `simple` | Generic projects | `version.txt` |\n| `node` | npm packages | `package.json` |\n| `python` | Python (pyproject.toml) | `pyproject.toml` |\n| `rust` | Rust crates | `Cargo.toml` |\n| `go` | Go modules | `version.go` or similar |\n\n### Extra Files for Custom Version Locations\n\nFor JSON files, you **must** use the object format with `type`, `path`, and `jsonpath`:\n\n```json\n{\n  \"packages\": {\n    \"my-plugin\": {\n      \"release-type\": \"simple\",\n      \"extra-files\": [\n        {\"type\": \"json\", \"path\": \"my-plugin/.claude-plugin/plugin.json\", \"jsonpath\": \"$.version\"}\n      ]\n    }\n  }\n}\n```\n\n**Common Mistakes:**\n\n1. Using a simple string path for JSON files:\n```json\n// WRONG - won't update the version field\n\"extra-files\": [\".claude-plugin/plugin.json\"]\n\n// CORRECT - uses JSON updater with jsonpath\n\"extra-files\": [\n  {\"type\": \"json\", \"path\": \".claude-plugin/plugin.json\", \"jsonpath\": \"$.version\"}\n]\n```\n\n2. Using absolute paths instead of package-relative paths:\n```json\n// WRONG - path gets doubled (package-name/package-name/.claude-plugin/...)\n\"extra-files\": [\n  {\"type\": \"json\", \"path\": \"my-plugin/.claude-plugin/plugin.json\", \"jsonpath\": \"$.version\"}\n]\n\n// CORRECT - path is relative to the package directory\n\"extra-files\": [\n  {\"type\": \"json\", \"path\": \".claude-plugin/plugin.json\", \"jsonpath\": \"$.version\"}\n]\n```\n\n**Key insight:** For monorepo packages, `extra-files` paths are relative to the package directory, NOT the repo root. Release-please automatically prepends the package path.\n\n**File Type Formats:**\n\n| File Type | Format |\n|-----------|--------|\n| JSON | `{\"type\": \"json\", \"path\": \"...\", \"jsonpath\": \"$.version\"}` |\n| YAML | `{\"type\": \"yaml\", \"path\": \"...\", \"jsonpath\": \"$.version\"}` |\n| TOML | `{\"type\": \"toml\", \"path\": \"...\", \"jsonpath\": \"$.version\"}` |\n| XML | `{\"type\": \"xml\", \"path\": \"...\", \"xpath\": \"//version\"}` |\n| Plain text | `\"path/to/version.txt\"` (string is fine) |\n\n## Changelog Configuration\n\n### Standard Changelog Sections\n\n```json\n{\n  \"changelog-sections\": [\n    {\"type\": \"feat\", \"section\": \"Features\"},\n    {\"type\": \"fix\", \"section\": \"Bug Fixes\"},\n    {\"type\": \"perf\", \"section\": \"Performance\"},\n    {\"type\": \"refactor\", \"section\": \"Code Refactoring\"},\n    {\"type\": \"docs\", \"section\": \"Documentation\"}\n  ]\n}\n```\n\n### Commit Type to Version Bump\n\n| Commit Type | Version Bump | CHANGELOG Section |\n|-------------|--------------|-------------------|\n| `feat:` | Minor | Features |\n| `fix:` | Patch | Bug Fixes |\n| `feat!:` | Major | Features (with BREAKING CHANGE) |\n| `BREAKING CHANGE:` | Major | Breaking Changes |\n| `chore:` | None | (hidden) |\n| `docs:` | None | Documentation |\n| `refactor:` | None | Code Refactoring |\n| `perf:` | Patch | Performance |\n\n## Manifest File\n\nThe `.release-please-manifest.json` tracks current versions:\n\n```json\n{\n  \"package-a\": \"1.2.3\",\n  \"package-b\": \"2.0.0\"\n}\n```\n\n**Important:** This file is auto-updated by release-please. Manual edits should only be done for:\n- Initial bootstrapping\n- Resetting after tag migration\n\n## GitHub Actions Workflow\n\n### Minimal Workflow\n\n```yaml\nname: Release Please\n\non:\n  push:\n    branches:\n      - main\n\npermissions:\n  contents: write\n  pull-requests: write\n\njobs:\n  release-please:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: googleapis/release-please-action@v4\n        with:\n          token: ${{ secrets.GITHUB_TOKEN }}\n```\n\n### With Custom Token (Required for Triggering Other Workflows)\n\n```yaml\n- uses: googleapis/release-please-action@v4\n  with:\n    token: ${{ secrets.MY_RELEASE_PLEASE_TOKEN }}\n```\n\nUse a PAT if you need release PRs to trigger other workflows (e.g., CI checks).\n\n## Adding a New Package to Monorepo\n\n1. **Update `release-please-config.json`:**\n```json\n{\n  \"packages\": {\n    \"new-package\": {\n      \"component\": \"new-package\",\n      \"release-type\": \"simple\",\n      \"extra-files\": [\"new-package/.version-file.json\"],\n      \"changelog-sections\": [...]\n    }\n  }\n}\n```\n\n2. **Update `.release-please-manifest.json`:**\n```json\n{\n  \"new-package\": \"1.0.0\"\n}\n```\n\n3. **Create initial version file** in the package if needed.\n\n## Migrating from Shared Tags to Component Tags\n\nWhen transitioning from `v1.0.0` style tags to `component-v1.0.0`:\n\n1. Add `\"include-component-in-tag\": true` to config\n2. Add `\"component\": \"package-name\"` to each package\n3. Old tags (`v1.0.0`) will be ignored\n4. New releases will create component-specific tags\n5. Close any pending combined release PRs\n\n**Note:** Release-please will scan for component-specific tags. First run after migration will create release PRs for all packages with changes since the manifest version.\n\n## Troubleshooting\n\n### Workflow Succeeds but No PR Created\n\nCheck:\n1. Are there releasable commits since last release tag?\n2. Do commits follow conventional format?\n3. Is the package path correct in config?\n\n### Version Not Bumping\n\nCheck:\n1. Commit type (feat/fix vs chore/docs)\n2. Commit scope matches package path\n3. Conventional commit format is correct\n\n### Wrong Version in Extra Files\n\nEnsure `extra-files` paths are correct relative to repo root, not package root:\n```json\n// Correct\n\"extra-files\": [\"my-package/.claude-plugin/plugin.json\"]\n\n// Wrong (if package path is \"my-package\")\n\"extra-files\": [\".claude-plugin/plugin.json\"]\n```\n\n## Quick Reference\n\n### Conventional Commit Format\n\n```\n<type>(<scope>): <description>\n\n[optional body]\n\n[optional footer(s)]\n```\n\n**Examples:**\n```bash\nfeat(auth): add OAuth2 support\nfix(api): handle timeout edge case\nfeat(cli)!: redesign command interface\n\nBREAKING CHANGE: Commands now use subcommand syntax.\n```\n\n### Version Bump Rules\n\n| Pattern | Bump |\n|---------|------|\n| `feat:` | Minor (1.0.0  1.1.0) |\n| `fix:` | Patch (1.0.0  1.0.1) |\n| `!` suffix or `BREAKING CHANGE:` | Major (1.0.0  2.0.0) |\n| `chore:`, `docs:`, `style:`, `test:` | No bump |\n\n### Useful Commands\n\n```bash\n# Check latest release-please-action version\ncurl -s https://api.github.com/repos/googleapis/release-please-action/releases/latest | jq -r '.tag_name'\n\n# List pending release PRs\ngh pr list --label \"autorelease: pending\"\n\n# View recent workflow runs\ngh run list --workflow=release-please.yml --limit=5\n\n# Check failed workflow logs\ngh run view <run-id> --log-failed\n```\n\n## Resources\n\n- [Release-Please Documentation](https://github.com/googleapis/release-please)\n- [Release-Please Action](https://github.com/googleapis/release-please-action)\n- [Conventional Commits](https://www.conventionalcommits.org/)\n- [Manifest Releaser Guide](https://github.com/googleapis/release-please/blob/main/docs/manifest-releaser.md)"
              },
              {
                "name": "release-please-protection",
                "description": "Detects and prevents manual edits to release-please managed files (CHANGELOG.md,\nversion fields in package.json, pyproject.toml, Cargo.toml). Provides conventional\ncommit templates. Use when editing changelogs, version bumps, release files, or\nwhen user mentions \"release\", \"changelog\", \"version bump\", or \"conventional commits\".\n",
                "path": "git-plugin/skills/release-please-protection/SKILL.md",
                "frontmatter": {
                  "created": "2025-12-16T00:00:00.000Z",
                  "modified": "2025-12-16T00:00:00.000Z",
                  "reviewed": "2025-12-16T00:00:00.000Z",
                  "name": "release-please-protection",
                  "description": "Detects and prevents manual edits to release-please managed files (CHANGELOG.md,\nversion fields in package.json, pyproject.toml, Cargo.toml). Provides conventional\ncommit templates. Use when editing changelogs, version bumps, release files, or\nwhen user mentions \"release\", \"changelog\", \"version bump\", or \"conventional commits\".\n"
                },
                "content": "# Release-Please Protection\n\nAutomatically detects and prevents manual edits to release-please managed files across all projects.\n\n## Overview\n\nThis skill provides proactive detection and warnings for files managed by Google's release-please automation tool. It helps prevent merge conflicts and workflow disruptions by identifying problematic edit attempts before they occur.\n\n## When This Skill Activates\n\nThe skill automatically activates in these scenarios:\n\n1. **Direct edit requests** to protected files\n2. **User mentions** of version bumps, releases, or changelog updates\n3. **Broad refactoring** that might touch version-controlled files\n4. **Documentation updates** that could include CHANGELOG.md\n5. **\"Fix all issues\"** or similar sweeping requests\n\n## Protected Files\n\n### Hard Protection (Permission System)\nThese files are **completely blocked** from editing by Claude Code's permission system:\n\n- `**/CHANGELOG.md` - All changelog files in any location\n\n**Operations blocked:** Edit, Write, MultiEdit\n**Operations allowed:** Read (for analysis and context)\n\n### Soft Protection (Skill Detection)\nThese files trigger **warnings and suggestions** before edits:\n\n#### Package Manager Manifests (Version Fields)\n- `package.json`  `\"version\": \"x.y.z\"` (npm/Node.js)\n- `pyproject.toml`  `version = \"x.y.z\"` (Python/uv)\n- `Cargo.toml`  `version = \"x.y.z\"` (Rust/cargo)\n- `.claude-plugin/plugin.json`  `\"version\": \"x.y.z\"` (Claude Code plugins)\n- `pom.xml`  `<version>x.y.z</version>` (Maven/Java)\n- `build.gradle`  `version = 'x.y.z'` (Gradle)\n- `pubspec.yaml`  `version: x.y.z` (Dart/Flutter)\n\n**Why soft protection?** Claude Code's permission system operates at the file level, not field level. Blocking entire manifest files would prevent legitimate dependency updates via automated tools (npm, cargo, uv, etc.).\n\n## Detection Logic\n\nBefore attempting any edit, the skill checks:\n\n### 1. File Path Analysis\n```\nif file_path ends with \"CHANGELOG.md\":\n     Inform user of hard permission block\n     Explain release-please workflow\n     Suggest conventional commit approach\n```\n\n### 2. Content Pattern Matching\n```\nif file is package manifest AND edit touches version field:\n     Warn about release-please management\n     Explain why manual edits cause conflicts\n     Offer to edit OTHER fields (but not version)\n     Provide conventional commit template\n```\n\n### 3. Intent Recognition\n```\nif user request contains keywords: \"version\", \"release\", \"bump\", \"changelog\":\n     Proactively explain release-please workflow\n     Check if files in scope are protected\n     Suggest proper approach before attempting edits\n```\n\n## Response Templates\n\n### When CHANGELOG.md Edit Attempted\n\n```\n CHANGELOG.md Protection Active\n\nI cannot edit CHANGELOG.md files - they're protected by Claude Code's permission\nsystem because they're managed by release-please automation.\n\n**Why this matters:**\nManual edits to CHANGELOG.md cause merge conflicts with automated release PRs,\nbreaking your release workflow.\n\n**Proper workflow:**\n1. Make your changes with conventional commit messages:\n   - feat: adds new features (minor version bump)\n   - fix: bug fixes (patch version bump)\n   - chore: maintenance tasks (no version bump)\n   - BREAKING CHANGE: breaking changes (major version bump)\n\n2. Release-please automatically:\n   - Detects conventional commits\n   - Generates CHANGELOG entries\n   - Creates a release PR with version bumps\n   - Tags releases when PR is merged\n\n**Example commit:**\n```\nfeat(auth): add OAuth2 support\n\nImplements OAuth2 authentication flow with PKCE.\nIncludes refresh token rotation and session management.\n```\n\n**Need to override?**\nFor emergency fixes, temporarily edit ~/.claude/settings.json:\n1. Comment out the CHANGELOG.md deny rules\n2. Make your edits\n3. Re-enable protection\n```\n\n### When Version Field Edit Detected\n\n```\n Version Field Protection Warning\n\nI notice you're asking me to modify the version field in [file_name]. This field\nis typically managed by release-please automation.\n\n**Current version:** [current_version]\n**Requested change:** [requested_change]\n\n**Why manual edits are problematic:**\n- Creates merge conflicts with release-please PRs\n- Can cause version numbering inconsistencies\n- Bypasses conventional commit history tracking\n\n**I can help in two ways:**\n\n1. **Automated approach (recommended):**\n   I'll help you craft a conventional commit message that will trigger the\n   appropriate version bump when release-please creates its next release PR.\n\n   For [requested_change], you should use:\n   - `feat:` for minor version bump\n   - `fix:` for patch version bump\n   - `feat!:` or `BREAKING CHANGE:` for major version bump\n\n2. **Manual override (emergency only):**\n   If you absolutely need to manually set the version (e.g., aligning with\n   external requirements), I can edit other fields in [file_name] but will\n   skip the version field. You'll need to edit that manually or temporarily\n   disable the skill protection.\n\nWhich approach would you prefer?\n```\n\n### When Broad Refactoring Requested\n\n```\n Release-Please Files Detected\n\nI've identified several release-please managed files in the scope of this\nrefactoring:\n\n**Protected files found:**\n- plugins/dotfiles-core/CHANGELOG.md (hard block)\n- plugins/dotfiles-toolkit/.claude-plugin/plugin.json (version field)\n- [other files...]\n\n**My approach:**\n I'll refactor all other files as requested\n I'll skip protected files and explain why\n I'll provide a summary of skipped changes\n\n**If you need version/changelog updates:**\nI'll generate appropriate conventional commit messages that will trigger\nrelease-please to make those changes automatically.\n\nShould I proceed with this approach?\n```\n\n## Conventional Commit Guide\n\nThe skill provides instant conventional commit templates based on the type of change:\n\n### Feature Addition\n```\nfeat(scope): brief description\n\nDetailed explanation of what was added and why.\nCan be multiple paragraphs.\n\nRefs: #issue-number\n```\n\n### Bug Fix\n```\nfix(scope): brief description\n\nExplanation of the bug and how it was fixed.\n\nFixes: #issue-number\n```\n\n### Breaking Change\n```\nfeat(scope)!: brief description\n\nBREAKING CHANGE: Explanation of what breaks and migration path.\n\nDetails about the new behavior.\n\nRefs: #issue-number\n```\n\n### Chore (No Version Bump)\n```\nchore(scope): brief description\n\nMaintenance work that doesn't affect functionality.\nExamples: dependency updates, refactoring, docs.\n```\n\n## Integration with Other Skills\n\nThis skill works alongside:\n\n- **Chezmoi Expert** - Ensures dotfiles templates don't manually edit versions\n- **Git Workflow** - Enforces conventional commits before creating PRs\n- **GitHub Actions** - Aware of release-please workflow configurations\n\n## Skill Configuration\n\nLocated in `dot_claude/skills/release-please-protection/` (source) which becomes `~/.claude/skills/release-please-protection/` after chezmoi apply:\n\n- `SKILL.md` - This file (skill definition)\n- `patterns.md` - Protected file pattern reference\n- `workflow.md` - Detailed release-please workflow guide\n\n## Limitations\n\n### What This Skill Cannot Prevent\n\n1. **Explicit overrides** - If you explicitly instruct me to edit despite warnings\n2. **Out-of-context files** - Files not in the current context window\n3. **External tools** - Commands like `sed`, `awk`, or direct bash edits\n4. **Git operations** - Manual `git commit` with modified protected files\n\n### What This Skill DOES Prevent\n\n1. **Accidental edits** - Catching mistakes before they happen\n2. **Workflow violations** - Explaining proper release-please patterns\n3. **Merge conflicts** - Preventing automated PR conflicts\n4. **Version inconsistencies** - Maintaining semantic versioning discipline\n\n## Emergency Overrides\n\nIf you absolutely must manually edit protected files:\n\n### Temporary Permission Override\n```bash\n# 1. Edit global settings\nvim ~/.claude/settings.json\n\n# 2. Comment out deny rules\n\"deny\": [\n  \"Bash(git add .)\",\n  \"Bash(git add -A)\",\n  \"Bash(git add --all)\",\n  // \"Edit(**/CHANGELOG.md)\",\n  // \"Write(**/CHANGELOG.md)\",\n  // \"MultiEdit(**/CHANGELOG.md)\"\n]\n\n# 3. Make your edits\n\n# 4. Re-enable protection (uncomment the lines)\n\n# 5. Verify with chezmoi\nchezmoi diff ~/.claude/settings.json\nchezmoi apply  # If template is out of sync\n```\n\n### Skill Bypass (Not Recommended)\n```bash\n# Temporarily disable skill\nmv .claude/skills/release-please-protection .claude/skills/release-please-protection.disabled\n\n# Make edits\n\n# Re-enable\nmv .claude/skills/release-please-protection.disabled .claude/skills/release-please-protection\n```\n\n## Success Metrics\n\nThis skill is working properly when:\n\n All CHANGELOG.md edit attempts are blocked with helpful explanations\n Version field modifications trigger warnings and alternatives\n Conventional commit suggestions match the requested changes\n Users understand the release-please workflow after first warning\n No merge conflicts occur with automated release PRs\n Version numbers follow semantic versioning consistently\n\n## Further Reading\n\n- See `patterns.md` for complete list of protected file patterns\n- See `workflow.md` for detailed release-please workflow documentation\n- Release-please docs: https://github.com/googleapis/release-please\n- Conventional commits: https://www.conventionalcommits.org/"
              }
            ]
          },
          {
            "name": "testing-plugin",
            "description": "Test execution, TDD workflow, and testing strategies",
            "source": "./testing-plugin",
            "category": "testing",
            "version": "3.0.1",
            "author": null,
            "install_commands": [
              "/plugin marketplace add laurigates/claude-plugins",
              "/plugin install testing-plugin@lgates-claude-plugins"
            ],
            "signals": {
              "stars": 1,
              "forks": 0,
              "pushed_at": "2026-01-12T12:05:51Z",
              "created_at": "2025-12-16T11:24:04Z",
              "license": null
            },
            "commands": [],
            "skills": [
              {
                "name": "hypothesis-testing",
                "description": "Property-based testing with Hypothesis for discovering edge cases and validating invariants.\nUse when implementing comprehensive test coverage, testing complex logic with many inputs,\nor validating mathematical properties and invariants across input domains.\nTriggered by: hypothesis, property-based testing, @given, strategies, generative testing.\n",
                "path": "testing-plugin/skills/hypothesis-testing/SKILL.md",
                "frontmatter": {
                  "created": "2025-12-16T00:00:00.000Z",
                  "modified": "2025-12-16T00:00:00.000Z",
                  "reviewed": "2025-12-16T00:00:00.000Z",
                  "name": "hypothesis-testing",
                  "description": "Property-based testing with Hypothesis for discovering edge cases and validating invariants.\nUse when implementing comprehensive test coverage, testing complex logic with many inputs,\nor validating mathematical properties and invariants across input domains.\nTriggered by: hypothesis, property-based testing, @given, strategies, generative testing.\n"
                },
                "content": "# Hypothesis Property-Based Testing\n\nHypothesis is a powerful property-based testing library that automatically generates test cases to find edge cases and validate properties of your code.\n\n## Core Concept\n\n**Traditional example-based testing:**\n```python\ndef test_addition():\n    assert add(2, 3) == 5\n    assert add(0, 0) == 0\n    assert add(-1, 1) == 0\n```\n\n**Property-based testing with Hypothesis:**\n```python\nfrom hypothesis import given\nimport hypothesis.strategies as st\n\n@given(st.integers(), st.integers())\ndef test_addition_commutative(a, b):\n    \"\"\"Addition is commutative for ALL integers.\"\"\"\n    assert add(a, b) == add(b, a)\n```\n\nHypothesis generates hundreds of test cases automatically, including edge cases you might not think of.\n\n## Installation\n\n```bash\n# Install hypothesis with pytest integration\nuv add --dev hypothesis pytest\n\n# Optional plugins\nuv add --dev hypothesis[numpy]      # NumPy strategies\nuv add --dev hypothesis[pandas]     # Pandas strategies\nuv add --dev hypothesis[django]     # Django model strategies\n```\n\n## Configuration\n\n### pyproject.toml Configuration\n\n```toml\n[tool.pytest.ini_options]\n# Hypothesis settings\naddopts = [\n    \"--hypothesis-show-statistics\",  # Show test statistics\n    \"--hypothesis-seed=0\",            # Reproducible tests (optional)\n]\n\n[tool.hypothesis]\n# Maximum number of examples to generate\nmax_examples = 200  # Default: 100, CI: 200+\n\n# Deadline for each test case (milliseconds)\ndeadline = 1000  # Default: 200ms, None to disable\n\n# Verbosity level (quiet, normal, verbose, debug)\nverbosity = \"normal\"\n\n# Fail fast on first error\nderandomize = false  # Set to true for deterministic tests\n\n# Database for example storage\ndatabase = \".hypothesis/examples\"  # Store found failures\n\n# Profile-specific settings\n[tool.hypothesis.profiles.dev]\nmax_examples = 50\ndeadline = 1000\nverbosity = \"normal\"\n\n[tool.hypothesis.profiles.ci]\nmax_examples = 500\ndeadline = 5000\nverbosity = \"verbose\"\n\n[tool.hypothesis.profiles.debug]\nmax_examples = 10\ndeadline = null\nverbosity = \"debug\"\n```\n\n### Activate Profile\n\n```python\n# tests/conftest.py\nfrom hypothesis import settings, Verbosity\n\n# Set default profile based on environment\nimport os\nif os.getenv(\"CI\"):\n    settings.load_profile(\"ci\")\nelse:\n    settings.load_profile(\"dev\")\n\n# Or configure programmatically\nsettings.register_profile(\"custom\", max_examples=100, deadline=500)\nsettings.load_profile(\"custom\")\n```\n\n## Basic Usage\n\n### Simple Property Tests\n\n```python\nfrom hypothesis import given, example\nimport hypothesis.strategies as st\n\n# Test numeric properties\n@given(st.integers())\ndef test_absolute_value_non_negative(x):\n    \"\"\"abs(x) is always non-negative.\"\"\"\n    assert abs(x) >= 0\n\n@given(st.integers(), st.integers())\ndef test_addition_associative(a, b, c):\n    \"\"\"Addition is associative: (a + b) + c == a + (b + c).\"\"\"\n    assert (a + b) + c == a + (b + c)\n\n# Test string properties\n@given(st.text())\ndef test_string_length(s):\n    \"\"\"Length of reversed string equals original.\"\"\"\n    assert len(s[::-1]) == len(s)\n\n@given(st.text(), st.text())\ndef test_string_concatenation(s1, s2):\n    \"\"\"String concatenation length is sum of lengths.\"\"\"\n    result = s1 + s2\n    assert len(result) == len(s1) + len(s2)\n\n# Add explicit examples alongside generated ones\n@given(st.integers())\n@example(0)\n@example(-1)\n@example(2**31 - 1)\ndef test_with_explicit_examples(x):\n    \"\"\"Test with both generated and explicit examples.\"\"\"\n    assert process(x) is not None\n```\n\n### Testing Functions\n\n```python\nfrom hypothesis import given, assume\nimport hypothesis.strategies as st\n\ndef safe_divide(a: float, b: float) -> float:\n    \"\"\"Divide a by b, avoiding division by zero.\"\"\"\n    if b == 0:\n        raise ValueError(\"Division by zero\")\n    return a / b\n\n@given(st.floats(allow_nan=False, allow_infinity=False),\n       st.floats(allow_nan=False, allow_infinity=False))\ndef test_safe_divide(a, b):\n    \"\"\"Test safe_divide with all valid floats.\"\"\"\n    assume(b != 0)  # Skip cases where b is zero\n\n    result = safe_divide(a, b)\n\n    # Properties to verify\n    assert isinstance(result, float)\n    assert result * b == pytest.approx(a)  # Inverse operation\n\n@given(st.floats())\ndef test_divide_by_zero_raises(a):\n    \"\"\"Division by zero raises ValueError.\"\"\"\n    with pytest.raises(ValueError, match=\"Division by zero\"):\n        safe_divide(a, 0)\n```\n\n## Strategies\n\n### Built-in Strategies\n\n```python\nimport hypothesis.strategies as st\n\n# Primitives\nst.none()                    # None\nst.booleans()                # True/False\nst.integers()                # Any integer\nst.integers(min_value=0, max_value=100)  # Bounded integers\nst.floats()                  # Any float\nst.floats(min_value=0.0, max_value=1.0)  # Bounded floats\nst.decimals()                # Decimal numbers\nst.fractions()               # Fraction objects\nst.complex_numbers()         # Complex numbers\n\n# Text and bytes\nst.text()                    # Unicode strings\nst.text(alphabet=\"abc\")      # Limited alphabet\nst.text(min_size=1, max_size=10)  # Bounded length\nst.binary()                  # Bytes\nst.characters()              # Single characters\n\n# Collections\nst.lists(st.integers())      # Lists of integers\nst.lists(st.text(), min_size=1, max_size=10)  # Bounded lists\nst.tuples(st.integers(), st.text())  # Fixed-size tuples\nst.sets(st.integers())       # Sets\nst.frozensets(st.text())     # Frozen sets\nst.dictionaries(keys=st.text(), values=st.integers())  # Dicts\n\n# Special types\nst.uuids()                   # UUID objects\nst.datetimes()               # datetime objects\nst.dates()                   # date objects\nst.times()                   # time objects\nst.timedeltas()              # timedelta objects\n\n# Constrained types\nst.emails()                  # Valid email addresses\nst.ip_addresses()            # IP addresses (v4 and v6)\nst.urls()                    # Valid URLs\n```\n\n### Composite Strategies\n\n```python\nfrom hypothesis import given\nfrom hypothesis.strategies import composite\nimport hypothesis.strategies as st\n\n# Define custom strategy\n@composite\ndef users(draw):\n    \"\"\"Generate user objects.\"\"\"\n    return {\n        \"id\": draw(st.integers(min_value=1)),\n        \"name\": draw(st.text(min_size=1, max_size=50)),\n        \"email\": draw(st.emails()),\n        \"age\": draw(st.integers(min_value=0, max_value=120)),\n        \"active\": draw(st.booleans())\n    }\n\n@given(users())\ndef test_user_validation(user):\n    \"\"\"Test user validation with generated users.\"\"\"\n    assert user[\"id\"] > 0\n    assert len(user[\"name\"]) > 0\n    assert \"@\" in user[\"email\"]\n    assert 0 <= user[\"age\"] <= 120\n\n# Complex composite strategy\n@composite\ndef http_requests(draw):\n    \"\"\"Generate HTTP request objects.\"\"\"\n    method = draw(st.sampled_from([\"GET\", \"POST\", \"PUT\", \"DELETE\"]))\n    path = draw(st.text(alphabet=\"abcdefghijklmnopqrstuvwxyz/\", min_size=1))\n    headers = draw(st.dictionaries(\n        keys=st.text(alphabet=\"abcdefghijklmnopqrstuvwxyz-\", min_size=1),\n        values=st.text()\n    ))\n\n    body = None\n    if method in [\"POST\", \"PUT\"]:\n        body = draw(st.one_of(st.none(), st.text(), st.binary()))\n\n    return {\n        \"method\": method,\n        \"path\": f\"/{path}\",\n        \"headers\": headers,\n        \"body\": body\n    }\n\n@given(http_requests())\ndef test_request_handler(request):\n    \"\"\"Test HTTP request handler with various requests.\"\"\"\n    response = handle_request(request)\n    assert response.status_code in [200, 201, 400, 404, 500]\n```\n\n### Data Classes and Models\n\n```python\nfrom dataclasses import dataclass\nfrom hypothesis import given\nfrom hypothesis.strategies import builds\nimport hypothesis.strategies as st\n\n@dataclass\nclass Point:\n    x: float\n    y: float\n\n# Generate Point instances\n@given(builds(Point, x=st.floats(), y=st.floats()))\ndef test_point_distance(point):\n    \"\"\"Test distance calculation for points.\"\"\"\n    origin = Point(0.0, 0.0)\n    distance = calculate_distance(origin, point)\n    assert distance >= 0\n\n# More complex model\n@dataclass\nclass User:\n    id: int\n    name: str\n    email: str\n    age: int\n\n# Strategy with validation\ndef valid_users():\n    return builds(\n        User,\n        id=st.integers(min_value=1),\n        name=st.text(min_size=1, max_size=100),\n        email=st.emails(),\n        age=st.integers(min_value=0, max_value=120)\n    )\n\n@given(valid_users())\ndef test_user_serialization(user):\n    \"\"\"Test user serialization round-trip.\"\"\"\n    json_data = user.to_json()\n    restored = User.from_json(json_data)\n    assert restored == user\n```\n\n### Strategy Combinators\n\n```python\nimport hypothesis.strategies as st\n\n# one_of: Choose from multiple strategies\nst.one_of(st.none(), st.integers(), st.text())\n\n# sampled_from: Sample from a list\nst.sampled_from([\"admin\", \"user\", \"guest\"])\n\n# just: Always return a specific value\nst.just(42)\n\n# lists with constraints\nst.lists(\n    st.integers(min_value=0),\n    min_size=1,\n    max_size=10,\n    unique=True  # No duplicates\n)\n\n# dictionaries with constraints\nst.dictionaries(\n    keys=st.text(min_size=1),\n    values=st.integers(),\n    min_size=1,\n    max_size=5\n)\n\n# tuples with mixed types\nst.tuples(st.integers(), st.text(), st.booleans())\n\n# fixed_dictionaries: Dictionary with specific keys\nst.fixed_dictionaries({\n    \"id\": st.integers(min_value=1),\n    \"name\": st.text(),\n    \"optional\": st.one_of(st.none(), st.text())\n})\n\n# recursive: Generate recursive structures\njson_strategy = st.recursive(\n    st.one_of(st.none(), st.booleans(), st.floats(), st.text()),\n    lambda children: st.lists(children) | st.dictionaries(st.text(), children),\n    max_leaves=10\n)\n```\n\n## Advanced Patterns\n\n### Stateful Testing\n\n```python\nfrom hypothesis.stateful import RuleBasedStateMachine, rule, invariant\nimport hypothesis.strategies as st\n\nclass ShoppingCartMachine(RuleBasedStateMachine):\n    \"\"\"Test shopping cart with stateful operations.\"\"\"\n\n    def __init__(self):\n        super().__init__()\n        self.cart = ShoppingCart()\n        self.items_added = []\n\n    @rule(item=st.text(min_size=1), quantity=st.integers(min_value=1, max_value=10))\n    def add_item(self, item, quantity):\n        \"\"\"Add item to cart.\"\"\"\n        self.cart.add(item, quantity)\n        self.items_added.append((item, quantity))\n\n    @rule(item=st.text())\n    def remove_item(self, item):\n        \"\"\"Remove item from cart.\"\"\"\n        try:\n            self.cart.remove(item)\n            self.items_added = [(i, q) for i, q in self.items_added if i != item]\n        except ValueError:\n            # Item not in cart, expected\n            pass\n\n    @rule()\n    def clear_cart(self):\n        \"\"\"Clear entire cart.\"\"\"\n        self.cart.clear()\n        self.items_added = []\n\n    @invariant()\n    def cart_is_consistent(self):\n        \"\"\"Cart item count matches what we've added.\"\"\"\n        expected_items = {item: qty for item, qty in self.items_added}\n        actual_items = self.cart.get_items()\n        assert expected_items == actual_items\n\n    @invariant()\n    def total_is_non_negative(self):\n        \"\"\"Cart total is always non-negative.\"\"\"\n        assert self.cart.get_total() >= 0\n\n# Run the state machine\nTestShoppingCart = ShoppingCartMachine.TestCase\n```\n\n### Shrinking and Example Database\n\n```python\nfrom hypothesis import given, settings, example\nimport hypothesis.strategies as st\n\n@given(st.lists(st.integers()))\ndef test_list_processing(items):\n    \"\"\"Test list processing - Hypothesis will shrink failing examples.\"\"\"\n    result = process_list(items)\n    assert result is not None\n\n# When a test fails, Hypothesis:\n# 1. Finds the failing input\n# 2. Shrinks it to the simplest failing case\n# 3. Stores it in .hypothesis/examples database\n# 4. Replays it on future runs\n\n# Example: If test fails on [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n# Hypothesis shrinks to smallest failing case: [1, 2]\n\n# Disable shrinking for debugging\n@given(st.lists(st.integers()))\n@settings(max_examples=100, phases=[\"generate\"])  # Skip shrink phase\ndef test_without_shrinking(items):\n    \"\"\"Test without shrinking for faster debugging.\"\"\"\n    assert process_list(items) is not None\n```\n\n### Targeted Property Testing\n\n```python\nfrom hypothesis import given, target\nimport hypothesis.strategies as st\n\n@given(st.lists(st.integers()))\ndef test_sort_with_targeting(items):\n    \"\"\"Guide Hypothesis toward larger lists.\"\"\"\n    # Target larger lists to test scalability\n    target(float(len(items)))\n\n    sorted_items = sorted(items)\n    assert all(sorted_items[i] <= sorted_items[i+1]\n               for i in range(len(sorted_items) - 1))\n\n@given(st.floats(min_value=0.0, max_value=1.0))\ndef test_with_edge_targeting(probability):\n    \"\"\"Guide Hypothesis toward edge values (0.0 and 1.0).\"\"\"\n    # Target values close to edges\n    target(abs(probability - 0.5))  # Prefer extreme values\n\n    result = simulate_with_probability(probability)\n    assert 0 <= result <= 1\n```\n\n### Hypothesis with Async Code\n\n```python\nimport pytest\nfrom hypothesis import given\nimport hypothesis.strategies as st\n\n# Async property test\n@pytest.mark.asyncio\n@given(st.integers())\nasync def test_async_function(value):\n    \"\"\"Test async function with property-based testing.\"\"\"\n    result = await async_process(value)\n    assert result is not None\n\n# Async with composite strategies\n@pytest.mark.asyncio\n@given(st.lists(st.integers(), min_size=1))\nasync def test_async_batch_processing(items):\n    \"\"\"Test async batch processing.\"\"\"\n    results = await process_batch(items)\n    assert len(results) == len(items)\n    assert all(r is not None for r in results)\n```\n\n## When to Use Hypothesis vs Example-Based Tests\n\n### Use Hypothesis (Property-Based) When:\n\n1. **Testing mathematical properties**\n   ```python\n   @given(st.integers(), st.integers())\n   def test_addition_commutative(a, b):\n       assert a + b == b + a\n   ```\n\n2. **Testing invariants across many inputs**\n   ```python\n   @given(st.lists(st.integers()))\n   def test_sort_idempotent(items):\n       sorted_once = sorted(items)\n       sorted_twice = sorted(sorted_once)\n       assert sorted_once == sorted_twice\n   ```\n\n3. **Finding edge cases**\n   ```python\n   @given(st.text())\n   def test_parse_input(text):\n       # Hypothesis will find weird edge cases like:\n       # \"\", \"\\x00\", \"\", very long strings, etc.\n       result = parse(text)\n       assert result is not None\n   ```\n\n4. **Testing serialization round-trips**\n   ```python\n   @given(st.from_type(MyData))\n   def test_serialization(data):\n       json_str = data.to_json()\n       restored = MyData.from_json(json_str)\n       assert restored == data\n   ```\n\n5. **Testing APIs with many parameters**\n   ```python\n   @given(\n       st.text(),\n       st.integers(min_value=1),\n       st.booleans(),\n       st.sampled_from([\"option1\", \"option2\"])\n   )\n   def test_api_call(name, count, flag, option):\n       response = api_call(name, count, flag, option)\n       assert response.status in [200, 400]\n   ```\n\n### Use Example-Based Tests When:\n\n1. **Testing specific known edge cases**\n   ```python\n   def test_empty_list():\n       assert process([]) == []\n\n   def test_single_item():\n       assert process([1]) == [1]\n   ```\n\n2. **Testing exact business logic**\n   ```python\n   def test_discount_calculation():\n       # Exact prices from requirements\n       assert calculate_discount(100, 0.1) == 10\n       assert calculate_discount(50, 0.2) == 10\n   ```\n\n3. **Testing error messages**\n   ```python\n   def test_validation_error_message():\n       with pytest.raises(ValueError, match=\"Email must contain @\"):\n           validate_email(\"invalid\")\n   ```\n\n4. **Testing integration with external systems**\n   ```python\n   def test_api_integration():\n       # Specific API behavior\n       response = api.get(\"/users/123\")\n       assert response[\"name\"] == \"Test User\"\n   ```\n\n5. **Testing UI behavior**\n   ```python\n   def test_button_click():\n       button.click()\n       assert button.text == \"Clicked\"\n   ```\n\n### Hybrid Approach (Best Practice)\n\n```python\nfrom hypothesis import given, example\nimport hypothesis.strategies as st\n\n# Combine property-based + example-based\n@given(st.integers())\n@example(0)           # Explicit edge case\n@example(-1)          # Explicit edge case\n@example(2**31 - 1)   # Explicit edge case\ndef test_absolute_value(x):\n    \"\"\"Test with both generated and explicit examples.\"\"\"\n    result = abs(x)\n    assert result >= 0\n    assert result == abs(-x)\n\n# Property test + regression test\n@given(st.lists(st.integers()))\n@example([1, 2, 3])  # Known good case\n@example([])         # Edge case\n@example([42] * 1000)  # Performance edge case\ndef test_list_processing(items):\n    \"\"\"Test general property + specific known cases.\"\"\"\n    result = process_list(items)\n    assert len(result) == len(items)\n```\n\n## Best Practices\n\n### 1. Start with Simple Properties\n\n```python\n# Start simple\n@given(st.integers())\ndef test_increment(x):\n    assert x + 1 > x\n\n# Then add complexity\n@given(st.integers(), st.integers())\ndef test_addition_properties(a, b):\n    # Commutative\n    assert a + b == b + a\n    # Associative\n    assert (a + 1) + b == a + (1 + b)\n```\n\n### 2. Use assume() Sparingly\n\n```python\n# BAD: Too many assumes (slow)\n@given(st.integers(), st.integers())\ndef test_slow(a, b):\n    assume(a > 0)\n    assume(b > 0)\n    assume(a < 100)\n    assume(b < 100)\n    assert a + b < 200\n\n# GOOD: Use constrained strategies\n@given(st.integers(min_value=1, max_value=99),\n       st.integers(min_value=1, max_value=99))\ndef test_fast(a, b):\n    assert a + b < 200\n```\n\n### 3. Test Invariants, Not Implementation\n\n```python\n# BAD: Tests implementation details\n@given(st.lists(st.integers()))\ndef test_sort_implementation(items):\n    result = my_sort(items)\n    # Checks specific algorithm behavior\n    assert result.pivot_index == len(items) // 2\n\n# GOOD: Tests invariants\n@given(st.lists(st.integers()))\ndef test_sort_properties(items):\n    result = my_sort(items)\n    # Checks output properties\n    assert len(result) == len(items)\n    assert sorted(result) == result\n    assert set(result) == set(items)\n```\n\n### 4. Use @example() for Regression Tests\n\n```python\n@given(st.lists(st.integers()))\n@example([])              # Found bug with empty list\n@example([1, 1, 1])       # Found bug with duplicates\n@example([-2**31])        # Found bug with min int\ndef test_with_regressions(items):\n    \"\"\"Property test + regression tests.\"\"\"\n    result = process(items)\n    assert result is not None\n```\n\n### 5. Configure for Different Environments\n\n```python\nfrom hypothesis import given, settings, Verbosity\n\n# Development: Fast feedback\n@given(st.lists(st.integers()))\n@settings(max_examples=50, deadline=500)\ndef test_dev(items):\n    assert process(items) is not None\n\n# CI: Thorough testing\n@given(st.lists(st.integers()))\n@settings(max_examples=500, deadline=5000, verbosity=Verbosity.verbose)\ndef test_ci(items):\n    assert process(items) is not None\n```\n\n## Common Patterns\n\n### Testing Encoding/Decoding\n\n```python\n@given(st.from_type(MyData))\ndef test_json_roundtrip(data):\n    \"\"\"JSON encoding/decoding preserves data.\"\"\"\n    json_str = data.to_json()\n    restored = MyData.from_json(json_str)\n    assert restored == data\n\n@given(st.binary())\ndef test_base64_roundtrip(data):\n    \"\"\"Base64 encoding/decoding preserves data.\"\"\"\n    encoded = base64.b64encode(data)\n    decoded = base64.b64decode(encoded)\n    assert decoded == data\n```\n\n### Testing Parsers\n\n```python\n@given(st.text())\ndef test_parser_does_not_crash(text):\n    \"\"\"Parser handles any input without crashing.\"\"\"\n    try:\n        result = parse(text)\n        # If parsing succeeds, verify result is valid\n        assert isinstance(result, ParsedData)\n    except ParseError:\n        # Parse errors are expected for invalid input\n        pass\n```\n\n### Testing Database Operations\n\n```python\n@given(st.lists(valid_users(), max_size=10))\ndef test_batch_insert(users):\n    \"\"\"Batch insert preserves all users.\"\"\"\n    db.batch_insert(users)\n\n    for user in users:\n        retrieved = db.get_user(user.id)\n        assert retrieved == user\n\n@given(valid_users())\ndef test_update_preserves_id(user):\n    \"\"\"Updating user preserves ID.\"\"\"\n    db.save(user)\n    original_id = user.id\n\n    user.name = \"Updated Name\"\n    db.save(user)\n\n    assert user.id == original_id\n```\n\n## CI Integration\n\n```yaml\n# .github/workflows/test.yml\nname: Tests\n\non: [push, pull_request]\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Install uv\n        uses: astral-sh/setup-uv@v2\n\n      - name: Set up Python\n        run: uv python install 3.12\n\n      - name: Install dependencies\n        run: uv sync --all-extras --dev\n\n      - name: Run hypothesis tests (CI profile)\n        run: |\n          uv run pytest \\\n            --hypothesis-show-statistics \\\n            --hypothesis-profile=ci \\\n            --hypothesis-seed=${{ github.run_number }}\n\n      - name: Upload hypothesis database\n        uses: actions/upload-artifact@v4\n        if: failure()\n        with:\n          name: hypothesis-examples\n          path: .hypothesis/\n```\n\n## Debugging Failing Tests\n\n```python\nfrom hypothesis import given, settings, Verbosity, Phase\nimport hypothesis.strategies as st\n\n# Debug mode: Verbose output, no shrinking\n@given(st.lists(st.integers()))\n@settings(\n    verbosity=Verbosity.debug,\n    max_examples=10,\n    phases=[Phase.generate],  # Skip shrinking\n    print_blob=True           # Print input data\n)\ndef test_debug(items):\n    \"\"\"Debug failing test with full output.\"\"\"\n    result = buggy_function(items)\n    assert result is not None\n\n# Reproduce specific failing example\n@given(st.lists(st.integers()))\n@example([1, 2, -2147483648])  # Specific failing case\ndef test_reproduce_failure(items):\n    \"\"\"Reproduce and fix specific failure.\"\"\"\n    result = process(items)\n    assert result is not None\n```\n\n## Resources\n\n- **Hypothesis Documentation**: https://hypothesis.readthedocs.io/\n- **Hypothesis for Property-Based Testing**: https://increment.com/testing/in-praise-of-property-based-testing/\n- **PBT vs Example-Based**: https://hypothesis.works/articles/what-is-property-based-testing/\n- **Hypothesis Strategies**: https://hypothesis.readthedocs.io/en/latest/data.html\n- **Stateful Testing**: https://hypothesis.readthedocs.io/en/latest/stateful.html\n\n## Summary\n\nHypothesis provides property-based testing for Python:\n- **@given decorator**: Generate test inputs automatically\n- **Strategies**: Built-in and custom data generators\n- **Shrinking**: Automatically minimize failing examples\n- **Stateful testing**: Test complex state machines\n- **Example database**: Store and replay failing cases\n- **Use for**: Properties, invariants, round-trips, edge case discovery\n- **Combine with**: Example-based tests for comprehensive coverage\n- **CI integration**: Run with more examples in CI environments"
              },
              {
                "name": "mutation-testing",
                "description": "Validate test effectiveness with mutation testing using Stryker (TypeScript/JavaScript)\nand mutmut (Python). Find weak tests that pass despite code mutations.\nUse when user mentions mutation testing, Stryker, mutmut, test effectiveness,\nfinding weak tests, or improving test quality through mutation analysis.\n",
                "path": "testing-plugin/skills/mutation-testing/SKILL.md",
                "frontmatter": {
                  "created": "2025-12-16T00:00:00.000Z",
                  "modified": "2025-12-16T00:00:00.000Z",
                  "reviewed": "2025-12-16T00:00:00.000Z",
                  "name": "mutation-testing",
                  "description": "Validate test effectiveness with mutation testing using Stryker (TypeScript/JavaScript)\nand mutmut (Python). Find weak tests that pass despite code mutations.\nUse when user mentions mutation testing, Stryker, mutmut, test effectiveness,\nfinding weak tests, or improving test quality through mutation analysis.\n",
                  "allowed-tools": "Bash, Read, Edit, Write, Grep, Glob, TodoWrite"
                },
                "content": "# Mutation Testing\n\nExpert knowledge for mutation testing - validating that your tests actually catch bugs by introducing deliberate code mutations.\n\n## Core Expertise\n\n**Mutation Testing Concept**\n- **Mutants**: Small code changes (mutations) introduced automatically\n- **Killed**: Test fails with mutation (good - test caught the bug)\n- **Survived**: Test passes with mutation (bad - weak test)\n- **Coverage**: Tests execute mutated code but don't catch it\n- **Score**: Percentage of mutants killed (aim for 80%+)\n\n**What Mutation Testing Reveals**\n- Tests that don't actually verify behavior\n- Missing assertions or edge cases\n- Overly permissive assertions\n- Dead code or unnecessary logic\n- Areas needing stronger tests\n\n## TypeScript/JavaScript (Stryker)\n\n### Installation\n\n```bash\n# Using Bun\nbun add -d @stryker-mutator/core\n\n# Using npm\nnpm install -D @stryker-mutator/core\n\n# For Vitest\nbun add -d @stryker-mutator/vitest-runner\n\n# For Jest\nbun add -d @stryker-mutator/jest-runner\n```\n\n### Configuration\n\n```typescript\n// stryker.config.mjs\n/** @type {import('@stryker-mutator/api/core').PartialStrykerOptions} */\nexport default {\n  packageManager: 'bun',\n  reporters: ['html', 'clear-text', 'progress', 'dashboard'],\n  testRunner: 'vitest',\n  coverageAnalysis: 'perTest',\n\n  // Files to mutate\n  mutate: [\n    'src/**/*.ts',\n    '!src/**/*.test.ts',\n    '!src/**/*.spec.ts',\n    '!src/**/*.d.ts',\n  ],\n\n  // Thresholds for CI\n  thresholds: {\n    high: 80,\n    low: 60,\n    break: 60, // Fail build if below this\n  },\n\n  // Incremental mode (faster)\n  incremental: true,\n  incrementalFile: '.stryker-tmp/incremental.json',\n\n  // Concurrency\n  concurrency: 4,\n\n  // Timeout\n  timeoutMS: 60000,\n}\n```\n\n### Running Stryker\n\n```bash\n# Run mutation testing\nnpx stryker run\n\n# Incremental mode (only changed files)\nnpx stryker run --incremental\n\n# Specific files\nnpx stryker run --mutate \"src/utils/**/*.ts\"\n\n# With specific configuration\nnpx stryker run --configFile stryker.prod.config.mjs\n\n# Generate HTML report\nnpx stryker run --reporters html,clear-text\n\n# Open HTML report\nopen reports/mutation/html/index.html\n```\n\n### Understanding Results\n\n```\nMutation score: 82.5%\n- Killed: 66 (tests caught the mutation)\n- Survived: 14 (tests passed despite mutation - weak tests!)\n- No Coverage: 0 (mutated code not executed)\n- Timeout: 0 (tests took too long)\n- Runtime Errors: 0 (mutation broke the code)\n- Compile Errors: 0 (mutation caused syntax error)\n```\n\n### Example: Weak Test\n\n```typescript\n// Source code\nfunction calculateDiscount(price: number, percentage: number): number {\n  return price - (price * percentage / 100)\n}\n\n//  WEAK: Test passes even if we mutate the calculation\ntest('applies discount', () => {\n  const result = calculateDiscount(100, 10)\n  expect(result).toBeDefined() // Too weak!\n})\n\n// Stryker mutates the code:\n// function calculateDiscount(price: number, percentage: number): number {\n//   return price + (price * percentage / 100)  // Changed - to +\n// }\n// Test still passes!  Survived mutant\n\n//  STRONG: Test catches mutation\ntest('applies discount correctly', () => {\n  expect(calculateDiscount(100, 10)).toBe(90)\n  expect(calculateDiscount(100, 20)).toBe(80)\n  expect(calculateDiscount(50, 10)).toBe(45)\n})\n// Mutation causes test to fail  Killed mutant\n```\n\n### Common Mutation Types\n\n```typescript\n// Arithmetic Operator\n// Original: a + b\n// Mutants: a - b, a * b, a / b\n\n// Relational Operator\n// Original: a > b\n// Mutants: a >= b, a < b, a <= b, a === b\n\n// Conditional Boundary\n// Original: a >= 10\n// Mutants: a > 10, a < 10\n\n// Logical Operator\n// Original: a && b\n// Mutants: a || b, a, b\n\n// Unary Operator\n// Original: !condition\n// Mutants: condition\n\n// String Literal\n// Original: 'hello'\n// Mutants: '', 'Stryker was here!'\n\n// Boolean Literal\n// Original: true\n// Mutants: false\n\n// Array Declaration\n// Original: [1, 2, 3]\n// Mutants: []\n```\n\n### Ignoring Specific Mutations\n\n```typescript\n// Disable mutation for a block\n// Stryker disable all\nfunction debugOnlyCode() {\n  console.log('This won\\'t be mutated')\n}\n// Stryker restore all\n\n// Disable specific mutator\n// Stryker disable next-line ArithmeticOperator\nconst total = price + tax\n```\n\n### CI/CD Integration\n\n```yaml\n# .github/workflows/mutation.yml\nname: Mutation Testing\n\non:\n  pull_request:\n    branches: [main]\n\njobs:\n  mutation:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Setup Bun\n        uses: oven-sh/setup-bun@v1\n\n      - name: Install dependencies\n        run: bun install\n\n      - name: Run mutation tests\n        run: bun run stryker run\n\n      - name: Upload mutation report\n        uses: actions/upload-artifact@v3\n        if: always()\n        with:\n          name: mutation-report\n          path: reports/mutation/html/\n```\n\n## Python (mutmut)\n\n### Installation\n\n```bash\n# Using uv\nuv add --dev mutmut\n\n# Using pip\npip install mutmut\n```\n\n### Basic Configuration\n\n```toml\n# pyproject.toml\n[tool.mutmut]\npaths_to_mutate = \"src/\"\nbackup = false\nrunner = \"python -m pytest -x --assert=plain -q\"\ntests_dir = \"tests/\"\n```\n\n### Running mutmut\n\n```bash\n# Run mutation testing\nuv run mutmut run\n\n# Run on specific paths\nuv run mutmut run --paths-to-mutate=src/calculator.py\n\n# Show results\nuv run mutmut results\n\n# Show summary\nuv run mutmut summary\n\n# Show specific mutant\nuv run mutmut show 1\n\n# Apply a mutant (to test it manually)\nuv run mutmut apply 1\n\n# Generate HTML report\nuv run mutmut html\nopen html/index.html\n```\n\n### Understanding Results\n\n```\nStatus: 45/50 mutants killed (90%)\n- Killed: 45 (tests caught the mutation)\n- Survived: 5 (tests passed despite mutation)\n- Suspicious: 0 (inconsistent results)\n- Timeout: 0 (tests took too long)\n```\n\n### Example: Improving Weak Test\n\n```python\n# Source code\ndef calculate_discount(price: float, percentage: float) -> float:\n    return price - (price * percentage / 100)\n\n#  WEAK: Test passes with mutations\ndef test_applies_discount():\n    result = calculate_discount(100, 10)\n    assert result is not None  # Too weak!\n    # mutmut can change the calculation and test still passes\n\n#  STRONG: Test catches mutations\ndef test_applies_discount_correctly():\n    assert calculate_discount(100, 10) == 90.0\n    assert calculate_discount(100, 20) == 80.0\n    assert calculate_discount(50, 10) == 45.0\n    assert calculate_discount(0, 10) == 0.0\n```\n\n### Common Mutation Types (Python)\n\n```python\n# Arithmetic operators\n# Original: a + b  a - b, a * b, a / b, a // b, a % b\n\n# Comparison operators\n# Original: a > b  a >= b, a < b, a <= b, a == b, a != b\n\n# Logical operators\n# Original: a and b  a or b, a, b\n\n# Assignment operators\n# Original: a += 1  a -= 1, a *= 1, a /= 1\n\n# Boolean literals\n# Original: True  False\n\n# Number literals\n# Original: 42  43, 41\n\n# String literals\n# Original: \"hello\"  \"XXhelloXX\", \"\"\n```\n\n### Filtering Results\n\n```bash\n# Show only survived mutants\nuv run mutmut results | grep \"^Survived\"\n\n# Show killed mutants\nuv run mutmut results | grep \"^Killed\"\n\n# Show mutants for specific file\nuv run mutmut show src/calculator.py\n```\n\n### Excluding Code from Mutation\n\n```python\n# Exclude entire function\n# pragma: no mutate\ndef legacy_code():\n    pass\n\n# Exclude specific line\nresult = expensive_computation()  # pragma: no mutate\n```\n\n### CI/CD Integration\n\n```yaml\n# .github/workflows/mutation.yml\nname: Mutation Testing\n\non:\n  pull_request:\n    branches: [main]\n\njobs:\n  mutation:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Install uv\n        uses: astral-sh/setup-uv@v1\n\n      - name: Install dependencies\n        run: uv sync\n\n      - name: Run mutation tests\n        run: uv run mutmut run\n\n      - name: Show results\n        if: always()\n        run: uv run mutmut results\n\n      - name: Generate HTML report\n        if: always()\n        run: uv run mutmut html\n\n      - name: Upload report\n        uses: actions/upload-artifact@v3\n        if: always()\n        with:\n          name: mutation-report\n          path: html/\n```\n\n## Interpreting Results\n\n### Mutation Score Targets\n\n| Score | Quality | Action |\n|-------|---------|--------|\n| 90%+ | Excellent | Maintain quality |\n| 80-89% | Good | Small improvements |\n| 70-79% | Acceptable | Focus on weak areas |\n| 60-69% | Needs work | Add missing tests |\n| < 60% | Poor | Major test improvements needed |\n\n### Survived Mutants Analysis\n\n**Common Reasons Mutants Survive:**\n\n1. **Missing assertions**\n```typescript\n// Mutant survives\ntest('processes data', () => {\n  processData(input)\n  // No assertion!\n})\n\n// Fix: Add assertion\ntest('processes data', () => {\n  const result = processData(input)\n  expect(result).toEqual(expected)\n})\n```\n\n2. **Weak assertions**\n```python\n# Mutant survives\ndef test_calculation():\n    result = calculate(10, 5)\n    assert result > 0  # Too weak!\n\n# Fix: Specific assertion\ndef test_calculation():\n    result = calculate(10, 5)\n    assert result == 15\n```\n\n3. **Dead code**\n```typescript\nfunction example(x: number) {\n  if (x > 10) {\n    return 'large'\n  }\n  if (x < 0) {\n    return 'negative'\n  }\n  return 'small'\n  // Unreachable code mutated but never executed\n}\n\n// Fix: Remove dead code or add test\ntest('handles edge case', () => {\n  expect(example(0)).toBe('small')\n})\n```\n\n4. **Equivalent mutants**\n```typescript\n// Original\nconst result = x + 0\n\n// Mutant (mathematically equivalent)\nconst result = x - 0\n\n// Both produce same result - valid survivor\n```\n\n## Best Practices\n\n**When to Run Mutation Tests**\n- After achieving high code coverage (80%+)\n- Before major releases\n- On critical business logic modules\n- When test quality is questioned\n- In CI for important branches\n\n**Incremental Approach**\n1. Start with core business logic modules\n2. Fix survived mutants\n3. Gradually expand coverage\n4. Integrate into CI pipeline\n5. Maintain high mutation score\n\n**Performance Optimization**\n```typescript\n// Stryker\nexport default {\n  // Only mutate changed files\n  incremental: true,\n\n  // Focus on important files\n  mutate: ['src/core/**/*.ts', 'src/utils/**/*.ts'],\n\n  // Skip slow tests\n  disableTypeChecks: '{src,test}/**/*.ts',\n\n  // Adjust concurrency\n  concurrency: 4,\n}\n```\n\n```bash\n# mutmut - incremental runs\nuv run mutmut run --paths-to-mutate=src/core/\n```\n\n**Common Pitfalls**\n-  Running mutation tests before basic coverage\n-  Expecting 100% mutation score\n-  Not excluding generated code\n-  Treating equivalent mutants as failures\n-  Running full mutation suite on every commit\n\n**Integration with Coverage**\n```bash\n# 1. First, ensure good coverage\nvitest --coverage\n# Target: 80%+ coverage\n\n# 2. Then, validate test quality with mutations\nnpx stryker run\n# Target: 80%+ mutation score\n```\n\n## Workflow Example\n\n### TypeScript/Vitest/Stryker\n\n```bash\n# 1. Write tests with coverage\nbun test --coverage\n\n# 2. Check coverage report\nopen coverage/index.html\n# Ensure 80%+ coverage\n\n# 3. Run mutation testing\nnpx stryker run\n\n# 4. Check mutation report\nopen reports/mutation/html/index.html\n\n# 5. Fix survived mutants by improving tests\n# (Review each survived mutant)\n\n# 6. Re-run mutation tests\nnpx stryker run --incremental\n```\n\n### Python/pytest/mutmut\n\n```bash\n# 1. Write tests with coverage\nuv run pytest --cov\n\n# 2. Check coverage report\nuv run pytest --cov --cov-report=html\nopen htmlcov/index.html\n# Ensure 80%+ coverage\n\n# 3. Run mutation testing\nuv run mutmut run\n\n# 4. Check results\nuv run mutmut results\n\n# 5. Investigate survived mutants\nuv run mutmut show <id>\n\n# 6. Fix weak tests\n\n# 7. Re-run on updated files\nuv run mutmut run --paths-to-mutate=src/fixed_module.py\n```\n\n## Improving Weak Tests\n\n### Pattern: Insufficient Assertions\n\n```typescript\n// Before: Mutation survives\ntest('calculates sum', () => {\n  const result = sum([1, 2, 3])\n  expect(result).toBeGreaterThan(0) // Weak!\n})\n\n// After: Mutation killed\ntest('calculates sum correctly', () => {\n  expect(sum([1, 2, 3])).toBe(6)\n  expect(sum([0, 0, 0])).toBe(0)\n  expect(sum([-1, 1])).toBe(0)\n  expect(sum([])).toBe(0)\n})\n```\n\n### Pattern: Missing Edge Cases\n\n```python\n# Before: Mutation survives\ndef test_divide():\n    result = divide(10, 2)\n    assert result == 5\n\n# After: Mutation killed\ndef test_divide():\n    assert divide(10, 2) == 5\n    assert divide(9, 3) == 3\n    assert divide(7, 2) == 3.5\n    with pytest.raises(ZeroDivisionError):\n        divide(10, 0)\n```\n\n### Pattern: Boundary Conditions\n\n```typescript\n// Before: Mutation survives\ntest('validates age', () => {\n  expect(isValidAge(25)).toBe(true)\n})\n\n// After: Mutation killed (tests boundaries)\ntest('validates age boundaries', () => {\n  expect(isValidAge(18)).toBe(true)   // Min valid\n  expect(isValidAge(17)).toBe(false)  // Just below\n  expect(isValidAge(100)).toBe(true)  // Max valid\n  expect(isValidAge(101)).toBe(false) // Just above\n  expect(isValidAge(0)).toBe(false)\n  expect(isValidAge(-1)).toBe(false)\n})\n```\n\n## Troubleshooting\n\n**Mutation tests taking too long**\n```typescript\n// Stryker: Increase concurrency\nexport default {\n  concurrency: Math.max(os.cpus().length - 1, 1),\n  timeoutMS: 30000,\n}\n```\n\n```bash\n# mutmut: Use caching\nuv run mutmut run --use-coverage\n```\n\n**Too many survived mutants**\n- Focus on critical modules first\n- Add specific assertions\n- Test boundary conditions\n- Review mutation details\n\n**All tests failing**\n```bash\n# Verify tests pass before mutations\nbun test  # or uv run pytest\n```\n\n**False positives (equivalent mutants)**\n```typescript\n// Ignore mathematically equivalent mutants\n// Stryker disable next-line all\nconst result = x + 0\n```\n\n## See Also\n\n- `vitest-testing` - Unit testing framework\n- `python-testing` - Python pytest testing\n- `test-quality-analysis` - Detecting test smells\n- `api-testing` - HTTP API testing\n\n## References\n\n- Stryker: https://stryker-mutator.io/\n- mutmut: https://github.com/boxed/mutmut\n- Mutation Testing Intro: https://en.wikipedia.org/wiki/Mutation_testing"
              },
              {
                "name": "Playwright Testing",
                "description": "Playwright end-to-end testing for web applications. Cross-browser testing (Chromium, Firefox, WebKit),\nvisual regression, API testing, mobile emulation. Use when writing E2E tests, testing across browsers,\nor setting up automated UI testing workflows.\n",
                "path": "testing-plugin/skills/playwright-testing/SKILL.md",
                "frontmatter": {
                  "created": "2025-12-16T00:00:00.000Z",
                  "modified": "2025-12-16T00:00:00.000Z",
                  "reviewed": "2025-12-16T00:00:00.000Z",
                  "name": "Playwright Testing",
                  "description": "Playwright end-to-end testing for web applications. Cross-browser testing (Chromium, Firefox, WebKit),\nvisual regression, API testing, mobile emulation. Use when writing E2E tests, testing across browsers,\nor setting up automated UI testing workflows.\n",
                  "allowed-tools": "Glob, Grep, Read, Bash, Edit, Write, TodoWrite, WebFetch, WebSearch, BashOutput, KillShell"
                },
                "content": "# Playwright Testing\n\nPlaywright is a modern end-to-end testing framework for web applications. It provides reliable, fast, and cross-browser testing with excellent developer experience.\n\n## Core Expertise\n\n**What is Playwright?**\n- **Cross-browser**: Test on Chromium, Firefox, WebKit (Safari)\n- **Reliable**: Auto-wait, auto-retry, no flaky tests\n- **Fast**: Parallel execution, browser context isolation\n- **Modern**: TypeScript-first, async/await, auto-complete\n- **Multi-platform**: Windows, macOS, Linux\n\n**Key Capabilities**\n- End-to-end UI testing\n- API testing (REST, GraphQL)\n- Visual regression testing\n- Mobile emulation\n- Network interception and mocking\n- Authentication state management\n- Parallel test execution\n- Video and screenshot capture\n- Trace viewer for debugging\n\n## Installation\n\n```bash\n# Initialize Playwright (recommended)\nbun create playwright\n\n# Or install manually\nbun add --dev @playwright/test\n\n# Install browsers\nbunx playwright install\n\n# Install with system dependencies (Linux)\nbunx playwright install --with-deps\n\n# Verify installation\nbunx playwright --version\n```\n\n## Configuration (playwright.config.ts)\n\n### Minimal Setup\n\n```typescript\n// playwright.config.ts\nimport { defineConfig, devices } from '@playwright/test';\n\nexport default defineConfig({\n  testDir: './tests',\n  timeout: 30000,\n  use: {\n    baseURL: 'http://localhost:3000',\n    trace: 'on-first-retry',\n  },\n  projects: [\n    {\n      name: 'chromium',\n      use: { ...devices['Desktop Chrome'] },\n    },\n  ],\n});\n```\n\n### Recommended Production Setup\n\n```typescript\n// playwright.config.ts\nimport { defineConfig, devices } from '@playwright/test';\n\nexport default defineConfig({\n  testDir: './tests',\n  fullyParallel: true,\n  forbidOnly: !!process.env.CI,\n  retries: process.env.CI ? 2 : 0,\n  workers: process.env.CI ? 1 : undefined,\n  reporter: [\n    ['html'],\n    ['json', { outputFile: 'test-results/results.json' }],\n    ['junit', { outputFile: 'test-results/junit.xml' }],\n  ],\n  timeout: 30000,\n  expect: {\n    timeout: 5000,\n  },\n  use: {\n    baseURL: process.env.BASE_URL || 'http://localhost:3000',\n    trace: 'on-first-retry',\n    screenshot: 'only-on-failure',\n    video: 'retain-on-failure',\n    actionTimeout: 10000,\n    navigationTimeout: 30000,\n  },\n  projects: [\n    {\n      name: 'chromium',\n      use: { ...devices['Desktop Chrome'] },\n    },\n    {\n      name: 'firefox',\n      use: { ...devices['Desktop Firefox'] },\n    },\n    {\n      name: 'webkit',\n      use: { ...devices['Desktop Safari'] },\n    },\n    {\n      name: 'mobile-chrome',\n      use: { ...devices['Pixel 5'] },\n    },\n    {\n      name: 'mobile-safari',\n      use: { ...devices['iPhone 13'] },\n    },\n  ],\n  webServer: {\n    command: 'bun run dev',\n    url: 'http://localhost:3000',\n    reuseExistingServer: !process.env.CI,\n    timeout: 120000,\n  },\n});\n```\n\n## Essential Commands\n\n```bash\n# Run all tests\nbunx playwright test\n\n# Run specific test file\nbunx playwright test tests/login.spec.ts\n\n# Run tests in headed mode (see browser)\nbunx playwright test --headed\n\n# Run tests in debug mode\nbunx playwright test --debug\n\n# Run specific project (browser)\nbunx playwright test --project=chromium\n\n# Run tests in UI mode\nbunx playwright test --ui\n\n# Generate tests (record interactions)\nbunx playwright codegen http://localhost:3000\n\n# Open last test report\nbunx playwright show-report\n\n# Open trace viewer\nbunx playwright show-trace trace.zip\n\n# Update snapshots\nbunx playwright test --update-snapshots\n```\n\n## Writing Tests\n\n### Basic Test Structure\n\n```typescript\n// tests/example.spec.ts\nimport { test, expect } from '@playwright/test';\n\ntest('basic test', async ({ page }) => {\n  await page.goto('https://example.com');\n  await expect(page).toHaveTitle(/Example/);\n});\n\ntest.describe('login flow', () => {\n  test('should login successfully', async ({ page }) => {\n    await page.goto('/login');\n    await page.fill('input[name=\"email\"]', 'user@example.com');\n    await page.fill('input[name=\"password\"]', 'password123');\n    await page.click('button[type=\"submit\"]');\n    await expect(page).toHaveURL('/dashboard');\n  });\n});\n```\n\n### Selectors and Locators\n\n```typescript\nimport { test, expect } from '@playwright/test';\n\ntest('selectors', async ({ page }) => {\n  await page.goto('/');\n\n  // Text selector (recommended)\n  await page.getByText('Sign in').click();\n  await page.getByRole('button', { name: 'Submit' }).click();\n\n  // Label selector\n  await page.getByLabel('Email').fill('user@example.com');\n\n  // Placeholder selector\n  await page.getByPlaceholder('Enter your name').fill('John');\n\n  // Test ID selector\n  await page.getByTestId('login-button').click();\n\n  // CSS selector\n  await page.locator('.button-primary').click();\n\n  // XPath selector\n  await page.locator('xpath=//button[text()=\"Submit\"]').click();\n\n  // Chaining selectors\n  await page\n    .locator('.card')\n    .filter({ hasText: 'Product' })\n    .getByRole('button')\n    .click();\n});\n```\n\n### Assertions\n\n```typescript\nimport { test, expect } from '@playwright/test';\n\ntest('assertions', async ({ page }) => {\n  await page.goto('/');\n\n  // Page assertions\n  await expect(page).toHaveTitle('My App');\n  await expect(page).toHaveURL(/dashboard/);\n\n  // Element assertions\n  const button = page.getByRole('button');\n  await expect(button).toBeVisible();\n  await expect(button).toBeEnabled();\n  await expect(button).toHaveText('Submit');\n  await expect(button).toContainText('Sub');\n  await expect(button).toHaveAttribute('type', 'submit');\n  await expect(button).toHaveClass(/btn-primary/);\n\n  // Input assertions\n  const input = page.getByLabel('Email');\n  await expect(input).toHaveValue('user@example.com');\n  await expect(input).toBeEmpty();\n\n  // Count assertions\n  await expect(page.locator('.item')).toHaveCount(5);\n\n  // Negation\n  await expect(button).not.toBeDisabled();\n});\n```\n\n### Page Object Model\n\n```typescript\n// page-objects/login-page.ts\nimport { Page, Locator } from '@playwright/test';\n\nexport class LoginPage {\n  readonly page: Page;\n  readonly emailInput: Locator;\n  readonly passwordInput: Locator;\n  readonly submitButton: Locator;\n\n  constructor(page: Page) {\n    this.page = page;\n    this.emailInput = page.getByLabel('Email');\n    this.passwordInput = page.getByLabel('Password');\n    this.submitButton = page.getByRole('button', { name: 'Sign in' });\n  }\n\n  async goto() {\n    await this.page.goto('/login');\n  }\n\n  async login(email: string, password: string) {\n    await this.emailInput.fill(email);\n    await this.passwordInput.fill(password);\n    await this.submitButton.click();\n  }\n}\n\n// tests/login.spec.ts\nimport { test, expect } from '@playwright/test';\nimport { LoginPage } from '../page-objects/login-page';\n\ntest('login with page object', async ({ page }) => {\n  const loginPage = new LoginPage(page);\n  await loginPage.goto();\n  await loginPage.login('user@example.com', 'password123');\n  await expect(page).toHaveURL('/dashboard');\n});\n```\n\n## Fixtures\n\n### Built-in Fixtures\n\n```typescript\nimport { test } from '@playwright/test';\n\ntest('built-in fixtures', async ({ page, context, browser }) => {\n  // page - isolated browser page\n  await page.goto('/');\n\n  // context - browser context (cookies, storage)\n  await context.clearCookies();\n\n  // browser - browser instance\n  const newPage = await browser.newPage();\n});\n```\n\n### Custom Fixtures\n\n```typescript\n// fixtures/auth-fixture.ts\nimport { test as base } from '@playwright/test';\nimport { LoginPage } from '../page-objects/login-page';\n\ntype AuthFixtures = {\n  authenticatedPage: Page;\n};\n\nexport const test = base.extend<AuthFixtures>({\n  authenticatedPage: async ({ page }, use) => {\n    const loginPage = new LoginPage(page);\n    await loginPage.goto();\n    await loginPage.login('user@example.com', 'password123');\n    await use(page);\n  },\n});\n\n// tests/dashboard.spec.ts\nimport { test } from '../fixtures/auth-fixture';\n\ntest('access dashboard', async ({ authenticatedPage }) => {\n  await authenticatedPage.goto('/dashboard');\n  // User is already logged in\n});\n```\n\n## Authentication State\n\n### Save Authentication State\n\n```typescript\n// tests/auth.setup.ts\nimport { test as setup } from '@playwright/test';\n\nconst authFile = 'playwright/.auth/user.json';\n\nsetup('authenticate', async ({ page }) => {\n  await page.goto('/login');\n  await page.getByLabel('Email').fill('user@example.com');\n  await page.getByLabel('Password').fill('password123');\n  await page.getByRole('button', { name: 'Sign in' }).click();\n\n  await page.waitForURL('/dashboard');\n\n  await page.context().storageState({ path: authFile });\n});\n```\n\n### Use Saved State\n\n```typescript\n// playwright.config.ts\nexport default defineConfig({\n  projects: [\n    { name: 'setup', testMatch: /.*\\.setup\\.ts/ },\n    {\n      name: 'chromium',\n      use: {\n        ...devices['Desktop Chrome'],\n        storageState: 'playwright/.auth/user.json',\n      },\n      dependencies: ['setup'],\n    },\n  ],\n});\n```\n\n## API Testing\n\n```typescript\nimport { test, expect } from '@playwright/test';\n\ntest('api testing', async ({ request }) => {\n  // GET request\n  const response = await request.get('https://api.example.com/users');\n  expect(response.ok()).toBeTruthy();\n  expect(response.status()).toBe(200);\n\n  const users = await response.json();\n  expect(users).toHaveLength(10);\n\n  // POST request\n  const createResponse = await request.post('https://api.example.com/users', {\n    data: {\n      name: 'John Doe',\n      email: 'john@example.com',\n    },\n  });\n  expect(createResponse.ok()).toBeTruthy();\n\n  // With authentication\n  const authResponse = await request.get('https://api.example.com/profile', {\n    headers: {\n      Authorization: 'Bearer token123',\n    },\n  });\n  expect(authResponse.ok()).toBeTruthy();\n});\n```\n\n## Network Interception\n\n```typescript\nimport { test, expect } from '@playwright/test';\n\ntest('mock api response', async ({ page }) => {\n  // Mock API response\n  await page.route('**/api/users', (route) => {\n    route.fulfill({\n      status: 200,\n      contentType: 'application/json',\n      body: JSON.stringify([\n        { id: 1, name: 'John' },\n        { id: 2, name: 'Jane' },\n      ]),\n    });\n  });\n\n  await page.goto('/users');\n  await expect(page.getByText('John')).toBeVisible();\n});\n\ntest('block images', async ({ page }) => {\n  // Block image requests\n  await page.route('**/*.{png,jpg,jpeg}', (route) => route.abort());\n\n  await page.goto('/');\n  // Page loads faster without images\n});\n\ntest('intercept and modify', async ({ page }) => {\n  await page.route('**/api/config', async (route) => {\n    const response = await route.fetch();\n    const json = await response.json();\n    json.feature_flag = true;\n    await route.fulfill({ json });\n  });\n\n  await page.goto('/');\n});\n```\n\n## Visual Regression Testing\n\n```typescript\nimport { test, expect } from '@playwright/test';\n\ntest('visual regression', async ({ page }) => {\n  await page.goto('/');\n\n  // Full page screenshot\n  await expect(page).toHaveScreenshot('homepage.png');\n\n  // Element screenshot\n  const header = page.locator('header');\n  await expect(header).toHaveScreenshot('header.png');\n\n  // With options\n  await expect(page).toHaveScreenshot('homepage-mobile.png', {\n    fullPage: true,\n    maxDiffPixels: 100,\n  });\n});\n\n// Update snapshots with:\n// bunx playwright test --update-snapshots\n```\n\n## Mobile Emulation\n\n```typescript\nimport { test, devices } from '@playwright/test';\n\ntest.use({\n  ...devices['iPhone 13'],\n});\n\ntest('mobile test', async ({ page }) => {\n  await page.goto('/');\n  // Test runs in iPhone 13 viewport\n});\n\n// Or configure in playwright.config.ts:\n// projects: [\n//   {\n//     name: 'mobile',\n//     use: { ...devices['Pixel 5'] },\n//   },\n// ]\n```\n\n## Parallel Execution\n\n```typescript\n// playwright.config.ts\nexport default defineConfig({\n  fullyParallel: true,\n  workers: process.env.CI ? 1 : undefined, // All cores locally, 1 in CI\n});\n\n// Force serial execution for specific tests\ntest.describe.serial('checkout flow', () => {\n  test('add to cart', async ({ page }) => {\n    // ...\n  });\n\n  test('proceed to checkout', async ({ page }) => {\n    // Runs after previous test\n  });\n});\n```\n\n## Debugging\n\n### Debug Mode\n\n```bash\n# Run with debugger\nbunx playwright test --debug\n\n# Debug specific test\nbunx playwright test tests/login.spec.ts --debug\n\n# Pause on failure\nbunx playwright test --headed --pause-on-failure\n```\n\n### Trace Viewer\n\n```typescript\n// playwright.config.ts\nexport default defineConfig({\n  use: {\n    trace: 'on-first-retry', // or 'on', 'off', 'retain-on-failure'\n  },\n});\n```\n\n```bash\n# View trace\nbunx playwright show-trace trace.zip\n```\n\n**Trace viewer shows:**\n- Timeline of actions\n- Screenshots at each step\n- Network activity\n- Console logs\n- Source code\n\n## CI/CD Integration\n\n### GitHub Actions\n\n```yaml\nname: Playwright Tests\non:\n  push:\n    branches: [main]\n  pull_request:\n\njobs:\n  test:\n    timeout-minutes: 60\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n\n      - uses: oven-sh/setup-bun@v2\n        with:\n          bun-version: latest\n\n      - name: Install dependencies\n        run: bun install --frozen-lockfile\n\n      - name: Install Playwright Browsers\n        run: bunx playwright install --with-deps\n\n      - name: Run Playwright tests\n        run: bunx playwright test\n\n      - name: Upload test results\n        uses: actions/upload-artifact@v4\n        if: always()\n        with:\n          name: playwright-report\n          path: playwright-report/\n          retention-days: 30\n```\n\n### GitLab CI\n\n```yaml\nplaywright:\n  image: mcr.microsoft.com/playwright:v1.40.0-jammy\n  stage: test\n  script:\n    - bun install --frozen-lockfile\n    - bunx playwright test\n  artifacts:\n    when: always\n    paths:\n      - playwright-report/\n      - test-results/\n    expire_in: 1 week\n```\n\n## Best Practices\n\n### Use Built-in Locators\n\n```typescript\n//  Good: Resilient to UI changes\nawait page.getByRole('button', { name: 'Submit' }).click();\nawait page.getByLabel('Email').fill('user@example.com');\nawait page.getByText('Welcome').click();\n\n//  Bad: Fragile selectors\nawait page.locator('#submit-btn-123').click();\nawait page.locator('div > div > input').fill('user@example.com');\n```\n\n### Auto-waiting\n\n```typescript\n//  Good: Playwright waits automatically\nawait page.getByRole('button').click();\n\n//  Bad: Manual waits\nawait page.waitForTimeout(1000);\nawait page.getByRole('button').click();\n```\n\n### Isolate Tests\n\n```typescript\n//  Good: Independent tests\ntest('test 1', async ({ page }) => {\n  await page.goto('/');\n  // Test logic\n});\n\ntest('test 2', async ({ page }) => {\n  await page.goto('/');\n  // Independent test logic\n});\n\n//  Bad: Tests depend on each other\n```\n\n### Use Test IDs for Dynamic Content\n\n```html\n<!-- HTML -->\n<button data-testid=\"submit-btn\">Submit</button>\n```\n\n```typescript\n// Test\nawait page.getByTestId('submit-btn').click();\n```\n\n## Troubleshooting\n\n### Tests Timing Out\n\n```typescript\n// Increase timeout for specific test\ntest('slow test', async ({ page }) => {\n  test.setTimeout(60000);\n  await page.goto('/slow-page');\n});\n\n// Or in config:\nexport default defineConfig({\n  timeout: 60000,\n  expect: {\n    timeout: 10000,\n  },\n});\n```\n\n### Flaky Tests\n\n```bash\n# Run test multiple times\nbunx playwright test --repeat-each=10\n\n# Retry failed tests\nbunx playwright test --retries=3\n```\n\n### Element Not Found\n\n```typescript\n// Wait for element explicitly\nawait page.waitForSelector('.element');\n\n// Or use auto-wait assertions\nawait expect(page.locator('.element')).toBeVisible();\n```\n\n### Browser Not Found\n\n```bash\n# Reinstall browsers\nbunx playwright install\n\n# Verify installation\nbunx playwright install --help\n```\n\n## References\n\n- Official docs: https://playwright.dev\n- Configuration: https://playwright.dev/docs/test-configuration\n- API reference: https://playwright.dev/docs/api/class-test\n- Best practices: https://playwright.dev/docs/best-practices\n- CI/CD: https://playwright.dev/docs/ci\n- Trace viewer: https://playwright.dev/docs/trace-viewer"
              },
              {
                "name": "property-based-testing",
                "description": "Property-based testing with fast-check (TypeScript/JavaScript) and Hypothesis (Python).\nGenerate test cases automatically, find edge cases, and test mathematical properties.\nUse when user mentions property-based testing, fast-check, Hypothesis, generating\ntest data, QuickCheck-style testing, or finding edge cases automatically.\n",
                "path": "testing-plugin/skills/property-based-testing/SKILL.md",
                "frontmatter": {
                  "created": "2025-12-16T00:00:00.000Z",
                  "modified": "2025-12-16T00:00:00.000Z",
                  "reviewed": "2025-12-16T00:00:00.000Z",
                  "name": "property-based-testing",
                  "description": "Property-based testing with fast-check (TypeScript/JavaScript) and Hypothesis (Python).\nGenerate test cases automatically, find edge cases, and test mathematical properties.\nUse when user mentions property-based testing, fast-check, Hypothesis, generating\ntest data, QuickCheck-style testing, or finding edge cases automatically.\n",
                  "allowed-tools": "Bash, Read, Edit, Write, Grep, Glob, TodoWrite"
                },
                "content": "# Property-Based Testing\n\nExpert knowledge for property-based testing - automatically generating test cases to verify code properties rather than testing specific examples.\n\n## Core Expertise\n\n**Property-Based Testing Concept**\n- **Traditional testing**: Test specific examples\n- **Property-based testing**: Test properties that should hold for all inputs\n- **Generators**: Automatically create diverse test inputs\n- **Shrinking**: Minimize failing cases to simplest example\n- **Coverage**: Explore edge cases humans might miss\n\n**When to Use Property-Based Testing**\n- Mathematical operations (commutative, associative properties)\n- Encoders/decoders (roundtrip properties)\n- Parsers and serializers\n- Data transformations\n- API contracts\n- Invariants and constraints\n\n## TypeScript/JavaScript (fast-check)\n\n### Installation\n\n```bash\n# Using Bun\nbun add -d fast-check\n\n# Using npm\nnpm install -D fast-check\n```\n\n### Basic Example\n\n```typescript\nimport { test } from 'vitest'\nimport * as fc from 'fast-check'\n\n// Traditional example-based test\ntest('reverse twice returns original', () => {\n  expect(reverse(reverse([1, 2, 3]))).toEqual([1, 2, 3])\n})\n\n// Property-based test\ntest('reverse twice returns original - property based', () => {\n  fc.assert(\n    fc.property(\n      fc.array(fc.integer()), // Generate random arrays of integers\n      (arr) => {\n        expect(reverse(reverse(arr))).toEqual(arr)\n      }\n    )\n  )\n})\n// fast-check automatically generates 100s of test cases!\n```\n\n### Built-in Generators\n\n```typescript\nimport * as fc from 'fast-check'\n\n// Numbers\nfc.integer()                          // Any integer\nfc.integer({ min: 0, max: 100 })      // Range\nfc.nat()                              // Natural numbers ( 0)\nfc.float()                            // Floating-point\nfc.double()                           // Double precision\n\n// Strings\nfc.string()                           // Any string\nfc.string({ minLength: 1, maxLength: 10 })\nfc.hexaString()                       // Hex strings\nfc.asciiString()                      // ASCII only\nfc.unicodeString()                    // Unicode\nfc.emailAddress()                     // Email format\n\n// Arrays and Objects\nfc.array(fc.integer())                // Array of integers\nfc.array(fc.string(), { minLength: 1, maxLength: 5 })\nfc.set(fc.integer())                  // Unique values\nfc.record({                           // Objects\n  name: fc.string(),\n  age: fc.nat(),\n})\n\n// Booleans and Constants\nfc.boolean()\nfc.constant('value')\nfc.constantFrom('a', 'b', 'c')        // Pick from options\n\n// Dates\nfc.date()\nfc.date({ min: new Date('2020-01-01') })\n\n// Complex Types\nfc.tuple(fc.string(), fc.integer())   // Fixed-size tuple\nfc.oneof(fc.string(), fc.integer())   // Union type\nfc.option(fc.string())                // string | null\n```\n\n### Custom Generators\n\n```typescript\n// Generate user objects\nconst userArbitrary = fc.record({\n  id: fc.nat(),\n  name: fc.string({ minLength: 1, maxLength: 50 }),\n  email: fc.emailAddress(),\n  age: fc.integer({ min: 18, max: 120 }),\n  roles: fc.array(fc.constantFrom('admin', 'user', 'guest'), {\n    minLength: 1,\n    maxLength: 3,\n  }),\n})\n\ntest('user validation properties', () => {\n  fc.assert(\n    fc.property(userArbitrary, (user) => {\n      const validated = validateUser(user)\n      expect(validated.age).toBeGreaterThanOrEqual(18)\n      expect(validated.name.length).toBeGreaterThan(0)\n      expect(validated.roles.length).toBeGreaterThan(0)\n    })\n  )\n})\n\n// Generate using map\nconst positiveNumberArbitrary = fc.nat().map((n) => n + 1)\n\n// Generate using chain (dependent values)\nconst emailAndDomainArbitrary = fc.string().chain((domain) =>\n  fc.record({\n    email: fc.constant(`user@${domain}.com`),\n    domain: fc.constant(domain),\n  })\n)\n```\n\n### Common Properties to Test\n\n#### Roundtrip Property (Encode/Decode)\n\n```typescript\ntest('JSON serialization roundtrip', () => {\n  fc.assert(\n    fc.property(\n      fc.record({\n        name: fc.string(),\n        age: fc.nat(),\n        tags: fc.array(fc.string()),\n      }),\n      (obj) => {\n        const serialized = JSON.stringify(obj)\n        const deserialized = JSON.parse(serialized)\n        expect(deserialized).toEqual(obj)\n      }\n    )\n  )\n})\n```\n\n#### Idempotence (f(f(x)) = f(x))\n\n```typescript\ntest('sort is idempotent', () => {\n  fc.assert(\n    fc.property(fc.array(fc.integer()), (arr) => {\n      const sorted = sort(arr)\n      const doubleSorted = sort(sorted)\n      expect(doubleSorted).toEqual(sorted)\n    })\n  )\n})\n```\n\n#### Commutativity (f(a, b) = f(b, a))\n\n```typescript\ntest('addition is commutative', () => {\n  fc.assert(\n    fc.property(fc.integer(), fc.integer(), (a, b) => {\n      expect(add(a, b)).toBe(add(b, a))\n    })\n  )\n})\n```\n\n#### Associativity ((a + b) + c = a + (b + c))\n\n```typescript\ntest('addition is associative', () => {\n  fc.assert(\n    fc.property(fc.integer(), fc.integer(), fc.integer(), (a, b, c) => {\n      expect(add(add(a, b), c)).toBe(add(a, add(b, c)))\n    })\n  )\n})\n```\n\n#### Identity (f(x, identity) = x)\n\n```typescript\ntest('multiplication identity', () => {\n  fc.assert(\n    fc.property(fc.integer(), (n) => {\n      expect(multiply(n, 1)).toBe(n)\n    })\n  )\n})\n```\n\n#### Inverse (f(g(x)) = x)\n\n```typescript\ntest('encryption/decryption inverse', () => {\n  fc.assert(\n    fc.property(fc.string(), fc.string(), (plaintext, key) => {\n      const encrypted = encrypt(plaintext, key)\n      const decrypted = decrypt(encrypted, key)\n      expect(decrypted).toBe(plaintext)\n    })\n  )\n})\n```\n\n### Shrinking (Simplifying Failing Cases)\n\n```typescript\n// When a property fails, fast-check automatically shrinks\n// the input to the minimal failing case\n\ntest('finds minimal failing case', () => {\n  fc.assert(\n    fc.property(fc.array(fc.integer()), (arr) => {\n      // This will fail for arrays containing 42\n      expect(arr).not.toContain(42)\n    })\n  )\n})\n\n// Output:\n// Property failed after 1 tests\n// Shrunk 5 time(s)\n// Counterexample: [[42]]   Minimal failing case!\n```\n\n### Configuration\n\n```typescript\ntest('configured property test', () => {\n  fc.assert(\n    fc.property(fc.array(fc.integer()), (arr) => {\n      expect(sort(arr)).toBeSorted()\n    }),\n    {\n      numRuns: 1000,      // Run 1000 tests (default: 100)\n      seed: 42,           // Reproducible tests\n      endOnFailure: true, // Stop after first failure\n      verbose: true,      // Show all generated values\n    }\n  )\n})\n```\n\n### Preconditions (Filtering)\n\n```typescript\ntest('division properties for non-zero divisors', () => {\n  fc.assert(\n    fc.property(fc.integer(), fc.integer(), (a, b) => {\n      fc.pre(b !== 0) // Skip cases where b is 0\n\n      const result = divide(a, b)\n      expect(multiply(result, b)).toBeCloseTo(a)\n    })\n  )\n})\n```\n\n## Python (Hypothesis)\n\n### Installation\n\n```bash\n# Using uv\nuv add --dev hypothesis\n\n# Using pip\npip install hypothesis\n```\n\n### Basic Example\n\n```python\nfrom hypothesis import given, strategies as st\nimport pytest\n\n# Traditional example-based test\ndef test_reverse_twice_example():\n    assert reverse(reverse([1, 2, 3])) == [1, 2, 3]\n\n# Property-based test\n@given(st.lists(st.integers()))\ndef test_reverse_twice_property(arr):\n    assert reverse(reverse(arr)) == arr\n    # Hypothesis automatically generates 100s of test cases!\n```\n\n### Built-in Strategies\n\n```python\nfrom hypothesis import strategies as st\n\n# Numbers\nst.integers()                          # Any integer\nst.integers(min_value=0, max_value=100)\nst.floats()                            # Floating-point\nst.floats(min_value=0.0, max_value=1.0, allow_nan=False)\nst.decimals()                          # Decimal precision\n\n# Strings\nst.text()                              # Any string\nst.text(min_size=1, max_size=10)\nst.text(alphabet='abc')                # Limited alphabet\nst.binary()                            # Bytes\n\n# Collections\nst.lists(st.integers())                # List of integers\nst.lists(st.text(), min_size=1, max_size=5)\nst.sets(st.integers())                 # Unique values\nst.dictionaries(keys=st.text(), values=st.integers())\n\n# Booleans and Constants\nst.booleans()\nst.just('value')                       # Constant\nst.sampled_from(['a', 'b', 'c'])      # Pick from options\n\n# Dates and Times\nst.dates()\nst.datetimes()\nst.times()\nst.timedeltas()\n\n# Complex Types\nst.tuples(st.text(), st.integers())   # Fixed-size tuple\nst.one_of(st.text(), st.integers())   # Union type\n```\n\n### Custom Strategies\n\n```python\nfrom hypothesis import strategies as st\nfrom dataclasses import dataclass\n\n@dataclass\nclass User:\n    id: int\n    name: str\n    email: str\n    age: int\n\n# Strategy for generating users\nusers = st.builds(\n    User,\n    id=st.integers(min_value=1),\n    name=st.text(min_size=1, max_size=50),\n    email=st.emails(),\n    age=st.integers(min_value=18, max_value=120),\n)\n\n@given(users)\ndef test_user_validation(user):\n    validated = validate_user(user)\n    assert validated.age >= 18\n    assert len(validated.name) > 0\n```\n\n```python\n# Using map\npositive_numbers = st.integers(min_value=0).map(lambda n: n + 1)\n\n# Using flatmap (dependent values)\n@st.composite\ndef email_and_domain(draw):\n    domain = draw(st.text(min_size=1))\n    return {\n        'email': f'user@{domain}.com',\n        'domain': domain,\n    }\n```\n\n### Common Properties to Test\n\n#### Roundtrip Property\n\n```python\nimport json\nfrom hypothesis import given, strategies as st\n\n@given(st.dictionaries(\n    keys=st.text(),\n    values=st.one_of(st.integers(), st.text(), st.booleans())\n))\ndef test_json_roundtrip(obj):\n    serialized = json.dumps(obj)\n    deserialized = json.loads(serialized)\n    assert deserialized == obj\n```\n\n#### Idempotence\n\n```python\n@given(st.lists(st.integers()))\ndef test_sort_idempotent(arr):\n    sorted_once = sorted(arr)\n    sorted_twice = sorted(sorted_once)\n    assert sorted_once == sorted_twice\n```\n\n#### Commutativity\n\n```python\n@given(st.integers(), st.integers())\ndef test_addition_commutative(a, b):\n    assert add(a, b) == add(b, a)\n```\n\n#### Associativity\n\n```python\n@given(st.integers(), st.integers(), st.integers())\ndef test_addition_associative(a, b, c):\n    assert add(add(a, b), c) == add(a, add(b, c))\n```\n\n#### Identity\n\n```python\n@given(st.integers())\ndef test_multiplication_identity(n):\n    assert multiply(n, 1) == n\n```\n\n#### Inverse\n\n```python\n@given(st.text(), st.text(min_size=1))\ndef test_encryption_inverse(plaintext, key):\n    encrypted = encrypt(plaintext, key)\n    decrypted = decrypt(encrypted, key)\n    assert decrypted == plaintext\n```\n\n### Shrinking (Simplifying Failing Cases)\n\n```python\nfrom hypothesis import given, strategies as st\n\n@given(st.lists(st.integers()))\ndef test_finds_minimal_failing_case(arr):\n    # This will fail for arrays containing 42\n    assert 42 not in arr\n\n# Output:\n# Falsifying example: test_finds_minimal_failing_case(\n#     arr=[42]   Minimal failing case!\n# )\n```\n\n### Configuration and Settings\n\n```python\nfrom hypothesis import given, settings, strategies as st\n\n@settings(max_examples=1000, deadline=None)\n@given(st.lists(st.integers()))\ndef test_with_custom_settings(arr):\n    assert sort(arr) == sorted(arr)\n\n# Global settings\nfrom hypothesis import settings, Verbosity\n\nsettings.register_profile(\"ci\", max_examples=1000, verbosity=Verbosity.verbose)\nsettings.register_profile(\"dev\", max_examples=100)\nsettings.load_profile(\"dev\")\n```\n\n### Assumptions (Preconditions)\n\n```python\nfrom hypothesis import given, assume, strategies as st\n\n@given(st.integers(), st.integers())\ndef test_division_properties(a, b):\n    assume(b != 0)  # Skip cases where b is 0\n\n    result = divide(a, b)\n    assert abs(multiply(result, b) - a) < 0.0001\n```\n\n### Stateful Testing\n\n```python\nfrom hypothesis.stateful import RuleBasedStateMachine, rule, invariant\nfrom hypothesis import strategies as st\n\nclass ShoppingCartMachine(RuleBasedStateMachine):\n    def __init__(self):\n        super().__init__()\n        self.cart = ShoppingCart()\n        self.items = []\n\n    @rule(item=st.text(min_size=1), price=st.floats(min_value=0.01, max_value=1000))\n    def add_item(self, item, price):\n        self.cart.add(item, price)\n        self.items.append((item, price))\n\n    @rule()\n    def clear_cart(self):\n        self.cart.clear()\n        self.items = []\n\n    @invariant()\n    def total_matches_items(self):\n        expected_total = sum(price for _, price in self.items)\n        assert abs(self.cart.total() - expected_total) < 0.01\n\n# Run stateful test\nTestCart = ShoppingCartMachine.TestCase\n```\n\n## Real-World Examples\n\n### TypeScript: URL Parser\n\n```typescript\nimport * as fc from 'fast-check'\n\ntest('URL parsing roundtrip', () => {\n  fc.assert(\n    fc.property(\n      fc.webUrl(), // Built-in URL generator\n      (url) => {\n        const parsed = parseURL(url)\n        const reconstructed = buildURL(parsed)\n        expect(normalizeURL(reconstructed)).toBe(normalizeURL(url))\n      }\n    )\n  )\n})\n```\n\n### Python: Data Validation\n\n```python\nfrom hypothesis import given, strategies as st\nfrom pydantic import BaseModel, ValidationError\n\nclass Product(BaseModel):\n    name: str\n    price: float\n    quantity: int\n\n@given(st.builds(\n    Product,\n    name=st.text(min_size=1),\n    price=st.floats(min_value=0.01, max_value=10000),\n    quantity=st.integers(min_value=0, max_value=1000),\n))\ndef test_product_validation_accepts_valid_data(product):\n    # Should not raise\n    validated = Product(**product.dict())\n    assert validated.price > 0\n    assert validated.quantity >= 0\n```\n\n### TypeScript: List Operations\n\n```typescript\ntest('filter and map compose correctly', () => {\n  fc.assert(\n    fc.property(\n      fc.array(fc.integer()),\n      fc.func(fc.boolean()),\n      fc.func(fc.integer()),\n      (arr, predicate, transform) => {\n        const result1 = arr.filter(predicate).map(transform)\n        const result2 = arr.map(transform).filter((_, i) =>\n          predicate(arr[i])\n        )\n        // Order might differ but length should match\n        expect(result1.length).toBe(result2.length)\n      }\n    )\n  )\n})\n```\n\n### Python: Cache Behavior\n\n```python\nfrom hypothesis import given, strategies as st\n\n@given(st.text(), st.integers())\ndef test_cache_returns_same_value(key, value):\n    cache = Cache()\n\n    # First set\n    cache.set(key, value)\n    result1 = cache.get(key)\n\n    # Second get should return same value\n    result2 = cache.get(key)\n\n    assert result1 == value\n    assert result2 == value\n```\n\n## Best Practices\n\n**Start with Properties**\n- Identify mathematical properties (commutative, associative)\n- Look for roundtrip properties (encode/decode)\n- Test invariants (things that should always be true)\n- Verify contracts and postconditions\n\n**Complement Example-Based Tests**\n```typescript\n// Use both approaches\ntest('addition examples', () => {\n  expect(add(2, 3)).toBe(5)\n  expect(add(-1, 1)).toBe(0)\n})\n\ntest('addition properties', () => {\n  fc.assert(\n    fc.property(fc.integer(), fc.integer(), (a, b) => {\n      expect(add(a, b)).toBe(add(b, a)) // Commutative\n      expect(add(a, 0)).toBe(a)          // Identity\n    })\n  )\n})\n```\n\n**Shrinking is Your Friend**\n- Don't ignore shrunk counterexamples\n- Minimal failing cases reveal root causes\n- Shrinking finds edge cases you'd never write by hand\n\n**Performance Considerations**\n```typescript\n// Limit expensive tests\nfc.assert(\n  fc.property(fc.array(fc.integer()), (arr) => {\n    expensiveOperation(arr)\n  }),\n  { numRuns: 50 } // Reduce from default 100\n)\n```\n\n**Reproducibility**\n```python\n# Set seed for reproducible failures\n@settings(derandomize=True)\n@given(st.lists(st.integers()))\ndef test_reproducible(arr):\n    assert process(arr) is not None\n```\n\n## Common Pitfalls\n\n**Overly Permissive Assertions**\n```typescript\n//  BAD: Too weak\nfc.assert(\n  fc.property(fc.array(fc.integer()), (arr) => {\n    expect(sort(arr)).toBeDefined() // Passes even if sort is broken!\n  })\n)\n\n//  GOOD: Specific properties\nfc.assert(\n  fc.property(fc.array(fc.integer()), (arr) => {\n    const sorted = sort(arr)\n    // Check actual properties\n    for (let i = 1; i < sorted.length; i++) {\n      expect(sorted[i]).toBeGreaterThanOrEqual(sorted[i - 1])\n    }\n  })\n)\n```\n\n**Too Many Assumptions**\n```python\n#  BAD: Filters out too many cases\n@given(st.integers(), st.integers())\ndef test_slow(a, b):\n    assume(a > 100)\n    assume(a < 110)\n    assume(b > 200)\n    assume(b < 210)\n    # Better to use specific strategy!\n\n#  GOOD: Generate what you need\n@given(st.integers(min_value=101, max_value=109),\n       st.integers(min_value=201, max_value=209))\ndef test_fast(a, b):\n    # No filtering needed\n```\n\n**Testing Implementation, Not Properties**\n```typescript\n//  BAD: Tests implementation\nfc.assert(\n  fc.property(fc.array(fc.integer()), (arr) => {\n    const spy = vi.spyOn(Math, 'max')\n    sort(arr)\n    expect(spy).toHaveBeenCalled() // Testing how it's implemented\n  })\n)\n\n//  GOOD: Tests properties\nfc.assert(\n  fc.property(fc.array(fc.integer()), (arr) => {\n    const sorted = sort(arr)\n    // Test what it does, not how\n    expect(sorted.length).toBe(arr.length)\n    expect(new Set(sorted)).toEqual(new Set(arr))\n  })\n)\n```\n\n## CI/CD Integration\n\n### TypeScript\n\n```json\n{\n  \"scripts\": {\n    \"test\": \"vitest\",\n    \"test:property\": \"vitest --grep 'property'\",\n    \"test:ci\": \"vitest --run --coverage\"\n  }\n}\n```\n\n### Python\n\n```yaml\n# .github/workflows/test.yml\nname: Tests\n\non: [push, pull_request]\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - uses: astral-sh/setup-uv@v1\n      - run: uv sync\n      - run: uv run pytest --hypothesis-show-statistics\n```\n\n## Troubleshooting\n\n**Tests taking too long**\n```typescript\n// Reduce number of runs\nfc.assert(property, { numRuns: 50 })\n```\n\n```python\n@settings(max_examples=50)\n@given(...)\n```\n\n**Hard to find failing case**\n```typescript\n// Increase attempts\nfc.assert(property, { numRuns: 10000 })\n```\n\n**Flaky property tests**\n```python\n# Use seed for reproducibility\n@settings(derandomize=True)\n```\n\n**Too many filtered cases**\n```\nHypothesis: Unable to satisfy assumptions\n```\n Use more specific generators instead of `assume()`\n\n## See Also\n\n- `vitest-testing` - Unit testing framework\n- `python-testing` - Python pytest testing\n- `test-quality-analysis` - Detecting test smells\n- `mutation-testing` - Validate test effectiveness\n\n## References\n\n- fast-check: https://fast-check.dev/\n- Hypothesis: https://hypothesis.readthedocs.io/\n- Property-Based Testing: https://fsharpforfunandprofit.com/posts/property-based-testing/"
              },
              {
                "name": "Test Quality Analysis",
                "description": "Detect test smells, overmocking, flaky tests, and coverage issues. Analyze test effectiveness, maintainability, and reliability. Use when reviewing tests or improving test quality.",
                "path": "testing-plugin/skills/test-quality-analysis/SKILL.md",
                "frontmatter": {
                  "created": "2025-12-16T00:00:00.000Z",
                  "modified": "2025-12-16T00:00:00.000Z",
                  "reviewed": "2025-12-16T00:00:00.000Z",
                  "name": "Test Quality Analysis",
                  "description": "Detect test smells, overmocking, flaky tests, and coverage issues. Analyze test effectiveness, maintainability, and reliability. Use when reviewing tests or improving test quality.",
                  "allowed-tools": "Bash, Read, Edit, Write, Grep, Glob, TodoWrite"
                },
                "content": "# Test Quality Analysis\n\nExpert knowledge for analyzing and improving test quality - detecting test smells, overmocking, insufficient coverage, and other testing anti-patterns.\n\n## Core Expertise\n\n**Test Quality Dimensions**\n- **Correctness**: Tests verify the right behavior\n- **Reliability**: Tests are deterministic and not flaky\n- **Maintainability**: Tests are easy to understand and modify\n- **Performance**: Tests run quickly\n- **Coverage**: Tests cover critical code paths\n- **Isolation**: Tests don't depend on external state\n\n## Test Smells\n\n### Overmocking\n\n**Problem**: Mocking too many dependencies, making tests fragile and disconnected from reality.\n\n```typescript\n//  BAD: Overmocked\ntest('calculate total', () => {\n  const mockAdd = vi.fn(() => 10)\n  const mockMultiply = vi.fn(() => 20)\n  const mockSubtract = vi.fn(() => 5)\n\n  // Testing implementation, not behavior\n  const result = calculate(mockAdd, mockMultiply, mockSubtract)\n  expect(result).toBe(15)\n})\n\n//  GOOD: Mock only external dependencies\ntest('calculate order total', () => {\n  const mockPricingAPI = vi.fn(() => ({ tax: 0.1, shipping: 5 }))\n\n  const order = { items: [{ price: 10 }, { price: 20 }] }\n  const total = calculateTotal(order, mockPricingAPI)\n\n  expect(total).toBe(38) // 30 + 3 tax + 5 shipping\n})\n```\n\n**Detection**:\n- More than 3-4 mocks in a single test\n- Mocking internal utilities or pure functions\n- Mocking data structures or value objects\n- Complex mock setup that mirrors production code\n\n**Fix**:\n- Mock only I/O boundaries (APIs, databases, filesystem)\n- Use real implementations for business logic\n- Extract testable pure functions\n- Consider integration tests instead\n\n### Fragile Tests\n\n**Problem**: Tests break with unrelated code changes.\n\n```typescript\n//  BAD: Fragile selector\ntest('submits form', async ({ page }) => {\n  await page.locator('.form-container > div:nth-child(2) > button').click()\n})\n\n//  GOOD: Semantic selector\ntest('submits form', async ({ page }) => {\n  await page.getByRole('button', { name: 'Submit' }).click()\n})\n```\n\n```python\n#  BAD: Tests implementation details\ndef test_user_creation():\n    user = User()\n    user._internal_id = 123  # Testing private attribute\n    assert user._internal_id == 123\n\n#  GOOD: Tests public interface\ndef test_user_creation():\n    user = User(id=123)\n    assert user.get_id() == 123\n```\n\n**Detection**:\n- Tests break when refactoring without changing behavior\n- Assertions on private methods or attributes\n- Brittle CSS selectors in E2E tests\n- Testing implementation details vs. behavior\n\n**Fix**:\n- Test public APIs, not internal implementation\n- Use semantic selectors (role, label, text)\n- Follow the \"test behavior, not implementation\" principle\n- Avoid testing private methods directly\n\n### Flaky Tests\n\n**Problem**: Tests pass or fail non-deterministically.\n\n```typescript\n//  BAD: Race condition\ntest('loads data', async () => {\n  fetchData()\n  await new Promise(resolve => setTimeout(resolve, 1000))\n  expect(data).toBeDefined()\n})\n\n//  GOOD: Proper async handling\ntest('loads data', async () => {\n  const data = await fetchData()\n  expect(data).toBeDefined()\n})\n```\n\n```python\n#  BAD: Time-dependent test\ndef test_expires_in_one_hour():\n    token = create_token()\n    time.sleep(3601)\n    assert token.is_expired()\n\n#  GOOD: Inject time dependency\ndef test_expires_in_one_hour():\n    now = datetime(2024, 1, 1, 12, 0)\n    future = datetime(2024, 1, 1, 13, 1)\n    token = create_token(now)\n    assert token.is_expired(future)\n```\n\n**Detection**:\n- Test passes locally but fails in CI\n- Test fails when run in different order\n- Tests with arbitrary `sleep()` or `setTimeout()`\n- Timing-dependent assertions\n\n**Fix**:\n- Use proper async/await patterns\n- Mock time and dates\n- Avoid arbitrary waits, use explicit waiting\n- Ensure test isolation\n- Reset shared state between tests\n\n### Test Duplication\n\n**Problem**: Similar test logic repeated across multiple tests.\n\n```typescript\n//  BAD: Duplicated setup\ntest('user can edit profile', async ({ page }) => {\n  await page.goto('/login')\n  await page.fill('[name=email]', 'user@example.com')\n  await page.fill('[name=password]', 'password')\n  await page.click('button[type=submit]')\n  await page.goto('/profile')\n  // Test logic...\n})\n\ntest('user can view settings', async ({ page }) => {\n  await page.goto('/login')\n  await page.fill('[name=email]', 'user@example.com')\n  await page.fill('[name=password]', 'password')\n  await page.click('button[type=submit]')\n  await page.goto('/settings')\n  // Test logic...\n})\n\n//  GOOD: Extract to fixture/helper\nasync function loginAsUser(page) {\n  await page.goto('/login')\n  await page.fill('[name=email]', 'user@example.com')\n  await page.fill('[name=password]', 'password')\n  await page.click('button[type=submit]')\n}\n\ntest('user can edit profile', async ({ page }) => {\n  await loginAsUser(page)\n  await page.goto('/profile')\n  // Test logic...\n})\n```\n\n**Detection**:\n- Copy-pasted test setup code\n- Similar assertion patterns across tests\n- Repeated fixture or mock configurations\n\n**Fix**:\n- Extract common setup to `beforeEach()` hooks\n- Create reusable fixtures or test helpers\n- Use parameterized tests for similar scenarios\n- Apply DRY principle to test code\n\n### Slow Tests\n\n**Problem**: Tests take too long to run, slowing down feedback loop.\n\n```typescript\n//  BAD: Unnecessary setup in every test\ndescribe('User API', () => {\n  beforeEach(async () => {\n    await database.migrate() // Slow!\n    await seedDatabase()     // Slow!\n  })\n\n  test('creates user', async () => {\n    const user = await createUser({ name: 'John' })\n    expect(user.name).toBe('John')\n  })\n\n  test('updates user', async () => {\n    const user = await createUser({ name: 'John' })\n    await updateUser(user.id, { name: 'Jane' })\n    expect(user.name).toBe('Jane')\n  })\n})\n\n//  GOOD: Shared expensive setup\ndescribe('User API', () => {\n  beforeAll(async () => {\n    await database.migrate()\n    await seedDatabase()\n  })\n\n  beforeEach(async () => {\n    await cleanUserTable() // Fast!\n  })\n\n  // Tests...\n})\n```\n\n**Detection**:\n- Test suite takes > 10 seconds for unit tests\n- Unnecessary database migrations in tests\n- No parallelization of independent tests\n- Excessive E2E tests for unit-testable logic\n\n**Fix**:\n- Use `beforeAll()` for expensive one-time setup\n- Mock external dependencies\n- Run tests in parallel\n- Push tests down the pyramid (more unit, fewer E2E)\n- Use in-memory databases or test doubles\n\n### Poor Assertions\n\n**Problem**: Weak or missing assertions that don't verify behavior.\n\n```typescript\n//  BAD: No assertion\ntest('creates user', async () => {\n  await createUser({ name: 'John' })\n  // No verification!\n})\n\n//  BAD: Weak assertion\ntest('returns users', async () => {\n  const users = await getUsers()\n  expect(users).toBeDefined() // Too vague!\n})\n\n//  BAD: Assertion on mock\ntest('calls API', async () => {\n  const mockAPI = vi.fn()\n  await service.fetchData(mockAPI)\n  expect(mockAPI).toHaveBeenCalled() // Testing mock, not behavior\n})\n\n//  GOOD: Strong, specific assertions\ntest('creates user with correct attributes', async () => {\n  const user = await createUser({ name: 'John', email: 'john@example.com' })\n\n  expect(user).toMatchObject({\n    id: expect.any(Number),\n    name: 'John',\n    email: 'john@example.com',\n    createdAt: expect.any(Date),\n  })\n})\n```\n\n**Detection**:\n- Tests with no assertions\n- Assertions only on mocks, not outputs\n- Vague assertions (`toBeDefined()`, `toBeTruthy()`)\n- Not testing edge cases or error conditions\n\n**Fix**:\n- Assert on actual outputs and side effects\n- Use specific matchers\n- Test both happy path and error cases\n- Verify state changes, not just mock calls\n\n### Insufficient Coverage\n\n**Problem**: Critical code paths not tested.\n\n```typescript\n// Source code\nfunction calculateDiscount(price: number, coupon?: string): number {\n  if (coupon === 'SAVE20') return price * 0.8\n  if (coupon === 'SAVE50') return price * 0.5\n  return price\n}\n\n//  BAD: Only tests happy path\ntest('applies SAVE20 discount', () => {\n  expect(calculateDiscount(100, 'SAVE20')).toBe(80)\n})\n\n//  GOOD: Tests all paths\ndescribe('calculateDiscount', () => {\n  it('applies SAVE20 discount', () => {\n    expect(calculateDiscount(100, 'SAVE20')).toBe(80)\n  })\n\n  it('applies SAVE50 discount', () => {\n    expect(calculateDiscount(100, 'SAVE50')).toBe(50)\n  })\n\n  it('returns original price for invalid coupon', () => {\n    expect(calculateDiscount(100, 'INVALID')).toBe(100)\n  })\n\n  it('returns original price when no coupon provided', () => {\n    expect(calculateDiscount(100)).toBe(100)\n  })\n})\n```\n\n**Detection**:\n- Coverage below 80% for critical modules\n- Untested error handling paths\n- Missing edge case tests\n- No tests for boundary conditions\n\n**Fix**:\n- Aim for 80%+ coverage on business logic\n- Test error paths and exceptions\n- Test boundary values (0, null, max values)\n- Use mutation testing to find weak tests\n\n## Analysis Tools\n\n### Coverage Analysis (TypeScript/JavaScript)\n\n```bash\n# Vitest coverage\nvitest --coverage\n\n# View HTML report\nopen coverage/index.html\n\n# Check thresholds\nvitest --coverage --coverage.thresholds.lines=80\n```\n\n```typescript\n// vitest.config.ts\nexport default defineConfig({\n  test: {\n    coverage: {\n      provider: 'v8',\n      reporter: ['text', 'html', 'lcov'],\n      thresholds: {\n        lines: 80,\n        functions: 80,\n        branches: 80,\n        statements: 80,\n      },\n      exclude: [\n        'node_modules/',\n        '**/*.config.ts',\n        '**/*.d.ts',\n        '**/types/**',\n      ],\n    },\n  },\n})\n```\n\n### Coverage Analysis (Python)\n\n```bash\n# pytest-cov\nuv run pytest --cov --cov-report=html\n\n# View report\nopen htmlcov/index.html\n\n# Show missing lines\nuv run pytest --cov --cov-report=term-missing\n\n# Fail if below threshold\nuv run pytest --cov --cov-fail-under=80\n```\n\n```toml\n# pyproject.toml\n[tool.coverage.run]\nsource = [\"src\"]\nbranch = true\nomit = [\"*/tests/*\", \"*/test_*.py\"]\n\n[tool.coverage.report]\nprecision = 2\nshow_missing = true\nskip_covered = false\n\n[tool.coverage.html]\ndirectory = \"htmlcov\"\n```\n\n### Test Performance Analysis\n\n```bash\n# Vitest: Show slow tests\nvitest --reporter=verbose\n\n# pytest: Show slowest tests\nuv run pytest --durations=10\n\n# pytest: Profile test execution\nuv run pytest --profile\n\n# Playwright: Trace for performance\nnpx playwright test --trace on\n```\n\n## Best Practices Checklist\n\n### Unit Test Quality\n\n- [ ] **Fast**: Tests run in milliseconds\n- [ ] **Isolated**: No dependencies between tests\n- [ ] **Repeatable**: Same results every time\n- [ ] **Self-validating**: Clear pass/fail without manual inspection\n- [ ] **Timely**: Written alongside code (TDD)\n\n### Mock Usage Guidelines\n\n- [ ] Mock only external dependencies (APIs, databases, filesystem)\n- [ ] Don't mock business logic or pure functions\n- [ ] Don't mock data structures or value objects\n- [ ] Use real implementations when possible\n- [ ] Limit to 3-4 mocks per test maximum\n\n### Test Coverage Goals\n\n- [ ] 80%+ line coverage for business logic\n- [ ] 100% coverage for critical paths (payment, auth, security)\n- [ ] All error paths tested\n- [ ] Boundary conditions tested\n- [ ] Happy path and edge cases covered\n\n### Test Naming\n\n```typescript\n//  GOOD: Descriptive test names\ntest('calculateTotal adds tax and shipping to subtotal', () => {})\ntest('login fails with invalid credentials', () => {})\ntest('createUser throws ValidationError for invalid email', () => {})\n\n//  BAD: Vague test names\ntest('test1', () => {})\ntest('works correctly', () => {})\ntest('handles error', () => {})\n```\n\n### Test Structure (AAA Pattern)\n\n```typescript\ntest('user registration flow', async () => {\n  // Arrange: Setup test data and dependencies\n  const userData = {\n    email: 'user@example.com',\n    password: 'secure123',  // pragma: allowlist secret\n  }\n  const mockEmailService = vi.fn()\n\n  // Act: Execute the behavior being tested\n  const user = await registerUser(userData, mockEmailService)\n\n  // Assert: Verify the expected outcome\n  expect(user).toMatchObject({\n    email: 'user@example.com',\n    emailVerified: false,\n  })\n  expect(mockEmailService).toHaveBeenCalledWith(\n    'user@example.com',\n    expect.any(String)\n  )\n})\n```\n\n## Code Review Checklist\n\nWhen reviewing tests, check for:\n\n### Correctness\n- [ ] Tests verify actual behavior, not implementation\n- [ ] Assertions are specific and meaningful\n- [ ] Error cases are tested\n- [ ] Edge cases are covered\n\n### Reliability\n- [ ] No flaky tests (timing, ordering issues)\n- [ ] Proper async/await usage\n- [ ] No arbitrary waits (`sleep`, `setTimeout`)\n- [ ] Tests are isolated and independent\n\n### Maintainability\n- [ ] Test names clearly describe behavior\n- [ ] Tests follow AAA pattern (Arrange, Act, Assert)\n- [ ] Minimal code duplication\n- [ ] Clear and focused assertions\n\n### Performance\n- [ ] Unit tests run in < 10 seconds total\n- [ ] Expensive setup in `beforeAll()`, not `beforeEach()`\n- [ ] Tests run in parallel when possible\n- [ ] Mocks used for slow dependencies\n\n### Coverage\n- [ ] Critical paths have tests\n- [ ] Coverage meets threshold (80%+)\n- [ ] Both happy path and error cases covered\n- [ ] Boundary conditions tested\n\n## Refactoring Test Smells\n\n### Overmocking Refactor\n\n```typescript\n// Before: Overmocked\ntest('processes order', () => {\n  const mockValidator = vi.fn(() => true)\n  const mockCalculator = vi.fn(() => 100)\n  const mockFormatter = vi.fn(() => '$100.00')\n\n  const result = processOrder(mockValidator, mockCalculator, mockFormatter)\n  expect(result).toBe('$100.00')\n})\n\n// After: Mock only I/O\ntest('processes order and sends confirmation', async () => {\n  const mockEmailService = vi.fn()\n\n  const order = { items: [{ price: 50 }, { price: 50 }] }\n  await processOrder(order, mockEmailService)\n\n  expect(mockEmailService).toHaveBeenCalledWith(\n    expect.objectContaining({\n      total: 100,\n      formattedTotal: '$100.00',\n    })\n  )\n})\n```\n\n### Flaky Test Refactor\n\n```typescript\n// Before: Flaky\ntest('animation completes', async () => {\n  triggerAnimation()\n  await new Promise(resolve => setTimeout(resolve, 500))\n  expect(isAnimationComplete()).toBe(true)\n})\n\n// After: Deterministic\ntest('animation completes', async () => {\n  vi.useFakeTimers()\n\n  triggerAnimation()\n  vi.advanceTimersByTime(500)\n\n  expect(isAnimationComplete()).toBe(true)\n\n  vi.restoreAllMocks()\n})\n```\n\n## Common Anti-Patterns\n\n### Testing Implementation Details\n\n```typescript\n//  BAD\ntest('uses correct algorithm', () => {\n  const spy = vi.spyOn(Math, 'sqrt')\n  calculateDistance({ x: 0, y: 0 }, { x: 3, y: 4 })\n  expect(spy).toHaveBeenCalled() // Testing how, not what\n})\n\n//  GOOD\ntest('calculates distance correctly', () => {\n  const distance = calculateDistance({ x: 0, y: 0 }, { x: 3, y: 4 })\n  expect(distance).toBe(5) // Testing output\n})\n```\n\n### Mocking Too Much\n\n```typescript\n//  BAD: Mocking everything\nconst mockAdd = vi.fn((a, b) => a + b)\nconst mockMultiply = vi.fn((a, b) => a * b)\nconst mockFormat = vi.fn((n) => `$${n}`)\n\n//  GOOD: Use real implementations\nimport { add, multiply, format } from './utils'\n// Only mock external services\nconst mockPaymentGateway = vi.fn()\n```\n\n### Ignoring Test Failures\n\n```typescript\n//  BAD: Skipping failing tests\ntest.skip('this test is broken', () => {\n  // Don't leave broken tests!\n})\n\n//  GOOD: Fix or remove\ntest('feature works correctly', () => {\n  // Fixed implementation\n})\n```\n\n## Tools and Commands\n\n### TypeScript/JavaScript\n\n```bash\n# Run tests with coverage\nvitest --coverage\n\n# Find slow tests\nvitest --reporter=verbose\n\n# Watch mode for TDD\nvitest --watch\n\n# UI mode for debugging\nvitest --ui\n\n# Generate coverage report\nvitest --coverage --coverage.reporter=html\n```\n\n### Python\n\n```bash\n# Run tests with coverage\nuv run pytest --cov\n\n# Show missing lines\nuv run pytest --cov --cov-report=term-missing\n\n# Find slow tests\nuv run pytest --durations=10\n\n# Run only failed tests\nuv run pytest --lf\n\n# Generate HTML coverage report\nuv run pytest --cov --cov-report=html\n```\n\n## See Also\n\n- `vitest-testing` - TypeScript/JavaScript testing\n- `python-testing` - Python pytest testing\n- `playwright-testing` - E2E testing\n- `mutation-testing` - Validate test effectiveness\n\n## References\n\n- Test Smells: https://testsmells.org/\n- Test Double Patterns: https://martinfowler.com/bliki/TestDouble.html\n- Testing Best Practices: https://kentcdodds.com/blog/common-mistakes-with-react-testing-library"
              },
              {
                "name": "test-tier-selection",
                "description": "Automatic selection of appropriate test tiers based on change scope. Guides unit tests for small changes, full suite for larger changes. Use when running tests, discussing testing strategy, or after code modifications.",
                "path": "testing-plugin/skills/test-tier-selection/SKILL.md",
                "frontmatter": {
                  "created": "2025-12-16T00:00:00.000Z",
                  "modified": "2025-12-16T00:00:00.000Z",
                  "reviewed": "2025-12-16T00:00:00.000Z",
                  "name": "test-tier-selection",
                  "description": "Automatic selection of appropriate test tiers based on change scope. Guides unit tests for small changes, full suite for larger changes. Use when running tests, discussing testing strategy, or after code modifications.",
                  "allowed-tools": "Bash, Read, Glob, Grep"
                },
                "content": "# Test Tier Selection\n\nAutomatic guidance for selecting appropriate test tiers based on change context and scope.\n\n## Test Tier Definitions\n\n| Tier | Duration | Scope | When to Run |\n|------|----------|-------|-------------|\n| **Unit** | < 30s | Single function/module | After every code change |\n| **Integration** | < 5min | Component interactions | After feature completion |\n| **E2E** | < 30min | Full user flows | Before commit/PR |\n\n## Decision Matrix\n\n### Change Type  Test Tier\n\n| Change Type | Unit | Integration | E2E |\n|-------------|------|-------------|-----|\n| Single function fix | Required | Skip | Skip |\n| New feature (1 file) | Required | Required | Skip |\n| Multi-file feature | Required | Required | Required |\n| Refactoring | Required | Required | Optional |\n| API changes | Required | Required | Required |\n| UI changes | Required | Optional | Required |\n| Bug fix (isolated) | Required | Optional | Skip |\n| Database changes | Required | Required | Required |\n| Config changes | Required | Required | Optional |\n\n## Escalation Signals\n\n**Escalate to Integration when:**\n- Changes span multiple files\n- Business logic affected\n- Service boundaries modified\n- Database queries changed\n\n**Escalate to E2E when:**\n- User-facing features modified\n- Authentication/authorization changes\n- Critical path functionality\n- Before creating PR\n\n## Commands by Tier\n\n```bash\n# Tier 1: Unit (fast feedback)\n/test:quick\n\n# Tier 2: Integration (feature completion)\n/test:full --coverage\n\n# Tier 3: E2E (pre-commit)\n/test:full\n```\n\n## Agent Consultation Triggers\n\n**Consult `test-architecture` agent when:**\n- New feature module created\n- Coverage drops > 5%\n- > 3 flaky tests detected\n- Framework questions arise\n- Test strategy needs adjustment\n\n**Consult `test-runner` agent when:**\n- Need test execution with analysis\n- Multiple failures to diagnose\n- Want concise failure summary\n\n**Consult `system-debugging` agent when:**\n- Integration test failures with unclear cause\n- Environment/timing issues\n- Flaky tests related to concurrency\n\n## Quick Reference\n\n### After Small Change\n```\n1. Run /test:quick\n2. If pass: Continue working\n3. If fail: Fix immediately\n```\n\n### After Feature Completion\n```\n1. Run /test:full --coverage\n2. Check coverage targets met\n3. If gaps: /test:consult coverage\n```\n\n### Before Commit/PR\n```\n1. Run /test:full\n2. All tiers must pass\n3. Review coverage report\n```\n\n### For New Features\n```\n1. /test:consult new-feature\n2. Write tests (TDD)\n3. Run /test:quick during development\n4. Run /test:full before PR\n```\n\n## Activation Triggers\n\nThis skill auto-activates when:\n- User mentions \"test\", \"run tests\", \"testing\"\n- After code modification by Claude\n- During TDD workflow\n- When `/test:*` commands invoked\n- When discussing test strategy"
              },
              {
                "name": "Vitest Testing",
                "description": "Vitest test runner for JavaScript and TypeScript. Fast, modern alternative to Jest.\nVite-native, ESM support, watch mode, UI mode, coverage, mocking, snapshot testing.\nUse when setting up tests for Vite projects, migrating from Jest, or needing fast test execution.\n",
                "path": "testing-plugin/skills/vitest-testing/SKILL.md",
                "frontmatter": {
                  "created": "2025-12-16T00:00:00.000Z",
                  "modified": "2025-12-16T00:00:00.000Z",
                  "reviewed": "2025-12-16T00:00:00.000Z",
                  "name": "Vitest Testing",
                  "description": "Vitest test runner for JavaScript and TypeScript. Fast, modern alternative to Jest.\nVite-native, ESM support, watch mode, UI mode, coverage, mocking, snapshot testing.\nUse when setting up tests for Vite projects, migrating from Jest, or needing fast test execution.\n",
                  "allowed-tools": "Glob, Grep, Read, Bash, Edit, Write, TodoWrite, WebFetch, WebSearch, BashOutput, KillShell"
                },
                "content": "# Vitest Testing\n\nVitest is a modern test runner designed for Vite projects. It's fast, ESM-native, and provides a Jest-compatible API with better TypeScript support and instant HMR-powered watch mode.\n\n## Core Expertise\n\n**What is Vitest?**\n- **Vite-native**: Reuses Vite config, transforms, and plugins\n- **Fast**: Instant feedback with HMR-powered watch mode\n- **Jest-compatible**: Drop-in replacement with similar API\n- **TypeScript**: First-class TypeScript support\n- **ESM**: Native ESM support, no transpilation needed\n\n**Key Capabilities**\n- Unit and integration testing\n- Mocking (functions, modules, timers, globals)\n- Snapshot testing\n- Coverage reporting (v8 or istanbul)\n- Watch mode with instant feedback\n- UI mode with visual test browser\n- Parallel test execution\n- Built-in benchmarking\n\n## Installation\n\n```bash\n# Core Vitest\nbun add --dev vitest\n\n# TypeScript support (usually automatic)\nbun add --dev @vitest/ui\n\n# Coverage (choose one)\nbun add --dev @vitest/coverage-v8      # Recommended (faster)\nbun add --dev @vitest/coverage-istanbul\n\n# DOM testing\nbun add --dev happy-dom\n# or\nbun add --dev jsdom\n\n# Verify installation\nbunx vitest --version\n```\n\n## Configuration (vitest.config.ts)\n\n### Minimal Setup\n\n```typescript\n// vitest.config.ts\nimport { defineConfig } from 'vitest/config';\n\nexport default defineConfig({\n  test: {\n    globals: true,\n    environment: 'node',\n  },\n});\n```\n\n### Recommended Production Setup\n\n```typescript\n// vitest.config.ts\nimport { defineConfig } from 'vitest/config';\nimport path from 'path';\n\nexport default defineConfig({\n  test: {\n    globals: true,\n    environment: 'node', // or 'happy-dom' for browser-like environment\n    setupFiles: ['./test/setup.ts'],\n    include: ['**/*.{test,spec}.{js,ts,jsx,tsx}'],\n    exclude: ['node_modules', 'dist', 'build', '.next'],\n    coverage: {\n      provider: 'v8', // or 'istanbul'\n      reporter: ['text', 'json', 'html', 'lcov'],\n      exclude: [\n        'node_modules/',\n        'test/',\n        '**/*.config.{js,ts}',\n        '**/*.d.ts',\n      ],\n      thresholds: {\n        lines: 80,\n        functions: 80,\n        branches: 80,\n        statements: 80,\n      },\n    },\n    testTimeout: 10000,\n    mockReset: true,\n    restoreMocks: true,\n    clearMocks: true,\n  },\n  resolve: {\n    alias: {\n      '@': path.resolve(__dirname, './src'),\n    },\n  },\n});\n```\n\n### With Vite Project\n\n```typescript\n// vitest.config.ts\nimport { defineConfig, mergeConfig } from 'vitest/config';\nimport viteConfig from './vite.config';\n\nexport default mergeConfig(\n  viteConfig,\n  defineConfig({\n    test: {\n      globals: true,\n      environment: 'happy-dom',\n      setupFiles: ['./test/setup.ts'],\n      coverage: {\n        provider: 'v8',\n        reporter: ['text', 'html'],\n      },\n    },\n  })\n);\n```\n\n## Essential Commands\n\n```bash\n# Run all tests\nbunx vitest\n\n# Run tests once (CI mode)\nbunx vitest run\n\n# Watch mode (default)\nbunx vitest watch\n\n# UI mode\nbunx vitest --ui\n\n# Coverage\nbunx vitest --coverage\n\n# Run specific tests\nbunx vitest src/utils.test.ts\n\n# Filter tests by name\nbunx vitest -t \"should add numbers\"\n\n# Run related tests (changed files)\nbunx vitest related src/utils.ts\n\n# Update snapshots\nbunx vitest -u\n\n# Benchmarks\nbunx vitest bench\n```\n\n## Writing Tests\n\n### Basic Test Structure\n\n```typescript\n// src/math.test.ts\nimport { describe, it, expect } from 'vitest';\nimport { add, multiply } from './math';\n\ndescribe('math utils', () => {\n  it('should add two numbers', () => {\n    expect(add(2, 3)).toBe(5);\n  });\n\n  it('should multiply two numbers', () => {\n    expect(multiply(2, 3)).toBe(6);\n  });\n});\n```\n\n### Assertions\n\n```typescript\nimport { expect, test } from 'vitest';\n\ntest('assertions', () => {\n  // Equality\n  expect(2 + 2).toBe(4);\n  expect({ a: 1 }).toEqual({ a: 1 });\n  expect([1, 2]).toStrictEqual([1, 2]);\n\n  // Truthiness\n  expect(true).toBeTruthy();\n  expect(false).toBeFalsy();\n  expect(null).toBeNull();\n  expect(undefined).toBeUndefined();\n\n  // Numbers\n  expect(10).toBeGreaterThan(5);\n  expect(5).toBeLessThan(10);\n  expect(0.1 + 0.2).toBeCloseTo(0.3);\n\n  // Strings\n  expect('hello world').toMatch(/world/);\n  expect('hello').toContain('ell');\n\n  // Arrays/Iterables\n  expect([1, 2, 3]).toContain(2);\n  expect([1, 2, 3]).toHaveLength(3);\n\n  // Objects\n  expect({ a: 1, b: 2 }).toHaveProperty('a');\n  expect({ a: 1, b: 2 }).toMatchObject({ a: 1 });\n\n  // Errors\n  expect(() => {\n    throw new Error('oops');\n  }).toThrow('oops');\n});\n```\n\n### Async Tests\n\n```typescript\nimport { test, expect } from 'vitest';\n\n// Async/await\ntest('async test', async () => {\n  const data = await fetchData();\n  expect(data).toBe('expected');\n});\n\n// Promise chaining\ntest('promise test', () => {\n  return fetchData().then((data) => {\n    expect(data).toBe('expected');\n  });\n});\n\n// Resolves/Rejects\ntest('promise resolves', async () => {\n  await expect(fetchData()).resolves.toBe('expected');\n});\n\ntest('promise rejects', async () => {\n  await expect(fetchBadData()).rejects.toThrow('error');\n});\n```\n\n## Mocking\n\n### Mock Functions\n\n```typescript\nimport { vi, test, expect } from 'vitest';\n\ntest('mock function', () => {\n  const mockFn = vi.fn();\n\n  mockFn('hello');\n  mockFn('world');\n\n  expect(mockFn).toHaveBeenCalledTimes(2);\n  expect(mockFn).toHaveBeenCalledWith('hello');\n  expect(mockFn).toHaveBeenLastCalledWith('world');\n});\n\n// Mock implementation\ntest('mock implementation', () => {\n  const mockFn = vi.fn((x: number) => x * 2);\n\n  expect(mockFn(5)).toBe(10);\n  expect(mockFn).toHaveBeenCalledWith(5);\n});\n\n// Mock return values\ntest('mock return values', () => {\n  const mockFn = vi.fn();\n\n  mockFn.mockReturnValue(42);\n  expect(mockFn()).toBe(42);\n\n  mockFn.mockReturnValueOnce(1).mockReturnValueOnce(2);\n  expect(mockFn()).toBe(1);\n  expect(mockFn()).toBe(2);\n  expect(mockFn()).toBe(42); // Returns default\n});\n```\n\n### Mock Modules\n\n```typescript\nimport { vi, beforeEach, test, expect } from 'vitest';\n\n// Mock entire module\nvi.mock('./api', () => ({\n  fetchUser: vi.fn(() => Promise.resolve({ id: 1, name: 'John' })),\n  createUser: vi.fn(),\n}));\n\nimport { fetchUser, createUser } from './api';\n\nbeforeEach(() => {\n  vi.clearAllMocks();\n});\n\ntest('uses mocked api', async () => {\n  const user = await fetchUser(1);\n  expect(user).toEqual({ id: 1, name: 'John' });\n  expect(fetchUser).toHaveBeenCalledWith(1);\n});\n```\n\n### Partial Mocking\n\n```typescript\nimport { vi, test, expect } from 'vitest';\n\n// Mock only specific exports\nvi.mock('./utils', async (importOriginal) => {\n  const actual = await importOriginal();\n  return {\n    ...actual,\n    add: vi.fn(() => 999), // Mock only 'add'\n  };\n});\n\nimport { add, multiply } from './utils';\n\ntest('partial mock', () => {\n  expect(add(1, 2)).toBe(999); // Mocked\n  expect(multiply(2, 3)).toBe(6); // Real implementation\n});\n```\n\n### Mock Timers\n\n```typescript\nimport { vi, beforeEach, afterEach, test, expect } from 'vitest';\n\nbeforeEach(() => {\n  vi.useFakeTimers();\n});\n\nafterEach(() => {\n  vi.restoreAllMocks();\n});\n\ntest('timer mocking', () => {\n  const callback = vi.fn();\n\n  setTimeout(callback, 1000);\n  expect(callback).not.toHaveBeenCalled();\n\n  vi.advanceTimersByTime(1000);\n  expect(callback).toHaveBeenCalledTimes(1);\n});\n\ntest('fast-forward time', () => {\n  const callback = vi.fn();\n\n  setInterval(callback, 1000);\n\n  vi.advanceTimersByTime(3500);\n  expect(callback).toHaveBeenCalledTimes(3);\n});\n```\n\n### Mock Globals\n\n```typescript\nimport { vi, test, expect } from 'vitest';\n\ntest('mock fetch', async () => {\n  global.fetch = vi.fn(() =>\n    Promise.resolve({\n      json: () => Promise.resolve({ data: 'mocked' }),\n    })\n  );\n\n  const response = await fetch('https://api.example.com');\n  const data = await response.json();\n\n  expect(data).toEqual({ data: 'mocked' });\n  expect(fetch).toHaveBeenCalledWith('https://api.example.com');\n});\n```\n\n## Snapshot Testing\n\n```typescript\nimport { test, expect } from 'vitest';\n\ntest('snapshot test', () => {\n  const data = {\n    id: 1,\n    name: 'John',\n    email: 'john@example.com',\n  };\n\n  expect(data).toMatchSnapshot();\n});\n\n// Inline snapshots\ntest('inline snapshot', () => {\n  const result = add(2, 3);\n  expect(result).toMatchInlineSnapshot('5');\n});\n\n// Update snapshots with: bunx vitest -u\n```\n\n## Coverage\n\n### v8 Provider (Recommended)\n\n```bash\n# Install\nbun add --dev @vitest/coverage-v8\n\n# Run with coverage\nbunx vitest --coverage\n```\n\n**Configuration:**\n```typescript\n// vitest.config.ts\nexport default defineConfig({\n  test: {\n    coverage: {\n      provider: 'v8',\n      reporter: ['text', 'json', 'html'],\n      include: ['src/**/*.ts'],\n      exclude: [\n        'node_modules/',\n        'test/',\n        '**/*.config.ts',\n        '**/*.d.ts',\n      ],\n      thresholds: {\n        lines: 80,\n        functions: 80,\n        branches: 80,\n        statements: 80,\n      },\n    },\n  },\n});\n```\n\n### Istanbul Provider\n\n```bash\n# Install\nbun add --dev @vitest/coverage-istanbul\n\n# Run with coverage\nbunx vitest --coverage\n```\n\n**When to use:**\n-  Need specific Istanbul features\n-  Migrating from Jest (Istanbul is default)\n-  Slower than v8\n\n## Watch Mode\n\n```bash\n# Start watch mode (default)\nbunx vitest\n\n# Commands in watch mode:\n# - r: rerun all tests\n# - f: rerun only failed tests\n# - u: update snapshots\n# - p: filter by filename\n# - t: filter by test name\n# - q: quit\n```\n\n**Configuration:**\n```typescript\nexport default defineConfig({\n  test: {\n    watch: true,\n    watchExclude: ['node_modules/**', 'dist/**'],\n  },\n});\n```\n\n## UI Mode\n\n```bash\n# Start UI mode\nbunx vitest --ui\n\n# Opens browser at http://localhost:51204\n```\n\n**Features:**\n- Visual test browser\n- Click to run specific tests\n- View test results and logs\n- Filter and search tests\n- Inspect coverage\n\n## Setup Files\n\n```typescript\n// test/setup.ts\nimport { beforeAll, afterAll, beforeEach, afterEach } from 'vitest';\n\nbeforeAll(() => {\n  // Setup once before all tests\n  console.log('Starting tests');\n});\n\nafterAll(() => {\n  // Cleanup once after all tests\n  console.log('Tests complete');\n});\n\nbeforeEach(() => {\n  // Setup before each test\n  vi.clearAllMocks();\n});\n\nafterEach(() => {\n  // Cleanup after each test\n  vi.restoreAllMocks();\n});\n```\n\n**Reference in config:**\n```typescript\nexport default defineConfig({\n  test: {\n    setupFiles: ['./test/setup.ts'],\n  },\n});\n```\n\n## Migration from Jest\n\n### API Compatibility\n\nVitest provides a Jest-compatible API:\n\n```typescript\n// Works in both Jest and Vitest\nimport { describe, it, expect, beforeEach, afterEach } from 'vitest';\n\ndescribe('my tests', () => {\n  beforeEach(() => {\n    // Setup\n  });\n\n  it('should work', () => {\n    expect(true).toBe(true);\n  });\n});\n```\n\n### Migration Steps\n\n1. **Replace Jest with Vitest:**\n```bash\nbun remove jest @types/jest\nbun add --dev vitest\n```\n\n2. **Update scripts in package.json:**\n```json\n{\n  \"scripts\": {\n    \"test\": \"vitest\",\n    \"test:ci\": \"vitest run\",\n    \"test:coverage\": \"vitest --coverage\"\n  }\n}\n```\n\n3. **Convert jest.config.js to vitest.config.ts:**\n```typescript\n// jest.config.js  vitest.config.ts\nexport default defineConfig({\n  test: {\n    globals: true,\n    environment: 'jsdom', // was testEnvironment in Jest\n    setupFiles: ['./test/setup.ts'], // was setupFilesAfterEnv\n    coverage: {\n      provider: 'v8',\n      reporter: ['text', 'html'],\n    },\n  },\n});\n```\n\n4. **Update imports:**\n```typescript\n// Before (Jest)\nimport { describe, it, expect } from '@jest/globals';\n\n// After (Vitest)\nimport { describe, it, expect } from 'vitest';\n```\n\n5. **Update mocking syntax:**\n```typescript\n// Jest\njest.mock('./api');\nconst mockFn = jest.fn();\n\n// Vitest\nvi.mock('./api');\nconst mockFn = vi.fn();\n```\n\n## CI/CD Integration\n\n### GitHub Actions\n\n```yaml\nname: Test\non:\n  push:\n    branches: [main]\n  pull_request:\n\njobs:\n  test:\n    name: Test\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n\n      - uses: oven-sh/setup-bun@v2\n        with:\n          bun-version: latest\n\n      - name: Install dependencies\n        run: bun install --frozen-lockfile\n\n      - name: Run tests\n        run: bunx vitest run --coverage\n\n      - name: Upload coverage\n        uses: codecov/codecov-action@v4\n        with:\n          files: ./coverage/lcov.info\n```\n\n### GitLab CI\n\n```yaml\ntest:\n  image: oven/bun:latest\n  stage: test\n  script:\n    - bun install --frozen-lockfile\n    - bunx vitest run --coverage\n  coverage: '/Lines\\s*:\\s*(\\d+\\.\\d+)%/'\n  artifacts:\n    reports:\n      coverage_report:\n        coverage_format: cobertura\n        path: coverage/cobertura-coverage.xml\n```\n\n## Troubleshooting\n\n### Tests Not Running\n\n```bash\n# Verify config is detected\nbunx vitest --config vitest.config.ts\n\n# Check test file patterns\nbunx vitest --reporter=verbose\n\n# Debug configuration\nbunx vitest --help\n```\n\n### ESM Import Errors\n\n```typescript\n// vitest.config.ts\nexport default defineConfig({\n  test: {\n    environment: 'node',\n    globals: true,\n  },\n  resolve: {\n    conditions: ['import', 'node'],\n  },\n});\n```\n\n### Coverage Thresholds Failing\n\n```bash\n# View detailed coverage report\nbunx vitest --coverage\n\n# Open HTML report\nopen coverage/index.html\n\n# Adjust thresholds\n# In vitest.config.ts:\ncoverage: {\n  thresholds: {\n    lines: 70,      // Lower threshold\n    functions: 70,\n    branches: 70,\n    statements: 70,\n  },\n}\n```\n\n### Slow Tests\n\n```bash\n# Run tests in parallel (default)\nbunx vitest --threads\n\n# Limit parallelism\nbunx vitest --maxWorkers=4\n\n# Profile slow tests\nbunx vitest --reporter=verbose\n```\n\n## Performance Comparison\n\n| Tool | Startup | Watch Mode | Coverage |\n|------|---------|------------|----------|\n| Vitest | ~100ms | Instant HMR | v8 (fast) |\n| Jest | ~3-5s | Polling | Istanbul (slower) |\n\n**Vitest is 5-10x faster than Jest in watch mode.**\n\n## References\n\n- Official docs: https://vitest.dev\n- Configuration: https://vitest.dev/config/\n- API reference: https://vitest.dev/api/\n- Migration from Jest: https://vitest.dev/guide/migration.html\n- Coverage: https://vitest.dev/guide/coverage.html"
              }
            ]
          },
          {
            "name": "code-quality-plugin",
            "description": "Code review, refactoring, linting, and static analysis",
            "source": "./code-quality-plugin",
            "category": "quality",
            "version": "1.1.0",
            "author": null,
            "install_commands": [
              "/plugin marketplace add laurigates/claude-plugins",
              "/plugin install code-quality-plugin@lgates-claude-plugins"
            ],
            "signals": {
              "stars": 1,
              "forks": 0,
              "pushed_at": "2026-01-12T12:05:51Z",
              "created_at": "2025-12-16T11:24:04Z",
              "license": null
            },
            "commands": [
              {
                "name": "/refactor",
                "description": "Refactor selected code for quality improvements",
                "path": "code-quality-plugin/commands/refactor.md",
                "frontmatter": {
                  "created": "2025-12-16T00:00:00.000Z",
                  "modified": "2025-12-16T00:00:00.000Z",
                  "reviewed": "2025-12-16T00:00:00.000Z",
                  "allowed-tools": "Read, Write, Edit, MultiEdit, Glob, Grep, SlashCommand",
                  "argument-hint": "<code-selection>",
                  "description": "Refactor selected code for quality improvements"
                },
                "content": "You are now in **Refactor Mode**. Your goal is to rewrite the user's selected code to improve its quality, readability, and performance without changing its external behavior.\n\n### Instructions\n\n1. **Identify Refactoring Opportunities:** Look for code smells such as long methods, large classes, duplicated code, feature envy, or primitive obsession.\n\n2. **Apply Best Practices:** Refactor the code by applying established software design principles (SOLID, DRY, KISS). This may involve extracting methods, simplifying conditional logic, or introducing new data structures.\n\n3. **Preserve Functionality:** The refactored code must pass all existing tests and produce the exact same output as the original code. Its external contract must not change.\n\n4. **Verify Quality:** After refactoring:\n   - Use SlashCommand: `/lint:check --fix` to ensure code quality\n   - Use SlashCommand: `/test:run` to verify functionality is preserved\n   - If tests fail, revert changes and try a different approach\n\n5. **Output Code Only:** Provide only the improved, refactored code block. Do not include explanations unless specifically requested.\n\nBegin refactoring."
              }
            ],
            "skills": [
              {
                "name": "ast-grep Search",
                "description": "AST-based code search using ast-grep for structural pattern matching. Use when searching for code patterns, refactoring, or performing semantic code analysis across multiple languages.",
                "path": "code-quality-plugin/skills/ast-grep-search/SKILL.md",
                "frontmatter": {
                  "created": "2025-12-16T00:00:00.000Z",
                  "modified": "2025-12-16T00:00:00.000Z",
                  "reviewed": "2025-12-16T00:00:00.000Z",
                  "name": "ast-grep Search",
                  "description": "AST-based code search using ast-grep for structural pattern matching. Use when searching for code patterns, refactoring, or performing semantic code analysis across multiple languages.",
                  "allowed-tools": "Bash, Read, Grep, Glob"
                },
                "content": "# ast-grep Search\n\nExpert knowledge for using `ast-grep` as a powerful AST-based code search and refactoring tool with structural pattern matching across 20+ programming languages.\n\n## Core Expertise\n\n**ast-grep Advantages**\n- AST-based matching (more precise than text-based tools)\n- Extremely fast (written in Rust, multi-core processing)\n- Supports 20+ languages via tree-sitter\n- Pattern code syntax (write code to match code)\n- Built-in rewriting capabilities\n- Interactive mode for safe transformations\n- Language server protocol support\n- YAML-based rule configuration for custom linting\n\n**Supported Languages**\nJavaScript, TypeScript, Python, Java, Go, Rust, C++, C, C#, Ruby, PHP, Swift, Kotlin, Scala, HTML, CSS, YAML, JSON, and more.\n\n## Basic Usage\n\n### Simple Pattern Search\n```bash\n# Basic pattern matching\nast-grep -p 'console.log($MSG)' --lang js\nast-grep -p 'function $NAME($$$ARGS) { $$$ }' --lang js\nast-grep -p 'def $FUNC($$$): $$$' --lang py\n\n# Search in specific files/directories\nast-grep -p 'import $PKG' src/\nast-grep -p 'class $NAME:' tests/ --lang py\n```\n\n### Pattern Syntax\n\n**Meta Variables (Wildcards)**\n- `$VAR` - Match any single AST node (named node)\n- `$$VAR` - Match any single unnamed node\n- `$$$ARGS` - Match zero or more nodes (e.g., function arguments)\n- `$_` - Match single node without capturing\n\n**Naming Rules**\n- Must start with `$`\n- Followed by uppercase letters, underscores, or digits\n- Valid: `$MATCH`, `$META_VAR`, `$VAR1`, `$_`, `$_123`\n- Invalid: `$invalid`, `$Svalue`, `$KEBAB-CASE`\n\n### Language Selection\n```bash\n# Specify language explicitly\nast-grep -p 'pattern' --lang js\nast-grep -p 'pattern' --lang py\nast-grep -p 'pattern' --lang rs\nast-grep -p 'pattern' --lang go\n\n# Common language codes\n# js/ts/jsx/tsx - JavaScript/TypeScript\n# py - Python\n# rs - Rust\n# go - Go\n# java - Java\n# cpp/c - C++/C\n# rb - Ruby\n# php - PHP\n```\n\n## Advanced Pattern Matching\n\n### Capturing and Reusing Variables\n```bash\n# Match same variable used twice\nast-grep -p '$A == $A' --lang js  # Matches: x == x (not x == y)\n\n# Multiple captures with same name must match identically\nast-grep -p 'if ($COND) { $$$ } else if ($COND) { $$$ }' --lang js\n\n# Use underscore prefix to allow different matches\nast-grep -p '$_VAR == $_VAR' --lang js  # Matches: x == y\n```\n\n### Multi-node Matching\n```bash\n# Match function calls with any number of arguments\nast-grep -p 'console.log($$$)' --lang js\n# Matches: console.log(), console.log(x), console.log(x, y, z)\n\n# Match function definitions with any parameters\nast-grep -p 'function $NAME($$$PARAMS) { $$$BODY }' --lang js\n\n# Match try-catch blocks\nast-grep -p 'try { $$$ } catch ($ERR) { $$$ }' --lang js\n```\n\n### Nested Patterns\n```bash\n# Find nested function calls\nast-grep -p 'React.useState($$$)' --lang jsx\n\n# Find method chains\nast-grep -p '$OBJ.$METHOD1().$METHOD2()' --lang js\n\n# Find specific imports\nast-grep -p \"import { $$$IMPORTS } from '$PKG'\" --lang js\n```\n\n## Code Search and Rewrite\n\n### Search and Replace\n```bash\n# Basic rewrite\nast-grep -p 'var $VAR = $VAL' -r 'let $VAR = $VAL' --lang js\n\n# Update function syntax\nast-grep -p 'function($$$ARGS) { $$$BODY }' \\\n         -r '($$$ARGS) => { $$$BODY }' --lang js\n\n# Replace deprecated API calls\nast-grep -p 'oldAPI($$$ARGS)' -r 'newAPI($$$ARGS)' --lang py\n```\n\n### Interactive Mode\n```bash\n# Review changes before applying\nast-grep -p 'var $V = $X' -r 'let $V = $X' -i --lang js\n\n# Update all automatically (use with caution)\nast-grep -p 'console.log($$$)' -r '// removed log' -U --lang js\n```\n\n### Dry Run and Preview\n```bash\n# Show what would be changed without modifying files\nast-grep -p 'pattern' -r 'replacement' --lang js\n# (Default behavior - shows matches and proposed changes)\n\n# Apply changes to all files\nast-grep -p 'pattern' -r 'replacement' -U --lang js\n```\n\n## Command-Line Options\n\n### Main Commands\n\n**ast-grep run** - One-time search or rewrite (default)\n```bash\nast-grep run -p 'pattern' [PATHS]\nast-grep -p 'pattern' -r 'rewrite' -l js src/\n```\n\n**ast-grep scan** - Scan using YAML configuration\n```bash\nast-grep scan                  # Use default sgconfig.yml\nast-grep scan -c sgconfig.yml  # Specific config file\nast-grep scan -r rule-name     # Run specific rule\nast-grep scan --filter 'console'  # Filter rules by pattern\nast-grep scan --inline-rules 'rule.yml'  # Inline rule file\n```\n\n**ast-grep test** - Test ast-grep rules\n```bash\nast-grep test                  # Run all tests\nast-grep test -c custom-config.yml  # Test with custom config\nast-grep test --snapshot-dir snapshots/  # Specify snapshot directory\n```\n\n**ast-grep new** - Create new project/rules/tests\n```bash\nast-grep new project my-linter    # Initialize new project\nast-grep new rule no-console-log  # Create new rule template\nast-grep new test test-suite      # Create new test template\nast-grep new util common-patterns # Create utility rule\n```\n\n**ast-grep lsp** - Language server for editor integration\n```bash\nast-grep lsp  # Start language server\n```\n\n### Common Flags\n\n| Flag | Purpose | Example |\n|------|---------|---------|\n| `-p, --pattern` | Search pattern | `ast-grep -p 'console.log($MSG)'` |\n| `-r, --rewrite` | Replacement pattern | `ast-grep -p 'var $V' -r 'let $V'` |\n| `-l, --lang` | Target language | `ast-grep -p 'pattern' -l js` |\n| `-i, --interactive` | Interactive mode | `ast-grep -p 'old' -r 'new' -i` |\n| `-U, --update-all` | Auto-apply all changes | `ast-grep -p 'old' -r 'new' -U` |\n| `--json` | JSON output | `ast-grep -p 'pattern' --json` |\n| `-A, -B, -C` | Context lines | `ast-grep -p 'pattern' -A 3` |\n| `--color` | Color output | `ast-grep -p 'pattern' --color always` |\n| `--heading` | Group by file | `ast-grep -p 'pattern' --heading` |\n| `--debug-query` | Debug pattern parsing | `ast-grep -p 'pattern' --debug-query` |\n\n### Output Formats\n\n```bash\n# Default: colorized, grouped by file\nast-grep -p 'pattern'\n\n# JSON output (for tooling integration)\nast-grep -p 'pattern' --json\n\n# Pretty JSON\nast-grep -p 'pattern' --json=pretty\n\n# Stream JSON (one result per line)\nast-grep -p 'pattern' --json=stream\n\n# Compact JSON\nast-grep -p 'pattern' --json=compact\n```\n\n## YAML Rule Configuration\n\n### Rule File Structure\n\nA complete ast-grep rule file contains these sections:\n\n```yaml\n# Minimal rule (required fields only)\nid: rule-identifier\nlanguage: JavaScript\nrule:\n  pattern: console.log($$$)\n\n---\n# Complete rule with all fields\nid: no-await-in-promise-all\nlanguage: TypeScript\nseverity: error\nmessage: Avoid await inside Promise.all\nnote: |\n  Using await inside Promise.all defeats the purpose of parallel execution.\n  Extract async operations before Promise.all.\nurl: https://docs.example.com/no-await-promise-all\n\n# Finding\nrule:\n  pattern: Promise.all($ARGS)\n  has:\n    pattern: await $_\n    stopBy: end\n\nconstraints:\n  ARGS:\n    regex: '^\\[.*\\]$'\n\nutils:\n  is-promise:\n    pattern: Promise.$METHOD($$$)\n\n# Patching\ntransform:\n  VAR:\n    substring:\n      source: $ARG\n      startChar: 0\n      endChar: -1\n\nfix: |\n  const results = await Promise.all($ARGS)\n\n# Linting\nlabels:\n  - label: problematic await\n    source: await $_\n\n# Globbing\nfiles:\n  - '**/*.ts'\n  - '**/*.tsx'\nignores:\n  - '**/*.test.ts'\n  - '**/node_modules/**'\n\n# Metadata\nmetadata:\n  category: async\n  tags: [performance, best-practices]\n```\n\n### Rule Types\n\n**Atomic Rules** - Match individual AST nodes\n\n```yaml\n# Pattern matching\nrule:\n  pattern: console.log($$$)\n\n# Kind matching (node type)\nrule:\n  kind: function_declaration\n  has:\n    field: name\n    regex: '^test_'\n\n# Regex matching\nrule:\n  regex: 'TODO|FIXME|XXX'\n```\n\n**Relational Rules** - Match node relationships\n\n```yaml\n# has: parent contains child\nrule:\n  pattern: Promise.all($ARGS)\n  has:\n    pattern: await $_\n    stopBy: end  # Stop at nearest enclosing function\n\n# inside: child appears within parent\nrule:\n  pattern: await $_\n  inside:\n    pattern: Promise.all($$$)\n\n# follows: node appears after another\nrule:\n  pattern: $A\n  follows:\n    pattern: $B\n\n# precedes: node appears before another\nrule:\n  pattern: $A\n  precedes:\n    pattern: $B\n```\n\n**Composite Rules** - Combine multiple rules\n\n```yaml\n# all: AND logic - all rules must match\nrule:\n  all:\n    - pattern: function $NAME($$$) { $$$ }\n    - not:\n        has:\n          pattern: return $$$\n    - inside:\n        kind: class_declaration\n\n# any: OR logic - any rule can match\nrule:\n  any:\n    - pattern: var $VAR = $$$\n    - pattern: let $VAR = $$$\n\n# not: negation\nrule:\n  pattern: function $NAME($$$) { $$$ }\n  not:\n    has:\n      pattern: return $$$\n\n# matches: reference utility rules\nrule:\n  pattern: $CALL($$$)\n  matches: is-console-method\n```\n\n**Utility Rules** - Reusable patterns\n\n```yaml\n# In rule file\nutils:\n  is-console-method:\n    kind: call_expression\n    has:\n      field: function\n      pattern: console.$METHOD\n\n  is-async-function:\n    any:\n      - pattern: async function $NAME($$$) { $$$ }\n      - pattern: async ($$$) => $$$\n\n  has-side-effect:\n    any:\n      - matches: is-console-method\n      - pattern: $OBJ.$MUTATE($$$)\n      - pattern: $VAR = $$$\n\n# Using utility rules\nrule:\n  pattern: $EXPR\n  matches: has-side-effect\n```\n\n### Constraints and Transformations\n\n**Constraints** - Filter meta-variables by conditions\n\n```yaml\nrule:\n  pattern: if ($COND) { $$$ }\n\nconstraints:\n  COND:\n    # Regex constraint\n    regex: '^true$|^false$'\n\n  COND:\n    # Kind constraint\n    kind: binary_expression\n\n  COND:\n    # Pattern constraint\n    pattern: $A == $B\n```\n\n**Transformations** - Manipulate captured variables\n\n```yaml\ntransform:\n  # String replacement\n  NEW_NAME:\n    replace:\n      source: $OLD_NAME\n      replace: 'Test'\n      by: 'Spec'\n\n  # Substring extraction\n  TRIMMED:\n    substring:\n      source: $TEXT\n      startChar: 1\n      endChar: -1\n\n  # Convert to uppercase\n  UPPER:\n    convert:\n      source: $NAME\n      toCase: upperCase\n\n  # Convert to lowercase\n  LOWER:\n    convert:\n      source: $NAME\n      toCase: lowerCase\n\nfix: |\n  describe($NEW_NAME, () => {\n    $$$TESTS\n  })\n```\n\n### File Globbing\n\nControl which files rules apply to:\n\n```yaml\n# Include specific patterns\nfiles:\n  - 'src/**/*.ts'\n  - 'src/**/*.tsx'\n  - '!src/**/*.test.ts'  # Exclude pattern\n\n# Exclude patterns (checked first)\nignores:\n  - '**/node_modules/**'\n  - '**/dist/**'\n  - '**/*.min.js'\n  - '**/coverage/**'\n\n# Globbing logic:\n# 1. If file matches any ignores pattern  skip\n# 2. If files is configured and file matches  include\n# 3. If neither configured  include by default\n```\n\n### Multiple Rules in One File\n\nSeparate rules with `---`:\n\n```yaml\n# Rule 1\nid: no-var\nlanguage: JavaScript\nseverity: error\nmessage: Use let or const instead of var\nrule:\n  pattern: var $VAR = $$$\nfix: const $VAR = $$$\n\n---\n# Rule 2\nid: no-console\nlanguage: JavaScript\nseverity: warning\nmessage: Remove console statements\nrule:\n  pattern: console.$METHOD($$$)\n```\n\n## Rule Testing\n\n### Test File Structure\n\nCreate test files in the same directory as rules:\n\n```yaml\n# rule-name-test.yml\nid: no-console-test\ntestCases:\n  # Valid code (should not match)\n  - id: no-console-in-code\n    valid:\n      - console.error('error')  # Only log is forbidden\n      - const x = 'console.log'\n\n    # Invalid code (should match and fix)\n    - console.log('test')\n    - console.log(x, y, z)\n\n  # Test with snapshots\n  - id: test-with-fix\n    input: |\n      var x = 1;\n      var y = 2;\n    output: |\n      const x = 1;\n      const y = 2;\n```\n\n### Running Tests\n\n```bash\n# Run all tests\nast-grep test\n\n# Run specific test configuration\nast-grep test -c sgconfig.yml\n\n# Update snapshots\nast-grep test --update-all\n\n# Specify test directory\nast-grep test --test-dir tests/\n\n# Specify snapshot directory\nast-grep test --snapshot-dir snapshots/\n```\n\n### Test Workflow\n\n```bash\n# 1. Create rule\nast-grep new rule no-console-log\n\n# 2. Write rule in rules/no-console-log.yml\ncat > rules/no-console-log.yml <<EOF\nid: no-console-log\nlanguage: JavaScript\nmessage: Remove console.log statements\nseverity: warning\nrule:\n  pattern: console.log(\\$\\$\\$)\nfix: ''\nEOF\n\n# 3. Create test file\ncat > rules/no-console-log-test.yml <<EOF\nid: no-console-log-test\ntestCases:\n  - id: basic-test\n    valid:\n      - console.error('error')\n      - const log = console.log\n    invalid:\n      - console.log('test')\n      - console.log(x, y)\nEOF\n\n# 4. Run tests\nast-grep test\n\n# 5. Scan codebase\nast-grep scan -r no-console-log\n```\n\n## Project Configuration\n\n### Initialize a Project\n\n```bash\n# Create new ast-grep project\nast-grep new project my-linter\n\n# This creates:\n# my-linter/\n#  sgconfig.yml       # Main configuration\n#  rules/             # Rule definitions\n#     rule1.yml\n#     rule1-test.yml\n#  utils/             # Utility rules\n```\n\n### Project Config (sgconfig.yml)\n\n```yaml\n# Rule directories\nruleDirs:\n  - rules\n  - custom-rules\n\n# Utility directories\nutilDirs:\n  - utils\n\n# Test configuration\ntestConfigs:\n  testDir: rules\n  snapshotDir: __snapshots__\n\n# Language configuration\nlanguageGlobs:\n  - language: TypeScript\n    extensions: [ts, tsx, cts, mts]\n  - language: JavaScript\n    extensions: [js, jsx, cjs, mjs]\n\n# Custom languages (tree-sitter)\ncustomLanguages:\n  - libraryPath: ./my-parser.so\n    language: MyLanguage\n    extensions: [mylang]\n```\n\n## Language-Specific Patterns\n\n### JavaScript/TypeScript\n```bash\n# Find React hooks\nast-grep -p 'const [$STATE, $SETTER] = useState($INIT)' --lang jsx\n\n# Find async functions\nast-grep -p 'async function $NAME($$$) { $$$ }' --lang js\n\n# Find class methods\nast-grep -p 'class $CLASS { $METHOD($$$) { $$$ } }' --lang ts\n\n# Find import statements\nast-grep -p \"import $NAME from '$PKG'\" --lang js\n\n# Find async/await patterns\nast-grep -p 'await $PROMISE' --lang ts\n\n# Find TypeScript type assertions\nast-grep -p '$EXPR as $TYPE' --lang ts\n```\n\n### Python\n```bash\n# Find class definitions\nast-grep -p 'class $NAME($$$BASES): $$$' --lang py\n\n# Find decorators\nast-grep -p '@$DECORATOR\\ndef $FUNC($$$): $$$' --lang py\n\n# Find comprehensions\nast-grep -p '[$EXPR for $VAR in $ITER]' --lang py\n\n# Find context managers\nast-grep -p 'with $RESOURCE as $VAR: $$$' --lang py\n\n# Find f-strings\nast-grep -p 'f\"$$$\"' --lang py\n\n# Find type hints\nast-grep -p 'def $NAME($$$) -> $TYPE: $$$' --lang py\n```\n\n### Rust\n```bash\n# Find function definitions\nast-grep -p 'fn $NAME($$$) -> $RET { $$$ }' --lang rs\n\n# Find struct definitions\nast-grep -p 'struct $NAME { $$$FIELDS }' --lang rs\n\n# Find impl blocks\nast-grep -p 'impl $TRAIT for $TYPE { $$$ }' --lang rs\n\n# Find unsafe blocks\nast-grep -p 'unsafe { $$$ }' --lang rs\n\n# Find macro invocations\nast-grep -p '$MACRO!($$$)' --lang rs\n\n# Find lifetime annotations\nast-grep -p \"fn $NAME<'$LIFE>($$$) { $$$ }\" --lang rs\n```\n\n### Go\n```bash\n# Find function definitions\nast-grep -p 'func $NAME($$$) $RET { $$$ }' --lang go\n\n# Find struct definitions\nast-grep -p 'type $NAME struct { $$$FIELDS }' --lang go\n\n# Find defer statements\nast-grep -p 'defer $FUNC($$$)' --lang go\n\n# Find goroutines\nast-grep -p 'go $FUNC($$$)' --lang go\n\n# Find interface definitions\nast-grep -p 'type $NAME interface { $$$METHODS }' --lang go\n\n# Find error handling\nast-grep -p 'if err != nil { $$$ }' --lang go\n```\n\n## Practical Use Cases\n\n### Code Quality and Linting\n```bash\n# Find console.log statements (debugging leftovers)\nast-grep -p 'console.log($$$)' --lang js\n\n# Find TODO comments embedded in code\nast-grep -p '// TODO: $$$' --lang js\n\n# Find magic numbers\nast-grep -p 'if ($VAR > 100)' --lang py\n\n# Find long parameter lists (code smell)\nast-grep -p 'function $NAME($A, $B, $C, $D, $E, $$$)' --lang js\n\n# Find empty catch blocks\nast-grep -p 'try { $$$ } catch ($E) { }' --lang js\n\n# Find unused imports (simple check)\nast-grep -p 'import $NAME from $PKG' --lang js\n```\n\n### Security Analysis\n```bash\n# Find eval usage\nast-grep -p 'eval($$$)' --lang js\n\n# Find SQL string concatenation (potential injection)\nast-grep -p '\"SELECT * FROM \" + $VAR' --lang py\n\n# Find password variables\nast-grep -p 'password = $$$' --lang py\n\n# Find dangerous shell calls\nast-grep -p 'os.system($$$)' --lang py\n\n# Find innerHTML assignments (XSS risk)\nast-grep -p '$ELEM.innerHTML = $$$' --lang js\n\n# Find unsanitized user input\nast-grep -p 'document.write($$$)' --lang js\n```\n\n### Refactoring Patterns\n```bash\n# Replace var with let/const\nast-grep -p 'var $V = $X' -r 'const $V = $X' --lang js -U\n\n# Convert function to arrow function\nast-grep -p 'function($$$ARGS) { return $EXPR }' \\\n         -r '($$$ARGS) => $EXPR' --lang js -i\n\n# Update import paths\nast-grep -p \"import $NAME from '@old/$PATH'\" \\\n         -r \"import $NAME from '@new/$PATH'\" --lang ts -U\n\n# Rename API calls\nast-grep -p 'oldAPI.$METHOD($$$)' \\\n         -r 'newAPI.$METHOD($$$)' --lang py -i\n\n# Convert callbacks to async/await\nast-grep -p '$FUNC($$$, function($ERR, $DATA) { $$$ })' --lang js\n\n# Modernize class components to hooks\nast-grep -p 'class $NAME extends React.Component { $$$ }' --lang jsx\n```\n\n### Finding Definitions\n```bash\n# Find all function definitions\nast-grep -p 'function $NAME($$$) { $$$ }' --lang js\nast-grep -p 'def $NAME($$$): $$$' --lang py\nast-grep -p 'fn $NAME($$$) { $$$ }' --lang rs\n\n# Find all class definitions\nast-grep -p 'class $NAME { $$$ }' --lang js\nast-grep -p 'class $NAME: $$$' --lang py\nast-grep -p 'struct $NAME { $$$ }' --lang rs\n\n# Find all interface definitions\nast-grep -p 'interface $NAME { $$$FIELDS }' --lang ts\n\n# Find exported functions\nast-grep -p 'export function $NAME($$$) { $$$ }' --lang js\nast-grep -p 'pub fn $NAME($$$) { $$$ }' --lang rs\n```\n\n### Finding Usage\n```bash\n# Find function calls\nast-grep -p '$FUNC($$$)' --lang js\n\n# Find method calls\nast-grep -p '$OBJ.$METHOD($$$)' --lang py\n\n# Find specific library usage\nast-grep -p 'requests.get($$$)' --lang py\nast-grep -p 'axios.post($$$)' --lang js\n\n# Find React component usage\nast-grep -p '<$COMPONENT $$$>$$$</$COMPONENT>' --lang jsx\n\n# Find hook usage\nast-grep -p 'use$HOOK($$$)' --lang jsx\n```\n\n### Migration and Deprecation\n```bash\n# Find deprecated API usage\nast-grep -p 'React.createClass($$$)' --lang jsx\n\n# Find old lifecycle methods\nast-grep -p 'componentWillMount($$$) { $$$ }' --lang jsx\n\n# Find legacy promise patterns\nast-grep -p '$PROMISE.done($$$)' --lang js\n\n# Find deprecated lodash imports\nast-grep -p \"import _ from 'lodash'\" --lang js\n\n# Update to new API\nast-grep -p 'React.findDOMNode($$$)' \\\n         -r 'ref.current' --lang jsx -i\n```\n\n## Advanced YAML Rule Examples\n\n### Complex Linting Rule\n\n```yaml\nid: no-nested-ternary\nlanguage: JavaScript\nseverity: warning\nmessage: Avoid nested ternary expressions\nnote: |\n  Nested ternary operators reduce code readability.\n  Consider using if-else statements or early returns.\n\nrule:\n  pattern: $A ? $B : $C\n  any:\n    - has:\n        pattern: $X ? $Y : $Z\n        field: consequent\n    - has:\n        pattern: $X ? $Y : $Z\n        field: alternate\n\nfiles:\n  - 'src/**/*.js'\n  - 'src/**/*.ts'\nignores:\n  - '**/*.test.js'\n```\n\n### Security Rule with Fix\n\n```yaml\nid: no-eval\nlanguage: JavaScript\nseverity: error\nmessage: Never use eval() - it's a security risk\nurl: https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/eval\n\nrule:\n  any:\n    - pattern: eval($CODE)\n    - pattern: new Function($$$ARGS, $CODE)\n    - pattern: setTimeout($STRING, $$$)\n    - pattern: setInterval($STRING, $$$)\n\nconstraints:\n  CODE:\n    kind: string\n  STRING:\n    kind: string\n\nlabels:\n  - label: dangerous eval usage\n    source: eval($CODE)\n\nfix: |\n  // FIXME: Replace eval with safe alternative\n  $CODE\n```\n\n### Refactoring Rule with Transformation\n\n```yaml\nid: modernize-var-declarations\nlanguage: JavaScript\nseverity: info\nmessage: Use const for immutable variables\n\nrule:\n  pattern: var $VAR = $INIT\n\nconstraints:\n  VAR:\n    regex: '^[A-Z_]+$'  # Constants naming pattern\n\ntransform:\n  CONST_NAME:\n    convert:\n      source: $VAR\n      toCase: upperCase\n\nfix: const $VAR = $INIT\n\nutils:\n  is-reassigned:\n    pattern: $VAR = $$$\n    inside:\n      kind: block\n```\n\n### Performance Rule\n\n```yaml\nid: no-array-in-loop\nlanguage: JavaScript\nseverity: warning\nmessage: Avoid creating arrays inside loops\nnote: Creating arrays in loops can cause performance issues\n\nrule:\n  all:\n    - pattern: '[$$$]'\n    - inside:\n        any:\n          - kind: for_statement\n          - kind: while_statement\n          - kind: do_statement\n    - not:\n        inside:\n          kind: function_declaration\n          stopBy: neighbor\n\nfiles:\n  - '**/*.js'\nignores:\n  - '**/*.test.js'\n```\n\n## Integration with Other Tools\n\n### Pipe to other commands\n```bash\n# Count matches\nast-grep -p 'pattern' --json=stream | wc -l\n\n# Extract matched files\nast-grep -p 'pattern' --json=stream | jq -r '.file' | sort -u\n\n# Open files in editor\nast-grep -p 'TODO' --json=stream | jq -r '.file' | xargs nvim\n\n# Combine with grep for post-filtering\nast-grep -p 'function $NAME($$$) { $$$ }' --lang js | grep -i 'async'\n\n# Format output with jq\nast-grep -p 'pattern' --json=stream | \\\n  jq '{file: .file, line: .range.start.line, match: .text}'\n```\n\n### Combine with fd/find\n```bash\n# Search only in specific file patterns\nfd -e js -e ts | xargs ast-grep -p 'pattern'\n\n# Search in git-tracked files only\ngit ls-files '*.py' | xargs ast-grep -p 'pattern'\n\n# Search in modified files\ngit diff --name-only | xargs ast-grep -p 'console.log($$$)' --lang js\n```\n\n### CI/CD Integration\n\n```bash\n# In GitHub Actions\n- name: Lint with ast-grep\n  run: |\n    ast-grep scan --json > results.json\n    if [ -s results.json ]; then\n      echo \"Linting errors found\"\n      cat results.json | jq '.'\n      exit 1\n    fi\n\n# Pre-commit hook\n#!/bin/bash\n# .git/hooks/pre-commit\nast-grep scan --json > /tmp/ast-grep-results.json\nif [ -s /tmp/ast-grep-results.json ]; then\n  echo \"ast-grep violations found:\"\n  cat /tmp/ast-grep-results.json | jq -r '.[] | \"\\(.file):\\(.range.start.line) - \\(.message)\"'\n  exit 1\nfi\n```\n\n### Editor Integration\n\n```bash\n# VS Code - install ast-grep extension\n# Or use LSP\nast-grep lsp\n\n# Vim/Neovim - with null-ls or ALE\n# Configure to use ast-grep scan\nlet g:ale_linters = {'javascript': ['ast-grep']}\n\n# Use as a formatter\nast-grep -p 'pattern' -r 'replacement' -U --lang js %\n```\n\n## Performance Tips\n\n**Fast Searches**\n- Specify language explicitly with `-l/--lang` flag\n- Narrow search paths (e.g., `src/` instead of `.`)\n- Use simpler patterns when possible\n- Leverage multi-core processing (default)\n- Use `files` and `ignores` in YAML rules\n\n**Large Codebases**\n- Use `--json=stream` for incremental processing\n- Combine with `fd` to filter files first\n- Use configuration files instead of CLI for complex rules\n- Consider running on subsets and combining results\n- Cache results when possible\n\n**Rule Optimization**\n- Use `kind` matching when possible (faster than pattern)\n- Place most specific rules first in `any` blocks\n- Use `stopBy` in relational rules to limit search depth\n- Use specific patterns instead of broad `$$$` wildcards\n- Use utility rules to centralize common patterns\n\n## Best Practices\n\n**When to Use ast-grep**\n- Structural code refactoring across files\n- Finding complex code patterns and anti-patterns\n- Multi-language code analysis\n- Precise code transformations\n- Custom linting rules\n- Semantic code search\n- Migration and deprecation tasks\n\n**When to Use grep/ripgrep Instead**\n- Simple text search\n- Searching non-code files (logs, docs)\n- Literal string matching\n- When language is unknown\n- Quick one-off searches without structural requirements\n\n**Rule Writing Best Practices**\n- Start with simple patterns, add complexity incrementally\n- Test rules with `ast-grep test` before deploying\n- Use descriptive IDs and helpful messages\n- Provide documentation URLs for complex rules\n- Use utility rules for common patterns\n- Test fix patterns in interactive mode first\n- Add constraints to reduce false positives\n- Use the playground for pattern development\n\n**Common Mistakes to Avoid**\n- Forgetting to specify language (`--lang`)\n- Using too generic patterns that match unintended code\n- Not testing rewrites in interactive mode first\n- Forgetting that `$VAR` matches single nodes (use `$$$` for multiple)\n- Not escaping special characters in patterns\n- Modifying files without backup (`-U` without testing)\n- Writing patterns that match comments as code\n- Not using `stopBy` in relational rules (too broad matching)\n\n**Testing and Validation**\n- Always create test cases for rules\n- Test both valid and invalid code\n- Use snapshot testing for complex transformations\n- Run tests in CI/CD pipeline\n- Validate rules on real codebases before deploying\n- Use `--debug-query` to understand pattern parsing\n\n## Debugging and Development\n\n### Debug Pattern Matching\n\n```bash\n# Debug pattern parsing\nast-grep -p 'pattern' --debug-query --lang js\n\n# Show AST structure\nast-grep -p '.' --debug-query --lang js file.js\n\n# Verbose output\nast-grep -p 'pattern' -vv --lang js\n```\n\n### Interactive Playground\n\nUse the online playground for rapid development:\n- Visit: https://ast-grep.github.io/playground.html\n- Test patterns in real-time\n- View AST structure\n- Test fix patterns\n- Export to YAML rules\n\n### Local Development Workflow\n\n```bash\n# 1. Initialize project\nast-grep new project my-rules\n\n# 2. Create rule with test\nast-grep new rule my-rule\n\n# 3. Edit rule in editor\n$EDITOR rules/my-rule.yml\n\n# 4. Test iteratively\nast-grep test -u  # Update snapshots\nast-grep test     # Run tests\n\n# 5. Scan real code\nast-grep scan -r my-rule src/\n\n# 6. Use interactive mode for fixes\nast-grep scan -r my-rule -i\n```\n\n## Quick Reference\n\n### Essential Pattern Syntax\n\n| Pattern | Matches | Example |\n|---------|---------|---------|\n| `$VAR` | Single named AST node | `console.log($MSG)` |\n| `$$VAR` | Single unnamed node | `$$EXPR` |\n| `$$$ARGS` | Zero or more nodes | `func($$$ARGS)` |\n| `$_` | Unnamed capture | `$_ == $_` |\n| `$A == $A` | Identical captures | `x == x` (not `x == y`) |\n| `$_VAR` | Non-capturing (any match) | `$_A == $_A` matches `x == y` |\n\n### Common Language Codes\n\n| Code | Language |\n|------|----------|\n| `js` | JavaScript |\n| `ts` | TypeScript |\n| `jsx` | JavaScript (JSX) |\n| `tsx` | TypeScript (JSX) |\n| `py` | Python |\n| `rs` | Rust |\n| `go` | Go |\n| `java` | Java |\n| `cpp` | C++ |\n| `c` | C |\n| `rb` | Ruby |\n| `php` | PHP |\n| `cs` | C# |\n| `swift` | Swift |\n| `kt` | Kotlin |\n\n### Rule Composition Cheat Sheet\n\n```yaml\n# Atomic\nrule:\n  pattern: code_pattern    # Match code structure\n  kind: node_type          # Match AST node type\n  regex: text_pattern      # Match node text\n\n# Relational\nrule:\n  has:                     # Contains child\n    pattern: child_pattern\n  inside:                  # Within parent\n    pattern: parent_pattern\n  follows:                 # After sibling\n    pattern: previous_pattern\n  precedes:                # Before sibling\n    pattern: next_pattern\n\n# Composite\nrule:\n  all: [rule1, rule2]      # AND\n  any: [rule1, rule2]      # OR\n  not: rule                # NOT\n  matches: util_rule       # Reference utility\n\n# Constraints\nconstraints:\n  VAR:\n    regex: pattern         # Text constraint\n    kind: node_type        # Type constraint\n    pattern: structure     # Structure constraint\n```\n\n### Common Workflow Commands\n\n```bash\n# 1. Search for pattern\nast-grep -p 'pattern' --lang js src/\n\n# 2. Preview rewrite\nast-grep -p 'old' -r 'new' --lang py\n\n# 3. Interactive rewrite\nast-grep -p 'old' -r 'new' -i --lang js\n\n# 4. Batch rewrite\nast-grep -p 'old' -r 'new' -U --lang ts\n\n# 5. Configuration-based scan\nast-grep scan -c sgconfig.yml\n\n# 6. Test rules\nast-grep test\n\n# 7. Create new rule\nast-grep new rule rule-name\n\n# 8. Debug pattern\nast-grep -p 'pattern' --debug-query --lang js\n```\n\n## Resources and Links\n\n- **Official Documentation**: https://ast-grep.github.io/\n- **Playground**: https://ast-grep.github.io/playground.html\n- **GitHub Repository**: https://github.com/ast-grep/ast-grep\n- **Rule Reference**: https://ast-grep.github.io/reference/rule.html\n- **Pattern Guide**: https://ast-grep.github.io/guide/pattern-syntax.html\n- **Configuration Reference**: https://ast-grep.github.io/reference/yaml.html\n\nThis makes ast-grep an invaluable tool for precise, AST-based code search and transformation across polyglot codebases, with powerful YAML-based rule configuration for custom linting and refactoring workflows."
              },
              {
                "name": "code-antipatterns-analysis",
                "description": "Analyze codebases for anti-patterns, code smells, and quality issues using ast-grep structural pattern matching. Use when reviewing code quality, identifying technical debt, or performing comprehensive code analysis across JavaScript, TypeScript, Python, Vue, React, or other supported languages.",
                "path": "code-quality-plugin/skills/code-antipatterns-analysis/SKILL.md",
                "frontmatter": {
                  "created": "2025-12-16T00:00:00.000Z",
                  "modified": "2025-12-16T00:00:00.000Z",
                  "reviewed": "2025-12-16T00:00:00.000Z",
                  "name": "code-antipatterns-analysis",
                  "description": "Analyze codebases for anti-patterns, code smells, and quality issues using ast-grep structural pattern matching. Use when reviewing code quality, identifying technical debt, or performing comprehensive code analysis across JavaScript, TypeScript, Python, Vue, React, or other supported languages.",
                  "allowed-tools": "Bash, Read, Grep, Glob, TodoWrite, Task"
                },
                "content": "# Code Anti-patterns Analysis\n\nExpert knowledge for systematic detection and analysis of anti-patterns, code smells, and quality issues across codebases using ast-grep and parallel agent delegation.\n\n## Analysis Philosophy\n\nThis skill emphasizes **parallel delegation** for comprehensive analysis. Rather than sequentially scanning for issues, launch multiple specialized agents to examine different categories simultaneously, then consolidate findings.\n\n## Analysis Categories\n\n### 1. JavaScript/TypeScript Anti-patterns\n\n**Callback Hell & Async Issues**\n```bash\n# Nested callbacks (3+ levels)\nast-grep -p '$FUNC($$$, function($$$) { $FUNC2($$$, function($$$) { $$$ }) })' --lang js\n\n# Missing error handling in async\nast-grep -p 'async function $NAME($$$) { $$$ }' --lang js\n# Then check if try-catch is present\n\n# Unhandled promise rejection\nast-grep -p '$PROMISE.then($$$)' --lang js\n# Without .catch() - use composite rule\n```\n\n**Magic Values**\n```bash\n# Magic numbers in comparisons\nast-grep -p 'if ($VAR > 100)' --lang js\nast-grep -p 'if ($VAR < 50)' --lang js\nast-grep -p 'if ($VAR === 42)' --lang js\n\n# Magic strings\nast-grep -p \"if ($VAR === 'admin')\" --lang js\n```\n\n**Empty Catch Blocks**\n```bash\nast-grep -p 'try { $$$ } catch ($E) { }' --lang js\n```\n\n**Console Statements (Debug Leftovers)**\n```bash\nast-grep -p 'console.log($$$)' --lang js\nast-grep -p 'console.debug($$$)' --lang js\nast-grep -p 'console.warn($$$)' --lang js\n```\n\n**var Instead of let/const**\n```bash\nast-grep -p 'var $VAR = $$$' --lang js\n```\n\n### 2. Vue 3 Anti-patterns\n\n**Props Mutation**\n```yaml\n# YAML rule for props mutation detection\nid: vue-props-mutation\nlanguage: JavaScript\nmessage: Avoid mutating props directly\nrule:\n  pattern: props.$PROP = $VALUE\n```\n\n```bash\n# Direct prop assignment\nast-grep -p 'props.$PROP = $VALUE' --lang js\n```\n\n**Missing Keys in v-for**\n```bash\n# Search in Vue templates\nast-grep -p 'v-for=\"$ITEM in $LIST\"' --lang html\n# Check if :key is present nearby\n```\n\n**Options API in Composition API Codebase**\n```bash\n# Find Options API usage\nast-grep -p 'export default { data() { $$$ } }' --lang js\nast-grep -p 'export default { methods: { $$$ } }' --lang js\nast-grep -p 'export default { computed: { $$$ } }' --lang js\n\n# vs Composition API\nast-grep -p 'defineComponent({ setup($$$) { $$$ } })' --lang js\n```\n\n**Reactive State Issues**\n```bash\n# Destructuring reactive state (loses reactivity)\nast-grep -p 'const { $$$PROPS } = $REACTIVE' --lang js\n\n# Should use toRefs\nast-grep -p 'const { $$$PROPS } = toRefs($REACTIVE)' --lang js\n```\n\n### 3. TypeScript Quality Issues\n\n**Excessive `any` Usage**\n```bash\nast-grep -p ': any' --lang ts\nast-grep -p 'as any' --lang ts\nast-grep -p '<any>' --lang ts\n```\n\n**Non-null Assertions**\n```bash\nast-grep -p '$VAR!' --lang ts\nast-grep -p '$VAR!.$PROP' --lang ts\n```\n\n**Type Assertions Instead of Guards**\n```bash\nast-grep -p '$VAR as $TYPE' --lang ts\n```\n\n**Missing Return Types**\n```bash\n# Functions without return type annotations\nast-grep -p 'function $NAME($$$) { $$$ }' --lang ts\n# Check if return type is present\n```\n\n### 4. Async/Promise Patterns\n\n**Unhandled Promises**\n```bash\n# Promise without await or .then/.catch\nast-grep -p '$ASYNC_FUNC($$$)' --lang js\n# Context: check if result is used\n\n# Floating promises (no await)\nast-grep -p '$PROMISE_RETURNING()' --lang ts\n```\n\n**Nested Callbacks (Pyramid of Doom)**\n```bash\nast-grep -p '$F1($$$, function($$$) { $F2($$$, function($$$) { $F3($$$, function($$$) { $$$ }) }) })' --lang js\n```\n\n**Promise Constructor Anti-pattern**\n```bash\n# Wrapping already-async code in new Promise\nast-grep -p 'new Promise(($RESOLVE, $REJECT) => { $ASYNC_FUNC($$$).then($$$) })' --lang js\n```\n\n### 5. Code Complexity\n\n**Long Functions (Manual Review)**\n```bash\n# Find function definitions, then count lines\nast-grep -p 'function $NAME($$$) { $$$ }' --lang js --json | jq '.[] | select(.range.end.line - .range.start.line > 50)'\n```\n\n**Deep Nesting**\n```bash\n# Nested if statements (4+ levels)\nast-grep -p 'if ($A) { if ($B) { if ($C) { if ($D) { $$$ } } } }' --lang js\n```\n\n**Large Parameter Lists**\n```bash\nast-grep -p 'function $NAME($A, $B, $C, $D, $E, $$$)' --lang js\n```\n\n**Cyclomatic Complexity Indicators**\n```bash\n# Multiple conditionals in single function\nast-grep -p 'if ($$$) { $$$ } else if ($$$) { $$$ } else if ($$$) { $$$ }' --lang js\n```\n\n### 6. React/Pinia Store Patterns\n\n**Direct State Mutation (Pinia)**\n```bash\n# Direct store state mutation outside actions\nast-grep -p '$STORE.$STATE = $VALUE' --lang js\n```\n\n**Missing Dependencies in useEffect**\n```bash\nast-grep -p 'useEffect(() => { $$$ }, [])' --lang jsx\n# Check if variables used inside are in dependency array\n```\n\n**Inline Functions in JSX**\n```bash\nast-grep -p '<$COMPONENT onClick={() => $$$} />' --lang jsx\nast-grep -p '<$COMPONENT onChange={() => $$$} />' --lang jsx\n```\n\n### 7. Memory & Performance\n\n**Event Listeners Without Cleanup**\n```bash\nast-grep -p 'addEventListener($EVENT, $HANDLER)' --lang js\n# Check for corresponding removeEventListener\n```\n\n**setInterval Without Cleanup**\n```bash\nast-grep -p 'setInterval($$$)' --lang js\n# Check for clearInterval\n```\n\n**Large Arrays in Computed/Memos**\n```bash\nast-grep -p 'computed(() => $ARRAY.filter($$$))' --lang js\nast-grep -p 'useMemo(() => $ARRAY.filter($$$), [$$$])' --lang jsx\n```\n\n### 8. Security Concerns\n\n**eval Usage**\n```bash\nast-grep -p 'eval($$$)' --lang js\nast-grep -p 'new Function($$$)' --lang js\n```\n\n**innerHTML Assignment (XSS Risk)**\n```bash\nast-grep -p '$ELEM.innerHTML = $$$' --lang js\nast-grep -p 'dangerouslySetInnerHTML={{ __html: $$$ }}' --lang jsx\n```\n\n**Hardcoded Secrets**\n```bash\nast-grep -p \"apiKey: '$$$'\" --lang js\nast-grep -p \"password = '$$$'\" --lang js\nast-grep -p \"secret: '$$$'\" --lang js\n```\n\n**SQL String Concatenation**\n```bash\nast-grep -p '\"SELECT * FROM \" + $VAR' --lang js\nast-grep -p '`SELECT * FROM ${$VAR}`' --lang js\n```\n\n### 9. Python Anti-patterns\n\n**Bare Except**\n```bash\nast-grep -p 'except: $$$' --lang py\n```\n\n**Mutable Default Arguments**\n```bash\nast-grep -p 'def $FUNC($ARG=[])' --lang py\nast-grep -p 'def $FUNC($ARG={})' --lang py\n```\n\n**Global Variable Usage**\n```bash\nast-grep -p 'global $VAR' --lang py\n```\n\n**Type: ignore Without Reason**\n```bash\n# Search in comments via grep\ngrep -r \"# type: ignore$\" --include=\"*.py\"\n```\n\n## Parallel Analysis Strategy\n\nWhen analyzing a codebase, launch multiple agents in parallel to maximize efficiency:\n\n### Agent Delegation Pattern\n\n```markdown\n1. **Language Detection Agent** (Explore)\n   - Detect project languages and frameworks\n   - Identify relevant file patterns\n\n2. **JavaScript/TypeScript Agent** (code-analysis or Explore)\n   - JS anti-patterns\n   - TypeScript quality issues\n   - Async/Promise patterns\n\n3. **Framework-Specific Agent** (code-analysis or Explore)\n   - Vue 3 anti-patterns (if Vue detected)\n   - React anti-patterns (if React detected)\n   - Pinia/Redux patterns (if detected)\n\n4. **Security Agent** (security-audit)\n   - Security concerns\n   - Hardcoded values\n   - Injection risks\n\n5. **Complexity Agent** (code-analysis or Explore)\n   - Code complexity metrics\n   - Long functions\n   - Deep nesting\n\n6. **Python Agent** (if Python detected)\n   - Python anti-patterns\n   - Type annotation issues\n```\n\n### Consolidation\n\nAfter parallel analysis completes:\n1. Aggregate findings by severity (critical, high, medium, low)\n2. Group by category (security, performance, maintainability)\n3. Provide actionable remediation suggestions\n4. Prioritize fixes based on impact\n\n## YAML Rule Examples\n\n### Complete Anti-pattern Rule\n\n```yaml\nid: no-empty-catch\nlanguage: JavaScript\nseverity: warning\nmessage: Empty catch block suppresses errors silently\nnote: |\n  Empty catch blocks hide errors and make debugging difficult.\n  Either log the error, handle it specifically, or re-throw.\n\nrule:\n  pattern: try { $$$ } catch ($E) { }\n\nfix: |\n  try { $$$ } catch ($E) {\n    console.error('Error:', $E);\n    throw $E;\n  }\n\nfiles:\n  - 'src/**/*.js'\n  - 'src/**/*.ts'\nignores:\n  - '**/*.test.js'\n  - '**/node_modules/**'\n```\n\n### Vue Props Mutation Rule\n\n```yaml\nid: no-props-mutation\nlanguage: JavaScript\nseverity: error\nmessage: Never mutate props directly - use emit or local copy\n\nrule:\n  all:\n    - pattern: props.$PROP = $VALUE\n    - inside:\n        kind: function_declaration\n\nnote: |\n  Props should be treated as immutable. To modify data:\n  1. Emit an event to parent: emit('update:propName', newValue)\n  2. Create a local ref: const local = ref(props.propName)\n```\n\n## Integration with Commands\n\nThis skill is designed to work with the `/code:antipatterns` command, which:\n1. Detects project language stack\n2. Launches parallel specialized agents\n3. Consolidates findings into prioritized report\n4. Suggests automated fixes where possible\n\n## Best Practices for Analysis\n\n1. **Start with language detection** - Run appropriate patterns for detected languages\n2. **Use parallel agents** - Don't sequentially analyze; delegate to specialized agents\n3. **Prioritize by severity** - Security issues first, then correctness, then style\n4. **Provide fixes** - Don't just identify problems; suggest solutions\n5. **Consider context** - Some \"anti-patterns\" are acceptable in specific contexts\n6. **Check test files separately** - Different standards may apply to test code\n\n## Severity Levels\n\n| Severity | Description | Examples |\n|----------|-------------|----------|\n| **Critical** | Security vulnerabilities, data loss risk | eval(), SQL injection, hardcoded secrets |\n| **High** | Bugs, incorrect behavior | Props mutation, unhandled promises, empty catch |\n| **Medium** | Maintainability issues | Magic numbers, deep nesting, large functions |\n| **Low** | Style/preference | var usage, console.log, inline functions |\n\n## Resources\n\n- **ast-grep Documentation**: https://ast-grep.github.io/\n- **ast-grep Playground**: https://ast-grep.github.io/playground.html\n- **OWASP Top 10**: https://owasp.org/www-project-top-ten/\n- **Clean Code Principles**: https://clean-code-developer.com/"
              },
              {
                "name": "Code Review Checklist",
                "description": "Structured code review approach covering security, quality, performance, and consistency.",
                "path": "code-quality-plugin/skills/code-review-checklist/SKILL.md",
                "frontmatter": {
                  "name": "Code Review Checklist",
                  "description": "Structured code review approach covering security, quality, performance, and consistency.",
                  "allowed-tools": "Read, Grep, Glob",
                  "created": "2025-12-27T00:00:00.000Z",
                  "modified": "2025-12-27T00:00:00.000Z",
                  "reviewed": "2025-12-27T00:00:00.000Z"
                },
                "content": "# Code Review Checklist\n\nStructured approach to reviewing code changes.\n\n## Review Priority Order\n\n1. **Security** (Critical) - Vulnerabilities, secrets, injection\n2. **Correctness** (High) - Logic errors, breaking changes\n3. **Performance** (Medium) - Inefficiencies, resource leaks\n4. **Quality** (Medium) - Maintainability, readability\n5. **Style** (Low) - Formatting, naming (should be automated)\n\n## Security Checklist\n\n### Secrets & Credentials\n- [ ] No hardcoded API keys, passwords, tokens\n- [ ] No credentials in logs or error messages\n- [ ] Secrets loaded from environment/vault\n\n### Injection Vulnerabilities\n- [ ] SQL queries use parameterized statements\n- [ ] User input is sanitized before HTML output (XSS)\n- [ ] Shell commands don't include user input (command injection)\n- [ ] File paths are validated (path traversal)\n\n### Authentication & Authorization\n- [ ] Auth checks on all protected endpoints\n- [ ] Proper session handling\n- [ ] Secure password handling (hashing, not plaintext)\n\n### Data Exposure\n- [ ] Sensitive data not logged\n- [ ] API responses don't leak internal details\n- [ ] Error messages don't expose system info\n\n## Correctness Checklist\n\n### Logic\n- [ ] Edge cases handled (null, empty, boundary values)\n- [ ] Error conditions handled appropriately\n- [ ] Async operations properly awaited\n- [ ] Race conditions considered\n\n### Breaking Changes\n- [ ] API contracts maintained\n- [ ] Database migrations are reversible\n- [ ] Feature flags for risky changes\n\n### Testing\n- [ ] New code has tests\n- [ ] Tests cover error paths, not just happy path\n- [ ] Existing tests still pass\n\n## Performance Checklist\n\n### Efficiency\n- [ ] No N+1 queries\n- [ ] Appropriate data structures used\n- [ ] No unnecessary loops or iterations\n- [ ] Caching considered for expensive operations\n\n### Resources\n- [ ] Database connections closed/pooled\n- [ ] File handles closed\n- [ ] No memory leaks (event listeners removed, etc.)\n\n### Scale\n- [ ] Works with realistic data volumes\n- [ ] Pagination for large result sets\n- [ ] Timeouts on external calls\n\n## Quality Checklist\n\n### Readability\n- [ ] Clear, descriptive names\n- [ ] Functions do one thing\n- [ ] No overly complex conditionals\n- [ ] Comments explain \"why\", not \"what\"\n\n### Maintainability\n- [ ] DRY (no copy-paste duplication)\n- [ ] Appropriate abstractions\n- [ ] Dependencies are justified\n- [ ] No dead code\n\n### Consistency\n- [ ] Follows project patterns\n- [ ] Matches existing code style\n- [ ] Uses established utilities/helpers\n\n## Review Output Format\n\n```markdown\n## Review: [PR Title]\n\n**Risk Level**: LOW | MEDIUM | HIGH | CRITICAL\n\n### Critical Issues\n1. [Category] Description (file:line)\n   - Impact: What could go wrong\n   - Fix: Specific recommendation\n\n### Suggestions\n1. [Category] Description (file:line)\n   - Why: Reasoning\n   - Consider: Alternative approach\n\n### Positive Notes\n- [Recognition of good patterns]\n```\n\n## Quick Checks\n\nFor fast reviews, at minimum check:\n1. Any secrets or credentials?\n2. Any SQL/command injection?\n3. Are error cases handled?\n4. Do tests exist for new code?"
              },
              {
                "name": "Debugging Methodology",
                "description": "Systematic debugging approach with tool recommendations for memory, performance, and system-level issues.",
                "path": "code-quality-plugin/skills/debugging-methodology/SKILL.md",
                "frontmatter": {
                  "name": "Debugging Methodology",
                  "description": "Systematic debugging approach with tool recommendations for memory, performance, and system-level issues.",
                  "allowed-tools": "Bash, Read, Grep, Glob",
                  "created": "2025-12-27T00:00:00.000Z",
                  "modified": "2025-12-27T00:00:00.000Z",
                  "reviewed": "2025-12-27T00:00:00.000Z"
                },
                "content": "# Debugging Methodology\n\nSystematic approach to finding and fixing bugs.\n\n## Core Principles\n\n1. **Occam's Razor** - Start with the simplest explanation\n2. **Binary Search** - Isolate the problem area systematically\n3. **Preserve Evidence** - Understand state before making changes\n4. **Document Hypotheses** - Track what was tried and didn't work\n\n## Debugging Workflow\n\n```\n1. Understand  What is expected vs actual behavior?\n2. Reproduce  Can you trigger the bug reliably?\n3. Locate  Where in the code does it happen?\n4. Diagnose  Why does it happen? (root cause)\n5. Fix  Minimal change to resolve\n6. Verify  Confirm fix works, no regressions\n```\n\n## Common Bug Patterns\n\n| Symptom | Likely Cause | Check First |\n|---------|--------------|-------------|\n| TypeError/null | Missing null check | Input validation |\n| Off-by-one | Loop bounds, array index | Boundary conditions |\n| Race condition | Async timing | Await/promise handling |\n| Import error | Path/module resolution | File paths, exports |\n| Type mismatch | Wrong type passed | Function signatures |\n| Flaky test | Timing, shared state | Test isolation |\n\n## System-Level Tools\n\n### Memory Analysis\n```bash\n# Valgrind (C/C++/Rust)\nvalgrind --leak-check=full --show-leak-kinds=all ./program\nvalgrind --tool=massif ./program  # Heap profiling\n\n# Python\npython -m memory_profiler script.py\n```\n\n### Performance Profiling\n```bash\n# Linux perf\nperf record -g ./program\nperf report\nperf top  # Real-time CPU usage\n\n# Python\npython -m cProfile -s cumtime script.py\n```\n\n### System Tracing (Traditional)\n```bash\n# System calls (ptrace-based, high overhead)\nstrace -f -e trace=all -p PID\n\n# Library calls\nltrace -f -S ./program\n\n# Open files/sockets\nlsof -p PID\n\n# Memory mapping\npmap -x PID\n```\n\n### eBPF Tracing (Modern, Production-Safe)\n\neBPF is the modern replacement for strace/ptrace-based tracing. Key advantages:\n- **Low overhead**: Safe for production use\n- **No recompilation**: Works on running binaries\n- **Non-intrusive**: Doesn't stop program execution\n- **Kernel-verified**: Bounded execution, can't crash the system\n\n```bash\n# BCC tools (install: apt install bpfcc-tools)\n# Trace syscalls with timing (like strace but faster)\nsudo syscount -p PID              # Count syscalls\nsudo opensnoop -p PID             # Trace file opens\nsudo execsnoop                    # Trace new processes\nsudo tcpconnect                   # Trace TCP connections\nsudo funccount 'vfs_*'            # Count kernel function calls\n\n# bpftrace (install: apt install bpftrace)\n# One-liner tracing scripts\nsudo bpftrace -e 'tracepoint:syscalls:sys_enter_open { printf(\"%s %s\\n\", comm, str(args->filename)); }'\nsudo bpftrace -e 'uprobe:/bin/bash:readline { printf(\"readline\\n\"); }'\n\n# Trace function arguments in Go/other languages\nsudo bpftrace -e 'uprobe:./myapp:main.handleRequest { printf(\"called\\n\"); }'\n```\n\n**eBPF Tool Hierarchy**:\n| Level | Tool | Use Case |\n|-------|------|----------|\n| High | BCC tools | Pre-built tracing scripts |\n| Medium | bpftrace | One-liner custom traces |\n| Low | libbpf/gobpf | Custom eBPF programs |\n\n**When to use eBPF over strace**:\n- Production systems (strace adds 10-100x overhead)\n- Long-running traces\n- High-frequency syscalls\n- When you can't afford to slow down the process\n\n### Network Debugging\n```bash\n# Packet capture\ntcpdump -i any port 8080\n\n# Connection status\nss -tuln\nnetstat -tuln\n```\n\n## Language-Specific Debugging\n\n### Python\n```python\n# Quick debug\nimport pdb; pdb.set_trace()\n\n# Better: ipdb or pudb\nimport ipdb; ipdb.set_trace()\n\n# Print with context\nprint(f\"{var=}\")  # Python 3.8+\n```\n\n### JavaScript/TypeScript\n```javascript\n// Browser/Node\ndebugger;\n\n// Structured logging\nconsole.log({ var1, var2, context: 'function_name' });\n```\n\n### Rust\n```rust\n// Debug print\ndbg!(&variable);\n\n// Backtrace on panic\nRUST_BACKTRACE=1 cargo run\n```\n\n## Debugging Questions\n\nWhen stuck, ask:\n1. What changed recently that could cause this?\n2. Does it happen in all environments or just one?\n3. Is the bug in my code or a dependency?\n4. What assumptions am I making that might be wrong?\n5. Can I write a minimal reproduction?\n\n## Anti-Patterns to Avoid\n\n- **Shotgun debugging**: Random changes hoping something works\n- **Printf debugging only**: Use proper debuggers when available\n- **Fixing symptoms**: Find root cause, not just band-aids\n- **Skipping reproduction**: Always reproduce before fixing\n- **Not testing the fix**: Verify the fix actually works"
              },
              {
                "name": "Documentation Quality Analysis",
                "description": "Analyze and validate documentation quality for PRDs, ADRs, PRPs, CLAUDE.md, and .claude/rules/ to ensure standards compliance and freshness",
                "path": "code-quality-plugin/skills/documentation-quality/SKILL.md",
                "frontmatter": {
                  "name": "Documentation Quality Analysis",
                  "description": "Analyze and validate documentation quality for PRDs, ADRs, PRPs, CLAUDE.md, and .claude/rules/ to ensure standards compliance and freshness",
                  "allowed-tools": "Bash, Read, Grep, Glob, TodoWrite",
                  "created": "2026-01-08T00:00:00.000Z",
                  "modified": "2026-01-08T00:00:00.000Z",
                  "reviewed": "2026-01-08T00:00:00.000Z"
                },
                "content": "# Documentation Quality Analysis\n\nExpert analysis of technical documentation quality, structure, and maintenance for codebases using Blueprint Development methodology and Claude Code conventions.\n\n## Core Expertise\n\nDocumentation quality is critical for:\n- **AI Assistant Context**: Well-structured docs enable better AI assistance\n- **Knowledge Preservation**: Captures architectural decisions and rationale\n- **Onboarding**: Accelerates new team member productivity\n- **Maintenance**: Prevents knowledge loss and technical debt\n\nThis skill provides systematic analysis of:\n- **CLAUDE.md**: Project-level AI assistant instructions\n- **.claude/rules/**: Modular rule definitions\n- **ADRs**: Architecture Decision Records\n- **PRDs**: Product Requirements Documents\n- **PRPs**: Product Requirement Prompts (Blueprint methodology)\n\n## Documentation Types & Standards\n\n### CLAUDE.md\n\n**Purpose**: Guide AI assistants on working with the codebase\n\n**Required Elements**:\n```yaml\n---\ncreated: YYYY-MM-DD\nmodified: YYYY-MM-DD\nreviewed: YYYY-MM-DD\n---\n\n# Project Name\n\n## Project Structure\n[Directory layout and organization]\n\n## Rules\n[Key rules and conventions]\n\n## Development Workflow\n[Common tasks and patterns]\n\n## Conventions\n[Naming, structure, etc.]\n```\n\n**Quality Indicators**:\n-  Clear project structure overview\n-  References to .claude/rules/ files\n-  Tables for quick reference\n-  Focused and concise (not a full manual)\n-  Updated within last 6 months\n\n### .claude/rules/\n\n**Purpose**: Modular, reusable rule definitions\n\n**File Structure**:\n```yaml\n---\ncreated: YYYY-MM-DD\nmodified: YYYY-MM-DD\nreviewed: YYYY-MM-DD\n---\n\n# Rule Title\n\n[Clear, specific guidance on a single concern]\n```\n\n**Quality Indicators**:\n-  One concern per rule file\n-  Descriptive file names (kebab-case)\n-  Clear scope and applicability\n-  Actionable guidance with examples\n-  Cross-references to related rules\n\n**Common Rules**:\n- `plugin-structure.md` - Plugin organization\n- `release-please.md` - Version management\n- `skill-development.md` - Skill creation patterns\n- `agentic-optimization.md` - CLI optimization for AI\n- `command-naming.md` - Command conventions\n\n### Architecture Decision Records (ADRs)\n\n**Purpose**: Document significant architectural choices\n\n**Format**: MADR (Markdown Architecture Decision Records)\n\n**Structure**:\n```markdown\n# ADR-NNNN: Title\n\n**Date**: YYYY-MM\n**Status**: Accepted | Superseded | Deprecated\n**Deciders**: [who decided]\n\n## Context\n[Problem and constraints]\n\n## Decision\n[What was decided]\n\n## Consequences\n[Positive and negative outcomes]\n```\n\n**Location**: `docs/adrs/` or `docs/adr/`\n\n**Naming**: Sequential numbers, kebab-case titles\n- `0001-plugin-based-architecture.md`\n- `0002-domain-driven-organization.md`\n\n**Quality Indicators**:\n-  All major architectural decisions documented\n-  Sequential numbering without gaps\n-  Clear context and rationale\n-  Consequences documented (both pros and cons)\n-  Index file maintained\n-  Status accurate (Accepted/Superseded/Deprecated)\n\n### Product Requirements Documents (PRDs)\n\n**Purpose**: Define what needs to be built and why\n\n**Location**: `docs/prds/` or `.claude/blueprints/prds/`\n\n**Structure**:\n```markdown\n# Project/Feature Name - PRD\n\n**Created**: YYYY-MM-DD\n**Status**: Draft | Active | Implemented | Archived\n**Version**: X.Y\n\n## Executive Summary\n- Problem Statement\n- Proposed Solution\n- Business Impact\n\n## Stakeholders & Personas\n[Who cares and who uses]\n\n## Functional Requirements\n[What the system must do]\n\n## Non-Functional Requirements\n[Performance, security, accessibility]\n\n## Success Metrics\n[How we measure success]\n\n## Scope\n- In Scope\n- Out of Scope\n\n## Technical Considerations\n[Architecture, dependencies, integrations]\n```\n\n**Quality Indicators**:\n-  Clear problem statement\n-  User personas defined\n-  Specific, measurable requirements\n-  Success metrics defined\n-  Scope explicitly bounded\n-  Status field accurate\n-  Updated when requirements change\n\n### Product Requirement Prompts (PRPs)\n\n**Purpose**: AI-executable feature specifications (Blueprint methodology)\n\n**Location**: `docs/prps/`\n\n**Structure**:\n```markdown\n# [Feature Name] PRP\n\n## Goal & Why\n[One sentence goal + business justification]\n\n## Success Criteria\n[Specific, testable acceptance criteria]\n\n## Context\n- **Documentation References**: [URLs with sections]\n- **ai_docs References**: [Curated context]\n- **Codebase Intelligence**: [Files, patterns, snippets]\n- **Known Gotchas**: [Warnings and mitigations]\n\n## Implementation Blueprint\n[Architecture decision + task breakdown + pseudocode]\n\n## TDD Requirements\n[Test strategy + critical test cases]\n\n## Validation Gates\n[Executable commands for quality gates]\n\n## Confidence Score: X/10\n- Context Completeness: X/10\n- Implementation Clarity: X/10\n- Gotchas Documented: X/10\n- Validation Coverage: X/10\n```\n\n**Quality Indicators**:\n-  Explicit file paths and line numbers\n-  Code snippets from actual codebase\n-  Executable validation commands\n-  Honest confidence scoring (7 for execution)\n-  Known gotchas with mitigations\n-  Test strategy defined\n\n## Quality Analysis Commands\n\n### Check for Frontmatter\n\n```bash\n# Check if file has required frontmatter\ngrep -A 5 \"^---$\" CLAUDE.md | grep -E \"(created|modified|reviewed):\"\n\n# Find files missing frontmatter\nfor f in docs/adrs/*.md; do\n  grep -q \"^---$\" \"$f\" || echo \"Missing frontmatter: $f\"\ndone\n```\n\n### Validate ADR Naming\n\n```bash\n# Check ADR naming convention (NNNN-title.md)\nfind docs/adrs -name \"*.md\" ! -name \"README.md\" ! -name \"[0-9][0-9][0-9][0-9]-*.md\"\n\n# Check for sequential numbering\nls docs/adrs/[0-9]*.md | sort\n```\n\n### Check Documentation Freshness\n\n```bash\n# Find docs not modified in 6 months\nfind docs -name \"*.md\" -mtime +180\n\n# Check git history for documentation\ngit log --since=\"6 months ago\" --oneline -- docs/ .claude/ CLAUDE.md\n\n# Last modification of specific doc\ngit log -1 --format=\"%ai %s\" -- CLAUDE.md\n```\n\n### Validate Sections\n\n```bash\n# Check if ADR has required sections\ngrep -E \"^## (Context|Decision|Consequences)\" docs/adrs/0001-*.md\n\n# Check PRD completeness\ngrep -E \"^## (Executive Summary|Functional Requirements|Success Metrics)\" docs/prds/*.md\n```\n\n### Count Documentation\n\n```bash\n# Documentation inventory\necho \"CLAUDE.md: $(test -f CLAUDE.md && echo '' || echo '')\"\necho \"Rules: $(ls .claude/rules/*.md 2>/dev/null | wc -l) files\"\necho \"ADRs: $(ls docs/adrs/*.md 2>/dev/null | grep -v README | wc -l) files\"\necho \"PRDs: $(ls docs/prds/*.md 2>/dev/null | wc -l) files\"\necho \"PRPs: $(ls docs/prps/*.md 2>/dev/null | wc -l) files\"\n```\n\n## Quality Scoring Methodology\n\n### Overall Quality Score (0-10)\n\nCalculate as average of five dimensions:\n\n| Dimension | Score 9-10 | Score 7-8 | Score 5-6 | Score 3-4 | Score 0-2 |\n|-----------|------------|-----------|-----------|-----------|-----------|\n| **Structure** | Perfect org, all conventions | Minor naming issues | Some disorganization | Poor structure | Missing/chaotic |\n| **Completeness** | All sections present | 1-2 missing sections | Several gaps | Major gaps | Severely incomplete |\n| **Freshness** | Updated <3mo | Updated <6mo | Updated <12mo | Stale >12mo | Abandoned >24mo |\n| **Standards** | Perfect compliance | Minor deviations | Some non-compliance | Poor compliance | No standards |\n| **Content Quality** | Excellent clarity | Good with minor issues | Acceptable | Unclear/vague | Unusable |\n\n### Dimension-Specific Scoring\n\n**Structure (Organization & Naming)**:\n- File naming conventions followed\n- Directory structure logical\n- Sequential numbering (ADRs)\n- Proper categorization (.claude/rules/)\n\n**Completeness (Required Elements)**:\n- All required sections present\n- Frontmatter complete\n- Cross-references included\n- Examples provided where needed\n\n**Freshness (Currency)**:\n- `modified` dates recent\n- Git commits align with modified dates\n- Reflects current codebase state\n- Regular review cadence\n\n**Standards Compliance (Format Adherence)**:\n- Frontmatter present and correct\n- Template structure followed\n- Markdown formatting valid\n- Links and references work\n\n**Content Quality (Clarity & Usefulness)**:\n- Clear, specific language\n- Actionable guidance\n- Relevant examples\n- Appropriate detail level\n- No contradictions or confusion\n\n## Common Documentation Issues\n\n### Critical Issues (Must Fix)\n\n| Issue | Detection | Fix |\n|-------|-----------|-----|\n| Missing CLAUDE.md | `! -f CLAUDE.md` | Create using project template |\n| No frontmatter | `! grep \"^---$\"` | Add YAML frontmatter with dates |\n| Completely outdated | modified >24mo | Review and update or archive |\n| Broken structure | Missing required sections | Follow template structure |\n| Invalid ADR naming | Not NNNN-title.md | Rename to follow convention |\n\n### Warnings (Should Fix)\n\n| Issue | Detection | Fix |\n|-------|-----------|-----|\n| Stale docs | modified >6mo | Review and update modified date |\n| Missing sections | Template mismatch | Add missing sections |\n| No ADR index | No README in adrs/ | Create index file |\n| Vague requirements | Review content | Add specificity and examples |\n| Low confidence PRP | Score <7 | Research more context |\n\n### Suggestions (Nice to Have)\n\n| Issue | Detection | Fix |\n|-------|-----------|-----|\n| Sparse rules | <3 rule files | Extract common patterns to rules |\n| No PRPs | Empty prps/ dir | Create PRPs for planned features |\n| Missing examples | Grep for code blocks | Add code examples |\n| Poor cross-refs | Few markdown links | Link related documentation |\n| No metrics | PRD without success criteria | Define measurable metrics |\n\n## Analysis Workflow\n\n### 1. Inventory Phase\n\nCollect all documentation:\n```bash\n# List all documentation\nfind . -name \"CLAUDE.md\" -o -path \"*/.claude/rules/*.md\" -o -path \"*/docs/adrs/*.md\" -o -path \"*/docs/prds/*.md\" -o -path \"*/docs/prps/*.md\"\n```\n\nCreate inventory:\n- Count files by type\n- Note missing standard docs\n- Check directory structure\n\n### 2. Validation Phase\n\nFor each document type:\n- **Read** the file\n- **Check** frontmatter exists and is valid\n- **Verify** required sections present\n- **Validate** naming conventions\n- **Assess** content quality\n\n### 3. Freshness Phase\n\nCheck currency:\n```bash\n# Git last modified\ngit log -1 --format=\"%ai\" -- path/to/doc.md\n\n# Compare frontmatter vs git\n# (modified date should match recent git activity)\n```\n\nFlag stale documents:\n- >6mo: Warning\n- >12mo: Concern\n- >24mo: Critical\n\n### 4. Scoring Phase\n\nCalculate scores:\n1. **Structure**: File org, naming (0-10)\n2. **Completeness**: Sections present (0-10)\n3. **Freshness**: Currency (0-10)\n4. **Standards**: Format compliance (0-10)\n5. **Content**: Quality, clarity (0-10)\n\n**Overall** = Average of 5 dimensions\n\n### 5. Reporting Phase\n\nGenerate report:\n- Executive summary with overall score\n- Inventory table\n- Dimension scores\n- Critical issues (must fix)\n- Warnings (should fix)\n- Suggestions (nice to have)\n- Actionable recommendations with specific files/fixes\n\n## Agentic Optimizations\n\n| Task | Optimized Approach |\n|------|-------------------|\n| List docs | `find` with multiple `-name` patterns, single command |\n| Check frontmatter | `grep -l \"^---$\" *.md` batch check |\n| Validate names | Shell globbing `[0-9][0-9][0-9][0-9]-*.md` |\n| Count files | Pipeline `ls | wc -l` |\n| Git history | `git log --since=\"6 months ago\" --oneline` |\n| Batch validation | `for` loop over files, collect issues |\n\n## Quick Reference\n\n### Frontmatter Template\n\n```yaml\n---\ncreated: 2026-01-08\nmodified: 2026-01-08\nreviewed: 2026-01-08\n---\n```\n\n### ADR Quick Template\n\n```markdown\n# ADR-NNNN: Title\n\n**Date**: 2026-01\n**Status**: Accepted\n\n## Context\n[Why this decision?]\n\n## Decision\n[What did we decide?]\n\n## Consequences\n Pros: ...\n Cons: ...\n```\n\n### Quality Score Guide\n\n- **9-10**: Excellent - Reference quality\n- **7-8**: Good - Minor improvements\n- **5-6**: Fair - Several issues\n- **3-4**: Poor - Major work needed\n- **0-2**: Critical - Severe problems\n\n## Related Tools\n\n- `/docs:quality-check` - Run comprehensive analysis\n- `/blueprint:init` - Initialize Blueprint Development\n- `/blueprint:prd` - Generate PRD from project docs\n- `/blueprint:adr` - Generate ADRs from codebase\n- `/blueprint:prp-create` - Create PRP for feature\n\n## Best Practices\n\n1. **Regular Reviews**: Run quality checks monthly\n2. **Update Modified Dates**: When editing, update frontmatter\n3. **Quarterly Reviews**: Update `reviewed` date every 3 months\n4. **Template Adherence**: Use standard templates consistently\n5. **Specificity**: Prefer explicit over vague (file paths, metrics)\n6. **Cross-Reference**: Link related documentation\n7. **Examples**: Include code snippets and real examples\n8. **Scope Management**: One concern per document\n9. **Git Sync**: Commit docs with code changes\n10. **AI-Friendly**: Write for both humans and AI assistants\n\n## Error Handling\n\n```bash\n# Safe directory checks\ntest -d docs/adrs && ls docs/adrs || echo \"ADRs directory not found\"\n\n# Safe file reads with fallback\ncat CLAUDE.md 2>/dev/null || echo \"CLAUDE.md not found\"\n\n# Git-aware freshness (works without git)\ngit log -1 --format=\"%ai\" -- CLAUDE.md 2>/dev/null || echo \"No git history\"\n\n# Glob with no-match handling\nshopt -s nullglob\nfor f in docs/adrs/*.md; do\n  echo \"Processing $f\"\ndone\n```\n\n## References\n\n- [MADR (Markdown ADR)](https://adr.github.io/madr/) - ADR template format\n- [Michael Nygard ADR](https://cognitect.com/blog/2011/11/15/documenting-architecture-decisions) - Original ADR format\n- Blueprint Development methodology - PRP/PRD patterns\n- `.claude/rules/` - Project-specific documentation standards"
              },
              {
                "name": "Linter Autofix Patterns",
                "description": "Cross-language linter autofix commands and common fix patterns for biome, ruff, clippy, shellcheck, and more.",
                "path": "code-quality-plugin/skills/linter-autofix/SKILL.md",
                "frontmatter": {
                  "name": "Linter Autofix Patterns",
                  "description": "Cross-language linter autofix commands and common fix patterns for biome, ruff, clippy, shellcheck, and more.",
                  "allowed-tools": "Bash, Read, Edit, Grep",
                  "created": "2025-12-27T00:00:00.000Z",
                  "modified": "2025-12-27T00:00:00.000Z",
                  "reviewed": "2025-12-27T00:00:00.000Z"
                },
                "content": "# Linter Autofix Patterns\n\nQuick reference for running linter autofixes across languages.\n\n## Autofix Commands\n\n| Language | Linter | Autofix Command |\n|----------|--------|-----------------|\n| TypeScript/JS | biome | `npx @biomejs/biome check --write .` |\n| TypeScript/JS | biome format | `npx @biomejs/biome format --write .` |\n| Python | ruff | `ruff check --fix .` |\n| Python | ruff format | `ruff format .` |\n| Rust | clippy | `cargo clippy --fix --allow-dirty` |\n| Rust | rustfmt | `cargo fmt` |\n| Go | gofmt | `gofmt -w .` |\n| Go | go mod | `go mod tidy` |\n| Shell | shellcheck | No autofix (manual only) |\n\n## Common Fix Patterns\n\n### JavaScript/TypeScript (Biome)\n\n**Unused imports**\n```typescript\n// Before\nimport { useState, useEffect, useMemo } from 'react';\n// Only useState used\n\n// After\nimport { useState } from 'react';\n```\n\n**Prefer const**\n```typescript\n// Before\nlet x = 5;  // Never reassigned\n\n// After\nconst x = 5;\n```\n\n### Python (Ruff)\n\n**Import sorting (I001)**\n```python\n# Before\nimport os\nfrom typing import List\nimport sys\n\n# After\nimport os\nimport sys\nfrom typing import List\n```\n\n**Unused imports (F401)**\n```python\n# Before\nimport os\nimport sys  # unused\n\n# After\nimport os\n```\n\n**Line too long (E501)**\n```python\n# Before\nresult = some_function(very_long_argument_one, very_long_argument_two, very_long_argument_three)\n\n# After\nresult = some_function(\n    very_long_argument_one,\n    very_long_argument_two,\n    very_long_argument_three,\n)\n```\n\n### Rust (Clippy)\n\n**Redundant clone**\n```rust\n// Before\nlet s = String::from(\"hello\").clone();\n\n// After\nlet s = String::from(\"hello\");\n```\n\n**Use if let**\n```rust\n// Before\nmatch option {\n    Some(x) => do_something(x),\n    None => {},\n}\n\n// After\nif let Some(x) = option {\n    do_something(x);\n}\n```\n\n### Shell (ShellCheck)\n\n**Quote variables (SC2086)**\n```bash\n# Before\necho $variable\n\n# After\necho \"$variable\"\n```\n\n**Use $(...) instead of backticks (SC2006)**\n```bash\n# Before\nresult=`command`\n\n# After\nresult=$(command)\n```\n\n## Workflow\n\n1. Run autofix first: `ruff check --fix . && ruff format .`\n2. Check remaining issues: `ruff check .`\n3. Manual fixes for complex cases\n4. Verify: re-run linter to confirm clean\n\n## When to Escalate\n\nStop and use different approach when:\n- Fix requires understanding business logic\n- Multiple files need coordinated changes\n- Warning indicates potential bug (not just style)\n- Security-related linter rule\n- Type error requires interface/API changes"
              }
            ]
          },
          {
            "name": "python-plugin",
            "description": "Python development ecosystem - uv, ruff, pytest, packaging",
            "source": "./python-plugin",
            "category": "language",
            "version": "1.0.0",
            "author": null,
            "install_commands": [
              "/plugin marketplace add laurigates/claude-plugins",
              "/plugin install python-plugin@lgates-claude-plugins"
            ],
            "signals": {
              "stars": 1,
              "forks": 0,
              "pushed_at": "2026-01-12T12:05:51Z",
              "created_at": "2025-12-16T11:24:04Z",
              "license": null
            },
            "commands": [],
            "skills": [
              {
                "name": "basedpyright-type-checking",
                "description": "Basedpyright static type checker configuration, installation, and usage patterns.\nUse when implementing type checking, configuring LSP, comparing type checkers,\nor setting up strict type validation in Python projects.\nTriggered by: basedpyright, pyright, type checking, LSP, mypy alternative, static analysis.\n",
                "path": "python-plugin/skills/basedpyright-type-checking/SKILL.md",
                "frontmatter": {
                  "created": "2025-12-16T00:00:00.000Z",
                  "modified": "2025-12-16T00:00:00.000Z",
                  "reviewed": "2025-12-16T00:00:00.000Z",
                  "name": "basedpyright-type-checking",
                  "description": "Basedpyright static type checker configuration, installation, and usage patterns.\nUse when implementing type checking, configuring LSP, comparing type checkers,\nor setting up strict type validation in Python projects.\nTriggered by: basedpyright, pyright, type checking, LSP, mypy alternative, static analysis.\n"
                },
                "content": "# Basedpyright Type Checking\n\nBasedpyright is a fork of Pyright with additional features and stricter defaults, designed for maximum type safety and performance.\n\n## Installation\n\n### Via uv (Recommended)\n```bash\n# Install globally\nuv tool install basedpyright\n\n# Install as dev dependency\nuv add --dev basedpyright\n\n# Run with uv\nuv run basedpyright\n```\n\n### Via pipx\n```bash\npipx install basedpyright\n```\n\n## Basic Usage\n\n```bash\n# Check entire project\nbasedpyright\n\n# Check specific files/directories\nbasedpyright src/ tests/\n\n# Watch mode for development\nbasedpyright --watch\n\n# Output JSON for tooling integration\nbasedpyright --outputjson\n\n# Verbose diagnostics\nbasedpyright --verbose\n```\n\n## Configuration\n\n### pyproject.toml Configuration\n\n```toml\n[tool.basedpyright]\n# Type checking mode (off, basic, standard, strict, all)\ntypeCheckingMode = \"strict\"\n\n# Python version and platform\npythonVersion = \"3.12\"\npythonPlatform = \"All\"\n\n# Execution environments for multi-environment projects\nexecutionEnvironments = [\n  { root = \"src\", pythonVersion = \"3.12\" },\n  { root = \"tests\", extraPaths = [\"src\"] }\n]\n\n# Strict type checking rules (enabled in strict mode)\nstrictListInference = true\nstrictDictionaryInference = true\nstrictSetInference = true\nstrictParameterNoneValue = true\n\n# Additional strict rules (beyond standard Pyright)\nreportUnusedCallResult = \"error\"\nreportImplicitStringConcatenation = \"error\"\nreportMissingSuperCall = \"error\"\nreportUninitializedInstanceVariable = \"error\"\n\n# Standard type checking rules\nreportMissingImports = \"error\"\nreportMissingTypeStubs = \"warning\"\nreportUnusedImport = \"error\"\nreportUnusedClass = \"warning\"\nreportUnusedFunction = \"warning\"\nreportUnusedVariable = \"error\"\nreportDuplicateImport = \"error\"\nreportOptionalSubscript = \"error\"\nreportOptionalMemberAccess = \"error\"\nreportOptionalCall = \"error\"\nreportOptionalIterable = \"error\"\nreportOptionalContextManager = \"error\"\nreportOptionalOperand = \"error\"\nreportTypedDictNotRequiredAccess = \"warning\"\nreportPrivateImportUsage = \"error\"\nreportConstantRedefinition = \"error\"\nreportIncompatibleMethodOverride = \"error\"\nreportIncompatibleVariableOverride = \"error\"\nreportInconsistentConstructor = \"error\"\nreportOverlappingOverload = \"error\"\nreportMissingSuperCall = \"warning\"\nreportUninitializedInstanceVariable = \"warning\"\nreportInvalidStringEscapeSequence = \"error\"\nreportUnknownParameterType = \"warning\"\nreportUnknownArgumentType = \"warning\"\nreportUnknownLambdaType = \"warning\"\nreportUnknownVariableType = \"warning\"\nreportUnknownMemberType = \"warning\"\nreportMissingParameterType = \"error\"\nreportMissingTypeArgument = \"error\"\nreportInvalidTypeVarUse = \"error\"\nreportCallInDefaultInitializer = \"warning\"\nreportUnnecessaryIsInstance = \"warning\"\nreportUnnecessaryCast = \"warning\"\nreportUnnecessaryComparison = \"warning\"\nreportAssertAlwaysTrue = \"error\"\nreportSelfClsParameterName = \"error\"\nreportImplicitStringConcatenation = \"warning\"\nreportUndefinedVariable = \"error\"\nreportUnboundVariable = \"error\"\nreportInvalidStubStatement = \"error\"\nreportIncompleteStub = \"warning\"\nreportUnsupportedDunderAll = \"error\"\nreportUnusedCoroutine = \"error\"\n\n# Include/exclude patterns\ninclude = [\"src\", \"tests\"]\nexclude = [\n  \"**/__pycache__\",\n  \"**/.venv\",\n  \"**/.git\",\n  \"**/node_modules\",\n  \"**/.mypy_cache\",\n  \"**/.pytest_cache\"\n]\n\n# Stub search paths\nstubPath = \"typings\"\n\n# Virtual environment detection\nvenvPath = \".\"\nvenv = \".venv\"\n```\n\n### Minimal Strict Configuration\n\n```toml\n[tool.basedpyright]\ntypeCheckingMode = \"strict\"\npythonVersion = \"3.12\"\ninclude = [\"src\"]\nexclude = [\"**/__pycache__\", \"**/.venv\"]\n\n# Basedpyright-specific strict rules\nreportUnusedCallResult = \"error\"\nreportImplicitStringConcatenation = \"error\"\nreportMissingSuperCall = \"error\"\nreportUninitializedInstanceVariable = \"error\"\n```\n\n## Type Checking Modes\n\n### Mode Comparison\n\n| Mode | Description | Use Case |\n|------|-------------|----------|\n| `off` | No type checking | Legacy code, migration start |\n| `basic` | Basic type checking | Gradual typing adoption |\n| `standard` | Standard strictness | Most projects (default Pyright) |\n| `strict` | Strict type checking | Type-safe codebases |\n| `all` | Maximum strictness | High-assurance systems |\n\n### Progressive Type Checking\n\n```toml\n# Start with basic mode\n[tool.basedpyright]\ntypeCheckingMode = \"basic\"\ninclude = [\"src/new_module\"]  # Type check new code only\n\n# Gradually expand\ninclude = [\"src/new_module\", \"src/api\"]\n\n# Eventually enable strict mode\ntypeCheckingMode = \"strict\"\ninclude = [\"src\"]\n```\n\n## LSP Integration\n\n### Neovim with nvim-lspconfig\n\n```lua\n-- Using mason.nvim\nrequire(\"mason\").setup()\nrequire(\"mason-lspconfig\").setup({\n  ensure_installed = { \"basedpyright\" }\n})\n\n-- Direct configuration\nrequire(\"lspconfig\").basedpyright.setup({\n  settings = {\n    basedpyright = {\n      analysis = {\n        typeCheckingMode = \"strict\",\n        diagnosticMode = \"workspace\",\n        autoSearchPaths = true,\n        useLibraryCodeForTypes = true,\n        diagnosticSeverityOverrides = {\n          reportUnusedCallResult = \"error\",\n          reportImplicitStringConcatenation = \"error\",\n        }\n      }\n    }\n  }\n})\n```\n\n### VS Code Settings\n\n```json\n{\n  \"basedpyright.analysis.typeCheckingMode\": \"strict\",\n  \"basedpyright.analysis.diagnosticMode\": \"workspace\",\n  \"basedpyright.analysis.autoSearchPaths\": true,\n  \"basedpyright.analysis.useLibraryCodeForTypes\": true,\n  \"basedpyright.analysis.diagnosticSeverityOverrides\": {\n    \"reportUnusedCallResult\": \"error\",\n    \"reportImplicitStringConcatenation\": \"error\"\n  }\n}\n```\n\n### Language Server Protocol\n\n```bash\n# Start LSP server\nbasedpyright-langserver --stdio\n\n# Used by editors for:\n# - Real-time type checking\n# - Auto-completion with type hints\n# - Go to definition\n# - Find references\n# - Rename symbols\n# - Quick fixes\n```\n\n## Basedpyright vs Pyright vs mypy\n\n### Feature Comparison\n\n| Feature | Basedpyright | Pyright | mypy |\n|---------|-------------|---------|------|\n| **Speed** | Fastest | Fastest | Slower |\n| **Strictness** | Strictest defaults | Configurable | Configurable |\n| **LSP Support** | Built-in | Built-in | Via dmypy |\n| **Type Inference** | Enhanced | Excellent | Good |\n| **Plugin System** | Limited | Limited | Extensive |\n| **Community** | Growing | Microsoft-backed | Large |\n| **Additional Rules** | Yes (stricter) | Standard | Via plugins |\n\n### When to Choose Basedpyright\n\n**Choose Basedpyright when:**\n- You want maximum type safety with stricter defaults\n- You need the fastest type checker available\n- You're starting a new project with strict typing requirements\n- You want additional strictness rules beyond standard Pyright\n- You prefer opinionated defaults over extensive configuration\n- You need LSP integration with enhanced diagnostics\n\n**Choose Pyright when:**\n- You need Microsoft's official support and stability\n- You want standard type checking without extra strictness\n- Your team prefers industry-standard tooling\n- You need compatibility with VS Code Pylance\n\n**Choose mypy when:**\n- You need extensive plugin ecosystem\n- You have legacy code with mypy configuration\n- You require specific mypy plugins (e.g., django-stubs, pydantic-mypy)\n- You need fine-grained control over type checking behavior\n- Your team has mypy expertise\n\n### Migration from Pyright\n\n```toml\n# Existing pyproject.toml with [tool.pyright]\n[tool.pyright]\ntypeCheckingMode = \"strict\"\ninclude = [\"src\"]\n\n# Change to [tool.basedpyright] - same configuration\n[tool.basedpyright]\ntypeCheckingMode = \"strict\"\ninclude = [\"src\"]\n\n# Add basedpyright-specific rules\nreportUnusedCallResult = \"error\"\nreportImplicitStringConcatenation = \"error\"\n```\n\n### Migration from mypy\n\n```toml\n# From mypy.ini or [tool.mypy]\n[tool.mypy]\nstrict = true\nwarn_unused_ignores = true\nwarn_redundant_casts = true\n\n# To basedpyright\n[tool.basedpyright]\ntypeCheckingMode = \"strict\"\nreportUnnecessaryCast = \"warning\"\n# Note: Some mypy-specific options don't have direct equivalents\n```\n\n## Advanced Patterns\n\n### Multiple Execution Environments\n\n```toml\n[tool.basedpyright]\nexecutionEnvironments = [\n  # Main source code\n  { root = \"src\", pythonVersion = \"3.12\", extraPaths = [] },\n\n  # Tests with access to src\n  { root = \"tests\", pythonVersion = \"3.12\", extraPaths = [\"src\"] },\n\n  # Scripts with different requirements\n  { root = \"scripts\", pythonVersion = \"3.11\", extraPaths = [\"src\"] }\n]\n```\n\n### Custom Type Stubs\n\n```toml\n[tool.basedpyright]\nstubPath = \"typings\"  # Directory for custom .pyi files\n\n# Directory structure:\n# typings/\n#   third_party_lib/\n#     __init__.pyi\n#     module.pyi\n```\n\n### Ignore Specific Errors\n\n```python\n# Inline type ignore\nresult = unsafe_operation()  # type: ignore[reportUnknownVariableType]\n\n# File-level ignore\n# basedpyright: ignore[reportMissingImports]\n\n# Function-level ignore\ndef legacy_function():  # basedpyright: ignore\n    # No type checking in this function\n    pass\n```\n\n### Type Checking Specific Files Only\n\n```toml\n[tool.basedpyright]\n# Strict checking for new code only\ninclude = [\n  \"src/api/**/*.py\",\n  \"src/models/**/*.py\",\n  \"!src/legacy/**/*.py\"  # Exclude legacy code\n]\n```\n\n## CI Integration\n\n### GitHub Actions\n\n```yaml\nname: Type Check\n\non: [push, pull_request]\n\njobs:\n  type-check:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Install uv\n        uses: astral-sh/setup-uv@v2\n        with:\n          enable-cache: true\n\n      - name: Set up Python\n        run: uv python install 3.12\n\n      - name: Install dependencies\n        run: uv sync --all-extras --dev\n\n      - name: Run basedpyright\n        run: uv run basedpyright\n```\n\n### Pre-commit Hook\n\n```yaml\n# .pre-commit-config.yaml\nrepos:\n  - repo: https://github.com/DetachHead/basedpyright\n    rev: v1.18.3\n    hooks:\n      - id: basedpyright\n        additional_dependencies: []  # Add runtime dependencies if needed\n```\n\n### Make/Just Task\n\n```makefile\n# Makefile\n.PHONY: typecheck\ntypecheck:\n\tuv run basedpyright\n\n# With JSON output for CI parsing\n.PHONY: typecheck-ci\ntypecheck-ci:\n\tuv run basedpyright --outputjson > typecheck-results.json\n```\n\n## Best Practices\n\n### 1. Start Strict Early\n\n```toml\n# New projects: Start with strict mode\n[tool.basedpyright]\ntypeCheckingMode = \"strict\"\ninclude = [\"src\"]\n```\n\n### 2. Progressive Type Coverage\n\n```bash\n# Generate baseline of current issues\nbasedpyright --outputjson > baseline.json\n\n# Fix issues incrementally\n# Use reportUnknownMemberType = \"warning\" initially\n# Upgrade to \"error\" when resolved\n```\n\n### 3. Type Annotations First\n\n```python\n# Always provide type hints for public APIs\ndef process_data(\n    items: list[dict[str, Any]],\n    config: Config | None = None\n) -> ProcessedResult:\n    \"\"\"Process data with optional configuration.\"\"\"\n    ...\n\n# Use Protocol for structural typing\nfrom typing import Protocol\n\nclass Drawable(Protocol):\n    def draw(self) -> None: ...\n\ndef render(obj: Drawable) -> None:  # Accepts any type with draw()\n    obj.draw()\n```\n\n### 4. Leverage Type Narrowing\n\n```python\nfrom typing import assert_type\n\ndef process_optional(value: str | None) -> str:\n    if value is None:\n        return \"default\"\n\n    # Type narrowed to str\n    assert_type(value, str)  # Compile-time type assertion\n    return value.upper()\n```\n\n### 5. Use TypedDict for Structured Data\n\n```python\nfrom typing import TypedDict, NotRequired\n\nclass UserData(TypedDict):\n    id: int\n    name: str\n    email: str\n    age: NotRequired[int]  # Optional field\n\ndef create_user(data: UserData) -> User:\n    # Type-safe dictionary access\n    return User(\n        id=data[\"id\"],\n        name=data[\"name\"],\n        email=data[\"email\"],\n        age=data.get(\"age\")\n    )\n```\n\n### 6. Monitor Type Coverage\n\n```bash\n# Check type coverage percentage\nbasedpyright --verbose | grep \"completion\"\n\n# Goal: Aim for 95%+ type annotation coverage\n```\n\n## Common Issues and Solutions\n\n### Issue: Too Many False Positives\n\n```toml\n# Solution: Adjust diagnostic severity\n[tool.basedpyright]\nreportUnknownMemberType = \"warning\"  # Downgrade from error\nreportUnknownArgumentType = \"warning\"\n```\n\n### Issue: Third-Party Library Without Stubs\n\n```bash\n# Solution: Install type stubs\nuv add --dev types-requests types-pyyaml\n\n# Or create custom stubs in typings/\n```\n\n### Issue: Performance on Large Codebases\n\n```toml\n# Solution: Limit scope or use include patterns\n[tool.basedpyright]\ninclude = [\"src/core\", \"src/api\"]  # Check subset\nexclude = [\"src/legacy\", \"**/*_test.py\"]  # Skip tests initially\n```\n\n### Issue: Conflicts with Runtime Behavior\n\n```python\n# Solution: Use TYPE_CHECKING for type-only imports\nfrom typing import TYPE_CHECKING\n\nif TYPE_CHECKING:\n    from expensive_module import LargeType\n\ndef process(data: \"LargeType\") -> None:  # String annotation\n    # Runtime code doesn't import expensive_module\n    ...\n```\n\n## Resources\n\n- **Official Repository**: https://github.com/DetachHead/basedpyright\n- **Pyright Documentation**: https://microsoft.github.io/pyright/ (most rules apply)\n- **Type Hints PEPs**: PEP 484, 526, 544, 585, 604, 612, 613\n- **Python Type System**: https://typing.readthedocs.io/\n\n## Summary\n\nBasedpyright provides the fastest and strictest type checking experience for Python:\n- Install via `uv tool install basedpyright`\n- Configure in `pyproject.toml` with `[tool.basedpyright]`\n- Use `typeCheckingMode = \"strict\"` for maximum safety\n- Integrate with LSP for real-time feedback in editors\n- Choose over Pyright for stricter defaults and additional rules\n- Choose over mypy for speed and modern type inference\n- Monitor coverage and progressively improve type annotations"
              },
              {
                "name": "pytest-advanced",
                "description": "Advanced pytest patterns including fixtures, markers, plugins, and async testing.\nUse when implementing test infrastructure, organizing test suites, using pytest plugins,\nor setting up complex test scenarios with fixtures and parametrization.\nTriggered by: pytest, fixtures, parametrize, conftest, test organization, async testing.\n",
                "path": "python-plugin/skills/pytest-advanced/SKILL.md",
                "frontmatter": {
                  "created": "2025-12-16T00:00:00.000Z",
                  "modified": "2025-12-16T00:00:00.000Z",
                  "reviewed": "2025-12-16T00:00:00.000Z",
                  "name": "pytest-advanced",
                  "description": "Advanced pytest patterns including fixtures, markers, plugins, and async testing.\nUse when implementing test infrastructure, organizing test suites, using pytest plugins,\nor setting up complex test scenarios with fixtures and parametrization.\nTriggered by: pytest, fixtures, parametrize, conftest, test organization, async testing.\n"
                },
                "content": "# Advanced Pytest Patterns\n\nComprehensive guide to advanced pytest features for robust, maintainable test suites.\n\n## Installation\n\n```bash\n# Install pytest with common plugins\nuv add --dev pytest pytest-cov pytest-asyncio pytest-xdist pytest-mock\n\n# Core plugins explained:\n# pytest-cov: Code coverage reporting\n# pytest-asyncio: Async/await test support\n# pytest-xdist: Parallel test execution\n# pytest-mock: Enhanced mocking with fixtures\n```\n\n## Configuration\n\n### pyproject.toml Configuration\n\n```toml\n[tool.pytest.ini_options]\n# Test discovery\ntestpaths = [\"tests\"]\npython_files = [\"test_*.py\", \"*_test.py\"]\npython_classes = [\"Test*\"]\npython_functions = [\"test_*\"]\n\n# Output and reporting\naddopts = [\n    \"-v\",                      # Verbose output\n    \"--strict-markers\",        # Enforce marker registration\n    \"--strict-config\",         # Enforce valid configuration\n    \"--tb=short\",              # Shorter traceback format\n    \"--disable-warnings\",      # Hide warnings (or use -W for control)\n    \"-ra\",                     # Show summary of all test outcomes\n    \"--cov=src\",              # Coverage for src directory\n    \"--cov-report=html\",       # HTML coverage report\n    \"--cov-report=term-missing\", # Terminal report with missing lines\n    \"--cov-fail-under=80\",     # Fail if coverage below 80%\n]\n\n# Markers (custom test markers)\nmarkers = [\n    \"slow: marks tests as slow (deselect with '-m \\\"not slow\\\"')\",\n    \"integration: marks tests as integration tests\",\n    \"unit: marks tests as unit tests\",\n    \"smoke: marks tests as smoke tests for CI\",\n    \"requires_network: marks tests that need network access\",\n    \"requires_auth: marks tests that need authentication\",\n]\n\n# Asyncio configuration\nasyncio_mode = \"auto\"  # Automatically detect async tests\n\n# Timeouts (requires pytest-timeout)\ntimeout = 300  # Default timeout: 5 minutes\ntimeout_method = \"thread\"\n\n# Warnings\nfilterwarnings = [\n    \"error\",                    # Treat warnings as errors\n    \"ignore::DeprecationWarning\",  # Except deprecation warnings\n    \"ignore::PendingDeprecationWarning\",\n]\n\n# Coverage configuration\n[tool.coverage.run]\nbranch = true\nsource = [\"src\"]\nomit = [\n    \"*/tests/*\",\n    \"*/test_*.py\",\n    \"*/__pycache__/*\",\n    \"*/site-packages/*\",\n]\n\n[tool.coverage.report]\nexclude_lines = [\n    \"pragma: no cover\",\n    \"def __repr__\",\n    \"raise AssertionError\",\n    \"raise NotImplementedError\",\n    \"if __name__ == .__main__.:\",\n    \"if TYPE_CHECKING:\",\n    \"@abstractmethod\",\n]\nprecision = 2\nshow_missing = true\n\n[tool.coverage.html]\ndirectory = \"htmlcov\"\n```\n\n## Fixtures\n\n### Basic Fixtures\n\n```python\n# tests/conftest.py\nimport pytest\nfrom typing import Generator\nfrom myapp.database import Database\nfrom myapp.models import User\n\n@pytest.fixture\ndef db() -> Generator[Database, None, None]:\n    \"\"\"Provide a database connection for tests.\"\"\"\n    database = Database(\":memory:\")  # In-memory SQLite\n    database.create_tables()\n    yield database\n    database.close()\n\n@pytest.fixture\ndef sample_user() -> User:\n    \"\"\"Provide a sample user for tests.\"\"\"\n    return User(id=1, name=\"Test User\", email=\"test@example.com\")\n\n@pytest.fixture\ndef authenticated_client(client, sample_user):\n    \"\"\"Provide an authenticated HTTP client.\"\"\"\n    client.login(sample_user)\n    return client\n\n# Usage in tests\ndef test_user_creation(db: Database, sample_user: User):\n    db.save(sample_user)\n    assert db.get_user(sample_user.id) == sample_user\n```\n\n### Fixture Scopes\n\n```python\nimport pytest\nfrom typing import Generator\n\n# Scope: function (default) - runs for each test\n@pytest.fixture(scope=\"function\")\ndef fresh_data() -> dict[str, str]:\n    \"\"\"New data for each test.\"\"\"\n    return {\"key\": \"value\"}\n\n# Scope: class - runs once per test class\n@pytest.fixture(scope=\"class\")\ndef shared_resource() -> str:\n    \"\"\"Shared across all tests in a class.\"\"\"\n    return \"shared_value\"\n\n# Scope: module - runs once per test module\n@pytest.fixture(scope=\"module\")\ndef module_db() -> Generator[Database, None, None]:\n    \"\"\"Database shared across module.\"\"\"\n    db = Database(\"test.db\")\n    yield db\n    db.cleanup()\n\n# Scope: session - runs once per test session\n@pytest.fixture(scope=\"session\")\ndef global_config() -> dict[str, str]:\n    \"\"\"Configuration shared across all tests.\"\"\"\n    return load_config(\"test_config.yaml\")\n\n# Scope comparison\n# function: Each test gets fresh fixture\n# class: Tests in same class share fixture\n# module: Tests in same file share fixture\n# session: All tests share fixture\n```\n\n### Autouse Fixtures\n\n```python\nimport pytest\nfrom unittest.mock import patch\n\n# Automatically applied to all tests\n@pytest.fixture(autouse=True)\ndef reset_state():\n    \"\"\"Reset global state before each test.\"\"\"\n    clear_cache()\n    reset_config()\n    yield\n    # Cleanup after test\n\n# Module-level autouse\n@pytest.fixture(scope=\"module\", autouse=True)\ndef setup_test_environment():\n    \"\"\"Set up environment for entire module.\"\"\"\n    os.environ[\"ENV\"] = \"test\"\n    yield\n    del os.environ[\"ENV\"]\n\n# Mock external services automatically\n@pytest.fixture(autouse=True)\ndef mock_external_api():\n    \"\"\"Mock external API for all tests.\"\"\"\n    with patch(\"myapp.external.api_call\") as mock:\n        mock.return_value = {\"status\": \"ok\"}\n        yield mock\n```\n\n### Parametrized Fixtures\n\n```python\nimport pytest\n\n# Parametrized fixture\n@pytest.fixture(params=[\"sqlite\", \"postgres\", \"mysql\"])\ndef database_backend(request) -> str:\n    \"\"\"Test with multiple database backends.\"\"\"\n    return request.param\n\ndef test_query_execution(database_backend: str):\n    \"\"\"This test runs 3 times, once per backend.\"\"\"\n    db = Database(backend=database_backend)\n    result = db.query(\"SELECT 1\")\n    assert result == 1\n\n# Complex parametrization\n@pytest.fixture(params=[\n    pytest.param(\"fast\", marks=pytest.mark.unit),\n    pytest.param(\"slow\", marks=pytest.mark.slow),\n])\ndef execution_mode(request) -> str:\n    return request.param\n\n# Indirect parametrization\n@pytest.fixture\ndef user(request) -> User:\n    \"\"\"Create user with parametrized attributes.\"\"\"\n    return User(**request.param)\n\n@pytest.mark.parametrize(\"user\", [\n    {\"name\": \"Alice\", \"age\": 30},\n    {\"name\": \"Bob\", \"age\": 25},\n], indirect=True)\ndef test_user_validation(user: User):\n    assert user.name in [\"Alice\", \"Bob\"]\n```\n\n### Factory Fixtures\n\n```python\nimport pytest\nfrom typing import Callable\n\n@pytest.fixture\ndef user_factory() -> Callable[[str], User]:\n    \"\"\"Factory to create users on demand.\"\"\"\n    created_users: list[User] = []\n\n    def _create_user(name: str, **kwargs) -> User:\n        user = User(name=name, **kwargs)\n        created_users.append(user)\n        return user\n\n    yield _create_user\n\n    # Cleanup all created users\n    for user in created_users:\n        user.delete()\n\ndef test_multiple_users(user_factory):\n    \"\"\"Create multiple users in one test.\"\"\"\n    alice = user_factory(\"Alice\", age=30)\n    bob = user_factory(\"Bob\", age=25)\n    assert alice.name != bob.name\n```\n\n## Markers\n\n### Built-in Markers\n\n```python\nimport pytest\n\n# Skip test unconditionally\n@pytest.mark.skip(reason=\"Feature not implemented yet\")\ndef test_future_feature():\n    pass\n\n# Skip test conditionally\n@pytest.mark.skipif(sys.version_info < (3, 12), reason=\"Requires Python 3.12+\")\ndef test_new_syntax():\n    match value:\n        case pattern:\n            pass\n\n# Expected failure (test runs but failure is acceptable)\n@pytest.mark.xfail(reason=\"Known bug #123\")\ndef test_buggy_feature():\n    assert broken_function() == expected\n\n# Expected failure with strict mode\n@pytest.mark.xfail(strict=True, reason=\"Must fail or test fails\")\ndef test_must_fail():\n    assert False  # If this passes, test fails\n\n# Parametrize test with multiple inputs\n@pytest.mark.parametrize(\"input,expected\", [\n    (2, 4),\n    (3, 9),\n    (4, 16),\n])\ndef test_square(input: int, expected: int):\n    assert input ** 2 == expected\n\n# Parametrize with ids for readable output\n@pytest.mark.parametrize(\"value,expected\", [\n    pytest.param(0, False, id=\"zero\"),\n    pytest.param(1, True, id=\"one\"),\n    pytest.param(-1, True, id=\"negative\"),\n])\ndef test_truthiness(value: int, expected: bool):\n    assert bool(value) == expected\n```\n\n### Custom Markers\n\n```python\n# tests/conftest.py\nimport pytest\n\ndef pytest_configure(config):\n    \"\"\"Register custom markers.\"\"\"\n    config.addinivalue_line(\n        \"markers\", \"slow: marks tests as slow (deselect with '-m \\\"not slow\\\"')\"\n    )\n    config.addinivalue_line(\n        \"markers\", \"integration: marks tests as integration tests\"\n    )\n    config.addinivalue_line(\n        \"markers\", \"requires_network: marks tests that need network access\"\n    )\n\n# Usage in tests\n@pytest.mark.slow\ndef test_large_computation():\n    \"\"\"This test takes a long time.\"\"\"\n    result = compute_for_hours()\n    assert result is not None\n\n@pytest.mark.integration\ndef test_database_integration(db):\n    \"\"\"Test database integration.\"\"\"\n    db.save_data({\"key\": \"value\"})\n    assert db.load_data()[\"key\"] == \"value\"\n\n@pytest.mark.requires_network\ndef test_api_call():\n    \"\"\"Test external API call.\"\"\"\n    response = requests.get(\"https://api.example.com\")\n    assert response.status_code == 200\n\n# Combine multiple markers\n@pytest.mark.slow\n@pytest.mark.integration\n@pytest.mark.requires_network\ndef test_full_integration():\n    \"\"\"Slow integration test requiring network.\"\"\"\n    pass\n```\n\n### Running Tests by Marker\n\n```bash\n# Run only unit tests\npytest -m unit\n\n# Run all except slow tests\npytest -m \"not slow\"\n\n# Run integration or slow tests\npytest -m \"integration or slow\"\n\n# Run integration but not slow tests\npytest -m \"integration and not slow\"\n\n# Run specific markers with verbose output\npytest -v -m \"unit and not requires_network\"\n```\n\n## Plugins\n\n### pytest-cov (Coverage)\n\n```bash\n# Install\nuv add --dev pytest-cov\n\n# Usage\npytest --cov=src --cov-report=html --cov-report=term-missing\n\n# Configuration in pyproject.toml\n[tool.pytest.ini_options]\naddopts = [\"--cov=src\", \"--cov-report=html\", \"--cov-fail-under=80\"]\n\n[tool.coverage.run]\nbranch = true\nsource = [\"src\"]\n\n[tool.coverage.report]\nexclude_lines = [\"pragma: no cover\", \"if TYPE_CHECKING:\"]\n```\n\n### pytest-asyncio (Async Testing)\n\n```bash\n# Install\nuv add --dev pytest-asyncio\n\n# Configuration\n[tool.pytest.ini_options]\nasyncio_mode = \"auto\"  # Automatically detect async tests\n```\n\n```python\nimport pytest\n\n# Async test\n@pytest.mark.asyncio\nasync def test_async_function():\n    result = await async_operation()\n    assert result == expected\n\n# Async fixture\n@pytest.fixture\nasync def async_client():\n    client = await create_async_client()\n    yield client\n    await client.close()\n\n@pytest.mark.asyncio\nasync def test_with_async_fixture(async_client):\n    response = await async_client.get(\"/api/data\")\n    assert response.status == 200\n```\n\n### pytest-xdist (Parallel Execution)\n\n```bash\n# Install\nuv add --dev pytest-xdist\n\n# Run tests in parallel\npytest -n auto  # Use all available CPUs\npytest -n 4     # Use 4 workers\n\n# Distribute tests across workers\npytest --dist loadfile  # Distribute by file\npytest --dist loadscope # Distribute by scope (module, class)\n```\n\n### pytest-mock (Enhanced Mocking)\n\n```bash\n# Install\nuv add --dev pytest-mock\n\n# Provides 'mocker' fixture\n```\n\n```python\ndef test_with_mock(mocker):\n    \"\"\"Use mocker fixture for easy mocking.\"\"\"\n    # Mock a function\n    mock_api = mocker.patch(\"myapp.external.api_call\")\n    mock_api.return_value = {\"data\": \"test\"}\n\n    # Mock a method\n    mocker.patch.object(MyClass, \"method\", return_value=42)\n\n    # Spy on a function (real function runs, but calls are recorded)\n    spy = mocker.spy(myapp.utils, \"helper_function\")\n\n    result = my_function()\n\n    assert result == expected\n    spy.assert_called_once_with(\"expected_arg\")\n```\n\n### pytest-timeout\n\n```bash\n# Install\nuv add --dev pytest-timeout\n\n# Configuration\n[tool.pytest.ini_options]\ntimeout = 300  # Default timeout: 5 minutes\ntimeout_method = \"thread\"\n```\n\n```python\n# Per-test timeout\n@pytest.mark.timeout(10)\ndef test_fast_function():\n    \"\"\"Must complete in 10 seconds.\"\"\"\n    pass\n\n# Disable timeout for specific test\n@pytest.mark.timeout(0)\ndef test_no_timeout():\n    \"\"\"Runs without timeout.\"\"\"\n    pass\n```\n\n### pytest-benchmark\n\n```bash\n# Install\nuv add --dev pytest-benchmark\n\n# Usage\ndef test_performance(benchmark):\n    result = benchmark(function_to_test, arg1, arg2)\n    assert result == expected\n\n# Compare benchmarks\npytest --benchmark-compare=0001  # Compare to baseline\npytest --benchmark-save=baseline  # Save as baseline\n```\n\n## conftest.py Patterns\n\n### Project Structure\n\n```\ntests/\n conftest.py              # Root conftest (session-level fixtures)\n unit/\n    conftest.py          # Unit test fixtures\n    test_models.py\n    test_utils.py\n integration/\n    conftest.py          # Integration test fixtures\n    test_api.py\n    test_database.py\n e2e/\n     conftest.py          # E2E test fixtures\n     test_workflows.py\n```\n\n### Root conftest.py\n\n```python\n# tests/conftest.py\nimport pytest\nfrom typing import Generator\nfrom myapp import create_app\nfrom myapp.database import Database\n\n# Session-level fixtures\n@pytest.fixture(scope=\"session\")\ndef app():\n    \"\"\"Create application for testing.\"\"\"\n    app = create_app(\"testing\")\n    return app\n\n@pytest.fixture(scope=\"session\")\ndef db_engine():\n    \"\"\"Create database engine for testing.\"\"\"\n    engine = create_test_engine()\n    yield engine\n    engine.dispose()\n\n# Hooks for pytest behavior customization\ndef pytest_configure(config):\n    \"\"\"Register custom markers.\"\"\"\n    config.addinivalue_line(\"markers\", \"slow: slow tests\")\n    config.addinivalue_line(\"markers\", \"integration: integration tests\")\n\ndef pytest_collection_modifyitems(config, items):\n    \"\"\"Automatically mark tests based on path.\"\"\"\n    for item in items:\n        if \"integration\" in item.nodeid:\n            item.add_marker(pytest.mark.integration)\n        if \"slow\" in item.nodeid:\n            item.add_marker(pytest.mark.slow)\n\n# Fixtures available to all tests\n@pytest.fixture(autouse=True)\ndef reset_database(db_engine):\n    \"\"\"Reset database before each test.\"\"\"\n    clear_tables(db_engine)\n    yield\n    rollback_transaction(db_engine)\n```\n\n### Domain-Specific conftest.py\n\n```python\n# tests/integration/conftest.py\nimport pytest\nfrom myapp.client import Client\n\n@pytest.fixture\ndef authenticated_client(app) -> Client:\n    \"\"\"HTTP client with authentication.\"\"\"\n    client = app.test_client()\n    client.login(\"test@example.com\", \"password\")\n    return client\n\n@pytest.fixture\ndef sample_data(db):\n    \"\"\"Load sample data for integration tests.\"\"\"\n    db.load_fixtures(\"integration_data.json\")\n    yield\n    db.clear_fixtures()\n\n# tests/e2e/conftest.py\n@pytest.fixture(scope=\"module\")\ndef browser():\n    \"\"\"Selenium browser for E2E tests.\"\"\"\n    from selenium import webdriver\n    driver = webdriver.Chrome()\n    yield driver\n    driver.quit()\n```\n\n## Async Testing Patterns\n\n### Basic Async Tests\n\n```python\nimport pytest\nimport asyncio\n\n@pytest.mark.asyncio\nasync def test_async_function():\n    \"\"\"Simple async test.\"\"\"\n    result = await fetch_data()\n    assert result is not None\n\n@pytest.mark.asyncio\nasync def test_concurrent_operations():\n    \"\"\"Test concurrent async operations.\"\"\"\n    results = await asyncio.gather(\n        fetch_user(1),\n        fetch_user(2),\n        fetch_user(3)\n    )\n    assert len(results) == 3\n```\n\n### Async Fixtures\n\n```python\nimport pytest\nfrom typing import AsyncGenerator\n\n@pytest.fixture\nasync def async_client() -> AsyncGenerator[AsyncClient, None]:\n    \"\"\"Async HTTP client fixture.\"\"\"\n    async with AsyncClient() as client:\n        yield client\n\n@pytest.fixture(scope=\"module\")\nasync def async_db() -> AsyncGenerator[AsyncDatabase, None]:\n    \"\"\"Async database connection.\"\"\"\n    db = AsyncDatabase(\"test.db\")\n    await db.connect()\n    yield db\n    await db.close()\n\n@pytest.mark.asyncio\nasync def test_with_async_fixtures(async_client, async_db):\n    \"\"\"Use multiple async fixtures.\"\"\"\n    await async_db.save({\"key\": \"value\"})\n    response = await async_client.get(\"/api/data\")\n    assert response.status_code == 200\n```\n\n### Event Loop Management\n\n```python\nimport pytest\nimport asyncio\n\n# Custom event loop for testing\n@pytest.fixture(scope=\"session\")\ndef event_loop():\n    \"\"\"Create event loop for entire test session.\"\"\"\n    policy = asyncio.get_event_loop_policy()\n    loop = policy.new_event_loop()\n    yield loop\n    loop.close()\n\n# Async fixture with explicit event loop\n@pytest.fixture\nasync def async_resource(event_loop):\n    \"\"\"Resource requiring specific event loop.\"\"\"\n    resource = await create_resource()\n    yield resource\n    await resource.cleanup()\n```\n\n### Testing Async Context Managers\n\n```python\n@pytest.mark.asyncio\nasync def test_async_context_manager():\n    \"\"\"Test async context manager.\"\"\"\n    async with AsyncResource() as resource:\n        result = await resource.process()\n        assert result is not None\n\n    # Verify cleanup happened\n    assert resource.is_closed()\n```\n\n### Testing Async Generators\n\n```python\n@pytest.mark.asyncio\nasync def test_async_generator():\n    \"\"\"Test async generator.\"\"\"\n    results = []\n    async for item in async_generator():\n        results.append(item)\n\n    assert len(results) == expected_count\n    assert all(isinstance(item, ExpectedType) for item in results)\n```\n\n## Test Organization Best Practices\n\n### 1. Test Structure (AAA Pattern)\n\n```python\ndef test_user_creation():\n    \"\"\"Test user creation with valid data.\"\"\"\n    # Arrange: Set up test data\n    user_data = {\"name\": \"Alice\", \"email\": \"alice@example.com\"}\n\n    # Act: Perform the action\n    user = create_user(user_data)\n\n    # Assert: Verify the outcome\n    assert user.name == \"Alice\"\n    assert user.email == \"alice@example.com\"\n    assert user.id is not None\n```\n\n### 2. Test Naming Conventions\n\n```python\n# Pattern: test_<function>_<scenario>_<expected_result>\n\ndef test_divide_by_zero_raises_error():\n    \"\"\"Division by zero raises ZeroDivisionError.\"\"\"\n    with pytest.raises(ZeroDivisionError):\n        divide(10, 0)\n\ndef test_user_login_with_valid_credentials_succeeds():\n    \"\"\"User login succeeds with valid credentials.\"\"\"\n    result = login(\"user@example.com\", \"correct_password\")\n    assert result.success is True\n\ndef test_api_call_with_invalid_token_returns_401():\n    \"\"\"API call with invalid token returns 401 Unauthorized.\"\"\"\n    response = api_call(token=\"invalid\")\n    assert response.status_code == 401\n```\n\n### 3. Test Grouping with Classes\n\n```python\nclass TestUserAuthentication:\n    \"\"\"Group related authentication tests.\"\"\"\n\n    def test_login_success(self, user):\n        \"\"\"Successful login.\"\"\"\n        assert login(user.email, user.password).success\n\n    def test_login_wrong_password(self, user):\n        \"\"\"Login fails with wrong password.\"\"\"\n        assert not login(user.email, \"wrong\").success\n\n    def test_logout(self, authenticated_user):\n        \"\"\"Logout clears session.\"\"\"\n        logout(authenticated_user)\n        assert not is_authenticated(authenticated_user)\n\nclass TestUserRegistration:\n    \"\"\"Group registration tests.\"\"\"\n\n    def test_register_new_user(self):\n        \"\"\"Register new user successfully.\"\"\"\n        pass\n\n    def test_register_duplicate_email(self, existing_user):\n        \"\"\"Registration fails with duplicate email.\"\"\"\n        pass\n```\n\n### 4. Parametrization for Data-Driven Tests\n\n```python\n@pytest.mark.parametrize(\"input,expected\", [\n    pytest.param(0, 0, id=\"zero\"),\n    pytest.param(1, 1, id=\"one\"),\n    pytest.param(2, 4, id=\"two\"),\n    pytest.param(3, 9, id=\"three\"),\n    pytest.param(-2, 4, id=\"negative\"),\n])\ndef test_square(input: int, expected: int):\n    \"\"\"Test square function with various inputs.\"\"\"\n    assert square(input) == expected\n\n# Complex parametrization\n@pytest.mark.parametrize(\"user_data,should_succeed\", [\n    ({\"name\": \"Alice\", \"email\": \"alice@example.com\"}, True),\n    ({\"name\": \"\", \"email\": \"alice@example.com\"}, False),\n    ({\"name\": \"Bob\", \"email\": \"invalid\"}, False),\n    ({\"name\": \"Charlie\"}, False),  # Missing email\n])\ndef test_user_validation(user_data: dict, should_succeed: bool):\n    \"\"\"Test user validation with various inputs.\"\"\"\n    if should_succeed:\n        user = create_user(user_data)\n        assert user is not None\n    else:\n        with pytest.raises(ValidationError):\n            create_user(user_data)\n```\n\n### 5. Test Data Management\n\n```python\n# tests/fixtures/users.json\n{\n  \"users\": [\n    {\"id\": 1, \"name\": \"Alice\", \"email\": \"alice@example.com\"},\n    {\"id\": 2, \"name\": \"Bob\", \"email\": \"bob@example.com\"}\n  ]\n}\n\n# tests/conftest.py\nimport json\nimport pytest\n\n@pytest.fixture\ndef users_data():\n    \"\"\"Load user test data from JSON.\"\"\"\n    with open(\"tests/fixtures/users.json\") as f:\n        return json.load(f)[\"users\"]\n\n@pytest.fixture\ndef sample_users(db, users_data):\n    \"\"\"Create sample users in database.\"\"\"\n    users = [db.create_user(data) for data in users_data]\n    yield users\n    for user in users:\n        db.delete_user(user.id)\n```\n\n## Common Patterns\n\n### Testing Exceptions\n\n```python\nimport pytest\n\n# Assert exception is raised\ndef test_divide_by_zero():\n    with pytest.raises(ZeroDivisionError):\n        divide(10, 0)\n\n# Assert exception message\ndef test_invalid_input():\n    with pytest.raises(ValueError, match=\"must be positive\"):\n        process(-1)\n\n# Capture exception for inspection\ndef test_custom_exception():\n    with pytest.raises(CustomError) as exc_info:\n        trigger_error()\n\n    assert exc_info.value.code == 42\n    assert \"details\" in exc_info.value.message\n```\n\n### Testing Warnings\n\n```python\nimport warnings\nimport pytest\n\ndef test_deprecated_function():\n    \"\"\"Test that deprecated function raises warning.\"\"\"\n    with pytest.warns(DeprecationWarning, match=\"deprecated\"):\n        deprecated_function()\n\ndef test_no_warnings():\n    \"\"\"Test that no warnings are raised.\"\"\"\n    with warnings.catch_warnings():\n        warnings.simplefilter(\"error\")\n        safe_function()  # Raises if any warning\n```\n\n### Mocking and Patching\n\n```python\nfrom unittest.mock import patch, Mock, MagicMock\n\ndef test_external_api_call(mocker):\n    \"\"\"Mock external API call.\"\"\"\n    # Mock function\n    mock_response = Mock()\n    mock_response.json.return_value = {\"data\": \"test\"}\n    mocker.patch(\"requests.get\", return_value=mock_response)\n\n    result = fetch_data_from_api()\n    assert result[\"data\"] == \"test\"\n\ndef test_database_interaction(mocker):\n    \"\"\"Mock database calls.\"\"\"\n    mock_db = mocker.patch(\"myapp.database.Database\")\n    mock_db.return_value.query.return_value = [{\"id\": 1}]\n\n    result = get_users()\n    assert len(result) == 1\n    mock_db.return_value.query.assert_called_once()\n```\n\n### Temporary Files and Directories\n\n```python\nimport pytest\nfrom pathlib import Path\n\ndef test_file_processing(tmp_path: Path):\n    \"\"\"Test with temporary directory.\"\"\"\n    # tmp_path is a Path object to a temporary directory\n    test_file = tmp_path / \"test.txt\"\n    test_file.write_text(\"test content\")\n\n    result = process_file(test_file)\n    assert result.success\n\ndef test_config_file(tmp_path: Path):\n    \"\"\"Test with temporary config file.\"\"\"\n    config_file = tmp_path / \"config.yaml\"\n    config_file.write_text(\"setting: value\")\n\n    app = create_app(config_file)\n    assert app.config[\"setting\"] == \"value\"\n```\n\n## Running Tests\n\n```bash\n# Basic test execution\npytest                          # Run all tests\npytest tests/unit/             # Run specific directory\npytest tests/test_models.py    # Run specific file\npytest tests/test_models.py::test_user_creation  # Run specific test\n\n# Verbosity and output\npytest -v                      # Verbose output\npytest -vv                     # Extra verbose\npytest -q                      # Quiet output\npytest --tb=short              # Short traceback\npytest --tb=no                 # No traceback\npytest -ra                     # Show summary of all outcomes\n\n# Test selection\npytest -k \"user\"               # Run tests matching \"user\"\npytest -k \"not slow\"           # Skip tests matching \"slow\"\npytest -m unit                 # Run tests with \"unit\" marker\npytest -m \"not integration\"    # Skip integration tests\n\n# Parallel execution\npytest -n auto                 # Use all CPUs\npytest -n 4                    # Use 4 workers\n\n# Coverage\npytest --cov=src --cov-report=html --cov-report=term-missing\n\n# Failed tests\npytest --lf                    # Run last failed tests\npytest --ff                    # Run failed first, then others\npytest --sw                    # Stop on first failure\npytest --maxfail=3             # Stop after 3 failures\n\n# Debugging\npytest --pdb                   # Drop into debugger on failure\npytest -x --pdb                # Stop on first failure and debug\npytest --trace                 # Drop into debugger at start of each test\n\n# Output capture\npytest -s                      # Disable output capture (show print statements)\npytest --capture=no            # Same as -s\n\n# Test collection\npytest --collect-only          # Show what tests would run (don't execute)\npytest --markers               # Show available markers\npytest --fixtures              # Show available fixtures\n```\n\n## CI Integration\n\n```yaml\n# .github/workflows/test.yml\nname: Tests\n\non: [push, pull_request]\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n    strategy:\n      matrix:\n        python-version: [\"3.11\", \"3.12\"]\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Install uv\n        uses: astral-sh/setup-uv@v2\n        with:\n          enable-cache: true\n\n      - name: Set up Python ${{ matrix.python-version }}\n        run: uv python install ${{ matrix.python-version }}\n\n      - name: Install dependencies\n        run: uv sync --all-extras --dev\n\n      - name: Run tests with coverage\n        run: |\n          uv run pytest \\\n            --cov=src \\\n            --cov-report=xml \\\n            --cov-report=term-missing \\\n            --junitxml=test-results.xml\n\n      - name: Upload coverage to Codecov\n        uses: codecov/codecov-action@v4\n        with:\n          file: ./coverage.xml\n          fail_ci_if_error: true\n\n      - name: Upload test results\n        uses: actions/upload-artifact@v4\n        if: always()\n        with:\n          name: test-results-${{ matrix.python-version }}\n          path: test-results.xml\n```\n\n## Resources\n\n- **pytest documentation**: https://docs.pytest.org/\n- **pytest-asyncio**: https://pytest-asyncio.readthedocs.io/\n- **pytest-cov**: https://pytest-cov.readthedocs.io/\n- **pytest-xdist**: https://pytest-xdist.readthedocs.io/\n- **pytest plugins**: https://docs.pytest.org/en/latest/reference/plugin_list.html\n\n## Summary\n\nAdvanced pytest provides:\n- **Fixtures**: Reusable test dependencies with flexible scoping\n- **Markers**: Test categorization and conditional execution\n- **Plugins**: Extended functionality (coverage, async, parallel, mocking)\n- **conftest.py**: Centralized fixture and configuration management\n- **Async support**: First-class async/await testing with pytest-asyncio\n- **Parametrization**: Data-driven testing with readable output\n- **Parallel execution**: Fast test runs with pytest-xdist\n- **Coverage reporting**: Track test coverage with pytest-cov"
              },
              {
                "name": "python-code-quality",
                "description": "Python code quality with ruff (linting & formatting) and mypy (type checking).\nCovers pyproject.toml configuration, pre-commit hooks, and type hints.\nUse when user mentions ruff, mypy, linting, formatting, type checking,\ncode style, or Python code quality.\n",
                "path": "python-plugin/skills/python-code-quality/SKILL.md",
                "frontmatter": {
                  "created": "2025-12-16T00:00:00.000Z",
                  "modified": "2025-12-16T00:00:00.000Z",
                  "reviewed": "2025-12-16T00:00:00.000Z",
                  "name": "python-code-quality",
                  "description": "Python code quality with ruff (linting & formatting) and mypy (type checking).\nCovers pyproject.toml configuration, pre-commit hooks, and type hints.\nUse when user mentions ruff, mypy, linting, formatting, type checking,\ncode style, or Python code quality.\n"
                },
                "content": "# Python Code Quality\n\nQuick reference for Python code quality tools: ruff (linting & formatting), mypy (type checking).\n\n## When This Skill Applies\n\n- Linting Python code\n- Code formatting\n- Type checking\n- Pre-commit hooks\n- CI/CD quality gates\n- Code style enforcement\n\n## Quick Reference\n\n### Ruff (Linter & Formatter)\n\n```bash\n# Lint code\nuv run ruff check .\n\n# Auto-fix issues\nuv run ruff check --fix .\n\n# Format code\nuv run ruff format .\n\n# Check and format\nuv run ruff check --fix . && uv run ruff format .\n\n# Show specific rule\nuv run ruff check --select E501  # Line too long\n\n# Ignore specific rule\nuv run ruff check --ignore E501\n```\n\n### Mypy (Type Checking)\n\n```bash\n# Type check project\nuv run mypy .\n\n# Type check specific file\nuv run mypy src/module.py\n\n# Strict mode\nuv run mypy --strict .\n\n# Show error codes\nuv run mypy --show-error-codes .\n```\n\n## pyproject.toml Configuration\n\n```toml\n[tool.ruff]\nline-length = 88\ntarget-version = \"py311\"\n\n[tool.ruff.lint]\nselect = [\n    \"E\",   # pycodestyle errors\n    \"W\",   # pycodestyle warnings\n    \"F\",   # pyflakes\n    \"I\",   # isort\n    \"N\",   # pep8-naming\n    \"UP\",  # pyupgrade\n    \"B\",   # flake8-bugbear\n]\nignore = [\n    \"E501\",  # line too long (handled by formatter)\n]\n\n[tool.ruff.lint.isort]\nknown-first-party = [\"myproject\"]\n\n[tool.mypy]\npython_version = \"3.11\"\nwarn_return_any = true\nwarn_unused_configs = true\ndisallow_untyped_defs = true\nexclude = [\"tests\"]\n```\n\n## Type Hints\n\n```python\n# Modern type hints (Python 3.10+)\ndef process_data(\n    items: list[str],                    # Not List[str]\n    config: dict[str, int],              # Not Dict[str, int]\n    optional: str | None = None,         # Not Optional[str]\n) -> tuple[bool, str]:                   # Not Tuple[bool, str]\n    return True, \"success\"\n\n# Type aliases\nfrom typing import TypeAlias\n\nUserId: TypeAlias = int\nUserDict: TypeAlias = dict[str, str | int]\n\ndef get_user(user_id: UserId) -> UserDict:\n    return {\"id\": user_id, \"name\": \"Alice\"}\n```\n\n## Pre-commit Configuration\n\n```yaml\n# .pre-commit-config.yaml\nrepos:\n  - repo: https://github.com/astral-sh/ruff-pre-commit\n    rev: v0.1.9\n    hooks:\n      - id: ruff\n        args: [--fix]\n      - id: ruff-format\n\n  - repo: https://github.com/pre-commit/mirrors-mypy\n    rev: v1.7.1\n    hooks:\n      - id: mypy\n        additional_dependencies: [types-requests]\n```\n\n## Common Ruff Rules\n\n- **E501**: Line too long\n- **F401**: Unused import\n- **F841**: Unused variable\n- **I001**: Import not sorted\n- **N806**: Variable should be lowercase\n- **B008**: Function call in argument defaults\n\n## See Also\n\n- `python-testing` - Testing code quality\n- `uv-project-management` - Adding quality tools to projects\n- `python-development` - Core Python patterns\n\n## References\n\n- Ruff: https://docs.astral.sh/ruff/\n- Mypy: https://mypy.readthedocs.io/\n- Detailed guide: See REFERENCE.md"
              },
              {
                "name": "python-development",
                "description": "Core Python development concepts, idioms, best practices, and language features.\nCovers Python 3.10+ features, type hints, async/await, and Pythonic patterns.\nFor running scripts, see uv-run. For project setup, see uv-project-management.\nUse when user mentions Python, type hints, async Python, decorators, context managers,\nor writing Pythonic code.\n",
                "path": "python-plugin/skills/python-development/SKILL.md",
                "frontmatter": {
                  "created": "2025-12-16T00:00:00.000Z",
                  "modified": "2025-12-16T00:00:00.000Z",
                  "reviewed": "2025-12-16T00:00:00.000Z",
                  "name": "python-development",
                  "description": "Core Python development concepts, idioms, best practices, and language features.\nCovers Python 3.10+ features, type hints, async/await, and Pythonic patterns.\nFor running scripts, see uv-run. For project setup, see uv-project-management.\nUse when user mentions Python, type hints, async Python, decorators, context managers,\nor writing Pythonic code.\n",
                  "allowed-tools": "Glob, Grep, Read, WebFetch, TodoWrite, WebSearch, BashOutput, KillShell, Edit, Write, NotebookEdit, Bash"
                },
                "content": "# Python Development\n\nCore Python language concepts, idioms, and best practices.\n\n## Core Expertise\n\n- **Python Language**: Modern Python 3.10+ features and idioms\n- **Best Practices**: Pythonic code, design patterns, SOLID principles\n- **Debugging**: Interactive debugging and profiling techniques\n- **Performance**: Optimization strategies and profiling\n- **Async Programming**: async/await patterns and asyncio\n\n## Modern Python Features (3.10+)\n\n### Type Hints\n\n```python\n# Modern syntax (Python 3.10+)\ndef process_items(\n    items: list[str],                    # Not List[str]\n    mapping: dict[str, int],             # Not Dict[str, int]\n    optional: str | None = None,         # Not Optional[str]\n) -> tuple[bool, str]:                   # Not Tuple[bool, str]\n    \"\"\"Process items with modern type hints.\"\"\"\n    return True, \"success\"\n\n# Type aliases\ntype UserId = int\ntype UserDict = dict[str, str | int]\n\ndef get_user(user_id: UserId) -> UserDict:\n    return {\"id\": user_id, \"name\": \"Alice\"}\n```\n\n### Pattern Matching (3.10+)\n\n```python\ndef handle_command(command: dict) -> str:\n    match command:\n        case {\"action\": \"create\", \"item\": item}:\n            return f\"Creating {item}\"\n        case {\"action\": \"delete\", \"item\": item}:\n            return f\"Deleting {item}\"\n        case {\"action\": \"list\"}:\n            return \"Listing items\"\n        case _:\n            return \"Unknown command\"\n```\n\n### Structural Pattern Matching\n\n```python\ndef process_response(response):\n    match response:\n        case {\"status\": 200, \"data\": data}:\n            return process_success(data)\n        case {\"status\": 404}:\n            raise NotFoundError()\n        case {\"status\": code} if code >= 500:\n            raise ServerError(code)\n```\n\n## Python Idioms\n\n### Context Managers\n\n```python\n# File handling\nwith open(\"file.txt\") as f:\n    content = f.read()\n\n# Custom context manager\nfrom contextlib import contextmanager\n\n@contextmanager\ndef database_connection():\n    conn = create_connection()\n    try:\n        yield conn\n    finally:\n        conn.close()\n\nwith database_connection() as conn:\n    conn.execute(\"SELECT * FROM users\")\n```\n\n### List Comprehensions\n\n```python\n# List comprehension\nsquares = [x**2 for x in range(10)]\n\n# Dict comprehension\nword_lengths = {word: len(word) for word in [\"hello\", \"world\"]}\n\n# Set comprehension\nunique_lengths = {len(word) for word in [\"hello\", \"world\", \"hi\"]}\n\n# Generator expression\nsum_of_squares = sum(x**2 for x in range(1000000))  # Memory efficient\n```\n\n### Iterators and Generators\n\n```python\ndef fibonacci():\n    a, b = 0, 1\n    while True:\n        yield a\n        a, b = b, a + b\n\n# Use generator\nfib = fibonacci()\nfirst_ten = [next(fib) for _ in range(10)]\n\n# Generator expression\neven_squares = (x**2 for x in range(10) if x % 2 == 0)\n```\n\n## Debugging\n\n### Interactive Debugging\n\n```python\nimport pdb\n\ndef problematic_function():\n    value = calculate()\n    pdb.set_trace()  # Debugger breakpoint\n    return process(value)\n```\n\n```bash\n# Debug on error\npython -m pdb script.py\n\n# pytest with debugger\nuv run pytest --pdb                     # Drop into pdb on failure\nuv run pytest --pdb --pdbcls=IPython.terminal.debugger:TerminalPdb\n```\n\n### Performance Profiling\n\n```bash\n# CPU profiling\nuv run python -m cProfile -s cumtime script.py | head -20\n\n# Line-by-line profiling (temporary dependency)\nuv run --with line-profiler kernprof -l -v script.py\n\n# Memory profiling (temporary dependency)\nuv run --with memory-profiler python -m memory_profiler script.py\n\n# Real-time profiling (ephemeral tool)\nuvx py-spy top -- python script.py\n\n# Quick profiling with scalene\nuv run --with scalene python -m scalene script.py\n```\n\n### Built-in Debugging Tools\n\n```python\n# Trace execution\nimport sys\n\ndef trace_calls(frame, event, arg):\n    if event == 'call':\n        print(f\"Calling {frame.f_code.co_name}\")\n    return trace_calls\n\nsys.settrace(trace_calls)\n\n# Memory tracking\nimport tracemalloc\n\ntracemalloc.start()\n# ... code to profile\nsnapshot = tracemalloc.take_snapshot()\ntop_stats = snapshot.statistics('lineno')\nfor stat in top_stats[:10]:\n    print(stat)\n```\n\n## Async Programming\n\n### Basic async/await\n\n```python\nimport asyncio\n\nasync def fetch_data(url: str) -> dict:\n    async with httpx.AsyncClient() as client:\n        response = await client.get(url)\n        return response.json()\n\nasync def main():\n    result = await fetch_data(\"https://api.example.com\")\n    print(result)\n\nasyncio.run(main())\n```\n\n### Concurrent Tasks\n\n```python\nasync def process_multiple():\n    # Run concurrently\n    results = await asyncio.gather(\n        fetch_data(\"url1\"),\n        fetch_data(\"url2\"),\n        fetch_data(\"url3\"),\n    )\n    return results\n\n# With timeout\nasync def with_timeout():\n    try:\n        result = await asyncio.wait_for(fetch_data(\"url\"), timeout=5.0)\n    except asyncio.TimeoutError:\n        print(\"Request timed out\")\n```\n\n## Design Patterns\n\n### Dependency Injection\n\n```python\nfrom typing import Protocol\n\nclass Database(Protocol):\n    def query(self, sql: str) -> list: ...\n\ndef get_users(db: Database) -> list:\n    return db.query(\"SELECT * FROM users\")\n```\n\n### Factory Pattern\n\n```python\ndef create_handler(handler_type: str):\n    match handler_type:\n        case \"json\":\n            return JSONHandler()\n        case \"xml\":\n            return XMLHandler()\n        case _:\n            raise ValueError(f\"Unknown handler: {handler_type}\")\n```\n\n### Decorator Pattern\n\n```python\nfrom functools import wraps\nimport time\n\ndef timer(func):\n    @wraps(func)\n    def wrapper(*args, **kwargs):\n        start = time.time()\n        result = func(*args, **kwargs)\n        end = time.time()\n        print(f\"{func.__name__} took {end - start:.2f}s\")\n        return result\n    return wrapper\n\n@timer\ndef slow_function():\n    time.sleep(1)\n```\n\n## Best Practices\n\n### SOLID Principles\n\n**Single Responsibility:**\n```python\n# Bad: Class does too much\nclass User:\n    def save(self): pass\n    def send_email(self): pass\n    def generate_report(self): pass\n\n# Good: Separate concerns\nclass User:\n    def save(self): pass\n\nclass EmailService:\n    def send_email(self, user): pass\n\nclass ReportGenerator:\n    def generate(self, user): pass\n```\n\n### Fail Fast\n\n```python\ndef process_data(data: dict) -> str:\n    # Validate early\n    if not data:\n        raise ValueError(\"Data cannot be empty\")\n    if \"required_field\" not in data:\n        raise KeyError(\"Missing required field\")\n\n    # Process with confidence\n    return data[\"required_field\"].upper()\n```\n\n### Functional Approach\n\n```python\n# Prefer immutable transformations\ndef process_items(items: list[int]) -> list[int]:\n    return [item * 2 for item in items]  # New list\n\n# Over mutations\ndef process_items_bad(items: list[int]) -> None:\n    for i in range(len(items)):\n        items[i] *= 2  # Mutates input\n```\n\n## Project Structure (src layout)\n\n```\nmy-project/\n pyproject.toml\n README.md\n src/\n    my_project/\n        __init__.py\n        core.py\n        utils.py\n        models.py\n tests/\n     conftest.py\n     test_core.py\n     test_utils.py\n```\n\n## See Also\n\n- **uv-run** - Running scripts, temporary dependencies, PEP 723\n- **uv-project-management** - Project setup and dependency management\n- **uv-tool-management** - Installing CLI tools globally\n- **python-testing** - Testing with pytest\n- **python-code-quality** - Linting and type checking with ruff/mypy\n- **python-packaging** - Building and publishing packages\n- **uv-python-versions** - Managing Python interpreters\n\n## References\n\n- Python docs: https://docs.python.org/3/\n- Type hints: https://docs.python.org/3/library/typing.html\n- Async: https://docs.python.org/3/library/asyncio.html\n- Detailed guide: See REFERENCE.md"
              },
              {
                "name": "python-packaging",
                "description": "Build and publish Python packages with uv and modern build tools. Covers uv build,\nuv publish, pyproject.toml, versioning, entry points, and PyPI publishing.\nUse when user mentions building packages, publishing to PyPI, uv build, uv publish,\npackage distribution, or Python wheel/sdist creation.\n",
                "path": "python-plugin/skills/python-packaging/SKILL.md",
                "frontmatter": {
                  "created": "2025-12-16T00:00:00.000Z",
                  "modified": "2025-12-16T00:00:00.000Z",
                  "reviewed": "2025-12-16T00:00:00.000Z",
                  "name": "python-packaging",
                  "description": "Build and publish Python packages with uv and modern build tools. Covers uv build,\nuv publish, pyproject.toml, versioning, entry points, and PyPI publishing.\nUse when user mentions building packages, publishing to PyPI, uv build, uv publish,\npackage distribution, or Python wheel/sdist creation.\n"
                },
                "content": "# Python Packaging\n\nQuick reference for building and publishing Python packages with UV and modern build tools.\n\n## When This Skill Applies\n\n- Building Python packages (wheels, sdists)\n- Publishing to PyPI or private indexes\n- Package versioning\n- Build system configuration\n- Editable installations\n\n## Quick Reference\n\n### Building Packages\n\n```bash\n# Build package\nuv build\n\n# Build specific formats\nuv build --wheel\nuv build --sdist\n\n# Output location: dist/\n```\n\n### Publishing\n\n```bash\n# Publish to PyPI\nuv publish\n\n# With token\nuv publish --token $PYPI_TOKEN\n\n# To Test PyPI\nuv publish --publish-url https://test.pypi.org/legacy/\n```\n\n### Package Structure\n\n```\nmy-package/\n pyproject.toml\n README.md\n LICENSE\n src/\n    my_package/\n        __init__.py\n        __version__.py\n        main.py\n tests/\n```\n\n## pyproject.toml Configuration\n\n```toml\n[project]\nname = \"my-package\"\nversion = \"0.1.0\"\ndescription = \"A great package\"\nreadme = \"README.md\"\nrequires-python = \">=3.11\"\nlicense = {text = \"MIT\"}\nauthors = [\n    {name = \"Your Name\", email = \"you@example.com\"}\n]\nkeywords = [\"python\", \"package\"]\nclassifiers = [\n    \"Development Status :: 4 - Beta\",\n    \"Intended Audience :: Developers\",\n    \"Programming Language :: Python :: 3\",\n    \"Programming Language :: Python :: 3.11\",\n]\n\ndependencies = [\n    \"requests>=2.31.0\",\n]\n\n[project.optional-dependencies]\ndev = [\"pytest\", \"ruff\", \"mypy\"]\n\n[project.urls]\nHomepage = \"https://github.com/user/my-package\"\nDocumentation = \"https://my-package.readthedocs.io\"\nRepository = \"https://github.com/user/my-package.git\"\nIssues = \"https://github.com/user/my-package/issues\"\n\n[project.scripts]\nmy-cli = \"my_package.cli:main\"\n\n[build-system]\nrequires = [\"uv_build>=0.9.2,<0.10.0\"]\nbuild-backend = \"uv_build\"\n```\n\n## Versioning\n\n```toml\n[project]\nversion = \"0.1.0\"  # Manual versioning\n\n# Dynamic versioning (from git tags)\ndynamic = [\"version\"]\n\n[tool.uv]\nversion-provider = \"git\"\n```\n\n## Entry Points\n\n```toml\n[project.scripts]\nmy-cli = \"my_package.cli:main\"\n\n[project.gui-scripts]\nmy-gui = \"my_package.gui:main\"\n\n[project.entry-points.\"my_plugin\"]\nplugin1 = \"my_package.plugins:plugin1\"\n```\n\n## Build Backends\n\n### UV Build (default)\n\n```toml\n[build-system]\nrequires = [\"uv_build>=0.9.2,<0.10.0\"]\nbuild-backend = \"uv_build\"\n```\n\n### Setuptools\n\n```toml\n[build-system]\nrequires = [\"setuptools>=68\", \"wheel\"]\nbuild-backend = \"setuptools.build_meta\"\n```\n\n### Hatchling\n\n```toml\n[build-system]\nrequires = [\"hatchling>=1.18\"]\nbuild-backend = \"hatchling.build\"\n```\n\n## Common Workflows\n\n### Publish to PyPI\n\n```bash\n# 1. Build\nuv build\n\n# 2. Check built packages\nls dist/\n\n# 3. Publish\nuv publish --token $PYPI_TOKEN\n```\n\n### Test PyPI First\n\n```bash\n# Publish to Test PyPI\nuv publish --publish-url https://test.pypi.org/legacy/ \\\n           --token $TEST_PYPI_TOKEN\n\n# Test installation\npip install --index-url https://test.pypi.org/simple/ my-package\n```\n\n## Package Classifiers\n\nCommon classifiers:\n\n```toml\nclassifiers = [\n    # Development Status\n    \"Development Status :: 3 - Alpha\",\n    \"Development Status :: 4 - Beta\",\n    \"Development Status :: 5 - Production/Stable\",\n\n    # Audience\n    \"Intended Audience :: Developers\",\n    \"Intended Audience :: Science/Research\",\n\n    # License\n    \"License :: OSI Approved :: MIT License\",\n\n    # Python Versions\n    \"Programming Language :: Python :: 3\",\n    \"Programming Language :: Python :: 3.11\",\n    \"Programming Language :: Python :: 3.12\",\n\n    # Framework\n    \"Framework :: Django\",\n    \"Framework :: FastAPI\",\n\n    # Topic\n    \"Topic :: Software Development :: Libraries\",\n    \"Topic :: Scientific/Engineering\",\n]\n```\n\nFull list: https://pypi.org/classifiers/\n\n## See Also\n\n- `uv-project-management` - Project setup and dependencies\n- `python-development` - Core Python patterns\n- `uv-workspaces` - Building workspace packages\n\n## References\n\n- UV build: https://docs.astral.sh/uv/guides/publish/\n- PyPI: https://pypi.org/\n- Detailed guide: See REFERENCE.md"
              },
              {
                "name": "python-testing",
                "description": "Python testing with pytest, coverage, fixtures, parametrization, and mocking.\nCovers test organization, conftest.py, markers, async testing, and TDD workflows.\nUse when user mentions pytest, unit tests, test coverage, fixtures, mocking,\nor writing Python tests.\n",
                "path": "python-plugin/skills/python-testing/SKILL.md",
                "frontmatter": {
                  "created": "2025-12-16T00:00:00.000Z",
                  "modified": "2025-12-16T00:00:00.000Z",
                  "reviewed": "2025-12-16T00:00:00.000Z",
                  "name": "python-testing",
                  "description": "Python testing with pytest, coverage, fixtures, parametrization, and mocking.\nCovers test organization, conftest.py, markers, async testing, and TDD workflows.\nUse when user mentions pytest, unit tests, test coverage, fixtures, mocking,\nor writing Python tests.\n"
                },
                "content": "# Python Testing\n\nQuick reference for Python testing with pytest, coverage, fixtures, and best practices.\n\n## When This Skill Applies\n\n- Writing unit tests and integration tests\n- Test-driven development (TDD)\n- Test fixtures and parametrization\n- Coverage analysis\n- Mocking and patching\n- Async testing\n\n## Quick Reference\n\n### Running Tests\n\n```bash\n# Basic test run\nuv run pytest\n\n# Verbose output\nuv run pytest -v\n\n# Show print statements\nuv run pytest -s\n\n# Stop at first failure\nuv run pytest -x\n\n# Run specific test\nuv run pytest tests/test_module.py::test_function\n\n# Run by keyword\nuv run pytest -k \"test_user\"\n```\n\n### Test Coverage\n\n```bash\n# Run with coverage\nuv run pytest --cov\n\n# HTML report\nuv run pytest --cov --cov-report=html\n\n# Show missing lines\nuv run pytest --cov --cov-report=term-missing\n\n# Coverage for specific module\nuv run pytest --cov=mymodule tests/\n```\n\n### Fixtures\n\n```python\nimport pytest\n\n@pytest.fixture\ndef sample_data():\n    return {\"key\": \"value\"}\n\n@pytest.fixture(scope=\"module\")\ndef db_connection():\n    conn = create_connection()\n    yield conn\n    conn.close()\n\ndef test_with_fixture(sample_data):\n    assert sample_data[\"key\"] == \"value\"\n```\n\n### Parametrize Tests\n\n```python\nimport pytest\n\n@pytest.mark.parametrize(\"input,expected\", [\n    (\"hello\", \"HELLO\"),\n    (\"world\", \"WORLD\"),\n    (\"test\", \"TEST\"),\n])\ndef test_uppercase(input: str, expected: str):\n    assert input.upper() == expected\n\n@pytest.mark.parametrize(\"value,is_valid\", [\n    (1, True),\n    (0, False),\n    (-1, False),\n])\ndef test_validation(value, is_valid):\n    assert validate(value) == is_valid\n```\n\n### Markers\n\n```python\nimport pytest\n\n@pytest.mark.slow\ndef test_slow_operation():\n    # Long-running test\n    pass\n\n@pytest.mark.skip(reason=\"Not implemented yet\")\ndef test_future_feature():\n    pass\n\n@pytest.mark.skipif(sys.platform == \"win32\", reason=\"Unix only\")\ndef test_unix_specific():\n    pass\n\n@pytest.mark.xfail\ndef test_known_issue():\n    # Expected to fail\n    pass\n```\n\n```bash\n# Run only marked tests\nuv run pytest -m slow\nuv run pytest -m \"not slow\"\n```\n\n### Async Testing\n\n```python\nimport pytest\n\n@pytest.mark.asyncio\nasync def test_async_function():\n    result = await async_operation()\n    assert result == expected_value\n\n@pytest.fixture\nasync def async_client():\n    client = AsyncClient()\n    await client.connect()\n    yield client\n    await client.disconnect()\n```\n\n### Mocking\n\n```python\nfrom unittest.mock import Mock, patch, MagicMock\n\ndef test_with_mock():\n    mock_obj = Mock()\n    mock_obj.method.return_value = \"mocked\"\n    assert mock_obj.method() == \"mocked\"\n\n@patch('module.external_api')\ndef test_with_patch(mock_api):\n    mock_api.return_value = {\"status\": \"success\"}\n    result = call_external_api()\n    assert result[\"status\"] == \"success\"\n\n# pytest-mock (cleaner)\ndef test_with_mocker(mocker):\n    mock = mocker.patch('module.function')\n    mock.return_value = 42\n    assert function() == 42\n```\n\n## Test Organization\n\n```\nproject/\n src/\n    myproject/\n        __init__.py\n        module.py\n tests/\n     __init__.py\n     conftest.py          # Shared fixtures\n     test_module.py\n     integration/\n         test_api.py\n```\n\n## conftest.py\n\n```python\n# tests/conftest.py\nimport pytest\n\n@pytest.fixture(scope=\"session\")\ndef app_config():\n    return {\"debug\": True, \"testing\": True}\n\n@pytest.fixture(autouse=True)\ndef reset_db():\n    setup_database()\n    yield\n    teardown_database()\n```\n\n## pyproject.toml Configuration\n\n```toml\n[tool.pytest.ini_options]\ntestpaths = [\"tests\"]\npython_files = [\"test_*.py\", \"*_test.py\"]\npython_classes = [\"Test*\"]\npython_functions = [\"test_*\"]\naddopts = [\n    \"-v\",\n    \"--strict-markers\",\n    \"--cov=src\",\n    \"--cov-report=term-missing\",\n]\nmarkers = [\n    \"slow: marks tests as slow\",\n    \"integration: marks tests as integration tests\",\n]\n\n[tool.coverage.run]\nsource = [\"src\"]\nomit = [\"*/tests/*\", \"*/test_*.py\"]\n\n[tool.coverage.report]\nexclude_lines = [\n    \"pragma: no cover\",\n    \"def __repr__\",\n    \"raise AssertionError\",\n    \"raise NotImplementedError\",\n    \"if __name__ == .__main__.:\",\n]\n```\n\n## Common Testing Patterns\n\n### Test Exceptions\n\n```python\nimport pytest\n\ndef test_raises_exception():\n    with pytest.raises(ValueError):\n        function_that_raises()\n\ndef test_raises_with_message():\n    with pytest.raises(ValueError, match=\"Invalid input\"):\n        function_that_raises()\n```\n\n### Test Warnings\n\n```python\nimport pytest\n\ndef test_deprecation_warning():\n    with pytest.warns(DeprecationWarning):\n        deprecated_function()\n```\n\n### Temporary Files\n\n```python\ndef test_with_tmp_path(tmp_path):\n    file_path = tmp_path / \"test.txt\"\n    file_path.write_text(\"content\")\n    assert file_path.read_text() == \"content\"\n```\n\n## TDD Workflow\n\n```bash\n# 1. RED: Write failing test\nuv run pytest tests/test_new_feature.py\n# FAILED\n\n# 2. GREEN: Implement minimal code\nuv run pytest tests/test_new_feature.py\n# PASSED\n\n# 3. REFACTOR: Improve code\nuv run pytest  # All tests pass\n```\n\n## See Also\n\n- `uv-project-management` - Adding pytest to projects\n- `python-code-quality` - Combining tests with linting\n- `python-development` - Core Python development patterns\n\n## References\n\n- Official docs: https://docs.pytest.org/\n- Detailed guide: See REFERENCE.md in this skill directory"
              },
              {
                "name": "ruff Formatting",
                "description": "Python code formatting with ruff format. Fast, Black-compatible formatting for consistent code style. Use when formatting Python files, enforcing style, or checking format compliance.",
                "path": "python-plugin/skills/ruff-formatting/SKILL.md",
                "frontmatter": {
                  "created": "2025-12-16T00:00:00.000Z",
                  "modified": "2025-12-16T00:00:00.000Z",
                  "reviewed": "2025-12-16T00:00:00.000Z",
                  "name": "ruff Formatting",
                  "description": "Python code formatting with ruff format. Fast, Black-compatible formatting for consistent code style. Use when formatting Python files, enforcing style, or checking format compliance.",
                  "allowed-tools": "Bash, Read, Edit, Write, Grep, Glob"
                },
                "content": "# ruff Formatting\n\nExpert knowledge for using `ruff format` as an extremely fast Python code formatter with Black compatibility.\n\n## Core Expertise\n\n**ruff format Advantages**\n- 10-30x faster than Black\n- Drop-in Black replacement (99.9% compatible)\n- Written in Rust for performance\n- Supports Black's configuration options\n- Format checking and diff preview\n- Respects `.gitignore` automatically\n\n## Basic Usage\n\n### Simple Formatting\n```bash\n# Format current directory\nruff format\n\n# Format specific files or directories\nruff format path/to/file.py\nruff format src/ tests/\n\n# IMPORTANT: Pass directory as parameter to stay in repo root\n#  Good\nruff format services/orchestrator\n\n#  Bad\ncd services/orchestrator && ruff format\n```\n\n### Format Checking\n```bash\n# Check if files are formatted (exit code 1 if not)\nruff format --check\n\n# Show diff without modifying files\nruff format --diff\n\n# Check specific files\nruff format --check src/ tests/\n\n# Preview changes before applying\nruff format --diff services/orchestrator\nruff format services/orchestrator  # Apply after review\n```\n\n### Selective Formatting\n```bash\n# Format only Python files\nruff format src/**/*.py\n\n# Format excluding tests\nruff format --exclude tests/\n\n# Format only changed files (git)\ngit diff --name-only --diff-filter=d | grep '\\.py$' | xargs ruff format\n\n# Format files in specific directory\nruff format src/core/ src/utils/\n```\n\n## Configuration\n\n### pyproject.toml\n```toml\n[tool.ruff.format]\n# Quote style\nquote-style = \"double\"  # or \"single\"\n\n# Indentation\nindent-style = \"space\"  # or \"tab\"\n\n# Line endings\nline-ending = \"auto\"  # or \"lf\", \"cr-lf\", \"native\"\n\n# Magic trailing comma handling\nskip-magic-trailing-comma = false\n\n# Format docstring code examples\ndocstring-code-format = true\n\n# Docstring code line length\ndocstring-code-line-length = \"dynamic\"  # or number like 80\n\n# Exclude patterns\nexclude = [\n    \"*.pyi\",           # Type stubs\n    \"**/__pycache__\",\n    \"**/node_modules\",\n    \".venv\",\n]\n```\n\n### ruff.toml (standalone)\n```toml\n# Line length (affects both formatting and linting)\nline-length = 88\n\n[format]\nquote-style = \"single\"\nindent-style = \"space\"\nskip-magic-trailing-comma = false\ndocstring-code-format = true\n```\n\n### Black Compatibility\n```toml\n[tool.ruff]\n# Same as Black defaults\nline-length = 88\nindent-width = 4\ntarget-version = \"py39\"\n\n[tool.ruff.format]\nquote-style = \"double\"\nindent-style = \"space\"\nskip-magic-trailing-comma = false\nline-ending = \"auto\"\n```\n\n## Advanced Features\n\n### Quote Styles\n```bash\n# Use single quotes\nruff format --config '[format]\\nquote-style = \"single\"'\n\n# Use double quotes (Black default)\nruff format --config '[format]\\nquote-style = \"double\"'\n\n# Preserve existing quotes (not recommended)\n# Not supported - ruff enforces consistency\n```\n\n**Quote Style Behavior**\n```python\n# double quotes (default)\ngreeting = \"Hello, world!\"\nname = \"Alice\"\n\n# single quotes\ngreeting = 'Hello, world!'\nname = 'Alice'\n\n# Triple quotes always use double (Black compatibility)\ndocstring = \"\"\"\nThis is a docstring.\nAlways uses double quotes.\n\"\"\"\n```\n\n### Indentation Styles\n```toml\n[tool.ruff.format]\n# Space indentation (default, recommended)\nindent-style = \"space\"\n\n# Tab indentation (not recommended)\nindent-style = \"tab\"\n```\n\n### Line Endings\n```toml\n[tool.ruff.format]\n# Auto-detect from existing files (default)\nline-ending = \"auto\"\n\n# Force Unix line endings (LF)\nline-ending = \"lf\"\n\n# Force Windows line endings (CRLF)\nline-ending = \"cr-lf\"\n\n# Use platform native\nline-ending = \"native\"\n```\n\n### Docstring Code Formatting\n```toml\n[tool.ruff.format]\n# Format code in docstrings (default: false)\ndocstring-code-format = true\n\n# Control line length for docstring code\ndocstring-code-line-length = \"dynamic\"  # Uses main line-length\n# or\ndocstring-code-line-length = 80  # Fixed length\n```\n\n**Example**\n```python\ndef example():\n    \"\"\"\n    Example function.\n\n    ```python\n    # This code will be formatted when docstring-code-format = true\n    result = calculate(\n        x=1,\n        y=2,\n        z=3,\n    )\n    ```\n    \"\"\"\n    pass\n```\n\n### Magic Trailing Comma\n```python\n# When skip-magic-trailing-comma = false (default)\n# Trailing comma forces multi-line\nitems = [\n    \"apple\",\n    \"banana\",\n    \"cherry\",  #  This comma forces expansion\n]\n\n# Without trailing comma, can be single-line\nitems = [\"apple\", \"banana\", \"cherry\"]\n\n# When skip-magic-trailing-comma = true\n# Trailing comma is ignored, formatter decides layout\n```\n\n## Integration Patterns\n\n### Pre-commit Hook\n```yaml\n# .pre-commit-config.yaml\nrepos:\n  - repo: https://github.com/astral-sh/ruff-pre-commit\n    rev: v0.14.0\n    hooks:\n      # Formatter\n      - id: ruff-format\n        types_or: [python, pyi]\n\n      # Advanced configuration\n      - id: ruff-format\n        args:\n          - --config=pyproject.toml\n        types_or: [python, pyi]\n```\n\n### GitHub Actions\n```yaml\n# .github/workflows/format.yml\nname: Format Check\n\non: [push, pull_request]\n\njobs:\n  format:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Install ruff\n        run: pip install ruff\n\n      - name: Check formatting\n        run: ruff format --check\n\n      # Or with auto-commit\n      - name: Format code\n        run: ruff format\n\n      - name: Commit changes\n        if: failure()\n        run: |\n          git config user.name \"github-actions\"\n          git config user.email \"github-actions@github.com\"\n          git add .\n          git commit -m \"Auto-format with ruff\"\n          git push\n```\n\n### GitLab CI\n```yaml\n# .gitlab-ci.yml\nRuff Format:\n  stage: build\n  image: ghcr.io/astral-sh/ruff:0.14.0-alpine\n  script:\n    - ruff format --check --diff\n  allow_failure: false\n```\n\n### Editor Integration\n\n#### VS Code\n```json\n// .vscode/settings.json\n{\n  \"[python]\": {\n    \"editor.formatOnSave\": true,\n    \"editor.defaultFormatter\": \"charliermarsh.ruff\"\n  },\n  \"ruff.format.args\": [\n    \"--line-length=100\"\n  ]\n}\n```\n\n#### Neovim\n```lua\n-- Using nvimf-lint and conform.nvim\nrequire(\"conform\").setup({\n  formatters_by_ft = {\n    python = { \"ruff_format\" },\n  },\n  format_on_save = {\n    timeout_ms = 500,\n    lsp_fallback = true,\n  },\n})\n```\n\n## Common Patterns\n\n### Format Check in CI\n```bash\n# Exit with error if not formatted\nruff format --check\n\n# Show what would change\nruff format --diff\n\n# Both check and show diff\nruff format --check --diff\n```\n\n### Format Only Changed Files\n```bash\n# Git: Format only modified files\ngit diff --name-only --diff-filter=d | grep '\\.py$' | xargs ruff format\n\n# Git: Format files in current branch\ngit diff --name-only main...HEAD | grep '\\.py$' | xargs ruff format\n\n# Git: Format staged files\ngit diff --cached --name-only --diff-filter=d | grep '\\.py$' | xargs ruff format\n```\n\n### Parallel Formatting\n```bash\n# Format multiple directories in parallel\nruff format src/ &\nruff format tests/ &\nruff format scripts/ &\nwait\n\n# Or use find with parallel\nfind src tests -name \"*.py\" -print0 | xargs -0 -P 4 ruff format\n```\n\n### Combined with Linting\n```bash\n# Format first, then lint\nruff format && ruff check\n\n# Format and lint with fixes\nruff format && ruff check --fix\n\n# Check both without modifying\nruff format --check && ruff check\n```\n\n### Migration from Black\n```bash\n# 1. Update dependencies\npip uninstall black\npip install ruff\n\n# 2. Keep Black configuration\n# ruff respects [tool.black] in pyproject.toml\n\n# 3. Test formatting\nruff format --diff\n\n# 4. Format entire codebase\nruff format .\n\n# 5. Update pre-commit config\n# Replace black with ruff-format\n```\n\n## Excluding Files\n\n### Configuration-based\n```toml\n[tool.ruff.format]\nexclude = [\n    \"*.pyi\",                    # Type stubs\n    \"**/node_modules\",          # Dependencies\n    \".venv\",                    # Virtual environment\n    \"**/__pycache__\",           # Cache\n    \"**/migrations/*.py\",       # Django migrations\n    \"generated/**/*.py\",        # Generated code\n]\n```\n\n### Command-line\n```bash\n# Exclude patterns\nruff format --exclude \"migrations\" --exclude \"*.pyi\"\n\n# Multiple patterns\nruff format --exclude \"{migrations,node_modules,generated}\"\n\n# Using extend-exclude (add to defaults)\nruff format --extend-exclude \"legacy/\"\n```\n\n## Notebook Support\n\n### Jupyter Notebooks\n```bash\n# Format Jupyter notebooks\nruff format notebook.ipynb\n\n# Check notebook formatting\nruff format --check *.ipynb\n\n# Exclude notebooks\nruff format --exclude \"*.ipynb\"\n```\n\n**Configuration**\n```toml\n[tool.ruff.format]\n# Include notebooks by default\n# Exclude if needed:\nexclude = [\"*.ipynb\"]\n\n[tool.ruff.lint.per-file-ignores]\n\"*.ipynb\" = [\"E501\"]  # Ignore line length in notebooks\n```\n\n## Best Practices\n\n**When to Use ruff format**\n- Pre-commit formatting\n- CI/CD format checking\n- Editor format-on-save\n- Codebase reformatting\n- Migration from Black\n\n**Critical: Directory Parameters**\n-  **Always** pass directory as parameter: `ruff format services/orchestrator`\n-  **Never** use cd: `cd services/orchestrator && ruff format`\n- Reason: Parallel execution, clearer output, tool compatibility\n\n**Format Workflow**\n1. **Preview**: `ruff format --diff` (see changes)\n2. **Check**: `ruff format --check` (CI validation)\n3. **Apply**: `ruff format` (modify files)\n4. **Verify**: `ruff format --check` (confirm)\n\n**Configuration Strategy**\n1. Start with Black defaults (88 char line length)\n2. Adjust quote-style if team prefers single quotes\n3. Enable docstring-code-format for better docs\n4. Use auto line-ending detection\n5. Exclude generated code and type stubs\n\n**Common Mistakes to Avoid**\n- Using `cd` instead of passing directory parameter\n- Not previewing with `--diff` before formatting\n- Mixing formatters (Black and ruff format)\n- Not excluding generated files\n- Forgetting to update pre-commit config\n\n**Black Migration Checklist**\n- [ ] Remove Black from dependencies\n- [ ] Add ruff to dependencies\n- [ ] Update pre-commit config (black  ruff-format)\n- [ ] Update CI/CD pipelines\n- [ ] Test with `ruff format --diff`\n- [ ] Format entire codebase\n- [ ] Update editor configuration\n- [ ] Document in team guidelines\n\n## Quick Reference\n\n### Essential Commands\n\n```bash\n# Basic operations\nruff format                         # Format current directory\nruff format path/to/dir             # Format specific directory\nruff format --check                 # Check if formatted\nruff format --diff                  # Show formatting changes\n\n# File operations\nruff format file1.py file2.py       # Format specific files\nruff format src/ tests/             # Format multiple directories\nruff format --exclude tests/        # Exclude directory\n\n# Configuration\nruff format --config path/to/ruff.toml  # Custom config\nruff format --line-length 100          # Override line length\n```\n\n### Configuration Quick Start\n\n**Minimal (Black-compatible)**\n```toml\n[tool.ruff]\nline-length = 88\n\n[tool.ruff.format]\nquote-style = \"double\"\nindent-style = \"space\"\n```\n\n**Recommended**\n```toml\n[tool.ruff]\nline-length = 88\ntarget-version = \"py311\"\n\n[tool.ruff.format]\nquote-style = \"double\"\nindent-style = \"space\"\nskip-magic-trailing-comma = false\ndocstring-code-format = true\nline-ending = \"auto\"\n\nexclude = [\n    \"*.pyi\",\n    \"migrations/**/*.py\",\n]\n```\n\n### Format vs Check\n\n| Command | Purpose | Exit Code | Modifies Files |\n|---------|---------|-----------|----------------|\n| `ruff format` | Format files | 0 | Yes |\n| `ruff format --check` | Validate formatting | 1 if unformatted | No |\n| `ruff format --diff` | Show changes | 0 | No |\n| `ruff format --check --diff` | Validate + show | 1 if unformatted | No |\n\nThis makes ruff format the preferred tool for fast, consistent Python code formatting."
              },
              {
                "name": "ruff Integration",
                "description": "Integrate ruff with editors, pre-commit hooks, and CI/CD pipelines. LSP configuration, GitHub Actions, GitLab CI, and development workflows. Use when setting up ruff tooling or configuring development environments.",
                "path": "python-plugin/skills/ruff-integration/SKILL.md",
                "frontmatter": {
                  "created": "2025-12-16T00:00:00.000Z",
                  "modified": "2025-12-16T00:00:00.000Z",
                  "reviewed": "2025-12-16T00:00:00.000Z",
                  "name": "ruff Integration",
                  "description": "Integrate ruff with editors, pre-commit hooks, and CI/CD pipelines. LSP configuration, GitHub Actions, GitLab CI, and development workflows. Use when setting up ruff tooling or configuring development environments.",
                  "allowed-tools": "Bash, Read, Edit, Write, Grep, Glob"
                },
                "content": "# ruff Integration\n\nExpert knowledge for integrating `ruff` into development workflows, editors, and CI/CD pipelines.\n\n## Core Expertise\n\n**Integration Points**\n- Editor integration (VS Code, Neovim, Zed, Helix)\n- Pre-commit hooks\n- CI/CD pipelines (GitHub Actions, GitLab CI)\n- Language Server Protocol (LSP)\n- Build systems and task runners\n\n## Editor Integration\n\n### VS Code\n\n**Installation**\n```bash\n# Install extension\ncode --install-extension charliermarsh.ruff\n```\n\n**Configuration** (`.vscode/settings.json`)\n```json\n{\n  // Python configuration\n  \"[python]\": {\n    \"editor.formatOnSave\": true,\n    \"editor.codeActionsOnSave\": {\n      \"source.fixAll\": \"explicit\",\n      \"source.organizeImports\": \"explicit\"\n    },\n    \"editor.defaultFormatter\": \"charliermarsh.ruff\"\n  },\n\n  // Ruff-specific settings\n  \"ruff.lint.args\": [\n    \"--select=E,F,B,I\"\n  ],\n  \"ruff.format.args\": [\n    \"--line-length=100\"\n  ],\n  \"ruff.importStrategy\": \"fromEnvironment\",\n  \"ruff.path\": [\"ruff\"],\n\n  // Custom configuration file\n  \"ruff.configuration\": \"~/path/to/ruff.toml\",\n\n  // Or inline configuration\n  \"ruff.configuration\": {\n    \"lint\": {\n      \"unfixable\": [\"F401\"],\n      \"extend-select\": [\"TID251\"]\n    },\n    \"format\": {\n      \"quote-style\": \"single\"\n    }\n  }\n}\n```\n\n**Workspace Settings**\n```json\n// .vscode/settings.json (project-specific)\n{\n  \"[python]\": {\n    \"editor.formatOnSave\": true,\n    \"editor.defaultFormatter\": \"charliermarsh.ruff\"\n  },\n  \"ruff.lint.select\": [\"E\", \"F\", \"B\", \"I\", \"UP\"],\n  \"ruff.lint.ignore\": [\"E501\"]\n}\n```\n\n### Neovim\n\n**Using LSP (nvim-lspconfig)**\n```lua\n-- Ruff LSP setup\nrequire('lspconfig').ruff.setup {\n  init_options = {\n    settings = {\n      -- Linting configuration\n      lint = {\n        select = {\"E\", \"F\", \"B\", \"I\"},\n        ignore = {\"E501\"}\n      },\n      -- Formatting configuration\n      format = {\n        [\"quote-style\"] = \"single\"\n      },\n      -- Line length\n      lineLength = 88\n    }\n  }\n}\n```\n\n**Using conform.nvim (Formatting)**\n```lua\nrequire(\"conform\").setup({\n  formatters_by_ft = {\n    python = { \"ruff_format\" },\n  },\n  format_on_save = {\n    timeout_ms = 500,\n    lsp_fallback = true,\n  },\n})\n```\n\n**Using nvim-lint (Linting)**\n```lua\nrequire(\"lint\").linters_by_ft = {\n  python = { \"ruff\" },\n}\n\n-- Auto-lint on save\nvim.api.nvim_create_autocmd({ \"BufWritePost\" }, {\n  callback = function()\n    require(\"lint\").try_lint()\n  end,\n})\n```\n\n**Inline Configuration**\n```lua\nrequire('lspconfig').ruff.setup {\n  init_options = {\n    settings = {\n      configuration = {\n        lint = {\n          unfixable = {\"F401\"},\n          [\"extend-select\"] = {\"TID251\"},\n          [\"flake8-tidy-imports\"] = {\n            [\"banned-api\"] = {\n              [\"typing.TypedDict\"] = {\n                msg = \"Use `typing_extensions.TypedDict` instead\"\n              }\n            }\n          }\n        },\n        format = {\n          [\"quote-style\"] = \"single\"\n        }\n      }\n    }\n  }\n}\n```\n\n### Zed\n\n**Configuration** (`settings.json`)\n```json\n{\n  \"languages\": {\n    \"Python\": {\n      \"language_servers\": [\"ruff\"],\n      \"format_on_save\": \"on\",\n      \"formatter\": [\n        {\n          \"code_actions\": {\n            \"source.organizeImports.ruff\": true,\n            \"source.fixAll.ruff\": true\n          }\n        },\n        {\n          \"language_server\": {\n            \"name\": \"ruff\"\n          }\n        }\n      ]\n    }\n  },\n  \"lsp\": {\n    \"ruff\": {\n      \"initialization_options\": {\n        \"settings\": {\n          \"lineLength\": 80,\n          \"lint\": {\n            \"extendSelect\": [\"I\"]\n          },\n          \"configuration\": \"~/path/to/ruff.toml\"\n        }\n      }\n    }\n  }\n}\n```\n\n### Helix\n\n**Configuration** (`languages.toml`)\n```toml\n# LSP configuration\n[language-server.ruff]\ncommand = \"ruff\"\nargs = [\"server\"]\n\n# Language-specific settings\n[language-server.ruff.config.settings]\nlineLength = 80\n\n[language-server.ruff.config.settings.lint]\nselect = [\"E4\", \"E7\"]\npreview = false\n\n[language-server.ruff.config.settings.format]\npreview = true\n\n# Python language configuration\n[[language]]\nname = \"python\"\nlanguage-servers = [\"ruff\", \"pyright\"]\nformatter = { command = \"ruff\", args = [\"format\", \"-\"] }\nauto-format = true\n```\n\n### EFM Language Server\n\n**Configuration** (`efm-langserver` config)\n```yaml\ntools:\n  python-ruff:\n    lint-command: \"ruff check --stdin-filename ${INPUT} --output-format concise --quiet -\"\n    lint-stdin: true\n    lint-formats:\n      - \"%f:%l:%c: %m\"\n    format-command: \"ruff format --stdin-filename ${INPUT} --quiet -\"\n    format-stdin: true\n```\n\n## Pre-commit Integration\n\n### Basic Setup\n```yaml\n# .pre-commit-config.yaml\nrepos:\n  - repo: https://github.com/astral-sh/ruff-pre-commit\n    rev: v0.14.0\n    hooks:\n      # Linter with auto-fix\n      - id: ruff-check\n        args: [--fix]\n\n      # Formatter\n      - id: ruff-format\n```\n\n### Advanced Configuration\n```yaml\nrepos:\n  - repo: https://github.com/astral-sh/ruff-pre-commit\n    rev: v0.14.0\n    hooks:\n      # Advanced linting\n      - id: ruff-check\n        name: Ruff linter\n        args:\n          - --fix\n          - --config=pyproject.toml\n          - --select=E,F,B,I\n        types_or: [python, pyi, jupyter]\n\n      # Formatting with specific config\n      - id: ruff-format\n        name: Ruff formatter\n        args:\n          - --config=pyproject.toml\n        types_or: [python, pyi]\n```\n\n### Installation\n```bash\n# Install pre-commit\npip install pre-commit\n\n# Install hooks\npre-commit install\n\n# Run manually\npre-commit run --all-files\n\n# Run on specific files\npre-commit run --files src/main.py\n\n# Update hooks\npre-commit autoupdate\n```\n\n### Multiple Python Versions\n```yaml\nrepos:\n  - repo: https://github.com/astral-sh/ruff-pre-commit\n    rev: v0.14.0\n    hooks:\n      - id: ruff-check\n        args: [--fix, --target-version=py39]\n      - id: ruff-format\n```\n\n## CI/CD Integration\n\n### GitHub Actions\n\n**Basic Workflow**\n```yaml\n# .github/workflows/lint.yml\nname: Lint\n\non: [push, pull_request]\n\njobs:\n  ruff:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - uses: astral-sh/ruff-action@v3\n```\n\n**Advanced Workflow**\n```yaml\nname: Code Quality\n\non: [push, pull_request]\n\njobs:\n  lint:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n\n      - uses: astral-sh/ruff-action@v3\n        with:\n          args: 'check --output-format github'\n          changed-files: 'true'\n\n      - name: Commit fixes\n        if: failure()\n        run: |\n          git config user.name \"github-actions\"\n          git config user.email \"github-actions@github.com\"\n          git add .\n          git commit -m \"Auto-fix linting issues\"\n          git push\n\n  format:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Check formatting\n        run: |\n          pip install ruff\n          ruff format --check\n```\n\n**With Multiple Python Versions**\n```yaml\njobs:\n  lint:\n    strategy:\n      matrix:\n        python-version: ['3.9', '3.10', '3.11', '3.12']\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - uses: actions/setup-python@v5\n        with:\n          python-version: ${{ matrix.python-version }}\n      - run: pip install ruff\n      - run: ruff check --target-version=py${{ matrix.python-version }}\n```\n\n**Separated Linting and Formatting**\n```yaml\njobs:\n  ruff-check:\n    name: Lint with Ruff\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - run: pip install ruff\n      - run: ruff check --output-format github\n\n  ruff-format:\n    name: Check Formatting\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - run: pip install ruff\n      - run: ruff format --check --diff\n```\n\n### GitLab CI\n\n**Basic Pipeline**\n```yaml\n# .gitlab-ci.yml\nstages:\n  - lint\n\nruff-check:\n  stage: lint\n  image: ghcr.io/astral-sh/ruff:0.14.0-alpine\n  script:\n    - ruff check\n\nruff-format:\n  stage: lint\n  image: ghcr.io/astral-sh/ruff:0.14.0-alpine\n  script:\n    - ruff format --check\n```\n\n**Advanced Pipeline**\n```yaml\n.base_ruff:\n  stage: build\n  interruptible: true\n  image:\n    name: ghcr.io/astral-sh/ruff:0.14.0-alpine\n  before_script:\n    - cd $CI_PROJECT_DIR\n    - ruff --version\n\nRuff Check:\n  extends: .base_ruff\n  script:\n    - ruff check --output-format=gitlab > code-quality-report.json\n  artifacts:\n    reports:\n      codequality: $CI_PROJECT_DIR/code-quality-report.json\n\nRuff Format:\n  extends: .base_ruff\n  script:\n    - ruff format --check --diff\n  allow_failure: false\n```\n\n### CircleCI\n```yaml\n# .circleci/config.yml\nversion: 2.1\n\njobs:\n  lint:\n    docker:\n      - image: cimg/python:3.11\n    steps:\n      - checkout\n      - run:\n          name: Install ruff\n          command: pip install ruff\n      - run:\n          name: Run linter\n          command: ruff check\n      - run:\n          name: Check formatting\n          command: ruff format --check\n\nworkflows:\n  main:\n    jobs:\n      - lint\n```\n\n### Jenkins\n```groovy\npipeline {\n    agent any\n\n    stages {\n        stage('Setup') {\n            steps {\n                sh 'pip install ruff'\n            }\n        }\n\n        stage('Lint') {\n            steps {\n                sh 'ruff check --output-format json > ruff-report.json'\n            }\n        }\n\n        stage('Format Check') {\n            steps {\n                sh 'ruff format --check'\n            }\n        }\n    }\n\n    post {\n        always {\n            archiveArtifacts artifacts: 'ruff-report.json', fingerprint: true\n        }\n    }\n}\n```\n\n## Build System Integration\n\n### Make\n```makefile\n# Makefile\n.PHONY: lint format check\n\n# Lint with ruff\nlint:\n\truff check\n\n# Format with ruff\nformat:\n\truff format\n\n# Check both\ncheck: lint\n\truff format --check\n\n# Fix issues\nfix:\n\truff check --fix\n\truff format\n\n# CI target\nci: check\n\t@echo \"All checks passed!\"\n```\n\n### Just\n```just\n# justfile\n# Lint Python code\nlint:\n    ruff check\n\n# Format Python code\nformat:\n    ruff format\n\n# Check formatting\nformat-check:\n    ruff format --check\n\n# Fix all issues\nfix:\n    ruff check --fix\n    ruff format\n\n# Run all checks (CI)\nci: lint format-check\n```\n\n### Task (go-task)\n```yaml\n# Taskfile.yml\nversion: '3'\n\ntasks:\n  lint:\n    desc: Lint Python code\n    cmds:\n      - ruff check\n\n  format:\n    desc: Format Python code\n    cmds:\n      - ruff format\n\n  format-check:\n    desc: Check formatting\n    cmds:\n      - ruff format --check\n\n  fix:\n    desc: Auto-fix issues\n    cmds:\n      - ruff check --fix\n      - ruff format\n\n  ci:\n    desc: Run CI checks\n    deps:\n      - lint\n      - format-check\n```\n\n### Poetry Scripts\n```toml\n# pyproject.toml\n[tool.poetry.scripts]\nlint = \"ruff check\"\nformat = \"ruff format\"\ncheck = \"ruff format --check && ruff check\"\n```\n\n### tox\n```ini\n# tox.ini\n[tox]\nenvlist = py39,py310,py311,lint\n\n[testenv]\ndeps = pytest\ncommands = pytest\n\n[testenv:lint]\ndeps = ruff\ncommands =\n    ruff check\n    ruff format --check\n\n[testenv:format]\ndeps = ruff\ncommands = ruff format\n```\n\n## Docker Integration\n\n### Dockerfile\n```dockerfile\n# Development stage with ruff\nFROM python:3.11-slim as development\n\n# Install ruff\nRUN pip install --no-cache-dir ruff\n\n# Copy source code\nCOPY . /app\nWORKDIR /app\n\n# Run checks\nRUN ruff check && ruff format --check\n\n# Production stage\nFROM python:3.11-slim as production\n# ... production setup\n```\n\n### Docker Compose\n```yaml\n# docker-compose.yml\nversion: '3.8'\n\nservices:\n  lint:\n    image: ghcr.io/astral-sh/ruff:0.14.0-alpine\n    volumes:\n      - .:/app\n    working_dir: /app\n    command: ruff check\n\n  format:\n    image: ghcr.io/astral-sh/ruff:0.14.0-alpine\n    volumes:\n      - .:/app\n    working_dir: /app\n    command: ruff format --check\n```\n\n## LSP Server Configuration\n\n### Ruff Server Features\n- Real-time linting\n- Auto-fixing on save\n- Import organization\n- Code actions\n- Hover documentation\n- Configuration reloading\n\n### Server Settings\n```json\n{\n  \"settings\": {\n    // Line length\n    \"lineLength\": 88,\n\n    // Linting\n    \"lint\": {\n      \"select\": [\"E\", \"F\", \"B\", \"I\"],\n      \"ignore\": [\"E501\"],\n      \"preview\": false\n    },\n\n    // Formatting\n    \"format\": {\n      \"preview\": false,\n      \"quote-style\": \"double\"\n    },\n\n    // Configuration file\n    \"configuration\": \"~/path/to/ruff.toml\"\n  }\n}\n```\n\n### Code Actions\n```json\n{\n  \"codeActionsOnSave\": {\n    // Fix all auto-fixable issues\n    \"source.fixAll\": \"explicit\",\n\n    // Organize imports\n    \"source.organizeImports\": \"explicit\"\n  }\n}\n```\n\n## Migration Guides\n\n### From Flake8 + Black\n```bash\n# 1. Remove old tools\npip uninstall flake8 black isort\n\n# 2. Install ruff\npip install ruff\n\n# 3. Migrate configuration\n# Convert .flake8 + pyproject.toml[black]  pyproject.toml[ruff]\n\n# 4. Update pre-commit\n# Replace black, flake8, isort hooks with ruff\n\n# 5. Update CI/CD\n# Replace black/flake8 commands with ruff\n\n# 6. Test\nruff check --diff\nruff format --diff\n```\n\n### From pylint\n```bash\n# 1. Map pylint rules to ruff equivalents\n# Use ruff's PLxxx rules (pylint compatibility)\n\n# 2. Update configuration\n[tool.ruff.lint]\nselect = [\"E\", \"F\", \"B\", \"I\", \"UP\", \"PL\"]\n\n[tool.ruff.lint.pylint]\nmax-args = 10\nmax-branches = 15\n\n# 3. Test\nruff check --select PL\n```\n\n## Best Practices\n\n**Editor Setup**\n- Enable format-on-save for consistency\n- Configure code actions for auto-fixing\n- Use project-specific settings (`.vscode/settings.json`)\n- Sync settings across team via version control\n\n**Pre-commit Strategy**\n- Run both `ruff-check --fix` and `ruff-format`\n- Order: check first, then format\n- Include Jupyter notebooks if needed\n- Use `types_or` for file filtering\n\n**CI/CD Strategy**\n- Run checks on every PR\n- Use `--output-format github` for annotations\n- Check formatting with `--check --diff`\n- Consider auto-fixing with bot commits\n\n**Performance**\n- Use ruff's built-in parallelism (default)\n- Cache ruff in CI (pip cache, Docker layers)\n- Run on changed files only in pre-commit\n- Use separate jobs for linting and formatting\n\n**Common Mistakes to Avoid**\n- Mixing multiple formatters (choose one)\n- Not syncing editor config with project config\n- Ignoring LSP server errors\n- Not testing CI changes locally\n- Forgetting to update documentation\n\n## Quick Reference\n\n### Editor Setup Commands\n\n```bash\n# VS Code\ncode --install-extension charliermarsh.ruff\n\n# Neovim (using lazy.nvim)\n# Add to plugins: 'neovim/nvim-lspconfig'\n\n# Check LSP status\n:LspInfo\n```\n\n### Pre-commit Commands\n\n```bash\n# Setup\npre-commit install\npre-commit run --all-files\n\n# Update\npre-commit autoupdate\n\n# Skip hooks (emergency)\ngit commit --no-verify\n```\n\n### CI/CD Quick Start\n\n**GitHub Actions**\n```yaml\n- uses: astral-sh/ruff-action@v3\n```\n\n**GitLab CI**\n```yaml\nruff-check:\n  image: ghcr.io/astral-sh/ruff:0.14.0-alpine\n  script: ruff check\n```\n\n### Configuration Hierarchy\n\n1. Command-line arguments (highest priority)\n2. Editor LSP settings\n3. `ruff.toml` in current directory\n4. `pyproject.toml` in current directory\n5. Parent directory configs (recursive)\n6. User config: `~/.config/ruff/ruff.toml`\n7. Ruff defaults (lowest priority)\n\nThis makes ruff integration seamless across development tools and CI/CD pipelines."
              },
              {
                "name": "ruff Linting",
                "description": "Python code quality with ruff linter. Fast linting, rule selection, auto-fixing, and configuration. Use when checking Python code quality, enforcing standards, or finding bugs.",
                "path": "python-plugin/skills/ruff-linting/SKILL.md",
                "frontmatter": {
                  "created": "2025-12-16T00:00:00.000Z",
                  "modified": "2025-12-16T00:00:00.000Z",
                  "reviewed": "2025-12-16T00:00:00.000Z",
                  "name": "ruff Linting",
                  "description": "Python code quality with ruff linter. Fast linting, rule selection, auto-fixing, and configuration. Use when checking Python code quality, enforcing standards, or finding bugs.",
                  "allowed-tools": "Bash, Read, Edit, Write, Grep, Glob"
                },
                "content": "# ruff Linting\n\nExpert knowledge for using `ruff check` as an extremely fast Python linter with comprehensive rule support and automatic fixing.\n\n## Core Expertise\n\n**ruff Advantages**\n- Extremely fast (10-100x faster than Flake8)\n- Written in Rust for performance\n- Replaces multiple tools (Flake8, pylint, isort, pyupgrade, etc.)\n- Auto-fix capabilities for many rules\n- Compatible with existing configurations\n- Over 800 built-in rules\n\n## Basic Usage\n\n### Simple Linting\n```bash\n# Lint current directory\nruff check\n\n# Lint specific files or directories\nruff check path/to/file.py\nruff check src/ tests/\n\n# IMPORTANT: Pass directory as parameter to stay in repo root\n#  Good\nruff check services/orchestrator\n\n#  Bad\ncd services/orchestrator && ruff check\n```\n\n### Auto-Fixing\n```bash\n# Show what would be fixed (diff preview)\nruff check --diff\n\n# Apply safe automatic fixes\nruff check --fix\n\n# Fix specific files\nruff check --fix src/main.py\n\n# Fix with preview (see changes before applying)\nruff check --diff services/orchestrator\nruff check --fix services/orchestrator\n```\n\n### Output Formats\n```bash\n# Default output\nruff check\n\n# Show statistics\nruff check --statistics\n\n# JSON output for tooling\nruff check --output-format json\n\n# GitHub Actions annotations\nruff check --output-format github\n\n# GitLab Code Quality report\nruff check --output-format gitlab\n\n# Concise output\nruff check --output-format concise\n```\n\n## Rule Selection\n\n### Common Rule Codes\n\n| Code | Description | Example Rules |\n|------|-------------|---------------|\n| `E` | pycodestyle errors | E501 (line too long) |\n| `F` | Pyflakes | F401 (unused import) |\n| `W` | pycodestyle warnings | W605 (invalid escape) |\n| `B` | flake8-bugbear | B006 (mutable default) |\n| `I` | isort | I001 (unsorted imports) |\n| `UP` | pyupgrade | UP006 (deprecated types) |\n| `SIM` | flake8-simplify | SIM102 (nested if) |\n| `D` | pydocstyle | D100 (missing docstring) |\n| `N` | pep8-naming | N806 (variable naming) |\n| `S` | flake8-bandit (security) | S101 (assert usage) |\n| `C4` | flake8-comprehensions | C400 (unnecessary generator) |\n\n### Selecting Rules\n```bash\n# Select specific rules at runtime\nruff check --select E,F,B,I\n\n# Extend default selection\nruff check --extend-select UP,SIM\n\n# Ignore specific rules\nruff check --ignore E501,E402\n\n# Show which rules would apply\nruff rule --all\n\n# Explain a specific rule\nruff rule F401\n```\n\n### Rule Queries\n```bash\n# List all available rules\nruff rule --all\n\n# Search for rules by pattern\nruff rule --all | grep \"import\"\n\n# Get detailed rule explanation\nruff rule F401\n# Output: unused-import (F401)\n#   Derived from the Pyflakes linter.\n#   Checks for unused imports.\n\n# List all linters\nruff linter\n\n# JSON output for automation\nruff rule F401 --output-format json\n```\n\n## Configuration\n\n### pyproject.toml\n```toml\n[tool.ruff]\n# Line length limit (same as Black)\nline-length = 88\n\n# Target Python version\ntarget-version = \"py311\"\n\n# Exclude directories\nexclude = [\n    \".git\",\n    \".venv\",\n    \"__pycache__\",\n    \"build\",\n    \"dist\",\n]\n\n[tool.ruff.lint]\n# Enable specific rule sets\nselect = [\n    \"E\",   # pycodestyle errors\n    \"F\",   # Pyflakes\n    \"B\",   # flake8-bugbear\n    \"I\",   # isort\n    \"UP\",  # pyupgrade\n    \"SIM\", # flake8-simplify\n]\n\n# Disable specific rules\nignore = [\n    \"E501\",  # Line too long (handled by formatter)\n    \"B008\",  # Function calls in argument defaults\n]\n\n# Allow automatic fixes\nfixable = [\"ALL\"]\nunfixable = [\"B\"]  # Don't auto-fix bugbear rules\n\n# Per-file ignores\n[tool.ruff.lint.per-file-ignores]\n\"__init__.py\" = [\"F401\", \"E402\"]\n\"tests/**/*.py\" = [\"S101\"]  # Allow assert in tests\n```\n\n### ruff.toml (standalone)\n```toml\n# Same options as pyproject.toml but without [tool.ruff] prefix\nline-length = 100\ntarget-version = \"py39\"\n\n[lint]\nselect = [\"E\", \"F\", \"B\"]\nignore = [\"E501\"]\n\n[lint.isort]\nknown-first-party = [\"myapp\"]\nforce-single-line = true\n```\n\n## Advanced Usage\n\n### Per-File Configuration\n```bash\n# Override settings for specific paths\nruff check --config path/to/ruff.toml\n\n# Use inline configuration\nruff check --select E,F,B --ignore E501\n```\n\n### Targeting Specific Issues\n```bash\n# Check only specific rule codes\nruff check --select F401,F841  # Only unused imports/variables\n\n# Security-focused check\nruff check --select S  # All bandit rules\n\n# Import organization only\nruff check --select I --fix\n\n# Docstring checks\nruff check --select D\n```\n\n### Integration Patterns\n```bash\n# Check only changed files (git)\ngit diff --name-only --diff-filter=d | grep '\\.py$' | xargs ruff check\n\n# Check files modified in branch\ngit diff --name-only main...HEAD | grep '\\.py$' | xargs ruff check\n\n# Parallel checking of multiple directories\nruff check src/ &\nruff check tests/ &\nwait\n\n# Combine with other tools\nruff check && pytest && mypy\n```\n\n## CI/CD Integration\n\n### Pre-commit Hook\n```yaml\n# .pre-commit-config.yaml\nrepos:\n  - repo: https://github.com/astral-sh/ruff-pre-commit\n    rev: v0.14.0\n    hooks:\n      # Linter with auto-fix\n      - id: ruff-check\n        args: [--fix]\n\n      # Advanced configuration\n      - id: ruff-check\n        name: Ruff linter\n        args:\n          - --fix\n          - --config=pyproject.toml\n          - --select=E,F,B,I\n        types_or: [python, pyi, jupyter]\n```\n\n### GitHub Actions\n```yaml\n# .github/workflows/lint.yml\nname: Lint\n\non: [push, pull_request]\n\njobs:\n  lint:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n\n      - uses: astral-sh/ruff-action@v3\n        with:\n          args: 'check --output-format github'\n          changed-files: 'true'\n\n      # Or using pip\n      - name: Install ruff\n        run: pip install ruff\n\n      - name: Run linter\n        run: ruff check --output-format github\n```\n\n### GitLab CI\n```yaml\n# .gitlab-ci.yml\nRuff Check:\n  stage: build\n  image: ghcr.io/astral-sh/ruff:0.14.0-alpine\n  script:\n    - ruff check --output-format=gitlab > code-quality-report.json\n  artifacts:\n    reports:\n      codequality: code-quality-report.json\n```\n\n## Common Patterns\n\n### Finding Specific Issues\n```bash\n# Find unused imports\nruff check --select F401\n\n# Find mutable default arguments\nruff check --select B006\n\n# Find deprecated type usage\nruff check --select UP006\n\n# Security issues\nruff check --select S\n\n# Code complexity\nruff check --select C901\n\n# Find all TODOs\nruff check --select FIX  # flake8-fixme\n```\n\n### Gradual Adoption\n```bash\n# Start with minimal rules\nruff check --select E,F\n\n# Add bugbear\nruff check --select E,F,B\n\n# Add import sorting\nruff check --select E,F,B,I --fix\n\n# Add pyupgrade\nruff check --select E,F,B,I,UP --fix\n\n# Generate baseline configuration\nruff check --select ALL --ignore <violations> > ruff-baseline.toml\n```\n\n### Refactoring Support\n```bash\n# Auto-fix all safe violations\nruff check --fix\n\n# Preview changes before fixing\nruff check --diff | less\n\n# Fix only imports\nruff check --select I --fix\n\n# Modernize code\nruff check --select UP --fix\n\n# Simplify comprehensions\nruff check --select C4,SIM --fix\n```\n\n## Plugin Configuration\n\n### isort (Import Sorting)\n```toml\n[tool.ruff.lint.isort]\ncombine-as-imports = true\nknown-first-party = [\"myapp\"]\nsection-order = [\"future\", \"standard-library\", \"third-party\", \"first-party\", \"local-folder\"]\n```\n\n### flake8-quotes\n```toml\n[tool.ruff.lint.flake8-quotes]\ndocstring-quotes = \"double\"\ninline-quotes = \"single\"\nmultiline-quotes = \"double\"\n```\n\n### pydocstyle\n```toml\n[tool.ruff.lint.pydocstyle]\nconvention = \"google\"  # or \"numpy\", \"pep257\"\n```\n\n### pylint\n```toml\n[tool.ruff.lint.pylint]\nmax-args = 10\nmax-branches = 15\nmax-returns = 8\nmax-statements = 60\n```\n\n## Best Practices\n\n**When to Use ruff check**\n- Code quality enforcement\n- Pre-commit validation\n- CI/CD pipelines\n- Refactoring assistance\n- Security scanning\n- Import organization\n\n**Critical: Directory Parameters**\n-  **Always** pass directory as parameter: `ruff check services/orchestrator`\n-  **Never** use cd: `cd services/orchestrator && ruff check`\n- Reason: Parallel execution, clearer output, tool compatibility\n\n**Rule Selection Strategy**\n1. Start minimal: `select = [\"E\", \"F\"]` (errors + pyflakes)\n2. Add bugbear: `select = [\"E\", \"F\", \"B\"]`\n3. Add imports: `select = [\"E\", \"F\", \"B\", \"I\"]`\n4. Add pyupgrade: `select = [\"E\", \"F\", \"B\", \"I\", \"UP\"]`\n5. Consider security: `select = [\"E\", \"F\", \"B\", \"I\", \"UP\", \"S\"]`\n\n**Fixable vs Unfixable**\n- Mark uncertain rules as `unfixable` to review manually\n- Common unfixables: `B` (bugbear), `F` (pyflakes F401)\n- Let ruff fix safe rules: `I` (isort), `UP` (pyupgrade)\n\n**Common Mistakes to Avoid**\n- Using `cd` instead of passing directory parameter\n- Enabling ALL rules immediately (use gradual adoption)\n- Not using `--diff` before `--fix`\n- Ignoring rule explanations (`ruff rule <code>`)\n- Not configuring per-file ignores for special cases\n\n## Quick Reference\n\n### Essential Commands\n\n```bash\n# Basic operations\nruff check                          # Lint current directory\nruff check path/to/dir              # Lint specific directory\nruff check --diff                   # Show fix preview\nruff check --fix                    # Apply fixes\n\n# Rule management\nruff rule --all                     # List all rules\nruff rule F401                      # Explain rule F401\nruff linter                         # List all linters\n\n# Output formats\nruff check --statistics             # Show violation counts\nruff check --output-format json     # JSON output\nruff check --output-format github   # GitHub Actions format\n\n# Selection\nruff check --select E,F,B          # Select rules\nruff check --ignore E501           # Ignore rules\nruff check --extend-select UP      # Extend selection\n```\n\n### Configuration Hierarchy\n\n1. Command-line arguments (highest priority)\n2. `ruff.toml` in current directory\n3. `pyproject.toml` in current directory\n4. Parent directory configs (recursive)\n5. User config: `~/.config/ruff/ruff.toml`\n\n### Common Rule Combinations\n\n```bash\n# Minimal safety\nruff check --select E,F\n\n# Good default\nruff check --select E,F,B,I\n\n# Comprehensive\nruff check --select E,F,B,I,UP,SIM\n\n# Security-focused\nruff check --select E,F,B,S\n\n# Docstring enforcement\nruff check --select D --config '[lint.pydocstyle]\\nconvention = \"google\"'\n```\n\nThis makes ruff check the preferred tool for fast, comprehensive Python code linting."
              },
              {
                "name": "uv-advanced-dependencies",
                "description": "Advanced dependency scenarios in uv projects: Git dependencies, path dependencies,\neditable installs, dependency groups, extras, constraints, and custom indexes.\nUse when user mentions git+https dependencies, local path dependencies, editable\ninstalls, dependency groups, or private package indexes.\n",
                "path": "python-plugin/skills/uv-advanced-dependencies/SKILL.md",
                "frontmatter": {
                  "created": "2025-12-16T00:00:00.000Z",
                  "modified": "2025-12-16T00:00:00.000Z",
                  "reviewed": "2025-12-16T00:00:00.000Z",
                  "name": "uv-advanced-dependencies",
                  "description": "Advanced dependency scenarios in uv projects: Git dependencies, path dependencies,\neditable installs, dependency groups, extras, constraints, and custom indexes.\nUse when user mentions git+https dependencies, local path dependencies, editable\ninstalls, dependency groups, or private package indexes.\n"
                },
                "content": "# UV Advanced Dependencies\n\nQuick reference for advanced dependency scenarios in UV projects.\n\n## When This Skill Applies\n\n- Git repository dependencies\n- Local path dependencies\n- Editable installations\n- Dependency constraints\n- Custom package indexes\n- Dependency groups and extras\n- Build dependencies\n\n## Quick Reference\n\n### Git Dependencies\n\n```bash\n# Add from Git repository\nuv add git+https://github.com/psf/requests\nuv add git+https://github.com/pallets/flask@main\nuv add git+ssh://git@github.com/user/repo.git@v1.0.0\n\n# Specific branch, tag, or commit\nuv add git+https://github.com/user/repo@feature-branch\nuv add git+https://github.com/user/repo@v2.0.0\nuv add git+https://github.com/user/repo@abc123\n```\n\n### Path Dependencies\n\n```bash\n# Add from local path\nuv add --editable ./local-package\nuv add ../another-project\nuv add /absolute/path/to/package\n\n# Non-editable path\nuv add --no-editable ./local-package\n```\n\n### Dependency Groups\n\n```bash\n# Add to named group\nuv add --group docs sphinx mkdocs\nuv add --group test pytest pytest-cov\n\n# Install specific groups\nuv sync --group docs\nuv sync --group test --group docs\n\n# Install all groups\nuv sync --all-groups\n```\n\n### Extras (Optional Dependencies)\n\n```bash\n# Install package with extras\nuv add 'fastapi[all]'\nuv add 'sqlalchemy[postgresql,mypy]'\n\n# Define extras in pyproject.toml\n[project.optional-dependencies]\ndev = [\"pytest\", \"ruff\"]\ndocs = [\"mkdocs\", \"mkdocs-material\"]\n```\n\n### Constraint Files\n\n```bash\n# Apply version constraints\nuv pip compile requirements.in --constraint constraints.txt\n\n# constraints.txt example:\n# numpy<2.0\n# pandas==2.0.3\n```\n\n### Custom Indexes\n\n```toml\n[tool.uv]\nindex-url = \"https://pypi.org/simple\"\nextra-index-url = [\n    \"https://custom.pypi.org/simple\",\n]\n```\n\n## Git Dependencies in pyproject.toml\n\n```toml\n[project]\ndependencies = [\n    \"my-package\",\n]\n\n[tool.uv.sources]\nmy-package = { git = \"https://github.com/user/my-package\" }\n\n# With branch\nmy-package = { git = \"https://github.com/user/my-package\", branch = \"main\" }\n\n# With tag\nmy-package = { git = \"https://github.com/user/my-package\", tag = \"v1.0.0\" }\n\n# With commit\nmy-package = { git = \"https://github.com/user/my-package\", rev = \"abc123\" }\n```\n\n## Path Dependencies in pyproject.toml\n\n```toml\n[project]\ndependencies = [\n    \"my-local-package\",\n]\n\n[tool.uv.sources]\nmy-local-package = { path = \"../my-local-package\" }\n\n# Editable (default for paths)\nmy-local-package = { path = \"../my-local-package\", editable = true }\n\n# Non-editable\nmy-local-package = { path = \"../my-local-package\", editable = false }\n```\n\n## Dependency Groups\n\n```toml\n[dependency-groups]\ndev = [\n    \"pytest>=7.0\",\n    \"pytest-cov>=4.0\",\n    \"ruff>=0.1.0\",\n]\ndocs = [\n    \"mkdocs-material>=9.0\",\n    \"mkdocstrings[python]>=0.24\",\n]\ntest = [\n    \"pytest-asyncio>=0.21\",\n    \"pytest-mock>=3.12\",\n]\n```\n\n## URL Dependencies\n\n```bash\n# Add from direct URL\nuv add https://files.pythonhosted.org/packages/.../requests-2.31.0.tar.gz\n\n# In pyproject.toml\n[tool.uv.sources]\nmy-package = { url = \"https://example.com/my-package-1.0.tar.gz\" }\n```\n\n## Private Package Indexes\n\n```toml\n[tool.uv]\n# Primary index\nindex-url = \"https://pypi.org/simple\"\n\n# Additional indexes\nextra-index-url = [\n    \"https://${PRIVATE_TOKEN}@private.pypi.org/simple\",\n]\n\n# Find links\nfind-links = [\n    \"https://download.pytorch.org/whl/cu118\",\n]\n```\n\n```bash\n# Set token via environment\nexport PRIVATE_TOKEN=\"secret\"\nuv sync\n```\n\n## Build Dependencies\n\n```toml\n[build-system]\nrequires = [\n    \"setuptools>=68\",\n    \"wheel\",\n    \"Cython>=3.0\",\n]\nbuild-backend = \"setuptools.build_meta\"\n```\n\n## Common Patterns\n\n### Development from Local Checkout\n\n```bash\n# Clone dependency\ngit clone https://github.com/user/lib.git ../lib\n\n# Add as editable\ncd my-project\nuv add --editable ../lib\n```\n\n### Monorepo Path Dependencies\n\n```toml\n[tool.uv.sources]\nmy-core = { path = \"packages/core\" }\nmy-utils = { path = \"packages/utils\" }\n```\n\n### Mixed Sources\n\n```toml\n[project]\ndependencies = [\n    \"fastapi\",          # PyPI\n    \"my-lib\",           # Git\n    \"my-local\",         # Path\n]\n\n[tool.uv.sources]\nmy-lib = { git = \"https://github.com/user/my-lib\" }\nmy-local = { path = \"../my-local\" }\n```\n\n## Resolution Strategies\n\n```toml\n[tool.uv]\n# Highest compatible (default)\nresolution = \"highest\"\n\n# Lowest compatible\nresolution = \"lowest\"\n\n# Lowest direct, highest transitive\nresolution = \"lowest-direct\"\n```\n\n## See Also\n\n- `uv-project-management` - Basic dependency management\n- `uv-workspaces` - Workspace member dependencies\n- `python-packaging` - Build system configuration\n\n## References\n\n- Official docs: https://docs.astral.sh/uv/concepts/dependencies/\n- Detailed guide: See REFERENCE.md in this skill directory"
              },
              {
                "name": "uv-project-management",
                "description": "Python project setup, dependencies, and lockfiles with uv package manager. Covers\nuv init, uv add, uv remove, uv lock, uv sync, and pyproject.toml configuration.\nUse when user mentions uv, creating Python projects, managing dependencies,\nlockfiles, pyproject.toml, or Python packaging with uv.\n",
                "path": "python-plugin/skills/uv-project-management/SKILL.md",
                "frontmatter": {
                  "created": "2025-12-16T00:00:00.000Z",
                  "modified": "2025-12-16T00:00:00.000Z",
                  "reviewed": "2025-12-16T00:00:00.000Z",
                  "name": "uv-project-management",
                  "description": "Python project setup, dependencies, and lockfiles with uv package manager. Covers\nuv init, uv add, uv remove, uv lock, uv sync, and pyproject.toml configuration.\nUse when user mentions uv, creating Python projects, managing dependencies,\nlockfiles, pyproject.toml, or Python packaging with uv.\n"
                },
                "content": "# UV Project Management\n\nQuick reference for UV project setup, dependencies, and lockfiles.\n\n## When This Skill Applies\n\n- Initializing new Python projects (`uv init`)\n- Adding, removing, or updating dependencies (`uv add`, `uv remove`)\n- Managing lockfiles (`uv lock`)\n- Syncing project environments (`uv sync`)\n- Configuring pyproject.toml\n\nFor running scripts, see **uv-run** skill.\n\n## Quick Reference\n\n### Project Initialization\n\n```bash\n# Create new project with complete structure\nuv init my-project\ncd my-project\n\n# Initialize in existing directory\nuv init\n\n# Initialize with specific Python version\nuv init --python 3.11 my-app\n```\n\n### Dependency Management\n\n```bash\n# Add dependencies\nuv add requests\nuv add 'flask>=2.0'\nuv add 'django>=4.0,<5.0'\n\n# Add development dependencies\nuv add --dev pytest pytest-cov black\n\n# Add optional dependency groups\nuv add --group docs sphinx sphinx-rtd-theme\n\n# Remove dependencies\nuv remove requests flask\n\n# Migrate from requirements.txt\nuv add -r requirements.txt\n```\n\n### Lockfile Operations\n\n```bash\n# Create/update lockfile (uv.lock)\nuv lock\n\n# Lock with upgraded packages\nuv lock --upgrade-package requests\nuv lock --upgrade\n\n# Lock without installing (CI/CD)\nuv lock --frozen\n```\n\n### Environment Synchronization\n\n```bash\n# Sync environment to lockfile\nuv sync\n\n# Sync without updating lockfile\nuv sync --frozen\n\n# Error if lockfile is out of date\nuv sync --locked\n```\n\n## Project Structure\n\nUV projects follow this standard structure:\n\n```\nmy-project/\n pyproject.toml      # Project metadata and dependencies\n uv.lock            # Locked dependency versions\n .venv/             # Virtual environment (auto-created)\n README.md\n src/\n     my_project/\n         __init__.py\n```\n\n## Generated pyproject.toml\n\n```toml\n[project]\nname = \"my-project\"\nversion = \"0.1.0\"\ndescription = \"Add your description here\"\nreadme = \"README.md\"\ndependencies = []\n\n[build-system]\nrequires = [\"uv_build>=0.9.2,<0.10.0\"]\nbuild-backend = \"uv_build\"\n```\n\n## Common Workflows\n\n### Starting a New Project\n\n```bash\nuv init my-app && cd my-app\nuv add ruff pytest\nuv run pytest\n```\n\n### Adding Multiple Dependencies\n\n```bash\n# Production dependencies\nuv add fastapi uvicorn 'pydantic>=2.0'\n\n# Development tooling\nuv add --dev pytest pytest-cov ruff mypy\n\n# Documentation\nuv add --group docs sphinx mkdocs-material\n```\n\n### Updating Dependencies\n\n```bash\n# Update specific package\nuv lock --upgrade-package requests\n\n# Update all dependencies\nuv lock --upgrade\n\n# Sync after update\nuv sync\n```\n\n## Key Features\n\n- **Fast**: 10-100x faster than pip\n- **Deterministic**: Lockfile ensures reproducible installs\n- **Automatic**: Creates and manages virtual environments\n- **Modern**: Uses pyproject.toml for configuration\n- **Compatible**: Works with pip, Poetry, and other tools\n\n## See Also\n\n- **uv-run** - Running scripts, temporary dependencies, PEP 723\n- **uv-python-versions** - Managing Python interpreter versions\n- **uv-workspaces** - Monorepo and multi-package projects\n- **uv-advanced-dependencies** - Git, path, and constraint dependencies\n- **uv-tool-management** - Installing CLI tools globally\n- **python-testing** - Running tests with pytest\n- **python-code-quality** - Linting and formatting with ruff\n\n## References\n\n- Official docs: https://docs.astral.sh/uv/\n- GitHub: https://github.com/astral-sh/uv\n- Detailed guide: See REFERENCE.md in this skill directory"
              },
              {
                "name": "uv-python-versions",
                "description": "Install and manage Python interpreter versions with uv. Covers uv python install,\nuv python list, uv python pin, version pinning with .python-version file.\nUse when user mentions installing Python versions, switching Python versions,\n.python-version, uv python, or managing CPython/PyPy interpreters.\n",
                "path": "python-plugin/skills/uv-python-versions/SKILL.md",
                "frontmatter": {
                  "created": "2025-12-16T00:00:00.000Z",
                  "modified": "2025-12-16T00:00:00.000Z",
                  "reviewed": "2025-12-16T00:00:00.000Z",
                  "name": "uv-python-versions",
                  "description": "Install and manage Python interpreter versions with uv. Covers uv python install,\nuv python list, uv python pin, version pinning with .python-version file.\nUse when user mentions installing Python versions, switching Python versions,\n.python-version, uv python, or managing CPython/PyPy interpreters.\n"
                },
                "content": "# UV Python Version Management\n\nQuick reference for installing and managing Python interpreter versions with UV.\n\n## When This Skill Applies\n\n- Installing specific Python versions\n- Switching between multiple Python versions\n- Pinning Python versions for projects\n- Managing CPython and PyPy interpreters\n- Finding and listing installed Python versions\n\n## Quick Reference\n\n### Installing Python Versions\n\n```bash\n# Install latest Python\nuv python install\n\n# Install specific version\nuv python install 3.11\nuv python install 3.12\nuv python install 3.10 3.11 3.12\n\n# Install exact version\nuv python install 3.11.5\nuv python install cpython@3.11.5\n\n# Install PyPy\nuv python install pypy@3.9\nuv python install pypy@3.10\n```\n\n### Listing Python Versions\n\n```bash\n# List all available versions\nuv python list\n\n# List only installed versions\nuv python list --only-installed\n\n# List with verbose details\nuv python list --verbose\n```\n\n### Pinning Python Versions\n\n```bash\n# Pin version for current project\nuv python pin 3.11\nuv python pin 3.12.1\n\n# Pin PyPy\nuv python pin pypy@3.9\n\n# Pin with version file\n# Creates/updates .python-version\n```\n\n### Finding Python Interpreters\n\n```bash\n# Find any Python installation\nuv python find\n\n# Find specific version\nuv python find 3.11\nuv python find 3.12\n\n# Find PyPy\nuv python find pypy\nuv python find pypy@3.9\n```\n\n### Using Specific Python Versions\n\n```bash\n# In project commands\nuv run --python 3.11 script.py\nuv run --python 3.12 pytest\n\n# Creating virtual environments\nuv venv --python 3.11\nuv venv --python 3.10 .venv-py310\n\n# Initializing projects\nuv init --python 3.12 my-project\n```\n\n## Python Version Sources\n\nUV searches for Python in this order:\n1. **UV-managed** - Installed via `uv python install`\n2. **.python-version** - Pin file in project directory\n3. **pyproject.toml** - `requires-python` field\n4. **System Python** - Existing system installations\n5. **Environment** - `$PATH` and standard locations\n\n## Version Pinning\n\n### .python-version File\n\n```bash\n# Pin creates this file\nuv python pin 3.11\n\n# File contents\n3.11\n\n# Exact version\nuv python pin 3.11.5\n```\n\n### pyproject.toml\n\n```toml\n[project]\nrequires-python = \">=3.11\"\n\n# UV respects this constraint\n```\n\n## Supported Python Implementations\n\n### CPython\n\n```bash\n# Default implementation\nuv python install 3.11\nuv python install cpython@3.11\nuv python install cpython@3.11.5\n```\n\n### PyPy\n\n```bash\n# Alternative Python implementation\nuv python install pypy@3.9\nuv python install pypy@3.10\n```\n\n## Common Commands\n\n```bash\n# Install and pin latest Python 3.12\nuv python install 3.12 && uv python pin 3.12\n\n# Install multiple versions for testing\nuv python install 3.10 3.11 3.12\n\n# Check which Python is active\nuv python find\nuv run python --version\n\n# Uninstall version (manual)\nrm -rf ~/.local/share/uv/python/cpython-3.11.5-*\n```\n\n## Integration with Projects\n\n### Project Initialization\n\n```bash\n# Initialize with specific Python\nuv init --python 3.11 my-project\n\n# Generates .python-version\ncat .python-version\n# 3.11\n```\n\n### Running Commands\n\n```bash\n# Use project's pinned Python\nuv run python script.py\n\n# Override with specific version\nuv run --python 3.12 script.py\n\n# Use system Python\nuv run --python python3 script.py\n```\n\n## Multi-Version Testing\n\n```bash\n# Test across Python versions\nuv run --python 3.10 pytest\nuv run --python 3.11 pytest\nuv run --python 3.12 pytest\n\n# Create version-specific venvs\nuv venv --python 3.10 .venv-py310\nuv venv --python 3.11 .venv-py311\nuv venv --python 3.12 .venv-py312\n```\n\n## Key Features\n\n- **Fast downloads**: Parallel downloads with caching\n- **Automatic**: Downloads versions on-demand\n- **Isolated**: UV-managed versions don't conflict with system Python\n- **Portable**: Uses standalone Python distributions\n- **Cross-platform**: Works on Linux, macOS, and Windows\n\n## See Also\n\n- `uv-project-management` - Using pinned Python versions in projects\n- `uv-workspaces` - Python versions in monorepos\n- `python-testing` - Testing across multiple Python versions\n\n## References\n\n- Official docs: https://docs.astral.sh/uv/guides/install-python/\n- Python standalone builds: https://github.com/indygreg/python-build-standalone\n- Detailed guide: See REFERENCE.md in this skill directory"
              },
              {
                "name": "uv-run",
                "description": "Run Python scripts with uv including inline dependencies (PEP 723),\ntemporary dependencies (--with), and ephemeral tool execution.\nUse when running scripts, needing one-off dependencies, or creating\nexecutable Python scripts. No venv activation required.\n",
                "path": "python-plugin/skills/uv-run/SKILL.md",
                "frontmatter": {
                  "created": "2025-12-16T00:00:00.000Z",
                  "modified": "2025-12-16T00:00:00.000Z",
                  "reviewed": "2025-12-16T00:00:00.000Z",
                  "name": "uv-run",
                  "description": "Run Python scripts with uv including inline dependencies (PEP 723),\ntemporary dependencies (--with), and ephemeral tool execution.\nUse when running scripts, needing one-off dependencies, or creating\nexecutable Python scripts. No venv activation required.\n",
                  "allowed-tools": "Glob, Grep, Read, WebFetch, TodoWrite, WebSearch, BashOutput, KillShell, Edit, Write, NotebookEdit, Bash"
                },
                "content": "# UV Run\n\nRun Python scripts with uv - no manual venv activation needed.\n\n## Core Capabilities\n\n- **Direct execution**: `uv run script.py` handles environment automatically\n- **Temporary dependencies**: `uv run --with requests script.py` for one-off needs\n- **Inline dependencies**: PEP 723 metadata blocks for self-contained scripts\n- **Ephemeral tools**: `uvx tool` runs CLI tools without installation\n\n## Essential Commands\n\n### Running Scripts\n\n```bash\n# Run script (uv manages environment automatically)\nuv run script.py\n\n# Run with arguments\nuv run script.py --input data.csv --output results.json\n\n# Run a specific module\nuv run -m http.server 8000\n\n# Run with specific Python version\nuv run --python 3.12 script.py\n```\n\n### Temporary Dependencies\n\nAdd dependencies for a single run without modifying project:\n\n```bash\n# Single dependency\nuv run --with requests fetch_data.py\n\n# Multiple dependencies\nuv run --with requests --with rich api_client.py\n\n# Version constraints\nuv run --with 'requests>=2.31' --with 'rich>12,<14' script.py\n\n# Combine with project dependencies\nuv run --with pytest-benchmark pytest  # Add benchmark to existing pytest\n```\n\n### Inline Script Dependencies (PEP 723)\n\nCreate self-contained scripts with embedded dependencies:\n\n```python\n#!/usr/bin/env -S uv run --script\n# /// script\n# requires-python = \">=3.11\"\n# dependencies = [\n#   \"requests>=2.31\",\n#   \"rich>=13.0\",\n# ]\n# ///\n\nimport requests\nfrom rich import print\n\nresponse = requests.get(\"https://api.github.com\")\nprint(response.json())\n```\n\nRun directly:\n```bash\nuv run script.py\n\n# Or make executable:\nchmod +x script.py\n./script.py\n```\n\n### Managing Script Dependencies\n\n```bash\n# Initialize script with metadata\nuv init --script example.py --python 3.12\n\n# Add dependency to script\nuv add --script example.py requests rich\n\n# Lock script dependencies for reproducibility\nuv lock --script example.py\n```\n\n### Ephemeral Tool Execution (uvx)\n\nRun CLI tools without installation:\n\n```bash\n# Run tool once\nuvx pycowsay \"Hello from uv!\"\nuvx httpie https://api.github.com\nuvx ruff check .\n\n# With specific version\nuvx ruff@0.1.0 check .\n\n# uvx is shorthand for:\nuv tool run pycowsay \"Hello\"\n```\n\n## Shebang Patterns\n\n### Self-Contained Executable Script\n\n```python\n#!/usr/bin/env -S uv run --script\n# /// script\n# dependencies = [\"click\", \"rich\"]\n# ///\n\nimport click\nfrom rich import print\n\n@click.command()\n@click.argument('name')\ndef hello(name):\n    print(f\"[green]Hello, {name}![/green]\")\n\nif __name__ == \"__main__\":\n    hello()\n```\n\n### Script with Python Version Requirement\n\n```python\n#!/usr/bin/env -S uv run --script --python 3.12\n# /// script\n# requires-python = \">=3.12\"\n# dependencies = [\"httpx\"]\n# ///\n\nimport httpx\n# Uses Python 3.12+ features\n```\n\n## When to Use Each Pattern\n\n| Scenario | Approach |\n|----------|----------|\n| Quick one-off task | `uv run --with pkg script.py` |\n| Reusable script | Inline deps (PEP 723) |\n| Shareable utility | PEP 723 + shebang |\n| Team collaboration | Inline deps + `uv lock --script` |\n| Run CLI tool once | `uvx tool` |\n| Project scripts | `uv run` (uses project deps) |\n\n## uvx vs uv run --with\n\n- **`uvx tool`**: Run a CLI **tool** without installation (e.g., `uvx ruff check .`)\n- **`uv run --with pkg`**: Run a **script** with temporary dependencies (e.g., `uv run --with requests script.py`)\n\n```bash\n# Run a tool (CLI application)\nuvx httpie https://api.github.com\n\n# Run a script with dependencies\nuv run --with httpx api_test.py\n```\n\n## Profiling and Debugging\n\n```bash\n# CPU profiling\nuv run python -m cProfile -s cumtime script.py | head -20\n\n# Line-by-line profiling (temporary dependency)\nuv run --with line-profiler kernprof -l -v script.py\n\n# Memory profiling\nuv run --with memory-profiler python -m memory_profiler script.py\n\n# Real-time profiling (ephemeral tool)\nuvx py-spy top -- python script.py\n\n# Quick profiling\nuv run --with scalene python -m scalene script.py\n```\n\n## See Also\n\n- **uv-project-management** - Project dependencies and lockfiles\n- **uv-tool-management** - Installing CLI tools globally\n- **python-development** - Core Python language patterns\n\n## References\n\n- Official docs: https://docs.astral.sh/uv/guides/scripts/\n- PEP 723: https://peps.python.org/pep-0723/\n- Tools: https://docs.astral.sh/uv/guides/tools/"
              },
              {
                "name": "uv-tool-management",
                "description": "Install and manage global Python CLI tools with uv (pipx alternative). Covers\nuv tool install, uvx for ephemeral execution, tool isolation, and updates.\nUse when user mentions uv tool, uvx, installing CLI tools globally, pipx\nreplacement, or running Python tools without installation.\n",
                "path": "python-plugin/skills/uv-tool-management/SKILL.md",
                "frontmatter": {
                  "created": "2025-12-16T00:00:00.000Z",
                  "modified": "2025-12-16T00:00:00.000Z",
                  "reviewed": "2025-12-16T00:00:00.000Z",
                  "name": "uv-tool-management",
                  "description": "Install and manage global Python CLI tools with uv (pipx alternative). Covers\nuv tool install, uvx for ephemeral execution, tool isolation, and updates.\nUse when user mentions uv tool, uvx, installing CLI tools globally, pipx\nreplacement, or running Python tools without installation.\n"
                },
                "content": "# UV Tool Management\n\nQuick reference for installing and managing global Python tools with UV (pipx alternative).\n\n## When This Skill Applies\n\n- Installing command-line tools globally (like pipx)\n- Managing tool installations and updates\n- Running tools ephemerally without installation\n- Listing and removing installed tools\n- Tool version management\n\n## Quick Reference\n\n### Installing Tools\n\n```bash\n# Install tool globally\nuv tool install ruff\nuv tool install black\nuv tool install pytest\n\n# Install specific version\nuv tool install ruff@0.1.0\nuv tool install 'pytest>=7.0'\n\n# Install from Git\nuv tool install git+https://github.com/astral-sh/ruff\n\n# Install with extras\nuv tool install 'mkdocs[i18n]'\nuv tool install 'fastapi[all]'\n```\n\n### Running Tools\n\n```bash\n# Run without installing (ephemeral)\nuvx pycowsay \"hello world\"\nuvx ruff check .\nuvx black --check .\n\n# uvx is alias for:\nuv tool run pycowsay \"hello world\"\n\n# Run with specific version\nuvx ruff@0.1.0 check .\n\n# Run from Git\nuvx git+https://github.com/user/tool script.py\n```\n\n### Managing Tools\n\n```bash\n# List installed tools\nuv tool list\n\n# Update tool\nuv tool install ruff --reinstall\nuv tool upgrade ruff\n\n# Remove tool\nuv tool uninstall ruff\n\n# Remove all tools\nuv tool uninstall --all\n```\n\n### Tool Information\n\n```bash\n# Check tool version\nruff --version\n\n# List tool binaries\nuv tool list --verbose\n\n# Show tool location\nwhich ruff\n# ~/.local/bin/ruff (Linux)\n# ~/Library/Application Support/uv/bin/ruff (macOS)\n```\n\n## uvx vs uv tool run\n\nThese commands are equivalent:\n\n```bash\nuvx ruff check .\nuv tool run ruff check .\n```\n\n`uvx` is a convenient shorthand for ephemeral tool execution.\n\n## Installation Locations\n\n### Tools Directory\n\n```bash\n# Linux\n~/.local/share/uv/tools/\n\n# macOS\n~/Library/Application Support/uv/tools/\n\n# Windows\n%LOCALAPPDATA%\\uv\\tools\\\n```\n\n### Binaries (Executables)\n\n```bash\n# Linux\n~/.local/bin/\n\n# macOS\n~/Library/Application Support/uv/bin/\n\n# Windows\n%LOCALAPPDATA%\\uv\\bin\\\n```\n\n**Add to PATH:**\n```bash\n# Add to ~/.bashrc or ~/.zshrc\nexport PATH=\"$HOME/.local/bin:$PATH\"\n```\n\n## Common Tools\n\n```bash\n# Code quality\nuv tool install ruff\nuv tool install black\nuv tool install mypy\n\n# Documentation\nuv tool install mkdocs\nuv tool install sphinx\n\n# Testing\nuv tool install pytest\nuv tool install tox\n\n# Build tools\nuv tool install build\nuv tool install twine\n\n# Utilities\nuv tool install httpie\nuv tool install pipx\nuv tool install cookiecutter\n```\n\n## UV Tool vs Project Dependencies\n\n**Use `uv tool` for:**\n- Command-line applications\n- Global development tools\n- Utilities used across projects\n\n**Use `uv add` for:**\n- Project-specific dependencies\n- Libraries imported in code\n- Development dependencies in specific projects\n\n```bash\n# Global tool (any project)\nuv tool install ruff\n\n# Project dependency (one project)\nuv add --dev ruff\n```\n\n## Tool Isolation\n\nEach tool gets its own virtual environment:\n\n```bash\n# Each tool is isolated\n~/.local/share/uv/tools/\n ruff/           # Isolated environment for ruff\n black/          # Isolated environment for black\n pytest/         # Isolated environment for pytest\n\n# No dependency conflicts between tools\n```\n\n## Common Workflows\n\n### Setup Development Tools\n\n```bash\n# Install common development tools globally\nuv tool install ruff\nuv tool install mypy\nuv tool install pytest\nuv tool install ipython\n\n# Now available in any project\nruff check .\nmypy src/\npytest\nipython\n```\n\n### One-Off Tool Usage\n\n```bash\n# Run without installing\nuvx pycowsay \"Temporary tool!\"\nuvx httpie https://api.github.com\n\n# No cleanup needed\n```\n\n### Replace pipx\n\n```bash\n# Old (pipx)\npipx install black\npipx run pycowsay \"hello\"\n\n# New (uv)\nuv tool install black\nuvx pycowsay \"hello\"\n```\n\n## Key Features\n\n- **Fast**: 10-100x faster than pipx\n- **Isolated**: Each tool in separate environment\n- **Ephemeral**: Run tools without installation\n- **Version control**: Pin tool versions\n- **Git support**: Install from repositories\n\n## See Also\n\n- `uv-project-management` - Project-specific dependencies\n- `uv-python-versions` - Python versions for tools\n- `python-code-quality` - Using ruff, mypy, black\n\n## References\n\n- Official docs: https://docs.astral.sh/uv/guides/tools/\n- Tool directory: Use `uv cache dir` to find cache location\n- Detailed guide: See REFERENCE.md in this skill directory"
              },
              {
                "name": "uv-workspaces",
                "description": "Manage monorepo and multi-package Python projects with uv workspaces. Covers\nworkspace configuration, member dependencies, shared lockfiles, and building.\nUse when user mentions uv workspaces, Python monorepo, multi-package projects,\nworkspace members, or shared dependencies across packages.\n",
                "path": "python-plugin/skills/uv-workspaces/SKILL.md",
                "frontmatter": {
                  "created": "2025-12-16T00:00:00.000Z",
                  "modified": "2025-12-16T00:00:00.000Z",
                  "reviewed": "2025-12-16T00:00:00.000Z",
                  "name": "uv-workspaces",
                  "description": "Manage monorepo and multi-package Python projects with uv workspaces. Covers\nworkspace configuration, member dependencies, shared lockfiles, and building.\nUse when user mentions uv workspaces, Python monorepo, multi-package projects,\nworkspace members, or shared dependencies across packages.\n"
                },
                "content": "# UV Workspaces\n\nQuick reference for managing monorepo and multi-package projects with UV workspaces.\n\n## When This Skill Applies\n\n- Monorepo projects with multiple Python packages\n- Shared dependencies across multiple packages\n- Library packages with example applications\n- Projects with plugins or extensions\n- Internal package dependencies\n\n## Quick Reference\n\n### Workspace Structure\n\n```\nmy-workspace/\n pyproject.toml          # Root workspace config\n uv.lock                # Shared lockfile\n packages/\n    core/\n       pyproject.toml\n       src/core/\n    api/\n       pyproject.toml\n       src/api/\n    cli/\n        pyproject.toml\n        src/cli/\n README.md\n```\n\n### Root pyproject.toml\n\n```toml\n[tool.uv.workspace]\nmembers = [\n    \"packages/*\",\n]\n\n# Or explicit:\nmembers = [\n    \"packages/core\",\n    \"packages/api\",\n    \"packages/cli\",\n]\n\n# Exclude patterns\nexclude = [\n    \"packages/experimental\",\n]\n```\n\n### Package pyproject.toml\n\n```toml\n[project]\nname = \"my-core\"\nversion = \"0.1.0\"\ndependencies = []\n\n# Depend on workspace member\n[project]\ndependencies = [\"my-utils\"]\n\n[tool.uv.sources]\nmy-utils = { workspace = true }\n```\n\n## Common Commands\n\n```bash\n# Install all workspace members\nuv sync\n\n# Build specific package\nuv build --package my-core\n\n# Run in package context\nuv run --package my-api python script.py\n\n# Add dependency to specific member\ncd packages/my-core\nuv add requests\n\n# Lock entire workspace\nuv lock\n```\n\n## Workspace Members\n\n### Declaring Members\n\n```toml\n[tool.uv.workspace]\n# Glob patterns\nmembers = [\"packages/*\"]\n\n# Explicit paths\nmembers = [\n    \"packages/core\",\n    \"apps/web\",\n    \"tools/cli\",\n]\n\n# Mixed\nmembers = [\n    \"packages/*\",\n    \"apps/special\",\n]\n\n# Exclusions\nexclude = [\"packages/archived\"]\n```\n\n### Member Dependencies\n\n**Depend on another workspace member:**\n```toml\n# packages/api/pyproject.toml\n[project]\nname = \"my-api\"\ndependencies = [\n    \"my-core\",  # Workspace member\n    \"fastapi\",  # PyPI package\n]\n\n[tool.uv.sources]\nmy-core = { workspace = true }\n```\n\n## Shared Dependencies\n\n### Common Patterns\n\n**Development dependencies in root:**\n```toml\n# Root pyproject.toml\n[dependency-groups]\ndev = [\n    \"pytest>=7.0\",\n    \"ruff>=0.1.0\",\n    \"mypy>=1.7\",\n]\n\n# All members can use these\n```\n\n**Member-specific dependencies:**\n```toml\n# packages/api/pyproject.toml\n[project]\ndependencies = [\n    \"fastapi>=0.110.0\",\n]\n\n[dependency-groups]\ntest = [\n    \"pytest-asyncio\",  # Only for this member\n]\n```\n\n## Lockfile Management\n\n```bash\n# Single lockfile for entire workspace\nuv.lock\n\n# Update lockfile\nuv lock\n\n# Upgrade specific package across workspace\nuv lock --upgrade-package requests\n\n# Sync all members\nuv sync\n```\n\n## Building Packages\n\n```bash\n# Build all packages\nuv build\n\n# Build specific package\nuv build --package my-core\nuv build --package my-api\n\n# Build multiple packages\nuv build --package my-core --package my-api\n```\n\n## Common Workflows\n\n### Creating a Workspace\n\n```bash\n# Create root\nmkdir my-workspace && cd my-workspace\n\n# Create root pyproject.toml\ncat > pyproject.toml << 'EOF'\n[tool.uv.workspace]\nmembers = [\"packages/*\"]\nEOF\n\n# Create first package\nmkdir -p packages/core\ncd packages/core\nuv init core\n\n# Create second package\ncd ../..\nmkdir -p packages/api\ncd packages/api\nuv init api\n\n# Configure workspace dependency\n# Edit packages/api/pyproject.toml to depend on core\n```\n\n### Adding Inter-Package Dependencies\n\n```bash\n# In packages/api/\nuv add ../core\n\n# Or manually edit pyproject.toml:\n# [project]\n# dependencies = [\"my-core\"]\n#\n# [tool.uv.sources]\n# my-core = { workspace = true }\n```\n\n### Testing Across Workspace\n\n```bash\n# Test all packages\nuv run pytest packages/*/tests/\n\n# Test specific package\nuv run --package my-core pytest\n\n# Run with coverage\nuv run pytest --cov=packages\n```\n\n## Workspace vs Path Dependencies\n\n### Workspace Member\n\n```toml\n[tool.uv.sources]\nmy-package = { workspace = true }\n```\n\n- Always editable\n- Must be workspace member\n- Shared lockfile\n\n### Path Dependency\n\n```toml\n[tool.uv.sources]\nmy-package = { path = \"../my-package\" }\n```\n\n- Can be outside workspace\n- Optional editability\n- Independent locking\n\n## See Also\n\n- `uv-project-management` - Managing individual packages\n- `uv-advanced-dependencies` - Path and Git dependencies\n- `python-packaging` - Building and publishing workspace packages\n\n## References\n\n- Official docs: https://docs.astral.sh/uv/concepts/projects/workspaces/\n- Detailed guide: See REFERENCE.md in this skill directory"
              },
              {
                "name": "vulture-dead-code",
                "description": "Vulture and deadcode tools for detecting unused Python code (functions, classes, variables, imports).\nUse when cleaning up codebases, removing unused code, or enforcing code hygiene in CI.\nTriggered by: vulture, deadcode, dead code detection, unused code, code cleanup, remove unused.\n",
                "path": "python-plugin/skills/vulture-dead-code/SKILL.md",
                "frontmatter": {
                  "created": "2025-12-16T00:00:00.000Z",
                  "modified": "2025-12-16T00:00:00.000Z",
                  "reviewed": "2025-12-16T00:00:00.000Z",
                  "name": "vulture-dead-code",
                  "description": "Vulture and deadcode tools for detecting unused Python code (functions, classes, variables, imports).\nUse when cleaning up codebases, removing unused code, or enforcing code hygiene in CI.\nTriggered by: vulture, deadcode, dead code detection, unused code, code cleanup, remove unused.\n"
                },
                "content": "# Vulture and deadcode - Dead Code Detection\n\nTools for finding unused Python code including functions, classes, variables, imports, and attributes.\n\n## Overview\n\n**Vulture** (mature, confidence-based) and **deadcode** (newer, AST-based) both detect unused code but with different approaches:\n\n| Feature | Vulture | deadcode |\n|---------|---------|----------|\n| **Approach** | Static analysis + confidence scores | AST-based detection |\n| **Accuracy** | Confidence scores (60-100%) | High accuracy, fewer false positives |\n| **Speed** | Fast | Very fast |\n| **Configuration** | Whitelist files | TOML configuration |\n| **Maturity** | Mature (2012) | Newer (2023+) |\n| **Best For** | Large codebases, gradual cleanup | New projects, strict enforcement |\n\n## Installation\n\n```bash\n# Install vulture\nuv add --dev vulture\n\n# Install deadcode (newer alternative)\nuv add --dev deadcode\n\n# Install both for comparison\nuv add --dev vulture deadcode\n```\n\n## Vulture - Confidence-Based Detection\n\n### Basic Usage\n\n```bash\n# Check entire project\nvulture .\n\n# Check specific files/directories\nvulture src/ tests/\n\n# Minimum confidence threshold (60-100%)\nvulture --min-confidence 80 .\n\n# Exclude patterns\nvulture . --exclude \"**/migrations/*,**/tests/*\"\n\n# Sort by confidence\nvulture --sort-by-size .\n\n# Generate whitelist of current issues\nvulture . --make-whitelist > vulture_whitelist.py\n```\n\n### Configuration\n\n#### pyproject.toml Configuration\n\n```toml\n[tool.vulture]\n# Minimum confidence to report (60-100%)\nmin_confidence = 80\n\n# Paths to scan\npaths = [\"src\", \"tests\"]\n\n# Exclude patterns (glob)\nexclude = [\n    \"**/migrations/*\",\n    \"**/__pycache__/*\",\n    \"**/node_modules/*\",\n    \".venv/*\"\n]\n\n# Ignore decorators (marks functions as used)\nignore_decorators = [\n    \"@app.route\",\n    \"@pytest.fixture\",\n    \"@property\",\n    \"@staticmethod\",\n    \"@classmethod\"\n]\n\n# Ignore names matching patterns\nignore_names = [\n    \"test_*\",      # Test functions\n    \"setUp*\",      # Test setup\n    \"tearDown*\",   # Test teardown\n]\n\n# Make whitelist\nmake_whitelist = false\n\n# Sort results\nsort_by_size = false\n```\n\n#### vulture_whitelist.py Pattern\n\n```python\n# vulture_whitelist.py\n# Whitelist for false positives\n\n# Used by external code\n_.used_by_external_lib  # confidence: 60%\nMyClass.called_dynamically  # confidence: 60%\n\n# Used in templates\ndef render_template_helper():\n    pass  # confidence: 60%\n\n# Used via __getattr__\ndynamic_attribute = None  # confidence: 60%\n\n# Framework magic\nclass Meta:  # Django/Flask metadata\n    pass\n\n# Plugin system\ndef plugin_hook():  # Called by plugin system\n    pass\n```\n\n### Understanding Confidence Scores\n\n```python\n# 100% confidence (definitely unused)\ndef never_called():\n    \"\"\"This function is never called anywhere.\"\"\"\n    pass\n\n# 80% confidence (likely unused)\ndef maybe_called():\n    \"\"\"Called in commented code or string.\"\"\"\n    pass\n\n# 60% confidence (possibly unused)\ndef dynamic_call():\n    \"\"\"Might be called via getattr() or string.\"\"\"\n    pass\n\n# Set minimum confidence threshold\n# --min-confidence 80 = Report only high-confidence issues\n# --min-confidence 60 = Report all potential issues (more false positives)\n```\n\n### Common Patterns\n\n#### Unused Imports\n\n```python\n# FOUND: Unused import\nimport sys  # confidence: 100%\nimport os   # confidence: 100%\n\n# USED: Import is used\nimport logging\nlogger = logging.getLogger(__name__)\n```\n\n#### Unused Functions\n\n```python\n# FOUND: Unused function\ndef unused_helper():  # confidence: 100%\n    return 42\n\n# USED: Function is called\ndef used_helper():\n    return 42\n\nresult = used_helper()\n```\n\n#### Unused Class Attributes\n\n```python\nclass MyClass:\n    # FOUND: Unused attribute\n    unused_attr = 42  # confidence: 100%\n\n    # USED: Attribute is accessed\n    used_attr = 42\n\n    def method(self):\n        return self.used_attr\n```\n\n#### Unused Variables\n\n```python\ndef process():\n    # FOUND: Unused variable\n    unused = calculate()  # confidence: 100%\n\n    # USED: Variable is used\n    result = calculate()\n    return result\n```\n\n### False Positives (When to Whitelist)\n\n```python\n# 1. Dynamic attribute access\nclass Config:\n    DEBUG = True  # Accessed via getattr(config, 'DEBUG')\n\n# 2. Framework magic\nclass Meta:  # Used by Django ORM\n    db_table = 'users'\n\n# 3. Decorators\n@app.route('/api/data')\ndef api_endpoint():  # Route handler - appears unused\n    pass\n\n# 4. Test fixtures\n@pytest.fixture\ndef sample_data():  # Fixture - appears unused\n    return [1, 2, 3]\n\n# 5. Plugin hooks\ndef plugin_initialize():  # Called by plugin system\n    pass\n\n# 6. Serialization\nclass User:\n    def to_dict(self):  # Called by serialization library\n        pass\n```\n\n### Gradual Cleanup Strategy\n\n```bash\n# Step 1: Generate baseline\nvulture --make-whitelist > vulture_whitelist.py\n\n# Step 2: Fix high-confidence issues\nvulture --min-confidence 90 .\n\n# Step 3: Lower threshold gradually\nvulture --min-confidence 80 .\nvulture --min-confidence 70 .\n\n# Step 4: Update whitelist\nvulture --make-whitelist > vulture_whitelist.py\n\n# Step 5: Enforce in CI\nvulture --min-confidence 80 .\n```\n\n## deadcode - AST-Based Detection\n\n### Basic Usage\n\n```bash\n# Check entire project\ndeadcode .\n\n# Check specific files/directories\ndeadcode src/\n\n# Verbose output\ndeadcode --verbose .\n\n# Dry run (show what would be removed)\ndeadcode --dry-run .\n\n# Show unreachable code\ndeadcode --show-unreachable .\n\n# Generate configuration\ndeadcode --init\n```\n\n### Configuration\n\n#### pyproject.toml Configuration\n\n```toml\n[tool.deadcode]\n# Paths to scan\npaths = [\"src\"]\n\n# Exclude patterns\nexclude = [\n    \"tests/*\",\n    \"**/__pycache__/*\",\n    \"**/migrations/*\",\n]\n\n# Files to ignore completely\nignore_files = [\n    \"src/legacy.py\",\n    \"src/experimental.py\"\n]\n\n# Directories to exclude\nexclude_dirs = [\n    \".venv\",\n    \"node_modules\",\n    \".git\"\n]\n\n# Functions/classes to ignore\nignore_names = [\n    \"test_*\",      # Test functions\n    \"setUp\",       # Test methods\n    \"tearDown\",\n    \"main\",        # Entry points\n]\n\n# Ignore decorators\nignore_decorators = [\n    \"app.route\",\n    \"pytest.fixture\",\n    \"property\",\n    \"staticmethod\",\n    \"classmethod\",\n    \"abstractmethod\"\n]\n\n# Minimum number of references to consider \"used\"\nmin_references = 1\n\n# Show unreachable code (after return/raise)\nshow_unreachable = false\n```\n\n### Common Patterns\n\n#### Unused Code Detection\n\n```python\n# FOUND: Unused function\ndef unused_function():\n    return 42\n\n# FOUND: Unused class\nclass UnusedClass:\n    pass\n\n# FOUND: Unused variable\nUNUSED_CONSTANT = 42\n\n# FOUND: Unused import\nimport unused_module\n```\n\n#### Unreachable Code Detection\n\n```python\ndef example():\n    return 42\n    print(\"Unreachable\")  # FOUND: Code after return\n\ndef example2():\n    raise ValueError(\"Error\")\n    cleanup()  # FOUND: Code after raise\n\ndef example3():\n    if True:\n        return\n    else:\n        process()  # FOUND: Unreachable branch\n```\n\n### False Positives (Configuration)\n\n```python\n# 1. Public API (keep even if unused internally)\n# Add to ignore_names in pyproject.toml\n[tool.deadcode]\nignore_names = [\"PublicAPIClass\", \"public_function\"]\n\n# 2. Framework magic\n[tool.deadcode]\nignore_decorators = [\"app.route\", \"celery.task\"]\n\n# 3. Test infrastructure\n[tool.deadcode]\nignore_names = [\"test_*\", \"setUp*\", \"tearDown*\"]\n\n# 4. Entry points\n[tool.deadcode]\nignore_names = [\"main\", \"__main__\"]\n```\n\n## Comparison: Vulture vs deadcode\n\n### When to Choose Vulture\n\n**Use Vulture for:**\n- Large, mature codebases with complex dynamics\n- Gradual cleanup with confidence-based filtering\n- Whitelisting false positives easily\n- Handling dynamic code (getattr, exec, etc.)\n\n**Example workflow:**\n```bash\n# Start with high confidence\nvulture --min-confidence 90 .\n\n# Generate whitelist for false positives\nvulture --make-whitelist > vulture_whitelist.py\n\n# Edit whitelist manually\nvim vulture_whitelist.py\n\n# Run with whitelist\nvulture . vulture_whitelist.py\n```\n\n### When to Choose deadcode\n\n**Use deadcode for:**\n- New projects with strict code hygiene\n- Fewer false positives desired\n- AST-based accuracy\n- Unreachable code detection\n\n**Example workflow:**\n```bash\n# Generate initial config\ndeadcode --init\n\n# Configure in pyproject.toml\n[tool.deadcode]\npaths = [\"src\"]\nignore_decorators = [\"app.route\"]\n\n# Run checks\ndeadcode .\n\n# Enforce in CI\ndeadcode --strict .\n```\n\n### Hybrid Approach\n\nUse both tools for comprehensive detection:\n\n```bash\n# Run vulture for broad detection\nvulture --min-confidence 80 .\n\n# Run deadcode for precise detection\ndeadcode .\n\n# Compare results and whitelist false positives\n```\n\n## CI Integration\n\n### GitHub Actions with Vulture\n\n```yaml\n# .github/workflows/deadcode.yml\nname: Dead Code Check\n\non: [push, pull_request]\n\njobs:\n  vulture:\n    runs-on: ubuntu-latest\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Install uv\n        uses: astral-sh/setup-uv@v2\n\n      - name: Set up Python\n        run: uv python install 3.12\n\n      - name: Install dependencies\n        run: uv sync --all-extras --dev\n\n      - name: Run vulture\n        run: |\n          uv run vulture . \\\n            --min-confidence 80 \\\n            vulture_whitelist.py\n\n      - name: Upload results\n        uses: actions/upload-artifact@v4\n        if: failure()\n        with:\n          name: vulture-results\n          path: vulture-output.txt\n```\n\n### GitHub Actions with deadcode\n\n```yaml\n# .github/workflows/deadcode.yml\nname: Dead Code Check\n\non: [push, pull_request]\n\njobs:\n  deadcode:\n    runs-on: ubuntu-latest\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Install uv\n        uses: astral-sh/setup-uv@v2\n\n      - name: Set up Python\n        run: uv python install 3.12\n\n      - name: Install dependencies\n        run: uv sync --all-extras --dev\n\n      - name: Run deadcode\n        run: uv run deadcode .\n\n      - name: Check for unreachable code\n        run: uv run deadcode --show-unreachable .\n```\n\n### Pre-commit Hook\n\n```yaml\n# .pre-commit-config.yaml\nrepos:\n  # Vulture\n  - repo: https://github.com/jendrikseipp/vulture\n    rev: v2.11\n    hooks:\n      - id: vulture\n        args: ['--min-confidence', '80']\n        files: ^src/\n\n  # deadcode\n  - repo: https://github.com/albertas/deadcode\n    rev: v2.0.0\n    hooks:\n      - id: deadcode\n        args: ['.']\n        files: ^src/\n```\n\n## Best Practices\n\n### 1. Start with High Confidence\n\n```bash\n# Begin with high confidence (fewer false positives)\nvulture --min-confidence 90 .\n\n# Gradually lower threshold\nvulture --min-confidence 80 .\nvulture --min-confidence 70 .\n```\n\n### 2. Use Whitelists for False Positives\n\n```python\n# vulture_whitelist.py\n# Document WHY each item is whitelisted\n\n# Framework routes (Flask/Django)\n@app.route('/api/endpoint')\ndef api_handler():  # Called by framework\n    pass\n\n# Pytest fixtures\n@pytest.fixture\ndef sample_data():  # Used by test functions\n    return [1, 2, 3]\n\n# Plugin hooks\ndef on_load():  # Called by plugin system\n    pass\n```\n\n### 3. Integrate into Development Workflow\n\n```bash\n# Local development: Quick check\nvulture src/ --min-confidence 90\n\n# Pre-commit: Catch obvious issues\npre-commit run vulture --all-files\n\n# CI: Strict enforcement\nvulture . --min-confidence 80 vulture_whitelist.py\n```\n\n### 4. Review and Clean Regularly\n\n```bash\n# Weekly: Review dead code\nvulture --make-whitelist > current_issues.txt\n\n# Compare with last week\ndiff current_issues.txt last_week_issues.txt\n\n# Clean up incrementally\ngit grep \"def unused_function\" | xargs -I {} git rm {}\n```\n\n### 5. Combine with Other Tools\n\n```bash\n# Dead code + unused imports\nvulture . && ruff check --select F401 .\n\n# Dead code + type checking\nvulture . && basedpyright\n\n# Dead code + coverage\npytest --cov=src && vulture src/\n```\n\n## Common Pitfalls\n\n### 1. Dynamic Code\n\n```python\n# Problem: vulture can't detect dynamic usage\ndef dynamic_call():\n    pass\n\n# Called via getattr\nfunc = getattr(module, \"dynamic_call\")\nfunc()\n\n# Solution: Whitelist or use ignore comment\ndef dynamic_call():  # noqa: vulture\n    pass\n```\n\n### 2. Test Code\n\n```python\n# Problem: Test fixtures appear unused\n@pytest.fixture\ndef sample_data():  # Appears unused to vulture\n    return [1, 2, 3]\n\n# Solution: Configure ignore_decorators\n[tool.vulture]\nignore_decorators = [\"pytest.fixture\"]\n```\n\n### 3. Public API\n\n```python\n# Problem: Public API unused internally\nclass PublicAPI:\n    def public_method(self):  # Not called in codebase\n        pass\n\n# Solution: Whitelist or document\n[tool.deadcode]\nignore_names = [\"PublicAPI\"]\n```\n\n### 4. Framework Magic\n\n```python\n# Problem: Framework calls code dynamically\nclass Meta:  # Django ORM metadata\n    db_table = 'users'\n\n@app.route('/api')  # Flask route\ndef endpoint():\n    pass\n\n# Solution: Configure ignore_decorators\n[tool.vulture]\nignore_decorators = [\"app.route\"]\nignore_names = [\"Meta\"]\n```\n\n## Integration with IDEs\n\n### VS Code\n\n```json\n// settings.json\n{\n  \"python.linting.enabled\": true,\n  \"python.linting.vulture.enabled\": true,\n  \"python.linting.vulture.args\": [\n    \"--min-confidence\", \"80\"\n  ]\n}\n```\n\n### Neovim with LSP\n\n```lua\n-- Using null-ls\nlocal null_ls = require(\"null-ls\")\n\nnull_ls.setup({\n  sources = {\n    null_ls.builtins.diagnostics.vulture.with({\n      extra_args = { \"--min-confidence\", \"80\" }\n    }),\n  }\n})\n```\n\n## Summary\n\n**Vulture** provides confidence-based dead code detection:\n- Install: `uv add --dev vulture`\n- Usage: `vulture --min-confidence 80 .`\n- Whitelists: `vulture_whitelist.py` for false positives\n- Best for: Large codebases, gradual cleanup\n\n**deadcode** provides AST-based detection:\n- Install: `uv add --dev deadcode`\n- Usage: `deadcode .`\n- Configuration: `pyproject.toml` with `[tool.deadcode]`\n- Best for: New projects, strict enforcement\n\n**Best practices:**\n- Start with high confidence thresholds (90+)\n- Use whitelists for legitimate false positives\n- Integrate into CI for continuous monitoring\n- Combine with other tools (ruff, basedpyright, coverage)\n- Review and clean regularly\n- Document WHY code is whitelisted\n\n**Hybrid approach:**\n- Use vulture for broad detection with confidence scores\n- Use deadcode for precise detection with fewer false positives\n- Compare results and maintain whitelists accordingly"
              }
            ]
          },
          {
            "name": "typescript-plugin",
            "description": "TypeScript development - strict types, ESLint, Biome",
            "source": "./typescript-plugin",
            "category": "language",
            "version": "1.2.1",
            "author": null,
            "install_commands": [
              "/plugin marketplace add laurigates/claude-plugins",
              "/plugin install typescript-plugin@lgates-claude-plugins"
            ],
            "signals": {
              "stars": 1,
              "forks": 0,
              "pushed_at": "2026-01-12T12:05:51Z",
              "created_at": "2025-12-16T11:24:04Z",
              "license": null
            },
            "commands": [],
            "skills": [
              {
                "name": "Biome Tooling",
                "description": "Biome all-in-one formatter and linter for JavaScript, TypeScript, JSX, TSX, JSON, and CSS.\nZero-config setup, 15-20x faster than ESLint/Prettier. Use when working with modern JavaScript/TypeScript\nprojects, setting up formatting/linting, or migrating from ESLint+Prettier to a faster alternative.\n",
                "path": "typescript-plugin/skills/biome-tooling/SKILL.md",
                "frontmatter": {
                  "created": "2025-12-16T00:00:00.000Z",
                  "modified": "2025-12-16T00:00:00.000Z",
                  "reviewed": "2025-12-16T00:00:00.000Z",
                  "name": "Biome Tooling",
                  "description": "Biome all-in-one formatter and linter for JavaScript, TypeScript, JSX, TSX, JSON, and CSS.\nZero-config setup, 15-20x faster than ESLint/Prettier. Use when working with modern JavaScript/TypeScript\nprojects, setting up formatting/linting, or migrating from ESLint+Prettier to a faster alternative.\n",
                  "allowed-tools": "Glob, Grep, Read, Bash, Edit, Write, TodoWrite, WebFetch, WebSearch, BashOutput, KillShell"
                },
                "content": "# Biome Tooling\n\nBiome is a modern, performant toolchain for JavaScript, TypeScript, and related web languages. It combines formatting, linting, and import organization into a single tool that's **15-20x faster** than ESLint/Prettier.\n\n## Core Expertise\n\n**What is Biome?**\n- **All-in-one toolchain**: Linter + formatter + import sorter\n- **Zero-config**: Works out of the box with sensible defaults\n- **Fast**: Written in Rust, processes files in parallel\n- **Compatible**: Matches Prettier formatting 97%+\n- **Supports**: JavaScript, TypeScript, JSX, TSX, JSON, CSS\n\n**Key Capabilities**\n- Format code with opinionated, consistent style\n- Lint for errors, performance issues, and best practices\n- Organize imports (sort, remove unused)\n- Pre-commit hook integration\n- Editor integration (VS Code, Neovim, JetBrains)\n- CI/CD integration with detailed diagnostics\n\n## Installation\n\n```bash\n# Project-local (recommended)\nbun add --dev @biomejs/biome\n\n# Global installation\nbun add --global @biomejs/biome\n\n# npm alternative\nnpm install --save-dev @biomejs/biome\n\n# Verify installation\nbunx biome --version\n```\n\n## Essential Commands\n\n```bash\n# Format files\nbunx biome format --write src/\n\n# Lint with fixes\nbunx biome lint --write src/\n\n# Check everything (format + lint + organize imports)\nbunx biome check --write src/\n\n# Check without changes (CI mode)\nbunx biome check src/\n\n# Migrate from ESLint/Prettier\nbunx biome migrate eslint --write\nbunx biome migrate prettier --write\n\n# Initialize configuration\nbunx biome init\n\n# Explain a rule\nbunx biome explain noUnusedVariables\n```\n\n## Configuration (biome.json)\n\n### Minimal Setup (Zero Config)\n\nBiome works without configuration. For basic customization:\n\n```json\n{\n  \"$schema\": \"https://biomejs.dev/schemas/1.9.4/schema.json\",\n  \"vcs\": {\n    \"enabled\": true,\n    \"clientKind\": \"git\",\n    \"useIgnoreFile\": true\n  },\n  \"files\": {\n    \"ignoreUnknown\": false,\n    \"ignore\": [\"dist\", \"build\", \"node_modules\", \".next\", \"coverage\"]\n  },\n  \"formatter\": {\n    \"enabled\": true,\n    \"indentStyle\": \"space\",\n    \"indentWidth\": 2,\n    \"lineWidth\": 100\n  },\n  \"linter\": {\n    \"enabled\": true,\n    \"rules\": {\n      \"recommended\": true\n    }\n  },\n  \"organizeImports\": {\n    \"enabled\": true\n  }\n}\n```\n\n### Recommended Production Setup\n\n```json\n{\n  \"$schema\": \"https://biomejs.dev/schemas/1.9.4/schema.json\",\n  \"vcs\": {\n    \"enabled\": true,\n    \"clientKind\": \"git\",\n    \"useIgnoreFile\": true\n  },\n  \"files\": {\n    \"ignoreUnknown\": false,\n    \"ignore\": [\"dist\", \"build\", \"node_modules\", \".next\", \".nuxt\", \"coverage\"]\n  },\n  \"formatter\": {\n    \"enabled\": true,\n    \"indentStyle\": \"space\",\n    \"indentWidth\": 2,\n    \"lineWidth\": 100,\n    \"lineEnding\": \"lf\"\n  },\n  \"linter\": {\n    \"enabled\": true,\n    \"rules\": {\n      \"recommended\": true,\n      \"suspicious\": {\n        \"noExplicitAny\": \"error\",\n        \"noConsoleLog\": \"warn\"\n      },\n      \"style\": {\n        \"noNonNullAssertion\": \"warn\",\n        \"useConst\": \"error\"\n      },\n      \"correctness\": {\n        \"noUnusedVariables\": \"error\",\n        \"noUnusedImports\": \"error\"\n      },\n      \"complexity\": {\n        \"noForEach\": \"off\"\n      }\n    }\n  },\n  \"organizeImports\": {\n    \"enabled\": true\n  },\n  \"javascript\": {\n    \"formatter\": {\n      \"quoteStyle\": \"single\",\n      \"trailingCommas\": \"all\",\n      \"semicolons\": \"asNeeded\",\n      \"arrowParentheses\": \"asNeeded\"\n    }\n  },\n  \"overrides\": [\n    {\n      \"include\": [\"*.test.ts\", \"*.spec.ts\"],\n      \"linter\": {\n        \"rules\": {\n          \"suspicious\": {\n            \"noExplicitAny\": \"off\"\n          }\n        }\n      }\n    }\n  ]\n}\n```\n\n## Rule Categories\n\nBiome organizes rules into categories:\n\n| Category | Purpose | Example Rules |\n|----------|---------|---------------|\n| `recommended` | Essential rules everyone should enable | Most rules marked \"recommended\" |\n| `correctness` | Prevent bugs and logic errors | `noUnusedVariables`, `noUnreachable` |\n| `suspicious` | Detect code that might be wrong | `noExplicitAny`, `noDoubleEquals` |\n| `style` | Enforce consistent style | `useConst`, `noVar` |\n| `complexity` | Reduce code complexity | `noForEach`, `useFlatMap` |\n| `performance` | Optimize performance | `noAccumulatingSpread` |\n| `a11y` | Accessibility best practices | `noSvgWithoutTitle`, `useAltText` |\n| `security` | Security vulnerabilities | `noDangerouslySetInnerHtml` |\n\n## Editor Integration\n\n### VS Code\n\n**Install extension:**\n```bash\ncode --install-extension biomejs.biome\n```\n\n**Settings (.vscode/settings.json):**\n```json\n{\n  \"[javascript]\": {\n    \"editor.defaultFormatter\": \"biomejs.biome\",\n    \"editor.formatOnSave\": true,\n    \"editor.codeActionsOnSave\": {\n      \"quickfix.biome\": \"explicit\",\n      \"source.organizeImports.biome\": \"explicit\"\n    }\n  },\n  \"[typescript]\": {\n    \"editor.defaultFormatter\": \"biomejs.biome\",\n    \"editor.formatOnSave\": true,\n    \"editor.codeActionsOnSave\": {\n      \"quickfix.biome\": \"explicit\",\n      \"source.organizeImports.biome\": \"explicit\"\n    }\n  },\n  \"[json]\": {\n    \"editor.defaultFormatter\": \"biomejs.biome\",\n    \"editor.formatOnSave\": true\n  }\n}\n```\n\n### Neovim (with nvim-lspconfig)\n\n```lua\n-- Using mason and lspconfig\nrequire('lspconfig').biome.setup({\n  cmd = { 'biome', 'lsp-proxy' },\n  filetypes = {\n    'javascript',\n    'typescript',\n    'javascriptreact',\n    'typescriptreact',\n    'json',\n    'jsonc',\n  },\n  root_dir = require('lspconfig.util').root_pattern(\n    'biome.json',\n    'biome.jsonc'\n  ),\n  single_file_support = false,\n  on_attach = function(client, bufnr)\n    -- Format on save\n    vim.api.nvim_create_autocmd('BufWritePre', {\n      buffer = bufnr,\n      callback = function()\n        vim.lsp.buf.format({ async = false })\n      end,\n    })\n  end,\n})\n```\n\n### JetBrains IDEs\n\n**Install plugin:**\n- Settings  Plugins  Search \"Biome\"  Install\n\n**Configure:**\n- Settings  Languages & Frameworks  Biome\n- Enable \"Run Biome on save\"\n- Set Biome executable path\n\n## Pre-commit Hook Setup\n\n**Using Husky + lint-staged:**\n\n```bash\n# Install dependencies\nbun add --dev husky lint-staged\n\n# Initialize husky\nbunx husky init\n```\n\n**package.json:**\n```json\n{\n  \"scripts\": {\n    \"prepare\": \"husky\"\n  },\n  \"lint-staged\": {\n    \"*.{js,ts,jsx,tsx,json}\": [\n      \"biome check --write --no-errors-on-unmatched\"\n    ]\n  }\n}\n```\n\n**.husky/pre-commit:**\n```bash\n#!/usr/bin/env sh\nbunx lint-staged\n```\n\n**Using pre-commit (Python):**\n\n```yaml\n# .pre-commit-config.yaml\nrepos:\n  - repo: https://github.com/biomejs/pre-commit\n    rev: v0.1.0\n    hooks:\n      - id: biome-check\n        additional_dependencies: [\"@biomejs/biome@1.9.4\"]\n```\n\n## CI/CD Integration\n\n### GitHub Actions\n\n```yaml\nname: Biome Check\non:\n  push:\n    branches: [main]\n  pull_request:\n\njobs:\n  biome:\n    name: Format & Lint\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n\n      - uses: oven-sh/setup-bun@v2\n        with:\n          bun-version: latest\n\n      - name: Install dependencies\n        run: bun install --frozen-lockfile\n\n      - name: Run Biome\n        run: bunx biome ci src/\n```\n\n### GitLab CI\n\n```yaml\nbiome:\n  image: oven/bun:latest\n  stage: test\n  script:\n    - bun install --frozen-lockfile\n    - bunx biome ci src/\n  only:\n    - merge_requests\n    - main\n```\n\n## Migration Strategies\n\n### From ESLint + Prettier\n\n```bash\n# 1. Remove old tools\nbun remove eslint prettier eslint-config-prettier\n\n# 2. Delete config files\nrm .eslintrc.json .prettierrc .prettierignore\n\n# 3. Install Biome\nbun add --dev @biomejs/biome\n\n# 4. Initialize configuration\nbunx biome init\n\n# 5. Migrate rules (optional)\nbunx biome migrate eslint --write\nbunx biome migrate prettier --write\n\n# 6. Format entire codebase\nbunx biome check --write src/\n\n# 7. Update scripts in package.json\n{\n  \"scripts\": {\n    \"format\": \"biome format --write src/\",\n    \"lint\": \"biome lint --write src/\",\n    \"check\": \"biome check --write src/\",\n    \"ci\": \"biome ci src/\"\n  }\n}\n```\n\n### Gradual Migration (Keep Both)\n\n```json\n{\n  \"scripts\": {\n    \"format\": \"biome format --write src/ && prettier --write 'docs/**/*.md'\",\n    \"lint\": \"biome lint --write src/ && eslint --fix 'legacy/**/*.js'\"\n  }\n}\n```\n\n**Use Biome for new code, keep old tools for legacy directories.**\n\n## When to Use Biome vs ESLint\n\n### Use Biome When:\n-  Starting a new project\n-  Want zero-config setup\n-  Need fast CI/CD pipelines\n-  Working with standard JavaScript/TypeScript\n-  Want all-in-one tooling\n\n### Keep ESLint When:\n-  Need specific ESLint plugins (React hooks, a11y, etc.)\n-  Have complex custom rules\n-  Need framework-specific rules (Next.js, Nuxt)\n-  Legacy codebase with heavy ESLint customization\n\n**Hybrid approach**: Use Biome for formatting, ESLint for specialized linting.\n\n## Common Patterns\n\n### Ignore Files and Directories\n\n**Via biome.json:**\n```json\n{\n  \"files\": {\n    \"ignore\": [\n      \"dist\",\n      \"build\",\n      \"node_modules\",\n      \"**/*.config.js\",\n      \"scripts/legacy/**\"\n    ]\n  }\n}\n```\n\n**Via .gitignore (automatic):**\n```json\n{\n  \"vcs\": {\n    \"enabled\": true,\n    \"useIgnoreFile\": true\n  }\n}\n```\n\n### Rule-Specific Overrides\n\n```json\n{\n  \"overrides\": [\n    {\n      \"include\": [\"*.test.ts\", \"*.spec.ts\"],\n      \"linter\": {\n        \"rules\": {\n          \"suspicious\": {\n            \"noExplicitAny\": \"off\"\n          }\n        }\n      }\n    },\n    {\n      \"include\": [\"scripts/**/*.ts\"],\n      \"linter\": {\n        \"rules\": {\n          \"suspicious\": {\n            \"noConsoleLog\": \"off\"\n          }\n        }\n      }\n    }\n  ]\n}\n```\n\n### Custom Rule Severity\n\n```json\n{\n  \"linter\": {\n    \"rules\": {\n      \"suspicious\": {\n        \"noExplicitAny\": \"error\",      // CI fails\n        \"noConsoleLog\": \"warn\",        // CI warning\n        \"noDebugger\": \"info\"           // CI info only\n      }\n    }\n  }\n}\n```\n\n## Troubleshooting\n\n### Biome Not Detecting Files\n\n```bash\n# Check what Biome sees\nbunx biome check --verbose src/\n\n# Ensure files aren't ignored\nbunx biome explain --verbose noUnusedVariables\n```\n\n### Conflicts with Prettier Formatting\n\n```bash\n# Migrate Prettier config\nbunx biome migrate prettier --write\n\n# Verify compatibility\nbunx biome format --write test.js\nprettier --write test.js\ndiff test.js test.js.bak\n```\n\n### Editor Not Formatting\n\n**VS Code:**\n- Check extension is installed and enabled\n- Verify `biome.json` exists in workspace root\n- Restart TypeScript server: Cmd+Shift+P  \"Restart TS Server\"\n\n**Neovim:**\n- Check LSP is attached: `:LspInfo`\n- Verify `biome` binary in PATH: `:!which biome`\n- Check `biome.json` location matches `root_dir`\n\n### Performance Issues\n\n```bash\n# Use --max-diagnostics to limit output\nbunx biome check --max-diagnostics=50 src/\n\n# Check specific files instead of entire directory\nbunx biome check src/problematic-file.ts\n\n# Use --reporter=json for CI\nbunx biome check --reporter=json src/\n```\n\n## Performance Comparison\n\n| Tool | Time (1000 files) | Notes |\n|------|-------------------|-------|\n| Biome | 0.5s | Rust, parallel processing |\n| ESLint | 8-10s | Node.js, single-threaded |\n| Prettier | 3-5s | Node.js, formatting only |\n| ESLint + Prettier | 11-15s | Sequential execution |\n\n**Biome is 15-20x faster than ESLint/Prettier combined.**\n\n## References\n\n- Official docs: https://biomejs.dev\n- Configuration: https://biomejs.dev/reference/configuration/\n- Rules: https://biomejs.dev/linter/\n- Migration guide: https://biomejs.dev/guides/migrate-eslint-prettier/\n- Editor integration: https://biomejs.dev/"
              },
              {
                "name": "bun-lockfile-update",
                "description": "Update Bun lockfiles (bun.lockb) with proper dependency management. Covers\nbun update, bun install, lockfile regeneration, and security audits.\nUse when user mentions bun lockfile, bun update, bun.lockb, updating Bun\ndependencies, or resolving Bun lockfile conflicts.\n",
                "path": "typescript-plugin/skills/bun-lockfile-update/SKILL.md",
                "frontmatter": {
                  "created": "2025-12-16T00:00:00.000Z",
                  "modified": "2025-12-16T00:00:00.000Z",
                  "reviewed": "2025-12-16T00:00:00.000Z",
                  "name": "bun-lockfile-update",
                  "description": "Update Bun lockfiles (bun.lockb) with proper dependency management. Covers\nbun update, bun install, lockfile regeneration, and security audits.\nUse when user mentions bun lockfile, bun update, bun.lockb, updating Bun\ndependencies, or resolving Bun lockfile conflicts.\n"
                },
                "content": "# Bun Lockfile Update\n\nComprehensive guidance for updating Bun lockfiles (`bun.lockb`) with proper dependency management practices.\n\n## When to Use\n\nUse this skill automatically when:\n- User requests lockfile update or dependency refresh\n- User mentions outdated dependencies or security vulnerabilities\n- User wants to update specific packages or all dependencies\n- Lockfile conflicts occur during git operations\n- User needs to audit or verify dependency integrity\n\n## Core Commands\n\n### Update All Dependencies\n```bash\n# Update all dependencies to latest versions (respecting semver ranges in package.json)\nbun update\n\n# Update all dependencies AND modify package.json to latest versions\nbun update --latest\n```\n\n### Update Specific Dependencies\n```bash\n# Update specific package(s) to latest compatible version\nbun update <package-name>\nbun update <package1> <package2>\n\n# Update specific package to latest version (ignoring semver range)\nbun update --latest <package-name>\n```\n\n### Regenerate Lockfile\n```bash\n# Regenerate lockfile from package.json (clean install)\nrm bun.lockb\nbun install\n\n# Or force regeneration\nbun install --force\n```\n\n## Update Strategies\n\n### 1. Safe Update (Recommended)\nRespects semver ranges in `package.json`:\n\n```bash\n# Updates within semver constraints (^1.2.3  1.x.x, ~1.2.3  1.2.x)\nbun update\n\n# Review changes\ngit diff bun.lockb package.json\n\n# Test thoroughly\nbun test\nbun run build\n```\n\n**When to use:**\n- Regular maintenance updates\n- CI/CD pipeline updates\n- Production deployments\n- When stability is priority\n\n### 2. Aggressive Update\nUpdates to absolute latest versions:\n\n```bash\n# Updates AND modifies package.json to latest versions\nbun update --latest\n\n# Review ALL changes carefully\ngit diff bun.lockb package.json\n\n# Test exhaustively (breaking changes likely)\nbun test\nbun run build\nbun run lint\n```\n\n**When to use:**\n- Major version upgrades\n- Modernization efforts\n- Security vulnerability fixes requiring latest versions\n- Development/experimental branches\n\n### 3. Selective Update\nUpdates specific packages only:\n\n```bash\n# Update one critical package\nbun update lodash\n\n# Update multiple related packages\nbun update @types/node @types/react @types/react-dom\n\n# Update to latest version (ignore semver)\nbun update --latest typescript\n```\n\n**When to use:**\n- Targeted security patches\n- Specific bug fixes\n- Gradual migration strategies\n- Reducing blast radius of changes\n\n## Best Practices Workflow\n\n### Pre-Update Checklist\n1. **Commit current state:** Ensure clean working directory\n   ```bash\n   git status\n   git add .\n   git commit -m \"chore: checkpoint before dependency update\"\n   ```\n\n2. **Check for outdated packages:**\n   ```bash\n   bun outdated\n   ```\n\n3. **Review security advisories:**\n   ```bash\n   bun audit\n   ```\n\n### Update Process\n1. **Choose strategy:** Safe, aggressive, or selective\n2. **Execute update command**\n3. **Review changes:**\n   ```bash\n   git diff bun.lockb package.json\n   ```\n\n### Post-Update Validation\n1. **Verify installation:**\n   ```bash\n   rm -rf node_modules\n   bun install\n   ```\n\n2. **Run test suite:**\n   ```bash\n   bun test\n   ```\n\n3. **Run build:**\n   ```bash\n   bun run build\n   ```\n\n4. **Run linting:**\n   ```bash\n   bun run lint\n   ```\n\n5. **Check bundle size:**\n   ```bash\n   bun run build --analyze  # If available\n   ```\n\n6. **Test application manually:**\n   - Critical user flows\n   - Edge cases\n   - Cross-browser testing (if web app)\n\n### Commit Changes\n```bash\n# For safe updates\ngit add bun.lockb\ngit commit -m \"chore(deps): update dependencies\n\nUpdates all dependencies to latest compatible versions.\nAll tests passing.\"\n\n# For aggressive updates\ngit add bun.lockb package.json\ngit commit -m \"chore(deps): upgrade dependencies to latest\n\nBREAKING CHANGES:\n- Updated React 17  18\n- Updated TypeScript 4.9  5.3\n- Updated Vite 4  5\n\nSee CHANGELOG for migration notes.\nAll tests passing.\"\n```\n\n## Common Scenarios\n\n### Scenario 1: Regular Maintenance\n**Goal:** Keep dependencies fresh without breaking changes\n\n```bash\n# Weekly/monthly routine\nbun update\nbun test\ngit add bun.lockb\ngit commit -m \"chore(deps): update dependencies\"\n```\n\n### Scenario 2: Security Vulnerability\n**Goal:** Patch specific vulnerable package\n\n```bash\n# Check vulnerability report\nbun audit\n\n# Update vulnerable package to latest (may require --latest)\nbun update --latest <vulnerable-package>\n\n# Verify fix\nbun audit\n\n# Test and commit\nbun test\ngit add bun.lockb package.json\ngit commit -m \"fix(deps): patch security vulnerability in <package>\n\nFixes: CVE-XXXX-XXXXX\"\n```\n\n### Scenario 3: Major Version Upgrade\n**Goal:** Migrate to new major version of framework/library\n\n```bash\n# 1. Create feature branch\ngit checkout -b chore/upgrade-react-18\n\n# 2. Update target package\nbun update --latest react react-dom\n\n# 3. Update related packages\nbun update --latest @types/react @types/react-dom\n\n# 4. Review breaking changes documentation\n# (Check official migration guide)\n\n# 5. Update code for breaking changes\n# (Fix deprecated APIs, adjust imports, etc.)\n\n# 6. Run comprehensive tests\nbun test\nbun run build\nbun run lint\n\n# 7. Manual testing\n# (Test all critical flows)\n\n# 8. Commit and create PR\ngit add .\ngit commit -m \"chore(deps): upgrade React 17  18\n\nBREAKING CHANGES:\n- Automatic batching changes render behavior\n- Updated ReactDOM.render to createRoot\n- Removed IE 11 support\n\nSee docs/migration/react-18.md for details.\"\n```\n\n### Scenario 4: Lockfile Conflict Resolution\n**Goal:** Resolve merge conflict in `bun.lockb`\n\n```bash\n# 1. Accept either version (doesn't matter which)\ngit checkout --theirs bun.lockb  # Or --ours\n\n# 2. Regenerate lockfile from package.json\nrm bun.lockb\nbun install\n\n# 3. Verify installation\nbun test\n\n# 4. Commit resolution\ngit add bun.lockb\ngit commit -m \"chore: resolve lockfile merge conflict\"\n```\n\n### Scenario 5: Dependency Audit & Cleanup\n**Goal:** Remove unused dependencies and update remaining\n\n```bash\n# 1. Audit dependencies\nbun pm ls  # List installed packages\n\n# 2. Check for unused dependencies\nnpx depcheck  # Or manual review of package.json\n\n# 3. Remove unused packages\nbun remove <unused-package>\n\n# 4. Update remaining dependencies\nbun update\n\n# 5. Verify everything still works\nbun test\nbun run build\n```\n\n## Bun-Specific Features\n\n### Binary Lockfile\n- Bun uses binary lockfile format (`bun.lockb`)\n- Much faster to parse than `package-lock.json` or `yarn.lock`\n- Not human-readable (use `bun pm ls` to inspect)\n\n### Workspaces\n```bash\n# Update all workspace packages\nbun update\n\n# Update specific workspace\nbun update --filter <workspace-name>\n```\n\n### Compatibility\n```bash\n# Install with npm/yarn compatibility\nbun install --backend=npm\n\n# Generate package-lock.json for compatibility\nbun install --lockfile-only\n```\n\n## Troubleshooting\n\n### Lockfile Corruption\n```bash\n# Symptoms: Install errors, checksum mismatches\n# Solution: Regenerate lockfile\nrm bun.lockb\nbun install\n```\n\n### Peer Dependency Conflicts\n```bash\n# Symptoms: Peer dependency warnings during install\n# Solution: Update peer dependencies or use --force\nbun install --force\n\n# Or resolve conflicts manually in package.json\n```\n\n### Cache Issues\n```bash\n# Clear Bun cache\nrm -rf ~/.bun/install/cache\n\n# Reinstall\nrm -rf node_modules bun.lockb\nbun install\n```\n\n### Version Mismatch Errors\n```bash\n# Symptoms: Package version doesn't match expectations\n# Solution: Verify package.json and regenerate lockfile\ncat package.json  # Check version ranges\nrm bun.lockb\nbun install\n```\n\n## Security Best Practices\n\n### Regular Audits\n```bash\n# Check for vulnerabilities\nbun audit\n\n# Get detailed report\nbun audit --json > audit-report.json\n```\n\n### Automated Updates\n```bash\n# Use Renovate or Dependabot for automated PRs\n# Configure in .github/renovate.json or .github/dependabot.yml\n```\n\n### Review Dependencies\n```bash\n# Before updating, review package reputation\n# Check npm package page, GitHub stars, maintenance status\nbun pm ls <package-name>\n```\n\n### Lockfile Integrity\n```bash\n# Verify lockfile matches package.json\nbun install --frozen-lockfile  # CI/CD\nbun install --production --frozen-lockfile  # Production\n```\n\n## Integration with CI/CD\n\n### GitHub Actions Example\n```yaml\n- name: Install dependencies\n  run: bun install --frozen-lockfile\n\n- name: Run tests\n  run: bun test\n\n- name: Update lockfile (scheduled job)\n  run: |\n    bun update\n    bun test\n  if: github.event_name == 'schedule'\n```\n\n### Pre-commit Hook\n```bash\n# .husky/pre-commit or similar\n#!/bin/sh\nbun install --frozen-lockfile\nbun test\n```\n\n## Related Skills\n\n- **Node.js Development** - Modern JavaScript/TypeScript patterns with Bun\n- **Git Branch PR Workflow** - Managing dependency update PRs\n- **GitHub Actions Inspection** - Debugging CI/CD lockfile issues\n\n## References\n\n- [Bun CLI Documentation](https://bun.sh/docs/cli/install)\n- [Bun Package Manager](https://bun.sh/docs/cli/pm)\n- [Bun Workspaces](https://bun.sh/docs/install/workspaces)\n- [Semantic Versioning](https://semver.org/)"
              },
              {
                "name": "Knip Dead Code Detection",
                "description": "Knip finds unused files, dependencies, exports, and types in JavaScript/TypeScript projects.\nPlugin system for frameworks (React, Next.js, Vite), test runners (Vitest, Jest), and build tools.\nUse when cleaning up codebases, optimizing bundle size, or enforcing strict dependency hygiene in CI.\n",
                "path": "typescript-plugin/skills/knip-dead-code/SKILL.md",
                "frontmatter": {
                  "created": "2025-12-16T00:00:00.000Z",
                  "modified": "2025-12-16T00:00:00.000Z",
                  "reviewed": "2025-12-16T00:00:00.000Z",
                  "name": "Knip Dead Code Detection",
                  "description": "Knip finds unused files, dependencies, exports, and types in JavaScript/TypeScript projects.\nPlugin system for frameworks (React, Next.js, Vite), test runners (Vitest, Jest), and build tools.\nUse when cleaning up codebases, optimizing bundle size, or enforcing strict dependency hygiene in CI.\n",
                  "allowed-tools": "Glob, Grep, Read, Bash, Edit, Write, TodoWrite, WebFetch, WebSearch, BashOutput, KillShell"
                },
                "content": "# Knip Dead Code Detection\n\nKnip is a comprehensive tool for finding unused code, dependencies, and exports in JavaScript and TypeScript projects. It helps maintain clean codebases and catch dead code before it accumulates.\n\n## Core Expertise\n\n**What is Knip?**\n- **Unused detection**: Files, dependencies, exports, types, enum members\n- **Plugin system**: Supports 80+ frameworks and tools\n- **Fast**: Analyzes large codebases in seconds\n- **Actionable**: Clear reports with file locations\n- **CI-ready**: Exit codes for failing builds\n\n**Key Capabilities**\n- Detect unused dependencies (npm, workspace packages)\n- Find unused exports and types\n- Identify unused files\n- Discover unused enum members and class members\n- Detect re-exports that aren't used\n- Plugin support for frameworks (React, Next.js, Vue, Svelte)\n- Integration with monorepos and workspaces\n\n## Installation\n\n```bash\n# Project-local (recommended)\nbun add --dev knip\n\n# Global installation\nbun add --global knip\n\n# Verify installation\nbunx knip --version\n```\n\n## Basic Usage\n\n```bash\n# Run Knip (scans entire project)\nbunx knip\n\n# Show only unused dependencies\nbunx knip --dependencies\n\n# Show only unused exports\nbunx knip --exports\n\n# Show only unused files\nbunx knip --files\n\n# Production mode (only check production dependencies)\nbunx knip --production\n\n# Exclude specific issue types\nbunx knip --exclude-exports-used-in-file\n\n# Output JSON (for CI)\nbunx knip --reporter json\n\n# Debug mode (show configuration)\nbunx knip --debug\n```\n\n## Configuration\n\n### Auto-detection (Zero Config)\n\nKnip automatically detects:\n- Entry points (package.json `main`, `exports`, `bin`)\n- Frameworks (Next.js, Vite, Remix, etc.)\n- Test runners (Vitest, Jest, Playwright)\n- Build tools (ESLint, TypeScript, PostCSS)\n\n**No configuration needed for standard projects.**\n\n### knip.json (Explicit Configuration)\n\n```json\n{\n  \"$schema\": \"https://unpkg.com/knip@latest/schema.json\",\n  \"entry\": [\"src/index.ts\", \"src/cli.ts\"],\n  \"project\": [\"src/**/*.ts\"],\n  \"ignore\": [\"**/*.test.ts\", \"scripts/**\"],\n  \"ignoreDependencies\": [\"@types/*\"],\n  \"ignoreBinaries\": [\"npm-check-updates\"]\n}\n```\n\n### knip.ts (TypeScript Configuration)\n\n```typescript\n// knip.ts\nimport type { KnipConfig } from 'knip';\n\nconst config: KnipConfig = {\n  entry: ['src/index.ts', 'src/cli.ts'],\n  project: ['src/**/*.ts', 'scripts/**/*.ts'],\n  ignore: ['**/*.test.ts', '**/*.spec.ts', 'tmp/**'],\n  ignoreDependencies: [\n    '@types/*', // Type definitions\n    'typescript', // Always needed\n  ],\n  ignoreExportsUsedInFile: true,\n  ignoreWorkspaces: ['packages/legacy/**'],\n};\n\nexport default config;\n```\n\n### Recommended Production Setup\n\n```typescript\n// knip.ts\nimport type { KnipConfig } from 'knip';\n\nconst config: KnipConfig = {\n  // Entry points\n  entry: [\n    'src/index.ts',\n    'src/cli.ts',\n    'scripts/**/*.ts', // Include scripts\n  ],\n\n  // Project files\n  project: ['src/**/*.{ts,tsx}', 'scripts/**/*.ts'],\n\n  // Ignore patterns\n  ignore: [\n    '**/*.test.ts',\n    '**/*.spec.ts',\n    '**/__tests__/**',\n    '**/__mocks__/**',\n    'dist/**',\n    'build/**',\n    'coverage/**',\n    '.next/**',\n  ],\n\n  // Dependencies to ignore\n  ignoreDependencies: [\n    '@types/*', // Type definitions used implicitly\n    'typescript', // Always needed for TS projects\n    'tslib', // TypeScript helper library\n    '@biomejs/biome', // Used via CLI\n    'prettier', // Used via CLI\n  ],\n\n  // Binaries to ignore (used in package.json scripts)\n  ignoreBinaries: ['npm-check-updates', 'semantic-release'],\n\n  // Ignore exports used in the same file\n  ignoreExportsUsedInFile: true,\n\n  // Workspace configuration (for monorepos)\n  workspaces: {\n    '.': {\n      entry: ['src/index.ts'],\n    },\n    'packages/*': {\n      entry: ['src/index.ts', 'src/cli.ts'],\n    },\n  },\n};\n\nexport default config;\n```\n\n## Plugin System\n\nKnip automatically detects and configures plugins for popular tools:\n\n### Framework Plugins\n\n| Framework | Auto-detected | Entry Points |\n|-----------|---------------|--------------|\n| Next.js | `next.config.js` | `pages/`, `app/`, `middleware.ts` |\n| Vite | `vite.config.ts` | `index.html`, config plugins |\n| Remix | `remix.config.js` | `app/root.tsx`, `app/entry.*` |\n| Astro | `astro.config.mjs` | `src/pages/`, config integrations |\n| SvelteKit | `svelte.config.js` | `src/routes/`, `src/app.html` |\n| Nuxt | `nuxt.config.ts` | `app.vue`, `pages/`, `layouts/` |\n\n### Test Runner Plugins\n\n| Tool | Auto-detected | Entry Points |\n|------|---------------|--------------|\n| Vitest | `vitest.config.ts` | `**/*.test.ts`, config files |\n| Jest | `jest.config.js` | `**/*.test.js`, setup files |\n| Playwright | `playwright.config.ts` | `tests/**/*.spec.ts` |\n| Cypress | `cypress.config.ts` | `cypress/e2e/**/*.cy.ts` |\n\n### Build Tool Plugins\n\n| Tool | Auto-detected | Entry Points |\n|------|---------------|--------------|\n| TypeScript | `tsconfig.json` | Files in `include` |\n| ESLint | `.eslintrc.js` | Config files, plugins |\n| PostCSS | `postcss.config.js` | Config plugins |\n| Tailwind | `tailwind.config.js` | Config plugins, content files |\n\n### Plugin Configuration Override\n\n```typescript\n// knip.ts\nconst config: KnipConfig = {\n  // Disable specific plugins\n  eslint: false,\n  prettier: false,\n\n  // Override plugin config\n  vitest: {\n    entry: ['vitest.config.ts', 'test/setup.ts'],\n    config: ['vitest.config.ts'],\n  },\n\n  next: {\n    entry: [\n      'next.config.js',\n      'pages/**/*.tsx',\n      'app/**/*.tsx',\n      'middleware.ts',\n      'instrumentation.ts',\n    ],\n  },\n};\n```\n\n## Ignoring Issues\n\n### Ignore Patterns\n\n```typescript\n// knip.ts\nconst config: KnipConfig = {\n  // Ignore entire directories\n  ignore: ['legacy/**', 'vendor/**'],\n\n  // Ignore specific dependencies\n  ignoreDependencies: [\n    '@types/*',\n    'some-peer-dependency',\n  ],\n\n  // Ignore specific exports\n  ignoreExportsUsedInFile: {\n    interface: true, // Ignore interfaces used only in same file\n    type: true, // Ignore types used only in same file\n  },\n\n  // Ignore workspace packages\n  ignoreWorkspaces: ['packages/deprecated/**'],\n};\n```\n\n### Inline Comments\n\n```typescript\n// Ignore unused export\n// @knip-ignore-export\nexport const unusedFunction = () => {};\n\n// Ignore unused dependency in package.json\n{\n  \"dependencies\": {\n    \"some-package\": \"1.0.0\" // @knip-ignore-dependency\n  }\n}\n```\n\n### Whitelist Pattern\n\n```typescript\n// knip.ts - Whitelist specific exports\nconst config: KnipConfig = {\n  entry: ['src/index.ts'],\n  project: ['src/**/*.ts'],\n\n  // Only these exports are allowed to be unused (public API)\n  exports: {\n    include: ['src/index.ts'],\n  },\n};\n```\n\n## CI/CD Integration\n\n### GitHub Actions\n\n```yaml\nname: Knip\non:\n  push:\n    branches: [main]\n  pull_request:\n\njobs:\n  knip:\n    name: Check for unused code\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n\n      - uses: oven-sh/setup-bun@v2\n        with:\n          bun-version: latest\n\n      - name: Install dependencies\n        run: bun install --frozen-lockfile\n\n      - name: Run Knip\n        run: bunx knip --production\n\n      - name: Run Knip (strict)\n        run: bunx knip --max-issues 0\n```\n\n### GitLab CI\n\n```yaml\nknip:\n  image: oven/bun:latest\n  stage: test\n  script:\n    - bun install --frozen-lockfile\n    - bunx knip --production\n  only:\n    - merge_requests\n    - main\n```\n\n### Pre-commit Hook\n\n```yaml\n# .pre-commit-config.yaml\nrepos:\n  - repo: local\n    hooks:\n      - id: knip\n        name: Knip\n        entry: bunx knip\n        language: system\n        pass_filenames: false\n```\n\n## Common Patterns\n\n### Check Only Unused Dependencies\n\n```bash\n# Fastest check - only dependencies\nbunx knip --dependencies\n\n# Exit with error if any unused dependencies\nbunx knip --dependencies --max-issues 0\n```\n\n**Use in CI to enforce strict dependency hygiene.**\n\n### Check Only Exports (Library Development)\n\n```bash\n# Check for unused exports\nbunx knip --exports\n\n# Allow exports used in same file\nbunx knip --exports --exclude-exports-used-in-file\n```\n\n**Use for libraries to ensure clean public API.**\n\n### Production vs Development Dependencies\n\n```bash\n# Check production code only\nbunx knip --production\n\n# Check everything (including dev dependencies)\nbunx knip\n```\n\n### Monorepo Workflows\n\n```typescript\n// knip.ts\nconst config: KnipConfig = {\n  workspaces: {\n    '.': {\n      entry: ['scripts/**/*.ts'],\n      ignoreDependencies: ['@org/internal-package'],\n    },\n    'packages/web': {\n      entry: ['src/index.ts', 'src/App.tsx'],\n      ignoreDependencies: ['react', 'react-dom'], // Provided by parent\n    },\n    'packages/api': {\n      entry: ['src/server.ts'],\n    },\n  },\n};\n```\n\n```bash\n# Check all workspaces\nbunx knip\n\n# Check specific workspace\nbunx knip --workspace packages/web\n```\n\n## Interpreting Results\n\n### Example Output\n\n```\n No unused files\n No unused dependencies\n 2 unused exports\n\nsrc/utils.ts:\n  - calculateTax (line 42)\n  - formatDate (line 58)\n\nsrc/types.ts:\n  - UserRole (line 12)\n```\n\n### Issue Types\n\n| Type | Description | Action |\n|------|-------------|--------|\n| Unused file | File not imported anywhere | Delete or add to entry points |\n| Unused dependency | Package in package.json not used | Remove from dependencies |\n| Unused export | Exported but never imported | Remove export or make private |\n| Unused type | Type/interface exported but unused | Remove or make internal |\n| Unused enum member | Enum member never referenced | Remove member |\n| Duplicate export | Same export from multiple files | Consolidate exports |\n\n## Troubleshooting\n\n### False Positives (Exports Used via Side Effects)\n\n```typescript\n// knip.ts\nconst config: KnipConfig = {\n  // Ignore exports that are used via side effects\n  ignoreExportsUsedInFile: true,\n\n  // Or add to entry points\n  entry: ['src/index.ts', 'src/side-effect-file.ts'],\n};\n```\n\n### Knip Not Finding Entry Points\n\n```bash\n# Debug configuration\nbunx knip --debug\n\n# Manually specify entry points\nbunx knip --entry src/index.ts --entry src/cli.ts\n```\n\n### Performance Issues\n\n```bash\n# Exclude node_modules explicitly (usually automatic)\nbunx knip --exclude '**/node_modules/**'\n\n# Use .gitignore patterns\nbunx knip --include-libs false\n\n# Increase memory limit\nNODE_OPTIONS=--max-old-space-size=4096 bunx knip\n```\n\n### Plugin Not Detected\n\n```typescript\n// knip.ts - Force enable plugin\nconst config: KnipConfig = {\n  vite: {\n    entry: ['vite.config.ts'],\n    config: ['vite.config.ts'],\n  },\n};\n```\n\n### Unused Dependencies in Scripts\n\n```json\n// package.json - Knip detects binaries in scripts\n{\n  \"scripts\": {\n    \"lint\": \"eslint .\", // Detects eslint dependency\n    \"test\": \"vitest\" // Detects vitest dependency\n  }\n}\n```\n\nIf not detected:\n```typescript\n// knip.ts\nconst config: KnipConfig = {\n  ignoreDependencies: ['eslint', 'vitest'],\n};\n```\n\n## Advanced Usage\n\n### Custom Reporters\n\n```bash\n# JSON output (for CI)\nbunx knip --reporter json > knip-report.json\n\n# Compact output\nbunx knip --reporter compact\n\n# Custom format (coming soon)\nbunx knip --reporter custom\n```\n\n### Incremental Checks (Changed Files Only)\n\n```bash\n# Check only changed files (requires git)\nbunx knip --changed\n\n# Since specific commit\nbunx knip --changed --base main\n```\n\n### Type Checking Integration\n\n```typescript\n// knip.ts\nconst config: KnipConfig = {\n  // Include type-only imports as used\n  includeTypeImports: true,\n\n  // Check for unused TypeScript types\n  types: true,\n};\n```\n\n## Best Practices\n\n### Start with Dependencies Only\n\n```bash\n# Easiest wins first\nbunx knip --dependencies\n\n# Then move to exports\nbunx knip --exports\n\n# Finally check files\nbunx knip --files\n```\n\n### Gradual Adoption\n\n```typescript\n// knip.ts - Start strict, then relax\nconst config: KnipConfig = {\n  // Start with critical paths only\n  entry: ['src/index.ts'],\n  project: ['src/core/**/*.ts'],\n\n  // Expand coverage over time\n  // entry: ['src/**/*.ts'],\n  // project: ['src/**/*.ts'],\n};\n```\n\n### CI Strategy\n\n```yaml\n# Check dependencies in CI (fast, high value)\n- name: Check unused dependencies\n  run: bunx knip --dependencies --max-issues 0\n\n# Check exports in PR (prevents API bloat)\n- name: Check unused exports\n  run: bunx knip --exports\n  if: github.event_name == 'pull_request'\n```\n\n### Maintenance Schedule\n\n- **Weekly**: Run full Knip scan, clean up issues\n- **PR Review**: Check for new unused exports\n- **Pre-release**: Full scan with `--production`\n- **Refactors**: Run Knip before and after\n\n## References\n\n- Official docs: https://knip.dev\n- Configuration: https://knip.dev/reference/configuration\n- Plugins: https://knip.dev/reference/plugins\n- CLI reference: https://knip.dev/reference/cli\n- FAQ: https://knip.dev/reference/faq"
              },
              {
                "name": "nodejs-development",
                "description": "Modern Node.js development with Bun, Vite, Vue 3, Pinia, and TypeScript. Covers\nJavaScript/TypeScript projects, high-performance tooling, and modern frameworks.\nUse when user mentions Node.js, Bun, Vite, Vue, Pinia, npm, pnpm, JavaScript runtime,\nor building frontend/backend JS applications.\n",
                "path": "typescript-plugin/skills/nodejs-development/SKILL.md",
                "frontmatter": {
                  "created": "2025-12-16T00:00:00.000Z",
                  "modified": "2025-12-16T00:00:00.000Z",
                  "reviewed": "2025-12-16T00:00:00.000Z",
                  "name": "nodejs-development",
                  "description": "Modern Node.js development with Bun, Vite, Vue 3, Pinia, and TypeScript. Covers\nJavaScript/TypeScript projects, high-performance tooling, and modern frameworks.\nUse when user mentions Node.js, Bun, Vite, Vue, Pinia, npm, pnpm, JavaScript runtime,\nor building frontend/backend JS applications.\n",
                  "allowed-tools": "Glob, Grep, Read, Bash, Edit, Write, TodoWrite, WebFetch, WebSearch, BashOutput, KillShell, NotebookEdit"
                },
                "content": "# Node.js Development\n\nExpert knowledge for modern JavaScript/TypeScript development with focus on high-performance tooling and frameworks.\n\n## Core Expertise\n\n**Modern JavaScript Tooling**\n- **Bun**: Primary JavaScript runtime and package manager (25x faster than npm)\n- **Vite**: Lightning-fast build tool with HMR and optimized production builds\n- **TypeScript**: Type-safe development with modern configurations\n- **ESM**: Modern module syntax and tree-shaking optimization\n\n## Key Capabilities\n\n**Bun Runtime & Package Management**\n- Use `bun install` for dependency installation and `bun.lock` for reproducible builds\n- Implement `bun run` for script execution and `bun dev`/`bun build` patterns\n- Configure `bunfig.toml` for project-specific Bun settings\n- Leverage Bun's native TypeScript support and built-in bundler\n\n**Vue 3 & Modern Frontend**\n- **Vue 3**: Composition API, script setup, and reactive patterns\n- **Pinia**: State management with TypeScript support\n- **Vuetify**: Material Design components\n- **Vite**: Fast development server with instant HMR\n\n**TypeScript Excellence**\n- Configure TypeScript with strict mode and modern target settings\n- Implement comprehensive type definitions for Vue components and stores\n- Use TypeScript with Vite for optimal development experience\n- Apply advanced TypeScript patterns for robust applications\n\n**Testing & Quality Assurance**\n- **Vitest**: Fast unit testing framework with native TypeScript support\n- **Playwright**: End-to-end testing with browser automation\n- **Biome**: Code quality and formatting (unified, fast)\n\n**Debugging**\n- **Chrome DevTools**: Advanced debugging for browser and Node.js\n- **Node.js Inspector**: Built-in debugging with breakpoints and profiling\n- **Heap Snapshots**: Memory leak detection and heap analysis\n- **Performance Profiling**: CPU profiling, flame graphs, bottleneck identification\n- **Vue DevTools**: Component tree, state inspection, performance monitoring\n\n## Essential Commands\n\n```bash\n# Bun-first workflow\nbun create vite my-app --template vue-ts  # Create Vue 3 + TypeScript project\ncd my-app && bun install                  # Install dependencies\n\n# Development\nbun dev                          # Start dev server\nbun build                        # Build for production\nbun run check                    # Run Biome lint + format\nbun run test                     # Run tests\n\n# Debugging\nnode --inspect script.js         # Node.js debugging\nbun --inspect script.ts          # Bun debugging\nnode --prof script.js            # CPU profiling\n```\n\n## Best Practices\n\n**Project Structure**\n- Organize Vue 3 projects with clear component, store, and router separation\n- Configure `vite.config.ts` with optimizations\n- Implement proper error boundaries and loading states\n- Use Vue 3's Teleport and Suspense for advanced UI patterns\n\n**Performance & Security**\n- Implement proper CSP headers and security configurations\n- Optimize images and assets with Vite's asset handling\n- Use lazy loading and code splitting\n- Apply proper form validation and sanitization\n\n**Type Safety**\n```typescript\n// Modern type annotations (TypeScript 5.0+)\nfunction processData(\n    items: string[],\n    config: Record<string, number>,\n    optional?: string | null\n): [boolean, string] {\n    return [true, \"success\"];\n}\n```\n\nFor detailed debugging patterns, Vue 3 component structure, Vite configuration, production debugging, and framework integration, see REFERENCE.md."
              },
              {
                "name": "TypeScript Strict Mode",
                "description": "TypeScript strict mode configuration for 2025. Recommended tsconfig.json settings,\nstrict flags explained, moduleResolution strategies (Bundler vs NodeNext),\nverbatimModuleSyntax, noUncheckedIndexedAccess. Use when setting up TypeScript projects\nor migrating to stricter type safety.\n",
                "path": "typescript-plugin/skills/typescript-strict/SKILL.md",
                "frontmatter": {
                  "created": "2025-12-16T00:00:00.000Z",
                  "modified": "2025-12-16T00:00:00.000Z",
                  "reviewed": "2025-12-16T00:00:00.000Z",
                  "name": "TypeScript Strict Mode",
                  "description": "TypeScript strict mode configuration for 2025. Recommended tsconfig.json settings,\nstrict flags explained, moduleResolution strategies (Bundler vs NodeNext),\nverbatimModuleSyntax, noUncheckedIndexedAccess. Use when setting up TypeScript projects\nor migrating to stricter type safety.\n",
                  "allowed-tools": "Glob, Grep, Read, Bash, Edit, Write, TodoWrite, WebFetch, WebSearch, BashOutput, KillShell"
                },
                "content": "# TypeScript Strict Mode\n\nModern TypeScript configuration with strict type checking for maximum safety and developer experience. This guide focuses on TypeScript 5.x best practices for 2025.\n\n## Core Expertise\n\n**What is Strict Mode?**\n- **Type safety**: Catch more bugs at compile time\n- **Better IDE experience**: Improved autocomplete and refactoring\n- **Maintainability**: Self-documenting code with explicit types\n- **Modern defaults**: Align with current TypeScript best practices\n\n**Key Capabilities**\n- Strict null checking\n- Strict function types\n- No implicit any\n- No unchecked indexed access\n- Proper module resolution\n- Modern import/export syntax enforcement\n\n## Recommended tsconfig.json (2025)\n\n### Minimal Production Setup\n\n```json\n{\n  \"compilerOptions\": {\n    // Type Checking\n    \"strict\": true,\n    \"noUncheckedIndexedAccess\": true,\n    \"noImplicitOverride\": true,\n    \"noPropertyAccessFromIndexSignature\": true,\n    \"noFallthroughCasesInSwitch\": true,\n    \"noUnusedLocals\": true,\n    \"noUnusedParameters\": true,\n\n    // Modules\n    \"module\": \"ESNext\",\n    \"moduleResolution\": \"Bundler\",\n    \"resolveJsonModule\": true,\n    \"allowSyntheticDefaultImports\": true,\n    \"esModuleInterop\": false,\n    \"verbatimModuleSyntax\": true,\n\n    // Emit\n    \"target\": \"ES2022\",\n    \"lib\": [\"ES2023\", \"DOM\", \"DOM.Iterable\"],\n    \"outDir\": \"dist\",\n    \"declaration\": true,\n    \"declarationMap\": true,\n    \"sourceMap\": true,\n    \"removeComments\": false,\n    \"noEmit\": false,\n\n    // Interop\n    \"isolatedModules\": true,\n    \"allowJs\": false,\n    \"checkJs\": false,\n    \"skipLibCheck\": true,\n    \"forceConsistentCasingInFileNames\": true\n  },\n  \"include\": [\"src/**/*\"],\n  \"exclude\": [\"node_modules\", \"dist\", \"build\"]\n}\n```\n\n### Vite/Bun Project (Bundler)\n\n```json\n{\n  \"compilerOptions\": {\n    // Type Checking - Maximum strictness\n    \"strict\": true,\n    \"noUncheckedIndexedAccess\": true,\n    \"noImplicitOverride\": true,\n    \"noPropertyAccessFromIndexSignature\": true,\n    \"noFallthroughCasesInSwitch\": true,\n    \"noUnusedLocals\": true,\n    \"noUnusedParameters\": true,\n    \"allowUnreachableCode\": false,\n    \"allowUnusedLabels\": false,\n    \"exactOptionalPropertyTypes\": true,\n\n    // Modules (Bundler for Vite/Bun)\n    \"module\": \"ESNext\",\n    \"moduleResolution\": \"Bundler\",\n    \"resolveJsonModule\": true,\n    \"allowSyntheticDefaultImports\": true,\n    \"esModuleInterop\": false,\n    \"verbatimModuleSyntax\": true,\n\n    // Emit (Vite handles bundling)\n    \"target\": \"ES2022\",\n    \"lib\": [\"ES2023\", \"DOM\", \"DOM.Iterable\"],\n    \"jsx\": \"preserve\", // Vite handles JSX\n    \"noEmit\": true, // Vite handles emit\n\n    // Interop\n    \"isolatedModules\": true,\n    \"skipLibCheck\": true,\n    \"forceConsistentCasingInFileNames\": true,\n\n    // Path Mapping\n    \"baseUrl\": \".\",\n    \"paths\": {\n      \"@/*\": [\"src/*\"],\n      \"@components/*\": [\"src/components/*\"]\n    }\n  },\n  \"include\": [\"src/**/*\", \"vite.config.ts\"],\n  \"exclude\": [\"node_modules\", \"dist\"]\n}\n```\n\n### Node.js Library (NodeNext)\n\n```json\n{\n  \"compilerOptions\": {\n    // Type Checking\n    \"strict\": true,\n    \"noUncheckedIndexedAccess\": true,\n    \"noImplicitOverride\": true,\n\n    // Modules (NodeNext for Node.js)\n    \"module\": \"NodeNext\",\n    \"moduleResolution\": \"NodeNext\",\n    \"resolveJsonModule\": true,\n    \"allowSyntheticDefaultImports\": false,\n    \"esModuleInterop\": true,\n    \"verbatimModuleSyntax\": true,\n\n    // Emit (Node.js library)\n    \"target\": \"ES2022\",\n    \"lib\": [\"ES2023\"],\n    \"outDir\": \"dist\",\n    \"declaration\": true,\n    \"declarationMap\": true,\n    \"sourceMap\": true,\n\n    // Interop\n    \"isolatedModules\": true,\n    \"skipLibCheck\": true,\n    \"forceConsistentCasingInFileNames\": true\n  },\n  \"include\": [\"src/**/*\"],\n  \"exclude\": [\"node_modules\", \"dist\"]\n}\n```\n\n## Strict Flags Explained\n\n### `strict: true` (Umbrella Flag)\n\nEnables all strict type-checking options:\n\n```json\n{\n  \"strict\": true\n  // Equivalent to:\n  // \"noImplicitAny\": true,\n  // \"strictNullChecks\": true,\n  // \"strictFunctionTypes\": true,\n  // \"strictBindCallApply\": true,\n  // \"strictPropertyInitialization\": true,\n  // \"noImplicitThis\": true,\n  // \"alwaysStrict\": true\n}\n```\n\n**Always enable `strict: true` for new projects.**\n\n### `noImplicitAny`\n\nDisallows variables with implicit `any` type.\n\n```typescript\n//  Error with noImplicitAny\nfunction add(a, b) {\n  //         ^ Error: Parameter 'a' implicitly has an 'any' type\n  return a + b;\n}\n\n//  Correct\nfunction add(a: number, b: number): number {\n  return a + b;\n}\n```\n\n### `strictNullChecks`\n\n`null` and `undefined` are distinct from other types.\n\n```typescript\n//  Error with strictNullChecks\nconst name: string = null;\n//                   ^^^^ Error: Type 'null' is not assignable to type 'string'\n\n//  Correct\nconst name: string | null = null;\n\n//  Correct (handle null explicitly)\nfunction greet(name: string | null): string {\n  if (name === null) {\n    return 'Hello, stranger!';\n  }\n  return `Hello, ${name}!`;\n}\n```\n\n### `strictFunctionTypes`\n\nFunction parameter types are checked contravariantly.\n\n```typescript\ntype Logger = (msg: string | number) => void;\n\n//  Error with strictFunctionTypes\nconst log: Logger = (msg: string) => console.log(msg);\n//                   ^^^^^^^^^^^^^ Error: Type '(msg: string) => void' is not assignable\n\n//  Correct\nconst log: Logger = (msg: string | number) => console.log(msg);\n```\n\n### `strictBindCallApply`\n\nCheck that `bind`, `call`, and `apply` are invoked correctly.\n\n```typescript\nfunction greet(name: string, age: number) {\n  console.log(`${name} is ${age} years old`);\n}\n\n//  Error with strictBindCallApply\ngreet.call(undefined, 'John', '25');\n//                            ^^^^ Error: Argument of type 'string' is not assignable to 'number'\n\n//  Correct\ngreet.call(undefined, 'John', 25);\n```\n\n### `strictPropertyInitialization`\n\nClass properties must be initialized.\n\n```typescript\nclass User {\n  //  Error with strictPropertyInitialization\n  name: string;\n  //    ^^^^^^ Error: Property 'name' has no initializer\n\n  //  Correct (initialize in constructor)\n  name: string;\n  constructor(name: string) {\n    this.name = name;\n  }\n\n  //  Correct (default value)\n  age: number = 0;\n\n  //  Correct (definitely assigned assertion)\n  id!: number;\n}\n```\n\n### `noImplicitThis`\n\nDisallow `this` with implicit `any` type.\n\n```typescript\n//  Error with noImplicitThis\nfunction logName() {\n  console.log(this.name);\n  //          ^^^^ Error: 'this' implicitly has type 'any'\n}\n\n//  Correct (explicit this parameter)\nfunction logName(this: { name: string }) {\n  console.log(this.name);\n}\n```\n\n## Additional Strict Flags (Recommended for 2025)\n\n### `noUncheckedIndexedAccess` (Essential)\n\nIndex signatures return `T | undefined` instead of `T`.\n\n```typescript\n// Without noUncheckedIndexedAccess\nconst users: Record<string, User> = {};\nconst user = users['john'];\n// Type: User (wrong - might be undefined)\n\n//  With noUncheckedIndexedAccess\nconst users: Record<string, User> = {};\nconst user = users['john'];\n// Type: User | undefined (correct)\n\nif (user) {\n  console.log(user.name); // Type narrowed to User\n}\n```\n\n**Always enable this flag to prevent runtime errors.**\n\n### `noImplicitOverride`\n\nRequire `override` keyword for overridden methods.\n\n```typescript\nclass Base {\n  greet() {\n    console.log('Hello');\n  }\n}\n\nclass Derived extends Base {\n  //  Error with noImplicitOverride\n  greet() {\n    //  ^^^^^ Error: This member must have an 'override' modifier\n    console.log('Hi');\n  }\n\n  //  Correct\n  override greet() {\n    console.log('Hi');\n  }\n}\n```\n\n### `noPropertyAccessFromIndexSignature`\n\nForce bracket notation for index signatures.\n\n```typescript\ntype User = {\n  name: string;\n  [key: string]: string;\n};\n\nconst user: User = { name: 'John', email: 'john@example.com' };\n\n//  Error with noPropertyAccessFromIndexSignature\nconsole.log(user.email);\n//              ^^^^^ Error: Property 'email' comes from index signature, use bracket notation\n\n//  Correct\nconsole.log(user['email']);\n\n//  Also correct (explicit property)\nconsole.log(user.name);\n```\n\n### `noFallthroughCasesInSwitch`\n\nPrevent fallthrough in switch statements.\n\n```typescript\nfunction getDiscount(role: string): number {\n  switch (role) {\n    case 'admin':\n      return 0.5;\n    //  Error with noFallthroughCasesInSwitch\n    case 'user':\n      //    ^^^^ Error: Fallthrough case in switch\n      console.log('User discount');\n    case 'guest':\n      return 0.1;\n  }\n}\n\n//  Correct\nfunction getDiscount(role: string): number {\n  switch (role) {\n    case 'admin':\n      return 0.5;\n    case 'user':\n      console.log('User discount');\n      return 0.2; // Explicit return\n    case 'guest':\n      return 0.1;\n    default:\n      return 0;\n  }\n}\n```\n\n### `exactOptionalPropertyTypes`\n\nOptional properties cannot be set to `undefined` explicitly.\n\n```typescript\ntype User = {\n  name: string;\n  age?: number; // Type: number | undefined (implicit)\n};\n\n//  Error with exactOptionalPropertyTypes\nconst user: User = { name: 'John', age: undefined };\n//                                      ^^^^^^^^^ Error: Type 'undefined' is not assignable\n\n//  Correct (omit property)\nconst user: User = { name: 'John' };\n\n//  Correct (assign a value)\nconst user2: User = { name: 'Jane', age: 25 };\n```\n\n## Module Resolution\n\n### `moduleResolution: \"Bundler\"` (Vite/Bun)\n\nUse for projects with bundlers (Vite, Webpack, Bun).\n\n```json\n{\n  \"compilerOptions\": {\n    \"module\": \"ESNext\",\n    \"moduleResolution\": \"Bundler\"\n  }\n}\n```\n\n**Features:**\n-  No file extensions required in imports\n-  JSON imports without assertions\n-  Package.json `exports` field support\n-  Optimized for bundlers\n\n```typescript\n//  Works with Bundler\nimport config from './config.json';\nimport { add } from './utils'; // No .ts extension\n```\n\n### `moduleResolution: \"NodeNext\"` (Node.js)\n\nUse for Node.js libraries and servers.\n\n```json\n{\n  \"compilerOptions\": {\n    \"module\": \"NodeNext\",\n    \"moduleResolution\": \"NodeNext\"\n  }\n}\n```\n\n**Features:**\n-  Respects package.json `type: \"module\"`\n-  Requires explicit `.js` extensions (even for `.ts` files)\n-  Supports conditional exports\n-  Aligned with Node.js ESM behavior\n\n```typescript\n//  Works with NodeNext (note .js extension)\nimport { add } from './utils.js';\nimport config from './config.json' assert { type: 'json' };\n```\n\n**package.json:**\n```json\n{\n  \"type\": \"module\",\n  \"exports\": {\n    \".\": {\n      \"import\": \"./dist/index.js\",\n      \"types\": \"./dist/index.d.ts\"\n    }\n  }\n}\n```\n\n## verbatimModuleSyntax (Recommended for 2025)\n\nPrevents TypeScript from rewriting imports/exports.\n\n```json\n{\n  \"compilerOptions\": {\n    \"verbatimModuleSyntax\": true\n  }\n}\n```\n\n**Benefits:**\n-  Explicit `type` imports required\n-  Prevents unintended side effects\n-  Better tree-shaking\n-  Aligns with future JavaScript standards\n\n```typescript\n//  Error with verbatimModuleSyntax\nimport { User } from './types';\n//      ^^^^^^ Error: 'User' is a type and must be imported with 'import type'\n\n//  Correct\nimport type { User } from './types';\n\n//  Correct (value import)\nimport { fetchUser } from './api';\n\n//  Correct (mixed import)\nimport { fetchUser, type User } from './api';\n```\n\n**Replaces:**\n- `importsNotUsedAsValues` (deprecated)\n- `preserveValueImports` (deprecated)\n\n## Path Mapping\n\n```json\n{\n  \"compilerOptions\": {\n    \"baseUrl\": \".\",\n    \"paths\": {\n      \"@/*\": [\"src/*\"],\n      \"@components/*\": [\"src/components/*\"],\n      \"@utils/*\": [\"src/utils/*\"]\n    }\n  }\n}\n```\n\n**Usage:**\n```typescript\n// Instead of\nimport { Button } from '../../../components/Button';\n\n// Use\nimport { Button } from '@components/Button';\n```\n\n**Vite/Bun configuration:**\n```typescript\n// vite.config.ts\nimport { defineConfig } from 'vite';\nimport path from 'path';\n\nexport default defineConfig({\n  resolve: {\n    alias: {\n      '@': path.resolve(__dirname, './src'),\n      '@components': path.resolve(__dirname, './src/components'),\n    },\n  },\n});\n```\n\n## Migrating to Strict Mode\n\n### Step 1: Enable Gradually\n\n```json\n{\n  \"compilerOptions\": {\n    // Start with these\n    \"noImplicitAny\": true,\n    \"strictNullChecks\": false, // Enable later\n    \"strictFunctionTypes\": true,\n    \"strictBindCallApply\": true,\n    \"strictPropertyInitialization\": false, // Enable later\n    \"noImplicitThis\": true,\n    \"alwaysStrict\": true\n  }\n}\n```\n\n### Step 2: Fix Errors Incrementally\n\n```bash\n# Check errors without emitting\nbunx tsc --noEmit\n\n# Fix files one at a time\nbunx tsc --noEmit src/utils.ts\n```\n\n### Step 3: Enable Remaining Flags\n\n```json\n{\n  \"compilerOptions\": {\n    \"strict\": true, // Enable all at once\n    \"noUncheckedIndexedAccess\": true\n  }\n}\n```\n\n### Step 4: Optional Strict Flags\n\n```json\n{\n  \"compilerOptions\": {\n    \"strict\": true,\n    \"noUncheckedIndexedAccess\": true,\n    \"noImplicitOverride\": true,\n    \"noPropertyAccessFromIndexSignature\": true,\n    \"exactOptionalPropertyTypes\": true\n  }\n}\n```\n\n## Common Patterns\n\n### Handling Null/Undefined\n\n```typescript\n// Non-null assertion (use sparingly)\nconst element = document.getElementById('app')!;\n\n// Optional chaining\nconst name = user?.profile?.name;\n\n// Nullish coalescing\nconst displayName = user?.name ?? 'Anonymous';\n\n// Type guard\nfunction isUser(value: unknown): value is User {\n  return typeof value === 'object' && value !== null && 'name' in value;\n}\n```\n\n### Index Signature Safety\n\n```typescript\n//  Unsafe\nconst value = obj[key]; // Type: T (wrong)\n\n//  Safe with noUncheckedIndexedAccess\nconst value = obj[key]; // Type: T | undefined\n\nif (value !== undefined) {\n  // Type: T\n  console.log(value);\n}\n\n//  Safe with assertion\nconst value = obj[key];\nif (value === undefined) throw new Error('Key not found');\n// Type: T (narrowed)\n```\n\n## Troubleshooting\n\n### Too Many Errors\n\n```bash\n# Enable flags gradually\n# Start with noImplicitAny, then add others\n\n# Use @ts-expect-error for temporary fixes\n// @ts-expect-error - TODO: Fix this type\nconst value: string = null;\n```\n\n### Library Types Missing\n\n```bash\n# Install type definitions\nbun add --dev @types/node @types/react\n\n# Skip type checking for libraries\n{\n  \"compilerOptions\": {\n    \"skipLibCheck\": true\n  }\n}\n```\n\n### Module Resolution Errors\n\n```typescript\n// Bundler: No extension needed\nimport { add } from './utils';\n\n// NodeNext: Requires .js extension\nimport { add } from './utils.js';\n\n// Check moduleResolution setting\nbunx tsc --showConfig | grep moduleResolution\n```\n\n## References\n\n- TypeScript Handbook: https://www.typescriptlang.org/docs/handbook/intro.html\n- TSConfig Reference: https://www.typescriptlang.org/tsconfig\n- Strict Mode Guide: https://www.typescriptlang.org/tsconfig#strict\n- Module Resolution: https://www.typescriptlang.org/docs/handbook/module-resolution.html\n- Best Practices: https://www.typescriptlang.org/docs/handbook/declaration-files/do-s-and-don-ts.html"
              }
            ]
          },
          {
            "name": "tools-plugin",
            "description": "General utilities - fd, rg, jq, shell, imagemagick",
            "source": "./tools-plugin",
            "category": "utilities",
            "version": "2.0.1",
            "author": null,
            "install_commands": [
              "/plugin marketplace add laurigates/claude-plugins",
              "/plugin install tools-plugin@lgates-claude-plugins"
            ],
            "signals": {
              "stars": 1,
              "forks": 0,
              "pushed_at": "2026-01-12T12:05:51Z",
              "created_at": "2025-12-16T11:24:04Z",
              "license": null
            },
            "commands": [
              {
                "name": "/generate-image",
                "description": "Generate images using Nano Banana Pro (Gemini 3 Pro Image)",
                "path": "tools-plugin/commands/generate-image.md",
                "frontmatter": {
                  "created": "2025-12-16T00:00:00.000Z",
                  "modified": "2025-12-16T00:00:00.000Z",
                  "reviewed": "2025-12-16T00:00:00.000Z",
                  "description": "Generate images using Nano Banana Pro (Gemini 3 Pro Image)",
                  "args": "<prompt> [--aspect <ratio>] [--resolution <size>] [--reference <path>]"
                },
                "content": "Generate images using Google's Nano Banana Pro (Gemini 3 Pro Image) model.\n\n## Arguments\n\n- **{{arg:1}}** (required): Image description\n- **--aspect**: Aspect ratio (`1:1`, `2:3`, `3:2`, `3:4`, `4:3`, `4:5`, `5:4`, `9:16`, `16:9`, `21:9`) - default: `16:9`\n- **--resolution**: Image resolution (`1K`, `2K`, `4K`) - default: `2K`\n- **--reference**: Path to reference image (repeatable, max 5)\n- **--output**: Custom output path\n\n## Environment Requirements\n\nVerify API key is set:\n```bash\necho \"API Key: ${GOOGLE_API_KEY:+SET}${GEMINI_API_KEY:+SET}\"\n```\n\nIf not set, get one from: https://aistudio.google.com/apikey\n\n## Usage Examples\n\n```\n/generate-image \"A beautiful mountain landscape at sunset\"\n/generate-image \"Product photo on white background\" --aspect 1:1 --resolution 4K\n/generate-image \"Portrait photo\" --aspect 3:4\n/generate-image \"Cinematic scene\" --aspect 21:9\n/generate-image \"Similar style\" --reference existing_image.png\n```\n\n## Task Workflow\n\n1. **Parse arguments**:\n   - Extract prompt from {{arg:1}}\n   - Identify aspect ratio, resolution, and reference images\n\n2. **Build command**:\n   ```bash\n   uv run python .claude/scripts/nano_banana_pro.py \\\n     \"{{arg:1}}\" \\\n     --aspect {{aspect|default:\"16:9\"}} \\\n     --resolution {{resolution|default:\"2K\"}} \\\n     {{reference_flags}}\n   ```\n\n3. **Execute generation**:\n   ```bash\n   uv run python .claude/scripts/nano_banana_pro.py \"PROMPT\" --aspect RATIO --resolution SIZE\n   ```\n\n4. **Report results**:\n   - Show path to generated image\n   - Note any reference images used\n   - Offer next steps (regenerate, different aspect, etc.)\n\n## Output\n\nDefault output: `./generated/image_YYYYMMDD_HHMMSS.png`\n\nCustom output with `--output`:\n```\n/generate-image \"Scene\" --output custom_name.png\n```\n\n## Reference Images\n\nReference images help maintain consistency:\n- Use existing images as style references\n- Keep subjects consistent across generations\n- Match artistic styles\n\nWhen using references, describe the relationship:\n- \"Similar style to the reference\"\n- \"This person in a different setting\"\n- \"Same product, different angle\"\n\nMaximum 5 reference images per generation.\n\n## Aspect Ratio Quick Reference\n\n| Use Case | Ratio |\n|----------|-------|\n| Square/Instagram | 1:1 |\n| Portrait | 3:4, 9:16 |\n| Landscape | 16:9 |\n| Ultrawide | 21:9 |\n| Photo | 3:2, 4:3 |\n\n## Resolution Quick Reference\n\n| Use Case | Resolution |\n|----------|------------|\n| Preview | 1K |\n| Standard | 2K |\n| High quality | 4K |\n\n## Error Handling\n\n- **No API key**: Set `GOOGLE_API_KEY` or `GEMINI_API_KEY`\n- **Generation failed**: Simplify prompt or reduce references\n- **Rate limited**: Wait and retry"
              },
              {
                "name": "/handoffs",
                "description": "List, filter, and manage @AGENT-HANDOFF-MARKER markers across the codebase",
                "path": "tools-plugin/commands/handoffs.md",
                "frontmatter": {
                  "created": "2025-12-16T00:00:00.000Z",
                  "modified": "2025-12-16T00:00:00.000Z",
                  "reviewed": "2025-12-16T00:00:00.000Z",
                  "description": "List, filter, and manage @AGENT-HANDOFF-MARKER markers across the codebase",
                  "allowed_tools": [
                    "Bash",
                    "Grep",
                    "Read",
                    "TodoWrite"
                  ]
                },
                "content": "# /handoffs [OPTIONS]\n\nList all `@AGENT-HANDOFF-MARKER(agent)` markers in the codebase with filtering and status information.\n\n## Usage\n\n```bash\n/handoffs                           # List all pending handoffs\n/handoffs --agent ux-implementation # Filter by target agent\n/handoffs --stale                   # Show markers older than 7 days\n/handoffs --type accessibility      # Filter by handoff type\n/handoffs --priority blocking       # Filter by priority level\n/handoffs --summary                 # Show counts by agent/type\n```\n\n## Parameters\n\n- `--agent <name>` - Filter by target agent (e.g., `ux-implementation`, `typescript-development`)\n- `--stale` - Show only markers that haven't been addressed in 7+ days (based on git blame)\n- `--type <type>` - Filter by handoff type (e.g., `accessibility`, `form-validation`, `loading-states`)\n- `--priority <level>` - Filter by priority (`blocking`, `enhancement`)\n- `--summary` - Show summary counts instead of full listings\n- `--completed` - Include completed handoffs (`@AGENT-HANDOFF-MARKER-COMPLETE`)\n\n## Steps\n\n1. **Scan for markers**:\n   ```bash\n   # Find all @AGENT-HANDOFF-MARKER markers\n   rg \"@AGENT-HANDOFF-MARKER\\([^)]+\\)\" --type ts --type tsx --type js --type jsx --type vue -n\n   ```\n\n2. **Parse marker content**:\n   - Extract target agent from `@AGENT-HANDOFF-MARKER(agent-name)`\n   - Parse JSON-like content for type, priority, context, needs\n   - Note file path and line number\n\n3. **Apply filters**:\n   - If `--agent`: filter to matching target agent\n   - If `--type`: filter to matching handoff type\n   - If `--priority`: filter to matching priority level\n   - If `--stale`: use git blame to find markers >7 days old\n\n4. **Format output**:\n\n   **Default listing**:\n   ```\n   ## Pending Handoffs\n\n   ### ux-implementation (3 markers)\n\n   **src/components/Modal.tsx:42** [blocking]\n   - Type: accessibility\n   - Context: Modal dialog for confirmation actions\n   - Needs:\n     - Focus trap implementation\n     - ARIA dialog pattern\n     - Keyboard handling (Escape to close)\n\n   **src/pages/Register.tsx:156** [blocking]\n   - Type: form-validation\n   - Context: User registration form\n   - Needs:\n     - Error message placement\n     - Focus management on validation failure\n\n   **src/components/DataTable.tsx:89** [enhancement]\n   - Type: responsive\n   - Context: Data table with sortable columns\n   - Needs:\n     - Mobile layout pattern\n     - Touch-friendly sort controls\n\n   ### typescript-development (1 marker)\n\n   **src/components/Modal.tsx:98** [blocking]\n   - Type: component-implementation\n   - Context: Modal with UX specs from above\n   - Needs:\n     - React component implementation\n     - State management integration\n   ```\n\n   **Summary output** (`--summary`):\n   ```\n   ## Handoff Summary\n\n   ### By Agent\n   - ux-implementation: 3 (2 blocking, 1 enhancement)\n   - typescript-development: 1 (1 blocking)\n   - code-review: 0\n\n   ### By Type\n   - accessibility: 1\n   - form-validation: 1\n   - responsive: 1\n   - component-implementation: 1\n\n   ### By Priority\n   - blocking: 3\n   - enhancement: 1\n\n   Total: 4 pending handoffs\n   ```\n\n5. **Stale detection** (if `--stale`):\n   - Use git blame to get last modification date for each marker line\n   - Flag markers older than 7 days\n   - Show days since last modification\n\n   ```\n   ## Stale Handoffs (>7 days)\n\n   **src/components/OldComponent.tsx:34** [14 days old]\n   - Agent: ux-implementation\n   - Type: accessibility\n   - Last touched: 2024-01-01 by developer@example.com\n   ```\n\n6. **Provide next steps**:\n   ```\n   ## Next Steps\n\n   To address blocking handoffs:\n   1. Run the ux-implementation agent to process accessibility markers\n   2. Run the typescript-development agent after UX specs are complete\n\n   To clean up stale markers:\n   - Review if still needed\n   - Convert to @AGENT-HANDOFF-MARKER-COMPLETE if done\n   - Remove if obsolete\n   ```\n\n## Example Output\n\n```\n## Pending Handoffs\n\nFound 4 handoff markers across 3 files.\n\n### ux-implementation (3 markers)\n\n **src/components/Modal.tsx:42** `blocking`\n```typescript\n// @AGENT-HANDOFF-MARKER(ux-implementation) {\n//   type: \"accessibility\",\n//   context: \"Modal dialog for confirmation\",\n//   needs: [\"focus trap\", \"ARIA dialog\", \"Escape key\"]\n// }\n```\n Needs: Focus trap, ARIA dialog pattern, keyboard handling\n\n **src/pages/Register.tsx:156** `blocking`\n Needs: Error placement, focus management, ARIA live regions\n\n **src/components/DataTable.tsx:89** `enhancement`\n Needs: Mobile layout, touch-friendly controls\n\n### typescript-development (1 marker)\n\n **src/components/Modal.tsx:98** `blocking`\n Needs: React implementation, state management\n\n---\n\n**Summary**: 4 total (3 blocking, 1 enhancement)\n\n**Recommended workflow**:\n1. Process ux-implementation markers first (blocking work)\n2. Then typescript-development can implement specified patterns\n3. Finally code-review for quality validation\n```\n\n## Error Handling\n\n- **No markers found**: Report \"No @AGENT-HANDOFF-MARKER markers found in codebase\"\n- **Invalid filter**: Report unrecognized agent/type and list valid options\n- **Git not available**: Skip stale detection, note in output\n\n## See Also\n\n- **Skills**: `agent-handoff-markers` for marker format and patterns\n- **Skills**: `agent-coordination-patterns` for workflow patterns\n- **Skills**: `agent-file-coordination` for file-based coordination\n- **Commands**: `/workflow:primer` for agent continuation primers"
              }
            ],
            "skills": [
              {
                "name": "Binary Analysis",
                "description": "Reverse engineering and binary exploration using strings, binwalk, hexdump, and related tools.",
                "path": "tools-plugin/skills/binary-analysis/SKILL.md",
                "frontmatter": {
                  "name": "Binary Analysis",
                  "description": "Reverse engineering and binary exploration using strings, binwalk, hexdump, and related tools.",
                  "allowed-tools": "Bash, Read, Grep, Glob",
                  "created": "2025-12-27T00:00:00.000Z",
                  "modified": "2025-12-27T00:00:00.000Z",
                  "reviewed": "2025-12-27T00:00:00.000Z"
                },
                "content": "# Binary Analysis\n\nTools for exploring and reverse engineering binary files, firmware, and unknown data.\n\n## Quick Reference\n\n| Tool | Purpose | Install |\n|------|---------|---------|\n| `strings` | Extract printable text from binaries | Built-in (binutils) |\n| `binwalk` | Firmware analysis, file extraction | `pip install binwalk` or `cargo install binwalk` |\n| `hexdump` | Hex/ASCII dump | Built-in |\n| `xxd` | Hex dump with reverse capability | Built-in (vim) |\n| `file` | Identify file type | Built-in |\n\n## strings - Extract Text from Binaries\n\nFind human-readable strings embedded in binary files.\n\n```bash\n# Basic usage - find all printable strings (min 4 chars)\nstrings binary_file\n\n# Set minimum string length\nstrings -n 10 binary_file          # Only strings >= 10 chars\n\n# Show file offset of each string\nstrings -t x binary_file           # Hex offset\nstrings -t d binary_file           # Decimal offset\n\n# Search for specific patterns\nstrings binary_file | grep -i password\nstrings binary_file | grep -E 'https?://'\nstrings binary_file | grep -i api_key\n\n# Wide character strings (UTF-16)\nstrings -e l binary_file           # Little-endian 16-bit\nstrings -e b binary_file           # Big-endian 16-bit\nstrings -e L binary_file           # Little-endian 32-bit\n\n# Scan entire file (not just initialized data sections)\nstrings -a binary_file\n```\n\n**Common discoveries with strings:**\n- Hardcoded credentials, API keys\n- URLs and endpoints\n- Error messages (hints at functionality)\n- Library versions\n- Debug symbols and function names\n- Configuration paths\n\n## binwalk - Firmware Analysis\n\nIdentify and extract embedded files, analyze entropy, find hidden data.\n\n```bash\n# Signature scan - identify embedded files/data\nbinwalk firmware.bin\n\n# Extract all identified files\nbinwalk -e firmware.bin            # Extract to _firmware.bin.extracted/\nbinwalk --extract firmware.bin     # Same as -e\n\n# Recursive extraction (extract files within extracted files)\nbinwalk -Me firmware.bin\n\n# Entropy analysis - find compressed/encrypted regions\nbinwalk -E firmware.bin            # Generate entropy graph\nbinwalk --entropy firmware.bin\n\n# Opcode analysis - identify CPU architecture\nbinwalk -A firmware.bin\nbinwalk --opcodes firmware.bin\n\n# Raw byte extraction at offset\nbinwalk --dd='type:extension' firmware.bin\n\n# Specific signature types\nbinwalk --signature firmware.bin   # File signatures only\nbinwalk --raw='\\\\x1f\\\\x8b' firmware.bin  # Search for gzip magic bytes\n```\n\n**binwalk output interpretation:**\n```\nDECIMAL       HEXADECIMAL     DESCRIPTION\n--------------------------------------------------------------------------------\n0             0x0             TRX firmware header\n28            0x1C            LZMA compressed data\n1835008       0x1C0000        Squashfs filesystem, little endian\n```\n\n## hexdump / xxd - Raw Hex Analysis\n\n```bash\n# Hex + ASCII dump\nhexdump -C binary_file | head -50\nxxd binary_file | head -50\n\n# Dump specific byte range\nxxd -s 0x100 -l 256 binary_file    # 256 bytes starting at offset 0x100\n\n# Just hex, no ASCII\nhexdump -v -e '/1 \"%02x \"' binary_file\n\n# Create hex dump that can be reversed\nxxd binary_file > hex.txt\nxxd -r hex.txt > reconstructed_binary\n\n# Find specific bytes\nxxd binary_file | grep \"504b\"      # Look for PK (ZIP signature)\n```\n\n## file - Identify File Types\n\n```bash\n# Basic identification\nfile unknown_file\nfile -i unknown_file               # MIME type\n\n# Check multiple files\nfile *\n\n# Follow symlinks\nfile -L symlink\n```\n\n## Common Analysis Workflows\n\n### Unknown Binary Exploration\n```bash\n# 1. Identify file type\nfile mystery_file\n\n# 2. Check for embedded files\nbinwalk mystery_file\n\n# 3. Extract strings\nstrings -n 8 mystery_file | head -100\n\n# 4. Look at hex header\nxxd mystery_file | head -20\n\n# 5. Check entropy (compressed/encrypted?)\nbinwalk -E mystery_file\n```\n\n### Firmware Analysis\n```bash\n# 1. Initial scan\nbinwalk firmware.bin\n\n# 2. Extract everything\nbinwalk -Me firmware.bin\n\n# 3. Explore extracted filesystem\nfind _firmware.bin.extracted -type f -name \"*.conf\"\nfind _firmware.bin.extracted -type f -name \"passwd\"\n\n# 4. Search for secrets\ngrep -r \"password\" _firmware.bin.extracted/\nstrings -n 10 firmware.bin | grep -i -E \"(pass|key|secret|token)\"\n```\n\n### Finding Hidden Data\n```bash\n# Check for data after end of file\nbinwalk -E file.jpg               # Entropy spike at end = appended data\n\n# Look for embedded archives\nbinwalk file.jpg | grep -E \"(Zip|RAR|7z|gzip)\"\n\n# Extract with offset\ndd if=file.jpg of=hidden.zip bs=1 skip=12345\n```\n\n## File Signatures (Magic Bytes)\n\n| Signature | Hex | File Type |\n|-----------|-----|-----------|\n| `PK` | `50 4B 03 04` | ZIP archive |\n| `Rar!` | `52 61 72 21` | RAR archive |\n| `7z` | `37 7A BC AF` | 7-Zip |\n| `ELF` | `7F 45 4C 46` | Linux executable |\n| `MZ` | `4D 5A` | Windows executable |\n| `PNG` | `89 50 4E 47` | PNG image |\n| `JFIF` | `FF D8 FF E0` | JPEG image |\n| `sqsh` | `73 71 73 68` | SquashFS |\n| `hsqs` | `68 73 71 73` | SquashFS (LE) |\n\n## Tips\n\n- **Start with entropy**: High entropy = compressed or encrypted\n- **Look for strings first**: Often reveals purpose quickly\n- **Check file headers**: First 16 bytes often identify format\n- **Use recursive extraction**: Firmware often has nested archives\n- **Save offsets**: Note interesting locations for targeted extraction"
              },
              {
                "name": "fd File Finding",
                "description": "Fast file finding using fd command-line tool with smart defaults, gitignore awareness, and parallel execution. Use when searching for files by name, extension, or pattern across directories.",
                "path": "tools-plugin/skills/fd-file-finding/SKILL.md",
                "frontmatter": {
                  "created": "2025-12-16T00:00:00.000Z",
                  "modified": "2025-12-16T00:00:00.000Z",
                  "reviewed": "2025-12-16T00:00:00.000Z",
                  "name": "fd File Finding",
                  "description": "Fast file finding using fd command-line tool with smart defaults, gitignore awareness, and parallel execution. Use when searching for files by name, extension, or pattern across directories.",
                  "allowed-tools": "Bash, Read, Grep, Glob"
                },
                "content": "# fd File Finding\n\nExpert knowledge for using `fd` as a fast, user-friendly alternative to `find` with smart defaults and powerful filtering.\n\n## Core Expertise\n\n**fd Advantages**\n- Fast parallel execution (written in Rust)\n- Colorized output by default\n- Respects `.gitignore` automatically\n- Smart case-insensitive search\n- Simpler syntax than `find`\n- Regular expression support\n\n## Basic Usage\n\n### Simple File Search\n```bash\n# Find all files named config\nfd config\n\n# Find files with extension\nfd -e rs                    # All Rust files\nfd -e md                    # All Markdown files\nfd -e js -e ts              # JavaScript and TypeScript\n\n# Case-sensitive search\nfd -s Config                # Only exact case match\n```\n\n### Pattern Matching\n```bash\n# Regex patterns\nfd '^test_.*\\.py$'          # Python test files\nfd '\\.config$'              # Files ending in .config\nfd '^[A-Z]'                 # Files starting with uppercase\n\n# Glob patterns\nfd '*.lua'                  # All Lua files\nfd 'test-*.js'              # test-*.js files\n```\n\n## Advanced Filtering\n\n### Type Filtering\n```bash\n# Search only files\nfd -t f pattern             # Files only\nfd -t d pattern             # Directories only\nfd -t l pattern             # Symlinks only\nfd -t x pattern             # Executable files\n\n# Multiple types\nfd -t f -t l pattern        # Files and symlinks\n```\n\n### Depth Control\n```bash\n# Limit search depth\nfd -d 1 pattern             # Only current directory\nfd -d 3 pattern             # Max 3 levels deep\nfd --max-depth 2 pattern    # Alternative syntax\n\n# Minimum depth\nfd --min-depth 2 pattern    # Skip current directory\n```\n\n### Hidden and Ignored Files\n```bash\n# Include hidden files\nfd -H pattern               # Include hidden files (starting with .)\n\n# Include ignored files\nfd -I pattern               # Include .gitignore'd files\nfd -u pattern               # Unrestricted: hidden + ignored\n\n# Show all files\nfd -H -I pattern            # Show everything\n```\n\n### Size Filtering\n```bash\n# File size filters\nfd --size +10m              # Files larger than 10 MB\nfd --size -1k               # Files smaller than 1 KB\nfd --size +100k --size -10m # Between 100 KB and 10 MB\n```\n\n### Modification Time\n```bash\n# Files modified recently\nfd --changed-within 1d      # Last 24 hours\nfd --changed-within 2w      # Last 2 weeks\nfd --changed-within 3m      # Last 3 months\n\n# Files modified before\nfd --changed-before 1y      # Older than 1 year\n```\n\n## Execution and Processing\n\n### Execute Commands\n```bash\n# Execute command for each result\nfd -e jpg -x convert {} {.}.png     # Convert all JPG to PNG\n\n# Parallel execution\nfd -e rs -x rustfmt                 # Format all Rust files\n\n# Execute with multiple results\nfd -e md -X wc -l                   # Word count on all Markdown files\n```\n\n### Integration with Other Tools\n```bash\n# Pipe to other commands\nfd -e log | xargs rm                # Delete all log files\nfd -e rs | xargs cat | wc -l        # Count lines in Rust files\n\n# Use with rg for powerful search\nfd -e py | xargs rg \"import numpy\"  # Find numpy imports in Python files\n\n# Open files in editor\nfd -e md | xargs nvim               # Open all Markdown in Neovim\n```\n\n## Common Patterns\n\n### Development Workflows\n```bash\n# Find test files\nfd -e test.js -e spec.js            # JavaScript tests\nfd '^test_.*\\.py$'                  # Python tests\nfd '_test\\.go$'                     # Go tests\n\n# Find configuration files\nfd -g '*.config.js'                 # Config files\nfd -g '.env*'                       # Environment files\nfd -g '*rc' -H                      # RC files (include hidden)\n\n# Find source files\nfd -e rs -e toml -t f               # Rust project files\nfd -e py --exclude __pycache__      # Python excluding cache\nfd -e ts -e tsx src/                # TypeScript in src/\n```\n\n### Cleanup Operations\n```bash\n# Find and remove\nfd -e pyc -x rm                     # Remove Python bytecode\nfd node_modules -t d -x rm -rf      # Remove node_modules\nfd -g '*.log' --changed-before 30d -X rm  # Remove old logs\n\n# Find large files\nfd --size +100m -t f                # Files over 100 MB\nfd --size +1g -t f -x du -h         # Size of files over 1 GB\n```\n\n### Path-Based Search\n```bash\n# Search in specific directories\nfd pattern src/                     # Only in src/\nfd pattern src/ tests/              # Multiple directories\n\n# Exclude paths\nfd -e rs -E target/                 # Exclude target directory\nfd -e js -E node_modules -E dist    # Exclude multiple paths\n\n# Full path matching\nfd -p src/components/.*\\.tsx$       # Match full path\n```\n\n## Best Practices\n\n**When to Use fd**\n- Finding files by name or pattern\n- Searching with gitignore awareness\n- Fast directory traversal\n- Type-specific searches\n- Time-based file queries\n\n**When to Use find Instead**\n- Complex boolean logic\n- POSIX compatibility required\n- Advanced permission checks\n- Non-standard file attributes\n\n**Performance Tips**\n- Use `-j 1` for sequential search if order matters\n- Combine with `--max-depth` to limit scope\n- Use `-t f` to skip directory processing\n- Leverage gitignore for faster searches in repos\n\n**Integration with rg**\n```bash\n# Two-step search: find files, then search content\nfd -e py | xargs rg \"class.*Test\"   # Find test classes in Python\nfd -e rs | xargs rg \"TODO\"          # Find TODOs in Rust files\nfd -e md | xargs rg \"# \"            # Find headers in Markdown\n```\n\n## Quick Reference\n\n### Essential Options\n\n| Option | Purpose | Example |\n|--------|---------|---------|\n| `-e EXT` | Filter by extension | `fd -e rs` |\n| `-t TYPE` | Filter by type (f/d/l/x) | `fd -t d` |\n| `-d DEPTH` | Max search depth | `fd -d 3` |\n| `-H` | Include hidden files | `fd -H .env` |\n| `-I` | Include ignored files | `fd -I build` |\n| `-u` | Unrestricted (no ignore) | `fd -u pattern` |\n| `-E PATH` | Exclude path | `fd -E node_modules` |\n| `-x CMD` | Execute command | `fd -e log -x rm` |\n| `-X CMD` | Batch execute | `fd -e md -X cat` |\n| `-s` | Case-sensitive | `fd -s Config` |\n| `-g GLOB` | Glob pattern | `fd -g '*.json'` |\n\n### Time Units\n- `s` = seconds\n- `m` = minutes\n- `h` = hours\n- `d` = days\n- `w` = weeks\n- `y` = years\n\n### Size Units\n- `b` = bytes\n- `k` = kilobytes\n- `m` = megabytes\n- `g` = gigabytes\n- `t` = terabytes\n\n## Common Command Patterns\n\n```bash\n# Find recently modified source files\nfd -e rs --changed-within 1d\n\n# Find large files in current directory\nfd -d 1 -t f --size +10m\n\n# Find executable scripts\nfd -t x -e sh\n\n# Find config files including hidden\nfd -H -g '*config*'\n\n# Find and count lines\nfd -e py -X wc -l\n\n# Find files excluding build artifacts\nfd -e js -E dist -E node_modules -E build\n```\n\nThis makes fd the preferred tool for fast, intuitive file finding in development workflows."
              },
              {
                "name": "imagemagick-conversion",
                "description": "Convert and manipulate images with ImageMagick. Covers format conversion,\nresizing, batch processing, quality adjustment, and image transformations.\nUse when user mentions image conversion, resizing images, ImageMagick,\nmagick command, batch image processing, or thumbnail generation.\n",
                "path": "tools-plugin/skills/imagemagick-conversion/SKILL.md",
                "frontmatter": {
                  "created": "2025-12-16T00:00:00.000Z",
                  "modified": "2025-12-16T00:00:00.000Z",
                  "reviewed": "2025-12-16T00:00:00.000Z",
                  "name": "imagemagick-conversion",
                  "description": "Convert and manipulate images with ImageMagick. Covers format conversion,\nresizing, batch processing, quality adjustment, and image transformations.\nUse when user mentions image conversion, resizing images, ImageMagick,\nmagick command, batch image processing, or thumbnail generation.\n"
                },
                "content": "# ImageMagick Image Conversion\n\n**Project:** Project-independent\n**Gitignored:** Yes\n\n## Trigger\n\nUse this skill when users request image manipulation tasks including:\n- Converting between image formats (PNG, JPEG, WebP, GIF, TIFF, etc.)\n- Resizing images (dimensions, percentages, aspect ratios)\n- Batch processing multiple images\n- Adjusting image quality and compression\n- Creating thumbnails\n- Basic image transformations (rotate, flip, crop)\n\n## Overview\n\nImageMagick is a powerful command-line tool for image processing. This skill provides guidance for using the `magick` command to perform common image conversion and manipulation tasks.\n\n**Key Command Pattern:**\n```bash\nmagick input-file [options] output-file\n```\n\n## Common Use Cases\n\n### Format Conversion\n\n**Basic format conversion:**\n```bash\nmagick image.jpg image.png\nmagick photo.png photo.webp\n```\n\n**Batch convert all JPEGs to PNG:**\n```bash\nmagick mogrify -format png *.jpg\n```\n\n**Convert with specific output directory:**\n```bash\nmkdir -p output\nmagick mogrify -format webp -path output/ *.jpg\n```\n\n### Resizing Images\n\n**Resize by percentage:**\n```bash\nmagick image.jpg -resize 50% output.jpg\n```\n\n**Resize to specific width (maintain aspect ratio):**\n```bash\nmagick image.jpg -resize 800x output.jpg\n```\n\n**Resize to specific height (maintain aspect ratio):**\n```bash\nmagick image.jpg -resize x600 output.jpg\n```\n\n**Resize to fit within dimensions (maintain aspect ratio):**\n```bash\nmagick image.jpg -resize 800x600 output.jpg\n```\n\n**Resize to exact dimensions (ignore aspect ratio):**\n```bash\nmagick image.jpg -resize 800x600! output.jpg\n```\n\n**Resize only if larger:**\n```bash\nmagick image.jpg -resize '800x600>' output.jpg\n```\n\n**Resize only if smaller:**\n```bash\nmagick image.jpg -resize '800x600<' output.jpg\n```\n\n### Quality and Compression\n\n**Set JPEG quality (1-100, default 92):**\n```bash\nmagick image.jpg -quality 85 output.jpg\n```\n\n**Optimize PNG compression:**\n```bash\nmagick image.png -quality 95 output.png\n```\n\n**Create high-quality WebP:**\n```bash\nmagick image.jpg -quality 90 output.webp\n```\n\n### Thumbnails\n\n**Generate thumbnail (fast, lower quality):**\n```bash\nmagick image.jpg -thumbnail 200x200 thumb.jpg\n```\n\n**Generate thumbnail with padding:**\n```bash\nmagick image.jpg -thumbnail 200x200 -background white -gravity center -extent 200x200 thumb.jpg\n```\n\n### Batch Operations\n\n**Resize all images in directory:**\n```bash\nmagick mogrify -resize 800x600 -path resized/ *.jpg\n```\n\n**Convert and resize in one operation:**\n```bash\nmagick mogrify -resize 1200x -format webp -quality 85 -path output/ *.jpg\n```\n\n**Process specific file types:**\n```bash\nmagick mogrify -resize 50% -path smaller/ *.{jpg,png,gif}\n```\n\n### Image Information\n\n**Display image information:**\n```bash\nmagick identify image.jpg\n```\n\n**Detailed image information:**\n```bash\nmagick identify -verbose image.jpg\n```\n\n### Advanced Transformations\n\n**Rotate image:**\n```bash\nmagick image.jpg -rotate 90 rotated.jpg\n```\n\n**Flip horizontally:**\n```bash\nmagick image.jpg -flop flipped.jpg\n```\n\n**Flip vertically:**\n```bash\nmagick image.jpg -flip flipped.jpg\n```\n\n**Crop to specific region:**\n```bash\nmagick image.jpg -crop 800x600+100+100 cropped.jpg\n```\n\n**Auto-orient based on EXIF:**\n```bash\nmagick image.jpg -auto-orient output.jpg\n```\n\n**Strip metadata (reduce file size):**\n```bash\nmagick image.jpg -strip output.jpg\n```\n\n## Important Notes\n\n### mogrify vs convert\n\n- **`magick mogrify`**: Modifies files in-place or writes to specified path\n  - Use `-path` option to preserve originals\n  - Efficient for batch operations\n\n- **`magick convert`** (or just `magick`): Creates new files\n  - Always preserves original\n  - Better for single-file operations\n\n### Performance Tips\n\n1. **Use `-thumbnail` for thumbnails**: Faster than `-resize` for small previews\n2. **Use `-strip` to remove metadata**: Reduces file size significantly\n3. **Batch operations**: Process multiple files in one `mogrify` command\n4. **Quality settings**: 85-90 is usually optimal for JPEG (balances size/quality)\n\n### Format Recommendations\n\n- **JPEG**: Photos, complex images with gradients (lossy)\n- **PNG**: Screenshots, graphics with transparency (lossless)\n- **WebP**: Modern format, excellent compression (lossy or lossless)\n- **GIF**: Simple animations, limited colors\n- **TIFF**: Archival, high-quality storage\n\n## Safety Considerations\n\n**Always test commands on copies first:**\n```bash\n# Create test directory\nmkdir -p test-output\n\n# Test on single file\nmagick original.jpg -resize 50% test-output/test.jpg\n\n# Verify result before batch processing\n```\n\n**Use `-path` with mogrify to preserve originals:**\n```bash\n# This preserves originals in current directory\nmagick mogrify -resize 800x -path resized/ *.jpg\n```\n\n**Quote wildcards in shell:**\n```bash\n# Prevents premature shell expansion\nmagick mogrify -resize '800x600>' -path output/ '*.jpg'\n```\n\n## Common Patterns\n\n### Web Optimization Workflow\n\n```bash\n# Create optimized versions for web\nmkdir -p web-optimized\n\n# Convert to WebP with quality 85, resize to max 1920px width\nmagick mogrify -resize 1920x -quality 85 -format webp -path web-optimized/ *.jpg\n\n# Strip metadata to reduce size\nmagick mogrify -strip web-optimized/*.webp\n```\n\n### Thumbnail Generation\n\n```bash\n# Create thumbnail directory\nmkdir -p thumbnails\n\n# Generate 300x300 thumbnails with white padding\nfor img in *.jpg; do\n  magick \"$img\" -thumbnail 300x300 -background white -gravity center -extent 300x300 \"thumbnails/${img%.jpg}_thumb.jpg\"\ndone\n```\n\n### Multi-Format Export\n\n```bash\n# Export to multiple formats for compatibility\nmkdir -p exports/{png,webp,jpg}\n\nfor img in source/*.png; do\n  name=$(basename \"$img\" .png)\n  magick \"$img\" -quality 90 \"exports/png/$name.png\"\n  magick \"$img\" -quality 85 \"exports/webp/$name.webp\"\n  magick \"$img\" -quality 85 \"exports/jpg/$name.jpg\"\ndone\n```\n\n## Troubleshooting\n\n**Check ImageMagick version:**\n```bash\nmagick -version\n```\n\n**Verify supported formats:**\n```bash\nmagick identify -list format\n```\n\n**Test command on single file first:**\n```bash\n# Always test before batch operations\nmagick test-image.jpg -resize 50% test-output.jpg\n```\n\n## When to Use This Skill\n\n** Use this skill for:**\n- Format conversions between standard image types\n- Resizing operations (dimensions, percentages)\n- Quality adjustments and compression\n- Batch processing workflows\n- Generating thumbnails or previews\n- Basic transformations (rotate, crop, flip)\n\n** Don't use this skill for:**\n- Advanced photo editing (use GIMP, Photoshop)\n- Complex filters or effects (consider dedicated tools)\n- Video processing (use FFmpeg)\n- Vector graphics (use Inkscape, Illustrator)\n\n## Integration with Workflows\n\nThis skill complements other development workflows:\n- **Web development**: Optimize images for deployment\n- **Documentation**: Generate screenshots and diagrams\n- **CI/CD**: Automate image processing in pipelines\n- **Content creation**: Prepare images for various platforms\n\nThe `magick` command is typically available via Homebrew (`brew install imagemagick`) or system package managers."
              },
              {
                "name": "jq JSON Processing",
                "description": "JSON querying, filtering, and transformation with jq command-line tool. Use when working with JSON data, parsing JSON files, filtering JSON arrays/objects, or transforming JSON structures.",
                "path": "tools-plugin/skills/jq-json-processing/SKILL.md",
                "frontmatter": {
                  "created": "2025-12-16T00:00:00.000Z",
                  "modified": "2025-12-16T00:00:00.000Z",
                  "reviewed": "2025-12-16T00:00:00.000Z",
                  "name": "jq JSON Processing",
                  "description": "JSON querying, filtering, and transformation with jq command-line tool. Use when working with JSON data, parsing JSON files, filtering JSON arrays/objects, or transforming JSON structures.",
                  "allowed-tools": "Bash, Read, Write, Edit, Grep, Glob"
                },
                "content": "# jq JSON Processing\n\nExpert knowledge for processing, querying, and transforming JSON data using jq, the lightweight and flexible command-line JSON processor.\n\n## Core Expertise\n\n**JSON Operations**\n- Query and filter JSON with path expressions\n- Transform JSON structure and shape\n- Combine, merge, and split JSON data\n- Validate JSON syntax and structure\n\n**Data Extraction**\n- Extract specific fields from JSON objects\n- Filter arrays based on conditions\n- Navigate nested JSON structures\n- Handle null values and missing keys\n\n## Essential Commands\n\n### Basic Querying\n\n```bash\n# Pretty-print JSON\njq '.' file.json\n\n# Extract specific field\njq '.fieldName' file.json\n\n# Extract nested field\njq '.user.email' file.json\n\n# Extract array element\njq '.[0]' file.json\njq '.items[2]' file.json\n```\n\n### Array Operations\n\n```bash\n# Get array length\njq '.items | length' file.json\n\n# Map over array\njq '.items | map(.name)' file.json\n\n# Filter array\njq '.items[] | select(.active == true)' file.json\njq '.users[] | select(.age > 18)' file.json\n\n# Sort array\njq '.items | sort_by(.name)' file.json\njq '.items | sort_by(.date) | reverse' file.json\n\n# Get first/last elements\njq '.items | first' file.json\njq '.items | last' file.json\n\n# Unique values\njq '.tags | unique' file.json\n```\n\n### Object Operations\n\n```bash\n# Get all keys\njq 'keys' file.json\njq '.config | keys' file.json\n\n# Get all values\njq '.[] | values' file.json\n\n# Select specific fields\njq '{name, email}' file.json\njq '{name: .fullName, id: .userId}' file.json\n\n# Add field\njq '. + {newField: \"value\"}' file.json\n\n# Delete field\njq 'del(.password)' file.json\n\n# Merge objects\njq '. * {updated: true}' file.json\n```\n\n### Filtering and Conditions\n\n```bash\n# Select with conditions\njq 'select(.status == \"active\")' file.json\njq '.[] | select(.price < 100)' file.json\n\n# Multiple conditions (AND)\njq '.[] | select(.active and .verified)' file.json\njq '.[] | select(.age > 18 and .country == \"US\")' file.json\n\n# Multiple conditions (OR)\njq '.[] | select(.type == \"admin\" or .type == \"moderator\")' file.json\n\n# Exists / has field\njq '.[] | select(has(\"email\"))' file.json\njq 'select(.optional != null)' file.json\n\n# Not condition\njq '.[] | select(.status != \"deleted\")' file.json\n```\n\n### String Operations\n\n```bash\n# String interpolation\njq '\"Hello, \\(.name)\"' file.json\n\n# Convert to string\njq '.id | tostring' file.json\n\n# String contains\njq '.[] | select(.email | contains(\"@gmail.com\"))' file.json\n\n# String starts/ends with\njq '.[] | select(.name | startswith(\"A\"))' file.json\njq '.[] | select(.file | endswith(\".json\"))' file.json\n\n# Split string\njq '.path | split(\"/\")' file.json\n\n# Join array to string\njq '.tags | join(\", \")' file.json\n\n# Lowercase/uppercase\njq '.name | ascii_downcase' file.json\njq '.name | ascii_upcase' file.json\n```\n\n### Pipes and Composition\n\n```bash\n# Chain operations\njq '.items | map(.name) | sort | unique' file.json\n\n# Multiple filters\njq '.users[] | select(.active) | select(.age > 18) | .email' file.json\n\n# Group by\njq 'group_by(.category)' file.json\njq 'group_by(.status) | map({status: .[0].status, count: length})' file.json\n```\n\n### Output Formatting\n\n```bash\n# Compact output (no pretty-print)\njq -c '.' file.json\n\n# Raw output (no quotes for strings)\njq -r '.message' file.json\njq -r '.items[] | .name' file.json\n\n# Output as tab-separated values\njq -r '.[] | [.name, .age, .email] | @tsv' file.json\n\n# Output as CSV\njq -r '.[] | [.name, .age, .email] | @csv' file.json\n\n# Output as JSON array on one line\njq -c '[.items[]]' file.json\n```\n\n### Input/Output Options\n\n```bash\n# Read from stdin\ncat file.json | jq '.items'\ncurl -s https://api.example.com/data | jq '.results'\n\n# Multiple input files\njq -s '.' file1.json file2.json  # Slurp into array\n\n# Write to file\njq '.filtered' input.json > output.json\n\n# In-place edit (use sponge from moreutils)\njq '.updated = true' file.json | sponge file.json\n```\n\n### Advanced Patterns\n\n```bash\n# Recursive descent\njq '.. | .email? // empty' file.json\n\n# Reduce (sum, accumulate)\njq '[.items[].price] | add' file.json\njq 'reduce .items[] as $item (0; . + $item.price)' file.json\n\n# Variable assignment\njq '.items[] | . as $item | $item.name + \" - \" + ($item.price | tostring)' file.json\n\n# Conditional (if-then-else)\njq '.items[] | if .price > 100 then \"expensive\" else \"affordable\" end' file.json\njq 'if .error then .error else .data end' file.json\n\n# Try-catch for error handling\njq '.items[] | try .field catch \"not found\"' file.json\n\n# Flatten nested arrays\njq '.items | flatten' file.json\njq '.items | flatten(1)' file.json  # Flatten one level\n```\n\n### Real-World Examples\n\n```bash\n# Extract all emails from nested structure\njq '.. | .email? // empty' users.json\n\n# Get unique list of all tags across items\njq '[.items[].tags[]] | unique' data.json\n\n# Count items by status\njq 'group_by(.status) | map({status: .[0].status, count: length})' items.json\n\n# Transform API response to simple list\njq '.results[] | {id, name: .full_name, active: .is_active}' response.json\n\n# Filter GitHub workflow runs (recent failures)\ngh run list --json status,conclusion,name,createdAt | \\\n  jq '.[] | select(.conclusion == \"failure\") | {name, createdAt}'\n\n# Extract package.json dependencies with versions\njq '.dependencies | to_entries | map(\"\\(.key)@\\(.value)\")' package.json\n\n# Merge two JSON files\njq -s '.[0] * .[1]' base.json override.json\n\n# Create summary from log data\njq 'group_by(.level) | map({level: .[0].level, count: length, samples: [.[].message][:3]})' logs.json\n```\n\n## Best Practices\n\n**Query Construction**\n- Start simple, build complexity incrementally\n- Test filters on small datasets first\n- Use `-c` flag for compact output in scripts\n- Use `-r` flag for raw strings (no quotes)\n\n**Performance**\n- Use `select()` early in pipeline to reduce data\n- Use targeted queries for large files (instead of `..` recursive descent)\n- Stream large JSON with `--stream` flag\n- Consider `jq -c` for faster processing\n\n**Error Handling**\n- Use `?` operator for optional access: `.field?`\n- Use `// empty` to filter out nulls/errors\n- Use `try-catch` for graceful error handling\n- Check for field existence with `has(\"field\")`\n\n**Readability**\n- Break complex queries into multiple steps\n- Use variables with `as $var` for clarity\n- Add comments in shell scripts\n- Format multi-line jq programs for readability\n\n## Common Patterns\n\n### API Response Processing\n```bash\n# GitHub API: Get PR titles and authors\ngh pr list --json title,author,number | \\\n  jq -r '.[] | \"#\\(.number) - \\(.title) by @\\(.author.login)\"'\n\n# REST API: Extract and flatten pagination\ncurl -s \"https://api.example.com/items\" | \\\n  jq '.data.items[] | {id, name, status}'\n```\n\n### Configuration Files\n```bash\n# Extract environment-specific config\njq '.environments.production' config.json\n\n# Update configuration value\njq '.settings.timeout = 30' config.json > config.updated.json\n\n# Merge base config with environment overrides\njq -s '.[0] * .[1]' base-config.json prod-config.json\n```\n\n### Log Analysis\n```bash\n# Count errors by type\njq 'select(.level == \"error\") | .type' logs.json | sort | uniq -c\n\n# Extract error messages with timestamps\njq -r 'select(.level == \"error\") | \"\\(.timestamp) - \\(.message)\"' logs.json\n\n# Group by hour and count\njq -r '.timestamp | split(\"T\")[1] | split(\":\")[0]' logs.json | sort | uniq -c\n```\n\n### Data Transformation\n```bash\n# CSV to JSON (with headers)\njq -R -s 'split(\"\\n\") | .[1:] | map(split(\",\")) |\n  map({name: .[0], age: .[1], email: .[2]})' data.csv\n\n# JSON to CSV\njq -r '.[] | [.name, .age, .email] | @csv' data.json\n\n# Flatten nested structure\njq '[.items[] | {id, name, category: .meta.category}]' nested.json\n```\n\n## Troubleshooting\n\n### Invalid JSON\n```bash\n# Validate JSON syntax\njq empty file.json  # Returns exit code 0 if valid\n\n# Find syntax errors\njq '.' file.json 2>&1 | grep \"parse error\"\n```\n\n### Empty Results\n```bash\n# Debug: Print entire structure\njq '.' file.json\n\n# Debug: Check field existence\njq 'keys' file.json\njq 'type' file.json  # Check if array, object, etc.\n\n# Debug: Show all values\njq '.. | scalars' file.json\n```\n\n### Type Errors\n```bash\n# Check field types\njq '.field | type' file.json\n\n# Convert types safely\njq '.id | tonumber' file.json\njq '.count | tostring' file.json\n\n# Handle mixed types\njq '.items[] | if type == \"array\" then .[] else . end' file.json\n```\n\n### Performance Issues\n```bash\n# Stream large files\njq --stream '.' large-file.json\n\n# Process line by line\ncat large.json | jq -c '.[]' | while read -r line; do\n  echo \"$line\" | jq '.field'\ndone\n```\n\n## Integration with Other Tools\n\n```bash\n# With curl (API calls)\ncurl -s \"https://api.github.com/users/octocat\" | jq '.name, .bio'\n\n# With gh CLI (GitHub operations)\ngh api repos/owner/repo/issues | jq '.[] | {number, title, state}'\n\n# With find (batch processing)\nfind . -name \"package.json\" -exec jq '.version' {} \\;\n\n# With xargs (parallel processing)\ncat urls.txt | xargs -I {} curl -s {} | jq '.data'\n\n# With yq (YAML to JSON conversion)\nyq eval -o=json file.yaml | jq '.specific.field'\n```\n\n## Quick Reference\n\n### Operators\n- `.field` - Access field\n- `.[]` - Iterate array/object\n- `|` - Pipe (chain operations)\n- `,` - Multiple outputs\n- `?` - Optional (suppress errors)\n- `//` - Alternative operator (default value)\n\n### Functions\n- `keys`, `values` - Object keys/values\n- `length` - Array/object/string length\n- `map()`, `select()` - Array operations\n- `sort`, `sort_by()` - Sorting\n- `group_by()` - Grouping\n- `unique` - Remove duplicates\n- `add` - Sum numbers or concatenate\n- `has()` - Check field existence\n- `type` - Get value type\n\n### Type Conversions\n- `tostring`, `tonumber` - Convert types\n- `@csv`, `@tsv`, `@json` - Format output\n- `split()`, `join()` - String/array conversion\n\n## Installation\n\n```bash\n# macOS (Homebrew)\nbrew install jq\n\n# Ubuntu/Debian\nsudo apt-get install jq\n\n# Verify installation\njq --version\n```\n\n## Resources\n\n- **Official Manual**: https://stedolan.github.io/jq/manual/\n- **jq Playground**: https://jqplay.org/\n- **Tutorial**: https://stedolan.github.io/jq/tutorial/"
              },
              {
                "name": "justfile-expert",
                "description": "Just command runner expertise, Justfile syntax, recipe development, and cross-platform\ntask automation. Covers recipe patterns, parameters, modules, settings, and workflow\nintegration. Use when user mentions just, justfile, recipes, command runner, task\nautomation, project commands, or needs help writing executable project documentation.\n",
                "path": "tools-plugin/skills/justfile-expert/SKILL.md",
                "frontmatter": {
                  "created": "2025-12-16T00:00:00.000Z",
                  "modified": "2025-12-16T00:00:00.000Z",
                  "reviewed": "2025-12-16T00:00:00.000Z",
                  "name": "justfile-expert",
                  "description": "Just command runner expertise, Justfile syntax, recipe development, and cross-platform\ntask automation. Covers recipe patterns, parameters, modules, settings, and workflow\nintegration. Use when user mentions just, justfile, recipes, command runner, task\nautomation, project commands, or needs help writing executable project documentation.\n",
                  "allowed-tools": "Bash, BashOutput, Grep, Glob, Read, Write, Edit, TodoWrite"
                },
                "content": "# Justfile Expert\n\nExpert knowledge for Just command runner, recipe development, and task automation with focus on cross-platform compatibility and project standardization.\n\n## Core Expertise\n\n**Command Runner Mastery**\n- Justfile syntax and recipe structure\n- Cross-platform task automation (Linux, macOS, Windows)\n- Parameter handling and argument forwarding\n- Module organization for large projects\n\n**Recipe Development Excellence**\n- Recipe patterns for common operations\n- Dependency management between recipes\n- Shebang recipes for complex logic\n- Environment variable integration\n\n**Project Standardization**\n- Standard recipes for consistent workflows\n- Self-documenting project operations\n- Portable patterns across projects\n- Integration with CI/CD pipelines\n\n## Key Capabilities\n\n**Recipe Parameters**\n- **Required parameters**: `recipe param:` - must be provided\n- **Default values**: `recipe param=\"default\":` - optional with fallback\n- **Variadic `+`**: `recipe +FILES:` - one or more arguments\n- **Variadic `*`**: `recipe *FLAGS:` - zero or more arguments\n- **Environment export**: `recipe $VAR:` - parameter as env var\n\n**Settings Configuration**\n- **`set dotenv-load`**: Load `.env` file automatically\n- **`set positional-arguments`**: Enable `$1`, `$2` syntax\n- **`set export`**: Export all variables as env vars\n- **`set shell`**: Custom shell interpreter\n- **`set quiet`**: Suppress command echoing\n\n**Recipe Attributes**\n- **`[private]`**: Hide from `--list` output\n- **`[no-cd]`**: Don't change directory\n- **`[no-exit-message]`**: Suppress exit messages\n- **`[unix]`** / **`[windows]`**: Platform-specific recipes\n- **`[positional-arguments]`**: Per-recipe positional args\n\n**Module System**\n- **`mod name`**: Declare submodule\n- **`mod name 'path'`**: Custom module path\n- **Invocation**: `just module::recipe` or `just module recipe`\n\n## Essential Syntax\n\n**Basic Recipe Structure**\n```just\n# Comment describes the recipe\nrecipe-name:\n    command1\n    command2\n```\n\n**Recipe with Parameters**\n```just\nbuild target:\n    @echo \"Building {{target}}...\"\n    cd {{target}} && make\n\ntest *args:\n    uv run pytest {{args}}\n```\n\n**Recipe Dependencies**\n```just\ndefault: build test\n\nbuild: _setup\n    cargo build --release\n\n_setup:\n    @echo \"Setting up...\"\n```\n\n**Variables and Interpolation**\n```just\nversion := \"1.0.0\"\nproject := env('PROJECT_NAME', 'default')\n\ninfo:\n    @echo \"Project: {{project}} v{{version}}\"\n```\n\n**Conditional Recipes**\n```just\n[unix]\nopen:\n    xdg-open http://localhost:8080\n\n[windows]\nopen:\n    start http://localhost:8080\n```\n\n## Standard Recipes\n\nEvery project should provide these standard recipes:\n\n```just\n# Justfile - Project task runner\n# Run `just` or `just help` to see available recipes\n\nset dotenv-load\nset positional-arguments\n\n# Default recipe - show help\ndefault:\n    @just --list\n\n# Show available recipes with descriptions\nhelp:\n    @just --list --unsorted\n\n####################\n# Development\n####################\n\n# Run linters\nlint:\n    # Language-specific lint command\n\n# Format code\nformat:\n    # Language-specific format command\n\n# Run tests\ntest *args:\n    # Language-specific test command {{args}}\n\n# Development mode with watch\ndev:\n    # Start with file watching\n\n####################\n# Build & Deploy\n####################\n\n# Build project\nbuild:\n    # Build command\n\n# Clean build artifacts\nclean:\n    # Cleanup command\n\n# Start service\nstart:\n    # Start command\n\n# Stop service\nstop:\n    # Stop command\n```\n\n## Common Patterns\n\n**Setup/Bootstrap Recipe**\n```just\n# Initial project setup\nsetup:\n    #!/usr/bin/env bash\n    set -euo pipefail\n    echo \"Installing dependencies...\"\n    uv sync\n    echo \"Setting up pre-commit...\"\n    pre-commit install\n    echo \"Done!\"\n```\n\n**Docker Integration**\n```just\n# Build container image\ndocker-build tag=\"latest\":\n    docker build -t {{project}}:{{tag}} .\n\n# Run container\ndocker-run tag=\"latest\" *args:\n    docker run --rm -it {{project}}:{{tag}} {{args}}\n\n# Push to registry\ndocker-push tag=\"latest\":\n    docker push {{registry}}/{{project}}:{{tag}}\n```\n\n**Database Operations**\n```just\n# Run database migrations\ndb-migrate:\n    uv run alembic upgrade head\n\n# Create new migration\ndb-revision message:\n    uv run alembic revision --autogenerate -m \"{{message}}\"\n\n# Reset database\ndb-reset:\n    uv run alembic downgrade base\n    uv run alembic upgrade head\n```\n\n**CI/CD Recipes**\n```just\n# Full CI check (lint + test + build)\nci: lint test build\n    @echo \"CI passed!\"\n\n# Release workflow\nrelease version:\n    git tag -a \"v{{version}}\" -m \"Release {{version}}\"\n    git push origin \"v{{version}}\"\n```\n\n## Best Practices\n\n**Recipe Development Workflow**\n1. **Name clearly**: Use descriptive, verb-based names (`build`, `test`, `deploy`)\n2. **Document always**: Add comment before each recipe\n3. **Use defaults**: Provide sensible default parameter values\n4. **Group logically**: Organize with section comments\n5. **Hide internals**: Mark helper recipes as `[private]`\n6. **Test portability**: Verify on all target platforms\n\n**Critical Guidelines**\n- Always provide `default` recipe pointing to help\n- Use `@` prefix to suppress command echo when appropriate\n- Use shebang recipes for multi-line logic\n- Prefer `set dotenv-load` for configuration\n- Use modules for large projects (>20 recipes)\n- Include variadic `*args` for passthrough flexibility\n- Quote all variables in shell commands\n\n## Comparison with Alternatives\n\n| Feature | Just | Make | mise tasks |\n|---------|------|------|------------|\n| Syntax | Simple, clear | Complex, tabs required | YAML |\n| Dependencies | Built-in | Built-in | Manual |\n| Parameters | Full support | Limited | Full support |\n| Cross-platform | Excellent | Good | Excellent |\n| Tool versions | No | No | Yes |\n| Error messages | Clear | Cryptic | Clear |\n| Installation | Single binary | Pre-installed | Requires mise |\n\n**When to use Just:**\n- Cross-project standard recipes\n- Simple, readable task automation\n- No tool version management needed\n\n**When to use mise tasks:**\n- Project-specific with tool version pinning\n- Already using mise for tool management\n\n**When to use Make:**\n- Legacy projects with existing Makefiles\n- Build systems requiring incremental compilation\n\nFor detailed syntax reference, advanced patterns, and troubleshooting, see REFERENCE.md."
              },
              {
                "name": "rg Code Search",
                "description": "Fast code search using ripgrep (rg) with smart defaults, regex patterns, and file filtering. Use when searching for text patterns, code snippets, or performing multi-file code analysis.",
                "path": "tools-plugin/skills/rg-code-search/SKILL.md",
                "frontmatter": {
                  "created": "2025-12-16T00:00:00.000Z",
                  "modified": "2025-12-16T00:00:00.000Z",
                  "reviewed": "2025-12-16T00:00:00.000Z",
                  "name": "rg Code Search",
                  "description": "Fast code search using ripgrep (rg) with smart defaults, regex patterns, and file filtering. Use when searching for text patterns, code snippets, or performing multi-file code analysis.",
                  "allowed-tools": "Bash, Read, Grep, Glob"
                },
                "content": "# rg Code Search\n\nExpert knowledge for using `rg` (ripgrep) as a blazingly fast code search tool with powerful filtering and pattern matching.\n\n## Core Expertise\n\n**ripgrep Advantages**\n- Extremely fast (written in Rust)\n- Respects `.gitignore` automatically\n- Smart case-insensitive search\n- Recursive by default\n- Colorized output\n- Multi-line search support\n- Replace functionality\n\n## Basic Usage\n\n### Simple Search\n```bash\n# Basic search\nrg pattern                  # Search in current directory\nrg \"import numpy\"           # Search for exact phrase\nrg function_name            # Search for function name\n\n# Case-sensitive search\nrg -s Pattern               # Force case-sensitive\nrg -i PATTERN               # Force case-insensitive\n```\n\n### File Type Filtering\n```bash\n# Search specific file types\nrg pattern -t py            # Python files only\nrg pattern -t rs            # Rust files only\nrg pattern -t js            # JavaScript files\nrg pattern -t md            # Markdown files\n\n# Multiple types\nrg pattern -t py -t rs      # Python and Rust\n\n# List available types\nrg --type-list              # Show all known types\n```\n\n### Extension Filtering\n```bash\n# Filter by extension\nrg pattern -g '*.rs'        # Rust files\nrg pattern -g '*.{js,ts}'   # JavaScript and TypeScript\nrg pattern -g '!*.min.js'   # Exclude minified files\n```\n\n## Advanced Patterns\n\n### Regular Expressions\n```bash\n# Word boundaries\nrg '\\bfunction\\b'           # Match whole word \"function\"\nrg '\\btest_\\w+'             # Words starting with test_\n\n# Line anchors\nrg '^import'                # Lines starting with import\nrg 'return$'                # Lines ending with return\nrg '^class \\w+:'            # Python class definitions\n\n# Character classes\nrg 'TODO|FIXME|XXX'         # Find markers\nrg '[Ee]rror'               # Error or error\nrg '\\d{3}-\\d{4}'            # Phone numbers\n```\n\n### Multi-line Search\n```bash\n# Multi-line patterns\nrg -U 'fn.*\\{.*\\}'          # Function definitions (Rust)\nrg -U 'struct.*{[^}]*}'     # Struct definitions\n\n# Context lines\nrg -A 5 pattern             # Show 5 lines after\nrg -B 3 pattern             # Show 3 lines before\nrg -C 2 pattern             # Show 2 lines before and after\n```\n\n### Output Formatting\n```bash\n# Control output\nrg -l pattern               # List files with matches only\nrg -c pattern               # Count matches per file\nrg --count-matches pattern  # Total match count\n\n# Show context\nrg -n pattern               # Show line numbers (default)\nrg -N pattern               # Don't show line numbers\nrg --heading pattern        # Group by file (default)\nrg --no-heading pattern     # Don't group by file\n\n# Customize output\nrg --vimgrep pattern        # Vim-compatible format\nrg --json pattern           # JSON output\n```\n\n## Advanced Filtering\n\n### Path Filtering\n```bash\n# Search in specific directories\nrg pattern src/             # Only src/ directory\nrg pattern src/ tests/      # Multiple directories\n\n# Exclude paths\nrg pattern -g '!target/'    # Exclude target/\nrg pattern -g '!{dist,build,node_modules}/'  # Exclude multiple\n\n# Full path matching\nrg pattern -g '**/test/**'  # Only test directories\n```\n\n### Content Filtering\n```bash\n# Search only in files containing pattern\nrg --files-with-matches \"import.*React\" | xargs rg \"useState\"\n\n# Exclude files by content\nrg pattern --type-not markdown\n\n# Search only uncommitted files\nrg pattern $(git diff --name-only)\n```\n\n### Size and Hidden Files\n```bash\n# Include hidden files\nrg pattern -u               # Include hidden\nrg pattern -uu              # Include hidden + .gitignore'd\nrg pattern -uuu             # Unrestricted: everything\n\n# Exclude by size\nrg pattern --max-filesize 1M  # Skip files over 1MB\n```\n\n## Code Search Patterns\n\n### Finding Definitions\n```bash\n# Function definitions\nrg '^def \\w+\\('             # Python functions\nrg 'fn \\w+\\('               # Rust functions\nrg '^function \\w+\\('        # JavaScript functions\nrg '^\\s*class \\w+'          # Class definitions\n\n# Interface/type definitions\nrg '^interface \\w+'         # TypeScript interfaces\nrg '^type \\w+ ='            # Type aliases\nrg '^struct \\w+'            # Struct definitions (Rust/Go)\n```\n\n### Finding Usage\n```bash\n# Find function calls\nrg 'functionName\\('         # Direct calls\nrg '\\.methodName\\('         # Method calls\n\n# Find imports\nrg '^import.*module_name'   # Python imports\nrg '^use.*crate_name'       # Rust uses\nrg \"^import.*'package'\"     # JavaScript imports\n```\n\n### Code Quality Checks\n```bash\n# Find TODOs and FIXMEs\nrg 'TODO|FIXME|XXX|HACK'    # Find all markers\nrg -t py '#\\s*TODO'         # Python TODOs\nrg -t rs '//\\s*TODO'        # Rust TODOs\n\n# Find debug statements\nrg 'console\\.log'           # JavaScript\nrg 'println!'               # Rust\nrg 'print\\('                # Python\n\n# Find security issues\nrg 'password.*=|api_key.*=' # Potential secrets\nrg 'eval\\('                 # Eval usage\nrg 'exec\\('                 # Exec usage\n```\n\n### Testing Patterns\n```bash\n# Find tests\nrg '^def test_' -t py       # Python tests\nrg '#\\[test\\]' -t rs        # Rust tests\nrg \"describe\\(|it\\(\" -t js  # JavaScript tests\n\n# Find skipped tests\nrg '@skip|@pytest.mark.skip' -t py\nrg '#\\[ignore\\]' -t rs\nrg 'test\\.skip|it\\.skip' -t js\n```\n\n## File Operations\n\n### Search and Replace\n```bash\n# Preview replacements\nrg pattern --replace replacement\n\n# Perform replacement (requires external tool)\nrg pattern -l | xargs sed -i 's/pattern/replacement/g'\n\n# With confirmation (using fd and interactive)\nfd -e rs | xargs rg pattern --files-with-matches | xargs -I {} sh -c 'vim -c \"%s/pattern/replacement/gc\" -c \"wq\" {}'\n```\n\n### Integration with Other Tools\n```bash\n# Pipe to other commands\nrg -l \"TODO\" | xargs wc -l          # Count lines with TODOs\nrg \"function\" --files-with-matches | xargs nvim  # Open files in editor\n\n# Combine with fd\nfd -e py | xargs rg \"class.*Test\"   # Find test classes\nfd -e rs | xargs rg \"unsafe\"        # Find unsafe blocks\n\n# Count occurrences\nrg -c pattern | awk -F: '{sum+=$2} END {print sum}'\n```\n\n### Stats and Analysis\n```bash\n# Count total matches\nrg pattern --count-matches --no-filename | awk '{sum+=$1} END {print sum}'\n\n# Find most common matches\nrg pattern -o | sort | uniq -c | sort -rn\n\n# Files with most matches\nrg pattern -c | sort -t: -k2 -rn | head -10\n```\n\n## Performance Optimization\n\n### Speed Tips\n```bash\n# Limit search\nrg pattern --max-depth 3    # Limit directory depth\nrg pattern -g '*.rs' -t rust  # Use type filters\n\n# Parallel processing (default)\nrg pattern -j 4             # Use 4 threads\n\n# Memory management\nrg pattern --mmap           # Use memory maps (faster)\nrg pattern --no-mmap        # Don't use memory maps\n```\n\n### Large Codebase Strategies\n```bash\n# Narrow scope first\nrg pattern src/             # Specific directory\nrg pattern -t py -g '!test*'  # Specific type, exclude tests\n\n# Use file list caching\nrg --files > /tmp/files.txt\nrg pattern $(cat /tmp/files.txt)\n\n# Exclude large directories\nrg pattern -g '!{target,node_modules,dist,build}/'\n```\n\n## Best Practices\n\n**When to Use rg**\n- Searching code for patterns\n- Finding function/class definitions\n- Code analysis and auditing\n- Refactoring support\n- Security scanning\n\n**When to Use grep Instead**\n- POSIX compatibility required\n- Simple one-off searches\n- Piped input (stdin)\n- System administration tasks\n\n**Common Mistakes to Avoid**\n- Forgetting to escape regex special characters\n- Not using `-u` flags when searching ignored files\n- Not excluding large binary/generated files\n- Using grep when rg would be much faster\n\n## Quick Reference\n\n### Essential Options\n\n| Option | Purpose | Example |\n|--------|---------|---------|\n| `-t TYPE` | File type filter | `rg -t py pattern` |\n| `-g GLOB` | Glob pattern | `rg -g '*.rs' pattern` |\n| `-i` | Case-insensitive | `rg -i pattern` |\n| `-s` | Case-sensitive | `rg -s Pattern` |\n| `-w` | Match whole words | `rg -w word` |\n| `-l` | Files with matches | `rg -l pattern` |\n| `-c` | Count per file | `rg -c pattern` |\n| `-A N` | Lines after | `rg -A 5 pattern` |\n| `-B N` | Lines before | `rg -B 3 pattern` |\n| `-C N` | Context lines | `rg -C 2 pattern` |\n| `-U` | Multi-line | `rg -U 'pattern.*'` |\n| `-u` | Include hidden | `rg -u pattern` |\n| `--replace` | Replace text | `rg pattern --replace new` |\n\n### File Types (Common)\n\n| Type | Extensions |\n|------|------------|\n| `-t py` | Python (.py, .pyi) |\n| `-t rs` | Rust (.rs) |\n| `-t js` | JavaScript (.js, .jsx) |\n| `-t ts` | TypeScript (.ts, .tsx) |\n| `-t go` | Go (.go) |\n| `-t md` | Markdown (.md, .markdown) |\n| `-t yaml` | YAML (.yaml, .yml) |\n| `-t json` | JSON (.json) |\n\n### Common Command Patterns\n\n```bash\n# Find function definitions across codebase\nrg '^\\s*(def|fn|function)\\s+\\w+' -t py -t rs -t js\n\n# Find all imports\nrg '^(import|use|require)' -t py -t rs -t js\n\n# Find potential bugs\nrg 'TODO|FIXME|XXX|HACK|BUG'\n\n# Find test files and count tests\nrg -t py '^def test_' -c\n\n# Find large functions (50+ lines)\nrg -U 'def \\w+.*\\n(.*\\n){50,}' -t py\n\n# Security audit\nrg 'password|api_key|secret|token' -i -g '!*.{lock,log}'\n```\n\nThis makes rg the preferred tool for fast, powerful code search in development workflows."
              },
              {
                "name": "shell-expert",
                "description": "Shell scripting expertise, command-line tools, automation, and cross-platform\nscripting best practices. Covers shell script development, CLI tool usage,\nand system automation with bash, zsh, and POSIX shell.\nUse when user mentions shell scripts, bash, zsh, CLI commands, pipes, command-line\nautomation, or writing portable shell code.\n",
                "path": "tools-plugin/skills/shell-expert/SKILL.md",
                "frontmatter": {
                  "created": "2025-12-16T00:00:00.000Z",
                  "modified": "2025-12-16T00:00:00.000Z",
                  "reviewed": "2025-12-16T00:00:00.000Z",
                  "name": "shell-expert",
                  "description": "Shell scripting expertise, command-line tools, automation, and cross-platform\nscripting best practices. Covers shell script development, CLI tool usage,\nand system automation with bash, zsh, and POSIX shell.\nUse when user mentions shell scripts, bash, zsh, CLI commands, pipes, command-line\nautomation, or writing portable shell code.\n",
                  "allowed-tools": "Bash, BashOutput, KillShell, Grep, Glob, Read, Write, Edit, TodoWrite"
                },
                "content": "# Shell Expert\n\nExpert knowledge for shell scripting, command-line tools, and automation with focus on robust, portable, and efficient solutions.\n\n## Core Expertise\n\n**Command-Line Tool Mastery**\n- Expert knowledge of modern CLI tools (jq, yq, fd, rg, etc.)\n- JSON/YAML processing and transformation\n- File searching and text manipulation\n- System automation and orchestration\n\n**Shell Scripting Excellence**\n- POSIX-compliant shell scripting for maximum portability\n- Bash-specific features and best practices\n- Error handling and defensive programming\n- Cross-platform compatibility (Linux, macOS, BSD)\n\n**Automation & Integration**\n- CI/CD pipeline scripting\n- System administration automation\n- Tool integration and workflow automation\n- Performance optimization for shell operations\n\n## Key Capabilities\n\n**JSON/YAML Processing**\n- **jq**: Complex JSON queries, transformations, and filtering\n- **yq**: YAML manipulation, in-place editing, format conversion\n- **jd**: JSON diffing and patching for configuration management\n- **Data pipeline construction**: Chaining tools for complex transformations\n\n**File Operations & Search**\n- **fd**: Fast, user-friendly file finding with intuitive syntax\n- **rg (ripgrep)**: Lightning-fast recursive grep with gitignore support\n- **lsd**: Modern ls replacement with visual enhancements\n- **find/grep alternatives**: When and how to use modern replacements\n\n**Shell Script Development**\n- **Error Handling**: Proper trap usage, exit codes, error propagation\n- **Input Validation**: Argument parsing, option handling, user input sanitization\n- **Debugging**: Set options (-x, -e, -u, -o pipefail), debug output strategies\n- **Performance**: Process substitution, parallel execution, efficient loops\n\n**Cross-Platform Scripting**\n- **Platform Detection**: OS-specific behavior handling\n- **Path Management**: Portable path construction and manipulation\n- **Tool Availability**: Checking for and handling missing dependencies\n- **Compatibility Layers**: Writing scripts that work everywhere\n\n**Automation Patterns**\n- **Idempotent Operations**: Scripts that can run multiple times safely\n- **Atomic Operations**: Ensuring all-or-nothing execution\n- **Progress Reporting**: User-friendly output and status updates\n- **Logging & Monitoring**: Structured logging for automated systems\n\n## Essential Commands\n\n**jq - JSON Processing**\n```bash\njq . data.json                                    # Pretty-print\njq -r '.key.subkey' data.json                     # Extract value\njq '.items[] | select(.status == \"active\")'       # Filter\n```\n\n**yq - YAML Processing**\n```bash\nyq '.services.web.image' docker-compose.yml       # Read value\nyq -i '.version = \"2.1.0\"' config.yml            # Update in-place\nyq -o json config.yml                             # Convert to JSON\n```\n\n**fd - Fast File Finding**\n```bash\nfd 'pattern'                 # Find by pattern\nfd -e md                     # Find by extension\nfd -e sh -x shellcheck {}    # Find and execute\n```\n\n**rg - Recursive Grep**\n```bash\nrg 'DATABASE_URL'            # Basic search\nrg 'TODO' -t python          # Search specific file types\nrg -C 3 'error'              # Search with context\n```\n\n## Best Practices\n\n**Script Development Workflow**\n1. **Requirements Analysis**: Understand automation need and target platforms\n2. **Tool Selection**: Choose appropriate tools for the task\n3. **Prototype Development**: Create initial script with core functionality\n4. **Error Handling**: Add robust error handling and edge case management\n5. **Cross-Platform Testing**: Verify script works on all target systems\n6. **Performance Optimization**: Profile and optimize for efficiency\n7. **Documentation**: Add clear usage instructions and inline comments\n\n**Critical Guidelines**\n- Always use shellcheck for linting\n- Set strict mode: `set -euo pipefail`\n- Quote all variables: `\"${var}\"`\n- Use functions for reusable code\n- Implement proper cleanup with trap\n- Provide helpful error messages\n- Include --help and --version options\n- Use meaningful variable names\n- Comment complex logic\n- Test with different shells when targeting POSIX\n\n## Common Patterns\n\n**Robust Script Template**\n```bash\n#!/usr/bin/env bash\nset -euo pipefail\nIFS=$'\\n\\t'\n\ntrap 'echo \"Error on line $LINENO\"' ERR\ntrap cleanup EXIT\n\ncleanup() {\n    rm -f \"$TEMP_FILE\" 2>/dev/null || true\n}\n\nmain() {\n    parse_args \"$@\"\n    validate_environment\n    execute_task\n}\n\nmain \"$@\"\n```\n\n**Cross-Platform Detection**\n```bash\ndetect_os() {\n    case \"$OSTYPE\" in\n        linux*)   OS=\"linux\" ;;\n        darwin*)  OS=\"macos\" ;;\n        msys*)    OS=\"windows\" ;;\n        *)        OS=\"unknown\" ;;\n    esac\n}\n```\n\nFor detailed command-line tools reference, advanced automation examples, and troubleshooting guidance, see REFERENCE.md."
              },
              {
                "name": "vectorcode-init",
                "description": "Initialize VectorCode with automatic configuration generation. Installs git hooks,\ngenerates vectorcode.include and vectorcode.exclude patterns based on project type.\nUse when user mentions \"initialize VectorCode\", \"set up VectorCode\", vectorcode.include,\nvectorcode.exclude, or VectorCode configuration.\n",
                "path": "tools-plugin/skills/vectorcode-init/SKILL.md",
                "frontmatter": {
                  "created": "2025-12-16T00:00:00.000Z",
                  "modified": "2025-12-16T00:00:00.000Z",
                  "reviewed": "2025-12-16T00:00:00.000Z",
                  "name": "vectorcode-init",
                  "description": "Initialize VectorCode with automatic configuration generation. Installs git hooks,\ngenerates vectorcode.include and vectorcode.exclude patterns based on project type.\nUse when user mentions \"initialize VectorCode\", \"set up VectorCode\", vectorcode.include,\nvectorcode.exclude, or VectorCode configuration.\n"
                },
                "content": "# VectorCode Initialization\n\nAutomate VectorCode setup with intelligent repository analysis and configuration generation.\n\n## Capabilities\n\nThis skill provides automatic VectorCode initialization for code repositories:\n\n1. **Git Hook Installation** - Automatically installs VectorCode git hooks via `vectorcode init --hooks`\n2. **Smart Include Patterns** - Analyzes repository structure to generate `vectorcode.include` with relevant file patterns\n3. **Smart Exclude Patterns** - Creates `vectorcode.exclude` to skip common non-code files (build artifacts, dependencies, etc.)\n4. **Project Type Detection** - Recognizes Python, Node.js, Rust, Go, Java, and other project types\n5. **Configuration Validation** - Checks existing VectorCode setup and offers improvements\n\n## When to Use\n\nInvoke this skill when:\n- User asks to \"initialize VectorCode\" or \"set up VectorCode\"\n- User mentions \"vectorcode init\", \"vectorcode hooks\", or \"vectorcode configuration\"\n- User wants to create `vectorcode.include` or `vectorcode.exclude` files\n- User asks about VectorCode setup or configuration\n\n## Workflow\n\n### 1. Repository Analysis\n- Detect project type(s) by examining file extensions and structure\n- Identify source code directories (src/, lib/, app/, etc.)\n- Find test directories and documentation folders\n- Detect package manager and build tool configurations\n\n### 2. Generate Include Patterns\nBased on project type, create patterns like:\n- **Python**: `**/*.py`, `**/pyproject.toml`, `**/setup.py`\n- **Node.js/TypeScript**: `**/*.js`, `**/*.ts`, `**/*.jsx`, `**/*.tsx`, `**/package.json`\n- **Rust**: `**/*.rs`, `**/Cargo.toml`\n- **Go**: `**/*.go`, `**/go.mod`\n- **Configuration**: `**/*.yaml`, `**/*.yml`, `**/*.json`, `**/*.toml`\n- **Documentation**: `**/*.md`, `**/*.rst`\n\n### 3. Generate Exclude Patterns\nCommon exclusions:\n- Node.js: `node_modules/`, `dist/`, `build/`, `.next/`\n- Python: `__pycache__/`, `*.pyc`, `.venv/`, `venv/`, `.pytest_cache/`\n- Build artifacts: `target/`, `out/`, `bin/`, `obj/`\n- Dependencies: `vendor/`, `third_party/`\n- IDE/editor: `.vscode/`, `.idea/`, `*.swp`\n- Version control: `.git/`\n- Package managers: `.cargo/`, `.npm/`, `pip-cache/`\n\n### 4. Install Git Hooks\nRun `vectorcode init --hooks` to install:\n- **post-commit** - Automatically index changed files after commits\n- **post-merge** - Update index after merging branches\n- **post-checkout** - Refresh index when switching branches\n\n### 5. Validate Configuration\nAfter setup:\n- Check that hooks are executable\n- Verify include/exclude files are syntactically valid\n- Test with `vectorcode ls` to confirm project is indexed\n- Suggest running `vectorcode vectorise` for initial indexing\n\n## Response Templates\n\n### Success Response\n```markdown\n VectorCode initialized successfully!\n\n**Git hooks installed:**\n- post-commit  auto-index changed files\n- post-merge  update index after merge\n- post-checkout  refresh index on branch switch\n\n**Configuration created:**\n- `vectorcode.include` ({count} patterns for {project_types})\n- `vectorcode.exclude` ({count} exclusion patterns)\n\n**Next steps:**\n1. Review patterns in `vectorcode.include` and `vectorcode.exclude`\n2. Run `vectorcode vectorise .` to perform initial indexing\n3. Use `vectorcode ls` to verify project is indexed\n4. Query code with `vectorcode query \"your search\"`\n```\n\n### Existing Configuration Response\n```markdown\nVectorCode is already configured in this repository.\n\n**Current setup:**\n- Git hooks: {installed/not installed}\n- Include patterns: {count} patterns in `vectorcode.include`\n- Exclude patterns: {count} patterns in `vectorcode.exclude`\n\n**Suggested improvements:**\n{list any recommendations based on current project structure}\n\nWould you like me to:\n1. Add missing patterns for {detected project types}\n2. Install/update git hooks\n3. Regenerate configuration from scratch\n```\n\n### Custom Configuration Response\nWhen user has specific requirements:\n```markdown\nI'll create a custom VectorCode configuration for your needs.\n\n**Include patterns:** {custom patterns}\n**Exclude patterns:** {custom patterns}\n\n{explain reasoning for pattern choices based on user's requirements}\n```\n\n## Implementation Notes\n\n### Pattern Syntax\nVectorCode uses gitignore-style patterns:\n- `**/*.py` - All Python files recursively\n- `src/**/*.ts` - TypeScript files under src/\n- `!important.log` - Negation (include despite previous exclusion)\n- `*.test.js` - Glob patterns supported\n\n### Priority Order\n1. Exclude patterns are evaluated first\n2. Include patterns can override excludes using `!` prefix\n3. More specific patterns take precedence\n\n### Git Hook Behavior\nHooks only index files matching include patterns and not matching exclude patterns.\nThis keeps the index focused and performant.\n\n## Error Handling\n\n### VectorCode Not Installed\nIf `vectorcode` command is not found:\n```markdown\nVectorCode is not installed. Install it with:\n\n**Using Homebrew:**\n```bash\nbrew install vectorcode\n```\n\n**Using cargo:**\n```bash\ncargo install vectorcode\n```\n\nThen re-run initialization.\n```\n\n### Permission Issues\nIf hooks cannot be made executable:\n```markdown\nFailed to make git hooks executable. Run manually:\n```bash\nchmod +x .git/hooks/post-commit\nchmod +x .git/hooks/post-merge\nchmod +x .git/hooks/post-checkout\n```\n```\n\n## Related Skills\n- **VectorCode Search** - Semantic code search using VectorCode\n- **Git Repo Detection** - Identify repository information\n- **Shell Expert** - Shell scripting and command execution\n\n## References\n- [VectorCode Documentation](https://github.com/davidyz/vectorcode)\n- [VectorCode MCP Server](https://github.com/modelcontextprotocol/servers/tree/main/src/vectorcode)\n- `.claude/skills/vectorcode-init/patterns.md` - Common pattern reference"
              },
              {
                "name": "VectorCode Semantic Search",
                "description": "Semantic code search with VectorCode using embeddings for finding code by meaning, not just keywords. Use when searching for code patterns, similar implementations, concept-based search, or when keyword search fails. Automatically available via MCP.",
                "path": "tools-plugin/skills/vectorcode-search/SKILL.md",
                "frontmatter": {
                  "created": "2025-12-16T00:00:00.000Z",
                  "modified": "2025-12-16T00:00:00.000Z",
                  "reviewed": "2025-12-16T00:00:00.000Z",
                  "name": "VectorCode Semantic Search",
                  "description": "Semantic code search with VectorCode using embeddings for finding code by meaning, not just keywords. Use when searching for code patterns, similar implementations, concept-based search, or when keyword search fails. Automatically available via MCP.",
                  "allowed-tools": "mcp__vectorcode, Read, Grep, Glob"
                },
                "content": "# VectorCode Semantic Search\n\nExpert knowledge for using VectorCode's semantic code search capabilities through MCP integration. VectorCode indexes code using embeddings, enabling searches based on meaning and context rather than exact keyword matches.\n\n## Core Expertise\n\n**Semantic Search**\n- Find code by intent and meaning, not just keywords\n- Discover similar implementations across codebases\n- Locate related functionality without knowing exact names\n- Cross-language concept search\n\n**Index Management**\n- List indexed projects and files\n- Add new files to the index\n- Remove outdated or irrelevant files\n- Verify index coverage\n\n**Query Optimization**\n- Formulate effective semantic queries\n- Combine with traditional search tools\n- Balance recall vs precision\n- Iterate queries based on results\n\n## When to Use VectorCode\n\n** Use VectorCode when:**\n- Searching by concept or intent (\"authentication logic\", \"error handling patterns\")\n- Finding similar code without knowing exact function names\n- Exploring unfamiliar codebases\n- Discovering related functionality across modules\n- Keyword search returns too many or irrelevant results\n- Looking for implementation patterns\n\n** Use Grep/Glob instead when:**\n- Searching for exact strings or identifiers\n- Finding specific function/class names\n- Locating file paths or extensions\n- Simple pattern matching suffices\n- Need complete exhaustive results\n\n** Combine both when:**\n- Initial semantic search to find areas of interest\n- Follow up with grep for specific details\n- Broad concept search, narrow with keywords\n\n## Essential MCP Tools\n\n### List Indexed Projects\n\n```javascript\n// Tool: mcp__vectorcode__ls\n// Lists all projects that have been indexed by VectorCode\n\n// Parameters: none\n// Returns: List of project root paths\n\n// Use this first to verify what's indexed\n```\n\n**When to use:**\n- Starting work on a new machine\n- Verifying project is indexed\n- Choosing project_root for queries\n- Troubleshooting missing results\n\n### Query Code Semantically\n\n```javascript\n// Tool: mcp__vectorcode__query\n// Performs semantic search across indexed code\n\n{\n  \"n_query\": 10,              // Number of results to return\n  \"query_messages\": [         // Array of search keywords/phrases\n    \"authentication\",\n    \"user login\",\n    \"session management\"\n  ],\n  \"project_root\": \"/path/to/project\"  // Must match indexed path\n}\n```\n\n**Parameters:**\n- `n_query` (number): Results to return (start with 10-20)\n- `query_messages` (array): Distinct keywords or phrases\n- `project_root` (string): Exact path from `ls` output\n\n**Returns:**\n- File paths with relevance scores\n- Code snippets with context\n- Line ranges for matches\n\n### Add Files to Index\n\n```javascript\n// Tool: mcp__vectorcode__vectorise\n// Adds files to VectorCode's embedding index\n\n{\n  \"paths\": [\n    \"/absolute/path/to/file1.py\",\n    \"/absolute/path/to/file2.js\"\n  ],\n  \"project_root\": \"/path/to/project\"\n}\n```\n\n**When to use:**\n- After creating new files\n- When expanding index coverage\n- After major code changes\n- Before semantic search sessions\n\n**Important:** Use absolute paths for files\n\n### List Indexed Files\n\n```javascript\n// Tool: mcp__vectorcode__files_ls\n// Lists all files indexed for a specific project\n\n{\n  \"project_root\": \"/path/to/project\"\n}\n```\n\n**When to use:**\n- Verifying what's indexed\n- Checking coverage of modules\n- Debugging missing results\n- Planning index updates\n\n### Remove Files from Index\n\n```javascript\n// Tool: mcp__vectorcode__files_rm\n// Removes files from the index\n\n{\n  \"files\": [\n    \"/absolute/path/to/file1.py\",\n    \"/absolute/path/to/file2.js\"\n  ],\n  \"project_root\": \"/path/to/project\"\n}\n```\n\n**When to use:**\n- After deleting source files\n- Removing generated/build files\n- Cleaning up old code\n- Reducing index size\n\n## Query Formulation Best Practices\n\n### Effective Query Keywords\n\n** Good queries:**\n```javascript\n// Concept-based\n[\"database connection\", \"connection pooling\"]\n\n// Functional intent\n[\"user authentication\", \"password validation\"]\n\n// Pattern-based\n[\"error handling\", \"try catch\", \"exception\"]\n\n// Domain-specific\n[\"HTTP request\", \"API endpoint\", \"REST\"]\n```\n\n** Poor queries:**\n```javascript\n// Too specific (use grep instead)\n[\"function getUserById\"]\n\n// Single generic word\n[\"data\"]\n\n// Implementation details (language-specific)\n[\"async def\", \"try:\"]\n```\n\n### Query Keywords Should Be:\n\n1. **Conceptual, not literal**\n   -  \"def authenticate\"\n   -  \"user authentication logic\"\n\n2. **Distinct and orthogonal**\n   -  [\"login\", \"sign in\", \"authenticate\"] (redundant)\n   -  [\"authentication\", \"session\", \"authorization\"] (different aspects)\n\n3. **Multiple perspectives**\n   -  [\"database\", \"persistence\", \"storage\"] (covers concept broadly)\n\n4. **Domain language**\n   -  [\"HTTP request\", \"API client\", \"REST endpoint\"]\n\n### Iterative Query Refinement\n\n```bash\n# Round 1: Broad concept\nquery: [\"authentication\", \"login\"]\nresult: Too many results\n\n# Round 2: Narrow with context\nquery: [\"OAuth authentication\", \"token validation\"]\nresult: Better, but missing some\n\n# Round 3: Add related concepts\nquery: [\"OAuth\", \"JWT token\", \"bearer authentication\"]\nresult: Good coverage\n\n# If still too broad, reduce n_query or use grep to filter\n```\n\n## Common Patterns\n\n### Explore Unfamiliar Codebase\n\n```javascript\n// Step 1: List indexed projects\nmcp__vectorcode__ls()\n\n// Step 2: Broad exploration\nmcp__vectorcode__query({\n  n_query: 20,\n  query_messages: [\"main entry point\", \"application startup\", \"initialization\"],\n  project_root: \"/path/to/project\"\n})\n\n// Step 3: Follow specific area\nmcp__vectorcode__query({\n  n_query: 15,\n  query_messages: [\"database schema\", \"models\", \"ORM\"],\n  project_root: \"/path/to/project\"\n})\n```\n\n### Find Similar Implementations\n\n```javascript\n// Looking for similar error handling\nmcp__vectorcode__query({\n  n_query: 10,\n  query_messages: [\"error handling\", \"exception management\", \"retry logic\"],\n  project_root: \"/path/to/project\"\n})\n\n// Looking for API patterns\nmcp__vectorcode__query({\n  n_query: 15,\n  query_messages: [\"REST API\", \"HTTP handler\", \"endpoint routing\"],\n  project_root: \"/path/to/project\"\n})\n```\n\n### Cross-Module Search\n\n```javascript\n// Find authentication across different modules\nmcp__vectorcode__query({\n  n_query: 20,\n  query_messages: [\"authentication\", \"authorization\", \"access control\"],\n  project_root: \"/path/to/project\"\n})\n\n// Results will include frontend, backend, middleware, etc.\n```\n\n### Discover Dependencies\n\n```javascript\n// Find where external services are used\nmcp__vectorcode__query({\n  n_query: 15,\n  query_messages: [\"external API\", \"third party\", \"service integration\"],\n  project_root: \"/path/to/project\"\n})\n\n// Find database access patterns\nmcp__vectorcode__query({\n  n_query: 15,\n  query_messages: [\"database query\", \"SQL\", \"data access\"],\n  project_root: \"/path/to/project\"\n})\n```\n\n### Locate Configuration\n\n```javascript\n// Find configuration handling\nmcp__vectorcode__query({\n  n_query: 10,\n  query_messages: [\"configuration\", \"settings\", \"environment variables\"],\n  project_root: \"/path/to/project\"\n})\n```\n\n### Debug Feature Implementation\n\n```javascript\n// Find where feature is implemented\nmcp__vectorcode__query({\n  n_query: 15,\n  query_messages: [\"user registration\", \"signup\", \"account creation\"],\n  project_root: \"/path/to/project\"\n})\n\n// Then use grep for specific details\n// grep -r \"createUser\" <files-from-vectorcode>\n```\n\n## Combining with Traditional Search\n\n### Two-Stage Search Strategy\n\n```bash\n# Stage 1: VectorCode for discovery\n# Broad semantic search to find relevant areas\n\nmcp__vectorcode__query({\n  n_query: 20,\n  query_messages: [\"payment processing\", \"transaction\"],\n  project_root: \"/path/to/project\"\n})\n\n# Results: src/payments/processor.py, src/api/checkout.py, ...\n\n# Stage 2: Grep for specifics\n# Now search specific files for exact patterns\n\ngrep -r \"process_payment\" src/payments/ src/api/\n```\n\n### Validation Pattern\n\n```bash\n# Use VectorCode to find candidates\n# Use Grep to verify exact matches\n\n# 1. Semantic search\nvectorcode: \"configuration loading\"\n# Returns: config.py, settings.py, env.py\n\n# 2. Verify with grep\ngrep -l \"load_config\\|read_settings\" config.py settings.py env.py\n```\n\n## Index Management Workflow\n\n### Initial Setup\n\n```bash\n# 1. Check if project is indexed\nmcp__vectorcode__ls()\n\n# 2. If not indexed, run vectorcode init (see vectorcode-init command)\n# This typically happens automatically via git hooks\n\n# 3. Verify files are indexed\nmcp__vectorcode__files_ls({project_root: \"/path/to/project\"})\n\n# 4. Add missing files if needed\nmcp__vectorcode__vectorise({\n  paths: [\"/path/to/new_file.py\"],\n  project_root: \"/path/to/project\"\n})\n```\n\n### Maintain Index\n\n```bash\n# After major changes\n# 1. Add new files\nmcp__vectorcode__vectorise({\n  paths: [\"/path/to/new_module.py\", \"/path/to/new_util.js\"],\n  project_root: \"/path/to/project\"\n})\n\n# 2. Remove deleted files\nmcp__vectorcode__files_rm({\n  files: [\"/path/to/old_file.py\"],\n  project_root: \"/path/to/project\"\n})\n\n# 3. For updated files, re-vectorize\n# (removing and re-adding automatically re-indexes)\n```\n\n### Troubleshooting Missing Results\n\n```bash\n# Check if file is indexed\nmcp__vectorcode__files_ls({project_root: \"/path/to/project\"})\n# Look for specific file in results\n\n# If missing, add it\nmcp__vectorcode__vectorise({\n  paths: [\"/path/to/missing_file.py\"],\n  project_root: \"/path/to/project\"\n})\n\n# Verify project root matches exactly\n# Common mistake: \"/path/to/project\" vs \"/path/to/project/\"\n```\n\n## Advanced Techniques\n\n### Multi-Concept Queries\n\n```javascript\n// Combine multiple related concepts\nmcp__vectorcode__query({\n  n_query: 25,\n  query_messages: [\n    \"authentication\",\n    \"authorization\",\n    \"permission check\",\n    \"access control\",\n    \"role based\"\n  ],\n  project_root: \"/path/to/project\"\n})\n```\n\n### Progressive Refinement\n\n```javascript\n// Start broad\nn_query: 30\nquery: [\"feature X\"]\n\n// Analyze results, then narrow\nn_query: 15\nquery: [\"feature X\", \"specific aspect\", \"related concept\"]\n\n// Further refinement\nn_query: 10\nquery: [\"very specific aspect\", \"implementation detail\"]\n```\n\n### Cross-Language Patterns\n\n```javascript\n// VectorCode works across languages\nmcp__vectorcode__query({\n  n_query: 20,\n  query_messages: [\"async operations\", \"concurrency\", \"parallel execution\"],\n  project_root: \"/path/to/project\"\n})\n\n// Will find async/await (JS), asyncio (Python), goroutines (Go), etc.\n```\n\n## Performance Tips\n\n**Query Size:**\n- Start with `n_query: 10-15` for focused results\n- Increase to `20-30` for broad exploration\n- Higher numbers = more results but lower relevance\n\n**Query Formulation:**\n- Spend time on good keywords\n- Use 2-5 distinct concepts\n- Use distinct, specific search terms\n- Think about synonyms and related concepts\n\n**Project Root:**\n- Always use exact path from `mcp__vectorcode__ls`\n- Case-sensitive on Unix systems\n- Include/exclude trailing slashes consistently\n\n**Indexing:**\n- Index incrementally (new files only)\n- Don't re-index entire project frequently\n- Use git hooks for automatic indexing\n\n## Common Pitfalls\n\n###  Using Exact Code as Query\n\n```javascript\n// Don't do this\nquery: [\"def process_payment(amount, user_id):\"]\n\n// Do this instead\nquery: [\"payment processing\", \"transaction handling\"]\n```\n\n###  Single Generic Word\n\n```javascript\n// Too broad\nquery: [\"function\"]\n\n// Better\nquery: [\"utility functions\", \"helper methods\", \"common operations\"]\n```\n\n###  Wrong Project Root\n\n```javascript\n// If ls shows: \"/Users/name/project\"\n// Don't use: \"/Users/name/project/\"  \n// Use:       \"/Users/name/project\"   \n```\n\n###  Expecting Exact Matches\n\n```javascript\n// VectorCode finds semantic similarity, not exact matches\n// For exact matches, use grep\n```\n\n## Integration with Other Skills\n\n**Combine with:**\n- **rg-code-search** - Follow up with exact keyword search\n- **fd-file-finding** - Locate files by name after VectorCode narrows scope\n- **grep** - Extract specific patterns from VectorCode results\n\n**Workflow:**\n1. VectorCode: Find relevant areas semantically\n2. fd/glob: Locate specific files in those areas\n3. grep/rg: Extract exact code patterns\n4. Read: Examine specific files\n\n## Comparison Matrix\n\n| Need | Tool | Why |\n|------|------|-----|\n| Find by concept | VectorCode | Semantic understanding |\n| Find exact string | grep/rg | Fast, exhaustive |\n| Find files by name | fd/glob | File system patterns |\n| Explore unknown code | VectorCode | No prior knowledge needed |\n| Verify completeness | grep | Exhaustive search |\n| Find similar code | VectorCode | Pattern recognition |\n\n## Quick Reference\n\n### MCP Tools\n- `mcp__vectorcode__ls` - List indexed projects\n- `mcp__vectorcode__query` - Semantic code search\n- `mcp__vectorcode__vectorise` - Add files to index\n- `mcp__vectorcode__files_ls` - List indexed files\n- `mcp__vectorcode__files_rm` - Remove files from index\n\n### Query Parameters\n- `n_query` - Number of results (10-30 typical)\n- `query_messages` - Array of distinct keywords\n- `project_root` - Exact project path from `ls`\n\n### Best Practices\n- Use concept-based keywords\n- Provide 2-5 distinct terms\n- Start broad, refine iteratively\n- Combine with traditional search\n- Verify project_root exactly\n\n### Common Query Patterns\n```javascript\n// Exploration\n[\"main functionality\", \"core logic\", \"entry point\"]\n\n// Feature location\n[\"user authentication\", \"login flow\", \"session management\"]\n\n// Pattern discovery\n[\"error handling\", \"retry logic\", \"fallback\"]\n\n// Architecture\n[\"database access\", \"API integration\", \"service layer\"]\n```\n\n## Resources\n\n- **VectorCode MCP Integration**: Automatically available when MCP server is configured\n- **Git Hooks**: Use `vectorcode init --hooks` to auto-index on commits\n- **Index Files**: `.vectorcode.include` and `.vectorcode.exclude` control indexing"
              },
              {
                "name": "yq YAML Processing",
                "description": "YAML querying, filtering, and transformation with yq command-line tool. Use when working with YAML files, parsing YAML configuration, modifying Kubernetes manifests, GitHub Actions workflows, or transforming YAML structures.",
                "path": "tools-plugin/skills/yq-yaml-processing/SKILL.md",
                "frontmatter": {
                  "created": "2025-12-16T00:00:00.000Z",
                  "modified": "2025-12-16T00:00:00.000Z",
                  "reviewed": "2025-12-16T00:00:00.000Z",
                  "name": "yq YAML Processing",
                  "description": "YAML querying, filtering, and transformation with yq command-line tool. Use when working with YAML files, parsing YAML configuration, modifying Kubernetes manifests, GitHub Actions workflows, or transforming YAML structures.",
                  "allowed-tools": "Bash, Read, Write, Edit, Grep, Glob"
                },
                "content": "# yq YAML Processing\n\nExpert knowledge for processing, querying, and transforming YAML data using yq v4+, the lightweight command-line YAML processor with jq-like syntax.\n\n## Core Expertise\n\n**YAML Operations**\n- Query and filter YAML with path expressions\n- Transform YAML structure and shape\n- Multi-document YAML support\n- Convert between YAML, JSON, XML, and other formats\n\n**Configuration Management**\n- Modify Kubernetes manifests\n- Update GitHub Actions workflows\n- Process Helm values files\n- Manage application configurations\n\n## Essential Commands\n\n### Basic Querying\n\n```bash\n# Pretty-print YAML\nyq '.' file.yaml\n\n# Evaluate and format\nyq eval '.' file.yaml\n\n# Extract specific field\nyq '.fieldName' file.yaml\n\n# Extract nested field\nyq '.spec.containers[0].name' pod.yaml\n\n# Access array element\nyq '.[0]' array.yaml\nyq '.items[2]' data.yaml\n```\n\n### Reading YAML\n\n```bash\n# Read specific field\nyq '.metadata.name' deployment.yaml\n\n# Read nested structure\nyq '.spec.template.spec.containers[].image' deployment.yaml\n\n# Read with default value\nyq '.optional // \"default\"' file.yaml\n\n# Check if field exists\nyq 'has(\"fieldName\")' file.yaml\n```\n\n### Array Operations\n\n```bash\n# Get array length\nyq '.items | length' file.yaml\n\n# Map over array\nyq '.items[].name' file.yaml\n\n# Filter array\nyq '.items[] | select(.active == true)' file.yaml\nyq '.users[] | select(.age > 18)' file.yaml\n\n# Sort array\nyq '.items | sort_by(.name)' file.yaml\nyq '.items | sort_by(.date) | reverse' file.yaml\n\n# Get first/last elements\nyq '.items | first' file.yaml\nyq '.items | last' file.yaml\n\n# Unique values\nyq '.tags | unique' file.yaml\n\n# Filter and collect\nyq '[.items[] | select(.status == \"active\")]' file.yaml\n```\n\n### Modifying YAML (In-Place)\n\n```bash\n# Update field value\nyq -i '.metadata.name = \"new-name\"' file.yaml\n\n# Update nested field\nyq -i '.spec.replicas = 3' deployment.yaml\n\n# Add new field\nyq -i '.metadata.labels.app = \"myapp\"' file.yaml\n\n# Delete field\nyq -i 'del(.spec.nodeSelector)' file.yaml\n\n# Append to array\nyq -i '.items += {\"name\": \"new-item\"}' file.yaml\n\n# Update array element\nyq -i '.items[0].status = \"updated\"' file.yaml\n\n# Update all matching elements\nyq -i '(.items[] | select(.name == \"foo\")).status = \"active\"' file.yaml\n```\n\n### Multi-Document YAML\n\n```bash\n# Split multi-document YAML\nyq -s '.metadata.name' multi-doc.yaml\n# Creates files: doc-0.yaml, doc-1.yaml, etc.\n\n# Select specific document (0-indexed)\nyq 'select(document_index == 0)' multi-doc.yaml\n\n# Process all documents\nyq eval-all '.' multi-doc.yaml\n\n# Filter documents\nyq 'select(.kind == \"Deployment\")' k8s-resources.yaml\n\n# Combine YAML files\nyq eval-all '. as $item ireduce ({}; . * $item)' file1.yaml file2.yaml\n```\n\n### Object Operations\n\n```bash\n# Get all keys\nyq 'keys' file.yaml\n\n# Select specific fields\nyq '{name, version}' file.yaml\n\n# Rename field\nyq '{newName: .oldName, other: .other}' file.yaml\n\n# Merge objects\nyq '. * {\"updated\": true}' file.yaml\nyq eval-all 'select(fileIndex == 0) * select(fileIndex == 1)' base.yaml override.yaml\n\n# Deep merge\nyq eval-all '. as $item ireduce ({}; . *+ $item)' base.yaml override.yaml\n```\n\n### Filtering and Conditions\n\n```bash\n# Select with conditions\nyq 'select(.status == \"active\")' file.yaml\nyq '.[] | select(.price < 100)' file.yaml\n\n# Multiple conditions (AND)\nyq '.[] | select(.active and .verified)' file.yaml\nyq '.[] | select(.age > 18 and .country == \"US\")' file.yaml\n\n# Multiple conditions (OR)\nyq '.[] | select(.type == \"admin\" or .type == \"moderator\")' file.yaml\n\n# Has field\nyq '.[] | select(has(\"email\"))' file.yaml\n\n# Field not null\nyq 'select(.optional != null)' file.yaml\n\n# Not condition\nyq '.[] | select(.status != \"deleted\")' file.yaml\n\n# Contains (arrays)\nyq '.tags | contains([\"important\"])' file.yaml\n```\n\n### String Operations\n\n```bash\n# String interpolation\nyq '\"Hello, \\(.name)\"' file.yaml\n\n# Convert to string\nyq '.port | tostring' file.yaml\n\n# String contains\nyq '.[] | select(.email | contains(\"@gmail.com\"))' file.yaml\n\n# String starts/ends with\nyq '.[] | select(.name | test(\"^A\"))' file.yaml\nyq '.[] | select(.file | test(\"\\\\.yaml$\"))' file.yaml\n\n# Split string\nyq '.path | split(\"/\")' file.yaml\n\n# Join array to string\nyq '.tags | join(\", \")' file.yaml\n\n# Lowercase/uppercase\nyq '.name | downcase' file.yaml\nyq '.name | upcase' file.yaml\n\n# String substitution\nyq '.image | sub(\"v1.0\"; \"v2.0\")' file.yaml\n```\n\n### Format Conversion\n\n```bash\n# YAML to JSON\nyq -o=json '.' file.yaml\n\n# JSON to YAML\nyq -p=json '.' file.json\n\n# YAML to XML\nyq -o=xml '.' file.yaml\n\n# YAML to CSV/TSV\nyq -o=csv '.' file.yaml\nyq -o=tsv '.' file.yaml\n\n# Properties format\nyq -o=props '.' file.yaml\n\n# Compact JSON\nyq -o=json -I=0 '.' file.yaml\n```\n\n### Output Formatting\n\n```bash\n# Compact output\nyq -o=yaml -I=0 '.' file.yaml\n\n# Custom indentation\nyq -I=4 '.' file.yaml\n\n# No colors\nyq --no-colors '.' file.yaml\n\n# Raw output (no quotes)\nyq -r '.message' file.yaml\n\n# Null input (create YAML from scratch)\nyq -n '.name = \"example\" | .version = \"1.0\"'\n```\n\n### Real-World Examples\n\n```bash\n# Kubernetes: Get all container images\nyq '.spec.template.spec.containers[].image' deployment.yaml\n\n# Kubernetes: Update image version\nyq -i '.spec.template.spec.containers[0].image = \"myapp:v2.0\"' deployment.yaml\n\n# Kubernetes: Add label to all deployments\nyq -i '(.metadata.labels.environment = \"production\")' deployment.yaml\n\n# GitHub Actions: Extract job names\nyq '.jobs | keys' .github/workflows/ci.yml\n\n# GitHub Actions: Update checkout action version\nyq -i '(.jobs.*.steps[] | select(.uses == \"actions/checkout*\")).uses = \"actions/checkout@v5\"' workflow.yml\n\n# Docker Compose: Get all service names\nyq '.services | keys' docker-compose.yml\n\n# Docker Compose: Update service image\nyq -i '.services.web.image = \"nginx:latest\"' docker-compose.yml\n\n# Helm: Override values\nyq -i '.replicaCount = 5 | .image.tag = \"v2.0\"' values.yaml\n\n# Config: Merge environment-specific configs\nyq eval-all 'select(fileIndex == 0) * select(fileIndex == 1)' base-config.yaml prod-config.yaml\n\n# Extract all environment variables\nyq '.spec.template.spec.containers[].env[].name' deployment.yaml\n\n# Create ConfigMap from key-value pairs\nyq -n '.apiVersion = \"v1\" | .kind = \"ConfigMap\" | .metadata.name = \"myconfig\" |\n  .data.key1 = \"value1\" | .data.key2 = \"value2\"'\n\n# Batch update: Change all port references\nyq -i '(.. | select(has(\"port\"))).port = 8080' config.yaml\n```\n\n### Advanced Patterns\n\n```bash\n# Recursive descent (find all images)\nyq '.. | select(has(\"image\")) | .image' file.yaml\n\n# Variable assignment\nyq '.items[] | . as $item | $item.name + \" - \" + ($item.price | tostring)' file.yaml\n\n# Conditional updates\nyq -i '(.spec.replicas) |= if . < 3 then 3 else . end' deployment.yaml\n\n# Reduce (sum, accumulate)\nyq '[.items[].price] | add' file.yaml\n\n# Group by\nyq 'group_by(.category)' items.yaml\n\n# Flatten nested arrays\nyq '.items | flatten' file.yaml\n\n# Alternative operator (default values)\nyq '.optional // \"default-value\"' file.yaml\n\n# Error handling with alternative\nyq '.mayNotExist // empty' file.yaml\n```\n\n## Best Practices\n\n**Query Construction**\n- Use `yq eval` for complex expressions\n- Test on small files first before modifying production configs\n- Use `-i` flag carefully (always backup first)\n- Prefer specific paths over recursive descent for performance\n\n**Configuration Management**\n- Version control before in-place edits\n- Use `yq eval-all` for merging configurations\n- Validate YAML after modifications\n- Document complex transformations in scripts\n\n**Multi-Document YAML**\n- Use `select(document_index == N)` for specific documents\n- Use `eval-all` when processing multiple documents together\n- Split large multi-doc files with `-s` for easier management\n\n**Performance**\n- Use targeted queries for large files (instead of `..` recursive descent)\n- Use specific paths when possible\n- Process files in parallel when operating on multiple files\n- Stream large files if yq supports it\n\n## Common Patterns\n\n### Kubernetes Manifests\n\n```bash\n# Update deployment image\nyq -i '.spec.template.spec.containers[0].image = \"app:v2.0\"' deployment.yaml\n\n# Scale deployment\nyq -i '.spec.replicas = 5' deployment.yaml\n\n# Add environment variable\nyq -i '.spec.template.spec.containers[0].env += [{\"name\": \"DEBUG\", \"value\": \"true\"}]' deployment.yaml\n\n# Get all resource names\nyq '.metadata.name' *.yaml\n\n# Filter by kind\nyq 'select(.kind == \"Service\")' *.yaml\n\n# Extract all namespaces\nyq '.metadata.namespace' *.yaml | sort -u\n```\n\n### GitHub Actions Workflows\n\n```bash\n# List all jobs\nyq '.jobs | keys' .github/workflows/ci.yml\n\n# Get job steps\nyq '.jobs.build.steps[].name' .github/workflows/ci.yml\n\n# Update action version\nyq -i '(.jobs.*.steps[] | select(.uses | test(\"actions/checkout\"))).uses = \"actions/checkout@v5\"' workflow.yml\n\n# Add environment variable to job\nyq -i '.jobs.build.env.NODE_ENV = \"production\"' .github/workflows/ci.yml\n\n# Extract trigger events\nyq '.on | keys' .github/workflows/*.yml\n```\n\n### Configuration Files\n\n```bash\n# Environment-specific config merge\nyq eval-all 'select(fileIndex == 0) *+ select(fileIndex == 1)' base.yaml production.yaml\n\n# Update nested configuration\nyq -i '.database.host = \"prod-db.example.com\"' config.yaml\n\n# Add to array configuration\nyq -i '.allowed_hosts += [\"example.com\"]' config.yaml\n\n# Remove sensitive fields\nyq -i 'del(.secrets)' config.yaml\n```\n\n### Docker Compose\n\n```bash\n# List services\nyq '.services | keys' docker-compose.yml\n\n# Update service image\nyq -i '.services.app.image = \"myapp:latest\"' docker-compose.yml\n\n# Add port mapping\nyq -i '.services.web.ports += [\"8080:80\"]' docker-compose.yml\n\n# Set environment variables\nyq -i '.services.app.environment.DEBUG = \"true\"' docker-compose.yml\n```\n\n## Troubleshooting\n\n### Invalid YAML\n```bash\n# Validate YAML syntax\nyq '.' file.yaml  # Will show parse errors\n\n# Check YAML structure\nyq eval '.' file.yaml\n```\n\n### Empty Results\n```bash\n# Debug: Show entire structure\nyq '.' file.yaml\n\n# Debug: Check keys\nyq 'keys' file.yaml\n\n# Debug: Check type\nyq 'type' file.yaml\n\n# Debug: Show all scalar values\nyq '.. | select(tag == \"!!str\")' file.yaml\n```\n\n### Unexpected In-Place Edits\n```bash\n# Preview changes (without -i)\nyq '.field = \"new-value\"' file.yaml\n\n# Backup before edit\ncp file.yaml file.yaml.bak\nyq -i '.field = \"new-value\"' file.yaml\n\n# Use version control\ngit diff file.yaml\n```\n\n### Multi-Document Issues\n```bash\n# Count documents\nyq 'document_index' multi-doc.yaml | sort -u | wc -l\n\n# Process specific document\nyq 'select(document_index == 0)' multi-doc.yaml\n\n# Process all documents\nyq eval-all '.' multi-doc.yaml\n```\n\n## Integration with Other Tools\n\n```bash\n# With kubectl (Kubernetes)\nkubectl get deployment myapp -o yaml | yq '.spec.replicas'\n\n# With helm\nhelm template myapp ./chart | yq 'select(.kind == \"Service\")'\n\n# With git (version control)\ngit diff deployment.yaml | grep '^+' | yq -p yaml '.'\n\n# With find (batch processing)\nfind . -name \"*.yaml\" -exec yq '.version' {} \\;\n\n# With jq (JSON processing)\nyq -o=json '.' file.yaml | jq '.specific.field'\n\n# With envsubst (environment variable substitution)\nyq '.database.host = strenv(DB_HOST)' config.yaml\n```\n\n## yq vs jq Comparison\n\n| Operation | jq | yq |\n|-----------|----|----|\n| Read field | `jq '.field'` | `yq '.field'` |\n| Update in-place | Not supported | `yq -i '.field = \"value\"'` |\n| Format output | `jq .` | `yq .` |\n| Multi-file merge | `jq -s` | `yq eval-all` |\n| String interpolation | `\"\\(.var)\"` | `\"\\(.var)\"` |\n| Convert to JSON | N/A | `yq -o=json` |\n\n## Quick Reference\n\n### Operators\n- `.field` - Access field\n- `.[]` - Iterate array/object\n- `|` - Pipe (chain operations)\n- `,` - Multiple outputs\n- `//` - Alternative operator (default value)\n- `*` - Merge objects (shallow)\n- `*+` - Deep merge objects\n\n### Functions\n- `keys`, `values` - Object keys/values\n- `length` - Array/object/string length\n- `select()` - Filter\n- `sort_by()` - Sort\n- `group_by()` - Group\n- `unique` - Remove duplicates\n- `has()` - Check field existence\n- `type` - Get value type\n- `add` - Sum or concatenate\n- `del()` - Delete field\n\n### Flags\n- `-i` - In-place edit\n- `-o` - Output format (json, yaml, xml, csv, tsv, props)\n- `-p` - Input format (json, yaml, xml)\n- `-I` - Indent (default: 2)\n- `-r` - Raw output (no quotes)\n- `-n` - Null input (create from scratch)\n- `-s` - Split multi-document YAML\n\n### String Functions\n- `split()`, `join()` - String/array conversion\n- `contains()` - String/array contains\n- `test()` - Regex match\n- `sub()`, `gsub()` - String substitution\n- `upcase`, `downcase` - Case conversion\n\n## Installation\n\n```bash\n# macOS (Homebrew)\nbrew install yq\n\n# Note: Install mikefarah/yq (v4+), not the Python yq\nbrew install yq\n\n# Ubuntu/Debian (snap)\nsudo snap install yq\n\n# Verify installation (should be v4+)\nyq --version\n```\n\n**Important**: This skill assumes yq v4+ (mikefarah/yq). The older Python-based yq has different syntax.\n\n## Resources\n\n- **Official Documentation**: https://mikefarah.gitbook.io/yq/\n- **GitHub Repository**: https://github.com/mikefarah/yq\n- **Try with Docker**: `docker run --rm -i mikefarah/yq '.key' <<< 'key: value'`\n- **Operators Reference**: https://mikefarah.gitbook.io/yq/operators/"
              }
            ]
          },
          {
            "name": "rust-plugin",
            "description": "Rust development - cargo, clippy, testing, memory safety",
            "source": "./rust-plugin",
            "category": "language",
            "version": "1.0.0",
            "author": null,
            "install_commands": [
              "/plugin marketplace add laurigates/claude-plugins",
              "/plugin install rust-plugin@lgates-claude-plugins"
            ],
            "signals": {
              "stars": 1,
              "forks": 0,
              "pushed_at": "2026-01-12T12:05:51Z",
              "created_at": "2025-12-16T11:24:04Z",
              "license": null
            },
            "commands": [],
            "skills": [
              {
                "name": "cargo-llvm-cov",
                "description": "Code coverage for Rust using LLVM instrumentation with support for multiple output formats and CI integration.\nUse when measuring test coverage, generating coverage reports, enforcing coverage thresholds, or integrating with codecov/coveralls.\nTrigger terms: coverage, llvm-cov, code coverage, test coverage, coverage report, codecov, coveralls, branch coverage.\n",
                "path": "rust-plugin/skills/cargo-llvm-cov/SKILL.md",
                "frontmatter": {
                  "created": "2025-12-16T00:00:00.000Z",
                  "modified": "2025-12-16T00:00:00.000Z",
                  "reviewed": "2025-12-16T00:00:00.000Z",
                  "name": "cargo-llvm-cov",
                  "description": "Code coverage for Rust using LLVM instrumentation with support for multiple output formats and CI integration.\nUse when measuring test coverage, generating coverage reports, enforcing coverage thresholds, or integrating with codecov/coveralls.\nTrigger terms: coverage, llvm-cov, code coverage, test coverage, coverage report, codecov, coveralls, branch coverage.\n"
                },
                "content": "# cargo-llvm-cov - Code Coverage with LLVM\n\ncargo-llvm-cov provides accurate code coverage for Rust using LLVM's instrumentation-based coverage. It supports multiple output formats and integrates seamlessly with CI platforms.\n\n## Installation\n\n```bash\n# Install cargo-llvm-cov\ncargo install cargo-llvm-cov\n\n# Verify installation\ncargo llvm-cov --version\n\n# Install llvm-tools-preview component (required)\nrustup component add llvm-tools-preview\n```\n\n## Basic Usage\n\n```bash\n# Run tests and generate coverage\ncargo llvm-cov\n\n# Generate HTML report\ncargo llvm-cov --html\nopen target/llvm-cov/html/index.html\n\n# Generate LCOV report\ncargo llvm-cov --lcov --output-path target/llvm-cov/lcov.info\n\n# Generate JSON report\ncargo llvm-cov --json --output-path target/llvm-cov/coverage.json\n\n# Show coverage as text summary\ncargo llvm-cov --text\n\n# Show coverage for specific files\ncargo llvm-cov --text -- --show-instantiations\n```\n\n## Output Formats\n\n```bash\n# HTML report (interactive, line-by-line)\ncargo llvm-cov --html --open\n\n# LCOV format (compatible with many tools)\ncargo llvm-cov --lcov --output-path lcov.info\n\n# JSON format (programmatic analysis)\ncargo llvm-cov --json --output-path coverage.json\n\n# Cobertura XML (for Jenkins, GitLab)\ncargo llvm-cov --cobertura --output-path cobertura.xml\n\n# Text summary (terminal output)\ncargo llvm-cov --text\n\n# Multiple formats simultaneously\ncargo llvm-cov --html --lcov --output-path lcov.info\n```\n\n## Coverage Thresholds for CI\n\n```bash\n# Fail if coverage is below threshold\ncargo llvm-cov --fail-under-lines 80\n\n# Multiple threshold types\ncargo llvm-cov --fail-under-lines 80 --fail-under-functions 75\n\n# Available threshold types\ncargo llvm-cov --fail-under-lines 80      # Line coverage\ncargo llvm-cov --fail-under-regions 80    # Region coverage\ncargo llvm-cov --fail-under-functions 75  # Function coverage\n```\n\n### Threshold Configuration\n\nCreate a script or Makefile for consistent thresholds:\n\n```makefile\n# Makefile\n.PHONY: coverage coverage-ci\n\ncoverage:\n\tcargo llvm-cov --html --open\n\ncoverage-ci:\n\tcargo llvm-cov \\\n\t\t--fail-under-lines 80 \\\n\t\t--fail-under-functions 75 \\\n\t\t--lcov --output-path lcov.info\n```\n\nOr use a shell script:\n\n```bash\n#!/usr/bin/env bash\n# scripts/coverage.sh\nset -euo pipefail\n\nCOVERAGE_THRESHOLD=\"${COVERAGE_THRESHOLD:-80}\"\n\ncargo llvm-cov \\\n  --fail-under-lines \"$COVERAGE_THRESHOLD\" \\\n  --lcov --output-path target/llvm-cov/lcov.info \\\n  --html\n\necho \"Coverage threshold: $COVERAGE_THRESHOLD% (lines)\"\n```\n\n## Branch Coverage (Nightly)\n\nBranch coverage requires Rust nightly:\n\n```bash\n# Install nightly toolchain\nrustup toolchain install nightly\nrustup component add llvm-tools-preview --toolchain nightly\n\n# Run with branch coverage\ncargo +nightly llvm-cov --branch --html\n\n# Branch coverage with thresholds\ncargo +nightly llvm-cov \\\n  --branch \\\n  --fail-under-lines 80 \\\n  --fail-under-branches 70\n```\n\n### Branch Coverage Configuration\n\n```toml\n# rust-toolchain.toml\n[toolchain]\nchannel = \"nightly\"\ncomponents = [\"llvm-tools-preview\"]\n\n# Allows using `cargo llvm-cov --branch` without +nightly\n```\n\n## Integration with cargo-nextest\n\n```bash\n# Use nextest as test runner\ncargo llvm-cov nextest --html\n\n# With nextest profile\ncargo llvm-cov nextest --profile ci --lcov --output-path lcov.info\n\n# All nextest options work\ncargo llvm-cov nextest -E 'not test(slow_)' --html\n```\n\n## Codecov Integration\n\n```yaml\n# .github/workflows/coverage.yml\nname: Coverage\n\non: [push, pull_request]\n\njobs:\n  coverage:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n\n      - uses: dtolnay/rust-toolchain@stable\n        with:\n          components: llvm-tools-preview\n\n      - name: Install cargo-llvm-cov\n        uses: taiki-e/install-action@v2\n        with:\n          tool: cargo-llvm-cov\n\n      - name: Generate coverage\n        run: cargo llvm-cov --all-features --lcov --output-path lcov.info\n\n      - name: Upload to codecov\n        uses: codecov/codecov-action@v4\n        with:\n          files: lcov.info\n          fail_ci_if_error: true\n          token: ${{ secrets.CODECOV_TOKEN }}\n```\n\n## Coveralls Integration\n\n```yaml\n# .github/workflows/coverage.yml\nname: Coverage\n\non: [push, pull_request]\n\njobs:\n  coverage:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n\n      - uses: dtolnay/rust-toolchain@stable\n        with:\n          components: llvm-tools-preview\n\n      - name: Install cargo-llvm-cov\n        uses: taiki-e/install-action@v2\n        with:\n          tool: cargo-llvm-cov\n\n      - name: Generate coverage\n        run: cargo llvm-cov --all-features --lcov --output-path lcov.info\n\n      - name: Upload to Coveralls\n        uses: coverallsapp/github-action@v2\n        with:\n          github-token: ${{ secrets.GITHUB_TOKEN }}\n          path-to-lcov: lcov.info\n```\n\n## Advanced Configuration\n\n### Exclude Files from Coverage\n\n```bash\n# Exclude generated code\ncargo llvm-cov --ignore-filename-regex '.*generated.*'\n\n# Exclude test files\ncargo llvm-cov --ignore-filename-regex '.*test.*'\n\n# Multiple patterns\ncargo llvm-cov \\\n  --ignore-filename-regex '.*generated.*' \\\n  --ignore-filename-regex '.*mock.*'\n```\n\n### Workspace Coverage\n\n```bash\n# Coverage for all workspace members\ncargo llvm-cov --workspace --html\n\n# Coverage for specific packages\ncargo llvm-cov -p my_lib -p my_app --html\n\n# Exclude specific packages\ncargo llvm-cov --workspace --exclude integration_tests --html\n```\n\n### Coverage with Feature Flags\n\n```bash\n# Coverage with all features\ncargo llvm-cov --all-features --html\n\n# Coverage with specific features\ncargo llvm-cov --features async,tls --html\n\n# Coverage without default features\ncargo llvm-cov --no-default-features --html\n```\n\n## GitHub Actions: Complete Example\n\n```yaml\n# .github/workflows/coverage.yml\nname: Coverage\n\non:\n  push:\n    branches: [main]\n  pull_request:\n\nenv:\n  CARGO_TERM_COLOR: always\n  COVERAGE_THRESHOLD: 80\n\njobs:\n  coverage:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n\n      - uses: dtolnay/rust-toolchain@stable\n        with:\n          components: llvm-tools-preview\n\n      - uses: Swatinem/rust-cache@v2\n\n      - name: Install cargo-llvm-cov\n        uses: taiki-e/install-action@v2\n        with:\n          tool: cargo-llvm-cov\n\n      - name: Install cargo-nextest\n        uses: taiki-e/install-action@v2\n        with:\n          tool: nextest\n\n      - name: Generate coverage\n        run: |\n          cargo llvm-cov nextest \\\n            --all-features \\\n            --fail-under-lines $COVERAGE_THRESHOLD \\\n            --lcov --output-path lcov.info \\\n            --html\n\n      - name: Upload coverage to Codecov\n        uses: codecov/codecov-action@v4\n        with:\n          files: lcov.info\n          fail_ci_if_error: true\n          token: ${{ secrets.CODECOV_TOKEN }}\n\n      - name: Upload HTML report\n        uses: actions/upload-artifact@v4\n        if: always()\n        with:\n          name: coverage-report\n          path: target/llvm-cov/html/\n```\n\n## Clean Coverage Data\n\n```bash\n# Clean previous coverage data\ncargo llvm-cov clean\n\n# Clean and run fresh coverage\ncargo llvm-cov clean && cargo llvm-cov --html\n```\n\n## Doctests Coverage\n\n```bash\n# Include doctests in coverage\ncargo llvm-cov --doc --html\n\n# Doctests with workspace\ncargo llvm-cov --workspace --doc --html\n\n# Note: doctests run in separate context, may not integrate perfectly\n```\n\n## Comparison with tarpaulin\n\n| Feature | cargo-llvm-cov | cargo-tarpaulin |\n|---------|----------------|-----------------|\n| Backend | LLVM (compiler) | ptrace (runtime) |\n| Accuracy | Excellent | Good |\n| Performance | Fast | Slower |\n| Branch coverage | Yes (nightly) | Yes |\n| Stability | Stable | Sometimes unstable |\n| Platform support | All Rust targets | Linux, limited macOS |\n| Setup complexity | Simple | Simple |\n\n## Best Practices\n\n1. **Use with nextest for faster execution**:\n   ```bash\n   cargo llvm-cov nextest --all-features --html\n   ```\n\n2. **Enforce coverage thresholds in CI**:\n   ```bash\n   cargo llvm-cov --fail-under-lines 80\n   ```\n\n3. **Generate multiple formats for different tools**:\n   ```bash\n   cargo llvm-cov --html --lcov --output-path lcov.info\n   ```\n\n4. **Exclude generated code from coverage**:\n   ```bash\n   cargo llvm-cov --ignore-filename-regex '.*generated.*'\n   ```\n\n5. **Cache coverage dependencies in CI**:\n   ```yaml\n   - uses: Swatinem/rust-cache@v2\n   ```\n\n6. **Use branch coverage on nightly for critical code**:\n   ```bash\n   cargo +nightly llvm-cov --branch --fail-under-branches 70\n   ```\n\n7. **Clean coverage data between runs**:\n   ```bash\n   cargo llvm-cov clean\n   ```\n\n## Troubleshooting\n\n**Missing llvm-tools-preview:**\n```bash\nrustup component add llvm-tools-preview\n```\n\n**Coverage seems inaccurate:**\n```bash\n# Clean and regenerate\ncargo llvm-cov clean\ncargo clean\ncargo llvm-cov --html\n```\n\n**Nightly features not working:**\n```bash\nrustup toolchain install nightly\nrustup component add llvm-tools-preview --toolchain nightly\ncargo +nightly llvm-cov --branch --html\n```\n\n**Slow coverage generation:**\n```bash\n# Use nextest for parallel execution\ncargo llvm-cov nextest --html\n```\n\n**Doctests not included:**\n```bash\n# Run with --doc flag\ncargo llvm-cov --doc --html\n```\n\n## References\n\n- [cargo-llvm-cov documentation](https://github.com/taiki-e/cargo-llvm-cov)\n- [LLVM coverage mapping](https://llvm.org/docs/CoverageMappingFormat.html)\n- [Codecov Rust](https://about.codecov.io/language/rust/)\n- [coveralls-api crate](https://docs.rs/coveralls-api)"
              },
              {
                "name": "cargo-machete",
                "description": "Detect unused dependencies in Rust projects for cleaner Cargo.toml files and faster builds.\nUse when auditing dependencies, optimizing build times, cleaning up Cargo.toml, or detecting bloat.\nTrigger terms: unused dependencies, cargo-machete, dependency audit, dependency cleanup, bloat detection, cargo-udeps.\n",
                "path": "rust-plugin/skills/cargo-machete/SKILL.md",
                "frontmatter": {
                  "created": "2025-12-16T00:00:00.000Z",
                  "modified": "2025-12-16T00:00:00.000Z",
                  "reviewed": "2025-12-16T00:00:00.000Z",
                  "name": "cargo-machete",
                  "description": "Detect unused dependencies in Rust projects for cleaner Cargo.toml files and faster builds.\nUse when auditing dependencies, optimizing build times, cleaning up Cargo.toml, or detecting bloat.\nTrigger terms: unused dependencies, cargo-machete, dependency audit, dependency cleanup, bloat detection, cargo-udeps.\n"
                },
                "content": "# cargo-machete - Unused Dependency Detection\n\ncargo-machete is a fast tool for detecting unused dependencies in Rust projects. It analyzes your codebase to find dependencies listed in Cargo.toml but not actually used in your code.\n\n## Installation\n\n```bash\n# Install cargo-machete\ncargo install cargo-machete\n\n# Verify installation\ncargo machete --version\n```\n\n## Basic Usage\n\n```bash\n# Check for unused dependencies in current directory\ncargo machete\n\n# Check specific directory\ncargo machete /path/to/project\n\n# Check with detailed output\ncargo machete --with-metadata\n\n# Fix unused dependencies automatically (removes from Cargo.toml)\ncargo machete --fix\n\n# Check workspace\ncargo machete --workspace\n```\n\n## Output Examples\n\n### Basic Output\n\n```bash\n$ cargo machete\nFound unused dependencies in Cargo.toml:\n  serde_json (unused)\n  log (unused in lib, used in build.rs)\n  tokio (unused features: macros)\n```\n\n### With Metadata\n\n```bash\n$ cargo machete --with-metadata\nProject: my_app (bin)\n  Unused dependencies:\n    - serde_json (0.1.0)\n      Declared in: Cargo.toml [dependencies]\n      Not used in: src/main.rs\n\n  Partially used:\n    - tokio (1.35.0)\n      Unused features: macros, fs\n      Used features: runtime, net\n```\n\n## False Positive Handling\n\n### Common False Positives\n\n1. **Dependencies used only in build.rs**:\n   ```toml\n   [build-dependencies]\n   bindgen = \"0.69\"  # Correctly placed, machete won't flag\n   ```\n\n2. **Dependencies used only in examples**:\n   ```toml\n   [dev-dependencies]\n   criterion = \"0.5\"  # For examples/benchmarks\n   ```\n\n3. **Dependencies used via re-exports**:\n   ```rust\n   // lib.rs\n   pub use external_crate::SomeType;  # Machete may not detect\n   ```\n\n4. **Proc-macro dependencies**:\n   ```toml\n   [dependencies]\n   serde = { version = \"1.0\", features = [\"derive\"] }\n   # Machete may flag serde as unused if only using derive macro\n   ```\n\n### Ignoring False Positives\n\nCreate `.cargo-machete.toml` or add to `Cargo.toml`:\n\n```toml\n# .cargo-machete.toml\n[ignore]\n# Ignore specific dependencies\ndependencies = [\"serde\", \"log\"]\n\n# Ignore dependencies in specific crates\n[ignore.my_crate]\ndependencies = [\"tokio\"]\n```\n\nOr use inline comments in `Cargo.toml`:\n\n```toml\n[dependencies]\nserde = \"1.0\"  # machete:ignore - used via re-export\nlog = \"0.4\"    # machete:ignore - used in macro expansion\n```\n\n## Comparison with cargo-udeps\n\n| Feature | cargo-machete | cargo-udeps |\n|---------|---------------|-------------|\n| Accuracy | Good | Excellent |\n| Speed | Very fast | Slower |\n| Rust version | Stable | Requires nightly |\n| False positives | Some | Fewer |\n| Installation | Simple | Requires nightly setup |\n| Maintenance | Active | Active |\n\n### When to Use Each\n\n**Use cargo-machete when:**\n- Working with stable Rust\n- Need fast feedback in CI\n- Willing to verify results manually\n- Want simple installation\n\n**Use cargo-udeps when:**\n- Accuracy is critical\n- Can use nightly toolchain\n- Need to catch all unused dependencies\n- Have time for slower analysis\n\n### Using Both Together\n\n```bash\n# Fast check with machete\ncargo machete\n\n# Verify with udeps (more accurate)\ncargo +nightly udeps\n```\n\n## cargo-udeps Installation and Usage\n\nFor comparison, here's how to use the more accurate cargo-udeps:\n\n```bash\n# Install nightly and cargo-udeps\nrustup toolchain install nightly\ncargo +nightly install cargo-udeps\n\n# Run analysis (requires nightly)\ncargo +nightly udeps\n\n# With specific features\ncargo +nightly udeps --all-features\n\n# For workspace\ncargo +nightly udeps --workspace\n```\n\n## CI Integration\n\n### GitHub Actions with cargo-machete\n\n```yaml\nname: Dependency Check\n\non: [push, pull_request]\n\njobs:\n  unused-deps:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n\n      - uses: dtolnay/rust-toolchain@stable\n\n      - name: Install cargo-machete\n        uses: taiki-e/install-action@v2\n        with:\n          tool: cargo-machete\n\n      - name: Check for unused dependencies\n        run: cargo machete --with-metadata\n```\n\n### GitHub Actions with cargo-udeps (Nightly)\n\n```yaml\nname: Dependency Check\n\non: [push, pull_request]\n\njobs:\n  unused-deps:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n\n      - uses: dtolnay/rust-toolchain@nightly\n\n      - uses: Swatinem/rust-cache@v2\n\n      - name: Install cargo-udeps\n        uses: taiki-e/install-action@v2\n        with:\n          tool: cargo-udeps\n\n      - name: Check for unused dependencies\n        run: cargo +nightly udeps --workspace --all-features\n```\n\n### GitHub Action (Official cargo-machete Action)\n\n```yaml\nname: Dependency Check\n\non: [push, pull_request]\n\njobs:\n  unused-deps:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Check unused dependencies\n        uses: bnjbvr/cargo-machete@main\n```\n\n## Advanced Usage\n\n### Workspace Configuration\n\n```bash\n# Check all workspace members\ncargo machete --workspace\n\n# Check specific workspace members\ncargo machete -p crate1 -p crate2\n\n# Exclude specific members\ncargo machete --workspace --exclude integration_tests\n```\n\n### Custom Configuration File\n\nCreate `.cargo-machete.toml` in project root:\n\n```toml\n# .cargo-machete.toml\n\n# Global ignores\n[ignore]\ndependencies = [\n  \"serde\",      # Used via derive macro\n  \"log\",        # Used in macro expansion\n]\n\n# Per-crate ignores\n[ignore.my_lib]\ndependencies = [\"lazy_static\"]\n\n[ignore.my_bin]\ndependencies = [\"clap\"]\n\n# Workspace-wide settings\n[workspace]\n# Don't analyze these crates\nexclude = [\"internal_tools\", \"examples\"]\n```\n\n### Integration with Pre-commit\n\n```yaml\n# .pre-commit-config.yaml\nrepos:\n  - repo: local\n    hooks:\n      - id: cargo-machete\n        name: Check for unused dependencies\n        entry: cargo machete\n        language: system\n        pass_filenames: false\n        files: Cargo.toml$\n```\n\n## Workflow Integration\n\n### Combined with Other Tools\n\n```bash\n# Full dependency audit\ncargo machete                 # Check unused\ncargo outdated                # Check outdated\ncargo audit                   # Check security\ncargo deny check licenses     # Check licenses\n```\n\n### Makefile Integration\n\n```makefile\n# Makefile\n.PHONY: deps-check deps-clean\n\ndeps-check:\n\t@echo \"Checking for unused dependencies...\"\n\t@cargo machete --with-metadata\n\ndeps-clean:\n\t@echo \"Removing unused dependencies...\"\n\t@cargo machete --fix\n\t@echo \"Running cargo check...\"\n\t@cargo check --all-targets\n```\n\n### Script for CI\n\n```bash\n#!/usr/bin/env bash\n# scripts/check-deps.sh\nset -euo pipefail\n\necho \"Running cargo-machete...\"\nif ! cargo machete --with-metadata; then\n  echo \" Unused dependencies detected!\"\n  echo \"Run 'cargo machete --fix' to remove them.\"\n  exit 1\nfi\n\necho \" No unused dependencies found.\"\n```\n\n## Best Practices\n\n1. **Run regularly in CI**:\n   ```yaml\n   - run: cargo machete --with-metadata\n   ```\n\n2. **Document false positives**:\n   ```toml\n   [dependencies]\n   serde = \"1.0\"  # machete:ignore - used via proc macro\n   ```\n\n3. **Use with workspace**:\n   ```bash\n   cargo machete --workspace --with-metadata\n   ```\n\n4. **Verify before using --fix**:\n   ```bash\n   # Check first\n   cargo machete --with-metadata\n   # Review output, then fix\n   cargo machete --fix\n   # Verify everything still builds\n   cargo check --all-targets\n   ```\n\n5. **Combine with cargo-udeps for accuracy**:\n   ```bash\n   # Fast check\n   cargo machete\n   # Verify critical projects\n   cargo +nightly udeps -p critical_lib\n   ```\n\n6. **Add to pre-commit hooks** for early detection:\n   ```yaml\n   - id: cargo-machete\n     entry: cargo machete\n     language: system\n   ```\n\n7. **Keep configuration file** for complex projects:\n   ```toml\n   # .cargo-machete.toml\n   [ignore]\n   dependencies = [\"known-false-positives\"]\n   ```\n\n## Troubleshooting\n\n**False positives for proc macros:**\n```toml\n# Add to .cargo-machete.toml\n[ignore]\ndependencies = [\"serde\", \"tokio-macros\"]\n```\n\n**Build.rs dependencies flagged:**\n```toml\n# Should be in [build-dependencies]\n[build-dependencies]\ncc = \"1.0\"\n```\n\n**Re-exported dependencies flagged:**\n```toml\n# Document with comment\n[dependencies]\nexternal = \"1.0\"  # machete:ignore - re-exported in lib.rs\n```\n\n**Workspace member issues:**\n```bash\n# Check specific member\ncargo machete -p problematic_crate --with-metadata\n```\n\n**Need more accuracy:**\n```bash\n# Use cargo-udeps instead\ncargo +nightly udeps --workspace\n```\n\n## References\n\n- [cargo-machete repository](https://github.com/bnjbvr/cargo-machete)\n- [cargo-udeps repository](https://github.com/est31/cargo-udeps)\n- [Official GitHub Action](https://github.com/bnjbvr/cargo-machete)\n- [Rust dependency management best practices](https://doc.rust-lang.org/cargo/guide/dependencies.html)"
              },
              {
                "name": "cargo-nextest",
                "description": "Next-generation test runner for Rust with parallel execution, advanced filtering, and CI integration.\nUse when running tests, configuring test execution, setting up CI pipelines, or optimizing test performance.\nTrigger terms: nextest, test runner, parallel tests, test filtering, test performance, flaky tests, CI testing.\n",
                "path": "rust-plugin/skills/cargo-nextest/SKILL.md",
                "frontmatter": {
                  "created": "2025-12-16T00:00:00.000Z",
                  "modified": "2025-12-16T00:00:00.000Z",
                  "reviewed": "2025-12-16T00:00:00.000Z",
                  "name": "cargo-nextest",
                  "description": "Next-generation test runner for Rust with parallel execution, advanced filtering, and CI integration.\nUse when running tests, configuring test execution, setting up CI pipelines, or optimizing test performance.\nTrigger terms: nextest, test runner, parallel tests, test filtering, test performance, flaky tests, CI testing.\n"
                },
                "content": "# cargo-nextest - Next-Generation Test Runner\n\ncargo-nextest is a faster, more reliable test runner for Rust that executes each test in its own process for better isolation and parallel performance.\n\n## Installation\n\n```bash\n# Install cargo-nextest\ncargo install cargo-nextest --locked\n\n# Verify installation\ncargo nextest --version\n```\n\n## Basic Usage\n\n```bash\n# Run all tests with nextest\ncargo nextest run\n\n# Run specific test\ncargo nextest run test_name\n\n# Run tests in specific package\ncargo nextest run -p package_name\n\n# Run with verbose output\ncargo nextest run --verbose\n\n# Run ignored tests\ncargo nextest run -- --ignored\n\n# Run all tests including ignored\ncargo nextest run -- --include-ignored\n```\n\n## Configuration File\n\nCreate `.config/nextest.toml` in your project root:\n\n```toml\n[profile.default]\n# Number of retries for flaky tests\nretries = 0\n\n# Test threads (default: number of logical CPUs)\ntest-threads = 8\n\n# Fail fast - stop on first failure\nfail-fast = false\n\n# Show output for passing tests\nsuccess-output = \"never\"  # never, immediate, final, immediate-final\n\n# Show output for failing tests\nfailure-output = \"immediate\"  # never, immediate, final, immediate-final\n\n[profile.ci]\n# CI-specific configuration\nretries = 2\nfail-fast = true\nsuccess-output = \"never\"\nfailure-output = \"immediate-final\"\n\n# Slow test timeout\nslow-timeout = { period = \"60s\", terminate-after = 2 }\n\n[profile.ci.junit]\n# JUnit XML output for CI\npath = \"target/nextest/ci/junit.xml\"\n```\n\n## Test Filtering with Expression Language\n\n```bash\n# Run tests matching pattern\ncargo nextest run -E 'test(auth)'\n\n# Run tests in specific binary\ncargo nextest run -E 'binary(my_app)'\n\n# Run tests in specific package\ncargo nextest run -E 'package(my_crate)'\n\n# Complex expressions with operators\ncargo nextest run -E 'test(auth) and not test(slow)'\n\n# Run all integration tests\ncargo nextest run -E 'kind(test)'\n\n# Run only unit tests in library\ncargo nextest run -E 'kind(lib) and test(/)'\n```\n\n### Expression Operators\n\n- `test(pattern)` - Match test name (regex)\n- `binary(pattern)` - Match binary name\n- `package(pattern)` - Match package name\n- `kind(type)` - Match test kind (lib, bin, test, bench, example)\n- `platform(os)` - Match target platform\n- `not expr` - Logical NOT\n- `expr and expr` - Logical AND\n- `expr or expr` - Logical OR\n\n## Parallel Execution\n\nNextest runs each test in its own process by default, providing:\n\n- **Better isolation** - Tests cannot interfere with each other\n- **True parallelism** - No global state conflicts\n- **Fault isolation** - One test crash doesn't affect others\n- **Better resource management** - Each test has clean environment\n\n```bash\n# Control parallelism\ncargo nextest run --test-threads 4\n\n# Single-threaded execution\ncargo nextest run --test-threads 1\n\n# Use all available cores\ncargo nextest run --test-threads 0\n```\n\n## Output Formats\n\n```bash\n# Human-readable output (default)\ncargo nextest run\n\n# JSON output for programmatic parsing\ncargo nextest run --message-format json\n\n# JSON with test output\ncargo nextest run --message-format json-pretty\n\n# Generate JUnit XML for CI\ncargo nextest run --profile ci\n\n# Combine with cargo-llvm-cov for coverage\ncargo llvm-cov nextest --html\n```\n\n## Flaky Test Management\n\n```toml\n# In .config/nextest.toml\n[profile.default]\n# Retry flaky tests automatically\nretries = 3\n\n# Detect tests that pass on retry\n[profile.default.overrides]\nfilter = 'test(flaky_)'\nretries = 5\n```\n\n```bash\n# Run with retries\ncargo nextest run --retries 3\n\n# Show retry statistics\ncargo nextest run --retries 3 --failure-output immediate-final\n```\n\n## GitHub Actions Integration\n\n```yaml\nname: Test\n\non: [push, pull_request]\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n\n      - uses: dtolnay/rust-toolchain@stable\n\n      - name: Install nextest\n        uses: taiki-e/install-action@v2\n        with:\n          tool: nextest\n\n      - name: Run tests\n        run: cargo nextest run --profile ci --all-features\n\n      - name: Upload test results\n        if: always()\n        uses: actions/upload-artifact@v4\n        with:\n          name: test-results\n          path: target/nextest/ci/junit.xml\n\n      - name: Publish test results\n        uses: EnricoMi/publish-unit-test-result-action@v2\n        if: always()\n        with:\n          files: target/nextest/ci/junit.xml\n```\n\n## Advanced Configuration\n\n```toml\n# .config/nextest.toml\n[profile.default]\n# Timeout for slow tests\nslow-timeout = { period = \"30s\", terminate-after = 3 }\n\n# Test groups for resource management\n[test-groups.database]\nmax-threads = 1  # Serialize database tests\n\n[profile.default.overrides]\nfilter = 'test(db_)'\ntest-group = 'database'\n\n# Platform-specific overrides\n[[profile.default.overrides]]\nplatform = 'x86_64-pc-windows-msvc'\nslow-timeout = { period = \"60s\" }\n```\n\n## Doctests Limitation\n\n**Important**: nextest does not support doctests. Use cargo test for doctests:\n\n```bash\n# Run doctests separately\ncargo test --doc\n\n# Run both nextest and doctests in CI\ncargo nextest run && cargo test --doc\n```\n\n## Workspace Configuration\n\n```toml\n# In workspace root .config/nextest.toml\n[profile.default]\ndefault-filter = 'all()'\n\n# Per-package overrides\n[[profile.default.overrides]]\nfilter = 'package(slow_tests)'\ntest-threads = 1\nslow-timeout = { period = \"120s\" }\n```\n\n## Comparison with cargo test\n\n| Feature | cargo test | cargo nextest |\n|---------|------------|---------------|\n| Execution model | In-process | Per-test process |\n| Parallelism | Thread-based | Process-based |\n| Test isolation | Shared state | Complete isolation |\n| Output format | Limited | Rich (JSON, JUnit) |\n| Flaky test handling | Manual | Built-in retries |\n| Doctests | Supported | Not supported |\n| Performance | Good | Excellent |\n\n## Best Practices\n\n1. **Use profiles for different environments**:\n   - `default` for local development\n   - `ci` for continuous integration\n   - `coverage` for coverage analysis\n\n2. **Configure flaky test detection**:\n   ```toml\n   [profile.default]\n   retries = 2\n   ```\n\n3. **Group resource-intensive tests**:\n   ```toml\n   [test-groups.expensive]\n   max-threads = 2\n   ```\n\n4. **Set appropriate timeouts**:\n   ```toml\n   [profile.default]\n   slow-timeout = { period = \"60s\", terminate-after = 2 }\n   ```\n\n5. **Use expression filters effectively**:\n   ```bash\n   # Run fast tests during development\n   cargo nextest run -E 'not test(slow_)'\n   ```\n\n6. **Always run doctests separately in CI**:\n   ```yaml\n   - run: cargo nextest run --all-features\n   - run: cargo test --doc --all-features\n   ```\n\n## Troubleshooting\n\n**Tests timeout too quickly:**\n```toml\n[profile.default]\nslow-timeout = { period = \"120s\", terminate-after = 3 }\n```\n\n**Too much parallel execution:**\n```bash\ncargo nextest run --test-threads 4\n```\n\n**Need test output for debugging:**\n```bash\ncargo nextest run --success-output immediate --failure-output immediate\n```\n\n**Flaky tests in CI:**\n```toml\n[profile.ci]\nretries = 3\nfailure-output = \"immediate-final\"\n```\n\n## References\n\n- [nextest documentation](https://nexte.st/)\n- [Configuration reference](https://nexte.st/docs/configuration/)\n- [Expression language](https://nexte.st/docs/running/)\n- [CI Features](https://nexte.st/docs/ci-features/archiving/)"
              },
              {
                "name": "clippy-advanced",
                "description": "Advanced Clippy configuration for comprehensive Rust linting with custom rules, categories, and IDE integration.\nUse when configuring linting rules, enforcing code standards, setting up CI linting, or customizing clippy behavior.\nTrigger terms: clippy, linting, code quality, clippy.toml, pedantic, nursery, restriction, lint configuration, code standards.\n",
                "path": "rust-plugin/skills/clippy-advanced/SKILL.md",
                "frontmatter": {
                  "created": "2025-12-16T00:00:00.000Z",
                  "modified": "2025-12-16T00:00:00.000Z",
                  "reviewed": "2025-12-16T00:00:00.000Z",
                  "name": "clippy-advanced",
                  "description": "Advanced Clippy configuration for comprehensive Rust linting with custom rules, categories, and IDE integration.\nUse when configuring linting rules, enforcing code standards, setting up CI linting, or customizing clippy behavior.\nTrigger terms: clippy, linting, code quality, clippy.toml, pedantic, nursery, restriction, lint configuration, code standards.\n"
                },
                "content": "# clippy-advanced - Advanced Clippy Configuration\n\nAdvanced Clippy configuration for comprehensive Rust linting, including custom rules, lint categories, disallowed methods, and IDE integration.\n\n## Installation\n\n```bash\n# Clippy is included with rustup\nrustup component add clippy\n\n# Verify installation\ncargo clippy --version\n\n# Update clippy with rust toolchain\nrustup update\n```\n\n## Basic Usage\n\n```bash\n# Run clippy on current project\ncargo clippy\n\n# Run on all targets (lib, bins, tests, examples, benches)\ncargo clippy --all-targets\n\n# Run with all features enabled\ncargo clippy --all-features\n\n# Run on workspace\ncargo clippy --workspace --all-targets --all-features\n\n# Show detailed lint explanations\ncargo clippy -- -W clippy::all -A clippy::pedantic\n\n# Treat warnings as errors\ncargo clippy -- -D warnings\n```\n\n## clippy.toml Configuration File\n\nCreate `clippy.toml` or `.clippy.toml` in project root:\n\n```toml\n# clippy.toml - Project-wide clippy configuration\n\n# Enforce documentation for public items\n# Warn if public items are missing documentation\nmissing-docs-in-crate-items = \"warn\"\n\n# Cognitive complexity threshold\n# Functions with complexity above this will trigger a warning\ncognitive-complexity-threshold = 15\n\n# Type complexity threshold\n# Complex types will trigger a warning\ntype-complexity-threshold = 100\n\n# Function length threshold\n# Long functions will trigger a warning\ntoo-many-lines-threshold = 100\n\n# Too many arguments threshold\ntoo-many-arguments-threshold = 5\n\n# Vec box size threshold\n# Large heap allocations in Vec will trigger a warning\nvec-box-size-threshold = 4096\n\n# Disallowed methods with custom messages\ndisallowed-methods = [\n  { path = \"std::env::var\", reason = \"Use std::env::var_os for better Unicode handling\" },\n  { path = \"std::panic::catch_unwind\", reason = \"Prefer structured error handling\" },\n  { path = \"std::process::exit\", reason = \"Use Result propagation instead\" },\n]\n\n# Disallowed types\ndisallowed-types = [\n  { path = \"std::collections::HashMap\", reason = \"Use indexmap::IndexMap for deterministic iteration\" },\n  { path = \"once_cell::sync::Lazy\", reason = \"Use std::sync::LazyLock (Rust 1.80+)\" },\n]\n\n# Allowed identifiers (bypass naming lints)\nallowed-idents-below-min-chars = [\"i\", \"j\", \"x\", \"y\", \"id\", \"db\"]\n\n# Import granularity (prefer full paths)\n# Options: \"crate\", \"module\", \"item\", \"one\"\nimports-granularity = \"module\"\n\n# Enforce module inception\n# Warn about modules that only contain a single item\n# which could be moved up to parent module\nallow-module-inception = false\n\n# Standard library imports style\n# Options: \"absolute\", \"module\"\nimports-prefer-module = true\n\n# Single component path imports\n# Warn about imports of single component paths\nsingle-component-path-imports = \"warn\"\n\n# Array size threshold for performance lints\n# Large arrays passed by value will trigger a warning\narray-size-threshold = 512\n\n# String literal as bytes\n# Prefer b\"string\" over \"string\".as_bytes()\n# Options: \"always\", \"never\"\nliteral-representation = \"always\"\n\n# Allowed scripts for confusable characters\n# Prevent mixing similar-looking characters from different scripts\nallowed-confusable-scripts = [\"Latin\", \"Greek\"]\n\n# Semicolon consistency\n# Options: \"never\", \"always\"\nsemicolon-if-nothing-returned = \"always\"\n\n# Blacklist/whitelist naming\n# Use inclusive terminology\ndisallowed-names = [\"foo\", \"bar\", \"baz\", \"master\", \"slave\", \"whitelist\", \"blacklist\"]\n\n# Prefer module-level documentation\ndoc-markdown-inline-code = true\n```\n\n## Lint Categories\n\n### All Available Categories\n\n```bash\n# Default lints (enabled by default)\ncargo clippy -- -W clippy::all\n\n# Pedantic lints (opinionated style)\ncargo clippy -- -W clippy::pedantic\n\n# Restriction lints (opt-in for specific constraints)\ncargo clippy -- -W clippy::restriction\n\n# Nursery lints (experimental, may have false positives)\ncargo clippy -- -W clippy::nursery\n\n# Cargo lints (Cargo.toml issues)\ncargo clippy -- -W clippy::cargo\n\n# Complexity lints (overly complex code)\ncargo clippy -- -W clippy::complexity\n\n# Correctness lints (likely bugs)\ncargo clippy -- -W clippy::correctness\n\n# Perf lints (performance issues)\ncargo clippy -- -W clippy::perf\n\n# Style lints (code style)\ncargo clippy -- -W clippy::style\n\n# Suspicious lints (code that looks wrong)\ncargo clippy -- -W clippy::suspicious\n```\n\n### Recommended Category Combination\n\n```toml\n# Cargo.toml\n[workspace.lints.clippy]\n# Deny correctness issues (likely bugs)\ncorrectness = \"deny\"\n\n# Warn on complexity\ncomplexity = \"warn\"\n\n# Warn on performance issues\nperf = \"warn\"\n\n# Warn on style issues\nstyle = \"warn\"\n\n# Warn on suspicious patterns\nsuspicious = \"warn\"\n\n# Enable pedantic but allow some noisy lints\npedantic = \"warn\"\nmust_use_candidate = \"allow\"\nmissing_errors_doc = \"allow\"\n\n# Enable some restriction lints selectively\nclone_on_ref_ptr = \"warn\"\ndbg_macro = \"warn\"\nprint_stdout = \"warn\"\ntodo = \"warn\"\nunimplemented = \"warn\"\n\n# Enable nursery lints (experimental)\nuse_self = \"warn\"\n```\n\n## Cargo.toml Lint Configuration (Recommended)\n\n```toml\n# Cargo.toml - Modern workspace lint configuration (Rust 1.74+)\n[workspace.lints.clippy]\n# Correctness - deny bugs\ncorrectness = { level = \"deny\", priority = -1 }\n\n# Complexity\ncomplexity = \"warn\"\ncognitive_complexity = \"warn\"\ntoo_many_arguments = \"warn\"\ntoo_many_lines = \"warn\"\ntype_complexity = \"warn\"\n\n# Performance\nperf = \"warn\"\nlarge_enum_variant = \"warn\"\nlarge_stack_arrays = \"warn\"\n\n# Style\nstyle = \"warn\"\nmissing_docs_in_private_items = \"warn\"\n\n# Pedantic (selective)\npedantic = \"warn\"\nmust_use_candidate = \"allow\"\nmissing_errors_doc = \"allow\"\nmissing_panics_doc = \"allow\"\nmodule_name_repetitions = \"allow\"\n\n# Restriction (opt-in)\nclone_on_ref_ptr = \"warn\"\ndbg_macro = \"warn\"\nempty_drop = \"warn\"\nexit = \"warn\"\nexpect_used = \"warn\"\nfiletype_is_file = \"warn\"\nget_unwrap = \"warn\"\npanic = \"warn\"\nprint_stderr = \"warn\"\nprint_stdout = \"warn\"\ntodo = \"warn\"\nunimplemented = \"warn\"\nunreachable = \"warn\"\nunwrap_used = \"warn\"\n\n# Nursery (experimental, may have false positives)\nuse_self = \"warn\"\nuseless_let_if_seq = \"warn\"\n\n# Cargo\ncargo = \"warn\"\nmultiple_crate_versions = \"warn\"\n\n[workspace.lints.rust]\n# Rust lints\nmissing_docs = \"warn\"\nunsafe_code = \"warn\"\n```\n\n## Allow and Deny Attributes\n\n### Function-level Overrides\n\n```rust\n// Allow specific lint for entire function\n#[allow(clippy::too_many_arguments)]\nfn complex_function(a: i32, b: i32, c: i32, d: i32, e: i32, f: i32) {\n    // ...\n}\n\n// Deny specific lint\n#[deny(clippy::unwrap_used)]\nfn critical_function() -> Result<(), Error> {\n    // This will error if unwrap() is used\n    Ok(())\n}\n\n// Warn for specific lint\n#[warn(clippy::print_stdout)]\nfn debug_function() {\n    println!(\"This will warn\");\n}\n```\n\n### Module-level Configuration\n\n```rust\n// src/lib.rs or src/main.rs\n#![warn(clippy::all)]\n#![warn(clippy::pedantic)]\n#![warn(clippy::nursery)]\n#![deny(clippy::unwrap_used)]\n#![deny(clippy::expect_used)]\n\n// Allow specific lints\n#![allow(clippy::module_name_repetitions)]\n#![allow(clippy::must_use_candidate)]\n\n// Individual module configuration\n#[allow(clippy::pedantic)]\nmod legacy_code {\n    // Disable pedantic for this module\n}\n```\n\n### Inline Suppression\n\n```rust\n// Suppress for specific line\n#[allow(clippy::cast_possible_truncation)]\nlet x = value as u8;\n\n// Suppress for expression\nlet y = {\n    #[allow(clippy::cast_sign_loss)]\n    negative_value as u32\n};\n\n// Suppress for block\n{\n    #![allow(clippy::indexing_slicing)]\n    let element = slice[index];\n}\n```\n\n## CI Integration\n\n### GitHub Actions - Strict Linting\n\n```yaml\nname: Clippy\n\non: [push, pull_request]\n\nenv:\n  CARGO_TERM_COLOR: always\n\njobs:\n  clippy:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n\n      - uses: dtolnay/rust-toolchain@stable\n        with:\n          components: clippy\n\n      - uses: Swatinem/rust-cache@v2\n\n      - name: Run clippy\n        run: |\n          cargo clippy --workspace --all-targets --all-features -- -D warnings\n\n      - name: Run clippy pedantic\n        run: |\n          cargo clippy --workspace --all-targets --all-features -- \\\n            -W clippy::pedantic \\\n            -W clippy::nursery \\\n            -D clippy::correctness\n```\n\n### GitHub Actions - Reviewdog Integration\n\n```yaml\nname: Clippy Review\n\non: [pull_request]\n\njobs:\n  clippy-review:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n\n      - uses: dtolnay/rust-toolchain@stable\n        with:\n          components: clippy\n\n      - uses: Swatinem/rust-cache@v2\n\n      - uses: giraffate/clippy-action@v1\n        with:\n          reporter: 'github-pr-review'\n          github_token: ${{ secrets.GITHUB_TOKEN }}\n          clippy_flags: --all-targets --all-features\n```\n\n### Pre-commit Hook\n\n```yaml\n# .pre-commit-config.yaml\nrepos:\n  - repo: local\n    hooks:\n      - id: cargo-clippy\n        name: cargo clippy\n        entry: cargo clippy\n        args: ['--all-targets', '--all-features', '--', '-D', 'warnings']\n        language: system\n        pass_filenames: false\n        files: \\.rs$\n```\n\n## rust-analyzer Integration\n\nConfigure in VS Code settings or rust-analyzer config:\n\n```json\n// .vscode/settings.json\n{\n  \"rust-analyzer.check.command\": \"clippy\",\n  \"rust-analyzer.check.extraArgs\": [\n    \"--all-targets\",\n    \"--all-features\",\n    \"--\",\n    \"-W\",\n    \"clippy::pedantic\",\n    \"-W\",\n    \"clippy::nursery\"\n  ],\n  \"rust-analyzer.checkOnSave\": true\n}\n```\n\nOr in `rust-analyzer.toml`:\n\n```toml\n# rust-analyzer.toml\n[checkOnSave]\ncommand = \"clippy\"\nextraArgs = [\n  \"--all-targets\",\n  \"--all-features\",\n  \"--\",\n  \"-W\", \"clippy::pedantic\",\n  \"-W\", \"clippy::nursery\",\n  \"-A\", \"clippy::module_name_repetitions\"\n]\n```\n\n## Disallowed Methods Configuration\n\n```toml\n# clippy.toml\ndisallowed-methods = [\n  # Prevent unwrap/expect in production code\n  { path = \"std::option::Option::unwrap\", reason = \"Use unwrap_or, unwrap_or_else, or proper error handling\" },\n  { path = \"std::result::Result::unwrap\", reason = \"Use unwrap_or, unwrap_or_else, or the ? operator\" },\n  { path = \"std::option::Option::expect\", reason = \"Use unwrap_or, unwrap_or_else, or proper error handling\" },\n  { path = \"std::result::Result::expect\", reason = \"Use unwrap_or, unwrap_or_else, or the ? operator\" },\n\n  # Prevent panic\n  { path = \"std::panic\", reason = \"Use Result and proper error handling\" },\n\n  # Prevent process::exit\n  { path = \"std::process::exit\", reason = \"Return from main or propagate errors\" },\n\n  # Environment variable handling\n  { path = \"std::env::var\", reason = \"Use std::env::var_os for better Unicode handling\" },\n\n  # Prevent direct println! in libraries\n  { path = \"std::println\", reason = \"Use logging (log, tracing) instead of println\" },\n  { path = \"std::eprintln\", reason = \"Use logging (log, tracing) instead of eprintln\" },\n]\n\ndisallowed-types = [\n  # Prefer newer stdlib types\n  { path = \"std::sync::mpsc::channel\", reason = \"Use crossbeam-channel for better performance\" },\n  { path = \"std::collections::HashMap\", reason = \"Consider indexmap for deterministic ordering\" },\n\n  # Deprecated types\n  { path = \"std::mem::uninitialized\", reason = \"Use MaybeUninit instead\" },\n]\n```\n\n## Advanced Patterns\n\n### Conditional Linting for Tests\n\n```rust\n// src/lib.rs\n#![deny(clippy::unwrap_used)]\n\n// tests/integration.rs\n#![allow(clippy::unwrap_used)]  // Ok in tests\n\n#[cfg(test)]\nmod tests {\n    // Tests can use unwrap\n    #[test]\n    fn test_something() {\n        let value = Some(42);\n        assert_eq!(value.unwrap(), 42);\n    }\n}\n```\n\n### Feature-gated Lints\n\n```rust\n#[cfg(not(feature = \"unsafe_optimizations\"))]\n#![deny(unsafe_code)]\n\n#[cfg(feature = \"unsafe_optimizations\")]\n#![warn(unsafe_code)]\n```\n\n### Documentation Lints\n\n```rust\n// Enforce documentation\n#![warn(missing_docs)]\n#![warn(clippy::missing_docs_in_private_items)]\n\n/// Public function documentation\npub fn public_function() {\n    // ...\n}\n\n/// Private function documentation (if pedantic enabled)\nfn private_function() {\n    // ...\n}\n```\n\n## Best Practices\n\n1. **Start with defaults, gradually enable stricter lints**:\n   ```toml\n   [workspace.lints.clippy]\n   all = \"warn\"\n   correctness = \"deny\"\n   ```\n\n2. **Use Cargo.toml for workspace-wide configuration**:\n   ```toml\n   [workspace.lints.clippy]\n   # All crates inherit these\n   ```\n\n3. **Document why lints are suppressed**:\n   ```rust\n   #[allow(clippy::cast_possible_truncation)]  // Value range validated above\n   let x = value as u8;\n   ```\n\n4. **Treat warnings as errors in CI**:\n   ```yaml\n   - run: cargo clippy -- -D warnings\n   ```\n\n5. **Enable pedantic selectively**:\n   ```toml\n   pedantic = \"warn\"\n   must_use_candidate = \"allow\"  # Too noisy\n   ```\n\n6. **Use disallowed-methods for project-specific rules**:\n   ```toml\n   disallowed-methods = [\n     { path = \"std::println\", reason = \"Use tracing instead\" }\n   ]\n   ```\n\n7. **Integrate with rust-analyzer** for real-time feedback\n\n8. **Review and update configuration** as project matures\n\n## Troubleshooting\n\n**Too many warnings:**\n```bash\n# Start with just correctness\ncargo clippy -- -W clippy::correctness\n# Gradually enable more\n```\n\n**False positives:**\n```rust\n#[allow(clippy::specific_lint)]  // Document why\nfn special_case() { }\n```\n\n**Lint not applying:**\n```bash\n# Check clippy version\ncargo clippy --version\n# Update toolchain\nrustup update\n```\n\n**CI failures due to new lints:**\n```toml\n# Pin clippy version in rust-toolchain.toml\n[toolchain]\nchannel = \"1.75.0\"\ncomponents = [\"clippy\"]\n```\n\n## References\n\n- [Clippy documentation](https://doc.rust-lang.org/clippy/)\n- [Lint list](https://rust-lang.github.io/rust-clippy/master/)\n- [Configuration options](https://doc.rust-lang.org/clippy/configuration.html)\n- [rust-analyzer integration](https://rust-analyzer.github.io/manual.html)"
              },
              {
                "name": "rust-development",
                "description": "Modern Rust development with cargo, rustc, clippy, rustfmt, async programming, and\nmemory-safe systems programming. Covers ownership patterns, fearless concurrency,\nand the modern Rust ecosystem including Tokio, Serde, and popular crates.\nUse when user mentions Rust, cargo, rustc, clippy, rustfmt, ownership, borrowing,\nlifetimes, async Rust, or Rust crates.\n",
                "path": "rust-plugin/skills/rust-development/SKILL.md",
                "frontmatter": {
                  "created": "2025-12-16T00:00:00.000Z",
                  "modified": "2025-12-16T00:00:00.000Z",
                  "reviewed": "2025-12-16T00:00:00.000Z",
                  "name": "rust-development",
                  "description": "Modern Rust development with cargo, rustc, clippy, rustfmt, async programming, and\nmemory-safe systems programming. Covers ownership patterns, fearless concurrency,\nand the modern Rust ecosystem including Tokio, Serde, and popular crates.\nUse when user mentions Rust, cargo, rustc, clippy, rustfmt, ownership, borrowing,\nlifetimes, async Rust, or Rust crates.\n",
                  "allowed-tools": "Glob, Grep, Read, Bash, Edit, Write, TodoWrite, WebFetch, WebSearch, BashOutput, KillShell"
                },
                "content": "# Rust Development\n\nExpert knowledge for modern systems programming with Rust, focusing on memory safety, fearless concurrency, and zero-cost abstractions.\n\n## Core Expertise\n\n**Modern Rust Ecosystem**\n- **Cargo**: Build system, package manager, and workspace management\n- **Rustc**: Compiler optimization, target management, and cross-compilation\n- **Clippy**: Linting for idiomatic code and performance improvements\n- **Rustfmt**: Consistent code formatting following Rust style guidelines\n- **Rust-analyzer**: Advanced IDE support with LSP integration\n\n**Language Features**\n- Rust 2024 edition: RPITIT, async fn in traits, impl Trait improvements\n- Const generics and compile-time computation\n- Generic associated types (GATs)\n- Let-else patterns and if-let chains\n\n## Key Capabilities\n\n**Ownership & Memory Safety**\n- Implement ownership patterns with borrowing and lifetimes\n- Design zero-copy abstractions and efficient memory layouts\n- Apply RAII patterns through Drop trait and smart pointers (Box, Rc, Arc)\n- Leverage interior mutability patterns (Cell, RefCell, Mutex, RwLock)\n- Use Pin/Unpin for self-referential structures\n\n**Async Programming & Concurrency**\n- **Tokio**: Async runtime for high-performance network applications\n- **async-std**: Alternative async runtime with familiar API design\n- **Futures**: Composable async abstractions and stream processing\n- **Rayon**: Data parallelism with work-stealing thread pools\n- Design lock-free data structures with atomics and memory ordering\n\n**Error Handling & Type Safety**\n- Design comprehensive error types with thiserror and anyhow\n- Implement Result<T, E> and Option<T> patterns effectively\n- Use pattern matching for exhaustive error handling\n- Apply type-state patterns for compile-time guarantees\n\n**Performance Optimization**\n- Profile with cargo-flamegraph, perf, and criterion benchmarks\n- Optimize with SIMD intrinsics and auto-vectorization\n- Implement zero-cost abstractions and inline optimizations\n- Use unsafe code judiciously with proper safety documentation\n\n**Testing & Quality Assurance**\n- **Unit Testing**: #[test] modules with assertions\n- **Integration Testing**: tests/ directory for end-to-end validation\n- **Criterion**: Micro-benchmarking with statistical analysis\n- **Miri**: Undefined behavior detection in unsafe code\n- **Fuzzing**: cargo-fuzz for security and robustness testing\n\n## Essential Commands\n\n```bash\n# Project setup\ncargo new my-project      # Binary crate\ncargo new my-lib --lib    # Library crate\ncargo init                # Initialize in existing directory\n\n# Development workflow\ncargo build                      # Debug build\ncargo build --release           # Optimized build\ncargo run                       # Build and run\ncargo run --release             # Run optimized\ncargo test                      # Run all tests\ncargo test --lib               # Library tests only\ncargo bench                     # Run benchmarks\n\n# Code quality\ncargo clippy                    # Lint code\ncargo clippy -- -W clippy::pedantic  # Stricter lints\ncargo fmt                       # Format code\ncargo fmt --check              # Check formatting\ncargo fix                       # Auto-fix warnings\n\n# Dependencies\ncargo add serde --features derive  # Add dependency\ncargo update                       # Update deps\ncargo audit                        # Security audit\ncargo deny check                   # License/advisory check\n\n# Advanced tools\ncargo expand                    # Macro expansion\ncargo flamegraph               # Profile with flame graph\ncargo doc --open               # Generate and open docs\ncargo miri test                # Check for UB\n\n# Cross-compilation\nrustup target add wasm32-unknown-unknown\ncargo build --target wasm32-unknown-unknown\n```\n\n## Best Practices\n\n**Idiomatic Rust Patterns**\n```rust\n// Use iterators over manual loops\nlet sum: i32 = numbers.iter().filter(|x| **x > 0).sum();\n\n// Prefer combinators for Option/Result\nlet value = config.get(\"key\")\n    .and_then(|v| v.parse().ok())\n    .unwrap_or_default();\n\n// Use pattern matching effectively\nmatch result {\n    Ok(value) if value > 0 => process(value),\n    Ok(_) => handle_zero(),\n    Err(e) => return Err(e.into()),\n}\n\n// Let-else for early returns\nlet Some(config) = load_config() else {\n    return Err(ConfigError::NotFound);\n};\n```\n\n**Project Structure**\n```\nmy-project/\n Cargo.toml\n src/\n    lib.rs        # Library root\n    main.rs       # Binary entry point\n    error.rs      # Error types\n    modules/\n        mod.rs\n tests/            # Integration tests\n benches/          # Benchmarks\n examples/         # Example programs\n```\n\n**Error Handling**\n```rust\nuse thiserror::Error;\n\n#[derive(Error, Debug)]\npub enum AppError {\n    #[error(\"IO error: {0}\")]\n    Io(#[from] std::io::Error),\n\n    #[error(\"parse error: {message}\")]\n    Parse { message: String },\n\n    #[error(\"not found: {0}\")]\n    NotFound(String),\n}\n\npub type Result<T> = std::result::Result<T, AppError>;\n```\n\n**Common Crates**\n| Crate | Purpose |\n|-------|---------|\n| `serde` | Serialization/deserialization |\n| `tokio` | Async runtime |\n| `reqwest` | HTTP client |\n| `sqlx` | Async SQL |\n| `clap` | CLI argument parsing |\n| `tracing` | Logging/diagnostics |\n| `anyhow` | Application errors |\n| `thiserror` | Library errors |\n\nFor detailed async patterns, unsafe code guidelines, WebAssembly compilation, embedded development, and advanced debugging, see REFERENCE.md."
              }
            ]
          },
          {
            "name": "kubernetes-plugin",
            "description": "Kubernetes and Helm operations - deployments, charts, releases",
            "source": "./kubernetes-plugin",
            "category": "infrastructure",
            "version": "1.0.0",
            "author": null,
            "install_commands": [
              "/plugin marketplace add laurigates/claude-plugins",
              "/plugin install kubernetes-plugin@lgates-claude-plugins"
            ],
            "signals": {
              "stars": 1,
              "forks": 0,
              "pushed_at": "2026-01-12T12:05:51Z",
              "created_at": "2025-12-16T11:24:04Z",
              "license": null
            },
            "commands": [],
            "skills": [
              {
                "name": "argocd-login",
                "description": "ArgoCD CLI authentication with SSO. Provides argocd login command, gRPC-Web\nconfiguration, and post-login operations. Use when user mentions ArgoCD login,\nargocd authentication, SSO auth, or accessing ArgoCD applications and clusters.\n",
                "path": "kubernetes-plugin/skills/argocd-login/SKILL.md",
                "frontmatter": {
                  "created": "2025-12-16T00:00:00.000Z",
                  "modified": "2025-12-16T00:00:00.000Z",
                  "reviewed": "2025-12-16T00:00:00.000Z",
                  "name": "argocd-login",
                  "description": "ArgoCD CLI authentication with SSO. Provides argocd login command, gRPC-Web\nconfiguration, and post-login operations. Use when user mentions ArgoCD login,\nargocd authentication, SSO auth, or accessing ArgoCD applications and clusters.\n"
                },
                "content": "# ArgoCD CLI Login\n\nArgoCD CLI authentication with SSO for the Data Portal cluster.\n\n## When to Use\n\nUse this skill automatically when:\n- User requests ArgoCD login or authentication\n- User mentions accessing ArgoCD cluster or applications\n- User needs to interact with ArgoCD CLI tools\n- Authentication errors occur when using ArgoCD commands\n\n## Authentication Command\n\n```bash\nargocd login argocd.dataportal.fi --grpc-web --sso\n```\n\n### Command Breakdown\n\n- `argocd.dataportal.fi` - Data Portal ArgoCD server endpoint\n- `--grpc-web` - Enable gRPC-Web protocol (required for web-based SSO)\n- `--sso` - Use Single Sign-On authentication (opens browser for OAuth2 flow)\n\n## Usage Flow\n\n1. **Detect authentication need:**\n   - User explicitly requests login\n   - ArgoCD command fails with authentication error\n   - User mentions accessing ArgoCD cluster\n\n2. **Execute login command:**\n   ```bash\n   argocd login argocd.dataportal.fi --grpc-web --sso\n   ```\n\n3. **Guide user through SSO:**\n   - Command will open browser automatically\n   - User completes SSO authentication in browser\n   - CLI receives token upon successful authentication\n   - Session is stored in `~/.config/argocd/config`\n\n4. **Verify authentication:**\n   ```bash\n   argocd account get-user-info\n   ```\n\n## Common ArgoCD Operations (Post-Login)\n\n### Application Management\n```bash\n# List applications\nargocd app list\n\n# Get application details\nargocd app get <app-name>\n\n# Sync application\nargocd app sync <app-name>\n\n# View application resources\nargocd app resources <app-name>\n```\n\n### Cluster Information\n```bash\n# List clusters\nargocd cluster list\n\n# Get cluster info\nargocd cluster get <cluster-name>\n```\n\n### Project Management\n```bash\n# List projects\nargocd proj list\n\n# Get project details\nargocd proj get <project-name>\n```\n\n## Authentication Session\n\n- **Session storage:** `~/.config/argocd/config`\n- **Session persistence:** Tokens have configurable expiration\n- **Re-authentication:** Run login command again when session expires\n\n## Troubleshooting\n\n### Browser doesn't open\n- Manually open the URL printed by the CLI\n- Complete authentication in browser\n- Token will be received by CLI\n\n### gRPC-Web errors\n- Ensure `--grpc-web` flag is present\n- Check network connectivity to `argocd.dataportal.fi`\n- Verify firewall/proxy settings allow gRPC-Web traffic\n\n### SSO failures\n- Verify SSO provider is accessible\n- Check browser for authentication prompts\n- Ensure popup blockers aren't interfering\n- Try incognito/private browsing mode\n\n### Token expiration\n- Re-run login command: `argocd login argocd.dataportal.fi --grpc-web --sso`\n- Check token validity: `argocd account get-user-info`\n\n## Integration with ArgoCD MCP\n\nThis skill complements the ArgoCD MCP server tools:\n- MCP tools (`mcp__argocd-mcp__*`) require authenticated CLI session\n- Use this skill to establish authentication before MCP operations\n- Both use same configuration (`~/.config/argocd/config`)\n\n## Security Considerations\n\n- **Token storage:** CLI tokens stored locally in config file\n- **Token scope:** Full ArgoCD access (read/write based on RBAC)\n- **Token rotation:** Re-authenticate periodically for security\n- **Shared sessions:** CLI and MCP share authentication state\n\n## Example Interaction\n\n```\nUser: \"I need to check the status of my ArgoCD applications\"\n\nClaude: I'll log you into ArgoCD first, then check the application status.\n\n[Executes: argocd login argocd.dataportal.fi --grpc-web --sso]\n\nPlease complete the SSO authentication in the browser that just opened.\nOnce authenticated, I'll retrieve your application list.\n\n[After successful auth, executes: argocd app list]\n\nHere are your applications:\n...\n```\n\n## Related Skills\n\n- **Kubernetes Operations** - For kubectl operations on ArgoCD-managed resources\n- **GitHub Actions Inspection** - For CI/CD pipeline integration with ArgoCD\n- **Infrastructure Terraform** - For infrastructure managed by ArgoCD applications\n\n## References\n\n- [ArgoCD CLI Documentation](https://argo-cd.readthedocs.io/en/stable/user-guide/commands/argocd/)\n- [ArgoCD SSO Configuration](https://argo-cd.readthedocs.io/en/stable/operator-manual/user-management/#sso)\n- [gRPC-Web Protocol](https://github.com/grpc/grpc-web)"
              },
              {
                "name": "helm-chart-development",
                "description": "Create, test, and package Helm charts for Kubernetes. Covers helm create, Chart.yaml,\nvalues.yaml, template development, chart dependencies, packaging, and repository publishing.\nUse when user mentions Helm charts, helm create, Chart.yaml, values.yaml, helm lint,\nhelm template, helm package, or Kubernetes packaging.\n",
                "path": "kubernetes-plugin/skills/helm-chart-development/SKILL.md",
                "frontmatter": {
                  "created": "2025-12-16T00:00:00.000Z",
                  "modified": "2025-12-16T00:00:00.000Z",
                  "reviewed": "2025-12-16T00:00:00.000Z",
                  "name": "helm-chart-development",
                  "description": "Create, test, and package Helm charts for Kubernetes. Covers helm create, Chart.yaml,\nvalues.yaml, template development, chart dependencies, packaging, and repository publishing.\nUse when user mentions Helm charts, helm create, Chart.yaml, values.yaml, helm lint,\nhelm template, helm package, or Kubernetes packaging.\n"
                },
                "content": "# Helm Chart Development\n\nComprehensive guidance for creating, testing, and packaging custom Helm charts with best practices for maintainability and reusability.\n\n## When to Use\n\nUse this skill automatically when:\n- User wants to create a new Helm chart\n- User needs to validate chart structure or templates\n- User mentions testing charts locally\n- User wants to package or publish charts\n- User needs to manage chart dependencies\n- User asks about chart best practices\n\n## Chart Creation & Structure\n\n### Create New Chart\n\n```bash\n# Scaffold new chart with standard structure\nhelm create mychart\n\n# Creates:\n# mychart/\n#  Chart.yaml          # Chart metadata\n#  values.yaml         # Default values\n#  charts/             # Chart dependencies\n#  templates/          # Kubernetes manifests\n#     NOTES.txt       # Post-install instructions\n#     _helpers.tpl    # Template helpers\n#     deployment.yaml\n#     service.yaml\n#     ingress.yaml\n#     tests/\n#         test-connection.yaml\n#  .helmignore         # Files to ignore\n```\n\n### Chart.yaml Structure\n\n```yaml\n# Chart.yaml - Chart metadata\napiVersion: v2                  # Helm 3 uses v2\nname: mychart                   # Chart name\nversion: 0.1.0                  # Chart version (SemVer)\nappVersion: \"1.0.0\"            # Application version\ndescription: A Helm chart for Kubernetes\ntype: application               # application or library\nkeywords:\n  - api\n  - web\nhome: https://example.com\nsources:\n  - https://github.com/example/mychart\nmaintainers:\n  - name: John Doe\n    email: john@example.com\ndependencies:                   # Chart dependencies\n  - name: postgresql\n    version: \"12.1.9\"\n    repository: https://charts.bitnami.com/bitnami\n    condition: postgresql.enabled  # Optional: enable/disable\n    tags:                          # Optional: group dependencies\n      - database\n```\n\n### Values.yaml Design\n\n```yaml\n# values.yaml - Default configuration\n# Use clear hierarchy and comments\n\n# Replica configuration\nreplicaCount: 1\n\n# Image configuration\nimage:\n  repository: nginx\n  pullPolicy: IfNotPresent\n  tag: \"\"  # Overrides appVersion\n\nimagePullSecrets: []\nnameOverride: \"\"\nfullnameOverride: \"\"\n\n# Service configuration\nservice:\n  type: ClusterIP\n  port: 80\n\n# Ingress configuration\ningress:\n  enabled: false\n  className: \"\"\n  annotations: {}\n  hosts:\n    - host: chart-example.local\n      paths:\n        - path: /\n          pathType: ImplementationSpecific\n  tls: []\n\n# Resource limits\nresources:\n  limits:\n    cpu: 100m\n    memory: 128Mi\n  requests:\n    cpu: 100m\n    memory: 128Mi\n\n# Autoscaling\nautoscaling:\n  enabled: false\n  minReplicas: 1\n  maxReplicas: 100\n  targetCPUUtilizationPercentage: 80\n\n# Node selection\nnodeSelector: {}\ntolerations: []\naffinity: {}\n```\n\n## Chart Validation & Testing\n\n### Lint Chart\n\n```bash\n# Basic linting\nhelm lint ./mychart\n\n# Strict linting (warnings as errors)\nhelm lint ./mychart --strict\n\n# Lint with specific values\nhelm lint ./mychart \\\n  --values values.yaml \\\n  --strict\n\n# Lint with multiple value files\nhelm lint ./mychart \\\n  --values values/common.yaml \\\n  --values values/production.yaml \\\n  --strict\n```\n\n**What Lint Checks:**\n- Chart.yaml validity\n- values.yaml syntax\n- Template syntax errors\n- Required fields present\n- Version format (SemVer)\n- Deprecated API versions\n\n### Render Templates Locally\n\n```bash\n# Render all templates\nhelm template mychart ./mychart\n\n# Render with custom release name and namespace\nhelm template myrelease ./mychart \\\n  --namespace production\n\n# Render with values\nhelm template myrelease ./mychart \\\n  --values values.yaml\n\n# Render specific template\nhelm template myrelease ./mychart \\\n  --show-only templates/deployment.yaml\n\n# Render with debug output\nhelm template myrelease ./mychart \\\n  --debug\n\n# Validate against Kubernetes API\nhelm template myrelease ./mychart \\\n  --validate\n```\n\n### Dry-Run Installation\n\n```bash\n# Dry-run with server-side validation\nhelm install myrelease ./mychart \\\n  --namespace production \\\n  --dry-run \\\n  --debug\n\n# Validates:\n# - Template rendering\n# - Kubernetes API compatibility\n# - Resource conflicts\n# - RBAC permissions\n```\n\n### Run Chart Tests\n\n```bash\n# Install chart\nhelm install myrelease ./mychart --namespace test\n\n# Run tests\nhelm test myrelease --namespace test\n\n# Run tests with logs\nhelm test myrelease --namespace test --logs\n\n# Cleanup after tests\nhelm uninstall myrelease --namespace test\n```\n\n**Chart Test Structure:**\n\n```yaml\n# templates/tests/test-connection.yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: \"{{ include \"mychart.fullname\" . }}-test-connection\"\n  annotations:\n    \"helm.sh/hook\": test\n    \"helm.sh/hook-delete-policy\": hook-succeeded,hook-failed\nspec:\n  containers:\n  - name: wget\n    image: busybox\n    command: ['wget']\n    args: ['{{ include \"mychart.fullname\" . }}:{{ .Values.service.port }}']\n  restartPolicy: Never\n```\n\n## Template Development\n\n### Template Helpers (_helpers.tpl)\n\n```yaml\n{{/*\nExpand the name of the chart.\n*/}}\n{{- define \"mychart.name\" -}}\n{{- default .Chart.Name .Values.nameOverride | trunc 63 | trimSuffix \"-\" }}\n{{- end }}\n\n{{/*\nCreate a fully qualified app name.\n*/}}\n{{- define \"mychart.fullname\" -}}\n{{- if .Values.fullnameOverride }}\n{{- .Values.fullnameOverride | trunc 63 | trimSuffix \"-\" }}\n{{- else }}\n{{- $name := default .Chart.Name .Values.nameOverride }}\n{{- if contains $name .Release.Name }}\n{{- .Release.Name | trunc 63 | trimSuffix \"-\" }}\n{{- else }}\n{{- printf \"%s-%s\" .Release.Name $name | trunc 63 | trimSuffix \"-\" }}\n{{- end }}\n{{- end }}\n{{- end }}\n\n{{/*\nCommon labels\n*/}}\n{{- define \"mychart.labels\" -}}\nhelm.sh/chart: {{ include \"mychart.chart\" . }}\n{{ include \"mychart.selectorLabels\" . }}\n{{- if .Chart.AppVersion }}\napp.kubernetes.io/version: {{ .Chart.AppVersion | quote }}\n{{- end }}\napp.kubernetes.io/managed-by: {{ .Release.Service }}\n{{- end }}\n\n{{/*\nSelector labels\n*/}}\n{{- define \"mychart.selectorLabels\" -}}\napp.kubernetes.io/name: {{ include \"mychart.name\" . }}\napp.kubernetes.io/instance: {{ .Release.Name }}\n{{- end }}\n```\n\n### Template Best Practices\n\n**Use Named Templates:**\n```yaml\n#  GOOD: Reusable labels\nlabels:\n{{- include \"mychart.labels\" . | nindent 2 }}\n\n#  BAD: Duplicate label definitions\nlabels:\n  app.kubernetes.io/name: mychart\n  app.kubernetes.io/instance: {{ .Release.Name }}\n```\n\n**Quote String Values:**\n```yaml\n#  GOOD: Quoted to prevent YAML issues\nenv:\n- name: APP_NAME\n  value: {{ .Values.appName | quote }}\n\n#  BAD: Unquoted strings can break\nenv:\n- name: APP_NAME\n  value: {{ .Values.appName }}  # Breaks if value is \"true\" or \"123\"\n```\n\n**Use Required for Mandatory Values:**\n```yaml\n#  GOOD: Fails fast with clear error\ndatabase:\n  host: {{ required \"database.host is required\" .Values.database.host }}\n\n#  BAD: Silent failure or confusing errors\ndatabase:\n  host: {{ .Values.database.host }}\n```\n\n**Handle Whitespace Properly:**\n```yaml\n#  GOOD: Proper indentation and chomping\nlabels:\n{{- include \"mychart.labels\" . | nindent 2 }}\n\n#  BAD: Extra newlines or indentation issues\nlabels:\n{{ include \"mychart.labels\" . }}\n```\n\n**Conditional Resources:**\n```yaml\n#  GOOD: Clean conditional\n{{- if .Values.ingress.enabled -}}\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: {{ include \"mychart.fullname\" . }}\nspec:\n  ...\n{{- end }}\n\n#  BAD: Always creates resource\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: {{ include \"mychart.fullname\" . }}\nspec:\n  {{- if .Values.ingress.enabled }}\n  ...\n  {{- end }}\n```\n\n## Chart Dependencies\n\n### Define Dependencies (Chart.yaml)\n\n```yaml\n# Chart.yaml\ndependencies:\n- name: postgresql\n  version: \"12.1.9\"\n  repository: https://charts.bitnami.com/bitnami\n  condition: postgresql.enabled       # Enable/disable via values\n\n- name: redis\n  version: \"17.0.0\"\n  repository: https://charts.bitnami.com/bitnami\n  condition: redis.enabled\n\n- name: common                         # Local dependency\n  version: \"1.0.0\"\n  repository: file://../common-library\n```\n\n### Manage Dependencies\n\n```bash\n# Download/update dependencies\nhelm dependency update ./mychart\n\n# Creates:\n# - Chart.lock          # Locked versions\n# - charts/*.tgz        # Downloaded charts\n\n# Build from existing Chart.lock\nhelm dependency build ./mychart\n\n# List dependencies\nhelm dependency list ./mychart\n```\n\n### Configure Subchart Values\n\n```yaml\n# values.yaml - Parent chart\n# Configure subcharts using subchart name as key\n\n# PostgreSQL subchart configuration\npostgresql:\n  enabled: true\n  auth:\n    username: myapp\n    database: myapp\n    existingSecret: myapp-db-secret\n  primary:\n    persistence:\n      size: 10Gi\n\n# Redis subchart configuration\nredis:\n  enabled: true\n  auth:\n    enabled: false\n  master:\n    persistence:\n      size: 5Gi\n```\n\n### Override Subchart Values\n\n```bash\n# Override subchart values from CLI\nhelm install myapp ./mychart \\\n  --set postgresql.auth.password=secret123 \\\n  --set redis.enabled=false\n```\n\n## Chart Packaging & Distribution\n\n### Package Chart\n\n```bash\n# Package chart into .tgz\nhelm package ./mychart\n\n# Creates: mychart-0.1.0.tgz\n\n# Package with specific destination\nhelm package ./mychart --destination ./dist/\n\n# Package and update dependencies\nhelm package ./mychart --dependency-update\n\n# Sign package (requires GPG key)\nhelm package ./mychart --sign --key mykey --keyring ~/.gnupg/secring.gpg\n```\n\n### Chart Repository\n\n```bash\n# Create repository index\nhelm repo index ./repo/\n\n# Creates: index.yaml\n\n# Add local repository\nhelm repo add myrepo file://$(pwd)/repo\n\n# Update repository index\nhelm repo update\n\n# Search local repository\nhelm search repo myrepo/\n\n# Push to ChartMuseum (if using)\ncurl --data-binary \"@mychart-0.1.0.tgz\" http://chartmuseum.example.com/api/charts\n\n# Push to OCI registry (Helm 3.8+)\nhelm push mychart-0.1.0.tgz oci://registry.example.com/charts\n```\n\n## Schema Validation\n\n### Create Values Schema (values.schema.json)\n\n```json\n{\n  \"$schema\": \"https://json-schema.org/draft-07/schema#\",\n  \"title\": \"MyChart Values\",\n  \"type\": \"object\",\n  \"required\": [\"image\", \"service\"],\n  \"properties\": {\n    \"replicaCount\": {\n      \"type\": \"integer\",\n      \"minimum\": 1,\n      \"maximum\": 100,\n      \"description\": \"Number of replicas\"\n    },\n    \"image\": {\n      \"type\": \"object\",\n      \"required\": [\"repository\", \"tag\"],\n      \"properties\": {\n        \"repository\": {\n          \"type\": \"string\",\n          \"description\": \"Image repository\"\n        },\n        \"tag\": {\n          \"type\": \"string\",\n          \"pattern\": \"^v?[0-9]+\\\\.[0-9]+\\\\.[0-9]+$\",\n          \"description\": \"Image tag (SemVer)\"\n        },\n        \"pullPolicy\": {\n          \"type\": \"string\",\n          \"enum\": [\"Always\", \"IfNotPresent\", \"Never\"],\n          \"description\": \"Image pull policy\"\n        }\n      }\n    },\n    \"service\": {\n      \"type\": \"object\",\n      \"required\": [\"port\"],\n      \"properties\": {\n        \"type\": {\n          \"type\": \"string\",\n          \"enum\": [\"ClusterIP\", \"NodePort\", \"LoadBalancer\"],\n          \"description\": \"Service type\"\n        },\n        \"port\": {\n          \"type\": \"integer\",\n          \"minimum\": 1,\n          \"maximum\": 65535,\n          \"description\": \"Service port\"\n        }\n      }\n    },\n    \"ingress\": {\n      \"type\": \"object\",\n      \"properties\": {\n        \"enabled\": {\n          \"type\": \"boolean\",\n          \"description\": \"Enable ingress\"\n        },\n        \"hosts\": {\n          \"type\": \"array\",\n          \"items\": {\n            \"type\": \"object\",\n            \"required\": [\"host\"],\n            \"properties\": {\n              \"host\": {\n                \"type\": \"string\",\n                \"format\": \"hostname\"\n              }\n            }\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n### Schema Validation\n\nSchema validation runs automatically during:\n- `helm install`\n- `helm upgrade`\n- `helm template --validate`\n- `helm lint`\n\n```bash\n# Validation errors will show:\nError: values don't meet the specifications of the schema(s)\n- replicaCount: Invalid type. Expected: integer, given: string\n```\n\n## Chart Documentation\n\n### NOTES.txt Template\n\n```yaml\n# templates/NOTES.txt - Post-install instructions\nThank you for installing {{ .Chart.Name }}!\n\nYour release is named {{ .Release.Name }}.\n\nTo learn more about the release, try:\n\n  $ helm status {{ .Release.Name }} --namespace {{ .Release.Namespace }}\n  $ helm get all {{ .Release.Name }} --namespace {{ .Release.Namespace }}\n\n{{- if .Values.ingress.enabled }}\nApplication is available at:\n{{- range .Values.ingress.hosts }}\n  http{{ if $.Values.ingress.tls }}s{{ end }}://{{ .host }}\n{{- end }}\n{{- else }}\nGet the application URL by running:\n  export POD_NAME=$(kubectl get pods --namespace {{ .Release.Namespace }} -l \"app.kubernetes.io/name={{ include \"mychart.name\" . }},app.kubernetes.io/instance={{ .Release.Name }}\" -o jsonpath=\"{.items[0].metadata.name}\")\n  kubectl --namespace {{ .Release.Namespace }} port-forward $POD_NAME 8080:{{ .Values.service.port }}\n  echo \"Visit http://127.0.0.1:8080\"\n{{- end }}\n```\n\n### README.md\n\n```markdown\n# MyChart\n\nA Helm chart for deploying MyApp to Kubernetes.\n\n## Prerequisites\n\n- Kubernetes 1.19+\n- Helm 3.0+\n\n## Installation\n\n```bash\nhelm install myapp oci://registry.example.com/charts/mychart\n```\n\n## Configuration\n\nSee `values.yaml` in your chart directory for configuration options.\n\nKey parameters:\n- `replicaCount` - Number of replicas (default: 1)\n- `image.repository` - Image repository\n- `image.tag` - Image tag\n\n## Upgrading\n\n```bash\nhelm upgrade myapp oci://registry.example.com/charts/mychart\n```\n\n## Uninstallation\n\n```bash\nhelm uninstall myapp\n```\n```\n\n## Chart Testing Workflow\n\n### Local Development Testing\n\n```bash\n# 1. Create chart\nhelm create testchart\n\n# 2. Modify templates and values\n# Edit templates/deployment.yaml, values.yaml\n\n# 3. Lint\nhelm lint ./testchart --strict\n\n# 4. Render templates\nhelm template testapp ./testchart \\\n  --values test-values.yaml \\\n  --debug\n\n# 5. Dry-run\nhelm install testapp ./testchart \\\n  --namespace test \\\n  --create-namespace \\\n  --dry-run \\\n  --debug\n\n# 6. Install to test cluster\nhelm install testapp ./testchart \\\n  --namespace test \\\n  --create-namespace \\\n  --atomic \\\n  --wait\n\n# 7. Run tests\nhelm test testapp --namespace test --logs\n\n# 8. Verify deployment\nkubectl get all -n test -l app.kubernetes.io/instance=testapp\n\n# 9. Cleanup\nhelm uninstall testapp --namespace test\nkubectl delete namespace test\n```\n\n### CI/CD Testing\n\n```yaml\n# GitHub Actions example\nname: Chart Testing\n\non: [pull_request]\n\njobs:\n  lint-test:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n\n      - name: Set up Helm\n        uses: azure/setup-helm@v3\n        with:\n          version: '3.12.0'\n\n      - name: Lint Chart\n        run: helm lint ./charts/mychart --strict\n\n      - name: Template Chart\n        run: |\n          helm template test ./charts/mychart \\\n            --values ./charts/mychart/ci/test-values.yaml \\\n            --validate\n\n      - name: Install Chart Testing\n        uses: helm/chart-testing-action@v2\n\n      - name: Run Chart Tests\n        run: ct lint-and-install --charts ./charts/mychart\n```\n\n## Common Chart Patterns\n\n### ConfigMap from Values\n\n```yaml\n# templates/configmap.yaml\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: {{ include \"mychart.fullname\" . }}\ndata:\n  {{- range $key, $value := .Values.config }}\n  {{ $key }}: {{ $value | quote }}\n  {{- end }}\n```\n\n```yaml\n# values.yaml\nconfig:\n  app.name: \"MyApp\"\n  log.level: \"info\"\n  feature.enabled: \"true\"\n```\n\n### Secret from Existing Secret\n\n```yaml\n# templates/deployment.yaml\nenv:\n- name: DATABASE_PASSWORD\n  valueFrom:\n    secretKeyRef:\n      name: {{ .Values.existingSecret | default (include \"mychart.fullname\" .) }}\n      key: db-password\n```\n\n### Multiple Services\n\n```yaml\n# values.yaml\nservices:\n  api:\n    port: 8080\n    type: ClusterIP\n  metrics:\n    port: 9090\n    type: ClusterIP\n\n# templates/services.yaml\n{{- range $name, $config := .Values.services }}\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: {{ include \"mychart.fullname\" $ }}-{{ $name }}\nspec:\n  type: {{ $config.type }}\n  ports:\n  - port: {{ $config.port }}\n    targetPort: {{ $config.port }}\n  selector:\n    {{- include \"mychart.selectorLabels\" $ | nindent 4 }}\n{{- end }}\n```\n\n## Chart Best Practices\n\n### Versioning\n **DO**: Use SemVer for chart and app versions\n```yaml\n# Chart.yaml\nversion: 1.2.3        # Chart version\nappVersion: \"2.5.0\"   # Application version\n```\n\n### Naming\n **DO**: Use consistent naming functions\n```yaml\nname: {{ include \"mychart.fullname\" . }}\nlabels:\n{{- include \"mychart.labels\" . | nindent 2 }}\n```\n\n### Defaults\n **DO**: Provide sensible defaults in values.yaml\n```yaml\nreplicaCount: 1  # Safe default for testing\nresources:\n  limits:\n    cpu: 100m\n    memory: 128Mi  # Reasonable defaults\n```\n\n### Documentation\n **DO**: Comment values.yaml extensively\n```yaml\n# Number of replicas to deploy\n# Recommended: 3+ for production\nreplicaCount: 1\n```\n\n### Testing\n **DO**: Include chart tests\n```bash\n# Always include templates/tests/\nhelm test <release>\n```\n\n## Related Skills\n\n- **Helm Release Management** - Using charts to deploy\n- **Helm Debugging** - Troubleshooting chart issues\n- **Helm Values Management** - Configuring charts\n\n## References\n\n- [Helm Chart Development Guide](https://helm.sh/docs/topics/charts/)\n- [Helm Best Practices](https://helm.sh/docs/chart_best_practices/)\n- [Helm Template Guide](https://helm.sh/docs/chart_template_guide/)\n- [Chart Testing](https://github.com/helm/chart-testing)"
              },
              {
                "name": "helm-debugging",
                "description": "Debug and troubleshoot Helm deployment failures, template errors, and configuration\nissues. Covers helm template, helm lint, dry-run, debugging YAML parse errors,\nvalue type errors, and resource conflicts. Use when user mentions Helm errors,\ndebugging Helm, template rendering issues, or troubleshooting Helm deployments.\n",
                "path": "kubernetes-plugin/skills/helm-debugging/SKILL.md",
                "frontmatter": {
                  "created": "2025-12-16T00:00:00.000Z",
                  "modified": "2025-12-16T00:00:00.000Z",
                  "reviewed": "2025-12-16T00:00:00.000Z",
                  "name": "helm-debugging",
                  "description": "Debug and troubleshoot Helm deployment failures, template errors, and configuration\nissues. Covers helm template, helm lint, dry-run, debugging YAML parse errors,\nvalue type errors, and resource conflicts. Use when user mentions Helm errors,\ndebugging Helm, template rendering issues, or troubleshooting Helm deployments.\n"
                },
                "content": "# Helm Debugging & Troubleshooting\n\nComprehensive guidance for diagnosing and fixing Helm deployment failures, template errors, and configuration issues.\n\n## When to Use\n\nUse this skill automatically when:\n- User reports Helm deployment failures or errors\n- User mentions debugging, troubleshooting, or fixing Helm issues\n- Template rendering problems occur\n- Value validation or type errors\n- Resource conflicts or API errors\n- Image pull failures or pod crashes\n- User needs to inspect deployed resources\n\n## Context Safety (CRITICAL)\n\n**Always specify `--context`** explicitly in all kubectl and helm commands. Never rely on the current context.\n\n```bash\n# CORRECT: Explicit context\nkubectl --context=prod-cluster get pods -n prod\nhelm --kube-context=prod-cluster status myapp -n prod\n\n# WRONG: Relying on current context\nkubectl get pods -n prod  # Which cluster?\n```\n\nThis prevents accidental operations on the wrong cluster.\n\n---\n\n## Layered Validation Approach\n\n**ALWAYS follow this progression** for robust deployments:\n\n```bash\n# 1. LINT - Static analysis (local charts only)\nhelm lint ./mychart --strict\n\n# 2. TEMPLATE - Render templates locally\nhelm template myapp ./mychart \\\n  --debug \\\n  --values values.yaml\n\n# 3. DRY-RUN - Server-side validation\nhelm install myapp ./mychart \\\n  --namespace prod \\\n  --values values.yaml \\\n  --dry-run --debug\n\n# 4. INSTALL - Actual deployment\nhelm install myapp ./mychart \\\n  --namespace prod \\\n  --values values.yaml \\\n  --atomic --wait\n\n# 5. TEST - Post-deployment validation (if chart has tests)\nhelm test myapp --namespace prod --logs\n```\n\n## Core Debugging Commands\n\n### Template Rendering & Inspection\n\n```bash\n# Render all templates locally\nhelm template myapp ./mychart \\\n  --debug \\\n  --values values.yaml\n\n# Render specific template file\nhelm template myapp ./mychart \\\n  --show-only templates/deployment.yaml \\\n  --values values.yaml\n\n# Render with debug output (shows computed values)\nhelm template myapp ./mychart \\\n  --debug \\\n  --values values.yaml \\\n  2>&1 | less\n\n# Validate against Kubernetes API (dry-run)\nhelm install myapp ./mychart \\\n  --namespace prod \\\n  --values values.yaml \\\n  --dry-run \\\n  --debug\n```\n\n### Inspect Deployed Resources\n\n```bash\n# Get deployed manifest (actual YAML in cluster)\nhelm get manifest myapp --namespace prod\n\n# Get deployed values (what was actually used)\nhelm get values myapp --namespace prod\n\n# Get ALL values (including defaults)\nhelm get values myapp --namespace prod --all\n\n# Get release status with resources\nhelm status myapp --namespace prod --show-resources\n\n# Get release metadata\nhelm get metadata myapp --namespace prod\n\n# Get release hooks\nhelm get hooks myapp --namespace prod\n\n# Get everything about a release\nhelm get all myapp --namespace prod\n```\n\n### Chart Validation\n\n```bash\n# Lint chart structure and templates\nhelm lint ./mychart\n\n# Lint with strict mode (treats warnings as errors)\nhelm lint ./mychart --strict\n\n# Lint with specific values\nhelm lint ./mychart --values values.yaml --strict\n\n# Validate chart against Kubernetes API\nhelm install myapp ./mychart \\\n  --dry-run \\\n  --validate \\\n  --namespace prod\n```\n\n### Verbose Debugging\n\n```bash\n# Enable Helm debug logging\nhelm install myapp ./mychart \\\n  --namespace prod \\\n  --debug \\\n  --dry-run\n\n# Enable Kubernetes client logging\nhelm install myapp ./mychart \\\n  --namespace prod \\\n  --v=6  # Verbosity level 0-9\n\n# Combine debug and verbose\nhelm upgrade myapp ./mychart \\\n  --namespace prod \\\n  --debug \\\n  --v=6 \\\n  --wait\n```\n\n## Common Failure Scenarios\n\n### 1. YAML Parse Errors\n\n**Symptom:**\n```\nError: YAML parse error on <file>: error converting YAML to JSON\n```\n\n**Causes:**\n- Template whitespace issues (extra spaces, tabs mixed with spaces)\n- Incorrect indentation\n- Malformed YAML syntax\n- Template rendering issues\n\n**Debugging Steps:**\n\n```bash\n# 1. Render template locally to see output\nhelm template myapp ./mychart --debug 2>&1 | grep -A 10 \"error\"\n\n# 2. Render specific problematic template\nhelm template myapp ./mychart \\\n  --show-only templates/deployment.yaml \\\n  --debug\n\n# 3. Check for whitespace issues\nhelm template myapp ./mychart | cat -A  # Shows tabs/spaces\n\n# 4. Validate YAML syntax\nhelm template myapp ./mychart | yq eval '.' -\n```\n\n**Common Fixes:**\n\n```yaml\n#  WRONG: Inconsistent whitespace\nspec:\n  containers:\n  - name: {{ .Values.name }}\n      image: {{ .Values.image }}  # Too much indent\n\n#  CORRECT: Consistent 2-space indent\nspec:\n  containers:\n  - name: {{ .Values.name }}\n    image: {{ .Values.image }}\n\n#  WRONG: Missing whitespace chomping\nlabels:\n{{ toYaml .Values.labels }}  # Adds extra newlines\n\n#  CORRECT: Chomp whitespace\nlabels:\n{{- toYaml .Values.labels | nindent 2 }}\n\n#  WRONG: Conditional creates empty lines\n{{- if .Values.enabled }}\nenabled: true\n{{- end }}\n\n#  CORRECT: Chomp trailing whitespace\n{{- if .Values.enabled }}\nenabled: true\n{{- end -}}\n```\n\n### 2. Template Rendering Errors\n\n**Symptom:**\n```\nError: template: mychart/templates/deployment.yaml:15:8: executing \"mychart/templates/deployment.yaml\" at <.Values.foo>: nil pointer evaluating interface {}.foo\n```\n\n**Causes:**\n- Accessing undefined values\n- Incorrect value path\n- Missing required values\n- Type mismatches\n\n**Debugging Steps:**\n\n```bash\n# 1. Check what values are available\nhelm show values ./mychart\n\n# 2. Verify values being passed\nhelm template myapp ./mychart \\\n  --debug \\\n  --values values.yaml \\\n  2>&1 | grep \"COMPUTED VALUES\"\n\n# 3. Test with minimal values\nhelm template myapp ./mychart \\\n  --set foo=test \\\n  --debug\n```\n\n**Common Fixes:**\n\n```yaml\n#  WRONG: No default or check\nimage: {{ .Values.image.tag }}  # Fails if .Values.image is nil\n\n#  CORRECT: Use default\nimage: {{ .Values.image.tag | default \"latest\" }}\n\n#  CORRECT: Check before accessing\n{{- if .Values.image }}\nimage: {{ .Values.image.tag | default \"latest\" }}\n{{- end }}\n\n#  CORRECT: Use required for mandatory values\nimage: {{ required \"image.repository is required\" .Values.image.repository }}\n\n#  WRONG: Assuming type\nreplicas: {{ .Values.replicaCount }}  # May be string \"3\"\n\n#  CORRECT: Ensure int type\nreplicas: {{ .Values.replicaCount | int }}\n```\n\n### 3. Value Type Errors\n\n**Symptom:**\n```\nError: json: cannot unmarshal string into Go value of type int\n```\n\n**Causes:**\n- String passed where number expected\n- Boolean as string\n- Incorrect YAML parsing\n\n**Debugging Steps:**\n\n```bash\n# 1. Check value types in rendered output\nhelm template myapp ./mychart --debug | grep -A 5 \"replicaCount\"\n\n# 2. Verify values file syntax\nyq eval '.replicaCount' values.yaml\n\n# 3. Test with explicit type conversion\nhelm template myapp ./mychart --set-string name=\"value\"\n```\n\n**Common Fixes:**\n\n```yaml\n#  WRONG: String in values.yaml\nreplicaCount: \"3\"  # String\n\n#  CORRECT: Number in values.yaml\nreplicaCount: 3  # Int\n\n# Template: Always convert to correct type\nreplicas: {{ .Values.replicaCount | int }}\nport: {{ .Values.service.port | int }}\nenabled: {{ .Values.feature.enabled | ternary \"true\" \"false\" }}\n\n# Use --set-string for forcing strings\nhelm install myapp ./chart --set-string version=\"1.0\"\n```\n\n### 4. Resource Already Exists\n\n**Symptom:**\n```\nError: rendered manifests contain a resource that already exists\n```\n\n**Causes:**\n- Resource from previous failed install\n- Resource managed by another release\n- Manual resource creation conflict\n\n**Debugging Steps:**\n\n```bash\n# 1. Check if resource exists\nkubectl get <resource-type> <name> -n <namespace>\n\n# 2. Check resource ownership\nkubectl get <resource-type> <name> -n <namespace> -o yaml | grep -A 5 \"labels:\"\n\n# 3. Check which Helm release owns it\nhelm list --all-namespaces | grep <resource-name>\n\n# 4. Check for stuck releases\nhelm list --all-namespaces --failed\nhelm list --all-namespaces --pending\n```\n\n**Solutions:**\n\n```bash\n# Option 1: Uninstall conflicting release\nhelm uninstall <release> --namespace <namespace>\n\n# Option 2: Delete specific resource manually\nkubectl delete <resource-type> <name> -n <namespace>\n\n# Option 3: Use different release name\nhelm install myapp-v2 ./chart --namespace prod\n\n# Option 4: Adopt existing resources (advanced)\nkubectl annotate <resource-type> <name> \\\n  meta.helm.sh/release-name=<release> \\\n  meta.helm.sh/release-namespace=<namespace> \\\n  -n <namespace>\nkubectl label <resource-type> <name> \\\n  app.kubernetes.io/managed-by=Helm \\\n  -n <namespace>\n```\n\n### 5. Image Pull Failures\n\n**Symptom:**\n```\nPod status: ImagePullBackOff or ErrImagePull\n```\n\n**Causes:**\n- Wrong image name/tag\n- Missing registry credentials\n- Private registry authentication\n- Network/registry issues\n\n**Debugging Steps:**\n\n```bash\n# 1. Check pod events\nkubectl describe pod <pod-name> -n <namespace>\n\n# 2. Verify image in manifest\nhelm get manifest myapp -n prod | grep \"image:\"\n\n# 3. Check image pull secrets\nkubectl get secrets -n <namespace>\nkubectl get sa default -n <namespace> -o yaml | grep imagePullSecrets\n\n# 4. Test image pull manually\ndocker pull <image:tag>\n```\n\n**Solutions:**\n\n```bash\n# Option 1: Fix image name/tag in values\nhelm upgrade myapp ./chart \\\n  --namespace prod \\\n  --set image.repository=myregistry.io/myapp \\\n  --set image.tag=v1.0.0\n\n# Option 2: Create image pull secret\nkubectl create secret docker-registry regcred \\\n  --docker-server=<registry> \\\n  --docker-username=<user> \\\n  --docker-password=<pass> \\\n  --namespace <namespace>\n\n# Reference in values.yaml:\nimagePullSecrets:\n  - name: regcred\n\n# Option 3: Update service account\nkubectl patch serviceaccount default -n <namespace> \\\n  -p '{\"imagePullSecrets\": [{\"name\": \"regcred\"}]}'\n```\n\n### 6. CRD Issues\n\n**Symptom:**\n```\nError: unable to recognize \"\": no matches for kind \"MyCustomResource\" in version \"mygroup/v1\"\n```\n\n**Causes:**\n- CRD not installed\n- CRD installed in wrong order\n- CRD version mismatch\n- API version not supported in cluster\n\n**Debugging Steps:**\n\n```bash\n# 1. Check if CRD exists\nkubectl get crds | grep myresource\n\n# 2. Check CRD version\nkubectl get crd myresource.mygroup.io -o yaml | grep \"version:\"\n\n# 3. Check API versions supported\nkubectl api-resources | grep mygroup\n\n# 4. Verify template uses correct API version\nhelm template myapp ./chart | grep \"apiVersion:\"\n```\n\n**Solutions:**\n\n```bash\n# Option 1: Install CRDs first (if separate chart)\nhelm install myapp-crds ./crds --namespace prod\nhelm install myapp ./chart --namespace prod\n\n# Option 2: Use --skip-crds if reinstalling\nhelm upgrade myapp ./chart \\\n  --namespace prod \\\n  --skip-crds\n\n# Option 3: Manually install CRDs\nkubectl apply -f crds/\n\n# Option 4: Update chart to use correct API version\n# Edit templates to use supported apiVersion\n```\n\n### 7. Timeout Errors\n\n**Symptom:**\n```\nError: timed out waiting for the condition\n```\n\n**Causes:**\n- Pods not becoming ready (failing health checks)\n- Resource limits too low\n- Image pull taking too long\n- Init containers failing\n\n**Debugging Steps:**\n\n```bash\n# 1. Check pod status\nkubectl get pods -n <namespace> -l app.kubernetes.io/instance=myapp\n\n# 2. Check pod events and logs\nkubectl describe pod <pod-name> -n <namespace>\nkubectl logs <pod-name> -n <namespace>\n\n# 3. Check init containers\nkubectl logs <pod-name> -n <namespace> -c <init-container-name>\n\n# 4. Increase timeout and watch\nhelm upgrade myapp ./chart \\\n  --namespace prod \\\n  --wait \\\n  --timeout 15m \\\n  --debug &\nwatch kubectl get pods -n prod\n```\n\n**Solutions:**\n\n```bash\n# Option 1: Increase timeout\nhelm upgrade myapp ./chart \\\n  --namespace prod \\\n  --timeout 10m \\\n  --wait\n\n# Option 2: Don't wait (manual verification)\nhelm upgrade myapp ./chart \\\n  --namespace prod\n# Then manually check: kubectl get pods -n prod\n\n# Option 3: Fix readiness probe\n# Adjust in values.yaml or chart templates:\nreadinessProbe:\n  initialDelaySeconds: 30  # Give more time to start\n  periodSeconds: 10\n  timeoutSeconds: 5\n  failureThreshold: 6  # Allow more failures\n\n# Option 4: Increase resource limits\nresources:\n  limits:\n    memory: \"512Mi\"  # Was too low at 128Mi\n    cpu: \"1000m\"\n```\n\n### 8. Hook Failures\n\n**Symptom:**\n```\nError: pre-upgrade hooks failed: job failed\n```\n\n**Causes:**\n- Hook job failing\n- Hook timing issues\n- Hook dependencies not met\n- Hook timeout\n\n**Debugging Steps:**\n\n```bash\n# 1. Check hook jobs/pods\nkubectl get jobs -n <namespace>\nkubectl get pods -n <namespace> -l helm.sh/hook\n\n# 2. Check hook logs\nkubectl logs job/<hook-job-name> -n <namespace>\n\n# 3. Get hook definitions\nhelm get hooks myapp -n <namespace>\n\n# 4. Check hook status in release\nhelm get manifest myapp -n <namespace> | grep -A 10 \"helm.sh/hook\"\n```\n\n**Solutions:**\n\n```bash\n# Option 1: Delete failed hook resources\nkubectl delete job <hook-job> -n <namespace>\nhelm upgrade myapp ./chart --namespace prod\n\n# Option 2: Skip hooks temporarily (debugging only)\nhelm upgrade myapp ./chart \\\n  --namespace prod \\\n  --no-hooks\n\n# Option 3: Fix hook in template\n# Adjust hook annotations:\nannotations:\n  \"helm.sh/hook\": pre-upgrade\n  \"helm.sh/hook-weight\": \"0\"  # Order of execution\n  \"helm.sh/hook-delete-policy\": hook-succeeded,hook-failed  # Cleanup\n```\n\n## Debugging Workflow\n\n### Step-by-Step Debugging Process\n\n```bash\n# 1. IDENTIFY THE PROBLEM\n# Check release status\nhelm status myapp --namespace prod --show-resources\n\n# Check release history\nhelm history myapp --namespace prod\n\n# 2. INSPECT CONFIGURATION\n# What values were used?\nhelm get values myapp --namespace prod --all > actual-values.yaml\n\n# What manifests were deployed?\nhelm get manifest myapp --namespace prod > actual-manifests.yaml\n\n# 3. CHECK KUBERNETES RESOURCES\n# Are pods running?\nkubectl get pods -n prod -l app.kubernetes.io/instance=myapp\n\n# Any events?\nkubectl get events -n prod --sort-by='.lastTimestamp' | tail -20\n\n# Pod details\nkubectl describe pod <pod-name> -n prod\nkubectl logs <pod-name> -n prod\n\n# 4. VALIDATE LOCALLY\n# Re-render templates with same values\nhelm template myapp ./chart -f actual-values.yaml > local-manifests.yaml\n\n# Compare deployed vs local\ndiff actual-manifests.yaml local-manifests.yaml\n\n# 5. TEST FIX\n# Dry-run with fix\nhelm upgrade myapp ./chart \\\n  --namespace prod \\\n  --set fix.value=true \\\n  --dry-run --debug\n\n# Apply fix\nhelm upgrade myapp ./chart \\\n  --namespace prod \\\n  --set fix.value=true \\\n  --atomic --wait\n```\n\n## Best Practices for Debugging\n\n### Enable Debug Output\n **DO**: Use `--debug` to see what's happening\n```bash\nhelm install myapp ./chart --namespace prod --debug\n```\n\n### Dry-Run Everything\n **DO**: Always dry-run before applying changes\n```bash\nhelm upgrade myapp ./chart -n prod --dry-run --debug\n```\n\n### Layer Your Validation\n **DO**: Progress through validation layers\n```bash\nhelm lint ./chart --strict\nhelm template myapp ./chart -f values.yaml\nhelm install myapp ./chart -n prod --dry-run --debug\nhelm install myapp ./chart -n prod --atomic --wait\n```\n\n### Capture State\n **DO**: Save release state before changes\n```bash\n# Before upgrade\nhelm get values myapp -n prod --all > values-before.yaml\nhelm get manifest myapp -n prod > manifest-before.yaml\nkubectl get pods -n prod -o yaml > pods-before.yaml\n```\n\n### Use Atomic Deployments\n **DO**: Enable automatic rollback\n```bash\nhelm upgrade myapp ./chart -n prod --atomic --wait\n```\n\n### Check Kubernetes Resources\n **DO**: Inspect deployed resources directly\n```bash\nkubectl get all -n prod -l app.kubernetes.io/instance=myapp\nkubectl describe pod <pod> -n prod\nkubectl logs <pod> -n prod\n```\n\n### Understand Value Precedence\n **DO**: Know override order\n```bash\n# Lowest to highest precedence:\n# 1. Chart defaults (values.yaml)\n# 2. --reuse-values (previous release)\n# 3. -f values1.yaml\n# 4. -f values2.yaml (overrides values1.yaml)\n# 5. --set key=value (overrides everything)\n```\n\n## Debugging Tools & Utilities\n\n### yq - YAML Processor\n```bash\n# Validate YAML syntax\nhelm template myapp ./chart | yq eval '.' -\n\n# Extract specific values\nhelm get values myapp -n prod -o yaml | yq eval '.image.tag' -\n\n# Pretty print\nhelm get manifest myapp -n prod | yq eval '.' -\n```\n\n### kubectl Plugin: stern\n```bash\n# Tail logs from multiple pods\nstern -n prod myapp\n\n# Follow logs with timestamps\nstern -n prod myapp --timestamps\n```\n\n### kubectl Plugin: neat\n```bash\n# Clean kubectl output (remove clutter)\nkubectl get pod <pod> -n prod -o yaml | kubectl neat\n```\n\n### k9s - Kubernetes CLI\n```bash\n# Interactive cluster management\nk9s -n prod\n\n# Features:\n# - Live resource updates\n# - Log viewing\n# - Resource editing\n# - Port forwarding\n```\n\n## Integration with Other Tools\n\n### ArgoCD Debugging\n```bash\n# When managed by ArgoCD:\n\n# 1. Check ArgoCD Application status\nargocd app get <app-name>\n\n# 2. Still use helm for inspection\nhelm get values <release> -n <namespace> --all\nhelm get manifest <release> -n <namespace>\n\n# 3. Sync with debugging\nargocd app sync <app-name> --dry-run\nargocd app sync <app-name> --prune --force\n```\n\n### CI/CD Debugging\n```yaml\n# Add debugging to pipeline\n- name: Debug Helm Install\n  run: |\n    set -x  # Enable bash debugging\n    helm template myapp ./chart \\\n      -f values.yaml \\\n      --debug\n    helm install myapp ./chart \\\n      --namespace prod \\\n      --dry-run \\\n      --debug\n  continue-on-error: true  # Don't fail pipeline\n\n- name: Capture State on Failure\n  if: failure()\n  run: |\n    helm list --all-namespaces\n    kubectl get all -n prod\n    kubectl describe pods -n prod\n    kubectl logs -n prod --all-containers --tail=100\n```\n\n## Related Skills\n\n- **Helm Release Management** - Install, upgrade, uninstall operations\n- **Helm Values Management** - Advanced configuration management\n- **Helm Release Recovery** - Rollback and recovery strategies\n- **Kubernetes Operations** - Managing and debugging K8s resources\n- **ArgoCD CLI Login** - GitOps debugging with ArgoCD\n\n## References\n\n- [Helm Debugging Documentation](https://helm.sh/docs/chart_template_guide/debugging/)\n- [Helm Troubleshooting Guide](https://helm.sh/docs/faq/troubleshooting/)\n- [Kubernetes Debugging](https://kubernetes.io/docs/tasks/debug/)\n- [Template Function Reference](https://helm.sh/docs/chart_template_guide/function_list/)"
              },
              {
                "name": "helm-release-management",
                "description": "Manage Helm releases: install, upgrade, uninstall, list, and inspect releases.\nCovers helm install, helm upgrade, helm list, helm status, release history.\nUse when user mentions deploying Helm charts, upgrading releases, helm install,\nhelm upgrade, or managing Kubernetes deployments with Helm.\n",
                "path": "kubernetes-plugin/skills/helm-release-management/SKILL.md",
                "frontmatter": {
                  "created": "2025-12-16T00:00:00.000Z",
                  "modified": "2025-12-16T00:00:00.000Z",
                  "reviewed": "2025-12-16T00:00:00.000Z",
                  "name": "helm-release-management",
                  "description": "Manage Helm releases: install, upgrade, uninstall, list, and inspect releases.\nCovers helm install, helm upgrade, helm list, helm status, release history.\nUse when user mentions deploying Helm charts, upgrading releases, helm install,\nhelm upgrade, or managing Kubernetes deployments with Helm.\n"
                },
                "content": "# Helm Release Management\n\nComprehensive guidance for day-to-day Helm release operations including installation, upgrades, uninstallation, and release tracking.\n\n## When to Use\n\nUse this skill automatically when:\n- User requests deploying or installing Helm charts\n- User mentions upgrading or updating Helm releases\n- User wants to list or manage releases across namespaces\n- User needs to check release history or status\n- User requests uninstalling or removing releases\n\n## Core Release Operations\n\n### Install New Release\n\n```bash\n# Basic install\nhelm install <release-name> <chart> --namespace <namespace> --create-namespace\n\n# Install with custom values\nhelm install myapp bitnami/nginx \\\n  --namespace production \\\n  --create-namespace \\\n  --values values.yaml \\\n  --set replicaCount=3\n\n# Install with atomic rollback on failure\nhelm install myapp ./mychart \\\n  --namespace staging \\\n  --atomic \\\n  --timeout 5m \\\n  --wait\n\n# Install from repository with specific version\nhelm install mydb bitnami/postgresql \\\n  --namespace database \\\n  --version 12.1.9 \\\n  --values db-values.yaml\n\n# Dry-run before actual install\nhelm install myapp ./chart \\\n  --namespace prod \\\n  --dry-run \\\n  --debug\n```\n\n**Key Flags:**\n- `--namespace` - Target namespace (ALWAYS specify explicitly)\n- `--create-namespace` - Create namespace if it doesn't exist\n- `--values` / `-f` - Specify values file(s)\n- `--set` - Override individual values\n- `--atomic` - Rollback automatically on failure (RECOMMENDED)\n- `--wait` - Wait for resources to be ready\n- `--timeout` - Maximum time to wait (default 5m)\n- `--dry-run --debug` - Preview without installing\n\n### Upgrade Existing Release\n\n```bash\n# Basic upgrade with new values\nhelm upgrade myapp ./mychart \\\n  --namespace production \\\n  --values values.yaml\n\n# Upgrade with value overrides\nhelm upgrade myapp bitnami/nginx \\\n  --namespace prod \\\n  --reuse-values \\\n  --set image.tag=1.21.0\n\n# Upgrade with new chart version\nhelm upgrade mydb bitnami/postgresql \\\n  --namespace database \\\n  --version 12.2.0 \\\n  --atomic \\\n  --wait\n\n# Install if not exists, upgrade if exists\nhelm upgrade --install myapp ./chart \\\n  --namespace staging \\\n  --create-namespace \\\n  --values values.yaml\n\n# Force upgrade (recreate resources)\nhelm upgrade myapp ./chart \\\n  --namespace prod \\\n  --force \\\n  --recreate-pods\n```\n\n**Key Flags:**\n- `--reuse-values` - Reuse existing values, merge with new\n- `--reset-values` - Reset to chart defaults, ignore existing\n- `--install` - Install if release doesn't exist\n- `--force` - Force resource updates (use cautiously)\n- `--recreate-pods` - Recreate pods even if no changes\n- `--cleanup-on-fail` - Delete new resources on failed upgrade\n\n**Value Override Precedence** (lowest to highest):\n1. Chart default values (`values.yaml` in chart)\n2. Previous release values (with `--reuse-values`)\n3. Parent chart values\n4. User-specified values files (`-f values.yaml`)\n5. Individual value overrides (`--set key=value`)\n\n### Uninstall Release\n\n```bash\n# Basic uninstall\nhelm uninstall myapp --namespace production\n\n# Uninstall but keep history (allows rollback)\nhelm uninstall myapp \\\n  --namespace staging \\\n  --keep-history\n\n# Uninstall with timeout\nhelm uninstall myapp \\\n  --namespace prod \\\n  --timeout 10m \\\n  --wait\n```\n\n**Key Flags:**\n- `--keep-history` - Preserve release history\n- `--wait` - Wait for resource deletion\n- `--timeout` - Maximum time to wait for deletion\n\n### List Releases\n\n```bash\n# List releases in namespace\nhelm list --namespace production\n\n# List all releases across all namespaces\nhelm list --all-namespaces\n\n# List with additional details\nhelm list \\\n  --all-namespaces \\\n  --output yaml \\\n  --max 50\n\n# List including uninstalled releases\nhelm list \\\n  --namespace staging \\\n  --uninstalled\n\n# Filter releases by name pattern\nhelm list --filter '^my.*' --namespace prod\n```\n\n**Key Flags:**\n- `--all-namespaces` / `-A` - List releases across all namespaces\n- `--all` - Show all releases including failed\n- `--uninstalled` - Show uninstalled releases\n- `--deployed` - Show only deployed releases (default)\n- `--failed` - Show only failed releases\n- `--pending` - Show pending releases\n- `--filter` - Filter by release name (regex)\n- `--max` - Maximum number of releases (default 256)\n\n## Release Information & History\n\n### Check Release Status\n\n```bash\n# Get release status\nhelm status myapp --namespace production\n\n# Show deployed resources\nhelm status myapp \\\n  --namespace prod \\\n  --show-resources\n\n# Show release notes\nhelm status myapp \\\n  --namespace prod \\\n  --show-desc\n```\n\n### View Release History\n\n```bash\n# View revision history\nhelm history myapp --namespace production\n\n# View detailed history\nhelm history myapp \\\n  --namespace prod \\\n  --output yaml \\\n  --max 10\n```\n\n### Inspect Release\n\n```bash\n# Get deployed manifest\nhelm get manifest myapp --namespace production\n\n# Get deployed values\nhelm get values myapp --namespace production\n\n# Get all values (including defaults)\nhelm get values myapp \\\n  --namespace prod \\\n  --all\n\n# Get release metadata\nhelm get metadata myapp --namespace production\n\n# Get release notes\nhelm get notes myapp --namespace production\n\n# Get release hooks\nhelm get hooks myapp --namespace production\n\n# Get everything\nhelm get all myapp --namespace production\n```\n\n## Common Workflows\n\n### Workflow 1: Deploy New Application\n\n```bash\n# 1. Add chart repository (if needed)\nhelm repo add bitnami https://charts.bitnami.com/bitnami\nhelm repo update\n\n# 2. Search for chart\nhelm search repo nginx\n\n# 3. View default values\nhelm show values bitnami/nginx > default-values.yaml\n\n# 4. Create custom values file\ncat > my-values.yaml <<EOF\nreplicaCount: 3\nservice:\n  type: LoadBalancer\ningress:\n  enabled: true\n  hostname: myapp.example.com\nEOF\n\n# 5. Dry-run to validate\nhelm install myapp bitnami/nginx \\\n  --namespace production \\\n  --create-namespace \\\n  --values my-values.yaml \\\n  --dry-run --debug\n\n# 6. Install with atomic rollback\nhelm install myapp bitnami/nginx \\\n  --namespace production \\\n  --create-namespace \\\n  --values my-values.yaml \\\n  --atomic \\\n  --wait \\\n  --timeout 5m\n\n# 7. Verify deployment\nhelm status myapp --namespace production\nkubectl get pods -n production -l app.kubernetes.io/instance=myapp\n```\n\n### Workflow 2: Update Configuration\n\n```bash\n# 1. Check current values\nhelm get values myapp --namespace production > current-values.yaml\n\n# 2. Edit values\nvim current-values.yaml\n# (change replicaCount: 3  5)\n\n# 3. Upgrade with new values\nhelm upgrade myapp bitnami/nginx \\\n  --namespace production \\\n  --values current-values.yaml \\\n  --atomic \\\n  --wait\n\n# 4. Verify upgrade\nhelm history myapp --namespace production\nhelm status myapp --namespace production\n```\n\n### Workflow 3: Upgrade Chart Version\n\n```bash\n# 1. Check available versions\nhelm search repo bitnami/nginx --versions | head -10\n\n# 2. Review changelog for breaking changes\nhelm show readme bitnami/nginx --version 15.0.0\n\n# 3. Compare values schemas\nhelm show values bitnami/nginx --version 15.0.0 > new-values.yaml\ndiff <(helm get values myapp -n prod --all) new-values.yaml\n\n# 4. Upgrade to new version\nhelm upgrade myapp bitnami/nginx \\\n  --namespace production \\\n  --version 15.0.0 \\\n  --reuse-values \\\n  --atomic \\\n  --wait\n\n# 5. Monitor upgrade\nwatch kubectl get pods -n production\n\n# 6. Verify new version\nhelm list --namespace production\n```\n\n### Workflow 4: Multi-Environment Deployment\n\n```bash\n# Directory structure:\n# charts/myapp/\n# values/\n#    common.yaml        # Shared values\n#    dev.yaml          # Dev overrides\n#    staging.yaml      # Staging overrides\n#    production.yaml   # Production overrides\n\n# Deploy to dev\nhelm upgrade --install myapp ./charts/myapp \\\n  --namespace dev \\\n  --create-namespace \\\n  -f values/common.yaml \\\n  -f values/dev.yaml\n\n# Deploy to staging\nhelm upgrade --install myapp ./charts/myapp \\\n  --namespace staging \\\n  --create-namespace \\\n  -f values/common.yaml \\\n  -f values/staging.yaml\n\n# Deploy to production (with approval gate)\nhelm upgrade --install myapp ./charts/myapp \\\n  --namespace production \\\n  --create-namespace \\\n  -f values/common.yaml \\\n  -f values/production.yaml \\\n  --atomic \\\n  --wait \\\n  --timeout 10m\n```\n\n## Best Practices\n\n### Namespace Management\n **DO**: Always specify `--namespace` explicitly\n```bash\nhelm install myapp ./chart --namespace production\n```\n\n **DON'T**: Rely on current kubectl context\n```bash\nhelm install myapp ./chart  # Namespace may be unexpected\n```\n\n### Atomic Deployments\n **DO**: Use `--atomic` for production deployments\n```bash\nhelm upgrade myapp ./chart --namespace prod --atomic --wait\n```\n\n**Why**: Automatically rolls back on failure, prevents partial deployments\n\n### Value Management\n **DO**: Use multiple values files for layering\n```bash\nhelm install myapp ./chart \\\n  -f values/base.yaml \\\n  -f values/production.yaml \\\n  -f values/secrets.yaml\n```\n\n **DO**: Prefer `--values` over many `--set` flags\n```bash\n# Good: values.yaml\nhelm install myapp ./chart -f values.yaml\n\n# Prefer: values.yaml over many --set flags\nhelm install myapp ./chart --set a=1 --set b=2 --set c=3\n```\n\n### Version Pinning\n **DO**: Pin chart versions in production\n```bash\nhelm install myapp bitnami/nginx --version 15.0.2 --namespace prod\n```\n\n **DON'T**: Use floating versions in production\n```bash\nhelm install myapp bitnami/nginx --namespace prod  # Uses latest\n```\n\n### Pre-Deployment Validation\n **DO**: Always dry-run before installing/upgrading\n```bash\n# 1. Lint (if local chart)\nhelm lint ./mychart\n\n# 2. Template to see rendered manifests\nhelm template myapp ./mychart -f values.yaml\n\n# 3. Dry-run with debug\nhelm install myapp ./mychart \\\n  --namespace prod \\\n  -f values.yaml \\\n  --dry-run --debug\n\n# 4. Actual install\nhelm install myapp ./mychart \\\n  --namespace prod \\\n  -f values.yaml \\\n  --atomic --wait\n```\n\n### History Management\n **DO**: Limit revision history\n```bash\nhelm upgrade myapp ./chart \\\n  --namespace prod \\\n  --history-max 10  # Keep only last 10 revisions\n```\n\n### Resource Waiting\n **DO**: Use `--wait` for critical deployments\n```bash\nhelm upgrade myapp ./chart \\\n  --namespace prod \\\n  --wait \\\n  --timeout 5m  # Fail if not ready in 5 minutes\n```\n\n### Release Naming\n **DO**: Use consistent, descriptive release names\n```bash\n# Good: environment-specific\nhelm install myapp-prod ./chart --namespace production\nhelm install myapp-staging ./chart --namespace staging\n\n# Or: same name, different namespaces\nhelm install myapp ./chart --namespace production\nhelm install myapp ./chart --namespace staging\n```\n\n## Troubleshooting Common Issues\n\n### Issue: \"Release already exists\"\n```bash\n# Check if release exists\nhelm list --all-namespaces | grep myapp\n\n# If in different namespace, specify correct namespace\nhelm upgrade myapp ./chart --namespace <correct-namespace>\n\n# If stuck in failed state, uninstall and reinstall\nhelm uninstall myapp --namespace <namespace>\nhelm install myapp ./chart --namespace <namespace>\n```\n\n### Issue: Upgrade hangs or times out\n```bash\n# Increase timeout\nhelm upgrade myapp ./chart \\\n  --namespace prod \\\n  --wait \\\n  --timeout 15m\n\n# Check pod status manually\nkubectl get pods -n prod -l app.kubernetes.io/instance=myapp\nkubectl describe pod <pod-name> -n prod\n\n# If stuck, consider force upgrade\nhelm upgrade myapp ./chart \\\n  --namespace prod \\\n  --force \\\n  --cleanup-on-fail\n```\n\n### Issue: Can't find release\n```bash\n# Search all namespaces\nhelm list --all-namespaces | grep myapp\n\n# Check uninstalled releases\nhelm list --namespace <namespace> --uninstalled\n\n# Check failed releases\nhelm list --namespace <namespace> --failed\n```\n\n### Issue: Wrong values applied\n```bash\n# Check what values were used\nhelm get values myapp --namespace prod --all\n\n# Compare with expected values\ndiff <(helm get values myapp -n prod --all) values.yaml\n\n# Upgrade with correct values\nhelm upgrade myapp ./chart \\\n  --namespace prod \\\n  --reset-values \\  # Reset to chart defaults first\n  -f correct-values.yaml\n```\n\n## Integration with Other Tools\n\n### ArgoCD Integration\nWhen using ArgoCD for GitOps:\n- ArgoCD manages Helm releases via Application CRDs\n- Use ArgoCD UI/CLI for sync operations instead of `helm upgrade`\n- Can still use `helm template` locally for testing\n- Use `helm get values/manifest` to inspect deployed resources\n\n### CI/CD Integration\n```yaml\n# GitHub Actions example\n- name: Deploy with Helm\n  run: |\n    helm upgrade --install myapp ./charts/myapp \\\n      --namespace ${{ env.NAMESPACE }} \\\n      --create-namespace \\\n      -f values/common.yaml \\\n      -f values/${{ env.ENVIRONMENT }}.yaml \\\n      --atomic \\\n      --wait \\\n      --timeout 10m\n```\n\n### Kubernetes Context\nAlways ensure correct context:\n```bash\n# Check current context\nkubectl config current-context\n\n# Switch context if needed\nkubectl config use-context <context-name>\n\n# Or specify kubeconfig\nhelm install myapp ./chart \\\n  --kubeconfig=/path/to/kubeconfig \\\n  --namespace prod\n```\n\n## Related Skills\n\n- **Helm Debugging** - Troubleshooting failed deployments\n- **Helm Values Management** - Advanced values configuration\n- **Helm Release Recovery** - Rollback and recovery strategies\n- **ArgoCD CLI Login** - GitOps integration with ArgoCD\n- **Kubernetes Operations** - Managing deployed resources\n\n## References\n\n- [Helm Install Documentation](https://helm.sh/docs/helm/helm_install/)\n- [Helm Upgrade Documentation](https://helm.sh/docs/helm/helm_upgrade/)\n- [Helm Best Practices](https://helm.sh/docs/chart_best_practices/)\n- [Helm Values Documentation](https://helm.sh/docs/chart_template_guide/values_files/)"
              },
              {
                "name": "helm-release-recovery",
                "description": "Recover from failed Helm deployments, rollback releases, fix stuck states\n(pending-install, pending-upgrade). Covers helm rollback, release history,\natomic deployments. Use when user mentions rollback, failed Helm upgrade,\nstuck release, or recovering from Helm deployment failures.\n",
                "path": "kubernetes-plugin/skills/helm-release-recovery/SKILL.md",
                "frontmatter": {
                  "created": "2025-12-16T00:00:00.000Z",
                  "modified": "2025-12-16T00:00:00.000Z",
                  "reviewed": "2025-12-16T00:00:00.000Z",
                  "name": "helm-release-recovery",
                  "description": "Recover from failed Helm deployments, rollback releases, fix stuck states\n(pending-install, pending-upgrade). Covers helm rollback, release history,\natomic deployments. Use when user mentions rollback, failed Helm upgrade,\nstuck release, or recovering from Helm deployment failures.\n"
                },
                "content": "# Helm Release Recovery\n\nComprehensive guidance for recovering from failed Helm deployments, rolling back releases, and managing stuck or corrupted release states.\n\n## When to Use\n\nUse this skill automatically when:\n- User needs to rollback a failed or problematic deployment\n- User reports stuck releases (pending-install, pending-upgrade)\n- User mentions failed upgrades or partial deployments\n- User needs to recover from corrupted release state\n- User wants to view release history\n- User needs to clean up failed releases\n\n## Core Recovery Operations\n\n### Rollback to Previous Revision\n\n```bash\n# Rollback to previous revision (most recent successful)\nhelm rollback <release> --namespace <namespace>\n\n# Rollback to specific revision number\nhelm rollback <release> 3 --namespace <namespace>\n\n# Rollback with wait and atomic behavior\nhelm rollback <release> \\\n  --namespace <namespace> \\\n  --wait \\\n  --timeout 5m \\\n  --cleanup-on-fail\n\n# Rollback without waiting (faster but less safe)\nhelm rollback <release> \\\n  --namespace <namespace> \\\n  --no-hooks\n```\n\n**Key Flags:**\n- `--wait` - Wait for resources to be ready\n- `--timeout` - Maximum time to wait (default 5m)\n- `--cleanup-on-fail` - Delete new resources on failed rollback\n- `--no-hooks` - Skip running rollback hooks\n- `--force` - Force resource updates through deletion/recreation\n- `--recreate-pods` - Perform pods restart for the resource if applicable\n\n### View Release History\n\n```bash\n# View all revisions\nhelm history <release> --namespace <namespace>\n\n# View detailed history (YAML format)\nhelm history <release> \\\n  --namespace <namespace> \\\n  --output yaml\n\n# Limit number of revisions shown\nhelm history <release> \\\n  --namespace <namespace> \\\n  --max 10\n```\n\n**History Output Fields:**\n- REVISION: Sequential version number\n- UPDATED: Timestamp of deployment\n- STATUS: deployed, superseded, failed, pending-install, pending-upgrade\n- CHART: Chart name and version\n- APP VERSION: Application version\n- DESCRIPTION: What happened (Install complete, Upgrade complete, Rollback to X)\n\n### Check Release Status\n\n```bash\n# Check current release status\nhelm status <release> --namespace <namespace>\n\n# Show deployed resources\nhelm status <release> \\\n  --namespace <namespace> \\\n  --show-resources\n\n# Get status of specific revision\nhelm status <release> \\\n  --namespace <namespace> \\\n  --revision 5\n```\n\n## Common Recovery Scenarios\n\n### Scenario 1: Recent Deploy Failed - Simple Rollback\n\n**Symptoms:**\n- Recent upgrade/install failed\n- Application not working after deployment\n- Want to restore previous working version\n\n**Recovery Steps:**\n\n```bash\n# 1. Check release status\nhelm status myapp --namespace production\n\n# 2. View history to identify good revision\nhelm history myapp --namespace production\n\n# Output example:\n# REVISION  STATUS      CHART        DESCRIPTION\n# 1         superseded  myapp-1.0.0  Install complete\n# 2         superseded  myapp-1.1.0  Upgrade complete\n# 3         deployed    myapp-1.2.0  Upgrade \"myapp\" failed\n\n# 3. Rollback to previous working revision (2)\nhelm rollback myapp 2 \\\n  --namespace production \\\n  --wait \\\n  --timeout 5m\n\n# 4. Verify rollback\nhelm history myapp --namespace production\n# REVISION  STATUS      CHART        DESCRIPTION\n# ...\n# 4         deployed    myapp-1.1.0  Rollback to 2\n\n# 5. Verify application health\nkubectl get pods -n production -l app.kubernetes.io/instance=myapp\nhelm status myapp --namespace production\n```\n\n### Scenario 2: Stuck Release (pending-install/pending-upgrade)\n\n**Symptoms:**\n```bash\nhelm list -n production\n# NAME   STATUS          CHART\n# myapp  pending-upgrade myapp-1.0.0\n```\n\n**Causes:**\n- Installation/upgrade process interrupted\n- Timeout during deployment\n- Kubernetes API issues\n- Network issues during deployment\n\n**Recovery Steps:**\n\n```bash\n# 1. Check what's actually deployed\nkubectl get all -n production -l app.kubernetes.io/instance=myapp\n\n# 2. Check release history\nhelm history myapp --namespace production\n\n# Option A: Rollback to previous working revision\nhelm rollback myapp <previous-working-revision> \\\n  --namespace production \\\n  --wait\n\n# Option B: Force new upgrade to unstick\nhelm upgrade myapp ./chart \\\n  --namespace production \\\n  --force \\\n  --wait \\\n  --atomic\n\n# Option C: If rollback fails, delete and reinstall\n# WARNING: This will cause downtime\nhelm uninstall myapp --namespace production --keep-history\nhelm install myapp ./chart --namespace production --atomic\n\n# 3. Verify recovery\nhelm status myapp --namespace production\n```\n\n### Scenario 3: Failed Upgrade - Partial Deployment\n\n**Symptoms:**\n- Some resources updated, others not\n- Mixed old/new versions running\n- Application in inconsistent state\n\n**Recovery Steps:**\n\n```bash\n# 1. Assess current state\nhelm status myapp --namespace production --show-resources\nkubectl get pods -n production -l app.kubernetes.io/instance=myapp\n\n# 2. Check recent history\nhelm history myapp --namespace production\n\n# 3. Identify last successful revision\n# Look for STATUS=deployed (not superseded or failed)\n\n# 4. Rollback with force to ensure consistency\nhelm rollback myapp <good-revision> \\\n  --namespace production \\\n  --force \\\n  --recreate-pods \\\n  --wait \\\n  --timeout 10m\n\n# 5. If rollback fails, try cleanup and retry\nkubectl delete pod -n production -l app.kubernetes.io/instance=myapp --grace-period=0 --force\nhelm rollback myapp <good-revision> \\\n  --namespace production \\\n  --force \\\n  --wait\n\n# 6. Verify all pods are consistent\nkubectl get pods -n production -l app.kubernetes.io/instance=myapp -o wide\n```\n\n### Scenario 4: Can't Rollback - \"No Revision for Release\"\n\n**Symptoms:**\n```\nError: no revision for release \"myapp\"\n```\n\n**Causes:**\n- Release history corrupted or deleted\n- Helm storage backend issues\n- Namespace issues\n\n**Recovery Steps:**\n\n```bash\n# 1. Check if release actually exists\nhelm list --all-namespaces | grep myapp\n\n# 2. Check for secrets (Helm storage)\nkubectl get secrets -n production -l owner=helm,name=myapp\n\n# 3. If secrets exist, check their data\nkubectl get secret sh.helm.release.v1.myapp.v1 -n production -o yaml\n\n# Option A: Uninstall and reinstall (data loss risk)\nhelm uninstall myapp --namespace production\nhelm install myapp ./chart --namespace production\n\n# Option B: Adopt existing resources (advanced)\n# Manually annotate resources to be managed by new Helm release\nkubectl annotate <resource-type> <name> \\\n  meta.helm.sh/release-name=myapp \\\n  meta.helm.sh/release-namespace=production \\\n  -n production\nkubectl label <resource-type> <name> \\\n  app.kubernetes.io/managed-by=Helm \\\n  -n production\n\n# Then install new release\nhelm install myapp ./chart --namespace production\n```\n\n### Scenario 5: Rollback Itself Failed\n\n**Symptoms:**\n```\nError: UPGRADE FAILED: <reason>\n```\n\n**Recovery Steps:**\n\n```bash\n# 1. Check current state\nhelm status myapp --namespace production\nkubectl get all -n production -l app.kubernetes.io/instance=myapp\n\n# 2. Try rollback with different flags\n# Option A: Rollback without hooks\nhelm rollback myapp <revision> \\\n  --namespace production \\\n  --no-hooks \\\n  --wait\n\n# Option B: Rollback with force recreation\nhelm rollback myapp <revision> \\\n  --namespace production \\\n  --force \\\n  --recreate-pods \\\n  --cleanup-on-fail\n\n# Option C: Manual resource cleanup then rollback\nkubectl delete pod -n production -l app.kubernetes.io/instance=myapp --force --grace-period=0\nkubectl delete job -n production -l app.kubernetes.io/instance=myapp\nhelm rollback myapp <revision> --namespace production --wait\n\n# Option D: Nuclear option - uninstall and reinstall\n# Get current values first\nhelm get values myapp -n production --all > backup-values.yaml\n\n# Uninstall\nhelm uninstall myapp --namespace production\n\n# Reinstall with backed up values\nhelm install myapp ./chart \\\n  --namespace production \\\n  -f backup-values.yaml \\\n  --atomic --wait\n```\n\n### Scenario 6: Cascading Failures Across Environments\n\n**Symptoms:**\n- Bad deploy rolled out to multiple environments\n- Need to rollback dev, staging, and prod\n\n**Recovery Workflow:**\n\n```bash\n# 1. Identify last known good revision (check one environment)\nhelm history myapp --namespace production\n\n# 2. Stop any ongoing deployments\n# Cancel CI/CD pipelines, ArgoCD syncs, etc.\n\n# 3. Rollback in reverse order (prod  staging  dev)\n# Production (highest priority)\nhelm rollback myapp <good-revision> \\\n  --namespace production \\\n  --wait \\\n  --timeout 10m\n\n# Verify prod is stable\nkubectl get pods -n production -l app.kubernetes.io/instance=myapp\n# Run smoke tests\n\n# Staging\nhelm rollback myapp <good-revision> \\\n  --namespace staging \\\n  --wait\n\n# Dev (lowest priority, optional)\nhelm rollback myapp <good-revision> \\\n  --namespace dev\n\n# 4. Update deployment configs to prevent re-deploy\n# Pin version in values files\n# Update ArgoCD target revision\n# Tag git commit as known-good\n\n# 5. Post-mortem\n# Document what went wrong\n# Update CI/CD to prevent similar issues\n```\n\n## History Management\n\n### Limit Revision History\n\n```bash\n# Set max revisions during upgrade/install\nhelm upgrade myapp ./chart \\\n  --namespace production \\\n  --history-max 10  # Keep only last 10 revisions\n\n# Default is 10 revisions\n# Set to 0 for unlimited (not recommended)\n```\n\n### Clean Up Old Revisions\n\n```bash\n# Revisions are automatically pruned based on --history-max\n\n# Manual cleanup (advanced):\n# Find old Helm secrets\nkubectl get secrets -n production \\\n  -l owner=helm,name=myapp \\\n  --sort-by=.metadata.creationTimestamp\n\n# Delete specific revision secret (DANGEROUS)\nkubectl delete secret sh.helm.release.v1.myapp.v1 -n production\n```\n\n### Preserve History on Uninstall\n\n```bash\n# Keep history after uninstall (allows rollback)\nhelm uninstall myapp \\\n  --namespace production \\\n  --keep-history\n\n# List uninstalled releases\nhelm list --namespace production --uninstalled\n\n# Rollback uninstalled release (recreates it)\nhelm rollback myapp <revision> --namespace production\n```\n\n## Atomic Deployments (Prevention)\n\n### Use Atomic Flag\n\n```bash\n# Automatically rollback on failure\nhelm upgrade myapp ./chart \\\n  --namespace production \\\n  --atomic \\\n  --wait \\\n  --timeout 5m\n\n# Equivalent to:\n# 1. Upgrade\n# 2. If fails, automatically: helm rollback myapp\n```\n\n**When Atomic Helps:**\n- Prevents partial deployments\n- Automatic recovery from failed upgrades\n- No manual intervention needed\n- Maintains release in known-good state\n\n**Atomic Behavior:**\n- On success: Release marked as deployed\n- On failure: Automatic rollback to previous revision\n- On timeout: Automatic rollback\n- Cleanup: Failed resources deleted with `--cleanup-on-fail`\n\n### Atomic Best Practices\n\n **DO**: Use atomic for production deployments\n```bash\nhelm upgrade myapp ./chart -n prod --atomic --wait --timeout 10m\n```\n\n **DO**: Set appropriate timeout for your application\n```bash\n# Large database: longer timeout\nhelm upgrade db ./chart -n prod --atomic --wait --timeout 30m\n\n# Simple API: shorter timeout\nhelm upgrade api ./chart -n prod --atomic --wait --timeout 5m\n```\n\n **DON'T**: Use atomic for debugging (harder to inspect failures)\n```bash\n# For debugging, use dry-run instead\nhelm upgrade myapp ./chart -n dev --dry-run --debug\n```\n\n## Recovery Best Practices\n\n### Pre-Upgrade Backup\n\n **DO**: Capture state before upgrades\n```bash\n# Before upgrade\nhelm get values myapp -n prod --all > backup-values.yaml\nhelm get manifest myapp -n prod > backup-manifest.yaml\nkubectl get all -n prod -l app.kubernetes.io/instance=myapp -o yaml > backup-resources.yaml\n\n# Upgrade\nhelm upgrade myapp ./chart -n prod --atomic\n\n# If needed, restore from backups\n```\n\n### Progressive Rollout\n\n **DO**: Deploy to lower environments first\n```bash\n# 1. Dev\nhelm upgrade myapp ./chart -n dev --atomic\n# Test thoroughly\n\n# 2. Staging\nhelm upgrade myapp ./chart -n staging --atomic\n# More testing\n\n# 3. Production (with caution)\nhelm upgrade myapp ./chart -n prod --atomic --timeout 10m\n```\n\n### Monitor During Deployment\n\n **DO**: Watch deployment progress\n```bash\n# Terminal 1: Upgrade\nhelm upgrade myapp ./chart -n prod --atomic --wait --timeout 10m\n\n# Terminal 2: Watch pods\nwatch -n 2 kubectl get pods -n prod -l app.kubernetes.io/instance=myapp\n\n# Terminal 3: Watch events\nkubectl get events -n prod --watch --field-selector involvedObject.kind=Pod\n\n# Terminal 4: Application logs\nstern -n prod myapp\n```\n\n### Test Rollback Procedures\n\n **DO**: Practice rollback in non-prod\n```bash\n# In dev/staging:\n# 1. Deploy known-good version\nhelm upgrade myapp ./chart -n dev --atomic\n\n# 2. Deploy bad version intentionally\nhelm upgrade myapp ./bad-chart -n dev --set breakApp=true\n\n# 3. Practice rollback\nhelm rollback myapp -n dev --wait\n\n# 4. Verify recovery\nhelm status myapp -n dev\n```\n\n### Document Known-Good Revisions\n\n **DO**: Tag stable releases\n```bash\n# After successful deploy and verification\nhelm history myapp -n prod\n\n# Document revision in runbook:\n# \"Last known good: Revision 5 (v1.2.3) deployed 2025-01-15\"\n\n# Use git tags for chart versions\ngit tag -a v1.2.3 -m \"Stable release, Helm revision 5 in prod\"\n```\n\n## Troubleshooting Recovery Issues\n\n### Issue: Rollback Hangs\n\n```bash\n# Increase timeout\nhelm rollback myapp <revision> -n prod --wait --timeout 15m\n\n# Skip waiting\nhelm rollback myapp <revision> -n prod --no-hooks\n\n# Force recreation\nhelm rollback myapp <revision> -n prod --force --recreate-pods\n```\n\n### Issue: Resources Not Reverting\n\n```bash\n# Check what's actually deployed\nhelm get manifest myapp -n prod | kubectl diff -f -\n\n# Force delete stuck resources\nkubectl delete pod <pod> -n prod --force --grace-period=0\n\n# Then retry rollback\nhelm rollback myapp <revision> -n prod --force\n```\n\n### Issue: Hook Failures Blocking Rollback\n\n```bash\n# Check hook status\nkubectl get jobs -n prod -l helm.sh/hook\nkubectl get pods -n prod -l helm.sh/hook\n\n# Delete failed hooks\nkubectl delete job <hook-job> -n prod\n\n# Rollback without hooks\nhelm rollback myapp <revision> -n prod --no-hooks\n```\n\n### Issue: Can't Determine Good Revision\n\n```bash\n# List all revisions with details\nhelm history myapp -n prod --output yaml\n\n# Check each revision's values\nhelm get values myapp -n prod --revision 1\nhelm get values myapp -n prod --revision 2\nhelm get values myapp -n prod --revision 3\n\n# Check manifest differences\ndiff \\\n  <(helm get manifest myapp -n prod --revision 2) \\\n  <(helm get manifest myapp -n prod --revision 3)\n\n# Check git history for chart changes\ngit log --oneline charts/myapp/\n```\n\n## Integration with CI/CD\n\n### Automated Rollback on Failure\n\n```yaml\n# GitHub Actions example\n- name: Deploy to Production\n  id: deploy\n  run: |\n    helm upgrade myapp ./chart \\\n      --namespace production \\\n      --atomic \\\n      --wait \\\n      --timeout 10m\n  continue-on-error: true\n\n- name: Verify Deployment\n  id: verify\n  if: steps.deploy.outcome == 'success'\n  run: |\n    # Run smoke tests\n    ./scripts/smoke-tests.sh production\n\n- name: Rollback on Test Failure\n  if: steps.verify.outcome == 'failure'\n  run: |\n    echo \"Smoke tests failed, rolling back\"\n    helm rollback myapp --namespace production --wait\n```\n\n### ArgoCD Auto-Sync with Rollback\n\n```yaml\n# ArgoCD Application with auto-rollback\napiVersion: argoproj.io/v1alpha1\nkind: Application\nmetadata:\n  name: myapp\nspec:\n  syncPolicy:\n    automated:\n      prune: true\n      selfHeal: true\n      allowEmpty: false\n    retry:\n      limit: 5\n      backoff:\n        duration: 5s\n        factor: 2\n        maxDuration: 3m\n```\n\n## Related Skills\n\n- **Helm Release Management** - Install, upgrade operations\n- **Helm Debugging** - Troubleshooting deployment failures\n- **Helm Values Management** - Managing configuration\n- **Kubernetes Operations** - Managing deployed resources\n\n## References\n\n- [Helm Rollback Documentation](https://helm.sh/docs/helm/helm_rollback/)\n- [Helm Release Management](https://helm.sh/docs/topics/advanced/#managing-a-release)\n- [Helm History Documentation](https://helm.sh/docs/helm/helm_history/)\n- [Helm Storage Backends](https://helm.sh/docs/topics/advanced/#storage-backends)"
              },
              {
                "name": "helm-values-management",
                "description": "Manage Helm values across environments with override precedence, multi-environment\nconfigurations, and secret management. Covers values files, --set, --set-string,\nvalues schema validation. Use when user mentions Helm values, environment-specific\nconfigs, values.yaml, --set overrides, or Helm configuration.\n",
                "path": "kubernetes-plugin/skills/helm-values-management/SKILL.md",
                "frontmatter": {
                  "created": "2025-12-16T00:00:00.000Z",
                  "modified": "2025-12-16T00:00:00.000Z",
                  "reviewed": "2025-12-16T00:00:00.000Z",
                  "name": "helm-values-management",
                  "description": "Manage Helm values across environments with override precedence, multi-environment\nconfigurations, and secret management. Covers values files, --set, --set-string,\nvalues schema validation. Use when user mentions Helm values, environment-specific\nconfigs, values.yaml, --set overrides, or Helm configuration.\n"
                },
                "content": "# Helm Values Management\n\nComprehensive guidance for managing Helm values across environments, understanding override precedence, and advanced configuration strategies.\n\n## When to Use\n\nUse this skill automatically when:\n- User needs to configure Helm deployments with custom values\n- User mentions environment-specific configurations (dev/staging/prod)\n- User asks about value override precedence or merging\n- User needs to manage secrets or sensitive configuration\n- User wants to understand what values were deployed\n- User needs to validate or inspect values\n\n## Value Override Precedence\n\nValues are merged with **right-most precedence** (last wins):\n\n```\n1. Chart defaults (values.yaml in chart)\n   \n2. Parent chart values (if subchart)\n   \n3. Previous release values (--reuse-values)\n   \n4. Values files in order (-f values1.yaml -f values2.yaml)\n   \n5. Individual overrides (--set, --set-string, --set-json, --set-file)\n   \n   HIGHEST PRECEDENCE\n```\n\n### Example Precedence\n\n```yaml\n# Chart values.yaml\nreplicaCount: 1\nimage:\n  tag: \"1.0.0\"\n\n# -f base.yaml\nreplicaCount: 2\n\n# -f production.yaml\nimage:\n  tag: \"2.0.0\"\n\n# --set replicaCount=5\n\n# RESULT:\n# replicaCount: 5        (from --set, highest precedence)\n# image.tag: \"2.0.0\"     (from production.yaml)\n```\n\n## Core Value Commands\n\n### View Default Values\n\n```bash\n# Show chart default values\nhelm show values <chart>\n\n# Show values from specific chart version\nhelm show values <chart> --version 1.2.3\n\n# Save defaults to file\nhelm show values bitnami/nginx > default-values.yaml\n\n# Show values for local chart\nhelm show values ./mychart\n```\n\n### View Deployed Values\n\n```bash\n# Get values used in deployed release\nhelm get values <release> --namespace <namespace>\n\n# Get ALL values (including defaults)\nhelm get values <release> --namespace <namespace> --all\n\n# Get values in different formats\nhelm get values <release> -n <namespace> -o yaml\nhelm get values <release> -n <namespace> -o json\n\n# Get values from specific revision\nhelm get values <release> -n <namespace> --revision 2\n```\n\n### Set Values During Install/Upgrade\n\n```bash\n# Using values file\nhelm install myapp ./chart \\\n  --namespace prod \\\n  --values values.yaml\n\n# Using multiple values files (right-most wins)\nhelm install myapp ./chart \\\n  --namespace prod \\\n  -f values/base.yaml \\\n  -f values/production.yaml\n\n# Using --set for individual values\nhelm install myapp ./chart \\\n  --namespace prod \\\n  --set replicaCount=3 \\\n  --set image.tag=v2.0.0\n\n# Using --set-string to force string type\nhelm install myapp ./chart \\\n  --namespace prod \\\n  --set-string version=\"1.0\"  # Keeps as string, not number\n\n# Using --set-json for complex structures\nhelm install myapp ./chart \\\n  --namespace prod \\\n  --set-json 'nodeSelector={\"disktype\":\"ssd\",\"region\":\"us-west\"}'\n\n# Using --set-file to read value from file\nhelm install myapp ./chart \\\n  --namespace prod \\\n  --set-file tlsCert=./certs/tls.crt\n```\n\n### Value Reuse Strategies\n\n```bash\n# Reuse existing values, merge with new\nhelm upgrade myapp ./chart \\\n  --namespace prod \\\n  --reuse-values \\\n  --set image.tag=v2.0.0\n\n# Reset to chart defaults, ignore existing values\nhelm upgrade myapp ./chart \\\n  --namespace prod \\\n  --reset-values \\\n  -f new-values.yaml\n\n# Reset specific values (advanced)\nhelm upgrade myapp ./chart \\\n  --namespace prod \\\n  --reset-values \\\n  --reuse-values \\\n  -f values.yaml\n```\n\n## Multi-Environment Value Management\n\n### Directory Structure\n\n```\nproject/\n charts/\n    myapp/           # Helm chart\n        Chart.yaml\n        values.yaml  # Chart defaults\n        templates/\n values/              # Environment-specific values\n     common.yaml      # Shared across all environments\n     dev.yaml         # Development overrides\n     staging.yaml     # Staging overrides\n     production.yaml  # Production overrides\n     secrets/         # Sensitive values (gitignored)\n         dev.yaml\n         staging.yaml\n         production.yaml\n```\n\n### Common Values (values/common.yaml)\n\n```yaml\n# Shared configuration across all environments\napp:\n  name: myapp\n  labels:\n    team: platform\n    component: api\n\nservice:\n  type: ClusterIP\n  port: 8080\n\ningress:\n  enabled: true\n  className: nginx\n  annotations:\n    cert-manager.io/cluster-issuer: letsencrypt\n\nresources:\n  requests:\n    cpu: 100m\n    memory: 128Mi\n```\n\n### Dev Environment (values/dev.yaml)\n\n```yaml\n# Development-specific overrides\nreplicaCount: 1\n\nimage:\n  tag: latest\n  pullPolicy: Always\n\ningress:\n  hostname: myapp-dev.example.com\n\nresources:\n  limits:\n    cpu: 500m\n    memory: 512Mi\n\n# Enable debug mode\ndebug: true\nlogLevel: debug\n```\n\n### Staging Environment (values/staging.yaml)\n\n```yaml\n# Staging-specific overrides\nreplicaCount: 2\n\nimage:\n  tag: v1.2.3\n  pullPolicy: IfNotPresent\n\ningress:\n  hostname: myapp-staging.example.com\n\nresources:\n  limits:\n    cpu: 1000m\n    memory: 1Gi\n\n# Production-like settings\ndebug: false\nlogLevel: info\n```\n\n### Production Environment (values/production.yaml)\n\n```yaml\n# Production-specific overrides\nreplicaCount: 5\n\nimage:\n  tag: v1.2.3\n  pullPolicy: IfNotPresent\n\ningress:\n  hostname: myapp.example.com\n\nresources:\n  limits:\n    cpu: 2000m\n    memory: 2Gi\n\n# High availability\npodAntiAffinity:\n  enabled: true\n\n# Monitoring\nmonitoring:\n  enabled: true\n  serviceMonitor: true\n\n# Production hardening\ndebug: false\nlogLevel: warn\nsecurityContext:\n  readOnlyRootFilesystem: true\n  runAsNonRoot: true\n```\n\n### Deployment Commands\n\n```bash\n# Deploy to dev\nhelm upgrade --install myapp ./charts/myapp \\\n  --namespace dev \\\n  --create-namespace \\\n  -f values/common.yaml \\\n  -f values/dev.yaml \\\n  -f values/secrets/dev.yaml\n\n# Deploy to staging\nhelm upgrade --install myapp ./charts/myapp \\\n  --namespace staging \\\n  --create-namespace \\\n  -f values/common.yaml \\\n  -f values/staging.yaml \\\n  -f values/secrets/staging.yaml \\\n  --atomic --wait\n\n# Deploy to production\nhelm upgrade --install myapp ./charts/myapp \\\n  --namespace production \\\n  --create-namespace \\\n  -f values/common.yaml \\\n  -f values/production.yaml \\\n  -f values/secrets/production.yaml \\\n  --atomic --wait --timeout 10m\n```\n\n## Value Syntax & Types\n\n### Simple Values\n\n```yaml\n# String\nname: myapp\ntag: \"v1.0.0\"  # Quote to ensure string\n\n# Number\nreplicaCount: 3\nport: 8080\n\n# Boolean\nenabled: true\ndebug: false\n\n# Null\ndatabase: null\n```\n\n### Nested Values\n\n```yaml\n# Nested objects\nimage:\n  repository: nginx\n  tag: \"1.21.0\"\n  pullPolicy: IfNotPresent\n\n# Access in template: {{ .Values.image.repository }}\n```\n\n### Lists/Arrays\n\n```yaml\n# Simple list\ntags:\n  - api\n  - web\n  - production\n\n# List of objects\nenv:\n  - name: DATABASE_URL\n    value: postgres://db:5432/myapp\n  - name: REDIS_URL\n    value: redis://cache:6379\n\n# Access in template:\n# {{ range .Values.env }}\n# - name: {{ .name }}\n#   value: {{ .value }}\n# {{ end }}\n```\n\n### Setting Values via CLI\n\n```bash\n# Simple value\n--set name=myapp\n\n# Nested value (use dot notation)\n--set image.tag=v2.0.0\n--set ingress.annotations.\"cert-manager\\.io/cluster-issuer\"=letsencrypt\n\n# List values (use array index or {})\n--set tags[0]=api\n--set tags[1]=web\n--set tags={api,web,prod}\n\n# List of objects (use array syntax)\n--set 'env[0].name=DB_URL,env[0].value=postgres://db'\n\n# Complex JSON structures\n--set-json 'nodeSelector={\"disk\":\"ssd\",\"region\":\"us-west\"}'\n```\n\n### Value Type Coercion\n\n```bash\n# Force string (prevents numeric conversion)\n--set-string version=\"1.0\"  # Keeps as \"1.0\", not 1.0\n\n# Force boolean\n--set enabled=true\n\n# Force number\n--set port=8080\n\n# Read value from file\n--set-file cert=./tls.crt\n```\n\n## Values Schema Validation\n\n### Define Schema (values.schema.json)\n\n```json\n{\n  \"$schema\": \"https://json-schema.org/draft-07/schema#\",\n  \"type\": \"object\",\n  \"required\": [\"replicaCount\", \"image\"],\n  \"properties\": {\n    \"replicaCount\": {\n      \"type\": \"integer\",\n      \"minimum\": 1,\n      \"maximum\": 100,\n      \"description\": \"Number of replicas\"\n    },\n    \"image\": {\n      \"type\": \"object\",\n      \"required\": [\"repository\", \"tag\"],\n      \"properties\": {\n        \"repository\": {\n          \"type\": \"string\",\n          \"description\": \"Image repository\"\n        },\n        \"tag\": {\n          \"type\": \"string\",\n          \"pattern\": \"^v?[0-9]+\\\\.[0-9]+\\\\.[0-9]+$\",\n          \"description\": \"Image tag (SemVer)\"\n        }\n      }\n    },\n    \"enabled\": {\n      \"type\": \"boolean\",\n      \"description\": \"Enable feature\"\n    }\n  }\n}\n```\n\n### Validation Automatically Runs\n\n```bash\n# Schema is validated during:\nhelm install myapp ./chart --values values.yaml\nhelm upgrade myapp ./chart --values values.yaml\nhelm template myapp ./chart --values values.yaml --validate\n\n# Errors will show:\n# Error: values don't meet the specifications of the schema(s)\n```\n\n## Secret Management\n\n### Option 1: Separate Secret Files (Gitignored)\n\n```yaml\n# values/secrets/production.yaml (GITIGNORED)\ndatabase:\n  password: super-secret-password\n\napi:\n  key: api-key-12345\n\ntls:\n  cert: |\n    -----BEGIN CERTIFICATE-----\n    ...\n    -----END CERTIFICATE-----\n```\n\n```bash\n# Deploy with secrets file\nhelm upgrade myapp ./chart \\\n  --namespace prod \\\n  -f values/common.yaml \\\n  -f values/production.yaml \\\n  -f values/secrets/production.yaml\n```\n\n### Option 2: Environment Variables\n\n```bash\n# Set from environment\nhelm upgrade myapp ./chart \\\n  --namespace prod \\\n  -f values.yaml \\\n  --set database.password=$DB_PASSWORD \\\n  --set api.key=$API_KEY\n```\n\n### Option 3: Helm Secrets Plugin\n\n```bash\n# Install helm-secrets plugin\nhelm plugin install https://github.com/jkroepke/helm-secrets\n\n# Encrypt secrets file with sops\nhelm secrets enc values/secrets/production.yaml\n\n# Deploy with encrypted secrets (decrypted on-the-fly)\nhelm secrets upgrade myapp ./chart \\\n  --namespace prod \\\n  -f values/production.yaml \\\n  -f secrets://values/secrets/production.yaml\n```\n\n### Option 4: External Secrets Operator\n\n```yaml\n# Use ExternalSecret CRD to fetch from vault/AWS Secrets Manager\napiVersion: external-secrets.io/v1beta1\nkind: ExternalSecret\nmetadata:\n  name: myapp-secrets\nspec:\n  secretStoreRef:\n    name: vault-backend\n  target:\n    name: myapp-secrets\n  data:\n  - secretKey: database-password\n    remoteRef:\n      key: myapp/prod/db-password\n```\n\n```yaml\n# Reference in values.yaml\nexistingSecret: myapp-secrets\n```\n\n## Value Validation & Testing\n\n### Template with Values\n\n```bash\n# Render templates with values\nhelm template myapp ./chart \\\n  --values values.yaml\n\n# Validate against Kubernetes API\nhelm install myapp ./chart \\\n  --values values.yaml \\\n  --dry-run \\\n  --validate\n```\n\n### Check Computed Values\n\n```bash\n# See what values will be used (before install)\nhelm template myapp ./chart \\\n  --values values.yaml \\\n  --debug 2>&1 | grep -A 100 \"COMPUTED VALUES\"\n\n# See what values were used (after install)\nhelm get values myapp --namespace prod --all\n```\n\n### Test Different Value Combinations\n\n```bash\n# Test with minimal values\nhelm template myapp ./chart \\\n  --set image.tag=test\n\n# Test with full production values\nhelm template myapp ./chart \\\n  -f values/common.yaml \\\n  -f values/production.yaml\n\n# Test with overrides\nhelm template myapp ./chart \\\n  -f values/production.yaml \\\n  --set replicaCount=10\n```\n\n## Template Value Handling\n\n### Accessing Values\n\n```yaml\n# Simple value\nimage: {{ .Values.image.repository }}:{{ .Values.image.tag }}\n\n# With default\nreplicas: {{ .Values.replicaCount | default 1 }}\n\n# Required value (fails if not provided)\ndatabase: {{ required \"database.host is required\" .Values.database.host }}\n\n# Conditional\n{{- if .Values.ingress.enabled }}\napiVersion: networking.k8s.io/v1\nkind: Ingress\n{{- end }}\n```\n\n### Type Conversions\n\n```yaml\n# Ensure integer\nreplicas: {{ .Values.replicaCount | int }}\n\n# Ensure string (and quote)\nversion: {{ .Values.version | quote }}\n\n# Boolean\nenabled: {{ .Values.enabled | ternary \"true\" \"false\" }}\n```\n\n### Complex Value Rendering\n\n```yaml\n# Merge labels\nlabels:\n{{- toYaml .Values.labels | nindent 2 }}\n\n# Range over list\nenv:\n{{- range .Values.env }}\n- name: {{ .name }}\n  value: {{ .value | quote }}\n{{- end }}\n\n# Conditional inclusion\n{{- if .Values.extraEnv }}\n{{- toYaml .Values.extraEnv | nindent 2 }}\n{{- end }}\n```\n\n## Best Practices\n\n### Value File Organization\n\n **DO**: Layer values files (base  environment  secrets)\n```bash\nhelm install myapp ./chart \\\n  -f values/base.yaml \\\n  -f values/prod.yaml \\\n  -f values/secrets.yaml\n```\n\n **DO**: Use consistent naming conventions\n```\nvalues/\n base.yaml        # Or common.yaml\n dev.yaml\n staging.yaml\n production.yaml  # Or prod.yaml\n secrets/\n     production.yaml\n```\n\n **DON'T**: Mix concerns in single values file\n```yaml\n# Bad: Everything in one file\nproduction-with-secrets-and-configs.yaml\n```\n\n### Value Precedence\n\n **DO**: Understand and document precedence\n```bash\n# Explicit precedence (right-most wins):\nhelm install myapp ./chart \\\n  -f base.yaml \\      # Lowest\n  -f prod.yaml \\      # Overrides base\n  --set replicas=5    # Highest\n```\n\n **DON'T**: Mix --reuse-values with other value sources (confusing)\n```bash\n# Confusing: What values win?\nhelm upgrade myapp ./chart \\\n  --reuse-values \\\n  -f new-values.yaml\n```\n\n### Value Naming\n\n **DO**: Use clear, hierarchical names\n```yaml\ndatabase:\n  host: db.example.com\n  port: 5432\n  name: myapp\n\ncache:\n  host: redis.example.com\n  port: 6379\n```\n\n **DON'T**: Use flat, ambiguous names\n```yaml\ndbHost: db.example.com\ndbPort: 5432\ndb: myapp\nredisHost: redis.example.com\nredisPort: 6379\n```\n\n### Required Values\n\n **DO**: Mark required values in template\n```yaml\ndatabase:\n  host: {{ required \"database.host is required\" .Values.database.host }}\n```\n\n **DO**: Document required values in values.yaml comments\n```yaml\n# database.host is REQUIRED\ndatabase:\n  host: \"\"  # Set to your database hostname\n  port: 5432\n```\n\n### Secret Management\n\n **DO**: Keep secrets in separate, gitignored files\n```\nvalues/\n production.yaml          # Committed\n secrets/\n     production.yaml      # GITIGNORED\n```\n\n **DO**: Use existing secrets when possible\n```yaml\n# Reference existing Kubernetes secret\nexistingSecret: myapp-database-credentials\n```\n\n **DON'T**: Commit secrets to git\n```yaml\n# BAD: In committed values file\ndatabase:\n  password: super-secret-123  #  Visible in git\n```\n\n### Value Validation\n\n **DO**: Create values.schema.json for validation\n```json\n{\n  \"required\": [\"replicaCount\", \"image\"],\n  \"properties\": {\n    \"replicaCount\": {\n      \"type\": \"integer\",\n      \"minimum\": 1\n    }\n  }\n}\n```\n\n **DO**: Test value combinations\n```bash\n# Test each environment's values\nhelm template myapp ./chart -f values/dev.yaml\nhelm template myapp ./chart -f values/staging.yaml\nhelm template myapp ./chart -f values/production.yaml\n```\n\n## Troubleshooting Values\n\n### Debug Value Precedence\n\n```bash\n# See computed values\nhelm install myapp ./chart \\\n  -f values1.yaml \\\n  -f values2.yaml \\\n  --set key=value \\\n  --debug --dry-run 2>&1 | grep -A 50 \"COMPUTED VALUES\"\n```\n\n### Compare Values\n\n```bash\n# Compare deployed vs expected\ndiff <(helm get values myapp -n prod --all) expected-values.yaml\n\n# Compare environments\ndiff values/staging.yaml values/production.yaml\n```\n\n### Find Missing Values\n\n```bash\n# Check for required values\nhelm template myapp ./chart -f values.yaml 2>&1 | grep \"required\"\n\n# Validate schema\nhelm install myapp ./chart -f values.yaml --dry-run\n```\n\n## Related Skills\n\n- **Helm Release Management** - Using values during install/upgrade\n- **Helm Debugging** - Troubleshooting value errors\n- **Helm Chart Development** - Creating charts with good value design\n\n## References\n\n- [Helm Values Files](https://helm.sh/docs/chart_template_guide/values_files/)\n- [Helm Schema Validation](https://helm.sh/docs/topics/charts/#schema-files)\n- [Helm Secrets Plugin](https://github.com/jkroepke/helm-secrets)\n- [External Secrets Operator](https://external-secrets.io/)"
              },
              {
                "name": "kubectl-debugging",
                "description": "Debug Kubernetes pods, nodes, and workloads using kubectl debug. Covers ephemeral containers,\npod copying, node debugging, debug profiles, and interactive troubleshooting sessions.\nUse when user mentions kubectl debug, debugging pods, ephemeral containers, node debugging,\nor interactive troubleshooting in Kubernetes clusters.\n",
                "path": "kubernetes-plugin/skills/kubectl-debugging/SKILL.md",
                "frontmatter": {
                  "created": "2025-12-16T00:00:00.000Z",
                  "modified": "2025-12-16T00:00:00.000Z",
                  "reviewed": "2025-12-16T00:00:00.000Z",
                  "name": "kubectl-debugging",
                  "description": "Debug Kubernetes pods, nodes, and workloads using kubectl debug. Covers ephemeral containers,\npod copying, node debugging, debug profiles, and interactive troubleshooting sessions.\nUse when user mentions kubectl debug, debugging pods, ephemeral containers, node debugging,\nor interactive troubleshooting in Kubernetes clusters.\n",
                  "allowed-tools": "Glob, Grep, Read, Bash, Edit, Write, TodoWrite, WebFetch"
                },
                "content": "# kubectl debug - Interactive Kubernetes Debugging\n\nExpert knowledge for debugging Kubernetes resources using `kubectl debug` - ephemeral containers, pod copies, and node access.\n\n## Core Capabilities\n\n**kubectl debug** automates common debugging tasks:\n\n- **Ephemeral Containers**: Add debug containers to running pods without restart\n- **Pod Copying**: Create modified copies for debugging (different images, commands)\n- **Node Debugging**: Access node host namespaces and filesystem\n\n## Context Safety (CRITICAL)\n\n**Always specify `--context`** explicitly in every kubectl command:\n\n```bash\n# CORRECT: Explicit context\nkubectl --context=prod-cluster debug mypod -it --image=busybox\n\n# WRONG: Relying on current context\nkubectl debug mypod -it --image=busybox  # Which cluster?\n```\n\n## Quick Reference\n\n### Add Ephemeral Debug Container\n\n```bash\n# Interactive debugging with busybox\nkubectl --context=my-context debug mypod -it --image=busybox\n\n# Target specific container's process namespace\nkubectl --context=my-context debug mypod -it --image=busybox --target=mycontainer\n\n# Use a specific debug profile\nkubectl --context=my-context debug mypod -it --image=busybox --profile=netadmin\n```\n\n### Copy Pod for Debugging\n\n```bash\n# Create debug copy\nkubectl --context=my-context debug mypod -it --copy-to=mypod-debug --image=busybox\n\n# Copy and change container image\nkubectl --context=my-context debug mypod --copy-to=mypod-debug --set-image=app=busybox\n\n# Copy and modify command\nkubectl --context=my-context debug mypod -it --copy-to=mypod-debug --container=myapp -- sh\n\n# Copy on same node\nkubectl --context=my-context debug mypod -it --copy-to=mypod-debug --same-node --image=busybox\n```\n\n### Debug Node\n\n```bash\n# Interactive node debugging (host namespaces, filesystem at /host)\nkubectl --context=my-context debug node/mynode -it --image=busybox\n\n# With sysadmin profile for full capabilities\nkubectl --context=my-context debug node/mynode -it --image=ubuntu --profile=sysadmin\n```\n\n## Debug Profiles\n\n| Profile | Use Case | Capabilities |\n|---------|----------|--------------|\n| `legacy` | Default, unrestricted | Full access (backwards compatible) |\n| `general` | General purpose | Moderate restrictions |\n| `baseline` | Minimal restrictions | Pod security baseline |\n| `netadmin` | Network troubleshooting | NET_ADMIN capability |\n| `restricted` | High security environments | Strictest restrictions |\n| `sysadmin` | System administration | SYS_PTRACE, SYS_ADMIN |\n\n```bash\n# Network debugging (tcpdump, netstat, ss)\nkubectl --context=my-context debug mypod -it --image=nicolaka/netshoot --profile=netadmin\n\n# System debugging (strace, perf)\nkubectl --context=my-context debug mypod -it --image=ubuntu --profile=sysadmin\n```\n\n## Common Debug Images\n\n| Image | Size | Use Case |\n|-------|------|----------|\n| `busybox` | ~1MB | Basic shell, common utilities |\n| `alpine` | ~5MB | Shell with apk package manager |\n| `ubuntu` | ~77MB | Full Linux with apt |\n| `nicolaka/netshoot` | ~350MB | Network debugging (tcpdump, dig, curl, netstat) |\n| `gcr.io/k8s-debug/debug` | Varies | Official Kubernetes debug image |\n\n## Debugging Patterns\n\n### Network Connectivity Issues\n\n```bash\n# Add netshoot container for network debugging\nkubectl --context=my-context debug mypod -it \\\n  --image=nicolaka/netshoot \\\n  --profile=netadmin\n\n# Inside container:\n# - tcpdump -i any port 80\n# - dig kubernetes.default\n# - curl -v http://service:port\n# - ss -tlnp\n# - netstat -an\n```\n\n### Application Crashes\n\n```bash\n# Copy pod with different entrypoint to inspect\nkubectl --context=my-context debug mypod -it \\\n  --copy-to=mypod-debug \\\n  --container=app \\\n  -- sh\n\n# Inside: check filesystem, env vars, config files\n```\n\n### Process Inspection\n\n```bash\n# Target container's process namespace\nkubectl --context=my-context debug mypod -it \\\n  --image=busybox \\\n  --target=mycontainer\n\n# Inside: ps aux, /proc inspection\n```\n\n### Node-Level Issues\n\n```bash\n# Debug node with host access\nkubectl --context=my-context debug node/worker-1 -it \\\n  --image=ubuntu \\\n  --profile=sysadmin\n\n# Inside:\n# - Host filesystem at /host\n# - chroot /host for full access\n# - journalctl, systemctl, dmesg\n```\n\n### Non-Destructive Debugging\n\n```bash\n# Create copy, keeping original running\nkubectl --context=my-context debug mypod -it \\\n  --copy-to=mypod-debug \\\n  --same-node \\\n  --share-processes \\\n  --image=busybox\n\n# Original pod continues serving traffic\n# Debug copy shares storage if on same node\n```\n\n## Key Options\n\n| Option | Description |\n|--------|-------------|\n| `-it` | Interactive TTY (required for shell access) |\n| `--image` | Debug container image |\n| `--container` | Name for the debug container |\n| `--target` | Share process namespace with this container |\n| `--copy-to` | Create a copy instead of ephemeral container |\n| `--same-node` | Schedule copy on same node (with `--copy-to`) |\n| `--set-image` | Change container images in copy |\n| `--profile` | Security profile (legacy, netadmin, sysadmin, etc.) |\n| `--share-processes` | Enable process namespace sharing (default: true with --copy-to) |\n| `--replace` | Delete original pod when creating copy |\n\n## Best Practices\n\n1. **Use appropriate profiles** - Match capabilities to debugging needs\n2. **Prefer ephemeral containers** - Less disruptive than pod copies\n3. **Use `--copy-to` for invasive debugging** - Preserve original pod\n4. **Clean up debug pods** - Delete copies after debugging\n5. **Use `--same-node`** - For accessing shared storage/network conditions\n\n## Cleanup\n\n```bash\n# List debug pod copies\nkubectl --context=my-context get pods | grep -E \"debug|copy\"\n\n# Delete debug pods\nkubectl --context=my-context delete pod mypod-debug\n```\n\n## Requirements\n\n- Kubernetes 1.23+ for ephemeral containers (stable)\n- Kubernetes 1.25+ for debug profiles\n- RBAC permissions for pods/ephemeralcontainers\n\nFor detailed option reference, examples, and troubleshooting patterns, see REFERENCE.md."
              },
              {
                "name": "kubernetes-operations",
                "description": "Kubernetes operations including deployment, management, troubleshooting, kubectl mastery,\nand cluster stability. Covers K8s workloads, networking, storage, and debugging pods.\nUse when user mentions Kubernetes, K8s, kubectl, pods, deployments, services, ingress,\nConfigMaps, Secrets, or cluster operations.\n",
                "path": "kubernetes-plugin/skills/kubernetes-operations/SKILL.md",
                "frontmatter": {
                  "created": "2025-12-16T00:00:00.000Z",
                  "modified": "2025-12-16T00:00:00.000Z",
                  "reviewed": "2025-12-16T00:00:00.000Z",
                  "name": "kubernetes-operations",
                  "description": "Kubernetes operations including deployment, management, troubleshooting, kubectl mastery,\nand cluster stability. Covers K8s workloads, networking, storage, and debugging pods.\nUse when user mentions Kubernetes, K8s, kubectl, pods, deployments, services, ingress,\nConfigMaps, Secrets, or cluster operations.\n",
                  "allowed-tools": "Glob, Grep, Read, Bash, Edit, Write, TodoWrite, WebFetch"
                },
                "content": "# Kubernetes Operations\n\nExpert knowledge for Kubernetes cluster management, deployment, and troubleshooting with mastery of kubectl and cloud-native patterns.\n\n## Core Expertise\n\n**Kubernetes Operations**\n- **Workload Management**: Deployments, StatefulSets, DaemonSets, Jobs, and CronJobs\n- **Networking**: Services, Ingress, NetworkPolicies, and DNS configuration\n- **Configuration & Storage**: ConfigMaps, Secrets, PersistentVolumes, and PersistentVolumeClaims\n- **Troubleshooting**: Debugging pods, analyzing logs, and inspecting cluster events\n\n## Cluster Operations Process\n\n1. **Manifest First**: Always prefer declarative YAML manifests for resource management\n2. **Validate & Dry-Run**: Use `kubectl apply --dry-run=client` to validate changes\n3. **Inspect & Verify**: After applying changes, verify with `kubectl get`, `kubectl describe`, `kubectl logs`\n4. **Monitor Health**: Continuously check status of nodes, pods, and services\n5. **Clean Up**: Ensure old or unused resources are properly garbage collected\n\n## Essential Commands\n\n```bash\n# Resource management\nkubectl apply -f manifest.yaml\nkubectl get pods -A\nkubectl describe pod <pod-name>\nkubectl logs -f <pod-name>\nkubectl exec -it <pod-name> -- /bin/bash\n\n# Debugging\nkubectl get events --sort-by='.lastTimestamp'\nkubectl top nodes\nkubectl top pods --containers\nkubectl port-forward <pod-name> 8080:80\n\n# Deployment management\nkubectl rollout status deployment/<name>\nkubectl rollout history deployment/<name>\nkubectl rollout undo deployment/<name>\n\n# Cluster inspection\nkubectl cluster-info\nkubectl get nodes -o wide\nkubectl api-resources\n```\n\n## Key Debugging Patterns\n\n**Pod Debugging**\n```bash\n# Pod inspection\nkubectl describe pod <pod-name>\nkubectl get pod <pod-name> -o yaml\nkubectl logs <pod-name> --previous\n\n# Interactive debugging\nkubectl exec -it <pod-name> -- /bin/bash\nkubectl debug <pod-name> -it --image=busybox\nkubectl port-forward <pod-name> 8080:80\n```\n\n**Networking Troubleshooting**\n```bash\n# Service debugging\nkubectl get svc -o wide\nkubectl get endpoints\nkubectl describe svc <service>\n\n# Network connectivity\nkubectl run test-pod --image=busybox -it --rm -- sh\n# Inside pod: nslookup, wget, nc commands\n```\n\n**Common Issues**\n```bash\n# CrashLoopBackOff debugging\nkubectl logs <pod> --previous\nkubectl describe pod <pod>\nkubectl get events --field-selector involvedObject.name=<pod>\n\n# Resource constraints\nkubectl top pod <pod>\nkubectl describe pod <pod> | grep -A 5 Limits\n\n# State management\nkubectl state list\nkubectl state show <resource>\n```\n\n## Best Practices\n\n**Context Safety (CRITICAL)**\n- **Always specify `--context`** explicitly in every kubectl command\n- Never rely on the current context - it may have been changed by another process\n- Use `kubectl --context=<context-name> get pods` format for all operations\n- This prevents accidental operations on the wrong cluster (e.g., running production commands against staging)\n\n```bash\n# CORRECT: Explicit context\nkubectl --context=gke_myproject_us-central1_prod get pods\nkubectl --context=staging-cluster apply -f deployment.yaml\n\n# WRONG: Relying on current context\nkubectl get pods  # Which cluster is this targeting?\n```\n\n**Resource Definitions**\n- Use declarative YAML manifests\n- Implement proper labels and selectors\n- Define resource requests and limits\n- Configure health checks (liveness/readiness probes)\n\n**Security**\n- Use NetworkPolicies to restrict traffic\n- Implement RBAC for access control\n- Store sensitive data in Secrets\n- Run containers as non-root users\n\n**Monitoring**\n- Configure proper logging and metrics\n- Set up alerts for critical conditions\n- Use health checks and readiness probes\n- Monitor resource usage and quotas\n\nFor detailed debugging commands, troubleshooting patterns, Helm workflows, and advanced K8s operations, see REFERENCE.md."
              }
            ]
          },
          {
            "name": "terraform-plugin",
            "description": "Terraform and Terraform Cloud - infrastructure as code",
            "source": "./terraform-plugin",
            "category": "infrastructure",
            "version": "1.0.0",
            "author": null,
            "install_commands": [
              "/plugin marketplace add laurigates/claude-plugins",
              "/plugin install terraform-plugin@lgates-claude-plugins"
            ],
            "signals": {
              "stars": 1,
              "forks": 0,
              "pushed_at": "2026-01-12T12:05:51Z",
              "created_at": "2025-12-16T11:24:04Z",
              "license": null
            },
            "commands": [],
            "skills": [
              {
                "name": "infrastructure-terraform",
                "description": "Infrastructure as Code with Terraform including HCL configuration, state management,\nmodular design, and plan-apply workflows. Covers cloud and on-prem resource provisioning,\nremote backends, and Terraform modules.\nUse when user mentions Terraform, HCL, terraform plan, terraform apply, tfstate,\ninfrastructure as code, or IaC provisioning.\n",
                "path": "terraform-plugin/skills/infrastructure-terraform/SKILL.md",
                "frontmatter": {
                  "created": "2025-12-16T00:00:00.000Z",
                  "modified": "2025-12-16T00:00:00.000Z",
                  "reviewed": "2025-12-16T00:00:00.000Z",
                  "name": "infrastructure-terraform",
                  "description": "Infrastructure as Code with Terraform including HCL configuration, state management,\nmodular design, and plan-apply workflows. Covers cloud and on-prem resource provisioning,\nremote backends, and Terraform modules.\nUse when user mentions Terraform, HCL, terraform plan, terraform apply, tfstate,\ninfrastructure as code, or IaC provisioning.\n",
                  "allowed-tools": "Glob, Grep, Read, Bash, Edit, Write, TodoWrite"
                },
                "content": "# Infrastructure Terraform\n\nExpert knowledge for Infrastructure as Code using Terraform with focus on declarative HCL, state management, and resilient infrastructure.\n\n## Core Expertise\n\n**Terraform & IaC**\n- **Declarative Infrastructure**: Clean, modular, and reusable HCL code\n- **State Management**: Protecting and managing Terraform state with remote backends\n- **Providers & Modules**: Leveraging community and custom providers/modules\n- **Execution Lifecycle**: Mastering the plan -> review -> apply workflow\n\n## Infrastructure Provisioning Process\n\n1. **Plan First**: Always generate `terraform plan` and review carefully before changes\n2. **Modularize**: Break down infrastructure into reusable and composable modules\n3. **Secure State**: Use remote backends with locking to protect state file\n4. **Parameterize**: Use variables and outputs for flexible and configurable infrastructure\n5. **Destroy with Caution**: Double-check plan before running `terraform destroy`\n\n## Essential Commands\n\n```bash\n# Core workflow\nterraform init                   # Initialize working directory\nterraform plan                   # Generate execution plan\nterraform apply                  # Apply changes\nterraform destroy               # Destroy infrastructure\n\n# State management\nterraform state list            # List all resources\nterraform state show <resource> # Show specific resource\nterraform state pull > backup.tfstate  # Backup state\n\n# Validation and formatting\nterraform validate              # Validate configuration\nterraform fmt -recursive        # Format all files\nterraform graph | dot -Tsvg > graph.svg  # Dependency graph\n\n# Debugging\nexport TF_LOG=DEBUG             # Enable debug logging\nterraform plan -out=tfplan      # Save plan for review\nterraform show tfplan           # View saved plan\n```\n\n## Best Practices\n\n**Module Structure**\n```hcl\nmodule \"vpc\" {\n  source  = \"./modules/vpc\"\n  version = \"1.0.0\"\n\n  vpc_cidr = var.vpc_cidr\n  environment = var.environment\n}\n\noutput \"vpc_id\" {\n  value = module.vpc.vpc_id\n}\n```\n\n**Variable Configuration**\n```hcl\nvariable \"environment\" {\n  description = \"Environment name\"\n  type        = string\n  validation {\n    condition     = contains([\"dev\", \"staging\", \"prod\"], var.environment)\n    error_message = \"Environment must be dev, staging, or prod.\"\n  }\n}\n```\n\n**Remote State Backend**\n```hcl\nterraform {\n  backend \"s3\" {\n    bucket         = \"my-terraform-state\"\n    key            = \"prod/terraform.tfstate\"\n    region         = \"us-east-1\"\n    encrypt        = true\n    dynamodb_table = \"terraform-locks\"\n  }\n}\n```\n\n**Provider Configuration**\n```hcl\nterraform {\n  required_providers {\n    aws = {\n      source  = \"hashicorp/aws\"\n      version = \"~> 5.0\"\n    }\n  }\n  required_version = \">= 1.5\"\n}\n```\n\n## Key Debugging Techniques\n\n**State Debugging**\n```bash\n# State inspection\nterraform state list\nterraform state show aws_instance.web\n\n# State recovery\nterraform refresh\nterraform plan -refresh-only\nterraform import aws_instance.existing i-1234567890\n```\n\n**Error Resolution**\n```bash\n# Provider errors\nterraform init -upgrade\nterraform init -reconfigure\n\n# Resource conflicts\nterraform taint aws_instance.broken\nterraform apply -target=aws_instance.web\n```\n\nFor detailed debugging patterns, advanced module design, CI/CD integration, and troubleshooting strategies, see REFERENCE.md."
              },
              {
                "name": "tfc-list-runs",
                "description": "List Terraform Cloud runs for a workspace with filtering by status, operation type, and date. Use when reviewing run history, finding failed runs, or auditing infrastructure changes. Requires TFE_TOKEN environment variable.",
                "path": "terraform-plugin/skills/tfc-list-runs/SKILL.md",
                "frontmatter": {
                  "created": "2025-12-16T00:00:00.000Z",
                  "modified": "2025-12-16T00:00:00.000Z",
                  "reviewed": "2025-12-16T00:00:00.000Z",
                  "name": "tfc-list-runs",
                  "description": "List Terraform Cloud runs for a workspace with filtering by status, operation type, and date. Use when reviewing run history, finding failed runs, or auditing infrastructure changes. Requires TFE_TOKEN environment variable.",
                  "allowed-tools": "Bash, Read"
                },
                "content": "# Terraform Cloud List Runs\n\nList and filter runs from Terraform Cloud workspaces with formatted output.\n\n## Prerequisites\n\n```bash\nexport TFE_TOKEN=\"your-api-token\"        # User or team token\nexport TFE_ADDRESS=\"app.terraform.io\"    # Optional\n```\n\n## Core Commands\n\n### List Recent Runs for a Workspace\n\n```bash\n#!/bin/bash\nset -euo pipefail\n\nTOKEN=\"${TFE_TOKEN:?TFE_TOKEN not set}\"\nBASE_URL=\"https://${TFE_ADDRESS:-app.terraform.io}/api/v2\"\nWORKSPACE_ID=\"${1:?Usage: $0 <workspace-id> [limit]}\"\nLIMIT=\"${2:-10}\"\n\ncurl -sf --header \"Authorization: Bearer $TOKEN\" \\\n  \"$BASE_URL/workspaces/$WORKSPACE_ID/runs?page[size]=$LIMIT\" | \\\n  jq -r '.data[] | [\n    .id,\n    .attributes.status,\n    .attributes.\"created-at\"[0:19],\n    (.attributes.message // \"No message\")[0:50]\n  ] | @tsv' | \\\n  column -t -s $'\\t'\n```\n\n### List Runs by Workspace Name (requires org)\n\n```bash\nTOKEN=\"${TFE_TOKEN:?TFE_TOKEN not set}\"\nBASE_URL=\"https://${TFE_ADDRESS:-app.terraform.io}/api/v2\"\nORG=\"ForumViriumHelsinki\"\nWORKSPACE=\"infrastructure-gcp\"\n\n# Get workspace ID first\nWS_ID=$(curl -sf --header \"Authorization: Bearer $TOKEN\" \\\n  \"$BASE_URL/organizations/$ORG/workspaces/$WORKSPACE\" | \\\n  jq -r '.data.id')\n\n# List runs\ncurl -sf --header \"Authorization: Bearer $TOKEN\" \\\n  \"$BASE_URL/workspaces/$WS_ID/runs?page[size]=10\" | \\\n  jq -r '.data[] | \"\\(.id) | \\(.attributes.status) | \\(.attributes.\"created-at\"[0:19]) | \\(.attributes.message // \"No message\")\"'\n```\n\n### Filter by Status\n\n```bash\nTOKEN=\"${TFE_TOKEN:?TFE_TOKEN not set}\"\nBASE_URL=\"https://${TFE_ADDRESS:-app.terraform.io}/api/v2\"\nWORKSPACE_ID=\"ws-abc123\"\n\n# Filter by single status\ncurl -sf --header \"Authorization: Bearer $TOKEN\" \\\n  \"$BASE_URL/workspaces/$WORKSPACE_ID/runs?filter[status]=errored\" | \\\n  jq -r '.data[] | \"\\(.id) | \\(.attributes.status) | \\(.attributes.\"created-at\")\"'\n\n# Filter by multiple statuses\ncurl -sf --header \"Authorization: Bearer $TOKEN\" \\\n  \"$BASE_URL/workspaces/$WORKSPACE_ID/runs?filter[status]=errored,canceled\" | \\\n  jq -r '.data[] | \"\\(.id) | \\(.attributes.status)\"'\n```\n\n### Filter by Status Group\n\n```bash\n# Non-final runs (in progress)\ncurl -sf --header \"Authorization: Bearer $TOKEN\" \\\n  \"$BASE_URL/workspaces/$WORKSPACE_ID/runs?filter[status_group]=non_final\"\n\n# Final runs (completed)\ncurl -sf --header \"Authorization: Bearer $TOKEN\" \\\n  \"$BASE_URL/workspaces/$WORKSPACE_ID/runs?filter[status_group]=final\"\n\n# Discardable runs\ncurl -sf --header \"Authorization: Bearer $TOKEN\" \\\n  \"$BASE_URL/workspaces/$WORKSPACE_ID/runs?filter[status_group]=discardable\"\n```\n\n### Include Plan-Only Runs\n\nBy default, plan-only runs are excluded. To include them:\n\n```bash\ncurl -sf --header \"Authorization: Bearer $TOKEN\" \\\n  \"$BASE_URL/workspaces/$WORKSPACE_ID/runs?filter[operation]=plan_and_apply,plan_only,save_plan,refresh_only,destroy\"\n```\n\n### List Runs Across Organization\n\n```bash\nTOKEN=\"${TFE_TOKEN:?TFE_TOKEN not set}\"\nBASE_URL=\"https://${TFE_ADDRESS:-app.terraform.io}/api/v2\"\nORG=\"ForumViriumHelsinki\"\n\n# All runs in org (limited info, no total count)\ncurl -sf --header \"Authorization: Bearer $TOKEN\" \\\n  \"$BASE_URL/organizations/$ORG/runs?page[size]=20\" | \\\n  jq -r '.data[] | \"\\(.id) | \\(.attributes.status)\"'\n\n# Filter by workspace names\ncurl -sf --header \"Authorization: Bearer $TOKEN\" \\\n  \"$BASE_URL/organizations/$ORG/runs?filter[workspace_names]=infrastructure-gcp,infrastructure-github\"\n```\n\n## Formatted Output Examples\n\n### Table Format with Resource Changes\n\n```bash\ncurl -sf --header \"Authorization: Bearer $TOKEN\" \\\n  \"$BASE_URL/workspaces/$WORKSPACE_ID/runs?page[size]=10&include=plan\" | \\\n  jq -r '\n    [\"RUN_ID\", \"STATUS\", \"ADD\", \"CHG\", \"DEL\", \"CREATED\"],\n    (.data[] | [\n      .id,\n      .attributes.status,\n      (.relationships.plan.data.id as $pid |\n        (.included[] | select(.id == $pid) | .attributes.\"resource-additions\" // 0)),\n      (.relationships.plan.data.id as $pid |\n        (.included[] | select(.id == $pid) | .attributes.\"resource-changes\" // 0)),\n      (.relationships.plan.data.id as $pid |\n        (.included[] | select(.id == $pid) | .attributes.\"resource-destructions\" // 0)),\n      .attributes.\"created-at\"[0:19]\n    ]) | @tsv' | column -t\n```\n\n### JSON Output for Further Processing\n\n```bash\ncurl -sf --header \"Authorization: Bearer $TOKEN\" \\\n  \"$BASE_URL/workspaces/$WORKSPACE_ID/runs?page[size]=5\" | \\\n  jq '[.data[] | {\n    id: .id,\n    status: .attributes.status,\n    created: .attributes.\"created-at\",\n    message: .attributes.message,\n    has_changes: .attributes.\"has-changes\",\n    auto_apply: .attributes.\"auto-apply\"\n  }]'\n```\n\n## Available Filter Parameters\n\n| Parameter | Description | Example Values |\n|-----------|-------------|----------------|\n| `filter[status]` | Run status | `applied`, `errored`, `planned`, `canceled` |\n| `filter[status_group]` | Status group | `non_final`, `final`, `discardable` |\n| `filter[operation]` | Operation type | `plan_and_apply`, `plan_only`, `destroy` |\n| `filter[source]` | Run source | `tfe-api`, `tfe-ui`, `tfe-configuration-version` |\n| `filter[timeframe]` | Time period | `2024`, `year`, `month` |\n| `search[user]` | VCS username | Username string |\n| `search[commit]` | Commit SHA | SHA string |\n| `search[basic]` | Combined search | Search term |\n\n## Run Statuses\n\n**Final States:** `applied`, `planned_and_finished`, `discarded`, `errored`, `canceled`, `force_canceled`, `policy_soft_failed`\n\n**Non-Final States:** `pending`, `planning`, `planned`, `cost_estimating`, `policy_checking`, `confirmed`, `applying`, and others\n\n## Pagination\n\n```bash\n# Page 2 with 20 items per page\ncurl -sf --header \"Authorization: Bearer $TOKEN\" \\\n  \"$BASE_URL/workspaces/$WORKSPACE_ID/runs?page[number]=2&page[size]=20\"\n\n# Check pagination info\ncurl -sf --header \"Authorization: Bearer $TOKEN\" \\\n  \"$BASE_URL/workspaces/$WORKSPACE_ID/runs\" | \\\n  jq '.meta.pagination'\n```\n\n## Rate Limiting\n\nThe `/runs` endpoint has a special rate limit of **30 requests/minute** (not 30/second like most endpoints). Plan accordingly when scripting.\n\n## See Also\n\n- `tfc-run-logs`: Get plan/apply logs for a run\n- `tfc-run-status`: Quick status check for a run\n- `tfc-workspace-runs`: Convenience wrapper for known workspaces"
              },
              {
                "name": "tfc-plan-json",
                "description": "Download and analyze structured Terraform plan JSON output from Terraform Cloud. Use when analyzing resource changes, diffing infrastructure, or programmatically inspecting plan details. Requires TFE_TOKEN environment variable.",
                "path": "terraform-plugin/skills/tfc-plan-json/SKILL.md",
                "frontmatter": {
                  "created": "2025-12-16T00:00:00.000Z",
                  "modified": "2025-12-16T00:00:00.000Z",
                  "reviewed": "2025-12-16T00:00:00.000Z",
                  "name": "tfc-plan-json",
                  "description": "Download and analyze structured Terraform plan JSON output from Terraform Cloud. Use when analyzing resource changes, diffing infrastructure, or programmatically inspecting plan details. Requires TFE_TOKEN environment variable.",
                  "allowed-tools": "Bash, Read"
                },
                "content": "# Terraform Cloud Plan JSON\n\nDownload and analyze structured plan JSON output from Terraform Cloud runs for detailed resource change analysis.\n\n## Prerequisites\n\n```bash\nexport TFE_TOKEN=\"your-api-token\"        # User or team token with admin workspace access\nexport TFE_ADDRESS=\"app.terraform.io\"    # Optional\n```\n\n## Core Commands\n\n### Download Plan JSON\n\n```bash\n#!/bin/bash\nset -euo pipefail\n\nTOKEN=\"${TFE_TOKEN:?TFE_TOKEN not set}\"\nBASE_URL=\"https://${TFE_ADDRESS:-app.terraform.io}/api/v2\"\nRUN_ID=\"${1:?Usage: $0 <run-id> [output-file]}\"\nOUTPUT=\"${2:-plan.json}\"\n\n# Download with redirect following (API returns 307)\ncurl -Lsf --header \"Authorization: Bearer $TOKEN\" \\\n  -o \"$OUTPUT\" \\\n  \"$BASE_URL/runs/$RUN_ID/plan/json-output\"\n\necho \"Plan JSON saved to: $OUTPUT\"\n```\n\n### Download via Plan ID\n\n```bash\nTOKEN=\"${TFE_TOKEN:?TFE_TOKEN not set}\"\nPLAN_ID=\"plan-xyz789\"\n\ncurl -Lsf --header \"Authorization: Bearer $TOKEN\" \\\n  -o plan.json \\\n  \"https://app.terraform.io/api/v2/plans/$PLAN_ID/json-output\"\n```\n\n## Analysis Commands\n\n### Resource Change Summary\n\n```bash\ncurl -Lsf --header \"Authorization: Bearer $TFE_TOKEN\" \\\n  \"https://app.terraform.io/api/v2/runs/$RUN_ID/plan/json-output\" | \\\n  jq '{\n    terraform_version: .terraform_version,\n    format_version: .format_version,\n    summary: {\n      create: [.resource_changes[] | select(.change.actions | contains([\"create\"]))] | length,\n      update: [.resource_changes[] | select(.change.actions | contains([\"update\"]))] | length,\n      delete: [.resource_changes[] | select(.change.actions | contains([\"delete\"]))] | length,\n      replace: [.resource_changes[] | select(.change.actions | contains([\"delete\", \"create\"]))] | length,\n      read: [.resource_changes[] | select(.change.actions | contains([\"read\"]))] | length,\n      no_op: [.resource_changes[] | select(.change.actions == [\"no-op\"])] | length\n    }\n  }'\n```\n\n### List Resources Being Created\n\n```bash\ncurl -Lsf --header \"Authorization: Bearer $TFE_TOKEN\" \\\n  \"https://app.terraform.io/api/v2/runs/$RUN_ID/plan/json-output\" | \\\n  jq -r '.resource_changes[] | select(.change.actions | contains([\"create\"])) | .address'\n```\n\n### List Resources Being Destroyed\n\n```bash\ncurl -Lsf --header \"Authorization: Bearer $TFE_TOKEN\" \\\n  \"https://app.terraform.io/api/v2/runs/$RUN_ID/plan/json-output\" | \\\n  jq -r '.resource_changes[] | select(.change.actions | contains([\"delete\"])) | .address'\n```\n\n### List Resources Being Updated\n\n```bash\ncurl -Lsf --header \"Authorization: Bearer $TFE_TOKEN\" \\\n  \"https://app.terraform.io/api/v2/runs/$RUN_ID/plan/json-output\" | \\\n  jq -r '.resource_changes[] | select(.change.actions | contains([\"update\"])) | .address'\n```\n\n### Resources Being Replaced\n\n```bash\ncurl -Lsf --header \"Authorization: Bearer $TFE_TOKEN\" \\\n  \"https://app.terraform.io/api/v2/runs/$RUN_ID/plan/json-output\" | \\\n  jq -r '.resource_changes[] | select(.change.actions | contains([\"delete\", \"create\"])) |\n    \"\\(.address) (replace due to: \\(.action_reason // \"unknown\"))\"'\n```\n\n### Detailed Resource Changes\n\n```bash\ncurl -Lsf --header \"Authorization: Bearer $TFE_TOKEN\" \\\n  \"https://app.terraform.io/api/v2/runs/$RUN_ID/plan/json-output\" | \\\n  jq '.resource_changes[] | select(.change.actions != [\"no-op\"]) | {\n    address: .address,\n    actions: .change.actions,\n    before: .change.before,\n    after: .change.after\n  }'\n```\n\n### Show What's Changing in a Specific Resource\n\n```bash\nRESOURCE=\"aws_instance.web\"\n\ncurl -Lsf --header \"Authorization: Bearer $TFE_TOKEN\" \\\n  \"https://app.terraform.io/api/v2/runs/$RUN_ID/plan/json-output\" | \\\n  jq --arg addr \"$RESOURCE\" '\n    .resource_changes[] | select(.address == $addr) | {\n      address: .address,\n      actions: .change.actions,\n      before: .change.before,\n      after: .change.after,\n      after_unknown: .change.after_unknown\n    }'\n```\n\n### Provider Versions Used\n\n```bash\ncurl -Lsf --header \"Authorization: Bearer $TFE_TOKEN\" \\\n  \"https://app.terraform.io/api/v2/runs/$RUN_ID/plan/json-output\" | \\\n  jq '.configuration.provider_config | to_entries | map({\n    provider: .key,\n    version: .value.version_constraint\n  })'\n```\n\n### Output Values\n\n```bash\ncurl -Lsf --header \"Authorization: Bearer $TFE_TOKEN\" \\\n  \"https://app.terraform.io/api/v2/runs/$RUN_ID/plan/json-output\" | \\\n  jq '.output_changes | to_entries | map({\n    name: .key,\n    actions: .value.actions,\n    sensitive: .value.after_sensitive\n  })'\n```\n\n### Variables Used\n\n```bash\ncurl -Lsf --header \"Authorization: Bearer $TFE_TOKEN\" \\\n  \"https://app.terraform.io/api/v2/runs/$RUN_ID/plan/json-output\" | \\\n  jq '.variables | keys'\n```\n\n## Complete Analysis Script\n\n```bash\n#!/bin/bash\nset -euo pipefail\n\nTOKEN=\"${TFE_TOKEN:?TFE_TOKEN not set}\"\nRUN_ID=\"${1:?Usage: $0 <run-id>}\"\n\nPLAN=$(curl -Lsf --header \"Authorization: Bearer $TOKEN\" \\\n  \"https://app.terraform.io/api/v2/runs/$RUN_ID/plan/json-output\")\n\necho \"=== Plan Analysis for $RUN_ID ===\"\necho \"\"\necho \"Terraform Version: $(echo \"$PLAN\" | jq -r '.terraform_version')\"\necho \"\"\n\necho \"Resource Changes:\"\necho \"  Create:  $(echo \"$PLAN\" | jq '[.resource_changes[] | select(.change.actions | contains([\"create\"]))] | length')\"\necho \"  Update:  $(echo \"$PLAN\" | jq '[.resource_changes[] | select(.change.actions | contains([\"update\"]))] | length')\"\necho \"  Delete:  $(echo \"$PLAN\" | jq '[.resource_changes[] | select(.change.actions | contains([\"delete\"]))] | length')\"\necho \"  Replace: $(echo \"$PLAN\" | jq '[.resource_changes[] | select(.change.actions | contains([\"delete\", \"create\"]))] | length')\"\necho \"\"\n\necho \"Resources to Create:\"\necho \"$PLAN\" | jq -r '.resource_changes[] | select(.change.actions | contains([\"create\"])) | \"  - \" + .address'\n\necho \"\"\necho \"Resources to Destroy:\"\necho \"$PLAN\" | jq -r '.resource_changes[] | select(.change.actions | contains([\"delete\"])) | \"  - \" + .address'\n\necho \"\"\necho \"Resources to Update:\"\necho \"$PLAN\" | jq -r '.resource_changes[] | select(.change.actions | contains([\"update\"])) | \"  - \" + .address'\n```\n\n## Plan JSON Structure\n\nThe plan JSON output follows Terraform's JSON plan format:\n\n```json\n{\n  \"format_version\": \"1.2\",\n  \"terraform_version\": \"1.5.0\",\n  \"planned_values\": { ... },\n  \"resource_changes\": [\n    {\n      \"address\": \"aws_instance.web\",\n      \"mode\": \"managed\",\n      \"type\": \"aws_instance\",\n      \"name\": \"web\",\n      \"provider_name\": \"registry.terraform.io/hashicorp/aws\",\n      \"change\": {\n        \"actions\": [\"create\"],\n        \"before\": null,\n        \"after\": { ... },\n        \"after_unknown\": { ... },\n        \"before_sensitive\": false,\n        \"after_sensitive\": { ... }\n      }\n    }\n  ],\n  \"output_changes\": { ... },\n  \"configuration\": { ... },\n  \"variables\": { ... }\n}\n```\n\n### Change Actions\n\n- `[\"create\"]` - Resource will be created\n- `[\"delete\"]` - Resource will be destroyed\n- `[\"update\"]` - Resource will be updated in-place\n- `[\"delete\", \"create\"]` - Resource will be replaced\n- `[\"read\"]` - Data source will be read\n- `[\"no-op\"]` - No changes\n\n## Important Notes\n\n- **Requires Terraform 0.12+** for JSON output support\n- **Returns 204 No Content** if plan hasn't completed yet\n- **Follow redirects** - API returns HTTP 307 to temporary download URL\n- **Temporary URL** - Download URL is valid for ~1 minute\n- **Admin access required** - Need admin permissions on the workspace\n\n## Error Handling\n\n### 204 No Content\nPlan hasn't completed yet. Check run status first.\n\n### 401 Unauthorized\nToken lacks admin workspace access or is invalid.\n\n### 404 Not Found\nRun doesn't exist or you don't have permission.\n\n## See Also\n\n- `tfc-run-logs`: Get plan/apply logs (human-readable)\n- `tfc-run-status`: Quick status check for a run\n- `tfc-list-runs`: List recent runs in a workspace"
              },
              {
                "name": "tfc-run-logs",
                "description": "Retrieve plan and apply logs from Terraform Cloud runs. Use when examining TFC run output, debugging failed plans/applies, or reviewing infrastructure changes. Requires TFE_TOKEN environment variable.",
                "path": "terraform-plugin/skills/tfc-run-logs/SKILL.md",
                "frontmatter": {
                  "created": "2025-12-16T00:00:00.000Z",
                  "modified": "2025-12-16T00:00:00.000Z",
                  "reviewed": "2025-12-16T00:00:00.000Z",
                  "name": "tfc-run-logs",
                  "description": "Retrieve plan and apply logs from Terraform Cloud runs. Use when examining TFC run output, debugging failed plans/applies, or reviewing infrastructure changes. Requires TFE_TOKEN environment variable.",
                  "allowed-tools": "Bash, Read"
                },
                "content": "# Terraform Cloud Run Logs\n\nRetrieve and display plan and/or apply logs from Terraform Cloud runs directly in the terminal.\n\n## Prerequisites\n\n```bash\n# Required environment variables\nexport TFE_TOKEN=\"your-api-token\"        # User or team token (not organization token)\nexport TFE_ADDRESS=\"app.terraform.io\"    # Optional, defaults to app.terraform.io\n```\n\n## Core Workflow\n\n### Get Both Plan and Apply Logs\n\n```bash\n#!/bin/bash\nset -euo pipefail\n\nTOKEN=\"${TFE_TOKEN:?TFE_TOKEN not set}\"\nBASE_URL=\"https://${TFE_ADDRESS:-app.terraform.io}/api/v2\"\nRUN_ID=\"${1:?Usage: $0 <run-id>}\"\n\n# Get run with plan and apply relationships\nRUN_DATA=$(curl -sf --header \"Authorization: Bearer $TOKEN\" \\\n  \"$BASE_URL/runs/$RUN_ID?include=plan,apply\")\n\n# Extract IDs\nPLAN_ID=$(echo \"$RUN_DATA\" | jq -r '.data.relationships.plan.data.id')\nAPPLY_ID=$(echo \"$RUN_DATA\" | jq -r '.data.relationships.apply.data.id // empty')\n\n# Get and display plan logs\nPLAN_LOG_URL=$(curl -sf --header \"Authorization: Bearer $TOKEN\" \\\n  \"$BASE_URL/plans/$PLAN_ID\" | jq -r '.data.attributes.\"log-read-url\"')\n\necho \"=== PLAN OUTPUT ===\"\ncurl -sf \"$PLAN_LOG_URL\" | sed 's/\\x1b\\[[0-9;]*m//g'  # Strip ANSI codes\n\n# Get apply logs if exists\nif [ -n \"$APPLY_ID\" ]; then\n  APPLY_LOG_URL=$(curl -sf --header \"Authorization: Bearer $TOKEN\" \\\n    \"$BASE_URL/applies/$APPLY_ID\" | jq -r '.data.attributes.\"log-read-url\"')\n\n  echo \"\"\n  echo \"=== APPLY OUTPUT ===\"\n  curl -sf \"$APPLY_LOG_URL\" | sed 's/\\x1b\\[[0-9;]*m//g'\nfi\n```\n\n### Get Plan Logs Only\n\n```bash\nTOKEN=\"${TFE_TOKEN:?TFE_TOKEN not set}\"\nBASE_URL=\"https://${TFE_ADDRESS:-app.terraform.io}/api/v2\"\nRUN_ID=\"run-abc123\"\n\n# Get plan ID from run\nPLAN_ID=$(curl -sf --header \"Authorization: Bearer $TOKEN\" \\\n  \"$BASE_URL/runs/$RUN_ID\" | jq -r '.data.relationships.plan.data.id')\n\n# Get log URL and fetch logs\nPLAN_LOG_URL=$(curl -sf --header \"Authorization: Bearer $TOKEN\" \\\n  \"$BASE_URL/plans/$PLAN_ID\" | jq -r '.data.attributes.\"log-read-url\"')\n\ncurl -sf \"$PLAN_LOG_URL\"\n```\n\n### Get Apply Logs Only\n\n```bash\nTOKEN=\"${TFE_TOKEN:?TFE_TOKEN not set}\"\nBASE_URL=\"https://${TFE_ADDRESS:-app.terraform.io}/api/v2\"\nRUN_ID=\"run-abc123\"\n\n# Get apply ID from run\nAPPLY_ID=$(curl -sf --header \"Authorization: Bearer $TOKEN\" \\\n  \"$BASE_URL/runs/$RUN_ID\" | jq -r '.data.relationships.apply.data.id')\n\nif [ -n \"$APPLY_ID\" ] && [ \"$APPLY_ID\" != \"null\" ]; then\n  # Get log URL and fetch logs\n  APPLY_LOG_URL=$(curl -sf --header \"Authorization: Bearer $TOKEN\" \\\n    \"$BASE_URL/applies/$APPLY_ID\" | jq -r '.data.attributes.\"log-read-url\"')\n\n  curl -sf \"$APPLY_LOG_URL\"\nelse\n  echo \"No apply for this run\"\nfi\n```\n\n## Quick One-Liners\n\n### Plan Logs (with ANSI colors)\n```bash\ncurl -sf -H \"Authorization: Bearer $TFE_TOKEN\" \\\n  \"https://app.terraform.io/api/v2/runs/run-abc123?include=plan\" | \\\n  jq -r '.included[0].attributes.\"log-read-url\"' | xargs curl -sf\n```\n\n### Plan Logs (clean text)\n```bash\ncurl -sf -H \"Authorization: Bearer $TFE_TOKEN\" \\\n  \"https://app.terraform.io/api/v2/runs/run-abc123?include=plan\" | \\\n  jq -r '.included[0].attributes.\"log-read-url\"' | \\\n  xargs curl -sf | sed 's/\\x1b\\[[0-9;]*m//g'\n```\n\n## Important Notes\n\n- **Log URLs are secrets**: Archivist URLs contain embedded authentication - don't log them\n- **URLs expire**: Log URLs are valid for 25 hours\n- **No auth needed for logs**: Once you have the archivist URL, no bearer token is required\n- **ANSI codes**: Logs contain color codes; use `sed` to strip them for clean output\n- **Rate limits**: `/runs` endpoint is limited to 30 requests/minute\n\n## Common Errors\n\n### 404 Not Found\n- Run ID doesn't exist OR you don't have permission\n- TFC returns 404 for both cases (security measure)\n\n### 401 Unauthorized\n- Token is invalid or expired\n- Organization tokens cannot access run data - use user/team token\n\n### No Apply Logs\n- Run may be plan-only, not yet applied, or discarded\n- Check run status first\n\n## See Also\n\n- `tfc-run-status`: Quick status check for a run\n- `tfc-list-runs`: List recent runs in a workspace\n- `tfc-plan-json`: Get structured plan JSON output"
              },
              {
                "name": "tfc-run-status",
                "description": "Quick status check for Terraform Cloud runs showing status, resource changes, timestamps, and available actions. Use when monitoring run progress or checking if a run can be applied/canceled. Requires TFE_TOKEN environment variable.",
                "path": "terraform-plugin/skills/tfc-run-status/SKILL.md",
                "frontmatter": {
                  "created": "2025-12-16T00:00:00.000Z",
                  "modified": "2025-12-16T00:00:00.000Z",
                  "reviewed": "2025-12-16T00:00:00.000Z",
                  "name": "tfc-run-status",
                  "description": "Quick status check for Terraform Cloud runs showing status, resource changes, timestamps, and available actions. Use when monitoring run progress or checking if a run can be applied/canceled. Requires TFE_TOKEN environment variable.",
                  "allowed-tools": "Bash, Read"
                },
                "content": "# Terraform Cloud Run Status\n\nQuick status check for Terraform Cloud runs with resource change counts, timestamps, and available actions.\n\n## Prerequisites\n\n```bash\nexport TFE_TOKEN=\"your-api-token\"        # User or team token\nexport TFE_ADDRESS=\"app.terraform.io\"    # Optional\n```\n\n## Core Commands\n\n### Complete Status Check\n\n```bash\n#!/bin/bash\nset -euo pipefail\n\nTOKEN=\"${TFE_TOKEN:?TFE_TOKEN not set}\"\nBASE_URL=\"https://${TFE_ADDRESS:-app.terraform.io}/api/v2\"\nRUN_ID=\"${1:?Usage: $0 <run-id>}\"\n\ncurl -sf --header \"Authorization: Bearer $TOKEN\" \\\n  \"$BASE_URL/runs/$RUN_ID?include=plan,apply,cost-estimate\" | \\\n  jq -r '\n    \"Run ID:      \" + .data.id,\n    \"Status:      \" + .data.attributes.status,\n    \"Message:     \" + (.data.attributes.message // \"No message\"),\n    \"Created:     \" + .data.attributes.\"created-at\",\n    \"Has Changes: \" + (.data.attributes.\"has-changes\" | tostring),\n    \"Auto-Apply:  \" + (.data.attributes.\"auto-apply\" | tostring),\n    \"\",\n    \"Resource Changes:\",\n    \"  Additions:    \" + ((.included[] | select(.type == \"plans\") | .attributes.\"resource-additions\") // 0 | tostring),\n    \"  Changes:      \" + ((.included[] | select(.type == \"plans\") | .attributes.\"resource-changes\") // 0 | tostring),\n    \"  Destructions: \" + ((.included[] | select(.type == \"plans\") | .attributes.\"resource-destructions\") // 0 | tostring),\n    \"\",\n    \"Actions:\",\n    \"  Confirmable:     \" + (.data.attributes.actions.\"is-confirmable\" | tostring),\n    \"  Cancelable:      \" + (.data.attributes.actions.\"is-cancelable\" | tostring),\n    \"  Discardable:     \" + (.data.attributes.actions.\"is-discardable\" | tostring),\n    \"  Force-Cancelable:\" + (.data.attributes.actions.\"is-force-cancelable\" | tostring)\n  '\n```\n\n### Quick Status Only\n\n```bash\nTOKEN=\"${TFE_TOKEN:?TFE_TOKEN not set}\"\nRUN_ID=\"run-abc123\"\n\ncurl -sf --header \"Authorization: Bearer $TFE_TOKEN\" \\\n  \"https://app.terraform.io/api/v2/runs/$RUN_ID\" | \\\n  jq -r '.data.attributes.status'\n```\n\n### Status with Timestamps\n\n```bash\ncurl -sf --header \"Authorization: Bearer $TFE_TOKEN\" \\\n  \"https://app.terraform.io/api/v2/runs/$RUN_ID\" | \\\n  jq -r '\n    .data.attributes |\n    \"Status: \" + .status,\n    \"Timestamps:\",\n    \"  Created:   \" + (.\"created-at\" // \"N/A\"),\n    \"  Planned:   \" + (.\"status-timestamps\".\"planned-at\" // \"N/A\"),\n    \"  Applied:   \" + (.\"status-timestamps\".\"applied-at\" // \"N/A\")\n  '\n```\n\n### Check Available Actions\n\n```bash\ncurl -sf --header \"Authorization: Bearer $TFE_TOKEN\" \\\n  \"https://app.terraform.io/api/v2/runs/$RUN_ID\" | \\\n  jq '.data.attributes.actions'\n```\n\n### Check Permissions\n\n```bash\ncurl -sf --header \"Authorization: Bearer $TFE_TOKEN\" \\\n  \"https://app.terraform.io/api/v2/runs/$RUN_ID\" | \\\n  jq '.data.attributes.permissions'\n```\n\n## Poll Until Complete\n\n```bash\n#!/bin/bash\nset -euo pipefail\n\nTOKEN=\"${TFE_TOKEN:?TFE_TOKEN not set}\"\nRUN_ID=\"${1:?Usage: $0 <run-id>}\"\n\nFINAL_STATES=\"applied planned_and_finished planned_and_saved discarded errored canceled force_canceled policy_soft_failed\"\n\nwhile true; do\n  STATUS=$(curl -sf --header \"Authorization: Bearer $TOKEN\" \\\n    \"https://app.terraform.io/api/v2/runs/$RUN_ID\" | \\\n    jq -r '.data.attributes.status')\n\n  echo \"$(date +%H:%M:%S) Status: $STATUS\"\n\n  if echo \"$FINAL_STATES\" | grep -qw \"$STATUS\"; then\n    echo \"Run completed with status: $STATUS\"\n    exit 0\n  fi\n\n  sleep 5\ndone\n```\n\n## JSON Output\n\n### Full Run Details\n\n```bash\ncurl -sf --header \"Authorization: Bearer $TFE_TOKEN\" \\\n  \"https://app.terraform.io/api/v2/runs/$RUN_ID\" | \\\n  jq '{\n    id: .data.id,\n    status: .data.attributes.status,\n    message: .data.attributes.message,\n    created_at: .data.attributes.\"created-at\",\n    has_changes: .data.attributes.\"has-changes\",\n    auto_apply: .data.attributes.\"auto-apply\",\n    is_destroy: .data.attributes.\"is-destroy\",\n    actions: .data.attributes.actions,\n    timestamps: .data.attributes.\"status-timestamps\"\n  }'\n```\n\n### With Cost Estimate\n\n```bash\ncurl -sf --header \"Authorization: Bearer $TFE_TOKEN\" \\\n  \"https://app.terraform.io/api/v2/runs/$RUN_ID?include=cost-estimate\" | \\\n  jq '\n    if .included then\n      (.included[] | select(.type == \"cost-estimates\")) as $ce |\n      {\n        status: .data.attributes.status,\n        cost: {\n          prior_monthly: $ce.attributes.\"prior-monthly-cost\",\n          proposed_monthly: $ce.attributes.\"proposed-monthly-cost\",\n          delta_monthly: $ce.attributes.\"delta-monthly-cost\"\n        }\n      }\n    else\n      {status: .data.attributes.status, cost: \"N/A\"}\n    end\n  '\n```\n\n## Run Status Reference\n\n### Final States (run completed)\n- `applied` - Successfully applied\n- `planned_and_finished` - Plan-only or no changes\n- `planned_and_saved` - Saved plan ready for confirmation\n- `discarded` - User discarded the run\n- `errored` - Run encountered an error\n- `canceled` - User canceled the run\n- `force_canceled` - Forcefully terminated\n- `policy_soft_failed` - Sentinel soft fail (plan-only)\n\n### Non-Final States (in progress)\n- `pending` - Initial state\n- `fetching` / `fetching_completed` - Retrieving config\n- `queuing` / `plan_queued` - Waiting for capacity\n- `planning` - Plan in progress\n- `planned` - Plan complete, awaiting confirmation\n- `cost_estimating` / `cost_estimated` - Cost estimation\n- `policy_checking` / `policy_checked` - Sentinel evaluation\n- `policy_override` - Soft fail, override available\n- `confirmed` - User confirmed the plan\n- `apply_queued` / `applying` - Apply in progress\n\n## Action States\n\n| Action | When Available |\n|--------|----------------|\n| `is-confirmable` | Status is `planned`, `cost_estimated`, `policy_checked`, or `policy_override` |\n| `is-cancelable` | Status is `planning` or `applying` |\n| `is-discardable` | Status is `pending`, `planned`, `cost_estimated`, `policy_checked`, or `policy_override` |\n| `is-force-cancelable` | Cancel was called and cooloff period elapsed |\n\n## See Also\n\n- `tfc-run-logs`: Get plan/apply logs for a run\n- `tfc-list-runs`: List recent runs in a workspace\n- `tfc-plan-json`: Get structured plan JSON output"
              },
              {
                "name": "tfc-workspace-runs",
                "description": "Convenience wrapper for listing Terraform Cloud runs in Forum Virium Helsinki\nworkspaces (github, sentry, gcp, onelogin, twingate). Requires TFE_TOKEN.\nUse when user mentions TFC runs, Terraform Cloud workspace, listing TFC runs,\ninfrastructure run history, or checking Terraform Cloud status.\n",
                "path": "terraform-plugin/skills/tfc-workspace-runs/SKILL.md",
                "frontmatter": {
                  "created": "2025-12-16T00:00:00.000Z",
                  "modified": "2025-12-16T00:00:00.000Z",
                  "reviewed": "2025-12-16T00:00:00.000Z",
                  "name": "tfc-workspace-runs",
                  "description": "Convenience wrapper for listing Terraform Cloud runs in Forum Virium Helsinki\nworkspaces (github, sentry, gcp, onelogin, twingate). Requires TFE_TOKEN.\nUse when user mentions TFC runs, Terraform Cloud workspace, listing TFC runs,\ninfrastructure run history, or checking Terraform Cloud status.\n",
                  "allowed-tools": "Bash, Read"
                },
                "content": "# Terraform Cloud Workspace Runs\n\nConvenience wrapper for quick access to runs in Forum Virium Helsinki Terraform Cloud workspaces.\n\n## Prerequisites\n\n```bash\nexport TFE_TOKEN=\"your-api-token\"        # User or team token\nexport TFE_ADDRESS=\"app.terraform.io\"    # Optional\n```\n\n## Known Workspaces\n\n| Shorthand | Full Workspace Name |\n|-----------|---------------------|\n| `github` | `infrastructure-github` |\n| `sentry` | `infrastructure-sentry` |\n| `gcp` | `infrastructure-gcp` |\n| `onelogin` | `infrastructure-onelogin` |\n| `twingate` | `infrastructure-twingate` |\n\n## Core Commands\n\n### Quick List Runs\n\n```bash\n#!/bin/bash\nset -euo pipefail\n\nTOKEN=\"${TFE_TOKEN:?TFE_TOKEN not set}\"\nBASE_URL=\"https://${TFE_ADDRESS:-app.terraform.io}/api/v2\"\nORG=\"ForumViriumHelsinki\"\n\n# Map shorthand to full workspace name\ncase \"${1:-}\" in\n  github)   WORKSPACE=\"infrastructure-github\" ;;\n  sentry)   WORKSPACE=\"infrastructure-sentry\" ;;\n  gcp)      WORKSPACE=\"infrastructure-gcp\" ;;\n  onelogin) WORKSPACE=\"infrastructure-onelogin\" ;;\n  twingate) WORKSPACE=\"infrastructure-twingate\" ;;\n  *)\n    echo \"Usage: $0 <workspace> [limit]\"\n    echo \"Workspaces: github, sentry, gcp, onelogin, twingate\"\n    exit 1\n    ;;\nesac\n\nLIMIT=\"${2:-10}\"\n\n# Get workspace ID\nWS_ID=$(curl -sf --header \"Authorization: Bearer $TOKEN\" \\\n  \"$BASE_URL/organizations/$ORG/workspaces/$WORKSPACE\" | \\\n  jq -r '.data.id')\n\n# List runs\necho \"Recent runs for $WORKSPACE:\"\necho \"\"\n\ncurl -sf --header \"Authorization: Bearer $TOKEN\" \\\n  \"$BASE_URL/workspaces/$WS_ID/runs?page[size]=$LIMIT&include=plan\" | \\\n  jq -r '\n    [\"RUN_ID\", \"STATUS\", \"+\", \"~\", \"-\", \"CREATED\", \"MESSAGE\"],\n    (.data[] |\n      .relationships.plan.data.id as $pid |\n      [\n        .id,\n        .attributes.status,\n        ((.included[] | select(.id == $pid) | .attributes.\"resource-additions\") // 0 | tostring),\n        ((.included[] | select(.id == $pid) | .attributes.\"resource-changes\") // 0 | tostring),\n        ((.included[] | select(.id == $pid) | .attributes.\"resource-destructions\") // 0 | tostring),\n        .attributes.\"created-at\"[0:16],\n        (.attributes.message // \"No message\")[0:30]\n      ]\n    ) | @tsv' | column -t\n```\n\n### One-Liner Examples\n\n```bash\n# GCP workspace - recent runs\ncurl -sf -H \"Authorization: Bearer $TFE_TOKEN\" \\\n  \"https://app.terraform.io/api/v2/organizations/ForumViriumHelsinki/workspaces/infrastructure-gcp\" | \\\n  jq -r '.data.id' | \\\n  xargs -I{} curl -sf -H \"Authorization: Bearer $TFE_TOKEN\" \\\n    \"https://app.terraform.io/api/v2/workspaces/{}/runs?page[size]=5\" | \\\n  jq -r '.data[] | \"\\(.id) | \\(.attributes.status) | \\(.attributes.\"created-at\"[0:16])\"'\n\n# GitHub workspace - failed runs only\ncurl -sf -H \"Authorization: Bearer $TFE_TOKEN\" \\\n  \"https://app.terraform.io/api/v2/organizations/ForumViriumHelsinki/workspaces/infrastructure-github\" | \\\n  jq -r '.data.id' | \\\n  xargs -I{} curl -sf -H \"Authorization: Bearer $TFE_TOKEN\" \\\n    \"https://app.terraform.io/api/v2/workspaces/{}/runs?filter[status]=errored\" | \\\n  jq -r '.data[] | \"\\(.id) | \\(.attributes.status) | \\(.attributes.message)\"'\n```\n\n### Get Latest Run for Each Workspace\n\n```bash\n#!/bin/bash\nset -euo pipefail\n\nTOKEN=\"${TFE_TOKEN:?TFE_TOKEN not set}\"\nBASE_URL=\"https://${TFE_ADDRESS:-app.terraform.io}/api/v2\"\nORG=\"ForumViriumHelsinki\"\n\nWORKSPACES=\"infrastructure-github infrastructure-sentry infrastructure-gcp infrastructure-onelogin infrastructure-twingate\"\n\necho \"Latest run for each workspace:\"\necho \"\"\n\nfor WS in $WORKSPACES; do\n  WS_ID=$(curl -sf --header \"Authorization: Bearer $TOKEN\" \\\n    \"$BASE_URL/organizations/$ORG/workspaces/$WS\" | jq -r '.data.id')\n\n  LATEST=$(curl -sf --header \"Authorization: Bearer $TOKEN\" \\\n    \"$BASE_URL/workspaces/$WS_ID/runs?page[size]=1\" | \\\n    jq -r '.data[0] | \"\\(.id) | \\(.attributes.status) | \\(.attributes.\"created-at\"[0:16])\"')\n\n  echo \"$WS: $LATEST\"\ndone\n```\n\n### Check for In-Progress Runs\n\n```bash\n#!/bin/bash\nset -euo pipefail\n\nTOKEN=\"${TFE_TOKEN:?TFE_TOKEN not set}\"\nBASE_URL=\"https://${TFE_ADDRESS:-app.terraform.io}/api/v2\"\nORG=\"ForumViriumHelsinki\"\n\nWORKSPACES=\"infrastructure-github infrastructure-sentry infrastructure-gcp infrastructure-onelogin infrastructure-twingate\"\n\necho \"Checking for in-progress runs...\"\necho \"\"\n\nfor WS in $WORKSPACES; do\n  WS_ID=$(curl -sf --header \"Authorization: Bearer $TOKEN\" \\\n    \"$BASE_URL/organizations/$ORG/workspaces/$WS\" | jq -r '.data.id')\n\n  IN_PROGRESS=$(curl -sf --header \"Authorization: Bearer $TOKEN\" \\\n    \"$BASE_URL/workspaces/$WS_ID/runs?filter[status_group]=non_final&page[size]=5\" | \\\n    jq -r '.data | length')\n\n  if [ \"$IN_PROGRESS\" -gt 0 ]; then\n    echo \"$WS: $IN_PROGRESS run(s) in progress\"\n    curl -sf --header \"Authorization: Bearer $TOKEN\" \\\n      \"$BASE_URL/workspaces/$WS_ID/runs?filter[status_group]=non_final\" | \\\n      jq -r '.data[] | \"  - \\(.id): \\(.attributes.status)\"'\n  fi\ndone\n```\n\n## Quick Reference\n\n### Get Workspace ID\n\n```bash\n# Generic pattern\ncurl -sf -H \"Authorization: Bearer $TFE_TOKEN\" \\\n  \"https://app.terraform.io/api/v2/organizations/ForumViriumHelsinki/workspaces/infrastructure-gcp\" | \\\n  jq -r '.data.id'\n```\n\n### Workspace URLs (for reference)\n\n- **GitHub**: https://app.terraform.io/app/ForumViriumHelsinki/workspaces/infrastructure-github\n- **Sentry**: https://app.terraform.io/app/ForumViriumHelsinki/workspaces/infrastructure-sentry\n- **GCP**: https://app.terraform.io/app/ForumViriumHelsinki/workspaces/infrastructure-gcp\n- **OneLogin**: https://app.terraform.io/app/ForumViriumHelsinki/workspaces/infrastructure-onelogin\n- **Twingate**: https://app.terraform.io/app/ForumViriumHelsinki/workspaces/infrastructure-twingate\n\n## Integration with Other Skills\n\n### Get logs for latest GCP run\n\n```bash\n# Get latest run ID\nRUN_ID=$(curl -sf -H \"Authorization: Bearer $TFE_TOKEN\" \\\n  \"https://app.terraform.io/api/v2/organizations/ForumViriumHelsinki/workspaces/infrastructure-gcp\" | \\\n  jq -r '.data.id' | \\\n  xargs -I{} curl -sf -H \"Authorization: Bearer $TFE_TOKEN\" \\\n    \"https://app.terraform.io/api/v2/workspaces/{}/runs?page[size]=1\" | \\\n  jq -r '.data[0].id')\n\n# Then use tfc-run-logs skill to get logs\necho \"Use tfc-run-logs with run ID: $RUN_ID\"\n```\n\n### Quick status check for all workspaces\n\n```bash\n# Combine with tfc-run-status for detailed info on specific runs\n```\n\n## Customization\n\nTo add more workspaces, update the case statement in the script:\n\n```bash\ncase \"${1:-}\" in\n  github)   WORKSPACE=\"infrastructure-github\" ;;\n  sentry)   WORKSPACE=\"infrastructure-sentry\" ;;\n  gcp)      WORKSPACE=\"infrastructure-gcp\" ;;\n  onelogin) WORKSPACE=\"infrastructure-onelogin\" ;;\n  twingate) WORKSPACE=\"infrastructure-twingate\" ;;\n  # Add more here:\n  newworkspace) WORKSPACE=\"infrastructure-newworkspace\" ;;\n  *)\n    echo \"Usage: $0 <workspace>\"\n    exit 1\n    ;;\nesac\n```\n\n## See Also\n\n- `tfc-list-runs`: Full-featured run listing with all filters\n- `tfc-run-logs`: Get plan/apply logs for a specific run\n- `tfc-run-status`: Quick status check for a run\n- `tfc-plan-json`: Get structured plan JSON output\n- `terraform-workspace-manager`: Workspace orchestration and run management"
              }
            ]
          },
          {
            "name": "github-actions-plugin",
            "description": "GitHub Actions CI/CD - workflows, authentication, inspection",
            "source": "./github-actions-plugin",
            "category": "ci-cd",
            "version": "1.0.1",
            "author": null,
            "install_commands": [
              "/plugin marketplace add laurigates/claude-plugins",
              "/plugin install github-actions-plugin@lgates-claude-plugins"
            ],
            "signals": {
              "stars": 1,
              "forks": 0,
              "pushed_at": "2026-01-12T12:05:51Z",
              "created_at": "2025-12-16T11:24:04Z",
              "license": null
            },
            "commands": [],
            "skills": []
          },
          {
            "name": "documentation-plugin",
            "description": "Documentation generation - API docs, README, knowledge graphs",
            "source": "./documentation-plugin",
            "category": "documentation",
            "version": "1.0.0",
            "author": null,
            "install_commands": [
              "/plugin marketplace add laurigates/claude-plugins",
              "/plugin install documentation-plugin@lgates-claude-plugins"
            ],
            "signals": {
              "stars": 1,
              "forks": 0,
              "pushed_at": "2026-01-12T12:05:51Z",
              "created_at": "2025-12-16T11:24:04Z",
              "license": null
            },
            "commands": [],
            "skills": [
              {
                "name": "claude-blog-sources",
                "description": "Access Claude Blog for latest Claude Code improvements, usage patterns, and best practices.\nUse when researching Claude Code features, CLAUDE.md optimization, or staying current with\nClaude capabilities. Checks recent articles for relevant updates and patterns.\n",
                "path": "documentation-plugin/skills/claude-blog-sources/SKILL.md",
                "frontmatter": {
                  "created": "2025-12-16T00:00:00.000Z",
                  "modified": "2025-12-16T00:00:00.000Z",
                  "reviewed": "2025-12-16T00:00:00.000Z",
                  "name": "claude-blog-sources",
                  "description": "Access Claude Blog for latest Claude Code improvements, usage patterns, and best practices.\nUse when researching Claude Code features, CLAUDE.md optimization, or staying current with\nClaude capabilities. Checks recent articles for relevant updates and patterns.\n",
                  "allowed-tools": "WebFetch, WebSearch, Task"
                },
                "content": "# Claude Blog Sources\n\n## Overview\n\nThe Anthropic Claude Blog (https://www.claude.com/blog/) publishes official guidance on Claude Code features, usage patterns, and best practices. This skill provides structured access to blog content for staying current with Claude capabilities.\n\n## Primary Blog URL\n\n**Main Blog**: https://www.claude.com/blog/\n\nNote: May redirect to https://website.claude.com/blog - follow redirects automatically.\n\n## Key Articles for Claude Code\n\n### Essential Reading\n\n| Article | URL | Topic |\n|---------|-----|-------|\n| Using CLAUDE.md Files | /blog/using-claude-md-files | CLAUDE.md structure and best practices |\n| How Anthropic Teams Use Claude Code | /blog/how-anthropic-teams-use-claude-code | Internal usage patterns and workflows |\n| Claude Code on the Web | /blog/claude-code-on-the-web | Web-based features and capabilities |\n\n### Article Relevance Categories\n\n**High Relevance** (always check):\n- Articles mentioning \"CLAUDE.md\", \"Claude Code\", \"Skills\", \"Agents\"\n- Articles about coding workflows, development practices\n- Product announcements for Claude Code features\n\n**Medium Relevance** (check if applicable):\n- Articles about prompt engineering, context management\n- Enterprise AI deployment patterns\n- Integration guides (Slack, GitHub, etc.)\n\n## Research Workflow\n\n### When User Asks About Claude Code Features\n\n1. **Check Recent Articles First**\n   ```\n   WebSearch: site:claude.com/blog {feature_name} OR \"Claude Code\"\n   ```\n\n2. **Fetch Relevant Articles**\n   ```\n   WebFetch: https://www.claude.com/blog/{article-slug}\n   Prompt: Extract practical guidance, examples, and best practices for {topic}\n   ```\n\n3. **Cross-Reference with Documentation**\n   - Official docs: https://docs.claude.com/en/docs/claude-code/\n   - Compare blog insights with documentation\n\n### Monthly Article Review Process\n\nFor staying current with Claude improvements:\n\n1. **Fetch Blog Index**\n   ```\n   WebFetch: https://www.claude.com/blog/\n   Prompt: List all articles from the past month with titles, dates, and relevance to Claude Code\n   ```\n\n2. **Triage by Relevance**\n   - High: Directly mentions Claude Code, CLAUDE.md, Skills, or Agents\n   - Medium: General AI coding patterns, prompt engineering\n   - Low: Unrelated topics (enterprise, safety research, etc.)\n\n3. **Extract Key Insights**\n   For high-relevance articles, extract:\n   - New features or capabilities\n   - Updated best practices\n   - Example patterns and workflows\n   - Configuration recommendations\n\n4. **Update Local Knowledge**\n   - Consider updating relevant Skills with new patterns\n   - Update CLAUDE.md files with new best practices\n   - Create new Skills for newly documented features\n\n## CLAUDE.md Best Practices (from Blog)\n\nBased on the official blog post on CLAUDE.md files:\n\n### Structure Guidelines\n\n- **Keep concise**: Treat as documentation both humans and Claude need to understand quickly\n- **Strategic placement**: Root for team-wide, parent dirs for monorepos, home folder for universal\n- **Break into files**: Large information should be in separate markdown files, referenced from CLAUDE.md\n\n### Essential Sections\n\n1. **Project Overview**: Brief summary, key technologies, architectural patterns\n2. **Directory Map**: Visual hierarchy showing key directories\n3. **Standards & Conventions**: Type hints, code style, naming conventions\n4. **Common Commands**: Frequently-used commands with descriptions\n5. **Workflows**: Standard approaches for different task types\n6. **Tool Integration**: MCP servers, custom tools with usage examples\n\n### What to Avoid\n\n- Sensitive information (API keys, credentials, connection strings)\n- Excessive length (keep concise from context engineering perspective)\n- Theoretical content not matching actual development reality\n\n### Evolution Strategy\n\n- Start simple, expand deliberately\n- Add sections based on real friction points\n- Maintain as living document that evolves with codebase\n\n## Delegation Pattern\n\nWhen research requires deep investigation:\n\n```markdown\nUse research-documentation agent for:\n- Comprehensive blog article analysis\n- Cross-referencing multiple sources\n- Building knowledge summaries\n\nExample delegation prompt:\n\"Research the Claude blog for articles about {topic} from the past 3 months.\nExtract practical patterns and update recommendations. Focus on:\n- New features or capabilities\n- Changed best practices\n- Concrete examples we can apply\"\n```\n\n## Recent Articles Checklist\n\n*Last reviewed: November 2025. Update this list monthly when reviewing new articles.*\n\nArticles worth checking (sorted by relevance to Claude Code):\n\n- [ ] /blog/using-claude-md-files - CLAUDE.md best practices\n- [ ] /blog/how-anthropic-teams-use-claude-code - Internal usage patterns\n- [ ] /blog/improving-frontend-design-through-skills - Skills feature\n- [ ] /blog/claude-code-on-the-web - Web-based features\n\n## Integration with Other Skills\n\nThis skill complements:\n- **project-discovery**: Use blog patterns for new codebase orientation\n- **blueprint-development**: Apply latest CLAUDE.md best practices to PRDs\n- **multi-agent-workflows**: Incorporate blog-recommended delegation patterns"
              }
            ]
          },
          {
            "name": "project-plugin",
            "description": "Project initialization and management - setup, modernization, and continuous development workflows",
            "source": "./project-plugin",
            "category": "development",
            "version": "1.2.1",
            "author": null,
            "install_commands": [
              "/plugin marketplace add laurigates/claude-plugins",
              "/plugin install project-plugin@lgates-claude-plugins"
            ],
            "signals": {
              "stars": 1,
              "forks": 0,
              "pushed_at": "2026-01-12T12:05:51Z",
              "created_at": "2025-12-16T11:24:04Z",
              "license": null
            },
            "commands": [],
            "skills": [
              {
                "name": "project-discovery",
                "description": "Systematic project orientation for unfamiliar codebases. Automatically activates when Claude detects uncertainty about project state, structure, or tooling. Analyzes git state (branch, changes, commits), project type (language, framework, structure), and development tooling (build, test, lint, CI/CD). Provides structured summary with risk flags and recommendations. Use when entering new projects or when working on shaky assumptions.",
                "path": "project-plugin/skills/project-discovery/SKILL.md",
                "frontmatter": {
                  "created": "2025-12-16T00:00:00.000Z",
                  "modified": "2025-12-16T00:00:00.000Z",
                  "reviewed": "2025-12-16T00:00:00.000Z",
                  "name": "project-discovery",
                  "description": "Systematic project orientation for unfamiliar codebases. Automatically activates when Claude detects uncertainty about project state, structure, or tooling. Analyzes git state (branch, changes, commits), project type (language, framework, structure), and development tooling (build, test, lint, CI/CD). Provides structured summary with risk flags and recommendations. Use when entering new projects or when working on shaky assumptions.",
                  "allowed-tools": "Bash, Read, Grep, Glob, TodoWrite"
                },
                "content": "# Project Discovery\n\nSystematic project orientation to understand codebase state before making changes. Prevents working on incorrect assumptions by establishing clear context about git state, project structure, and development tooling.\n\n## Core Expertise\n\n**Automatic Activation Detection:**\n- Detects uncertainty in Claude's reasoning or responses\n- Activates on manual user requests for orientation\n- Focuses on git repositories only\n\n**Discovery Capabilities:**\n- Git state analysis (branch, changes, remote sync, commit history)\n- Project type identification (language, framework, monorepo detection)\n- Development tooling discovery (build, test, lint, CI/CD)\n- Documentation quick scan (README, setup instructions)\n- Risk flag identification (uncommitted work, branch divergence)\n\n**Output:**\n- Structured summary of project state\n- Critical risk flags highlighted\n- Actionable next-step recommendations\n- 2-3 minute discovery timeframe\n\n## When This Skill Activates\n\n### Automatic Triggers\n\nThis skill automatically activates when Claude's internal reasoning or responses contain uncertainty phrases like:\n\n- \"I should first understand...\"\n- \"Let me check the project...\"\n- \"Not sure about the structure...\"\n- \"I need to understand...\"\n- \"Before proceeding, let me...\"\n- \"I'm uncertain about...\"\n- \"Let me investigate the project...\"\n\n**Rationale:** These phrases indicate Claude is working on incomplete context, which can lead to incorrect assumptions, wrong commands, or inappropriate file edits.\n\n### Manual Invocation\n\nUsers can explicitly request project discovery with keywords:\n\n- \"orient yourself\"\n- \"discover the project\"\n- \"understand this codebase\"\n- \"what's the project state?\"\n- \"analyze the project structure\"\n- \"give me project context\"\n\n### When NOT to Activate\n\nDo NOT activate this skill when:\n- Claude has clear context and is confidently executing a specific task\n- User is asking about specific code that Claude has already analyzed\n- Current conversation already established project context\n- Working in a non-git directory (this skill is git-focused)\n\n## Systematic Discovery Workflow\n\nWhen activated, follow this 5-phase systematic discovery process. Complete all phases before providing the summary.\n\n---\n\n### Phase 1: Git State Analysis\n\n**Goal:** Understand version control state to prevent data loss and branch confusion.\n\n**Commands to Run:**\n\n```bash\n# Current branch and tracking info\ngit branch --show-current\ngit status --short --branch\n\n# Uncommitted changes summary\ngit status --porcelain | wc -l\ngit diff --stat\ngit diff --staged --stat\n\n# Remote sync status\ngit rev-list --left-right --count HEAD...@{u} 2>/dev/null || echo \"No tracking branch\"\n\n# Recent commit history (last 10 commits)\ngit log --oneline --decorate -n 10\n\n# Check for conventional commits pattern\ngit log --oneline -n 20 | grep -E \"^[a-f0-9]+ (feat|fix|docs|style|refactor|test|chore|build|ci|perf|revert)(\\(.+\\))?:\"\n```\n\n**What to Extract:**\n- Current branch name\n- Number of uncommitted files (staged + unstaged)\n- Number of commits ahead/behind remote\n- Recent commit messages (look for patterns, conventional commits)\n- Last commit author and date\n- Whether working tree is clean\n\n**Risk Flags:**\n-  Uncommitted changes exist (risk of data loss)\n-  Branch diverged from remote (conflicts possible)\n-  On main/master branch (should work on feature branch)\n-  Detached HEAD state (not on any branch)\n\n---\n\n### Phase 2: Project Type Detection\n\n**Goal:** Identify language, framework, and project structure to use correct tooling.\n\n**Commands to Run:**\n\n```bash\n# Check for project manifests (determines language/ecosystem)\nls -la | grep -E \"(package\\.json|Cargo\\.toml|pyproject\\.toml|go\\.mod|Gemfile|pom\\.xml|build\\.gradle|composer\\.json|mix\\.exs)\"\n\n# Detect monorepo structure\nfind . -maxdepth 3 -name \"package.json\" -o -name \"Cargo.toml\" -o -name \"pyproject.toml\" | head -20\n\n# Check directory structure\nls -d */ 2>/dev/null | head -20\n\n# Find entry points (main files)\nfind . -maxdepth 2 -name \"main.*\" -o -name \"index.*\" -o -name \"app.*\" -o -name \"__init__.py\" 2>/dev/null | head -10\n```\n\n**Project Manifest Detection:**\n\n| File | Language/Ecosystem | Common Frameworks |\n|------|-------------------|-------------------|\n| `package.json` | JavaScript/TypeScript | React, Vue, Next.js, Express, Node |\n| `Cargo.toml` | Rust | Actix, Rocket, Tokio |\n| `pyproject.toml` | Python | Django, FastAPI, Flask |\n| `go.mod` | Go | Gin, Echo, Fiber |\n| `Gemfile` | Ruby | Rails, Sinatra |\n| `pom.xml` / `build.gradle` | Java | Spring, Quarkus |\n| `composer.json` | PHP | Laravel, Symfony |\n| `mix.exs` | Elixir | Phoenix |\n\n**What to Extract:**\n- Primary language(s) and version(s)\n- Framework detected (check package.json dependencies, Cargo.toml deps, etc.)\n- Monorepo vs single-project (multiple manifests = monorepo)\n- Common directory patterns (src/, lib/, tests/, docs/)\n- Entry point files\n\n**Additional Framework Detection:**\n\n```bash\n# JavaScript/TypeScript frameworks\ngrep -E \"(react|vue|next|nuxt|svelte|angular|express|fastify|nest)\" package.json 2>/dev/null\n\n# Python frameworks\ngrep -E \"(django|fastapi|flask|pyramid)\" pyproject.toml 2>/dev/null\n\n# Check for specific config files\nls | grep -E \"(next\\.config|vite\\.config|webpack\\.config|tsconfig|jest\\.config|pytest\\.ini|setup\\.py)\"\n```\n\n---\n\n### Phase 3: Development Tooling Discovery\n\n**Goal:** Identify build system, test framework, linters, and CI/CD to run correct commands.\n\n**Commands to Run:**\n\n```bash\n# Build system detection\nls -la | grep -E \"(Makefile|Justfile|package\\.json|Cargo\\.toml|pyproject\\.toml)\"\n\n# Check package.json scripts (if JS/TS project)\njq -r '.scripts | keys[]' package.json 2>/dev/null | head -20\n\n# Check Makefile targets\ngrep \"^[a-zA-Z0-9_-]*:\" Makefile 2>/dev/null | cut -d: -f1 | head -20\n\n# Test framework detection\nfind . -maxdepth 3 -name \"*test*\" -o -name \"*spec*\" 2>/dev/null | grep -E \"\\.(js|ts|py|rs|go)$\" | head -10\n\n# Linter/formatter detection\nls -la | grep -E \"(\\.eslintrc|\\.prettierrc|ruff\\.toml|\\.flake8|rustfmt\\.toml|\\.golangci)\"\n\n# Pre-commit hooks\nls -la .git/hooks/ 2>/dev/null | grep -v sample\ncat .pre-commit-config.yaml 2>/dev/null | head -20\n\n# CI/CD detection\nls -la .github/workflows/ 2>/dev/null | grep \"\\.yml\"\nls -la .gitlab-ci.yml 2>/dev/null\nls -la .circleci/config.yml 2>/dev/null\n```\n\n**What to Extract:**\n\n**Build System:**\n- npm scripts (if package.json)\n- Make targets (if Makefile)\n- Cargo commands (if Rust)\n- Python build tools (setuptools, poetry, hatchling)\n\n**Test Framework:**\n- Jest, Vitest, Mocha (JS/TS)\n- pytest, unittest (Python)\n- cargo test (Rust)\n- go test (Go)\n- Test file naming conventions\n\n**Linters/Formatters:**\n- ESLint, Prettier (JS/TS)\n- ruff, black, flake8 (Python)\n- clippy, rustfmt (Rust)\n- golangci-lint (Go)\n\n**Pre-commit Hooks:**\n- Present or absent\n- Configured tools (from .pre-commit-config.yaml)\n\n**CI/CD:**\n- GitHub Actions (list workflow files)\n- GitLab CI\n- CircleCI\n- Other CI systems\n\n---\n\n### Phase 4: Documentation Quick Scan\n\n**Goal:** Understand project purpose and setup requirements from documentation.\n\n**Commands to Run:**\n\n```bash\n# README first section (project purpose)\nhead -50 README.md 2>/dev/null\n\n# Check for common documentation files\nls -la | grep -E \"(README|CONTRIBUTING|CHANGELOG|LICENSE|ARCHITECTURE|docs/)\"\n\n# Look for setup/installation instructions in README\ngrep -A 10 -i \"install\\|setup\\|getting started\" README.md 2>/dev/null | head -30\n\n# Check for documentation directory\nls -la docs/ 2>/dev/null | head -20\n```\n\n**What to Extract:**\n- Project name and one-sentence description\n- Primary purpose (web app, library, tool, etc.)\n- Key features or capabilities\n- Setup/installation instructions present?\n- CONTRIBUTING.md exists? (indicates contributor guidance)\n- Documentation directory structure\n\n**Documentation Quality Indicators:**\n-  README with clear description and setup steps\n-  CONTRIBUTING.md (good for contributions)\n-  CHANGELOG.md (indicates release management)\n-  docs/ directory (comprehensive documentation)\n-  Missing README or minimal content\n-  No setup instructions\n\n---\n\n### Phase 5: State Summary & Recommendations\n\n**Goal:** Synthesize all findings into actionable summary with risk flags.\n\n**Output Format Template:**\n\n```markdown\n# Project Discovery Summary\n\n##  Project Overview\n- **Type**: [Language] / [Framework] / [Monorepo or Single-project]\n- **Purpose**: [One-sentence description from README]\n- **Entry Point**: [Main file or startup command]\n\n##  Git State\n- **Branch**: [current-branch-name]\n- **Status**: [X files changed, Y staged, Z unstaged] OR [Working tree clean]\n- **Remote Sync**: [X commits ahead, Y commits behind] OR [In sync with origin]\n- **Last Commit**: [Hash] - [Message] by [Author] ([Time ago])\n- **Commit Style**: [Conventional commits detected] OR [Free-form commits]\n\n###  Risk Flags\n[List any risk flags found in Phase 1, or state \"None - safe to proceed\"]\n\n##  Development Tooling\n\n### Build System\n- [Build command: npm run build / cargo build / make / etc.]\n\n### Test Framework\n- [Test command: npm test / pytest / cargo test / etc.]\n- [Test file location: tests/ or src/__tests__/ or *_test.rs]\n\n### Code Quality\n- **Linters**: [ESLint / ruff / clippy / etc.]\n- **Formatters**: [Prettier / black / rustfmt / etc.]\n- **Pre-commit Hooks**: [Configured] OR [Not configured]\n\n### CI/CD\n- [GitHub Actions: X workflows] OR [No CI/CD detected]\n- [Workflows: build.yml, test.yml, deploy.yml]\n\n##  Documentation\n- **README**: [Present with setup instructions] OR [Missing or minimal]\n- **CONTRIBUTING**: [Present] OR [Not present]\n- **Other Docs**: [docs/ directory, ARCHITECTURE.md, etc.]\n\n##  Recommendations\n\n[Based on findings, provide 2-4 actionable recommendations, such as:]\n\n1. **Commit uncommitted work** - You have X unstaged files that could be lost\n2. **Create feature branch** - Currently on main; create a feature branch before making changes\n3. **Pull latest changes** - X commits behind origin/main\n4. **Run tests before changes** - Use `[test-command]` to establish baseline\n5. **Review setup instructions** - Check README.md for dependencies and setup steps\n6. **Safe to proceed** - Working tree clean, branch in sync, tooling detected\n\n---\n\n**Discovery completed in [time]. Ready to work with clear context.**\n```\n\n**Risk Flag Priority:**\n-  **Critical**: Uncommitted changes + on main branch + behind remote\n-  **Warning**: Any single risk flag (uncommitted changes, diverged branch, etc.)\n-  **Safe**: Clean working tree, feature branch, in sync with remote\n\n---\n\n## Integration with Other Skills\n\n### Related Skills\n- **git-commit-workflow**: Use after discovering conventional commit patterns\n- **chezmoi-expert**: If project is a dotfiles repo (detects chezmoi.toml)\n- **git-security-checks**: Run if pre-commit hooks detected\n- **Explore agent**: Delegate to this agent if deeper codebase exploration needed beyond initial orientation\n\n### When to Delegate\nAfter project discovery, if user asks for deeper investigation:\n- \"How does authentication work?\"  Use `Explore` agent\n- \"Review this code for security\"  Use `security-audit` agent\n- \"Understand the architecture\"  Use `code-analysis` agent\n\nProject discovery establishes **baseline context**; specialized skills handle **deep investigation**.\n\n---\n\n## Error Handling & Edge Cases\n\n### Non-Git Directory\nIf `git status` fails (not a git repository):\n\n```markdown\n **Not a Git Repository**\n\nThis skill is designed for git repositories only. This directory does not have a `.git` folder.\n\n**Recommendations:**\n1. Initialize git: `git init`\n2. Or navigate to a git repository\n3. Or use manual exploration tools (ls, find, etc.) for non-git projects\n```\n\n### Empty Repository\nIf git repo exists but has no commits:\n\n```markdown\n **Empty Git Repository**\n\nThis is a newly initialized git repository with no commits yet.\n\n**Recommendations:**\n1. Make initial commit to establish git history\n2. Check README.md for project purpose (if exists)\n3. Proceed with caution - no version history to reference\n```\n\n### Large Monorepo Performance\nIf discovery takes >30 seconds (e.g., huge monorepo):\n\n```markdown\n **Large Repository Detected**\n\nDiscovery is taking longer than expected. For large monorepos, consider:\n\n1. **Focus on specific subdirectory**: Navigate to relevant sub-project first\n2. **Use targeted exploration**: Ask specific questions rather than full discovery\n3. **Check monorepo docs**: Often have READMEs explaining structure\n```\n\n### Missing Documentation\nIf no README.md or minimal content:\n\n```markdown\n **Documentation Sparse**\n\nNo README.md found or content is minimal.\n\n**Recommendations:**\n1. Check commit messages for context about project purpose\n2. Examine directory structure and entry points\n3. Look for inline code comments\n4. Ask user for project context if available\n```\n\n---\n\n## Best Practices\n\n### Before Making Any Changes\n1. **Always run project discovery** when entering an unfamiliar codebase\n2. **Check git state** to preserve uncommitted work\n3. **Identify tooling** to use correct build/test commands\n4. **Read README** for setup requirements and project conventions\n\n### Discovery Efficiency\n1. **Complete all 5 phases** even if early phases reveal issues (comprehensive context prevents follow-up questions)\n2. **Highlight risk flags** prominently in summary\n3. **Provide actionable recommendations** specific to the project state\n4. **Keep discovery focused** (2-3 minutes; defer deep investigation to specialized skills)\n\n### Integration with Workflow\n1. **Discovery first, then action** - Establish context before editing files\n2. **Update mental model** - If discovery reveals surprises, re-evaluate planned approach\n3. **Respect git state** - Don't ignore risk flags; address them before proceeding\n\n---\n\n## Quick Reference: Discovery Commands\n\n### Essential Git Commands\n```bash\ngit branch --show-current                     # Current branch\ngit status --short --branch                   # Git state summary\ngit log --oneline -n 10                       # Recent commits\ngit rev-list --count HEAD...@{u}              # Commits ahead/behind remote\n```\n\n### Project Type Detection\n```bash\nls -la | grep -E \"(package\\.json|Cargo\\.toml|pyproject\\.toml|go\\.mod)\"\nfind . -maxdepth 3 -name \"package.json\"       # Monorepo detection\n```\n\n### Tooling Discovery\n```bash\njq -r '.scripts | keys[]' package.json        # npm scripts\ngrep \"^[a-zA-Z0-9_-]*:\" Makefile              # Make targets\nls -la .github/workflows/                      # GitHub Actions\n```\n\n### Documentation Scan\n```bash\nhead -50 README.md                            # Project description\nls -la | grep -E \"(README|CONTRIBUTING)\"      # Key docs\n```\n\n---\n\n## Example Output\n\nSee `examples.md` for complete discovery outputs for:\n- Python project with pytest + ruff + GitHub Actions\n- JavaScript/TypeScript project with npm + ESLint + Vitest\n- Rust project with cargo + clippy + no CI\n- Monorepo with multiple sub-projects\n- Project with uncommitted changes (risk flags)\n- Clean project ready for work\n\n---\n\n## Rationale: Why Systematic Discovery Matters\n\n**Problem:** Claude often works on incomplete assumptions:\n- Editing wrong branch\n- Using incorrect build commands\n- Overwriting uncommitted work\n- Missing critical tooling (tests, linters)\n\n**Solution:** Systematic orientation establishes:\n-  Clear git state (prevent data loss)\n-  Correct project type (use right tools)\n-  Available tooling (run proper commands)\n-  Risk awareness (flag dangerous states)\n\n**Result:** Confident, accurate work on solid foundation rather than shaky assumptions.\n\n---\n\n*For detailed command reference and more examples, see `discovery-commands.md` and `examples.md`.*"
              }
            ]
          },
          {
            "name": "sync-plugin",
            "description": "External system synchronization - GitHub, Podio integration",
            "source": "./sync-plugin",
            "category": "integration",
            "version": "1.0.0",
            "author": null,
            "install_commands": [
              "/plugin marketplace add laurigates/claude-plugins",
              "/plugin install sync-plugin@lgates-claude-plugins"
            ],
            "signals": {
              "stars": 1,
              "forks": 0,
              "pushed_at": "2026-01-12T12:05:51Z",
              "created_at": "2025-12-16T11:24:04Z",
              "license": null
            },
            "commands": [],
            "skills": []
          },
          {
            "name": "agent-patterns-plugin",
            "description": "Multi-agent coordination and orchestration patterns",
            "source": "./agent-patterns-plugin",
            "category": "ai",
            "version": "2.0.1",
            "author": null,
            "install_commands": [
              "/plugin marketplace add laurigates/claude-plugins",
              "/plugin install agent-patterns-plugin@lgates-claude-plugins"
            ],
            "signals": {
              "stars": 1,
              "forks": 0,
              "pushed_at": "2026-01-12T12:05:51Z",
              "created_at": "2025-12-16T11:24:04Z",
              "license": null
            },
            "commands": [
              {
                "name": "/check-negative-examples",
                "description": "Check skills/commands for negative framing and suggest positive alternatives",
                "path": "agent-patterns-plugin/commands/check-negative-examples.md",
                "frontmatter": {
                  "created": "2025-12-16T00:00:00.000Z",
                  "modified": "2025-12-16T00:00:00.000Z",
                  "reviewed": "2025-12-16T00:00:00.000Z",
                  "description": "Check skills/commands for negative framing and suggest positive alternatives",
                  "allowed_tools": [
                    "Bash",
                    "Grep",
                    "Read",
                    "Edit",
                    "AskUserQuestion"
                  ]
                },
                "content": "Check Claude skills, commands, and subagent prompts for negative examples and convert them to positive framing.\n\n**Background**: Anthropic's prompt engineering best practice recommends positive framing instead of negative instructions to avoid the \"pink elephant problem\" - telling Claude \"don't do X\" can actually increase the likelihood of X happening because it primes that concept.\n\n**What to detect:**\n- Negative instructions: \"don't\", \"do not\", \"never\", \"avoid\", \"must not\", \"cannot\", \"can't\"\n- Prohibitive language: \"do NOT\", \"NEVER\", \"AVOID\" (emphasis versions)\n- Exception: Some negative framing is acceptable when:\n  - Used sparingly with light touch\n  - Explaining what something is NOT as clarification\n  - In examples showing what to avoid\n  - In security contexts where explicit prohibitions are necessary\n\n**Steps:**\n\n1. **Scan for negative patterns**:\n   ```bash\n   # Search in skills\n   grep -rn -E \"(don't|do not|doesn't|do NOT|never|NEVER|avoid|Avoid|AVOID|must not|shouldn't|should not|can't|cannot)\" \\\n     ~/.claude/skills/ \\\n     --include=\"*.md\" \\\n     -A 1 -B 1\n\n   # Search in commands\n   grep -rn -E \"(don't|do not|doesn't|do NOT|never|NEVER|avoid|Avoid|AVOID|must not|shouldn't|should not|can't|cannot)\" \\\n     ~/.claude/commands/ \\\n     --include=\"*.md\" \\\n     -A 1 -B 1\n   ```\n\n2. **Analyze findings**:\n   - Group by file and pattern\n   - Count total occurrences\n   - Identify high-frequency offenders\n   - Filter out acceptable uses (e.g., in examples, security contexts)\n\n3. **Generate positive alternatives**:\n   For each negative instruction found, suggest positive reframing:\n\n   **Common transformations:**\n   - \"Don't use X\"  \"Use Y instead\" or \"Prefer Y for this task\"\n   - \"Never do X\"  \"Always do Y\" or \"Use Y as the standard approach\"\n   - \"Avoid X\"  \"Prefer Y\" or \"Use Y for better results\"\n   - \"Don't forget to X\"  \"Remember to X\" or \"Always X\"\n   - \"Do not create new files\"  \"Edit existing files whenever possible\"\n   - \"Don't use emojis\"  \"Use plain text formatting\" or \"Keep responses professional\"\n   - \"Never edit manually\"  \"Use automated workflows for updates\"\n\n   **Examples from real scenarios:**\n   -  \"Do not use markdown\"   \"Your response should be composed of smoothly flowing prose paragraphs\"\n   -  \"Do not make new versions\"   \"Make all updates in current files whenever possible\"\n   -  \"Never manually edit CHANGELOG.md\"   \"Use conventional commits to automatically generate CHANGELOG entries\"\n   -  \"Don't batch completions\"   \"Mark tasks complete immediately after finishing each one\"\n\n4. **Present findings report**:\n   ```\n    Negative Framing Analysis\n   =============================\n\n   Scanned locations:\n   - ~/.claude/skills/ (XX files)\n   - ~/.claude/commands/ (XX files)\n\n   Total negative patterns found: XX\n\n    Breakdown by pattern:\n   - \"don't\"/\"do not\": XX occurrences\n   - \"never\": XX occurrences\n   - \"avoid\": XX occurrences\n   - Other: XX occurrences\n\n    Files with most negative framing:\n   1. path/to/file.md (XX instances)\n   2. path/to/file2.md (XX instances)\n\n    Suggested rewrites:\n\n   File: ~/.claude/skills/example/SKILL.md:42\n    Current: \"Don't use X when processing data\"\n    Suggested: \"Use Y for data processing tasks\"\n\n   [Continue for each finding...]\n   ```\n\n5. **Ask user for action**:\n   Use AskUserQuestion to ask:\n   ```\n   Found XX instances of negative framing across XX files.\n\n   What would you like to do?\n   1. Show all findings with suggested fixes\n   2. Auto-fix straightforward cases (review before commit)\n   3. Show summary only\n   4. Export report to file\n   ```\n\n6. **Apply fixes (if requested)**:\n   - For auto-fix option:\n     - Only fix clear-cut cases\n     - Skip ambiguous or security-critical instructions\n     - Use Edit tool to make changes\n     - Create list of changes made\n\n   - For manual review:\n     - Show each instance with context\n     - Provide suggested rewrite\n     - Ask for confirmation before editing\n\n7. **Final report**:\n   ```\n    Negative Framing Check Complete!\n\n   Summary:\n   - Scanned: XX files\n   - Found: XX instances\n   - Fixed: XX instances\n   - Remaining: XX instances (require manual review)\n\n   Next steps:\n   1. Review changes: git diff\n   2. Test affected skills/commands\n   3. Commit if satisfied: git commit -m \"fix: convert negative framing to positive alternatives\"\n\n    Tip: Use positive framing to tell Claude what TO do, not what NOT to do.\n   This prevents the \"pink elephant problem\" where mentioning unwanted behavior\n   actually increases its likelihood.\n   ```\n\n**Implementation notes:**\n- Focus on instruction text, not explanatory prose\n- Preserve security-critical negative instructions (e.g., \"NEVER commit secrets\")\n- Keep the original meaning while reframing positively\n- Some legitimate uses of negative language are acceptable for clarity\n- Prioritize high-impact changes (frequently-used skills/commands)\n\n**Best practices for positive framing:**\n1. Tell Claude what TO do instead of what NOT to do\n2. Describe desired behavior explicitly\n3. Use examples of correct behavior\n4. Frame constraints as preferred alternatives\n5. Save strong negative language for critical security/safety issues\n\n**References:**\n- Anthropic prompt engineering: \"Tell Claude what to do instead of what not to do\"\n- Article: \"The Pink Elephant Problem: Why 'Don't Do That' Fails with LLMs\"\n- Claude Code best practices: Positive framing improves reliability"
              },
              {
                "name": "/delegate",
                "description": "Delegate tasks to specialized agents with automatic task-agent matching and parallel execution",
                "path": "agent-patterns-plugin/commands/delegate.md",
                "frontmatter": {
                  "created": "2025-12-16T00:00:00.000Z",
                  "modified": "2025-12-16T00:00:00.000Z",
                  "reviewed": "2025-12-16T00:00:00.000Z",
                  "description": "Delegate tasks to specialized agents with automatic task-agent matching and parallel execution",
                  "allowed-tools": "Task, TodoWrite, AskUserQuestion",
                  "argument-hint": "<task-description>"
                },
                "content": "## Context\n\n- Working directory: !`pwd`\n- Git status: !`git status --porcelain 2>/dev/null | head -10`\n- Project type: !`ls -1 package.json pyproject.toml Cargo.toml go.mod 2>/dev/null | head -1`\n- Recent files: !`git diff --name-only HEAD~5 2>/dev/null | head -10`\n\n## Parameters\n\n- `$1+`: Task description(s) - can be a single task or multiple tasks (comma-separated, numbered list, or natural language list)\n\n## Your Task\n\n**Intelligently delegate tasks to the most appropriate specialized agents, executing in parallel when possible.**\n\n### Step 1: Parse and Analyze Tasks\n\nExtract individual tasks from the user's input. Tasks may be provided as:\n- A comma-separated list\n- A numbered or bulleted list\n- Natural language with implicit task boundaries (look for \"and\", \"also\", conjunctions)\n- A single complex task that should be decomposed\n\n### Step 2: Match Tasks to Agents\n\nFor each identified task, determine the best agent match using this reference:\n\n| Task Pattern | Best Agent | When to Use |\n|--------------|------------|-------------|\n| Code exploration, finding implementations, tracing dependencies | `Explore` | Understanding code structure, locating patterns |\n| Security review, vulnerability assessment, OWASP analysis | `security-audit` | Security concerns, auth flows, injection risks |\n| Code quality review, architecture analysis | `code-review` | Quality assessment, design evaluation |\n| Bug investigation, root cause analysis | `system-debugging` | Complex debugging, error analysis |\n| Documentation generation, API docs | `documentation` | Creating/updating documentation |\n| Running tests, analyzing failures | `test-runner` | Test execution and reporting |\n| Test strategy, coverage analysis | `test-architecture` | Testing design decisions |\n| CI/CD pipelines, GitHub Actions | `cicd-pipelines` | Build/deployment automation |\n| Refactoring, SOLID principles | `code-refactoring` | Code quality improvements |\n| TypeScript development, type safety | `typescript-development` | TS-specific work |\n| Python development, tooling | `python-development` | Python-specific work |\n| JavaScript/Node development | `javascript-development` | JS-specific work |\n| Requirements, PRDs | `requirements-documentation` | Feature specifications |\n| UX implementation, accessibility | `ux-implementation` | User interface work |\n| API integration, REST endpoints | `api-integration` | External API work |\n| Research, documentation lookup | `research-documentation` | Technical research |\n| General multi-step tasks | `general-purpose` | Tasks not matching specific domains |\n\n### Step 3: Task Decomposition (When Beneficial)\n\nConsider splitting a task when:\n- It spans multiple domains (e.g., \"review and fix security issues\" = security-audit + code-refactoring)\n- It has sequential dependencies that can be parallelized partially\n- It's too large for a single agent to handle effectively\n- Different parts require different expertise\n\n**Do NOT split when:**\n- The task is atomic and domain-specific\n- Splitting would add overhead without benefit\n- The user explicitly wants a unified result\n\n### Step 4: Plan the Delegation\n\nCreate a delegation plan with TodoWrite:\n- List each task/subtask\n- Assign the selected agent\n- Note any dependencies between tasks\n- Identify which tasks can run in parallel\n\n### Step 5: Execute in Parallel\n\n**CRITICAL: Launch all independent tasks simultaneously using multiple Task tool calls in a single message.**\n\nFor each task, use the Task tool with:\n- `subagent_type`: The matched agent type\n- `prompt`: Detailed task description with all relevant context\n- `description`: Brief task summary\n\nInclude in each agent prompt:\n- The specific task to perform\n- Relevant context from the parsed input\n- Project/file context from above\n- Clear success criteria\n- Whether to produce output or take action\n\n### Step 6: Consolidate Results\n\nAfter all agents complete:\n1. Summarize findings from each agent\n2. Highlight any cross-cutting concerns discovered\n3. Note any follow-up actions needed\n4. Present a unified report to the user\n\n## Execution Guidelines\n\n### Parallel Execution Example\n\nWhen delegating multiple independent tasks, send them all at once:\n\n```markdown\n[Task 1 - security-audit agent]\n[Task 2 - code-review agent]\n[Task 3 - test-runner agent]\n```\n\nAll three launch simultaneously, maximizing efficiency.\n\n### Handling Dependencies\n\nIf Task B depends on Task A:\n1. Launch Task A first\n2. Wait for completion\n3. Pass Task A results to Task B\n4. Continue with any remaining parallel tasks\n\n### Agent Prompt Template\n\nWhen calling each agent, structure the prompt as:\n\n```\n## Task\n[Clear description of what to accomplish]\n\n## Context\n- Project: [type/framework]\n- Files of interest: [relevant paths]\n- Recent changes: [if applicable]\n\n## Scope\n[Specific boundaries for the task]\n\n## Expected Output\n[What the agent should produce/report]\n```\n\n## Output\n\nReport back to the user with:\n\n```markdown\n## Delegation Summary\n\n### Tasks Identified\n1. [Task 1]  `agent-type` \n2. [Task 2]  `agent-type` \n3. [Task 3]  `agent-type` \n\n### Execution Status\n- Parallel: Tasks 1, 2, 3 launched simultaneously\n- Sequential: [any dependent tasks]\n\n### Results\n\n#### [Task 1 Summary]\n[Key findings/actions]\n\n#### [Task 2 Summary]\n[Key findings/actions]\n\n#### [Task 3 Summary]\n[Key findings/actions]\n\n### Follow-up Actions\n- [Any remaining work]\n- [Cross-cutting concerns]\n```\n\n## Examples\n\n### Example 1: Multiple Independent Tasks\n```\n/delegate Review the auth module for security issues, update the API documentation, and run the test suite\n```\n Launches: `security-audit`, `documentation`, `test-runner` in parallel\n\n### Example 2: Complex Task Requiring Decomposition\n```\n/delegate Investigate why the login flow is broken and fix it\n```\n Launches: `system-debugging` (investigate)  `code-refactoring` (fix) sequentially\n\n### Example 3: Single Specialized Task\n```\n/delegate Find all usages of the deprecated UserService class\n```\n Launches: `Explore` agent (single task, no splitting needed)\n\n## See Also\n\n- **CLAUDE.md** (`.claude/CLAUDE.md`) - Delegation strategy and agent reference\n- **Commands** - `/code:review`, `/test:run`, `/git:commit` for specific workflows\n- **Skills** - Domain-specific skills auto-invoked by agents"
              },
              {
                "name": "/workflow-primer",
                "description": "Generate a continuation primer for agent handoff with todo list and context",
                "path": "agent-patterns-plugin/commands/workflow-primer.md",
                "frontmatter": {
                  "created": "2025-12-16T00:00:00.000Z",
                  "modified": "2025-12-26T00:00:00.000Z",
                  "reviewed": "2025-12-26T00:00:00.000Z",
                  "description": "Generate a continuation primer for agent handoff with todo list and context",
                  "allowed-tools": "Read, Grep, Glob, TodoWrite"
                },
                "content": "# /workflow:primer\n\nGenerate a structured todo list and context primer so another agent can continue from the current state.\n\n## Purpose\n\nWhen work must be handed off between agent sessions (due to context limits, user request, or task transition), this command creates a compact summary that enables seamless continuation.\n\n## Usage\n\n```bash\n/workflow:primer\n```\n\n## Output Structure\n\nThe primer includes:\n\n### 1. Current State Summary\nWhat has been accomplished in this session:\n- Completed tasks\n- Files modified\n- Key decisions made\n\n### 2. Remaining Todo List\nPending tasks in priority order:\n- Blocking items first\n- Clear, actionable descriptions\n- File paths where applicable\n\n### 3. Key Context\nCritical information for continuation:\n- Architecture decisions\n- Constraints discovered\n- Dependencies identified\n\n### 4. Active Files\nFiles currently being worked on:\n- Path and purpose\n- Current state (draft/partial/complete)\n- What remains to be done\n\n### 5. Blockers/Issues\nKnown obstacles:\n- Technical blockers\n- Questions needing answers\n- Dependencies on external factors\n\n## Example Output\n\n```markdown\n# Agent Continuation Primer\n\n## Session Summary\nImplemented user authentication flow for the dashboard.\nModified 4 files, created 2 new components.\n\n## Remaining Tasks\n1. [BLOCKING] Add error handling to login form\n   - File: src/components/LoginForm.tsx\n   - Need: validation messages, network error states\n\n2. [BLOCKING] Write unit tests for auth hook\n   - File: src/hooks/useAuth.test.ts\n   - Coverage: login, logout, token refresh\n\n3. Add loading states to login button\n   - File: src/components/LoginForm.tsx\n   - Enhancement, not blocking\n\n## Key Context\n- Using React Query for server state\n- JWT tokens stored in httpOnly cookies\n- Auth state in React Context (not Redux)\n\n## Active Files\n- src/hooks/useAuth.ts - Complete, needs tests\n- src/components/LoginForm.tsx - 80% done, needs error handling\n- src/pages/Login.tsx - Complete\n\n## Known Issues\n- Token refresh endpoint returns 500 intermittently (backend issue)\n- Need design input on error message styling\n```\n\n## When to Use\n\n- Context window is filling up and work must continue in new session\n- Handing off to a different specialized agent\n- User requests a break in the session\n- Long-running task needs checkpoint documentation\n\n## Integration\n\nThis command works with the agent-handoff-markers skill for inline code markers that persist between sessions.\n\n## See Also\n\n- **Skills**: `agent-handoff-markers` for inline code markers\n- **Skills**: `agent-coordination-patterns` for workflow patterns\n- **Skills**: `multi-agent-workflows` for complex coordination"
              }
            ],
            "skills": [
              {
                "name": "agent-coordination-patterns",
                "description": "Coordinate multi-agent workflows: sequential, parallel, and iterative patterns.\nDefines agent handoffs, dependencies, communication protocols, and integration.\nUse when designing multi-agent workflows, coordinating agent handoffs,\nplanning agent dependencies, or building complex agent pipelines.\n",
                "path": "agent-patterns-plugin/skills/agent-coordination-patterns/SKILL.md",
                "frontmatter": {
                  "created": "2025-12-16T00:00:00.000Z",
                  "modified": "2025-12-16T00:00:00.000Z",
                  "reviewed": "2025-12-16T00:00:00.000Z",
                  "name": "agent-coordination-patterns",
                  "description": "Coordinate multi-agent workflows: sequential, parallel, and iterative patterns.\nDefines agent handoffs, dependencies, communication protocols, and integration.\nUse when designing multi-agent workflows, coordinating agent handoffs,\nplanning agent dependencies, or building complex agent pipelines.\n"
                },
                "content": "# Agent Coordination Patterns\n\n## Description\n\nCoordination patterns for sequential, parallel, and iterative agent workflows. Defines how agents work together, communicate findings, and maintain context across handoffs in multi-agent systems.\n\n## When to Use\n\nAutomatically apply this skill when:\n- Designing multi-agent workflows\n- Coordinating agent handoffs\n- Planning agent dependencies\n- Integrating agent outputs\n- Building complex workflows\n- Optimizing agent collaboration\n\n## Core Principle: Hybrid Context Sharing\n\nTwo complementary layers work together:\n\n**1. Transparency Layer** (File-Based)\n- Human-inspectable files\n- Real-time progress visibility\n- Easy debugging and inspection\n- Clear agent coordination\n\n**2. Intelligence Layer** (Knowledge Graph)\n- Historical learning\n- Pattern recognition\n- Cross-session persistence\n- Audit trails\n\n## Agent Integration Protocol\n\n### Phase 1: Pre-Execution Context Reading\n\nBefore starting work, agents MUST:\n\n1. **Read workflow context**  Understand overall objective\n2. **Check agent queue**  Know dependencies and position\n3. **Review shared data**  Get requirements and standards\n4. **Read dependency outputs**  Build on previous work\n\n**Example Flow**:\n```\nUser delegates to python-developer:\n\n1. Read current-workflow.md  \"Building REST API\"\n2. Read agent-queue.md  \"research-assistant completed\"\n3. Read inter-agent-context.json  \"Tech: FastAPI + PostgreSQL\"\n4. Read research-assistant-output.md  \"Requirements defined\"\n5. Begin implementation with full context\n```\n\n### Phase 2: Progress Reporting During Execution\n\nContinuously communicate state:\n\n- Update progress file every 5-10 minutes\n- Report current activity clearly\n- List completed steps\n- Note any blockers immediately\n- Estimate remaining time\n\n### Phase 3: Post-Execution Output Writing\n\nProduce standardized results:\n\n- Document all accomplishments\n- Record technical decisions\n- List created artifacts\n- Note known issues\n- Provide handoff guidance\n\n## Coordination Patterns\n\n### Sequential Coordination\n\nAgents work one after another, each building on previous work.\n\n**Pattern Structure**:\n```\nAgent A completes  Writes output\n  \nAgent B reads A's output  Starts work  Writes output\n  \nAgent C reads A's and B's outputs  Starts work\n```\n\n**When to use**:\n- Clear dependencies exist\n- Each step requires previous completion\n- Linear workflow progression\n\n**Example Workflow**:\n```\nResearch Assistant (30 min)\n   (passes requirements)\nPython Developer (90 min)\n   (passes implementation)\nTest Architect (45 min)\n   (passes test suite)\nDocumentation Writer (30 min)\n```\n\n**Best Practices**:\n- Complete handoff notes are critical\n- Each agent validates previous work\n- Include \"next agent needs\" section\n- Document all assumptions made\n\n### Parallel Coordination\n\nMultiple agents work simultaneously on independent tasks.\n\n**Pattern Structure**:\n```\n          Agent A  Output A\nStart    Agent B  Output B   Integration Agent\n          Agent C  Output C\n```\n\n**When to use**:\n- Independent work streams\n- No direct dependencies\n- Can merge results later\n- Want faster completion\n\n**Example Workflow**:\n```\nRequirements Defined\n     Backend Developer (API)\n     Frontend Developer (UI)\n     Database Architect (Schema)\n         \n    Integration Tester (Verify all parts work together)\n```\n\n**Best Practices**:\n- Define clear interfaces upfront\n- Use shared contracts (API specs)\n- Regular sync points\n- Integration agent validates compatibility\n\n**Shared Contract Example**:\n```json\n{\n  \"api_contract\": {\n    \"/api/users\": {\n      \"GET\": \"returns user list\",\n      \"POST\": \"creates user\"\n    }\n  },\n  \"data_models\": {\n    \"User\": {\n      \"id\": \"string\",\n      \"name\": \"string\",\n      \"email\": \"string\"\n    }\n  }\n}\n```\n\n### Iterative Coordination\n\nAgent revisits work based on feedback from other agents.\n\n**Pattern Structure**:\n```\nAgent A  Agent B (reviews)  Issues found\n                                 \n   Feedback \n```\n\n**When to use**:\n- Quality improvement cycles\n- Refinement needed\n- Review and feedback loops\n- Progressive enhancement\n\n**Example Workflow**:\n```\nDeveloper  Code Review  Issues Found\n                             \n     Fix Issues \n\nSecurity Auditor  Vulnerabilities Found\n                             \nDeveloper  Apply Fixes \n```\n\n**Best Practices**:\n- Clear feedback format\n- Specific actionable items\n- Track iteration count\n- Define completion criteria\n\n**Feedback Format**:\n```markdown\n## Review Feedback\n\n### Critical Issues (Must Fix)\n1. SQL injection vulnerability in `/api/users` line 45\n2. Missing authentication on DELETE endpoint\n\n### Improvements (Should Fix)\n1. Add input validation for email format\n2. Implement rate limiting\n\n### Suggestions (Could Improve)\n1. Consider caching for performance\n2. Add more descriptive error messages\n```\n\n### Hybrid Coordination\n\nCombines multiple patterns for complex workflows.\n\n**Example Structure**:\n```\nSequential Start:\n  Research  Architecture Design\n           \nParallel Development:\n   Backend Team\n   Frontend Team\n   QA Test Planning\n           \nSequential Integration:\n  Integration  Testing\n           \nIterative Refinement:\n  Review  Fixes\n```\n\n**When to use**:\n- Complex projects\n- Multiple teams\n- Different phases need different patterns\n- Optimization opportunities\n\n## Coordination Rules\n\n### Dependency Management\n\n**Hard Dependencies** (Must Complete First):\n```json\n{\n  \"agent\": \"test-architect\",\n  \"depends_on\": [\"python-developer\"],\n  \"reason\": \"Cannot test code that doesn't exist\"\n}\n```\n\n**Soft Dependencies** (Preferred Order):\n```json\n{\n  \"agent\": \"documentation-writer\",\n  \"prefers_after\": [\"test-architect\"],\n  \"reason\": \"Better docs with test examples\"\n}\n```\n\n### Communication Protocols\n\n**Status Broadcasting**:\n- STARTING: Beginning work\n- IN_PROGRESS: Active work (% complete)\n- BLOCKED: Cannot continue\n- COMPLETED: Finished successfully\n- FAILED: Could not complete\n\n**Handoff Requirements**:\n- Summary of work done\n- Decisions made\n- Artifacts created\n- Known issues\n- Next steps guidance\n\n### Conflict Resolution\n\n**When agents disagree**:\n1. Document both perspectives\n2. Escalate to user if critical\n3. Use precedence rules\n4. Security > Functionality > Performance\n\n**Precedence Rules**:\n```\nSecurity Auditor > All Others (security issues)\nArchitect > Developers (design decisions)\nSenior > Junior (experience hierarchy)\nLater > Earlier (recent context)\n```\n\n## Best Practices\n\n### 1. Clear Communication\n- Explicit handoff notes\n- Document all assumptions\n- State dependencies clearly\n- Update progress frequently\n\n### 2. Robust Error Handling\n- Check for previous failures\n- Validate inputs exist\n- Handle missing dependencies\n- Report blockers immediately\n\n### 3. Maintain Context\n- Read all relevant outputs\n- Preserve decision history\n- Update shared context\n- Avoid duplicating work\n\n### 4. Quality Gates\n- Validate before handoff\n- Test integration points\n- Review critical paths\n- Ensure completeness\n\n## Common Pitfalls\n\n-  Starting without reading context\n-  Not updating progress during execution\n-  Vague or incomplete handoff notes\n-  Missing dependency outputs\n-  Parallel work without contracts\n-  No integration validation\n-  Infinite iteration loops\n\n## Integration with Other Skills\n\n- **agent-file-coordination**: Uses file structures for coordination\n- **graphiti-learning-workflows**: Learn optimal coordination patterns\n- **graphiti-episode-storage**: Store successful patterns\n- **multi-agent-workflows**: Higher-level workflow orchestration\n\n## References\n\n- Related Skills: `agent-file-coordination`, `multi-agent-workflows`\n- Design Patterns: Sequential, Parallel, Iterative, Hybrid\n- Replaces: `agent-context-management` (coordination sections)"
              },
              {
                "name": "agent-file-coordination",
                "description": "File-based context sharing for multi-agent workflows. Provides directory\norganization, agent output templates, progress tracking, and inter-agent context.\nUse when setting up multi-agent workflows, reading/writing agent context files,\nor maintaining workflow transparency with file-based coordination.\n",
                "path": "agent-patterns-plugin/skills/agent-file-coordination/SKILL.md",
                "frontmatter": {
                  "created": "2025-12-16T00:00:00.000Z",
                  "modified": "2025-12-16T00:00:00.000Z",
                  "reviewed": "2025-12-16T00:00:00.000Z",
                  "name": "agent-file-coordination",
                  "description": "File-based context sharing for multi-agent workflows. Provides directory\norganization, agent output templates, progress tracking, and inter-agent context.\nUse when setting up multi-agent workflows, reading/writing agent context files,\nor maintaining workflow transparency with file-based coordination.\n"
                },
                "content": "# Agent File Coordination\n\n## Description\n\nFile-based context sharing and coordination structures for multi-agent workflows. Provides standardized directory organization, file formats, and templates for transparent agent coordination and human inspection.\n\n## When to Use\n\nAutomatically apply this skill when:\n- Setting up multi-agent workflows\n- Reading/writing agent context files\n- Monitoring agent progress\n- Debugging agent coordination\n- Sharing data between agents\n- Maintaining workflow transparency\n\n## Directory Organization\n\n### Standard Structure\n```\n~/.claude/\n tasks/              # Workflow coordination\n    current-workflow.md      # Active workflow status\n    agent-queue.md           # Agent scheduling & dependencies\n    inter-agent-context.json # Structured cross-agent data\n\n docs/               # Agent outputs & results\n    {agent}-output.md        # Standardized agent results\n    agent-output-template.md # Template for consistency\n\n status/             # Real-time progress\n     {agent}-progress.md      # Live status updates\n```\n\n[... rest of the file content - see source file for complete content]\n\n## References\n\n- Related Skills: `agent-coordination-patterns`\n- Related Commands: Multi-agent workflow commands\n- Replaces: `agent-context-management` (file structure sections)"
              },
              {
                "name": "agent-handoff-markers",
                "description": "Standardized inline markers for inter-agent communication. Use when creating handoff annotations for other agents, scanning for pending work from upstream agents, or when the user mentions handoff markers, agent coordination, or cross-agent communication.",
                "path": "agent-patterns-plugin/skills/agent-handoff-markers/SKILL.md",
                "frontmatter": {
                  "created": "2025-12-16T00:00:00.000Z",
                  "modified": "2025-12-26T00:00:00.000Z",
                  "reviewed": "2025-12-26T00:00:00.000Z",
                  "name": "agent-handoff-markers",
                  "description": "Standardized inline markers for inter-agent communication. Use when creating handoff annotations for other agents, scanning for pending work from upstream agents, or when the user mentions handoff markers, agent coordination, or cross-agent communication.",
                  "allowed-tools": "Glob, Grep, Read, Edit, Write, TodoWrite"
                },
                "content": "# Agent Handoff Markers\n\nStructured inline markers for asynchronous agent-to-agent communication.\n\n## Benefits\n\n### Asynchronous Agent Coordination\n- Agents can request work from other agents without blocking\n- Work can be discovered and processed in future sessions\n- Enables non-linear development workflows\n\n### Traceability\n- Clear audit trail of inter-agent requests\n- Completion markers show what was delivered\n- Referenced files provide full context\n\n### Reduced Context Switching\n- Agents can complete their current work before handling handoffs\n- Markers persist until addressed\n- No need for immediate handoff processing\n\n### Improved Code Documentation\n- Markers serve as inline documentation of intent\n- Requirements are captured at the point of need\n- Context is preserved alongside the code\n\n### Workflow Flexibility\n- Any agent can create markers for any other agent\n- Priority levels allow triage\n- Type categorization enables filtering\n\n### CI/CD Integration Potential\n- Markers can be scanned in pre-commit hooks\n- Blocking markers could fail builds if unaddressed\n- Automated reports of pending work\n\n## Core Concept\n\nHandoff markers are structured comments in code that:\n1. Request work from a specific agent\n2. Provide context for the receiving agent\n3. Define requirements and constraints\n4. Track completion status\n\n## Marker Format\n\n### Basic Structure\n\n```typescript\n// @AGENT-HANDOFF-MARKER(target-agent) {\n//   type: \"category\",\n//   context: \"what this code does\",\n//   needs: [\"requirement 1\", \"requirement 2\"],\n//   priority: \"blocking|enhancement\",\n//   refs: [\"path/to/related/file\"]\n// }\n```\n\n### Full Example\n\n```typescript\n// @AGENT-HANDOFF-MARKER(ux-implementation) {\n//   type: \"form-validation\",\n//   context: \"User registration form with email/password\",\n//   needs: [\n//     \"error message placement strategy\",\n//     \"focus management on validation failure\",\n//     \"ARIA live region for error announcements\",\n//     \"inline vs summary validation decision\"\n//   ],\n//   priority: \"blocking\",\n//   refs: [\n//     \"src/components/FormField.tsx\",\n//     \"docs/design/registration-flow.md\"\n//   ],\n//   constraints: [\n//     \"must work with React Hook Form\",\n//     \"mobile-first responsive\"\n//   ]\n// }\nasync function handleRegistration(data: FormData) {\n  try {\n    await api.register(data);\n  } catch (errors) {\n    // @AGENT-PLACEHOLDER: implement error display\n    console.error(errors);\n  }\n}\n```\n\n## Target Agents\n\n### UX-Related Targets\n\n```typescript\n// @AGENT-HANDOFF-MARKER(ux-implementation)\n// For: Accessibility, component UX, responsive patterns, design tokens\n\n// @AGENT-HANDOFF-MARKER(service-design)\n// For: User journey decisions, information architecture, high-level UX strategy\n```\n\n### Development Targets\n\n```typescript\n// @AGENT-HANDOFF-MARKER(typescript-development)\n// For: Framework-specific implementation, type system, state management\n\n// @AGENT-HANDOFF-MARKER(code-review)\n// For: Quality review, security assessment, performance evaluation\n\n// @AGENT-HANDOFF-MARKER(test-architecture)\n// For: Test strategy, coverage requirements, test patterns\n```\n\n## Marker Types\n\n### Component Implementation\n\n```typescript\n// @AGENT-HANDOFF-MARKER(ux-implementation) {\n//   type: \"component-implementation\",\n//   context: \"Modal dialog for confirmation actions\",\n//   needs: [\n//     \"focus trap implementation\",\n//     \"keyboard handling (Escape to close)\",\n//     \"ARIA dialog pattern\",\n//     \"animation on open/close\"\n//   ]\n// }\n```\n\n### Accessibility\n\n```typescript\n// @AGENT-HANDOFF-MARKER(ux-implementation) {\n//   type: \"accessibility\",\n//   context: \"Data table with sortable columns\",\n//   needs: [\n//     \"ARIA sort attributes\",\n//     \"keyboard navigation for column headers\",\n//     \"screen reader announcements for sort changes\",\n//     \"focus management after sort\"\n//   ]\n// }\n```\n\n### Form Validation\n\n```typescript\n// @AGENT-HANDOFF-MARKER(ux-implementation) {\n//   type: \"form-validation\",\n//   context: \"Multi-step checkout form\",\n//   needs: [\n//     \"validation timing (blur vs submit)\",\n//     \"error message positioning\",\n//     \"progress indicator accessibility\",\n//     \"step navigation keyboard support\"\n//   ]\n// }\n```\n\n### Loading States\n\n```typescript\n// @AGENT-HANDOFF-MARKER(ux-implementation) {\n//   type: \"loading-states\",\n//   context: \"Dashboard data fetching\",\n//   needs: [\n//     \"skeleton screen design\",\n//     \"loading announcement for screen readers\",\n//     \"error recovery UI\",\n//     \"empty state handling\"\n//   ]\n// }\n```\n\n### Design Tokens\n\n```typescript\n// @AGENT-HANDOFF-MARKER(ux-implementation) {\n//   type: \"design-tokens\",\n//   context: \"Component library theming\",\n//   needs: [\n//     \"color token architecture\",\n//     \"dark mode support\",\n//     \"component-level token scoping\",\n//     \"responsive token overrides\"\n//   ]\n// }\n```\n\n### Responsive Behavior\n\n```typescript\n// @AGENT-HANDOFF-MARKER(ux-implementation) {\n//   type: \"responsive\",\n//   context: \"Navigation menu\",\n//   needs: [\n//     \"mobile menu pattern (drawer/bottom sheet)\",\n//     \"breakpoint strategy\",\n//     \"touch target sizing\",\n//     \"focus management across breakpoints\"\n//   ]\n// }\n```\n\n## Priority Levels\n\n### Blocking\n\nWork cannot proceed without this. Use for:\n- Critical accessibility barriers\n- Core interaction patterns\n- Required user flows\n\n```typescript\n// @AGENT-HANDOFF-MARKER(ux-implementation) {\n//   type: \"accessibility\",\n//   priority: \"blocking\",\n//   context: \"Form submit button\",\n//   needs: [\"keyboard activation\", \"disabled state handling\"]\n// }\n```\n\n### Enhancement\n\nImproves quality but not blocking. Use for:\n- Performance optimizations\n- Polish and refinement\n- Non-critical improvements\n\n```typescript\n// @AGENT-HANDOFF-MARKER(ux-implementation) {\n//   type: \"loading-states\",\n//   priority: \"enhancement\",\n//   context: \"Profile image upload\",\n//   needs: [\"optimistic UI\", \"progress indicator animation\"]\n// }\n```\n\n## Scanning for Markers\n\n### Finding All Handoffs\n\n```bash\n# Find all handoff markers\nrg \"@AGENT-HANDOFF-MARKER\\(\" --type ts --type tsx\n\n# Find markers for specific agent\nrg \"@AGENT-HANDOFF-MARKER\\(ux-implementation\\)\" --type ts\n\n# Find blocking markers only\nrg \"@AGENT-HANDOFF-MARKER.*priority.*blocking\" --type ts\n\n# Count markers by agent\nrg -o \"@AGENT-HANDOFF-MARKER\\([^)]+\\)\" | sort | uniq -c\n```\n\n### Agent Workflow\n\nWhen starting work, agents should:\n\n1. **Scan for incoming markers**\n   ```bash\n   rg \"@AGENT-HANDOFF-MARKER\\(ux-implementation\\)\" --type ts --type tsx -A 10\n   ```\n\n2. **Process each marker**\n   - Read context and requirements\n   - Check referenced files\n   - Implement or specify solution\n\n3. **Mark completion**\n   ```typescript\n   // @AGENT-HANDOFF-MARKER-COMPLETE(ux-implementation) {\n   //   implemented: [\"focus trap\", \"ARIA dialog\", \"Escape key\"],\n   //   notes: \"Uses FocusTrap from @headlessui/react\"\n   // }\n   ```\n\n4. **Create downstream markers if needed**\n   ```typescript\n   // @AGENT-HANDOFF-MARKER(typescript-development) {\n   //   type: \"component-implementation\",\n   //   context: \"Modal with UX specs defined above\",\n   //   needs: [\"React component implementation\", \"state management\"]\n   // }\n   ```\n\n## Placeholder Patterns\n\n### Simple Placeholder\n\n```typescript\n// @AGENT-PLACEHOLDER: error display implementation\nconsole.error(errors);\n```\n\n### Detailed Placeholder\n\n```typescript\n// @AGENT-PLACEHOLDER {\n//   waiting-for: \"ux-implementation\",\n//   requirement: \"accessible error announcements\",\n//   current-behavior: \"logs to console\"\n// }\nsetErrors(validationErrors);\n```\n\n### Implementation Stub\n\n```typescript\nfunction showValidationErrors(errors: ValidationError[]) {\n  // @AGENT-PLACEHOLDER: implement accessible error display\n  // Requirements from @AGENT-HANDOFF-MARKER above:\n  // - Focus first error field\n  // - Announce via ARIA live region\n  // - Display inline error messages\n\n  // Temporary implementation\n  errors.forEach(e => console.error(e.message));\n}\n```\n\n## Completion Markers\n\n### Simple Completion\n\n```typescript\n// @AGENT-HANDOFF-MARKER-COMPLETE(ux-implementation)\n// Implemented: focus trap, ARIA attributes, keyboard handling\n```\n\n### Detailed Completion\n\n```typescript\n// @AGENT-HANDOFF-MARKER-COMPLETE(ux-implementation) {\n//   resolved: \"2024-01-15\",\n//   implemented: [\n//     \"WCAG 2.1 AA compliant\",\n//     \"Focus trap using @headlessui/react\",\n//     \"Escape key closes modal\",\n//     \"Focus returns to trigger on close\"\n//   ],\n//   tests: \"src/__tests__/Modal.a11y.test.tsx\",\n//   notes: \"Added to component library as BaseModal\"\n// }\n```\n\n## Integration with File-Based Coordination\n\nHandoff markers complement the existing file-based system:\n\n### Agent Output Files\n\nWhen completing markers, update the agent output:\n\n```markdown\n<!-- ~/.claude/docs/ux-implementation-output.md -->\n\n## Completed Handoffs\n\n### Modal Dialog (src/components/Modal.tsx)\n- Implemented focus trap\n- Added ARIA attributes\n- Keyboard navigation complete\n- Tests added\n\n### Registration Form (src/pages/Register.tsx)\n- Error display pattern implemented\n- Focus management on validation\n- ARIA live regions for announcements\n\n## Pending Downstream Work\n\n- @AGENT-HANDOFF-MARKER(typescript-development) for Modal component wrapper\n- @AGENT-HANDOFF-MARKER(test-architecture) for E2E accessibility tests\n```\n\n### Inter-Agent Context\n\nUpdate shared context with marker status:\n\n```json\n{\n  \"workflow\": \"ux-implementation\",\n  \"completed_handoffs\": [\n    \"src/components/Modal.tsx:42\",\n    \"src/pages/Register.tsx:156\"\n  ],\n  \"pending_handoffs\": [\n    {\n      \"file\": \"src/components/DataTable.tsx\",\n      \"line\": 89,\n      \"type\": \"accessibility\",\n      \"priority\": \"blocking\"\n    }\n  ]\n}\n```\n\n## Best Practices\n\n### Be Specific\n\n```typescript\n// Bad: Vague requirement\n// @AGENT-HANDOFF-MARKER(ux-implementation) {\n//   needs: [\"make it accessible\"]\n// }\n\n// Good: Specific requirements\n// @AGENT-HANDOFF-MARKER(ux-implementation) {\n//   needs: [\n//     \"ARIA combobox pattern for autocomplete\",\n//     \"keyboard navigation (arrow keys, Enter, Escape)\",\n//     \"screen reader announcement on selection\"\n//   ]\n// }\n```\n\n### Provide Context\n\n```typescript\n// Bad: No context\n// @AGENT-HANDOFF-MARKER(ux-implementation) {\n//   needs: [\"error handling\"]\n// }\n\n// Good: Full context\n// @AGENT-HANDOFF-MARKER(ux-implementation) {\n//   context: \"Payment form in checkout flow, high-stakes interaction\",\n//   needs: [\"error recovery UX\", \"clear error messaging\"],\n//   constraints: [\"PCI compliance\", \"real-time validation\"]\n// }\n```\n\n### Include References\n\n```typescript\n// @AGENT-HANDOFF-MARKER(ux-implementation) {\n//   context: \"Notification system\",\n//   refs: [\n//     \"docs/design/notifications.md\",      // Design spec\n//     \"src/hooks/useNotifications.ts\",     // Existing hook\n//     \"src/components/Toast/Toast.tsx\"     // Related component\n//   ]\n// }\n```\n\n### Clean Up Completed Markers\n\nAfter implementation, either:\n1. Convert to `@AGENT-HANDOFF-MARKER-COMPLETE` marker\n2. Remove marker and document in commit message\n3. Move to documentation if pattern is reusable\n\n## Command Integration\n\nUse the `/handoffs` command to manage markers:\n\n```bash\n# List all pending handoffs\n/handoffs\n\n# Filter by agent\n/handoffs --agent ux-implementation\n\n# Show stale markers (>7 days)\n/handoffs --stale\n\n# Output as JSON for scripting\n/handoffs --json\n```\n\n## References\n\n- Agent Coordination Patterns: See agent-coordination-patterns skill\n- File-Based Coordination: See agent-file-coordination skill\n- Multi-Agent Workflows: See multi-agent-workflows skill"
              },
              {
                "name": "command-context-patterns",
                "description": "Write safe context expressions in Claude Code slash command files. Covers\nbacktick expressions, find vs ls patterns, and commands that always exit 0.\nUse when creating slash commands, writing context sections with backtick\nexpressions, or debugging command execution failures.\n",
                "path": "agent-patterns-plugin/skills/command-context-patterns/SKILL.md",
                "frontmatter": {
                  "created": "2025-12-16T00:00:00.000Z",
                  "modified": "2025-12-16T00:00:00.000Z",
                  "reviewed": "2025-12-16T00:00:00.000Z",
                  "name": "command-context-patterns",
                  "description": "Write safe context expressions in Claude Code slash command files. Covers\nbacktick expressions, find vs ls patterns, and commands that always exit 0.\nUse when creating slash commands, writing context sections with backtick\nexpressions, or debugging command execution failures.\n"
                },
                "content": "# Command Context Patterns\n\nBest practices for writing context expressions in Claude Code slash command files.\n\n## Activation\n\nUse this skill when:\n- Creating or editing slash command files (`.claude/commands/**/*.md`)\n- Writing context sections with backtick expressions (`!`...``)\n- Debugging command execution failures related to bash expressions\n\n## Safe Patterns\n\nContext expressions must use commands that **always exit 0** regardless of results.\n\n[Rest of content continues...]"
              },
              {
                "name": "MCP Server Management",
                "description": "Intelligent MCP server installation and management. Suggests MCP servers based on project context and helps install them project-by-project. Use when configuring MCP servers or when project needs specific integrations.",
                "path": "agent-patterns-plugin/skills/mcp-management/SKILL.md",
                "frontmatter": {
                  "created": "2025-12-16T00:00:00.000Z",
                  "modified": "2025-12-16T00:00:00.000Z",
                  "reviewed": "2025-12-16T00:00:00.000Z",
                  "name": "MCP Server Management",
                  "description": "Intelligent MCP server installation and management. Suggests MCP servers based on project context and helps install them project-by-project. Use when configuring MCP servers or when project needs specific integrations.",
                  "allowed-tools": "Bash, Read, Write, Edit, Grep, Glob, AskUserQuestion"
                },
                "content": "# MCP Server Management\n\nExpert knowledge for managing Model Context Protocol (MCP) servers on a project-by-project basis, with intelligent suggestions based on project context.\n\n[Rest of content continues...]"
              },
              {
                "name": "multi-agent-workflows",
                "description": "Orchestrate complex multi-agent workflows for development, infrastructure, and\nresearch. Provides workflow templates, agent sequences, and integration patterns.\nUse when planning complex projects, coordinating multiple agents, designing\nAPI development workflows, or infrastructure setup workflows.\n",
                "path": "agent-patterns-plugin/skills/multi-agent-workflows/SKILL.md",
                "frontmatter": {
                  "created": "2025-12-16T00:00:00.000Z",
                  "modified": "2025-12-16T00:00:00.000Z",
                  "reviewed": "2025-12-16T00:00:00.000Z",
                  "name": "multi-agent-workflows",
                  "description": "Orchestrate complex multi-agent workflows for development, infrastructure, and\nresearch. Provides workflow templates, agent sequences, and integration patterns.\nUse when planning complex projects, coordinating multiple agents, designing\nAPI development workflows, or infrastructure setup workflows.\n"
                },
                "content": "# Multi-Agent Workflow Orchestration\n\n[Full content from source file - copying complete SKILL.md content]"
              }
            ]
          },
          {
            "name": "accessibility-plugin",
            "description": "Accessibility and UX implementation - WCAG, ARIA, design tokens",
            "source": "./accessibility-plugin",
            "category": "ux",
            "version": "2.0.0",
            "author": null,
            "install_commands": [
              "/plugin marketplace add laurigates/claude-plugins",
              "/plugin install accessibility-plugin@lgates-claude-plugins"
            ],
            "signals": {
              "stars": 1,
              "forks": 0,
              "pushed_at": "2026-01-12T12:05:51Z",
              "created_at": "2025-12-16T11:24:04Z",
              "license": null
            },
            "commands": [],
            "skills": [
              {
                "name": "accessibility-implementation",
                "description": "WCAG 2.1/2.2 compliance implementation, ARIA patterns, keyboard navigation, focus management, and accessibility testing. Use when implementing accessible components, fixing accessibility issues, or when the user mentions WCAG, ARIA, screen readers, or keyboard navigation.",
                "path": "accessibility-plugin/skills/accessibility-implementation/SKILL.md",
                "frontmatter": {
                  "created": "2025-12-16T00:00:00.000Z",
                  "modified": "2025-12-16T00:00:00.000Z",
                  "reviewed": "2025-12-16T00:00:00.000Z",
                  "name": "accessibility-implementation",
                  "description": "WCAG 2.1/2.2 compliance implementation, ARIA patterns, keyboard navigation, focus management, and accessibility testing. Use when implementing accessible components, fixing accessibility issues, or when the user mentions WCAG, ARIA, screen readers, or keyboard navigation.",
                  "allowed-tools": "Glob, Grep, Read, Edit, Write, Bash, BashOutput, TodoWrite, WebSearch, WebFetch"
                },
                "content": "# Accessibility Implementation\n\nTechnical implementation of WCAG guidelines, ARIA patterns, and assistive technology support.\n\n## Core Expertise\n\n- **WCAG Compliance**: Implementing WCAG 2.1/2.2 success criteria in code\n- **ARIA Patterns**: Correct usage of roles, states, and properties\n- **Keyboard Navigation**: Focus management, key handlers, logical tab order\n- **Screen Readers**: Content structure, announcements, live regions\n- **Testing**: Automated and manual accessibility testing\n\n## WCAG Quick Reference\n\n### Level A (Must Have)\n\n| Criterion | Implementation |\n|-----------|----------------|\n| 1.1.1 Non-text Content | `alt` for images, labels for inputs |\n| 1.3.1 Info and Relationships | Semantic HTML, ARIA relationships |\n| 2.1.1 Keyboard | All interactive elements keyboard accessible |\n| 2.4.1 Bypass Blocks | Skip links, landmarks |\n| 4.1.2 Name, Role, Value | ARIA labels, roles for custom widgets |\n\n### Level AA (Should Have)\n\n| Criterion | Implementation |\n|-----------|----------------|\n| 1.4.3 Contrast (Minimum) | 4.5:1 text, 3:1 large text |\n| 1.4.11 Non-text Contrast | 3:1 for UI components |\n| 2.4.6 Headings and Labels | Descriptive, hierarchical headings |\n| 2.4.7 Focus Visible | Visible focus indicator (2px+ outline) |\n\n## ARIA Patterns\n\n### Buttons and Links\n\n```html\n<!-- Custom button -->\n<div role=\"button\" tabindex=\"0\"\n     aria-pressed=\"false\"\n     onkeydown=\"handleKeyDown(event)\">\n  Toggle Feature\n</div>\n\n<!-- Icon button (needs accessible name) -->\n<button aria-label=\"Close dialog\">\n  <svg aria-hidden=\"true\">...</svg>\n</button>\n\n<!-- Link vs button -->\n<!-- Use link for navigation, button for actions -->\n<a href=\"/page\">Go to page</a>\n<button type=\"button\">Submit form</button>\n```\n\n### Form Controls\n\n```html\n<!-- Input with label -->\n<label for=\"email\">Email address</label>\n<input id=\"email\" type=\"email\"\n       aria-describedby=\"email-hint email-error\"\n       aria-invalid=\"true\"\n       required>\n<div id=\"email-hint\">We'll never share your email</div>\n<div id=\"email-error\" role=\"alert\">Please enter a valid email</div>\n\n<!-- Checkbox group -->\n<fieldset>\n  <legend>Notification preferences</legend>\n  <label><input type=\"checkbox\" name=\"notif\" value=\"email\"> Email</label>\n  <label><input type=\"checkbox\" name=\"notif\" value=\"sms\"> SMS</label>\n</fieldset>\n\n<!-- Combobox (autocomplete) -->\n<label for=\"country\">Country</label>\n<input id=\"country\"\n       role=\"combobox\"\n       aria-expanded=\"false\"\n       aria-autocomplete=\"list\"\n       aria-controls=\"country-listbox\">\n<ul id=\"country-listbox\" role=\"listbox\" hidden>\n  <li role=\"option\" id=\"opt-us\">United States</li>\n  <li role=\"option\" id=\"opt-uk\">United Kingdom</li>\n</ul>\n```\n\n### Modal Dialog\n\n```html\n<div role=\"dialog\"\n     aria-modal=\"true\"\n     aria-labelledby=\"dialog-title\"\n     aria-describedby=\"dialog-desc\">\n  <h2 id=\"dialog-title\">Confirm Action</h2>\n  <p id=\"dialog-desc\">Are you sure you want to proceed?</p>\n  <button>Cancel</button>\n  <button>Confirm</button>\n</div>\n```\n\n```typescript\n// Focus trap implementation\nfunction trapFocus(dialog: HTMLElement) {\n  const focusable = dialog.querySelectorAll(\n    'button, [href], input, select, textarea, [tabindex]:not([tabindex=\"-1\"])'\n  );\n  const first = focusable[0] as HTMLElement;\n  const last = focusable[focusable.length - 1] as HTMLElement;\n\n  dialog.addEventListener('keydown', (e) => {\n    if (e.key === 'Tab') {\n      if (e.shiftKey && document.activeElement === first) {\n        e.preventDefault();\n        last.focus();\n      } else if (!e.shiftKey && document.activeElement === last) {\n        e.preventDefault();\n        first.focus();\n      }\n    }\n    if (e.key === 'Escape') {\n      closeDialog();\n    }\n  });\n\n  // Move focus to first element\n  first.focus();\n}\n```\n\n### Tabs\n\n```html\n<div role=\"tablist\" aria-label=\"Settings tabs\">\n  <button role=\"tab\"\n          id=\"tab-1\"\n          aria-selected=\"true\"\n          aria-controls=\"panel-1\">\n    General\n  </button>\n  <button role=\"tab\"\n          id=\"tab-2\"\n          aria-selected=\"false\"\n          aria-controls=\"panel-2\"\n          tabindex=\"-1\">\n    Privacy\n  </button>\n</div>\n\n<div role=\"tabpanel\" id=\"panel-1\" aria-labelledby=\"tab-1\">\n  General settings content\n</div>\n<div role=\"tabpanel\" id=\"panel-2\" aria-labelledby=\"tab-2\" hidden>\n  Privacy settings content\n</div>\n```\n\n```typescript\n// Tab keyboard navigation\ntablist.addEventListener('keydown', (e) => {\n  const tabs = Array.from(tablist.querySelectorAll('[role=\"tab\"]'));\n  const current = tabs.indexOf(document.activeElement as Element);\n\n  let next: number;\n  switch (e.key) {\n    case 'ArrowRight':\n      next = (current + 1) % tabs.length;\n      break;\n    case 'ArrowLeft':\n      next = (current - 1 + tabs.length) % tabs.length;\n      break;\n    case 'Home':\n      next = 0;\n      break;\n    case 'End':\n      next = tabs.length - 1;\n      break;\n    default:\n      return;\n  }\n\n  e.preventDefault();\n  (tabs[next] as HTMLElement).focus();\n  activateTab(tabs[next]);\n});\n```\n\n### Live Regions\n\n```html\n<!-- Status messages -->\n<div role=\"status\" aria-live=\"polite\">\n  Form saved successfully\n</div>\n\n<!-- Alerts (interrupts) -->\n<div role=\"alert\" aria-live=\"assertive\">\n  Error: Connection lost\n</div>\n\n<!-- Progress updates -->\n<div aria-live=\"polite\" aria-atomic=\"true\">\n  Loading: 45% complete\n</div>\n```\n\n## Keyboard Navigation\n\n### Standard Key Bindings\n\n| Key | Behavior |\n|-----|----------|\n| Tab | Move to next focusable element |\n| Shift+Tab | Move to previous focusable element |\n| Enter/Space | Activate button, select option |\n| Escape | Close modal, cancel operation |\n| Arrow keys | Navigate within component (tabs, menu, listbox) |\n| Home/End | Go to first/last item in list |\n\n### Focus Management\n\n```typescript\n// Return focus after modal close\nconst triggerElement = document.activeElement;\nopenModal();\n// On close:\ncloseModal();\ntriggerElement?.focus();\n\n// Move focus to error\nfunction showValidationErrors() {\n  const firstError = document.querySelector('[aria-invalid=\"true\"]');\n  (firstError as HTMLElement)?.focus();\n}\n\n// Skip link\n<a href=\"#main-content\" class=\"skip-link\">Skip to main content</a>\n<main id=\"main-content\" tabindex=\"-1\">...</main>\n```\n\n### Roving Tabindex\n\n```typescript\n// For composite widgets (toolbar, menu, tabs)\nfunction setRovingTabindex(container: HTMLElement, selector: string) {\n  const items = container.querySelectorAll(selector);\n\n  items.forEach((item, index) => {\n    item.setAttribute('tabindex', index === 0 ? '0' : '-1');\n  });\n\n  container.addEventListener('keydown', (e) => {\n    const current = Array.from(items).indexOf(document.activeElement as Element);\n    let next = current;\n\n    if (e.key === 'ArrowRight' || e.key === 'ArrowDown') {\n      next = (current + 1) % items.length;\n    } else if (e.key === 'ArrowLeft' || e.key === 'ArrowUp') {\n      next = (current - 1 + items.length) % items.length;\n    }\n\n    if (next !== current) {\n      items[current].setAttribute('tabindex', '-1');\n      items[next].setAttribute('tabindex', '0');\n      (items[next] as HTMLElement).focus();\n      e.preventDefault();\n    }\n  });\n}\n```\n\n## Testing\n\n### Automated Testing\n\n```bash\n# axe-core CLI\nnpx @axe-core/cli https://localhost:3000\n\n# Lighthouse accessibility audit\nnpx lighthouse http://localhost:3000 --only-categories=accessibility --output=json\n\n# pa11y\nnpx pa11y http://localhost:3000\n\n# jest-axe for unit tests\nnpm install --save-dev jest-axe\n```\n\n```typescript\n// jest-axe example\nimport { axe, toHaveNoViolations } from 'jest-axe';\n\nexpect.extend(toHaveNoViolations);\n\ntest('component is accessible', async () => {\n  const { container } = render(<MyComponent />);\n  const results = await axe(container);\n  expect(results).toHaveNoViolations();\n});\n```\n\n```typescript\n// Playwright accessibility testing\nimport { test, expect } from '@playwright/test';\nimport AxeBuilder from '@axe-core/playwright';\n\ntest('page should not have accessibility violations', async ({ page }) => {\n  await page.goto('/');\n\n  const results = await new AxeBuilder({ page })\n    .withTags(['wcag2a', 'wcag2aa'])\n    .analyze();\n\n  expect(results.violations).toEqual([]);\n});\n```\n\n### Manual Testing Checklist\n\n**Keyboard Navigation**\n- [ ] All interactive elements reachable via Tab\n- [ ] Focus order matches visual order\n- [ ] Focus indicator always visible\n- [ ] No keyboard traps\n- [ ] Escape closes modals/menus\n\n**Screen Reader Testing**\n- [ ] VoiceOver (macOS): Cmd+F5\n- [ ] NVDA (Windows): Free download\n- [ ] Test: Links announce destination\n- [ ] Test: Forms announce labels and errors\n- [ ] Test: Dynamic content announced\n\n**Visual Testing**\n- [ ] Zoom to 200% without horizontal scroll\n- [ ] Color contrast meets ratios\n- [ ] Information not conveyed by color alone\n- [ ] Focus indicators visible in all themes\n\n## Common Fixes\n\n### Missing Accessible Name\n\n```html\n<!-- Bad: Icon button without label -->\n<button><svg>...</svg></button>\n\n<!-- Good: Add aria-label -->\n<button aria-label=\"Close\">\n  <svg aria-hidden=\"true\">...</svg>\n</button>\n```\n\n### Missing Form Labels\n\n```html\n<!-- Bad: Placeholder as label -->\n<input placeholder=\"Email\">\n\n<!-- Good: Proper label -->\n<label for=\"email\">Email</label>\n<input id=\"email\" type=\"email\">\n\n<!-- Good: Visually hidden label -->\n<label for=\"search\" class=\"visually-hidden\">Search</label>\n<input id=\"search\" type=\"search\" placeholder=\"Search...\">\n```\n\n### Missing Heading Structure\n\n```html\n<!-- Bad: Skipping heading levels -->\n<h1>Page Title</h1>\n<h3>Section</h3>  <!-- Missing h2 -->\n\n<!-- Good: Proper hierarchy -->\n<h1>Page Title</h1>\n<h2>Section</h2>\n<h3>Subsection</h3>\n```\n\n### Focus Not Visible\n\n```css\n/* Bad: Removing focus outline */\nbutton:focus { outline: none; }\n\n/* Good: Custom focus indicator */\nbutton:focus-visible {\n  outline: 2px solid #0066cc;\n  outline-offset: 2px;\n}\n```\n\n### Color Contrast\n\n```css\n/* Bad: Low contrast */\n.text { color: #999; background: #fff; } /* 2.85:1 ratio */\n\n/* Good: Sufficient contrast */\n.text { color: #595959; background: #fff; } /* 4.56:1 ratio */\n```\n\n## CSS Utilities\n\n```css\n/* Visually hidden but accessible */\n.visually-hidden {\n  position: absolute;\n  width: 1px;\n  height: 1px;\n  padding: 0;\n  margin: -1px;\n  overflow: hidden;\n  clip: rect(0, 0, 0, 0);\n  white-space: nowrap;\n  border: 0;\n}\n\n/* Skip link */\n.skip-link {\n  position: absolute;\n  top: -40px;\n  left: 0;\n  padding: 8px;\n  background: #000;\n  color: #fff;\n  z-index: 100;\n}\n\n.skip-link:focus {\n  top: 0;\n}\n\n/* Reduced motion */\n@media (prefers-reduced-motion: reduce) {\n  *,\n  *::before,\n  *::after {\n    animation-duration: 0.01ms !important;\n    transition-duration: 0.01ms !important;\n  }\n}\n```\n\n## Best Practices\n\n### Semantic HTML First\nUse native HTML elements before ARIA. A `<button>` is better than `<div role=\"button\">`.\n\n### Don't Override Default Behavior\nNative elements have built-in accessibility. Don't break it with JavaScript.\n\n### Test with Real Users\nAutomated tools catch ~30% of issues. Manual testing with assistive technology is essential.\n\n### Provide Multiple Ways\nOffer keyboard, mouse, and touch alternatives for all interactions.\n\n## References\n\n- WCAG 2.1 Guidelines: https://www.w3.org/WAI/WCAG21/quickref/\n- ARIA Authoring Practices: https://www.w3.org/WAI/ARIA/apg/\n- axe-core Rules: https://dequeuniversity.com/rules/axe/\n- A11y Project Checklist: https://www.a11yproject.com/checklist/"
              },
              {
                "name": "design-tokens",
                "description": "CSS custom property architecture, theme systems, design token organization, and component library integration. Use when implementing design systems, theme switching, dark mode, or when the user mentions tokens, CSS variables, theming, or design system setup.",
                "path": "accessibility-plugin/skills/design-tokens/SKILL.md",
                "frontmatter": {
                  "created": "2025-12-16T00:00:00.000Z",
                  "modified": "2025-12-16T00:00:00.000Z",
                  "reviewed": "2025-12-16T00:00:00.000Z",
                  "name": "design-tokens",
                  "description": "CSS custom property architecture, theme systems, design token organization, and component library integration. Use when implementing design systems, theme switching, dark mode, or when the user mentions tokens, CSS variables, theming, or design system setup.",
                  "allowed-tools": "Glob, Grep, Read, Edit, Write, Bash, TodoWrite"
                },
                "content": "# Design Tokens\n\nDesign token architecture, CSS custom properties, and theme system implementation.\n\n## Core Expertise\n\n- **Token Architecture**: Organizing design tokens for scalability\n- **CSS Custom Properties**: Variable patterns and inheritance\n- **Theme Systems**: Light/dark mode, user preferences\n- **Component Integration**: Applying tokens consistently\n\n## Token Structure\n\n### Three-Tier Architecture\n\n```css\n/* 1. Primitive tokens (raw values) */\n:root {\n  --color-blue-50: #eff6ff;\n  --color-blue-100: #dbeafe;\n  --color-blue-500: #3b82f6;\n  --color-blue-600: #2563eb;\n  --color-blue-700: #1d4ed8;\n\n  --spacing-1: 0.25rem;\n  --spacing-2: 0.5rem;\n  --spacing-4: 1rem;\n  --spacing-8: 2rem;\n\n  --font-size-sm: 0.875rem;\n  --font-size-base: 1rem;\n  --font-size-lg: 1.125rem;\n}\n\n/* 2. Semantic tokens (purpose-based) */\n:root {\n  --color-primary: var(--color-blue-600);\n  --color-primary-hover: var(--color-blue-700);\n  --color-background: white;\n  --color-surface: var(--color-gray-50);\n  --color-text: var(--color-gray-900);\n  --color-text-muted: var(--color-gray-600);\n\n  --spacing-component: var(--spacing-4);\n  --spacing-section: var(--spacing-8);\n}\n\n/* 3. Component tokens (specific usage) */\n.button {\n  --button-padding-x: var(--spacing-4);\n  --button-padding-y: var(--spacing-2);\n  --button-bg: var(--color-primary);\n  --button-bg-hover: var(--color-primary-hover);\n  --button-text: white;\n\n  padding: var(--button-padding-y) var(--button-padding-x);\n  background: var(--button-bg);\n  color: var(--button-text);\n}\n\n.button:hover {\n  background: var(--button-bg-hover);\n}\n```\n\n### Token Categories\n\n```css\n:root {\n  /* Colors */\n  --color-{name}-{shade}: value;\n\n  /* Typography */\n  --font-family-{name}: value;\n  --font-size-{name}: value;\n  --font-weight-{name}: value;\n  --line-height-{name}: value;\n  --letter-spacing-{name}: value;\n\n  /* Spacing */\n  --spacing-{scale}: value;\n\n  /* Sizing */\n  --size-{name}: value;\n\n  /* Borders */\n  --border-width-{name}: value;\n  --border-radius-{name}: value;\n\n  /* Shadows */\n  --shadow-{name}: value;\n\n  /* Transitions */\n  --duration-{name}: value;\n  --easing-{name}: value;\n\n  /* Z-index */\n  --z-{name}: value;\n}\n```\n\n## Theme Implementation\n\n### Light/Dark Mode\n\n```css\n/* Default (light) theme */\n:root {\n  --color-background: #ffffff;\n  --color-surface: #f9fafb;\n  --color-text: #111827;\n  --color-text-muted: #6b7280;\n  --color-border: #e5e7eb;\n}\n\n/* Dark theme */\n[data-theme=\"dark\"] {\n  --color-background: #111827;\n  --color-surface: #1f2937;\n  --color-text: #f9fafb;\n  --color-text-muted: #9ca3af;\n  --color-border: #374151;\n}\n\n/* System preference */\n@media (prefers-color-scheme: dark) {\n  :root:not([data-theme=\"light\"]) {\n    --color-background: #111827;\n    --color-surface: #1f2937;\n    --color-text: #f9fafb;\n    --color-text-muted: #9ca3af;\n    --color-border: #374151;\n  }\n}\n```\n\n### Theme Switching (JavaScript)\n\n```typescript\ntype Theme = 'light' | 'dark' | 'system';\n\nfunction setTheme(theme: Theme) {\n  const root = document.documentElement;\n\n  if (theme === 'system') {\n    root.removeAttribute('data-theme');\n    localStorage.removeItem('theme');\n  } else {\n    root.setAttribute('data-theme', theme);\n    localStorage.setItem('theme', theme);\n  }\n}\n\nfunction getTheme(): Theme {\n  return (localStorage.getItem('theme') as Theme) || 'system';\n}\n\n// Initialize on page load\nfunction initTheme() {\n  const saved = localStorage.getItem('theme');\n  if (saved === 'light' || saved === 'dark') {\n    document.documentElement.setAttribute('data-theme', saved);\n  }\n}\n\n// Add to <head> to prevent flash\n// <script>\n//   (function() {\n//     var t = localStorage.getItem('theme');\n//     if (t === 'light' || t === 'dark') {\n//       document.documentElement.setAttribute('data-theme', t);\n//     }\n//   })();\n// </script>\n```\n\n### React Theme Context\n\n```typescript\nimport { createContext, useContext, useEffect, useState } from 'react';\n\ntype Theme = 'light' | 'dark' | 'system';\n\ninterface ThemeContextType {\n  theme: Theme;\n  setTheme: (theme: Theme) => void;\n  resolvedTheme: 'light' | 'dark';\n}\n\nconst ThemeContext = createContext<ThemeContextType | null>(null);\n\nexport function ThemeProvider({ children }: { children: React.ReactNode }) {\n  const [theme, setThemeState] = useState<Theme>('system');\n  const [resolvedTheme, setResolvedTheme] = useState<'light' | 'dark'>('light');\n\n  useEffect(() => {\n    const saved = localStorage.getItem('theme') as Theme;\n    if (saved) setThemeState(saved);\n  }, []);\n\n  useEffect(() => {\n    const root = document.documentElement;\n\n    if (theme === 'system') {\n      root.removeAttribute('data-theme');\n      const isDark = window.matchMedia('(prefers-color-scheme: dark)').matches;\n      setResolvedTheme(isDark ? 'dark' : 'light');\n    } else {\n      root.setAttribute('data-theme', theme);\n      setResolvedTheme(theme);\n    }\n  }, [theme]);\n\n  const setTheme = (newTheme: Theme) => {\n    setThemeState(newTheme);\n    if (newTheme === 'system') {\n      localStorage.removeItem('theme');\n    } else {\n      localStorage.setItem('theme', newTheme);\n    }\n  };\n\n  return (\n    <ThemeContext.Provider value={{ theme, setTheme, resolvedTheme }}>\n      {children}\n    </ThemeContext.Provider>\n  );\n}\n\nexport function useTheme() {\n  const context = useContext(ThemeContext);\n  if (!context) throw new Error('useTheme must be used within ThemeProvider');\n  return context;\n}\n```\n\n## File Organization\n\n### Recommended Structure\n\n```\nstyles/\n tokens/\n    primitives.css      # Raw values\n    semantic.css        # Purpose-based tokens\n    index.css           # Combines all tokens\n themes/\n    light.css           # Light theme overrides\n    dark.css            # Dark theme overrides\n base/\n    reset.css           # CSS reset\n    typography.css      # Base typography\n components/\n     button.css\n     card.css\n```\n\n### JSON Token Format (for tooling)\n\n```json\n{\n  \"color\": {\n    \"primary\": {\n      \"value\": \"#3b82f6\",\n      \"type\": \"color\",\n      \"description\": \"Primary brand color\"\n    },\n    \"background\": {\n      \"value\": \"{color.gray.50}\",\n      \"type\": \"color\"\n    }\n  },\n  \"spacing\": {\n    \"sm\": { \"value\": \"0.5rem\", \"type\": \"spacing\" },\n    \"md\": { \"value\": \"1rem\", \"type\": \"spacing\" },\n    \"lg\": { \"value\": \"2rem\", \"type\": \"spacing\" }\n  }\n}\n```\n\n## Component Integration\n\n### Component-Level Tokens\n\n```css\n/* Card component with local tokens */\n.card {\n  /* Component tokens with fallbacks */\n  --card-padding: var(--spacing-4, 1rem);\n  --card-radius: var(--border-radius-lg, 0.5rem);\n  --card-shadow: var(--shadow-md);\n  --card-bg: var(--color-surface);\n  --card-border: var(--color-border);\n\n  padding: var(--card-padding);\n  border-radius: var(--card-radius);\n  box-shadow: var(--card-shadow);\n  background: var(--card-bg);\n  border: 1px solid var(--card-border);\n}\n\n/* Variant via token override */\n.card--elevated {\n  --card-shadow: var(--shadow-lg);\n}\n\n.card--outlined {\n  --card-shadow: none;\n  --card-border: var(--color-border-strong);\n}\n```\n\n### Responsive Tokens\n\n```css\n:root {\n  --container-padding: var(--spacing-4);\n  --heading-size: var(--font-size-xl);\n}\n\n@media (min-width: 768px) {\n  :root {\n    --container-padding: var(--spacing-8);\n    --heading-size: var(--font-size-2xl);\n  }\n}\n\n@media (min-width: 1024px) {\n  :root {\n    --container-padding: var(--spacing-12);\n    --heading-size: var(--font-size-3xl);\n  }\n}\n```\n\n### Tailwind CSS Integration\n\n```javascript\n// tailwind.config.js\nmodule.exports = {\n  theme: {\n    colors: {\n      primary: 'var(--color-primary)',\n      'primary-hover': 'var(--color-primary-hover)',\n      background: 'var(--color-background)',\n      surface: 'var(--color-surface)',\n      text: 'var(--color-text)',\n      'text-muted': 'var(--color-text-muted)',\n    },\n    spacing: {\n      1: 'var(--spacing-1)',\n      2: 'var(--spacing-2)',\n      4: 'var(--spacing-4)',\n      8: 'var(--spacing-8)',\n    },\n    borderRadius: {\n      sm: 'var(--border-radius-sm)',\n      DEFAULT: 'var(--border-radius-md)',\n      lg: 'var(--border-radius-lg)',\n    },\n  },\n};\n```\n\n## Best Practices\n\n### Naming Conventions\n\n```css\n/* Use consistent prefixes */\n--color-{category}-{variant}\n--spacing-{scale}\n--font-{property}-{variant}\n\n/* Examples */\n--color-primary-500\n--color-text-muted\n--spacing-4\n--font-size-lg\n--font-weight-bold\n\n/* Avoid */\n--blue           /* Not specific enough */\n--padding-large  /* Mixing concern with scale */\n--colorPrimary   /* Inconsistent casing */\n```\n\n### Token Scoping\n\n```css\n/* Global tokens in :root */\n:root {\n  --color-primary: #3b82f6;\n}\n\n/* Component tokens in component scope */\n.button {\n  --button-bg: var(--color-primary);\n}\n\n/* Don't pollute global scope with component tokens */\n/* Bad */\n:root {\n  --button-padding: 1rem;  /* Too specific for global */\n}\n```\n\n### Fallback Values\n\n```css\n/* Always provide fallbacks for critical styles */\n.element {\n  color: var(--color-text, #111827);\n  padding: var(--spacing-4, 1rem);\n}\n\n/* Chain references with fallbacks at the end */\n.button {\n  background: var(--button-bg, var(--color-primary, #3b82f6));\n}\n```\n\n### Documentation\n\n```css\n/* Document token purpose and usage */\n\n/**\n * Primary brand color\n * Use for: buttons, links, focus rings\n * Contrast: 4.5:1 on white background\n */\n--color-primary: #3b82f6;\n\n/**\n * Base spacing unit\n * Use multiples: 2 (8px), 4 (16px), 8 (32px)\n */\n--spacing-1: 0.25rem;\n```\n\n## Common Patterns\n\n### Color Palette Generation\n\n```css\n/* Semantic colors referencing primitives */\n:root {\n  /* Primitive palette */\n  --color-blue-50: #eff6ff;\n  --color-blue-100: #dbeafe;\n  --color-blue-200: #bfdbfe;\n  --color-blue-300: #93c5fd;\n  --color-blue-400: #60a5fa;\n  --color-blue-500: #3b82f6;\n  --color-blue-600: #2563eb;\n  --color-blue-700: #1d4ed8;\n  --color-blue-800: #1e40af;\n  --color-blue-900: #1e3a8a;\n\n  /* Semantic mapping */\n  --color-primary: var(--color-blue-600);\n  --color-primary-light: var(--color-blue-100);\n  --color-primary-dark: var(--color-blue-800);\n}\n```\n\n### Typography Scale\n\n```css\n:root {\n  /* Modular scale (1.25 ratio) */\n  --font-size-xs: 0.64rem;   /* 10.24px */\n  --font-size-sm: 0.8rem;    /* 12.8px */\n  --font-size-base: 1rem;    /* 16px */\n  --font-size-lg: 1.25rem;   /* 20px */\n  --font-size-xl: 1.563rem;  /* 25px */\n  --font-size-2xl: 1.953rem; /* 31.25px */\n  --font-size-3xl: 2.441rem; /* 39.06px */\n\n  /* Line heights */\n  --line-height-tight: 1.25;\n  --line-height-normal: 1.5;\n  --line-height-relaxed: 1.75;\n}\n```\n\n### Spacing Scale\n\n```css\n:root {\n  /* 4px base unit */\n  --spacing-0: 0;\n  --spacing-1: 0.25rem;  /* 4px */\n  --spacing-2: 0.5rem;   /* 8px */\n  --spacing-3: 0.75rem;  /* 12px */\n  --spacing-4: 1rem;     /* 16px */\n  --spacing-5: 1.25rem;  /* 20px */\n  --spacing-6: 1.5rem;   /* 24px */\n  --spacing-8: 2rem;     /* 32px */\n  --spacing-10: 2.5rem;  /* 40px */\n  --spacing-12: 3rem;    /* 48px */\n  --spacing-16: 4rem;    /* 64px */\n}\n```\n\n## Migration Guide\n\n### From Hardcoded Values\n\n```css\n/* Before */\n.button {\n  background: #3b82f6;\n  padding: 8px 16px;\n  border-radius: 4px;\n}\n\n/* After */\n.button {\n  background: var(--color-primary);\n  padding: var(--spacing-2) var(--spacing-4);\n  border-radius: var(--border-radius-sm);\n}\n```\n\n### From Sass Variables\n\n```scss\n// Before (Sass)\n$primary: #3b82f6;\n$spacing-md: 1rem;\n\n.button {\n  background: $primary;\n  padding: $spacing-md;\n}\n\n// After (CSS custom properties)\n:root {\n  --color-primary: #3b82f6;\n  --spacing-4: 1rem;\n}\n\n.button {\n  background: var(--color-primary);\n  padding: var(--spacing-4);\n}\n```\n\n## References\n\n- CSS Custom Properties: https://developer.mozilla.org/en-US/docs/Web/CSS/CSS_cascading_variables\n- Design Tokens Format: https://design-tokens.github.io/community-group/format/\n- Style Dictionary: https://styledictionary.com/\n- Tailwind CSS: https://tailwindcss.com/docs/customizing-colors"
              }
            ]
          },
          {
            "name": "dotfiles-plugin",
            "description": "Dotfiles and editor configuration - chezmoi, neovim, obsidian",
            "source": "./dotfiles-plugin",
            "category": "configuration",
            "version": "1.0.0",
            "author": null,
            "install_commands": [
              "/plugin marketplace add laurigates/claude-plugins",
              "/plugin install dotfiles-plugin@lgates-claude-plugins"
            ],
            "signals": {
              "stars": 1,
              "forks": 0,
              "pushed_at": "2026-01-12T12:05:51Z",
              "created_at": "2025-12-16T11:24:04Z",
              "license": null
            },
            "commands": [],
            "skills": [
              {
                "name": "chezmoi-expert",
                "description": "Comprehensive chezmoi dotfiles management expertise including templates, cross-platform\nconfiguration, file naming conventions, and troubleshooting. Covers source directory\nmanagement, reproducible environment setup, and chezmoi templating with Go templates.\nUse when user mentions chezmoi, dotfiles, cross-platform config, chezmoi apply,\nchezmoi diff, .chezmoidata, or managing configuration files across machines.\n",
                "path": "dotfiles-plugin/skills/chezmoi-expert/SKILL.md",
                "frontmatter": {
                  "created": "2025-12-16T00:00:00.000Z",
                  "modified": "2025-12-16T00:00:00.000Z",
                  "reviewed": "2025-12-16T00:00:00.000Z",
                  "name": "chezmoi-expert",
                  "description": "Comprehensive chezmoi dotfiles management expertise including templates, cross-platform\nconfiguration, file naming conventions, and troubleshooting. Covers source directory\nmanagement, reproducible environment setup, and chezmoi templating with Go templates.\nUse when user mentions chezmoi, dotfiles, cross-platform config, chezmoi apply,\nchezmoi diff, .chezmoidata, or managing configuration files across machines.\n",
                  "allowed-tools": "Bash, Read, Write, Edit, Grep, Glob"
                },
                "content": "# Chezmoi Expert\n\nExpert knowledge for managing dotfiles with chezmoi, including templates, cross-platform support, and best practices.\n\n## Core Expertise\n\n- **Source vs Target Management**: Always work in `~/.local/share/chezmoi/`, never edit target files directly\n- **File Naming Conventions**: `dot_`, `private_`, `readonly_`, `executable_`, `exact_`, `symlink_` prefixes\n- **Template System**: Go templates with `.chezmoi.*` variables for platform-specific configs\n- **Cross-Platform Support**: Conditional logic for macOS/Linux differences\n\n## Critical Workflow\n\n**ALWAYS follow this workflow:**\n1. `chezmoi diff` - Preview changes before applying\n2. `chezmoi apply --dry-run` - Safe testing\n3. `chezmoi apply -v <path>` - Apply specific paths first\n4. Let user review before full `chezmoi apply`\n\n## Essential Commands\n\n```bash\n# Check differences\nchezmoi diff                    # All pending changes\nchezmoi status                  # Quick status overview\nchezmoi diff ~/.config/nvim     # Specific path changes\n\n# Apply changes\nchezmoi apply --dry-run         # Safe preview\nchezmoi apply -v ~/.config/nvim # Apply specific path\nchezmoi apply -v                # Apply all after review\n\n# Manage files\nchezmoi add ~/.bashrc           # Start managing file\nchezmoi re-add ~/.bashrc        # Update from modified target\nchezmoi managed                 # List managed files\nchezmoi verify                  # Verify target matches source\n\n# Templates\nchezmoi data                    # Show template variables\nchezmoi dump ~/.config/file     # Preview rendered output\nchezmoi execute-template < file # Test template\n```\n\n## File Naming Reference\n\n```\nSource                            Target\ndot_bashrc                       ~/.bashrc\nprivate_dot_ssh/config           ~/.ssh/config (mode 0600)\ndot_config/nvim/init.lua.tmpl    ~/.config/nvim/init.lua (templated)\nexact_dot_config/app/            ~/.config/app/ (exact match)\nexecutable_script.sh             ~/script.sh (mode 0755)\n```\n\n## Template Examples\n\n### Platform Detection\n```go\n{{ if eq .chezmoi.os \"darwin\" }}\n# macOS specific\nexport HOMEBREW_PREFIX=\"/opt/homebrew\"\n{{ else if eq .chezmoi.os \"linux\" }}\n# Linux specific\nexport HOMEBREW_PREFIX=\"/home/linuxbrew/.linuxbrew\"\n{{ end }}\n```\n\n### Architecture-Specific\n```go\n{{ if eq .chezmoi.arch \"arm64\" }}\n# Apple Silicon\nexport DOCKER_DEFAULT_PLATFORM=linux/arm64/v8\n{{ else if eq .chezmoi.arch \"amd64\" }}\n# Intel/AMD\nexport DOCKER_DEFAULT_PLATFORM=linux/amd64\n{{ end }}\n```\n\n## Special Files\n\n- `.chezmoi.toml.tmpl` - Main configuration template\n- `.chezmoiignore` - Files to ignore\n- `.chezmoiremove` - Files to remove from target\n- `.chezmoiexternal.toml` - External file management\n- `run_once_*.sh` - Run once on first apply\n- `run_onchange_*.sh` - Run when hash changes\n\n## Troubleshooting\n\n### Changes Not Applying\n```bash\nchezmoi managed | grep filename  # Check if managed\nchezmoi apply --force ~/.config/file  # Force apply\n```\n\n### Template Errors\n```bash\nchezmoi execute-template < file.tmpl  # Test rendering\nchezmoi data                          # Check variables\nchezmoi apply -v --debug ~/.config/file  # Debug output\n```\n\n### Merge Conflicts\n```bash\nchezmoi merge ~/.config/file     # Three-way merge\nchezmoi source-path ~/.config/file  # Get source path for manual edit\n```\n\nFor detailed reference documentation, see REFERENCE.md."
              },
              {
                "name": "neovim-configuration",
                "description": "Modern Neovim configuration expertise including Lua scripting, plugin management with\nlazy.nvim, LSP setup with Mason, AI integration with CodeCompanion, and workflow\noptimization. Covers keymaps, autocommands, and treesitter configuration.\nUse when user mentions Neovim, nvim, lazy.nvim, Mason, init.lua, Lua config,\nnvim plugins, or Neovim customization.\n",
                "path": "dotfiles-plugin/skills/neovim-configuration/SKILL.md",
                "frontmatter": {
                  "created": "2025-12-16T00:00:00.000Z",
                  "modified": "2025-12-16T00:00:00.000Z",
                  "reviewed": "2025-12-16T00:00:00.000Z",
                  "name": "neovim-configuration",
                  "description": "Modern Neovim configuration expertise including Lua scripting, plugin management with\nlazy.nvim, LSP setup with Mason, AI integration with CodeCompanion, and workflow\noptimization. Covers keymaps, autocommands, and treesitter configuration.\nUse when user mentions Neovim, nvim, lazy.nvim, Mason, init.lua, Lua config,\nnvim plugins, or Neovim customization.\n",
                  "allowed-tools": "Glob, Grep, Read, Edit, Write"
                },
                "content": "# Neovim Configuration\n\nExpert knowledge for modern Neovim configuration with Lua scripting, plugin management, LSP setup, and AI integration for optimal development workflows.\n\n## Core Expertise\n\n**Modern Neovim Configuration**\n- Lua-based configuration with lazy.nvim plugin management\n- LSP setup with Mason for language server management\n- AI integration with CodeCompanion and custom prompt strategies\n- Advanced key mapping and workflow optimization\n\n## Key Capabilities\n\n**Plugin Management & Architecture**\n- **lazy.nvim**: Modern plugin manager with lazy loading and performance optimization\n- **Mason.nvim**: Language server, DAP server, linter, and formatter management\n- **Plugin Organization**: Structured configuration with modular plugin setup\n- **Performance Optimization**: Startup time optimization and lazy loading strategies\n\n**Language Server Protocol (LSP) Integration**\n- **LSP Configuration**: Multi-language LSP setup with proper keybindings\n- **Completion**: nvim-cmp with multiple sources and intelligent completion\n- **Diagnostics**: Error handling, linting integration, and diagnostic display\n- **Code Navigation**: Go-to-definition, references, and symbol search\n\n**AI Integration & Automation**\n- **CodeCompanion**: AI-powered code assistance with custom prompts\n- **Custom Strategies**: Domain-specific AI workflows for different development contexts\n- **Prompt Management**: Custom prompts for Arduino, deployment, debugging, and more\n- **Workflow Integration**: AI assistance integrated into development workflows\n\n**Advanced Features**\n- **Treesitter**: Syntax highlighting, text objects, and code understanding\n- **Telescope**: Fuzzy finder for files, buffers, grep, and more\n- **Git Integration**: Fugitive, gitsigns, and version control workflows\n- **Testing Integration**: neotest with multi-language testing support\n- **Debugging**: nvim-dap with debugger integration for multiple languages\n\n**UI/UX Enhancements**\n- **Theme Management**: Color scheme selection and customization\n- **Status Line**: Custom status line with relevant information\n- **File Explorer**: File management with nvim-tree or oil.nvim\n- **Window Management**: Smart window splitting and navigation\n\n## Configuration Workflow\n\n**Neovim Configuration Process**\n1. **Configuration Architecture**: Design modular Lua configuration structure\n2. **Plugin Selection**: Choose optimal plugins for development workflow needs\n3. **LSP Setup**: Configure language servers with proper capabilities and keybindings\n4. **Keybinding Design**: Create intuitive, memorable key mappings\n5. **Performance Optimization**: Optimize startup time and runtime performance\n6. **AI Integration**: Set up AI assistance with custom prompts and workflows\n7. **Testing & Refinement**: Validate configuration across different file types and workflows\n\n## Best Practices\n\n**Configuration Organization**\n- Use modular Lua configuration with clear separation of concerns\n- Implement lazy loading for plugins to optimize startup time\n- Create consistent keybinding patterns across different modes and contexts\n- Maintain configuration documentation and comments for future reference\n\n**LSP & Development Tools**\n- Configure LSP servers with proper capabilities and error handling\n- Set up intelligent completion with multiple sources and filtering\n- Integrate formatters and linters with null-ls or conform.nvim\n- Create language-specific configurations for optimal development experience\n\n**Performance & Reliability**\n- Profile startup time and identify performance bottlenecks\n- Use lazy loading and conditional plugin loading\n- Implement proper error handling for plugin failures\n- Regular configuration maintenance and plugin updates\n\n## Priority Areas\n\n**Give priority to:**\n- Performance issues causing slow startup or laggy editing experience\n- LSP configuration problems preventing proper language support\n- Plugin conflicts or errors disrupting development workflow\n- Keybinding conflicts or inconsistencies affecting productivity\n- AI integration issues preventing effective code assistance\n\n## Common Configuration Patterns\n\n**Lazy.nvim Plugin Setup**\n```lua\nreturn {\n  \"plugin/name\",\n  lazy = true,\n  event = \"VeryLazy\",\n  dependencies = { \"dependency/plugin\" },\n  config = function()\n    require(\"plugin\").setup({\n      -- configuration\n    })\n  end,\n  keys = {\n    { \"<leader>k\", \"<cmd>Command<cr>\", desc = \"Description\" }\n  }\n}\n```\n\n**LSP Configuration**\n```lua\nlocal lspconfig = require(\"lspconfig\")\nlspconfig.lua_ls.setup({\n  on_attach = function(client, bufnr)\n    -- Keybindings and capabilities\n  end,\n  settings = {\n    Lua = {\n      diagnostics = { globals = { \"vim\" } }\n    }\n  }\n})\n```\n\n**Keybinding Pattern**\n```lua\nvim.keymap.set(\"n\", \"<leader>f\", function()\n  -- Function implementation\nend, { desc = \"Description\", silent = true })\n```\n\nThis expertise creates a highly optimized, modern development environment that enhances productivity through intelligent configuration, seamless tool integration, and AI-powered assistance while maintaining excellent performance and reliability."
              },
              {
                "name": "obsidian-bases",
                "description": "Obsidian Bases database feature for YAML-based interactive note views. Use when creating .base files, writing filter queries, building formulas, configuring table/card views, or working with Obsidian properties and frontmatter databases.",
                "path": "dotfiles-plugin/skills/obsidian-bases/SKILL.md",
                "frontmatter": {
                  "created": "2025-12-16T00:00:00.000Z",
                  "modified": "2025-12-16T00:00:00.000Z",
                  "reviewed": "2025-12-16T00:00:00.000Z",
                  "name": "obsidian-bases",
                  "description": "Obsidian Bases database feature for YAML-based interactive note views. Use when creating .base files, writing filter queries, building formulas, configuring table/card views, or working with Obsidian properties and frontmatter databases.",
                  "allowed-tools": "Read, Write, Edit, Grep, Glob"
                },
                "content": "# Obsidian Bases\n\nExpert knowledge for creating and managing Obsidian Bases - the interactive database feature introduced in Obsidian v1.9.10 that transforms notes into filterable, sortable views using YAML frontmatter properties.\n\n## Core Concepts\n\n**What is Bases?**\n- Native core plugin (no community plugins required)\n- Creates interactive database views from any set of notes\n- Uses `.base` file extension (plain-text YAML format)\n- **Only reads YAML frontmatter** - does not parse note content\n- Faster performance than Dataview with inline editing support\n\n**Key Distinction from Dataview:**\n- Bases: User-friendly, visual, inline editable, YAML frontmatter only\n- Dataview: More powerful queries, inline properties, content parsing\n\n## File Structure\n\n```yaml\n# example.base\nfilters:\n  # Global filters (apply to all views)\n  and:\n    - 'status != \"done\"'\n    - taggedWith(file.file, \"project\")\n\nformulas:\n  # Computed properties\n  days_left: '(dueDate - today()).days()'\n  status_icon: 'if(done, \"\", \"\")'\n\nviews:\n  - type: table\n    name: \"Active Tasks\"\n    filters:\n      'dueDate > now()'      # View-specific filter\n    properties:\n      - name: title\n        displayName: \"Task\"\n      - name: status\n      - name: dueDate\n    sort:\n      - property: dueDate\n        direction: asc\n\n  - type: card\n    name: \"Visual View\"\n    properties:\n      - name: cover\n      - name: title\n```\n\n## Property Access Patterns\n\n### Note Properties (Frontmatter)\n\n```yaml\n# Shorthand access\nprice\nstatus\ntags\n\n# Explicit prefix\nnote.price\nnote.status\n\n# Bracket notation (for spaces)\nnote[\"property name\"]\n```\n\n### File Properties (Implicit)\n\n```yaml\nfile.path      # Full file path\nfile.name      # File name only\nfile.folder    # Parent folder\nfile.size      # File size in bytes\nfile.ctime     # Creation time\nfile.mtime     # Modification time\nfile.ext       # Extension\nfile.file      # File object (for filter functions)\nfile.links     # Outgoing links\nfile.inlinks   # Incoming backlinks\n```\n\n### Formula Properties\n\n```yaml\nformula.my_formula\nformula[\"formula name\"]\n```\n\n## Filter Syntax\n\n### Basic Operators\n\n```yaml\n# Comparison (must have spaces around operators)\nprice > 10\nstatus == \"done\"\nage >= 18\n\n# Logical operators\nand:\n  - condition1\n  - condition2\n\nor:\n  - condition1\n  - condition2\n\nnot:\n  - condition\n```\n\n### Filter Functions\n\n```yaml\n# Tag filtering\ntaggedWith(file.file, \"project\")\ntaggedWith(file.file, \"project/web\")     # Nested tags\n\n# Link filtering\nlinksTo(file.file, \"Note Name\")\nfile.hasLink(this.file)                  # Backlinks to current note\n\n# Folder filtering\ninFolder(file.file, \"Projects\")\ninFolder(file.file, \"Projects/Web\")      # Nested folders\n\n# Date filtering\nfile.mtime > now() - \"1 week\"            # Modified recently\ndueDate < today()                        # Overdue\ncreatedDate >= \"2025-01-01\"              # This year\n\n# Regex matching\n/\\d{4}-\\d{2}-\\d{2}/.matches(file.name)   # Daily note format\n```\n\n### The `this` Variable\n\nContext-aware reference to the active note:\n\n```yaml\n# In sidebar: references active note in main pane\nfile.hasLink(this.file)                  # Find backlinks\n\n# In embedded base: references containing note\nfile.folder == this.file.folder          # Same folder\n\n# Exclude current note\nfile.path != this.file.path\n```\n\n## Formula Syntax\n\n### Basic Formulas\n\n```yaml\nformulas:\n  # Arithmetic\n  total: \"price * quantity\"\n  discounted: \"total * 0.9\"\n\n  # String manipulation\n  full_name: 'firstName + \" \" + lastName'\n\n  # Conditional logic\n  status_emoji: 'if(status == \"done\", \"\", if(status == \"in-progress\", \"\", \"\"))'\n\n  # Date calculations\n  days_until: '(dueDate - today()).days()'\n  overdue: 'dueDate < today()'\n\n  # Link analysis\n  backlink_count: 'file.inlinks.length'\n  has_backlinks: 'file.inlinks.length > 0'\n```\n\n### Built-in Functions\n\n**Global:**\n- `today()` - Current date\n- `now()` - Current date and time\n- `link(target, displayText?)` - Create link\n- `image(url)` - Create image object\n- `list(value)` - Ensure value is a list\n- `if(condition, trueResult, falseResult?)` - Conditional\n\n**String methods:**\n- `.toUpperCase()`, `.toLowerCase()`\n- `.trim()`, `.split(separator)`\n- `.startsWith(prefix)`, `.endsWith(suffix)`\n- `.replace(search, replacement)`\n\n**Number methods:**\n- `.toFixed(decimals)` - Format decimal places\n- `.round()`, `.floor()`, `.ceil()`\n\n**Date methods:**\n- `.date()` - Convert to date\n- `.startOf(unit)`, `.endOf(unit)`\n- `.format(pattern)`\n- `.days()`, `.months()`, `.years()` - Duration extraction\n\n**List methods:**\n- `.length` - Count elements\n- `[index]` - Access element (0-based)\n- `.filter(condition)` - Filter elements\n- `.map(transformation)` - Transform elements\n- `.join(separator)` - Concatenate to string\n\n### Duration Units\n\n```yaml\nnow() + \"1 week\"\nnow() - \"30 days\"\nfile.mtime > now() - \"1 month\"\n\n# Available units\ny, year, years\nM, month, months\nw, week, weeks\nd, day, days\nh, hour, hours\nm, minute, minutes\ns, second, seconds\n```\n\n## View Types\n\n### Table View\n\n```yaml\nviews:\n  - type: table\n    name: \"Tasks\"\n    properties:\n      - name: title\n        displayName: \"Task Name\"    # Column header\n        width: 200                   # Optional width\n      - name: status\n      - name: dueDate\n    sort:\n      - property: dueDate\n        direction: asc              # or desc\n```\n\n### Card View\n\n```yaml\nviews:\n  - type: card\n    name: \"Projects\"\n    properties:\n      - name: cover              # Cover image\n      - name: title\n      - name: status\n```\n\n## Common Patterns\n\n### Task Management\n\n```yaml\nfilters:\n  taggedWith(file.file, \"task\")\n\nformulas:\n  overdue: 'dueDate < today()'\n  priority_icon: 'if(priority == \"high\", \"\", if(priority == \"medium\", \"\", \"\"))'\n\nviews:\n  - type: table\n    name: \"Active\"\n    filters:\n      'status != \"done\"'\n    sort:\n      - property: dueDate\n        direction: asc\n```\n\n### Enhanced Backlinks\n\n```yaml\n# Drag to sidebar for context-aware backlinks\nfilters:\n  file.hasLink(this.file)\n\nviews:\n  - type: table\n    name: \"Backlinks\"\n    properties:\n      - name: file.name\n        displayName: \"Note\"\n      - name: file.mtime\n        displayName: \"Modified\"\n```\n\n### Book/Media Library\n\n```yaml\nfilters:\n  taggedWith(file.file, \"book\")\n\nformulas:\n  year_read: 'dateFinished.date().year()'\n\nviews:\n  - type: card\n    name: \"Library\"\n    properties:\n      - name: cover\n      - name: title\n      - name: author\n\n  - type: table\n    name: \"Reading List\"\n    filters:\n      'status == \"to-read\"'\n```\n\n### Weekly Review\n\n```yaml\nfilters:\n  file.mtime > now() - \"1 week\"\n\nformulas:\n  days_ago: '(today() - file.mtime.date()).days()'\n\nviews:\n  - type: table\n    name: \"Recent Activity\"\n    sort:\n      - property: file.mtime\n        direction: desc\n```\n\n## Embedding Bases\n\n```markdown\n![[MyBase.base]]                # Embed entire base\n![[MyBase.base#ViewName]]       # Embed specific view\n```\n\n## Best Practices\n\n**Filter Organization:**\n- Use global filters for the broadest scope (lowest common denominator)\n- Refine with view-level filters for specific subsets\n- Global + view filters combine with AND\n\n**Formula Reusability:**\n- Create formula properties for repeated logic\n- Reference as `formula.name` in views\n- No circular references allowed\n\n**Robust List Handling:**\n```yaml\n# Always wrap in list() for mixed single/array values\nlist(tags).length\nlist(tags).filter(value.startsWith(\"project\"))\n```\n\n**Date Validation:**\n```yaml\nvalid_date: 'if(dueDate, dueDate, \"No date\")'\n```\n\n## Common Gotchas\n\n**1. Arithmetic operator spacing:**\n```yaml\n#  Correct\nprice * 2\n\n#  Wrong (parser error)\nprice*2\n```\n\n**2. Quote nesting in YAML:**\n```yaml\n#  Correct - single outer, double inner\nformulas:\n  message: 'Hello \"world\"'\n\n#  Wrong\nformulas:\n  message: \"Hello \"world\"\"\n```\n\n**3. Link properties in frontmatter:**\n```yaml\n#  Correct - must quote\nrelated: \"[[Other Note]]\"\n\n#  Wrong\nrelated: [[Other Note]]\n```\n\n**4. File extension required:**\n```markdown\n<!--  Correct -->\n![[MyBase.base]]\n\n<!--  Wrong (looks for .md) -->\n![[MyBase]]\n```\n\n**5. Global vs view filter scope:**\n- Cannot override global filter at view level\n- Make global permissive, refine in views\n\n## Current Limitations\n\n- **View types:** Only table and card (no board, calendar, gallery yet)\n- **Images:** Display as text, not rendered in cards\n- **Inline properties:** Only YAML frontmatter (no Dataview inline fields)\n- **Content parsing:** Cannot query note body text\n- **Note creation:** Cannot create new notes from base\n- **Grouping:** No native group-by (use separate views instead)\n- **Aggregations:** No built-in sum/average/count\n\n## Property Types\n\n| Type | Example |\n|------|---------|\n| Text | `\"Project Alpha\"` |\n| List | `[\"tag1\", \"tag2\"]` |\n| Number | `42`, `3.14` |\n| Checkbox | `true`, `false` |\n| Date | `2025-11-26` |\n| Date & Time | `2025-11-26T14:30:00` |\n\n**Note:** Property types are vault-wide. If `priority` is Number in one note, it must be Number everywhere.\n\n## Resources\n\n- **Official Docs:** https://help.obsidian.md/bases\n- **Syntax Reference:** https://help.obsidian.md/bases/syntax\n- **Functions:** https://help.obsidian.md/bases/functions\n- **Roadmap:** https://help.obsidian.md/bases/roadmap"
              }
            ]
          },
          {
            "name": "bevy-plugin",
            "description": "Bevy game engine development - ECS, rendering, game architecture",
            "source": "./bevy-plugin",
            "category": "gamedev",
            "version": "1.0.0",
            "author": null,
            "install_commands": [
              "/plugin marketplace add laurigates/claude-plugins",
              "/plugin install bevy-plugin@lgates-claude-plugins"
            ],
            "signals": {
              "stars": 1,
              "forks": 0,
              "pushed_at": "2026-01-12T12:05:51Z",
              "created_at": "2025-12-16T11:24:04Z",
              "license": null
            },
            "commands": [],
            "skills": []
          },
          {
            "name": "graphiti-plugin",
            "description": "Graphiti knowledge graph - memory, learning, episode storage",
            "source": "./graphiti-plugin",
            "category": "ai",
            "version": "1.0.0",
            "author": null,
            "install_commands": [
              "/plugin marketplace add laurigates/claude-plugins",
              "/plugin install graphiti-plugin@lgates-claude-plugins"
            ],
            "signals": {
              "stars": 1,
              "forks": 0,
              "pushed_at": "2026-01-12T12:05:51Z",
              "created_at": "2025-12-16T11:24:04Z",
              "license": null
            },
            "commands": [],
            "skills": [
              {
                "name": "graphiti-episode-storage",
                "description": "Store episodes in Graphiti Memory: agent executions, error resolutions, workflow\ncompletions, technical decisions. Provides JSON schemas and storage patterns.\nUse when user mentions storing in Graphiti, add_memory, episode storage,\nbuilding knowledge base, or documenting agent work.\n",
                "path": "graphiti-plugin/skills/graphiti-episode-storage/SKILL.md",
                "frontmatter": {
                  "created": "2025-12-16T00:00:00.000Z",
                  "modified": "2025-12-16T00:00:00.000Z",
                  "reviewed": "2025-12-16T00:00:00.000Z",
                  "name": "graphiti-episode-storage",
                  "description": "Store episodes in Graphiti Memory: agent executions, error resolutions, workflow\ncompletions, technical decisions. Provides JSON schemas and storage patterns.\nUse when user mentions storing in Graphiti, add_memory, episode storage,\nbuilding knowledge base, or documenting agent work.\n"
                },
                "content": "# Graphiti Episode Storage\n\n## Description\n\nPatterns for storing episodes in Graphiti Memory including agent executions, error resolutions, workflow completions, and technical decisions. This skill provides proven JSON schemas and storage patterns for building institutional knowledge.\n\n## When to Use\n\nAutomatically apply this skill when:\n- Completing significant agent work\n- Resolving non-trivial errors\n- Finishing multi-step workflows\n- Making important technical decisions\n- Need to document execution for learning\n- Creating audit trails\n\n## Core Concept: Episodes\n\n**Episodes** are discrete events stored in Graphiti Memory that get automatically processed into facts and entities:\n\n- Agent executions and their outcomes\n- Error resolutions with root causes\n- Workflow completions with metrics\n- Technical decision rationales\n\n## Episode Storage Patterns\n\n### Pattern 1: Agent Execution Episodes\n\nStore each agent execution for learning and audit:\n\n```python\nmcp__graphiti-memory__add_memory(\n    name=f\"Agent Execution: {agent_name} - {task_summary}\",\n    episode_body=json.dumps({\n        \"agent\": agent_name,\n        \"timestamp\": datetime.now().isoformat(),\n        \"task_description\": user_request,\n        \"context_provided\": {\n            \"tech_stack\": [\"FastAPI\", \"PostgreSQL\"],\n            \"constraints\": [\"Must support async\", \"90% test coverage\"]\n        },\n        \"approach_taken\": [\n            \"Researched FastAPI async patterns\",\n            \"Implemented connection pooling\",\n            \"Added pytest-asyncio for testing\"\n        ],\n        \"outcome\": \"SUCCESS|PARTIAL|FAILED\",\n        \"deliverables\": [\n            \"API endpoints in /src/api/\",\n            \"Tests in /tests/\",\n            \"Documentation in /docs/\"\n        ],\n        \"lessons_learned\": [\n            \"Async context managers critical for DB connections\",\n            \"pytest-asyncio fixtures simplify testing\"\n        ],\n        \"time_spent_minutes\": 45,\n        \"challenges_encountered\": [\n            \"Initial connection pool configuration incorrect\"\n        ]\n    }),\n    source=\"json\",\n    source_description=f\"Agent execution: {agent_name}\",\n    group_id=f\"{agent_name}_executions\"\n)\n```\n\n**When to use**: After every significant agent execution\n**Value**: Learn from similar tasks, avoid past mistakes\n\n### Pattern 2: Error Resolution Episodes\n\nDocument how errors were resolved:\n\n```python\nmcp__graphiti-memory__add_memory(\n    name=f\"Error Resolved: {error_type} - {solution_summary}\",\n    episode_body=json.dumps({\n        \"error_type\": \"DatabaseConnectionError\",\n        \"context\": {\n            \"tech_stack\": [\"PostgreSQL\", \"SQLAlchemy\"],\n            \"environment\": \"Development\"\n        },\n        \"symptoms\": [\n            \"Connection timeouts after 30 seconds\",\n            \"Error: 'pool exhausted'\"\n        ],\n        \"root_cause\": \"Connection pool size too small for async workload\",\n        \"solution_applied\": \"Increased pool_size to 20, overflow to 10\",\n        \"verification\": \"No timeouts after load testing\",\n        \"similar_to\": \"Connection pooling issues seen in project X\",\n        \"prevention\": \"Always configure pool_size based on expected concurrency\"\n    }),\n    source=\"json\",\n    source_description=\"Error resolution\",\n    group_id=\"error_resolutions\"\n)\n```\n\n**When to use**: After resolving non-trivial errors\n**Value**: Build error knowledge base, faster future resolution\n\n### Pattern 3: Workflow Execution Episodes\n\nStore complete multi-agent workflow results:\n\n```python\nmcp__graphiti-memory__add_memory(\n    name=f\"Workflow: {workflow_type} - {project_name}\",\n    episode_body=json.dumps({\n        \"workflow_type\": \"api_development\",\n        \"project_name\": \"User Auth API\",\n        \"duration_minutes\": 180,\n        \"agents_involved\": [\n            \"research-assistant\",\n            \"python-developer\",\n            \"security-auditor\",\n            \"test-architect\"\n        ],\n        \"execution_sequence\": [\n            {\"agent\": \"research-assistant\", \"duration\": 30, \"outcome\": \"success\"},\n            {\"agent\": \"python-developer\", \"duration\": 90, \"outcome\": \"success\"},\n            {\"agent\": \"security-auditor\", \"duration\": 45, \"outcome\": \"issues_found\"},\n            {\"agent\": \"python-developer\", \"duration\": 15, \"outcome\": \"fixes_applied\"}\n        ],\n        \"overall_outcome\": \"SUCCESS\",\n        \"quality_metrics\": {\n            \"test_coverage\": \"94%\",\n            \"security_issues\": \"0 high, 2 low\",\n            \"performance\": \"avg 120ms response time\"\n        },\n        \"lessons_learned\": [\n            \"Security audit early prevents rework\",\n            \"Parallel testing during implementation saves time\"\n        ]\n    }),\n    source=\"json\",\n    source_description=\"Multi-agent workflow completion\",\n    group_id=\"workflow_executions\"\n)\n```\n\n**When to use**: After completing multi-step workflows\n**Value**: Optimize workflow patterns, estimate future timelines\n\n### Pattern 4: Decision Rationale Episodes\n\nDocument why important decisions were made:\n\n```python\nmcp__graphiti-memory__add_memory(\n    name=f\"Decision: {decision_topic} - {choice_made}\",\n    episode_body=json.dumps({\n        \"decision_topic\": \"API Framework Selection\",\n        \"context\": {\n            \"project_type\": \"REST API with async I/O\",\n            \"team_expertise\": \"Python\",\n            \"requirements\": [\"High performance\", \"Modern async support\"]\n        },\n        \"options_considered\": [\n            {\"option\": \"Flask\", \"pros\": [\"Simple\", \"Mature\"], \"cons\": [\"No async support\"]},\n            {\"option\": \"FastAPI\", \"pros\": [\"Async\", \"Modern\", \"Auto docs\"], \"cons\": [\"Newer\"]},\n            {\"option\": \"Django\", \"pros\": [\"Full-featured\"], \"cons\": [\"Heavy\", \"Not async-first\"]}\n        ],\n        \"decision_made\": \"FastAPI\",\n        \"rationale\": [\n            \"Async support critical for I/O-heavy workload\",\n            \"Auto OpenAPI docs reduce maintenance\",\n            \"Growing community and adoption\"\n        ],\n        \"outcome_months_later\": \"Excellent performance, team productive\"\n    }),\n    source=\"json\",\n    source_description=\"Technical decision rationale\",\n    group_id=\"technical_decisions\"\n)\n```\n\n**When to use**: After making significant technical decisions\n**Value**: Remember why decisions were made, inform future choices\n\n## Group ID Conventions\n\nOrganize episodes with consistent group IDs:\n\n**By Domain**:\n- `python_development` - Python-related tasks\n- `nodejs_development` - Node.js/TypeScript tasks\n- `rust_development` - Rust programming tasks\n- `infrastructure` - DevOps, containers, Kubernetes\n- `git_operations` - Git and GitHub operations\n\n**By Activity Type**:\n- `agent_executions` - General agent work\n- `error_resolutions` - Problem solving\n- `workflow_executions` - Multi-step workflows\n- `technical_decisions` - Architecture and tech choices\n- `code_reviews` - Review findings and improvements\n\n**By Project**:\n- `project_auth_api` - Specific project work\n- `project_frontend_app` - Another project\n- `migration_postgres_to_mongo` - Migration project\n\n**Best Practice**: Use descriptive, consistent group IDs for easy searching\n\n## Episode Quality Guidelines\n\n### What to Store\n\n **Store**:\n- Agent executions with approach and outcome\n- Error resolutions with root cause and fix\n- Workflow completions with metrics\n- Technical decisions with rationale\n- Patterns that emerge from work\n- Lessons learned from successes and failures\n\n **Don't Store**:\n- Trivial operations (single file edits)\n- Duplicate information already stored\n- Secrets or sensitive data\n- Excessively verbose logs\n- Work-in-progress (wait for completion)\n\n### Episode Quality\n\n**Good Episode** (specific, actionable):\n```json\n{\n  \"task\": \"Implement JWT authentication for FastAPI\",\n  \"approach\": [\"Used PyJWT library\", \"Added middleware decorator\"],\n  \"outcome\": \"SUCCESS\",\n  \"lessons\": \"HTTP-only cookies more secure than localStorage\"\n}\n```\n\n**Poor Episode** (vague, unusable):\n```json\n{\n  \"task\": \"Did some auth stuff\",\n  \"approach\": [\"Used library\"],\n  \"outcome\": \"It worked\"\n}\n```\n\n## Best Practices\n\n1. **Store after completion** - Wait until work succeeds before storing\n2. **Be specific** - Generic episodes aren't useful for learning\n3. **Include context** - Tech stack, constraints, requirements\n4. **Document outcomes** - Success/failure with metrics\n5. **Capture lessons** - What would you do differently?\n6. **Use consistent group IDs** - Makes searching effective\n7. **Update over time** - Add \"outcome_months_later\" insights\n\n## Common Pitfalls\n\n-  Storing episodes without outcomes (premature storage)\n-  Vague descriptions that don't help future work\n-  Storing failures without documenting what to avoid\n-  Not capturing \"why\" for decisions\n-  Overly verbose episodes (should be concise summaries)\n-  Inconsistent group_ids making search ineffective\n\n## Integration with Other Skills\n\n- **graphiti-memory-retrieval**: Search stored episodes before starting similar work\n- **graphiti-learning-workflows**: Use episodes in learning workflows\n- **agent-file-coordination**: Store agent execution episodes after workflows\n\n## References\n\n- Related Skills: `graphiti-memory-retrieval`, `graphiti-learning-workflows`\n- MCP Server: `graphiti-memory` (configured in settings.json)\n- Replaces: `knowledge-graph-patterns` (episode storage sections)"
              },
              {
                "name": "graphiti-learning-workflows",
                "description": "Learn from historical data and build institutional knowledge with Graphiti Memory.\nIntegrates episode storage and retrieval into learning patterns across sessions.\nUse when user mentions learning workflows, building knowledge over time,\nanalyzing past work patterns, or improving from historical data.\n",
                "path": "graphiti-plugin/skills/graphiti-learning-workflows/SKILL.md",
                "frontmatter": {
                  "created": "2025-12-16T00:00:00.000Z",
                  "modified": "2025-12-16T00:00:00.000Z",
                  "reviewed": "2025-12-16T00:00:00.000Z",
                  "name": "graphiti-learning-workflows",
                  "description": "Learn from historical data and build institutional knowledge with Graphiti Memory.\nIntegrates episode storage and retrieval into learning patterns across sessions.\nUse when user mentions learning workflows, building knowledge over time,\nanalyzing past work patterns, or improving from historical data.\n"
                },
                "content": "# Graphiti Learning Workflows\n\n## Description\n\nWorkflows for learning from historical data and building institutional knowledge over time. Integrates episode storage and memory retrieval into cohesive learning patterns that improve agent performance across sessions.\n\n## When to Use\n\nAutomatically apply this skill when:\n- Starting tasks similar to previous work\n- Building knowledge over time\n- Analyzing trends in development work\n- Creating audit trails for compliance\n- Improving from past successes and failures\n- Recognizing patterns across sessions\n\n## Learning Workflow Stages\n\n### Stage 1: Before Starting Work\n\n**Ask**: \"Have I done something like this before?\"\n\n**Workflow**:\n```\n1. Search for similar tasks in relevant group_ids\n2. Review past approaches and outcomes\n3. Note lessons learned from previous work\n4. Apply proven patterns\n5. Use proven successful approaches\n```\n\n**Example**:\n```python\n# User asks: \"Build REST API with JWT authentication\"\n\n# Step 1: Search for similar work\nsearch_memory_facts(\n    query=\"REST API JWT authentication implementation\",\n    group_ids=[\"python_development\", \"agent_executions\"],\n    max_facts=5\n)\n\n# Step 2: Review results\n# Found: FastAPI + JWT implementation from 2 months ago\n# Outcome: SUCCESS (94% test coverage, 120ms avg response)\n# Lessons: \"Use HTTP-only cookies\", \"Async context managers critical\"\n\n# Step 3: Apply insights\n# - Use FastAPI (proven to work)\n# - HTTP-only cookies for tokens\n# - Async database connections\n# - Start with pytest-asyncio fixtures\n\n# Result: Faster implementation, fewer mistakes\n```\n\n### Stage 2: During Work\n\n**Ask**: \"Am I encountering a known problem?\"\n\n**Workflow**:\n```\n1. When error occurs, search error_resolutions\n2. Check if similar issue solved before\n3. Apply known solutions first\n4. Try new approaches if no match\n5. Document new resolution for future\n```\n\n**Example**:\n```python\n# Error encountered: \"PostgreSQL connection pool exhausted\"\n\n# Step 1: Search for similar errors\nsearch_memory_facts(\n    query=\"PostgreSQL connection pool exhausted timeout\",\n    group_ids=[\"error_resolutions\"],\n    max_facts=3\n)\n\n# Step 2: Found match!\n# Root cause: Pool size too small for async workload\n# Solution: Increase pool_size to 20, overflow to 10\n# Verification: Load test confirms fix\n\n# Step 3: Apply immediately\n# Update config, test, verify\n\n# Result: 5-minute fix instead of hours of debugging\n```\n\n### Stage 3: After Completing Work\n\n**Ask**: \"What should I remember for next time?\"\n\n**Workflow**:\n```\n1. Store execution episode with approach taken\n2. Document lessons learned\n3. Note what worked well\n4. Record challenges and how overcome\n5. Update workflow patterns if improved\n```\n\n**Example**:\n```python\n# Just completed: FastAPI authentication implementation\n\n# Step 1: Store episode\nadd_memory(\n    name=\"Agent Execution: python-developer - FastAPI JWT Auth\",\n    episode_body=json.dumps({\n        \"task\": \"Implement JWT authentication for REST API\",\n        \"approach\": [\"FastAPI\", \"PyJWT\", \"HTTP-only cookies\"],\n        \"outcome\": \"SUCCESS\",\n        \"lessons_learned\": [\n            \"Async context managers essential for DB\",\n            \"HTTP-only cookies more secure than localStorage\",\n            \"pytest-asyncio fixtures simplify async tests\"\n        ],\n        \"time_spent\": 45,\n        \"deliverables\": [\"/src/api/auth.py\", \"/tests/test_auth.py\"]\n    }),\n    source=\"json\",\n    group_id=\"python_development\"\n)\n\n# Result: Knowledge available for next similar task\n```\n\n## Learning Patterns\n\n### Pattern 1: Incremental Learning\n\nBuild knowledge gradually from each task:\n\n**Week 1**: First FastAPI project\n- Store basic implementation patterns\n- Document initial lessons\n\n**Week 2**: Second FastAPI project\n- Search for first project patterns\n- Apply lessons learned\n- Store new insights\n\n**Week 3**: Third FastAPI project\n- Search both previous projects\n- Recognize emerging patterns\n- Store refined best practices\n\n**Result**: Each iteration improves on previous work\n\n### Pattern 2: Error Knowledge Base\n\nBuild comprehensive error resolution knowledge:\n\n**First Time**: Encounter error\n- Debug from scratch\n- Document solution\n- Store in error_resolutions\n\n**Second Time**: Similar error\n- Search error_resolutions\n- Apply known solution\n- Update if approach improved\n\n**Third Time**: Related error\n- Search finds similar patterns\n- Recognize pattern family\n- Solve faster each time\n\n**Result**: Error resolution time decreases over time\n\n### Pattern 3: Workflow Optimization\n\nImprove multi-agent workflows through learning:\n\n**Initial Workflow**:\n```\nResearch (30 min)  Development (90 min)  Testing (45 min)\nTotal: 165 minutes\n```\n\n**After storing and learning**:\n```\nReview past similar work (5 min) \nResearch only unknowns (15 min) \nDevelopment with proven patterns (60 min) \nTesting with known fixtures (30 min)\nTotal: 110 minutes (33% faster)\n```\n\n**Result**: Workflows optimize through historical learning\n\n### Pattern 4: Decision Consistency\n\nMake consistent technical decisions:\n\n**Problem**: Different projects use different authentication approaches\n\n**Solution**: Store decision rationales\n```python\nadd_memory(\n    name=\"Decision: API Authentication - JWT chosen\",\n    episode_body=json.dumps({\n        \"decision\": \"Use JWT with HTTP-only cookies\",\n        \"rationale\": [\n            \"Stateless scaling\",\n            \"Mobile app compatibility\",\n            \"Better security than localStorage\"\n        ],\n        \"alternatives_rejected\": [\n            \"Session cookies - scaling challenges\",\n            \"Basic auth - no token expiry\"\n        ]\n    }),\n    group_id=\"technical_decisions\"\n)\n```\n\n**Result**: Future projects search decisions, maintain consistency\n\n## Integration Workflows\n\n### Workflow 1: Agent Execution with Learning\n\n```\n1. Agent receives task\n2. Search for similar past work\n3. Review approaches and outcomes\n4. Execute task using insights\n5. Store execution results\n6. Note improvements made\n```\n\n**Tools used**:\n- `search_memory_facts` (before work)\n- `add_memory` (after work)\n\n### Workflow 2: Error Resolution with Learning\n\n```\n1. Error encountered\n2. Search error_resolutions\n3. If found: Apply solution\n4. If not found: Debug and solve\n5. Store resolution details\n6. Make available for future\n```\n\n**Tools used**:\n- `search_memory_facts` (when error occurs)\n- `add_memory` (after resolution)\n\n### Workflow 3: Multi-Agent Workflow with History\n\n```\n1. Workflow starts\n2. Search for similar past workflows\n3. Review agent sequence that worked\n4. Apply proven coordination patterns\n5. Execute workflow\n6. Store workflow results with metrics\n```\n\n**Tools used**:\n- `search_memory_nodes` (workflow patterns)\n- `add_memory` (workflow completion)\n\n## Metrics and Insights\n\nTrack improvement over time:\n\n**Efficiency Metrics**:\n- Time to complete similar tasks (trending down)\n- Error resolution time (trending down)\n- Code quality metrics (trending up)\n- Test coverage (trending up)\n\n**Knowledge Metrics**:\n- Episodes stored per domain\n- Successful pattern reuse count\n- Error resolution knowledge base size\n- Decision consistency rate\n\n**Example tracking**:\n```python\n# Search for all FastAPI projects\nsearch_memory_facts(\n    query=\"FastAPI project implementation\",\n    group_ids=[\"python_development\"],\n    max_facts=20\n)\n\n# Analyze:\n# - First project: 180 minutes, 85% coverage\n# - Second project: 120 minutes, 90% coverage\n# - Third project: 90 minutes, 94% coverage\n# Insight: 50% improvement through learning\n```\n\n## Best Practices\n\n1. **Always search before starting** - Don't reinvent solutions\n2. **Store after every significant task** - Build knowledge continuously\n3. **Be specific in episodes** - Generic data isn't useful\n4. **Document outcomes** - Success and failure both teach\n5. **Capture \"why\"** - Rationales help future decisions\n6. **Use consistent group_ids** - Makes patterns findable\n7. **Review trends** - Analyze improvement over time\n8. **Update episodes** - Add \"months later\" insights\n\n## Common Pitfalls\n\n-  Not searching before starting (missing available knowledge)\n-  Storing vague episodes (unusable for learning)\n-  Forgetting to store after work (lost learning opportunity)\n-  Inconsistent group_ids (fragmented knowledge)\n-  Not documenting failures (losing valuable lessons)\n-  Storing too much detail (noise obscures signal)\n-  Not reviewing past patterns (missing improvement opportunities)\n\n## Examples\n\n### Example 1: API Development Learning\n\n**First Project** (No history):\n```\nTask: Build REST API with auth\nTime: 180 minutes\nCoverage: 85%\nIssues: Connection pool problems, test fixture challenges\n\nStore episode with lessons learned\n```\n\n**Second Project** (With history):\n```\nSearch: \"REST API authentication connection pooling\"\nFound: First project lessons\nApplied: Known solutions\nTime: 120 minutes (33% faster)\nCoverage: 90%\nIssues: Minimal\n\nStore episode noting improvements\n```\n\n**Third Project** (Growing knowledge):\n```\nSearch: \"REST API authentication\"\nFound: Both previous projects\nPatterns recognized: Async context managers, pytest fixtures\nTime: 90 minutes (50% faster than first)\nCoverage: 94%\nIssues: None\n\nStore episode with refined patterns\n```\n\n### Example 2: Error Resolution Learning\n\n**First Occurrence**:\n```\nError: PostgreSQL connection timeouts\nDebug time: 2 hours\nSolution: Increase pool size\nStore: Detailed error resolution episode\n```\n\n**Second Occurrence** (Similar error):\n```\nError: MySQL connection timeouts\nSearch: \"database connection timeout pool\"\nFound: PostgreSQL solution\nApplied: Similar fix\nDebug time: 15 minutes (87% faster)\nStore: Updated episode with MySQL specifics\n```\n\n**Third Occurrence** (Pattern recognition):\n```\nError: Redis connection issues\nSearch: \"connection pool exhausted\"\nFound: Pattern across databases\nRecognized: Connection pool sizing principle\nDebug time: 5 minutes (95% faster)\nStore: General connection pooling best practices\n```\n\n## Integration with Other Skills\n\n- **graphiti-episode-storage**: Store episodes for learning\n- **graphiti-memory-retrieval**: Search for past knowledge\n- **agent-file-coordination**: Document agent learning in workflows\n- **agent-coordination-patterns**: Learn optimal coordination patterns\n\n## References\n\n- Related Skills: `graphiti-episode-storage`, `graphiti-memory-retrieval`\n- MCP Server: `graphiti-memory` (configured in settings.json)\n- Replaces: `knowledge-graph-patterns` (learning workflow sections)"
              },
              {
                "name": "graphiti-memory-retrieval",
                "description": "Search and retrieve information from Graphiti Memory graph database. Covers\nsearch_memory_facts, search_memory_nodes, query construction, and group filtering.\nUse when user mentions Graphiti search, memory retrieval, finding past work,\nsearching knowledge graph, or querying episodic memory.\n",
                "path": "graphiti-plugin/skills/graphiti-memory-retrieval/SKILL.md",
                "frontmatter": {
                  "created": "2025-12-16T00:00:00.000Z",
                  "modified": "2025-12-16T00:00:00.000Z",
                  "reviewed": "2025-12-16T00:00:00.000Z",
                  "name": "graphiti-memory-retrieval",
                  "description": "Search and retrieve information from Graphiti Memory graph database. Covers\nsearch_memory_facts, search_memory_nodes, query construction, and group filtering.\nUse when user mentions Graphiti search, memory retrieval, finding past work,\nsearching knowledge graph, or querying episodic memory.\n"
                },
                "content": "# Graphiti Memory Retrieval\n\n## Description\n\nTechniques for searching and retrieving information from Graphiti Memory. Provides proven search patterns for finding similar past work, error solutions, node summaries, and learning from historical data.\n\n## When to Use\n\nAutomatically apply this skill when:\n- Starting tasks similar to previous work\n- Encountering errors that may have been seen before\n- Looking for past patterns and solutions\n- Need to understand entity relationships\n- Building on proven approaches\n- Analyzing trends across sessions\n\n## Core Search Types\n\n**Facts Search**: Find specific relationships between entities\n- \"Agent X solved problem Y using approach Z\"\n- \"Configuration A causes error B\"\n- \"Pattern C appears in successful projects\"\n\n**Node Search**: Get comprehensive entity summaries\n- All relationships for an entity\n- How entities connect across episodes\n- Holistic view of patterns\n\n## Search Patterns\n\n### Pattern 1: Search for Similar Past Work\n\nBefore starting, search for similar tasks:\n\n```python\n# Search for similar operations\nmcp__graphiti-memory__search_memory_facts(\n    query=\"FastAPI async database connection setup with PostgreSQL\",\n    group_ids=[\"python_development\", \"agent_executions\"],\n    max_facts=5\n)\n\n# Use results to:\n# - Understand approach that worked before\n# - Avoid past mistakes\n# - Estimate time based on previous similar work\n```\n\n**When to use**: Before starting new work\n**Value**: Learn from past successes, avoid repeating mistakes\n\n### Pattern 2: Search for Error Patterns\n\nWhen encountering errors, search knowledge base:\n\n```python\n# Search for similar errors\nmcp__graphiti-memory__search_memory_facts(\n    query=\"PostgreSQL connection pool exhausted timeout\",\n    group_ids=[\"error_resolutions\"],\n    max_facts=3\n)\n\n# Use results to:\n# - Apply known solutions\n# - Avoid trying failed approaches\n# - Understand root causes faster\n```\n\n**When to use**: When encountering errors\n**Value**: Faster resolution using known solutions\n\n### Pattern 3: Search for Node Summaries\n\nGet comprehensive view of entity relationships:\n\n```python\n# Search for patterns across entity relationships\nmcp__graphiti-memory__search_memory_nodes(\n    query=\"FastAPI performance optimization techniques\",\n    group_ids=[\"python_development\"],\n    max_nodes=5\n)\n\n# Use results to:\n# - See all optimization patterns discovered\n# - Understand relationships between techniques\n# - Apply holistic approach\n```\n\n**When to use**: Need comprehensive understanding\n**Value**: See patterns and relationships\n\n### Pattern 4: Search Around Known Good Examples\n\nWhen you know a specific successful case:\n\n```python\n# Search centered on a known good execution\nmcp__graphiti-memory__search_memory_facts(\n    query=\"async testing patterns\",\n    center_node_uuid=\"<uuid_of_successful_project>\",\n    max_facts=10\n)\n\n# Use results to:\n# - Find related successful patterns\n# - See what worked in conjunction\n# - Build on proven approaches\n```\n\n**When to use**: Building on known successes\n**Value**: Find related winning patterns\n\n### Pattern 5: Entity-Filtered Search\n\nSearch for specific types of knowledge:\n\n```python\n# Search for user preferences\nmcp__graphiti-memory__search_memory_nodes(\n    query=\"coding style preferences for Python\",\n    entity=\"Preference\",\n    max_nodes=5\n)\n\n# Search for established procedures\nmcp__graphiti-memory__search_memory_nodes(\n    query=\"deployment workflow steps\",\n    entity=\"Procedure\",\n    max_nodes=5\n)\n\n# Permitted entity types: \"Preference\", \"Procedure\"\n```\n\n**When to use**: Looking for specific knowledge types\n**Value**: Targeted, relevant results\n\n## Query Construction Best Practices\n\n### Effective Queries\n\n**Good queries** (specific, contextual):\n-  \"FastAPI async database connection with PostgreSQL and connection pooling\"\n-  \"JWT authentication implementation with refresh tokens\"\n-  \"Rust async error handling with tokio runtime\"\n\n**Poor queries** (vague, generic):\n-  \"database stuff\"\n-  \"auth\"\n-  \"async\"\n\n### Query Tips\n\n1. **Include technology names**: \"FastAPI\", \"PostgreSQL\", \"React\"\n2. **Add context**: \"async\", \"authentication\", \"testing\"\n3. **Specify patterns**: \"connection pooling\", \"JWT tokens\", \"middleware\"\n4. **Use domain terms**: \"API endpoint\", \"database migration\", \"CI/CD\"\n\n## Group ID Filtering\n\nUse group IDs to narrow search scope:\n\n```python\n# Search specific domain\nsearch_memory_facts(\n    query=\"authentication implementation\",\n    group_ids=[\"python_development\"],  # Only Python work\n    max_facts=5\n)\n\n# Search multiple related domains\nsearch_memory_facts(\n    query=\"API authentication\",\n    group_ids=[\"python_development\", \"nodejs_development\"],\n    max_facts=5\n)\n\n# Search by activity type\nsearch_memory_facts(\n    query=\"authentication errors\",\n    group_ids=[\"error_resolutions\", \"security_audits\"],\n    max_facts=5\n)\n\n# Search specific project\nsearch_memory_facts(\n    query=\"deployment issues\",\n    group_ids=[\"project_auth_api\"],\n    max_facts=5\n)\n```\n\n## Result Interpretation\n\n### Fact Results\n\nFacts contain relationships:\n```\nEntity A --[relationship]--> Entity B\nExample: \"FastAPI project\" --[uses]--> \"PostgreSQL async driver\"\n```\n\n**Look for**:\n- Common patterns across multiple facts\n- Successful approaches (outcome: SUCCESS)\n- Warnings about failed approaches\n- Lessons learned\n\n### Node Results\n\nNodes contain entity summaries:\n```\nEntity: \"FastAPI Authentication\"\nSummary: All relationships this entity has\n```\n\n**Look for**:\n- How entity connects to other concepts\n- Frequency of appearance (important patterns)\n- Associated lessons and outcomes\n- Related best practices\n\n## Search Workflow\n\n### Before Starting Work\n\n1. **Search for similar tasks**\n   ```python\n   search_memory_facts(\n       query=\"<your task description with tech stack>\",\n       group_ids=[\"<relevant domain>\"],\n       max_facts=5\n   )\n   ```\n\n2. **Review results** for:\n   - Approaches that worked\n   - Pitfalls to avoid\n   - Time estimates\n   - Required resources\n\n3. **Apply insights** to current work\n\n### During Work (Error Encountered)\n\n1. **Search for similar errors**\n   ```python\n   search_memory_facts(\n       query=\"<error type> <technology> <symptoms>\",\n       group_ids=[\"error_resolutions\"],\n       max_facts=3\n   )\n   ```\n\n2. **Try known solutions first**\n3. **Document if new solution needed**\n\n### After Work (Validating Approach)\n\n1. **Search for similar successful work**\n   ```python\n   search_memory_nodes(\n       query=\"<technology> <pattern> best practices\",\n       max_nodes=5\n   )\n   ```\n\n2. **Compare your approach** to past successes\n3. **Note improvements** for future episodes\n\n## Best Practices\n\n1. **Search before starting** - Don't reinvent the wheel\n2. **Use specific queries** - Generic queries return generic results\n3. **Filter by group_id** - Narrow scope for relevance\n4. **Review multiple results** - Patterns emerge from multiple facts\n5. **Apply lessons learned** - Use historical knowledge\n6. **Combine search types** - Use both facts and nodes searches\n\n## Common Pitfalls\n\n-  Skipping search and reinventing solutions\n-  Vague queries returning irrelevant results\n-  Not filtering by group_id (too broad)\n-  Ignoring lessons from past failures\n-  Not checking for similar errors before debugging\n-  Only using fact search (missing node relationships)\n\n## Examples\n\n### Example 1: Starting API Development\n\n```\nTask: Build REST API with authentication\n\nSearch:\nmcp__graphiti-memory__search_memory_facts(\n    query=\"REST API authentication implementation FastAPI JWT\",\n    group_ids=[\"python_development\", \"agent_executions\"],\n    max_facts=5\n)\n\nResults show:\n- Past FastAPI + JWT implementation (SUCCESS)\n- Lesson: \"Use HTTP-only cookies for tokens\"\n- Pitfall: \"Avoid storing tokens in localStorage\"\n- Time: Previous similar task took 90 minutes\n\nAction: Apply proven approach, avoid known pitfalls\n```\n\n### Example 2: Resolving Database Error\n\n```\nError: \"PostgreSQL connection pool exhausted\"\n\nSearch:\nmcp__graphiti-memory__search_memory_facts(\n    query=\"PostgreSQL connection pool exhausted timeout\",\n    group_ids=[\"error_resolutions\"],\n    max_facts=3\n)\n\nResults show:\n- Root cause: Pool size too small for async workload\n- Solution: Increase pool_size to 20, overflow to 10\n- Verification: Load test after change\n\nAction: Apply known solution immediately\n```\n\n### Example 3: Understanding Patterns\n\n```\nGoal: Optimize FastAPI performance\n\nSearch:\nmcp__graphiti-memory__search_memory_nodes(\n    query=\"FastAPI performance optimization techniques\",\n    group_ids=[\"python_development\"],\n    max_nodes=5\n)\n\nResults show relationships:\n- FastAPI connects to async patterns\n- Async patterns connect to connection pooling\n- Connection pooling connects to performance gains\n- Lessons about async context managers\n\nAction: Apply holistic optimization approach\n```\n\n## Integration with Other Skills\n\n- **graphiti-episode-storage**: Search episodes you previously stored\n- **graphiti-learning-workflows**: Use retrieval in learning workflows\n- **agent-coordination-patterns**: Search for successful coordination patterns\n\n## References\n\n- Related Skills: `graphiti-episode-storage`, `graphiti-learning-workflows`\n- MCP Server: `graphiti-memory` (configured in settings.json)\n- Replaces: `knowledge-graph-patterns` (search sections)"
              }
            ]
          },
          {
            "name": "container-plugin",
            "description": "Container development and deployment - Docker, registry, Skaffold",
            "source": "./container-plugin",
            "category": "infrastructure",
            "version": "2.0.1",
            "author": null,
            "install_commands": [
              "/plugin marketplace add laurigates/claude-plugins",
              "/plugin install container-plugin@lgates-claude-plugins"
            ],
            "signals": {
              "stars": 1,
              "forks": 0,
              "pushed_at": "2026-01-12T12:05:51Z",
              "created_at": "2025-12-16T11:24:04Z",
              "license": null
            },
            "commands": [],
            "skills": [
              {
                "name": "container-development",
                "description": "Container development with Docker, Dockerfiles, 12-factor principles, multi-stage\nbuilds, and Skaffold workflows. Enforces MANDATORY non-root users, minimal Alpine/slim\nbase images, and security hardening. Covers containerization, orchestration, and secure\nimage construction.\nUse when user mentions Docker, Dockerfile, containers, docker-compose, multi-stage\nbuilds, container images, container security, or 12-factor app principles.\n",
                "path": "container-plugin/skills/container-development/SKILL.md",
                "frontmatter": {
                  "created": "2025-12-16T00:00:00.000Z",
                  "modified": "2025-12-16T00:00:00.000Z",
                  "reviewed": "2025-12-16T00:00:00.000Z",
                  "name": "container-development",
                  "description": "Container development with Docker, Dockerfiles, 12-factor principles, multi-stage\nbuilds, and Skaffold workflows. Enforces MANDATORY non-root users, minimal Alpine/slim\nbase images, and security hardening. Covers containerization, orchestration, and secure\nimage construction.\nUse when user mentions Docker, Dockerfile, containers, docker-compose, multi-stage\nbuilds, container images, container security, or 12-factor app principles.\n",
                  "allowed-tools": "Glob, Grep, Read, Bash, Edit, Write, TodoWrite, WebSearch, WebFetch"
                },
                "content": "# Container Development\n\nExpert knowledge for containerization and orchestration with focus on **security-first**, lean container images and 12-factor app methodology.\n\n## Security Philosophy (Non-Negotiable)\n\n**Non-Root is MANDATORY**: ALL production containers MUST run as non-root users. This is not optional.\n\n**Minimal Base Images**: Use Alpine (~5MB) for Node.js/Go/Rust. Use slim (~50MB) for Python (musl compatibility issues with Alpine).\n\n**Multi-Stage Builds Required**: Separate build and runtime environments. Build tools should NOT be in production images.\n\n## Core Expertise\n\n**Container Image Construction**\n- **Dockerfile/Containerfile Authoring**: Clear, efficient, and maintainable container build instructions\n- **Multi-Stage Builds**: Creating minimal, production-ready images\n- **Image Optimization**: Reducing image size, minimizing layer count, optimizing build cache\n- **Security Hardening**: Non-root users, minimal base images, vulnerability scanning\n\n**Container Orchestration**\n- **Service Architecture**: Microservices with proper service discovery\n- **Resource Management**: CPU/memory limits, auto-scaling policies, resource quotas\n- **Health & Monitoring**: Health checks, readiness probes, observability patterns\n- **Configuration Management**: Environment variables, secrets, configuration management\n\n## Key Capabilities\n\n- **12-Factor Adherence**: Ensures containerized applications follow 12-factor principles, especially configuration and statelessness\n- **Health & Reliability**: Implements proper health checks, readiness probes, and restart policies\n- **Skaffold Workflows**: Structures containerized applications for efficient development loops\n- **Orchestration Patterns**: Designs service meshes, load balancing, and container communication\n- **Performance Tuning**: Optimizes container resource usage, startup times, and runtime performance\n\n## Image Crafting Process\n\n1. **Analyze**: Understand application dependencies and build process\n2. **Structure**: Design multi-stage Dockerfile, separating build-time from runtime needs\n3. **Ignore**: Create comprehensive `.dockerignore` file\n4. **Build & Scan**: Build image and scan for vulnerabilities\n5. **Refine**: Iterate to optimize layer caching, reduce size, address security\n6. **Validate**: Ensure image runs correctly and adheres to 12-factor principles\n\n## Best Practices\n\n## Version Checking\n\n**CRITICAL**: Before using base images, verify latest versions:\n- **Node.js Alpine**: Check [Docker Hub node](https://hub.docker.com/_/node) for latest LTS\n- **Python slim**: Check [Docker Hub python](https://hub.docker.com/_/python) for latest\n- **nginx Alpine**: Check [Docker Hub nginx](https://hub.docker.com/_/nginx)\n\nUse WebSearch or WebFetch to verify current versions.\n\n**Multi-Stage Dockerfile Pattern (Node.js - Non-Root Alpine)**\n```dockerfile\n# Build stage - use Alpine for minimal size\nFROM node:24-alpine AS build\n\nWORKDIR /app\nCOPY package*.json ./\nRUN --mount=type=cache,target=/root/.npm npm ci\nCOPY . .\nRUN npm run build\n\n# Runtime stage - minimal nginx Alpine\nFROM nginx:1.27-alpine\n\n# Create non-root user BEFORE copying files\nRUN addgroup -g 1001 -S appgroup && \\\n    adduser -u 1001 -S appuser -G appgroup\n\nCOPY --from=build /app/dist /usr/share/nginx/html\n\n# Security: Make nginx dirs writable by non-root\nRUN chown -R appuser:appgroup /var/cache/nginx /var/run /var/log/nginx\n\nUSER appuser\nEXPOSE 8080\n\nHEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \\\n  CMD wget --no-verbose --tries=1 --spider http://localhost:8080/health || exit 1\n```\n\n**Security Best Practices (Mandatory)**\n- **Non-root user**: REQUIRED - never run as root in production\n- **Minimal base images**: Alpine for Node/Go/Rust, slim for Python\n- **Multi-stage builds**: REQUIRED - keep build tools out of runtime\n- **HEALTHCHECK**: REQUIRED for Kubernetes probes\n- **Vulnerability scanning**: Use Trivy or Grype in CI\n- **Version pinning**: Always use specific tags, never `latest`\n\n**12-Factor App Principles**\n- Configuration via environment variables\n- Stateless processes\n- Explicit dependencies\n- Port binding for services\n- Graceful shutdown handling\n\n**Skaffold Preference**\n- Favor Skaffold over Docker Compose for local development\n- Continuous development loop with hot reload\n- Production-like local environment\n\nFor detailed Dockerfile optimization techniques, orchestration patterns, security hardening, and Skaffold configuration, see REFERENCE.md.\n\n## Related Commands\n\n- `/configure:container` - Comprehensive container infrastructure validation\n- `/configure:dockerfile` - Dockerfile-specific configuration\n- `/configure:workflows` - GitHub Actions including container builds\n- `/configure:skaffold` - Kubernetes development configuration"
              },
              {
                "name": "skaffold-orbstack",
                "description": "OrbStack-optimized Skaffold workflows for local Kubernetes development without port-forward.\nUse when configuring Skaffold with OrbStack, accessing services via LoadBalancer or Ingress,\nor when the user mentions OrbStack, k8s.orb.local, service access, or eliminating port-forward.\n",
                "path": "container-plugin/skills/skaffold-orbstack/SKILL.md",
                "frontmatter": {
                  "created": "2025-12-16T00:00:00.000Z",
                  "modified": "2025-12-16T00:00:00.000Z",
                  "reviewed": "2025-12-16T00:00:00.000Z",
                  "name": "skaffold-orbstack",
                  "description": "OrbStack-optimized Skaffold workflows for local Kubernetes development without port-forward.\nUse when configuring Skaffold with OrbStack, accessing services via LoadBalancer or Ingress,\nor when the user mentions OrbStack, k8s.orb.local, service access, or eliminating port-forward.\n"
                },
                "content": "# Skaffold with OrbStack - Port-Forward-Free Development\n\n## Overview\n\nOrbStack provides superior local Kubernetes networking compared to other tools (minikube, kind, Docker Desktop). Services are accessible directly from macOS without port-forward.\n\n## Key OrbStack Advantages\n\n| Feature | OrbStack | minikube/kind |\n|---------|----------|---------------|\n| LoadBalancer auto-provision |  Yes |  Needs MetalLB |\n| Wildcard DNS (`*.k8s.orb.local`) |  Yes |  No |\n| cluster.local from host |  Yes |  No |\n| Pod IP direct access |  Yes |  No |\n| Auto HTTPS certificates |  Yes |  No |\n\n## Service Access Methods\n\n### Method 1: LoadBalancer Services (Simplest)\n\nChange service type from ClusterIP to LoadBalancer:\n\n```yaml\napiVersion: v1\nkind: Service\nmetadata:\n  name: my-app\nspec:\n  type: LoadBalancer  # OrbStack auto-provisions external IP\n  ports:\n    - port: 80\n      targetPort: 8080\n  selector:\n    app: my-app\n```\n\n**Access**: `curl http://my-app.default.svc.cluster.local` from macOS\n\n### Method 2: Ingress with Wildcard DNS (Recommended)\n\n**One-time setup - Install Ingress controller:**\n\n```bash\n# Ingress-NGINX (recommended)\nkubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.8.1/deploy/static/provider/cloud/deploy.yaml\n\n# OR Traefik\nhelm repo add traefik https://traefik.github.io/charts\nhelm install traefik traefik/traefik\n```\n\n**Create Ingress for your service:**\n\n```yaml\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: my-app\nspec:\n  ingressClassName: nginx\n  rules:\n    - host: my-app.k8s.orb.local\n      http:\n        paths:\n          - path: /\n            pathType: Prefix\n            backend:\n              service:\n                name: my-app\n                port:\n                  number: 80\n```\n\n**Access**: `http://my-app.k8s.orb.local` (auto-resolves)\n\n### Method 3: Direct Service DNS (cluster.local)\n\nOrbStack exposes cluster DNS to macOS:\n\n```bash\n# Access any service directly\ncurl http://my-app.default.svc.cluster.local:8080\n\n# Full DNS pattern\ncurl http://<service>.<namespace>.svc.cluster.local:<port>\n```\n\n## Skaffold Configuration for OrbStack\n\n### Minimal skaffold.yaml (No Port-Forward Needed)\n\n```yaml\napiVersion: skaffold/v4beta11\nkind: Config\nmetadata:\n  name: my-app\n\nbuild:\n  local:\n    push: false\n    useBuildkit: true\n  artifacts:\n    - image: my-app\n      docker:\n        dockerfile: Dockerfile\n\ndeploy:\n  kubeContext: orbstack\n  kubectl:\n    manifests:\n      - k8s/*.yaml\n  statusCheck: true\n  statusCheckDeadlineSeconds: 180\n\n# Port-forward REMOVED - use LoadBalancer/Ingress instead\n```\n\n### Profile: Local with Ingress\n\n```yaml\nprofiles:\n  - name: local-ingress\n    deploy:\n      kubeContext: orbstack\n      kubectl:\n        manifests:\n          - k8s/base/*.yaml\n          - k8s/ingress/*.yaml  # Ingress resources\n```\n\n### Profile: Services-Only (Frontend Local Dev)\n\n```yaml\nprofiles:\n  - name: services-only\n    build:\n      artifacts: []  # Don't build frontend\n    deploy:\n      kubeContext: orbstack\n      kubectl:\n        manifests:\n          - k8s/namespace.yaml\n          - k8s/database/*.yaml\n          - k8s/api/*.yaml\n```\n\nAccess backend at `http://api.k8s.orb.local` while running `npm run dev` locally.\n\n## Kubernetes Manifest Templates\n\n### LoadBalancer Service Template\n\n```yaml\n# k8s/service.yaml\napiVersion: v1\nkind: Service\nmetadata:\n  name: {{ .name }}\n  labels:\n    app: {{ .name }}\nspec:\n  type: LoadBalancer\n  ports:\n    - name: http\n      port: 80\n      targetPort: {{ .containerPort | default 8080 }}\n  selector:\n    app: {{ .name }}\n```\n\n### Ingress Template\n\n```yaml\n# k8s/ingress.yaml\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: {{ .name }}\n  annotations:\n    nginx.ingress.kubernetes.io/rewrite-target: /\nspec:\n  ingressClassName: nginx\n  rules:\n    - host: {{ .name }}.k8s.orb.local\n      http:\n        paths:\n          - path: /\n            pathType: Prefix\n            backend:\n              service:\n                name: {{ .name }}\n                port:\n                  number: 80\n```\n\n## Migration: Port-Forward to LoadBalancer\n\n### Before (Traditional)\n\n```yaml\n# skaffold.yaml with port-forward\nportForward:\n  - resourceType: service\n    resourceName: api\n    port: 8080\n    localPort: 8080\n    address: 127.0.0.1\n  - resourceType: service\n    resourceName: frontend\n    port: 3000\n    localPort: 3000\n    address: 127.0.0.1\n```\n\n```bash\nskaffold dev  # Services at localhost:8080, localhost:3000\n```\n\n### After (OrbStack Native)\n\n```yaml\n# k8s/services.yaml - Change service types\napiVersion: v1\nkind: Service\nmetadata:\n  name: api\nspec:\n  type: LoadBalancer  # Changed from ClusterIP\n  ports:\n    - port: 8080\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: frontend\nspec:\n  type: LoadBalancer  # Changed from ClusterIP\n  ports:\n    - port: 3000\n```\n\n```yaml\n# skaffold.yaml - Remove portForward section entirely\ndeploy:\n  kubeContext: orbstack\n  kubectl:\n    manifests:\n      - k8s/*.yaml\n# No portForward needed!\n```\n\n```bash\nskaffold dev  # Services at api.default.svc.cluster.local:8080\n              #            frontend.default.svc.cluster.local:3000\n```\n\n## Common Patterns\n\n### Database Access\n\n```yaml\n# k8s/postgresql.yaml\napiVersion: v1\nkind: Service\nmetadata:\n  name: postgresql\nspec:\n  type: LoadBalancer  # Access from local tools (DBeaver, pgAdmin)\n  ports:\n    - port: 5432\n```\n\n**Connection string**: `postgres://user:pass@postgresql.default.svc.cluster.local:5432/db`  <!-- pragma: allowlist secret -->\n\n### Multi-Service Application\n\n```yaml\n# k8s/ingress.yaml - Single Ingress for all services\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: app-ingress\nspec:\n  ingressClassName: nginx\n  rules:\n    - host: api.k8s.orb.local\n      http:\n        paths:\n          - path: /\n            pathType: Prefix\n            backend:\n              service:\n                name: api\n                port:\n                  number: 8080\n    - host: web.k8s.orb.local\n      http:\n        paths:\n          - path: /\n            pathType: Prefix\n            backend:\n              service:\n                name: frontend\n                port:\n                  number: 3000\n    - host: admin.k8s.orb.local\n      http:\n        paths:\n          - path: /\n            pathType: Prefix\n            backend:\n              service:\n                name: admin-panel\n                port:\n                  number: 8000\n```\n\n## Security Considerations\n\n### Default: Localhost Only\n\nOrbStack restricts services to localhost by default - safe on untrusted networks.\n\n### Expose to LAN (Use with Caution)\n\nSettings  Kubernetes  \"Expose services to local network devices\"\n\nOnly enable when:\n- Testing from mobile devices on same network\n- Sharing local environment with team\n- On trusted network\n\n## Troubleshooting\n\n### Service Not Accessible\n\n1. Check service type: `kubectl get svc`\n2. Verify LoadBalancer has EXTERNAL-IP (not `<pending>`)\n3. Test DNS: `nslookup my-app.default.svc.cluster.local`\n\n### Ingress Not Working\n\n1. Verify Ingress controller is running:\n   ```bash\n   kubectl -n ingress-nginx get pods\n   ```\n2. Check Ingress controller has LoadBalancer IP:\n   ```bash\n   kubectl -n ingress-nginx get svc\n   ```\n3. Verify Ingress resource:\n   ```bash\n   kubectl describe ingress my-app\n   ```\n\n### DNS Resolution Issues\n\n```bash\n# Test cluster DNS from macOS\nnslookup my-service.default.svc.cluster.local\n\n# If short names fail, use full domain\n#  my-service.default.svc\n#  my-service.default.svc.cluster.local\n```\n\n### Pod IP Direct Access (Debugging)\n\n```bash\n# Get pod IP\nkubectl get pods -o wide\n\n# Connect directly (OrbStack routes pod network to macOS)\ncurl http://10.42.0.15:8080\n```\n\n## Quick Setup Checklist\n\n1. [ ] Install Ingress controller (one-time)\n2. [ ] Change service types to LoadBalancer\n3. [ ] Create Ingress resources for pretty URLs\n4. [ ] Remove `portForward` from skaffold.yaml\n5. [ ] Set `kubeContext: orbstack` in deploy config\n6. [ ] Update local .env/config to use `.k8s.orb.local` URLs\n\n## Commands Reference\n\n```bash\n# Start development (no --port-forward needed)\nskaffold dev --kube-context=orbstack\n\n# Run specific profile\nskaffold dev -p services-only --kube-context=orbstack\n\n# Check service accessibility\nkubectl get svc -o wide\n\n# Verify Ingress\nkubectl get ingress\n```"
              }
            ]
          },
          {
            "name": "api-plugin",
            "description": "API integration and testing - REST endpoints, client generation",
            "source": "./api-plugin",
            "category": "development",
            "version": "1.0.0",
            "author": null,
            "install_commands": [
              "/plugin marketplace add laurigates/claude-plugins",
              "/plugin install api-plugin@lgates-claude-plugins"
            ],
            "signals": {
              "stars": 1,
              "forks": 0,
              "pushed_at": "2026-01-12T12:05:51Z",
              "created_at": "2025-12-16T11:24:04Z",
              "license": null
            },
            "commands": [
              {
                "name": "/api-tests",
                "description": "Check and configure API contract testing with Pact, OpenAPI validation, and schema testing",
                "path": "api-plugin/commands/api-tests.md",
                "frontmatter": {
                  "created": "2025-12-16T00:00:00.000Z",
                  "modified": "2025-12-16T00:00:00.000Z",
                  "reviewed": "2025-12-16T00:00:00.000Z",
                  "description": "Check and configure API contract testing with Pact, OpenAPI validation, and schema testing",
                  "allowed-tools": "Glob, Grep, Read, Write, Edit, Bash, AskUserQuestion, TodoWrite",
                  "argument-hint": "[--check-only] [--fix] [--type <pact|openapi|schema>]"
                },
                "content": "# /configure:api-tests\n\nCheck and configure API contract testing infrastructure for validating API contracts, schemas, and consumer-provider agreements.\n\n## Context\n\nThis command validates API testing setup and optionally configures contract testing, OpenAPI validation, and schema testing.\n\n**API Testing Types:**\n- **Contract Testing (Pact)** - Consumer-driven contracts between services\n- **OpenAPI Validation** - Validate requests/responses against OpenAPI spec\n- **Schema Testing** - JSON Schema validation for API responses\n- **Snapshot Testing** - API response structure verification\n\n**When to Use Each:**\n| Type | Use Case |\n|------|----------|\n| Pact | Microservices, multiple consumers, breaking change detection |\n| OpenAPI | API-first development, documentation-driven testing |\n| Schema | Simple validation, GraphQL APIs, single service |\n\n## Workflow\n\n### Phase 1: Project Detection\n\nDetect existing API testing infrastructure:\n\n| Indicator | Component | Status |\n|-----------|-----------|--------|\n| `pact` in dependencies | Pact contract testing | Installed |\n| `openapi.yaml` or `swagger.json` | OpenAPI specification | Present |\n| `@apidevtools/swagger-parser` | OpenAPI validation | Configured |\n| `ajv` in dependencies | JSON Schema validation | Configured |\n| `pacts/` directory | Pact contracts | Present |\n\n### Phase 2: Current State Analysis\n\nCheck for complete API testing setup:\n\n**Contract Testing (Pact):**\n- [ ] `@pact-foundation/pact` installed (JS) or `pact-python` (Python)\n- [ ] Consumer tests defined\n- [ ] Provider verification configured\n- [ ] Pact Broker or PactFlow configured (optional)\n- [ ] CI/CD pipeline integration\n\n**OpenAPI Validation:**\n- [ ] OpenAPI specification file exists\n- [ ] Request validation middleware configured\n- [ ] Response validation in tests\n- [ ] Schema auto-generation configured\n- [ ] Breaking change detection\n\n**Schema Testing:**\n- [ ] JSON Schema definitions exist\n- [ ] `ajv` or similar validator installed\n- [ ] Response validation helpers\n- [ ] Schema versioning strategy\n\n### Phase 3: Compliance Report\n\nGenerate formatted compliance report:\n\n```\nAPI Testing Compliance Report\n==============================\nProject: [name]\nAPI Type: [REST | GraphQL | gRPC]\n\nContract Testing (Pact):\n  @pact-foundation/pact    package.json               [ INSTALLED |  MISSING]\n  Consumer tests           tests/contract/consumer/   [ FOUND |  NONE]\n  Provider tests           tests/contract/provider/   [ FOUND |  NONE]\n  Pact Broker              CI configuration           [ CONFIGURED |  OPTIONAL]\n  can-i-deploy             CI gate                    [ CONFIGURED |  OPTIONAL]\n\nOpenAPI Validation:\n  OpenAPI spec             openapi.yaml               [ EXISTS |  MISSING]\n  Spec version             OpenAPI 3.1                [ CURRENT |  OUTDATED]\n  Request validation       middleware                 [ CONFIGURED |  MISSING]\n  Response validation      test helpers               [ CONFIGURED |  MISSING]\n  Breaking change CI       oasdiff                    [ CONFIGURED |  OPTIONAL]\n\nSchema Testing:\n  JSON Schemas             schemas/                   [ EXISTS |  N/A]\n  Schema validator         ajv/zod                    [ INSTALLED |  MISSING]\n  Response validation      test helpers               [ CONFIGURED |  MISSING]\n\nOverall: [X issues found]\n\nRecommendations:\n  - Add Pact consumer tests for service dependencies\n  - Configure OpenAPI response validation in tests\n  - Add breaking change detection to CI\n```\n\n### Phase 4: Configuration (if --fix or user confirms)\n\n#### Pact Contract Testing (JavaScript/TypeScript)\n\n**Install dependencies:**\n```bash\nbun add --dev @pact-foundation/pact @pact-foundation/pact-core\n```\n\n**Create `tests/contract/consumer/userService.pact.ts`:**\n```typescript\nimport { PactV4, MatchersV3 } from '@pact-foundation/pact';\nimport { resolve } from 'path';\n\nconst { like, eachLike, regex, datetime } = MatchersV3;\n\nconst provider = new PactV4({\n  consumer: 'frontend-app',\n  provider: 'user-service',\n  dir: resolve(__dirname, '../../../pacts'),\n  logLevel: 'warn',\n});\n\ndescribe('User Service Contract', () => {\n  describe('GET /api/users/:id', () => {\n    it('returns a user when user exists', async () => {\n      await provider\n        .addInteraction()\n        .given('a user with ID 1 exists')\n        .uponReceiving('a request to get user 1')\n        .withRequest({\n          method: 'GET',\n          path: '/api/users/1',\n          headers: {\n            Accept: 'application/json',\n          },\n        })\n        .willRespondWith({\n          status: 200,\n          headers: {\n            'Content-Type': 'application/json',\n          },\n          body: {\n            id: like(1),\n            name: like('John Doe'),\n            email: regex(/^[\\w.-]+@[\\w.-]+\\.\\w+$/, 'john@example.com'),\n            createdAt: datetime(\"yyyy-MM-dd'T'HH:mm:ss.SSSXXX\"),\n          },\n        })\n        .executeTest(async (mockServer) => {\n          const response = await fetch(`${mockServer.url}/api/users/1`, {\n            headers: { Accept: 'application/json' },\n          });\n\n          expect(response.status).toBe(200);\n\n          const user = await response.json();\n          expect(user).toHaveProperty('id');\n          expect(user).toHaveProperty('name');\n          expect(user).toHaveProperty('email');\n        });\n    });\n\n    it('returns 404 when user does not exist', async () => {\n      await provider\n        .addInteraction()\n        .given('no user with ID 999 exists')\n        .uponReceiving('a request to get non-existent user')\n        .withRequest({\n          method: 'GET',\n          path: '/api/users/999',\n          headers: {\n            Accept: 'application/json',\n          },\n        })\n        .willRespondWith({\n          status: 404,\n          headers: {\n            'Content-Type': 'application/json',\n          },\n          body: {\n            error: like('User not found'),\n            code: like('USER_NOT_FOUND'),\n          },\n        })\n        .executeTest(async (mockServer) => {\n          const response = await fetch(`${mockServer.url}/api/users/999`, {\n            headers: { Accept: 'application/json' },\n          });\n\n          expect(response.status).toBe(404);\n        });\n    });\n  });\n\n  describe('POST /api/users', () => {\n    it('creates a new user', async () => {\n      await provider\n        .addInteraction()\n        .uponReceiving('a request to create a user')\n        .withRequest({\n          method: 'POST',\n          path: '/api/users',\n          headers: {\n            'Content-Type': 'application/json',\n            Accept: 'application/json',\n          },\n          body: {\n            name: like('Jane Doe'),\n            email: like('jane@example.com'),\n          },\n        })\n        .willRespondWith({\n          status: 201,\n          headers: {\n            'Content-Type': 'application/json',\n          },\n          body: {\n            id: like(1),\n            name: like('Jane Doe'),\n            email: like('jane@example.com'),\n            createdAt: datetime(\"yyyy-MM-dd'T'HH:mm:ss.SSSXXX\"),\n          },\n        })\n        .executeTest(async (mockServer) => {\n          const response = await fetch(`${mockServer.url}/api/users`, {\n            method: 'POST',\n            headers: {\n              'Content-Type': 'application/json',\n              Accept: 'application/json',\n            },\n            body: JSON.stringify({\n              name: 'Jane Doe',\n              email: 'jane@example.com',\n            }),\n          });\n\n          expect(response.status).toBe(201);\n        });\n    });\n  });\n});\n```\n\n**Create `tests/contract/provider/userService.provider.ts`:**\n```typescript\nimport { Verifier } from '@pact-foundation/pact';\nimport { resolve } from 'path';\nimport { app } from '../../../src/app'; // Your Express/Fastify app\nimport { setupTestDatabase, seedProviderStates } from '../helpers/database';\n\ndescribe('User Service Provider Verification', () => {\n  let server: any;\n\n  beforeAll(async () => {\n    await setupTestDatabase();\n    server = app.listen(3001);\n  });\n\n  afterAll(async () => {\n    server.close();\n  });\n\n  it('validates the expectations of the consumer', async () => {\n    const verifier = new Verifier({\n      providerBaseUrl: 'http://localhost:3001',\n      pactUrls: [resolve(__dirname, '../../../pacts/frontend-app-user-service.json')],\n      // Or use Pact Broker:\n      // pactBrokerUrl: process.env.PACT_BROKER_URL,\n      // providerVersion: process.env.GIT_SHA,\n      // publishVerificationResult: process.env.CI === 'true',\n\n      stateHandlers: {\n        'a user with ID 1 exists': async () => {\n          await seedProviderStates({\n            users: [{ id: 1, name: 'John Doe', email: 'john@example.com' }],\n          });\n        },\n        'no user with ID 999 exists': async () => {\n          // Ensure user 999 doesn't exist (default state after cleanup)\n        },\n      },\n    });\n\n    await verifier.verifyProvider();\n  });\n});\n```\n\n#### Pact Contract Testing (Python)\n\n**Install dependencies:**\n```bash\nuv add --group dev pact-python\n```\n\n**Create `tests/contract/consumer/test_user_service.py`:**\n```python\nimport pytest\nfrom pact import Consumer, Provider, Like, EachLike, Term\nimport requests\n\npact = Consumer('frontend-app').has_pact_with(\n    Provider('user-service'),\n    pact_dir='./pacts',\n    log_dir='./logs',\n)\n\n@pytest.fixture(scope='module')\ndef pact_setup():\n    pact.start_service()\n    yield pact\n    pact.stop_service()\n\ndef test_get_user(pact_setup):\n    \"\"\"Test getting a user by ID.\"\"\"\n    expected = {\n        'id': Like(1),\n        'name': Like('John Doe'),\n        'email': Term(r'^[\\w.-]+@[\\w.-]+\\.\\w+$', 'john@example.com'),\n    }\n\n    (pact_setup\n        .given('a user with ID 1 exists')\n        .upon_receiving('a request to get user 1')\n        .with_request('GET', '/api/users/1')\n        .will_respond_with(200, body=expected))\n\n    with pact_setup:\n        result = requests.get(f'{pact_setup.uri}/api/users/1')\n\n    assert result.status_code == 200\n    assert 'id' in result.json()\n    assert 'name' in result.json()\n\ndef test_get_nonexistent_user(pact_setup):\n    \"\"\"Test 404 response for non-existent user.\"\"\"\n    (pact_setup\n        .given('no user with ID 999 exists')\n        .upon_receiving('a request to get non-existent user')\n        .with_request('GET', '/api/users/999')\n        .will_respond_with(404, body={\n            'error': Like('User not found'),\n            'code': Like('USER_NOT_FOUND'),\n        }))\n\n    with pact_setup:\n        result = requests.get(f'{pact_setup.uri}/api/users/999')\n\n    assert result.status_code == 404\n```\n\n#### OpenAPI Validation (JavaScript/TypeScript)\n\n**Install dependencies:**\n```bash\nbun add --dev @apidevtools/swagger-parser ajv ajv-formats\nbun add --dev openapi-typescript  # For TypeScript types from OpenAPI\n```\n\n**Create `tests/api/openapi-validator.ts`:**\n```typescript\nimport Ajv from 'ajv';\nimport addFormats from 'ajv-formats';\nimport SwaggerParser from '@apidevtools/swagger-parser';\nimport { OpenAPIV3 } from 'openapi-types';\n\nexport class OpenAPIValidator {\n  private ajv: Ajv;\n  private spec: OpenAPIV3.Document | null = null;\n  private schemas: Map<string, object> = new Map();\n\n  constructor() {\n    this.ajv = new Ajv({ allErrors: true, strict: false });\n    addFormats(this.ajv);\n  }\n\n  async loadSpec(specPath: string): Promise<void> {\n    this.spec = await SwaggerParser.validate(specPath) as OpenAPIV3.Document;\n\n    // Register all schemas from components\n    if (this.spec.components?.schemas) {\n      for (const [name, schema] of Object.entries(this.spec.components.schemas)) {\n        this.schemas.set(name, schema);\n        this.ajv.addSchema(schema, `#/components/schemas/${name}`);\n      }\n    }\n  }\n\n  validateResponse(\n    path: string,\n    method: string,\n    statusCode: number,\n    body: unknown\n  ): { valid: boolean; errors: string[] } {\n    if (!this.spec) {\n      throw new Error('OpenAPI spec not loaded. Call loadSpec() first.');\n    }\n\n    const pathItem = this.spec.paths?.[path];\n    if (!pathItem) {\n      return { valid: false, errors: [`Path ${path} not found in spec`] };\n    }\n\n    const operation = pathItem[method.toLowerCase() as keyof OpenAPIV3.PathItemObject] as OpenAPIV3.OperationObject;\n    if (!operation) {\n      return { valid: false, errors: [`Method ${method} not found for path ${path}`] };\n    }\n\n    const response = operation.responses?.[statusCode] || operation.responses?.['default'];\n    if (!response) {\n      return { valid: false, errors: [`Status ${statusCode} not defined for ${method} ${path}`] };\n    }\n\n    const responseObj = response as OpenAPIV3.ResponseObject;\n    const content = responseObj.content?.['application/json'];\n    if (!content?.schema) {\n      // No schema defined, consider valid\n      return { valid: true, errors: [] };\n    }\n\n    const validate = this.ajv.compile(content.schema);\n    const valid = validate(body);\n\n    return {\n      valid: !!valid,\n      errors: validate.errors?.map(e => `${e.instancePath} ${e.message}`) || [],\n    };\n  }\n\n  validateRequest(\n    path: string,\n    method: string,\n    body: unknown\n  ): { valid: boolean; errors: string[] } {\n    if (!this.spec) {\n      throw new Error('OpenAPI spec not loaded. Call loadSpec() first.');\n    }\n\n    const pathItem = this.spec.paths?.[path];\n    if (!pathItem) {\n      return { valid: false, errors: [`Path ${path} not found in spec`] };\n    }\n\n    const operation = pathItem[method.toLowerCase() as keyof OpenAPIV3.PathItemObject] as OpenAPIV3.OperationObject;\n    if (!operation?.requestBody) {\n      return { valid: true, errors: [] };\n    }\n\n    const requestBody = operation.requestBody as OpenAPIV3.RequestBodyObject;\n    const content = requestBody.content?.['application/json'];\n    if (!content?.schema) {\n      return { valid: true, errors: [] };\n    }\n\n    const validate = this.ajv.compile(content.schema);\n    const valid = validate(body);\n\n    return {\n      valid: !!valid,\n      errors: validate.errors?.map(e => `${e.instancePath} ${e.message}`) || [],\n    };\n  }\n}\n\n// Helper for tests\nexport async function createValidator(specPath: string = './openapi.yaml'): Promise<OpenAPIValidator> {\n  const validator = new OpenAPIValidator();\n  await validator.loadSpec(specPath);\n  return validator;\n}\n```\n\n**Create `tests/api/users.openapi.test.ts`:**\n```typescript\nimport { describe, it, expect, beforeAll } from 'vitest';\nimport request from 'supertest';\nimport { app } from '../../src/app';\nimport { createValidator, OpenAPIValidator } from './openapi-validator';\n\ndescribe('Users API - OpenAPI Compliance', () => {\n  let validator: OpenAPIValidator;\n\n  beforeAll(async () => {\n    validator = await createValidator('./openapi.yaml');\n  });\n\n  describe('GET /api/users', () => {\n    it('response matches OpenAPI schema', async () => {\n      const response = await request(app)\n        .get('/api/users')\n        .expect(200);\n\n      const result = validator.validateResponse('/api/users', 'GET', 200, response.body);\n\n      expect(result.valid).toBe(true);\n      if (!result.valid) {\n        console.error('Validation errors:', result.errors);\n      }\n    });\n  });\n\n  describe('POST /api/users', () => {\n    it('request matches OpenAPI schema', async () => {\n      const requestBody = {\n        name: 'Test User',\n        email: 'test@example.com',\n      };\n\n      const requestValidation = validator.validateRequest('/api/users', 'POST', requestBody);\n      expect(requestValidation.valid).toBe(true);\n\n      const response = await request(app)\n        .post('/api/users')\n        .send(requestBody)\n        .expect(201);\n\n      const responseValidation = validator.validateResponse('/api/users', 'POST', 201, response.body);\n      expect(responseValidation.valid).toBe(true);\n    });\n\n    it('rejects invalid request body', async () => {\n      const invalidBody = {\n        name: 123, // Should be string\n        // Missing required email\n      };\n\n      const validation = validator.validateRequest('/api/users', 'POST', invalidBody);\n      expect(validation.valid).toBe(false);\n      expect(validation.errors.length).toBeGreaterThan(0);\n    });\n  });\n\n  describe('GET /api/users/:id', () => {\n    it('404 response matches OpenAPI schema', async () => {\n      const response = await request(app)\n        .get('/api/users/99999')\n        .expect(404);\n\n      const result = validator.validateResponse('/api/users/{id}', 'GET', 404, response.body);\n      expect(result.valid).toBe(true);\n    });\n  });\n});\n```\n\n#### OpenAPI Breaking Change Detection\n\n**Install oasdiff:**\n```bash\n# Via npm/bun\nbun add --dev @oasdiff/oasdiff\n\n# Or via homebrew\nbrew install oasdiff\n```\n\n**Add to CI workflow:**\n```yaml\n- name: Check for breaking API changes\n  run: |\n    # Fetch main branch spec\n    git fetch origin main\n    git show origin/main:openapi.yaml > openapi-main.yaml\n\n    # Check for breaking changes\n    oasdiff breaking openapi-main.yaml openapi.yaml --fail-on ERR\n\n    # Generate changelog\n    oasdiff changelog openapi-main.yaml openapi.yaml\n```\n\n#### Schema Testing with Zod\n\n**Install dependencies:**\n```bash\nbun add zod\nbun add --dev @anatine/zod-openapi  # Optional: generate OpenAPI from Zod\n```\n\n**Create `src/schemas/user.ts`:**\n```typescript\nimport { z } from 'zod';\n\nexport const UserSchema = z.object({\n  id: z.number().int().positive(),\n  name: z.string().min(1).max(100),\n  email: z.string().email(),\n  createdAt: z.string().datetime(),\n  updatedAt: z.string().datetime().optional(),\n});\n\nexport const CreateUserSchema = UserSchema.omit({\n  id: true,\n  createdAt: true,\n  updatedAt: true,\n});\n\nexport const UpdateUserSchema = CreateUserSchema.partial();\n\nexport const UserListSchema = z.array(UserSchema);\n\nexport type User = z.infer<typeof UserSchema>;\nexport type CreateUser = z.infer<typeof CreateUserSchema>;\nexport type UpdateUser = z.infer<typeof UpdateUserSchema>;\n```\n\n**Create `tests/api/schema.test.ts`:**\n```typescript\nimport { describe, it, expect } from 'vitest';\nimport request from 'supertest';\nimport { app } from '../../src/app';\nimport { UserSchema, UserListSchema } from '../../src/schemas/user';\n\ndescribe('API Schema Validation', () => {\n  describe('GET /api/users', () => {\n    it('response matches User list schema', async () => {\n      const response = await request(app)\n        .get('/api/users')\n        .expect(200);\n\n      const result = UserListSchema.safeParse(response.body);\n\n      expect(result.success).toBe(true);\n      if (!result.success) {\n        console.error('Schema errors:', result.error.format());\n      }\n    });\n  });\n\n  describe('GET /api/users/:id', () => {\n    it('response matches User schema', async () => {\n      // Assuming user 1 exists\n      const response = await request(app)\n        .get('/api/users/1')\n        .expect(200);\n\n      const result = UserSchema.safeParse(response.body);\n\n      expect(result.success).toBe(true);\n    });\n  });\n});\n```\n\n### Phase 5: CI/CD Integration\n\n**Create `.github/workflows/api-tests.yml`:**\n\n```yaml\nname: API Contract Tests\n\non:\n  push:\n    branches: [main]\n  pull_request:\n    paths:\n      - 'openapi.yaml'\n      - 'src/api/**'\n      - 'tests/contract/**'\n\njobs:\n  consumer-tests:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n\n      - uses: oven-sh/setup-bun@v2\n\n      - name: Install dependencies\n        run: bun install --frozen-lockfile\n\n      - name: Run consumer contract tests\n        run: bun run test:contract:consumer\n\n      - name: Upload pacts\n        uses: actions/upload-artifact@v4\n        with:\n          name: pacts\n          path: pacts/\n\n  provider-tests:\n    runs-on: ubuntu-latest\n    needs: consumer-tests\n    services:\n      postgres:\n        image: postgres:16-alpine\n        env:\n          POSTGRES_USER: test\n          POSTGRES_PASSWORD: test\n          POSTGRES_DB: test_db\n        ports:\n          - 5432:5432\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - uses: oven-sh/setup-bun@v2\n\n      - name: Install dependencies\n        run: bun install --frozen-lockfile\n\n      - name: Download pacts\n        uses: actions/download-artifact@v4\n        with:\n          name: pacts\n          path: pacts/\n\n      - name: Run provider verification\n        run: bun run test:contract:provider\n        env:\n          DATABASE_URL: postgresql://test:test@localhost:5432/test_db\n\n  openapi-validation:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n        with:\n          fetch-depth: 0\n\n      - name: Validate OpenAPI spec\n        run: |\n          bunx @apidevtools/swagger-cli validate openapi.yaml\n\n      - name: Check for breaking changes\n        if: github.event_name == 'pull_request'\n        run: |\n          git fetch origin main\n          git show origin/main:openapi.yaml > openapi-main.yaml || echo \"No existing spec\"\n\n          if [ -f openapi-main.yaml ]; then\n            bunx oasdiff breaking openapi-main.yaml openapi.yaml --fail-on ERR\n          fi\n\n  # Optional: Publish to Pact Broker\n  publish-pacts:\n    runs-on: ubuntu-latest\n    needs: [consumer-tests, provider-tests]\n    if: github.ref == 'refs/heads/main'\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Download pacts\n        uses: actions/download-artifact@v4\n        with:\n          name: pacts\n          path: pacts/\n\n      - name: Publish to Pact Broker\n        run: |\n          curl -X PUT \\\n            -H \"Content-Type: application/json\" \\\n            -d @pacts/frontend-app-user-service.json \\\n            \"${{ secrets.PACT_BROKER_URL }}/pacts/provider/user-service/consumer/frontend-app/version/${{ github.sha }}\"\n        env:\n          PACT_BROKER_TOKEN: ${{ secrets.PACT_BROKER_TOKEN }}\n```\n\n**Add npm scripts to `package.json`:**\n```json\n{\n  \"scripts\": {\n    \"test:contract\": \"bun run test:contract:consumer && bun run test:contract:provider\",\n    \"test:contract:consumer\": \"vitest run tests/contract/consumer/\",\n    \"test:contract:provider\": \"vitest run tests/contract/provider/\",\n    \"test:openapi\": \"vitest run tests/api/*.openapi.test.ts\",\n    \"test:schema\": \"vitest run tests/api/schema.test.ts\",\n    \"openapi:validate\": \"bunx @apidevtools/swagger-cli validate openapi.yaml\",\n    \"openapi:bundle\": \"bunx @apidevtools/swagger-cli bundle openapi.yaml -o dist/openapi.json\",\n    \"openapi:types\": \"bunx openapi-typescript openapi.yaml -o src/types/api.d.ts\"\n  }\n}\n```\n\n### Phase 6: Standards Tracking\n\nUpdate `.fvh-standards.yaml`:\n\n```yaml\nstandards_version: \"2025.1\"\nlast_configured: \"[timestamp]\"\ncomponents:\n  api_tests: \"2025.1\"\n  api_tests_contract: \"[pact|none]\"\n  api_tests_openapi: true\n  api_tests_schema: \"[zod|ajv|none]\"\n  api_tests_breaking_change_ci: true\n```\n\n### Phase 7: Updated Compliance Report\n\n```\nAPI Testing Configuration Complete\n===================================\n\nContract Testing: Pact\nSchema Validation: Zod\nOpenAPI: 3.1\n\nConfiguration Applied:\n   @pact-foundation/pact installed\n   Consumer contract tests created\n   Provider verification configured\n   OpenAPI validator created\n   Zod schemas configured\n\nTest Structure:\n   tests/contract/consumer/ - Consumer tests\n   tests/contract/provider/ - Provider verification\n   tests/api/*.openapi.test.ts - OpenAPI validation\n   pacts/ - Generated contracts\n\nScripts Added:\n   bun run test:contract (all contract tests)\n   bun run test:contract:consumer (consumer only)\n   bun run test:contract:provider (provider only)\n   bun run test:openapi (OpenAPI validation)\n   bun run openapi:validate (spec validation)\n\nCI/CD:\n   Consumer tests job\n   Provider verification job\n   OpenAPI breaking change detection\n   Pact artifact upload\n\nNext Steps:\n  1. Run consumer tests:\n     bun run test:contract:consumer\n\n  2. Verify provider:\n     bun run test:contract:provider\n\n  3. Validate OpenAPI spec:\n     bun run openapi:validate\n\n  4. Check API compliance:\n     bun run test:openapi\n\nDocumentation:\n  - Pact: https://docs.pact.io\n  - OpenAPI: https://swagger.io/specification\n  - Zod: https://zod.dev\n```\n\n## Flags\n\n| Flag | Description |\n|------|-------------|\n| `--check-only` | Report status without offering fixes |\n| `--fix` | Apply all fixes automatically without prompting |\n| `--type <type>` | Focus on specific type (pact, openapi, schema) |\n\n## Examples\n\n```bash\n# Check compliance and offer fixes\n/configure:api-tests\n\n# Check only, no modifications\n/configure:api-tests --check-only\n\n# Auto-fix all issues\n/configure:api-tests --fix\n\n# Configure Pact only\n/configure:api-tests --fix --type pact\n\n# Configure OpenAPI validation only\n/configure:api-tests --fix --type openapi\n```\n\n## Error Handling\n\n- **No OpenAPI spec found**: Offer to create template\n- **Pact version mismatch**: Suggest upgrade path\n- **Schema validation fails**: Report specific errors\n- **Pact Broker not configured**: Provide setup instructions\n\n## See Also\n\n- `/configure:tests` - Unit testing configuration\n- `/configure:integration-tests` - Integration testing\n- `/configure:all` - Run all FVH compliance checks\n- **Pact documentation**: https://docs.pact.io\n- **OpenAPI specification**: https://swagger.io/specification\n- **Zod documentation**: https://zod.dev"
              }
            ],
            "skills": [
              {
                "name": "api-testing",
                "description": "HTTP API testing for TypeScript (Supertest) and Python (httpx, pytest). Covers\nREST APIs, GraphQL, request/response validation, authentication, and error handling.\nUse when user mentions API testing, Supertest, httpx, REST testing, endpoint testing,\nHTTP response validation, or testing API routes.\n",
                "path": "api-plugin/skills/api-testing/SKILL.md",
                "frontmatter": {
                  "created": "2025-12-16T00:00:00.000Z",
                  "modified": "2025-12-16T00:00:00.000Z",
                  "reviewed": "2025-12-16T00:00:00.000Z",
                  "name": "api-testing",
                  "description": "HTTP API testing for TypeScript (Supertest) and Python (httpx, pytest). Covers\nREST APIs, GraphQL, request/response validation, authentication, and error handling.\nUse when user mentions API testing, Supertest, httpx, REST testing, endpoint testing,\nHTTP response validation, or testing API routes.\n",
                  "allowed-tools": "Bash, Read, Edit, Write, Grep, Glob, TodoWrite"
                },
                "content": "# API Testing\n\nExpert knowledge for testing HTTP APIs with Supertest (TypeScript/JavaScript) and httpx/pytest (Python).\n\n## Core Expertise\n\n**API Testing Capabilities**\n- **Request testing**: Headers, query params, request bodies\n- **Response validation**: Status codes, headers, JSON schemas\n- **Authentication**: Bearer tokens, cookies, OAuth flows\n- **Error handling**: 4xx/5xx responses, validation errors\n- **Integration**: Database state, external services\n- **Performance**: Response times, load testing basics\n\n## TypeScript/JavaScript (Supertest)\n\n### Installation\n\n```bash\n# Using Bun\nbun add -d supertest @types/supertest\n\n# Using npm\nnpm install -D supertest @types/supertest\n```\n\n### Basic Setup with Express\n\n```typescript\n// app.ts\nimport express from 'express'\n\nexport const app = express()\napp.use(express.json())\n\napp.get('/api/health', (req, res) => {\n  res.json({ status: 'ok' })\n})\n\napp.post('/api/users', (req, res) => {\n  const { name, email } = req.body\n  if (!name || !email) {\n    return res.status(400).json({ error: 'Missing required fields' })\n  }\n  res.status(201).json({ id: 1, name, email })\n})\n```\n\n```typescript\n// app.test.ts\nimport { describe, it, expect } from 'vitest'\nimport request from 'supertest'\nimport { app } from './app'\n\ndescribe('API Tests', () => {\n  it('returns health status', async () => {\n    const response = await request(app)\n      .get('/api/health')\n      .expect(200)\n\n    expect(response.body).toEqual({ status: 'ok' })\n  })\n\n  it('creates a user', async () => {\n    const response = await request(app)\n      .post('/api/users')\n      .send({ name: 'John Doe', email: 'john@example.com' })\n      .expect(201)\n\n    expect(response.body).toMatchObject({\n      id: expect.any(Number),\n      name: 'John Doe',\n      email: 'john@example.com',\n    })\n  })\n\n  it('validates required fields', async () => {\n    const response = await request(app)\n      .post('/api/users')\n      .send({ name: 'John Doe' })\n      .expect(400)\n\n    expect(response.body.error).toBeDefined()\n  })\n})\n```\n\n### Request Methods\n\n```typescript\nimport request from 'supertest'\nimport { app } from './app'\n\n// GET request\nawait request(app)\n  .get('/api/users')\n  .expect(200)\n\n// POST request with body\nawait request(app)\n  .post('/api/users')\n  .send({ name: 'John', email: 'john@example.com' })\n  .expect(201)\n\n// PUT request\nawait request(app)\n  .put('/api/users/1')\n  .send({ name: 'Jane' })\n  .expect(200)\n\n// PATCH request\nawait request(app)\n  .patch('/api/users/1')\n  .send({ email: 'jane@example.com' })\n  .expect(200)\n\n// DELETE request\nawait request(app)\n  .delete('/api/users/1')\n  .expect(204)\n```\n\n### Headers and Query Parameters\n\n```typescript\n// Set headers\nawait request(app)\n  .get('/api/protected')\n  .set('Authorization', 'Bearer token123')\n  .set('Content-Type', 'application/json')\n  .expect(200)\n\n// Query parameters\nawait request(app)\n  .get('/api/users')\n  .query({ page: 1, limit: 10 })\n  .expect(200)\n\n// Multiple query parameters\nawait request(app)\n  .get('/api/search')\n  .query({ q: 'john', sort: 'name', order: 'asc' })\n  .expect(200)\n```\n\n### Response Assertions\n\n```typescript\ndescribe('Response validation', () => {\n  it('validates status code', async () => {\n    await request(app)\n      .get('/api/users')\n      .expect(200)\n  })\n\n  it('validates headers', async () => {\n    await request(app)\n      .get('/api/users')\n      .expect('Content-Type', /json/)\n      .expect(200)\n  })\n\n  it('validates response body', async () => {\n    const response = await request(app)\n      .get('/api/users/1')\n      .expect(200)\n\n    expect(response.body).toEqual({\n      id: 1,\n      name: 'John Doe',\n      email: 'john@example.com',\n      createdAt: expect.any(String),\n    })\n  })\n\n  it('validates array responses', async () => {\n    const response = await request(app)\n      .get('/api/users')\n      .expect(200)\n\n    expect(response.body).toBeInstanceOf(Array)\n    expect(response.body).toHaveLength(5)\n    expect(response.body[0]).toHaveProperty('id')\n  })\n})\n```\n\n### Authentication Testing\n\n```typescript\ndescribe('Authentication', () => {\n  let authToken: string\n\n  beforeAll(async () => {\n    // Login to get token\n    const response = await request(app)\n      .post('/api/auth/login')\n      .send({ email: 'user@example.com', password: 'password123' })  // pragma: allowlist secret\n      .expect(200)\n\n    authToken = response.body.token\n  })\n\n  it('accesses protected endpoint with token', async () => {\n    await request(app)\n      .get('/api/protected')\n      .set('Authorization', `Bearer ${authToken}`)\n      .expect(200)\n  })\n\n  it('rejects requests without token', async () => {\n    await request(app)\n      .get('/api/protected')\n      .expect(401)\n  })\n\n  it('rejects requests with invalid token', async () => {\n    await request(app)\n      .get('/api/protected')\n      .set('Authorization', 'Bearer invalid-token')\n      .expect(401)\n  })\n})\n```\n\n### File Upload Testing\n\n```typescript\nimport fs from 'fs'\nimport path from 'path'\n\nit('uploads a file', async () => {\n  const response = await request(app)\n    .post('/api/upload')\n    .attach('file', path.resolve(__dirname, 'test-file.pdf'))\n    .field('description', 'Test document')\n    .expect(200)\n\n  expect(response.body).toMatchObject({\n    filename: expect.any(String),\n    size: expect.any(Number),\n  })\n})\n```\n\n### Cookie Testing\n\n```typescript\ndescribe('Cookie handling', () => {\n  it('sets and reads cookies', async () => {\n    // Login sets cookie\n    const loginResponse = await request(app)\n      .post('/api/auth/login')\n      .send({ email: 'user@example.com', password: 'password' })  // pragma: allowlist secret\n      .expect(200)\n\n    const cookies = loginResponse.headers['set-cookie']\n\n    // Use cookie in subsequent request\n    await request(app)\n      .get('/api/profile')\n      .set('Cookie', cookies)\n      .expect(200)\n  })\n})\n```\n\n### Error Handling\n\n```typescript\ndescribe('Error handling', () => {\n  it('handles validation errors', async () => {\n    const response = await request(app)\n      .post('/api/users')\n      .send({ email: 'invalid-email' })\n      .expect(400)\n\n    expect(response.body).toMatchObject({\n      error: 'Validation failed',\n      details: expect.arrayContaining([\n        expect.objectContaining({\n          field: 'email',\n          message: expect.any(String),\n        }),\n      ]),\n    })\n  })\n\n  it('handles not found errors', async () => {\n    await request(app)\n      .get('/api/users/999999')\n      .expect(404)\n  })\n\n  it('handles server errors gracefully', async () => {\n    const response = await request(app)\n      .post('/api/error-prone-endpoint')\n      .expect(500)\n\n    expect(response.body).toHaveProperty('error')\n  })\n})\n```\n\n## Python (httpx + pytest)\n\n### Installation\n\n```bash\n# Using uv\nuv add --dev httpx pytest-asyncio\n\n# Using pip\npip install httpx pytest-asyncio\n```\n\n### Basic Setup with FastAPI\n\n```python\n# main.py\nfrom fastapi import FastAPI, HTTPException\nfrom pydantic import BaseModel\n\napp = FastAPI()\n\nclass User(BaseModel):\n    name: str\n    email: str\n\n@app.get(\"/api/health\")\ndef health_check():\n    return {\"status\": \"ok\"}\n\n@app.post(\"/api/users\", status_code=201)\ndef create_user(user: User):\n    return {\"id\": 1, \"name\": user.name, \"email\": user.email}\n\n@app.get(\"/api/users/{user_id}\")\ndef get_user(user_id: int):\n    if user_id == 999:\n        raise HTTPException(status_code=404, detail=\"User not found\")\n    return {\"id\": user_id, \"name\": \"John Doe\", \"email\": \"john@example.com\"}\n```\n\n```python\n# test_main.py\nimport pytest\nfrom httpx import AsyncClient\nfrom fastapi.testclient import TestClient\nfrom main import app\n\n# Synchronous testing\nclient = TestClient(app)\n\ndef test_health_check():\n    response = client.get(\"/api/health\")\n    assert response.status_code == 200\n    assert response.json() == {\"status\": \"ok\"}\n\ndef test_create_user():\n    response = client.post(\n        \"/api/users\",\n        json={\"name\": \"John Doe\", \"email\": \"john@example.com\"}\n    )\n    assert response.status_code == 201\n    data = response.json()\n    assert data[\"name\"] == \"John Doe\"\n    assert data[\"email\"] == \"john@example.com\"\n    assert \"id\" in data\n\ndef test_validation_error():\n    response = client.post(\"/api/users\", json={\"name\": \"John\"})\n    assert response.status_code == 422  # FastAPI validation error\n\ndef test_not_found():\n    response = client.get(\"/api/users/999\")\n    assert response.status_code == 404\n```\n\n### Async Testing with httpx\n\n```python\nimport pytest\nfrom httpx import AsyncClient\nfrom main import app\n\n@pytest.mark.asyncio\nasync def test_async_health_check():\n    async with AsyncClient(app=app, base_url=\"http://test\") as client:\n        response = await client.get(\"/api/health\")\n        assert response.status_code == 200\n        assert response.json() == {\"status\": \"ok\"}\n\n@pytest.mark.asyncio\nasync def test_async_create_user():\n    async with AsyncClient(app=app, base_url=\"http://test\") as client:\n        response = await client.post(\n            \"/api/users\",\n            json={\"name\": \"Jane Doe\", \"email\": \"jane@example.com\"}\n        )\n        assert response.status_code == 201\n        data = response.json()\n        assert data[\"name\"] == \"Jane Doe\"\n```\n\n### Fixtures for Common Setup\n\n```python\nimport pytest\nfrom httpx import AsyncClient\nfrom fastapi.testclient import TestClient\nfrom main import app\n\n@pytest.fixture\ndef client():\n    \"\"\"Synchronous test client\"\"\"\n    return TestClient(app)\n\n@pytest.fixture\nasync def async_client():\n    \"\"\"Async test client\"\"\"\n    async with AsyncClient(app=app, base_url=\"http://test\") as client:\n        yield client\n\n@pytest.fixture\ndef auth_token(client):\n    \"\"\"Get authentication token\"\"\"\n    response = client.post(\n        \"/api/auth/login\",\n        json={\"email\": \"user@example.com\", \"password\": \"password123\"}  # pragma: allowlist secret\n    )\n    return response.json()[\"token\"]\n\n# Usage\ndef test_protected_endpoint(client, auth_token):\n    response = client.get(\n        \"/api/protected\",\n        headers={\"Authorization\": f\"Bearer {auth_token}\"}\n    )\n    assert response.status_code == 200\n```\n\n### Headers and Query Parameters\n\n```python\ndef test_with_headers(client):\n    response = client.get(\n        \"/api/protected\",\n        headers={\n            \"Authorization\": \"Bearer token123\",\n            \"Content-Type\": \"application/json\"\n        }\n    )\n    assert response.status_code == 200\n\ndef test_with_query_params(client):\n    response = client.get(\n        \"/api/users\",\n        params={\"page\": 1, \"limit\": 10, \"sort\": \"name\"}\n    )\n    assert response.status_code == 200\n    assert len(response.json()) <= 10\n```\n\n### Authentication Testing\n\n```python\nimport pytest\nfrom fastapi.testclient import TestClient\nfrom main import app\n\n@pytest.fixture\ndef authenticated_client():\n    client = TestClient(app)\n    # Login\n    response = client.post(\n        \"/api/auth/login\",\n        json={\"email\": \"user@example.com\", \"password\": \"password123\"}  # pragma: allowlist secret\n    )\n    token = response.json()[\"token\"]\n\n    # Add token to client headers\n    client.headers[\"Authorization\"] = f\"Bearer {token}\"\n    return client\n\ndef test_access_protected_resource(authenticated_client):\n    response = authenticated_client.get(\"/api/protected\")\n    assert response.status_code == 200\n\ndef test_reject_unauthenticated(client):\n    response = client.get(\"/api/protected\")\n    assert response.status_code == 401\n```\n\n### File Upload Testing\n\n```python\ndef test_file_upload(client, tmp_path):\n    # Create temporary test file\n    test_file = tmp_path / \"test.txt\"\n    test_file.write_text(\"test content\")\n\n    with open(test_file, \"rb\") as f:\n        response = client.post(\n            \"/api/upload\",\n            files={\"file\": (\"test.txt\", f, \"text/plain\")},\n            data={\"description\": \"Test file\"}\n        )\n\n    assert response.status_code == 200\n    assert response.json()[\"filename\"] == \"test.txt\"\n```\n\n### Cookie Testing\n\n```python\ndef test_cookie_handling(client):\n    # Login sets cookie\n    response = client.post(\n        \"/api/auth/login\",\n        json={\"email\": \"user@example.com\", \"password\": \"password\"}  # pragma: allowlist secret\n    )\n    assert \"session\" in response.cookies\n\n    # Cookie automatically included in subsequent requests\n    response = client.get(\"/api/profile\")\n    assert response.status_code == 200\n```\n\n### Database Integration Testing\n\n```python\nimport pytest\nfrom sqlalchemy import create_engine\nfrom sqlalchemy.orm import sessionmaker\nfrom main import app, get_db, Base\n\n# Test database\nSQLALCHEMY_DATABASE_URL = \"sqlite:///./test.db\"\nengine = create_engine(SQLALCHEMY_DATABASE_URL)\nTestingSessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)\n\n@pytest.fixture\ndef db():\n    \"\"\"Create test database\"\"\"\n    Base.metadata.create_all(bind=engine)\n    yield\n    Base.metadata.drop_all(bind=engine)\n\n@pytest.fixture\ndef client(db):\n    \"\"\"Override database dependency\"\"\"\n    def override_get_db():\n        try:\n            db = TestingSessionLocal()\n            yield db\n        finally:\n            db.close()\n\n    app.dependency_overrides[get_db] = override_get_db\n    return TestClient(app)\n\ndef test_create_and_retrieve_user(client):\n    # Create user\n    response = client.post(\n        \"/api/users\",\n        json={\"name\": \"John\", \"email\": \"john@example.com\"}\n    )\n    assert response.status_code == 201\n    user_id = response.json()[\"id\"]\n\n    # Retrieve user\n    response = client.get(f\"/api/users/{user_id}\")\n    assert response.status_code == 200\n    assert response.json()[\"name\"] == \"John\"\n```\n\n## API Schema Validation\n\n### JSON Schema Validation (TypeScript)\n\n```typescript\nimport Ajv from 'ajv'\n\nconst ajv = new Ajv()\n\nconst userSchema = {\n  type: 'object',\n  properties: {\n    id: { type: 'number' },\n    name: { type: 'string' },\n    email: { type: 'string', format: 'email' },\n    createdAt: { type: 'string', format: 'date-time' },\n  },\n  required: ['id', 'name', 'email'],\n}\n\nit('validates user schema', async () => {\n  const response = await request(app)\n    .get('/api/users/1')\n    .expect(200)\n\n  const validate = ajv.compile(userSchema)\n  expect(validate(response.body)).toBe(true)\n})\n```\n\n### Pydantic Validation (Python)\n\n```python\nfrom pydantic import BaseModel, EmailStr, validator\n\nclass UserResponse(BaseModel):\n    id: int\n    name: str\n    email: EmailStr\n    created_at: str\n\n    @validator('name')\n    def name_must_not_be_empty(cls, v):\n        if not v.strip():\n            raise ValueError('Name cannot be empty')\n        return v\n\ndef test_user_response_schema(client):\n    response = client.get(\"/api/users/1\")\n    assert response.status_code == 200\n\n    # Validate response against schema\n    user = UserResponse(**response.json())\n    assert user.id == 1\n    assert isinstance(user.email, str)\n```\n\n## Performance Testing\n\n### Response Time Assertions (TypeScript)\n\n```typescript\nit('responds within acceptable time', async () => {\n  const start = Date.now()\n\n  await request(app)\n    .get('/api/users')\n    .expect(200)\n\n  const duration = Date.now() - start\n  expect(duration).toBeLessThan(100) // 100ms threshold\n})\n```\n\n### Response Time Assertions (Python)\n\n```python\nimport time\n\ndef test_response_time(client):\n    start = time.time()\n\n    response = client.get(\"/api/users\")\n\n    duration = time.time() - start\n    assert response.status_code == 200\n    assert duration < 0.1  # 100ms threshold\n```\n\n## Best Practices\n\n**Test Organization**\n- Group related endpoints in `describe` blocks\n- Use `beforeEach` for common setup\n- Keep tests focused on single behavior\n- Test both happy path and error cases\n\n**Database State**\n- Reset database between tests\n- Use transactions that rollback\n- Seed minimal test data\n- Avoid depending on test execution order\n\n**Assertions**\n- Validate status codes first\n- Check response structure\n- Verify specific field values\n- Test error message format\n\n**Mocking External Services**\n```typescript\nimport { vi } from 'vitest'\n\n// Mock external API\nvi.mock('./externalAPI', () => ({\n  fetchUserData: vi.fn(() => Promise.resolve({ status: 'ok' })),\n}))\n```\n\n```python\nfrom unittest.mock import patch\n\n@patch('main.external_api.fetch_user_data')\ndef test_with_mocked_external_service(mock_fetch, client):\n    mock_fetch.return_value = {\"status\": \"ok\"}\n\n    response = client.get(\"/api/users/1\")\n    assert response.status_code == 200\n```\n\n**Common Patterns**\n\n```typescript\n// Test factory for creating test data\nfunction createTestUser(overrides = {}) {\n  return {\n    name: 'Test User',\n    email: 'test@example.com',\n    ...overrides,\n  }\n}\n\n// Reusable authentication helper\nasync function authenticateUser(app: Express) {\n  const response = await request(app)\n    .post('/api/auth/login')\n    .send({ email: 'user@example.com', password: 'password' })  // pragma: allowlist secret\n\n  return response.body.token\n}\n```\n\n## GraphQL API Testing\n\n### TypeScript (Supertest)\n\n```typescript\nit('queries GraphQL endpoint', async () => {\n  const query = `\n    query GetUser($id: ID!) {\n      user(id: $id) {\n        id\n        name\n        email\n      }\n    }\n  `\n\n  const response = await request(app)\n    .post('/graphql')\n    .send({ query, variables: { id: '1' } })\n    .expect(200)\n\n  expect(response.body.data.user).toMatchObject({\n    id: '1',\n    name: expect.any(String),\n    email: expect.any(String),\n  })\n})\n```\n\n### Python (httpx)\n\n```python\ndef test_graphql_query(client):\n    query = \"\"\"\n    query GetUser($id: ID!) {\n      user(id: $id) {\n        id\n        name\n        email\n      }\n    }\n    \"\"\"\n\n    response = client.post(\n        \"/graphql\",\n        json={\"query\": query, \"variables\": {\"id\": \"1\"}}\n    )\n\n    assert response.status_code == 200\n    data = response.json()[\"data\"]\n    assert data[\"user\"][\"id\"] == \"1\"\n    assert \"name\" in data[\"user\"]\n```\n\n## Troubleshooting\n\n**Port already in use**\n```typescript\n// Use random port for testing\nconst server = app.listen(0) // 0 = random available port\nconst port = server.address().port\n```\n\n**Database connection issues**\n```python\n# Use separate test database\n@pytest.fixture(scope=\"session\")\ndef db_engine():\n    engine = create_engine(\"sqlite:///./test.db\")\n    yield engine\n    engine.dispose()\n```\n\n**Slow tests**\n```typescript\n// Mock expensive operations\nvi.mock('./slowService', () => ({\n  processData: vi.fn(() => Promise.resolve('mocked')),\n}))\n```\n\n## See Also\n\n- `vitest-testing` - Unit testing framework\n- `python-testing` - Python pytest patterns\n- `playwright-testing` - E2E API testing\n- `test-quality-analysis` - Test quality patterns\n\n## References\n\n- Supertest: https://github.com/ladjs/supertest\n- httpx: https://www.python-httpx.org/\n- FastAPI Testing: https://fastapi.tiangolo.com/tutorial/testing/\n- Node.js Testing Best Practices: https://github.com/goldbergyoni/nodejs-testing-best-practices"
              }
            ]
          },
          {
            "name": "communication-plugin",
            "description": "External communication formatting - Google Chat, ticket drafting",
            "source": "./communication-plugin",
            "category": "communication",
            "version": "1.0.0",
            "author": null,
            "install_commands": [
              "/plugin marketplace add laurigates/claude-plugins",
              "/plugin install communication-plugin@lgates-claude-plugins"
            ],
            "signals": {
              "stars": 1,
              "forks": 0,
              "pushed_at": "2026-01-12T12:05:51Z",
              "created_at": "2025-12-16T11:24:04Z",
              "license": null
            },
            "commands": [],
            "skills": []
          },
          {
            "name": "agents-plugin",
            "description": "Task-focused agents for test, review, debug, docs, and CI workflows",
            "source": "./agents-plugin",
            "category": "ai",
            "version": "1.0.0",
            "author": null,
            "install_commands": [
              "/plugin marketplace add laurigates/claude-plugins",
              "/plugin install agents-plugin@lgates-claude-plugins"
            ],
            "signals": {
              "stars": 1,
              "forks": 0,
              "pushed_at": "2026-01-12T12:05:51Z",
              "created_at": "2025-12-16T11:24:04Z",
              "license": null
            },
            "commands": [],
            "skills": []
          }
        ]
      }
    }
  ]
}