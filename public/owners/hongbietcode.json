{
  "owner": {
    "id": "hongbietcode",
    "display_name": "Trí",
    "type": "User",
    "avatar_url": "https://avatars.githubusercontent.com/u/56062734?u=25f3e69533b077313d759565f1c476ca2bc31c7b&v=4",
    "url": "https://github.com/hongbietcode",
    "bio": "██░░░░░░░░ loading 8%",
    "stats": {
      "total_repos": 1,
      "total_plugins": 6,
      "total_commands": 24,
      "total_skills": 25,
      "total_stars": 1,
      "total_forks": 0
    }
  },
  "repos": [
    {
      "full_name": "hongbietcode/synthetic-claude",
      "url": "https://github.com/hongbietcode/synthetic-claude",
      "description": "Extensible Claude Code plugin with multi-agent debate capabilities.",
      "homepage": "",
      "signals": {
        "stars": 1,
        "forks": 0,
        "pushed_at": "2026-01-07T17:25:07Z",
        "created_at": "2025-12-28T07:34:15Z",
        "license": null
      },
      "file_tree": [
        {
          "path": ".claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude-plugin/marketplace.json",
          "type": "blob",
          "size": 2155
        },
        {
          "path": ".claude",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude/settings.json",
          "type": "blob",
          "size": 83
        },
        {
          "path": ".gitignore",
          "type": "blob",
          "size": 12
        },
        {
          "path": "README.md",
          "type": "blob",
          "size": 5629
        },
        {
          "path": "docs",
          "type": "tree",
          "size": null
        },
        {
          "path": "docs/code-standards.md",
          "type": "blob",
          "size": 10181
        },
        {
          "path": "docs/codebase-summary.md",
          "type": "blob",
          "size": 14607
        },
        {
          "path": "docs/project-overview-pdr.md",
          "type": "blob",
          "size": 7135
        },
        {
          "path": "docs/project-roadmap.md",
          "type": "blob",
          "size": 12638
        },
        {
          "path": "docs/system-architecture.md",
          "type": "blob",
          "size": 17379
        },
        {
          "path": "plugins",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/content-creation",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/content-creation/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/content-creation/.claude-plugin/marketplace.json",
          "type": "blob",
          "size": 910
        },
        {
          "path": "plugins/content-creation/README.md",
          "type": "blob",
          "size": 1352
        },
        {
          "path": "plugins/content-creation/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/content-creation/commands/create-project-memory-skills.md",
          "type": "blob",
          "size": 820
        },
        {
          "path": "plugins/content-creation/commands/current-prompt-create.md",
          "type": "blob",
          "size": 158
        },
        {
          "path": "plugins/content-creation/commands/ecp.md",
          "type": "blob",
          "size": 521
        },
        {
          "path": "plugins/content-creation/commands/notebook-edit.md",
          "type": "blob",
          "size": 105
        },
        {
          "path": "plugins/content-creation/commands/py2notebook.md",
          "type": "blob",
          "size": 582
        },
        {
          "path": "plugins/content-creation/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/content-creation/skills/doc-coauthoring",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/content-creation/skills/doc-coauthoring/SKILL.md",
          "type": "blob",
          "size": 15815
        },
        {
          "path": "plugins/content-creation/skills/internal-comms",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/content-creation/skills/internal-comms/LICENSE.txt",
          "type": "blob",
          "size": 11357
        },
        {
          "path": "plugins/content-creation/skills/internal-comms/SKILL.md",
          "type": "blob",
          "size": 1511
        },
        {
          "path": "plugins/content-creation/skills/internal-comms/examples",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/content-creation/skills/internal-comms/examples/3p-updates.md",
          "type": "blob",
          "size": 3274
        },
        {
          "path": "plugins/content-creation/skills/internal-comms/examples/company-newsletter.md",
          "type": "blob",
          "size": 3295
        },
        {
          "path": "plugins/content-creation/skills/internal-comms/examples/faq-answers.md",
          "type": "blob",
          "size": 2366
        },
        {
          "path": "plugins/content-creation/skills/internal-comms/examples/general-comms.md",
          "type": "blob",
          "size": 602
        },
        {
          "path": "plugins/content-creation/skills/llm-apps-creator",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/content-creation/skills/llm-apps-creator/SKILL.md",
          "type": "blob",
          "size": 15045
        },
        {
          "path": "plugins/content-creation/skills/llm-apps-creator/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/content-creation/skills/llm-apps-creator/references/base_n_powerful_agent.py",
          "type": "blob",
          "size": 11763
        },
        {
          "path": "plugins/content-creation/skills/llm-apps-creator/references/langchain_structured_output.md",
          "type": "blob",
          "size": 24629
        },
        {
          "path": "plugins/content-creation/skills/power-agent-creator",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/content-creation/skills/power-agent-creator/SKILL.md",
          "type": "blob",
          "size": 11342
        },
        {
          "path": "plugins/content-creation/skills/power-agent-creator/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/content-creation/skills/power-agent-creator/references/base_n_powerful_agent.py",
          "type": "blob",
          "size": 11763
        },
        {
          "path": "plugins/content-creation/skills/power-agent-creator/references/prompts.py",
          "type": "blob",
          "size": 14509
        },
        {
          "path": "plugins/content-creation/skills/power-agent-creator/references/tools",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/content-creation/skills/power-agent-creator/references/tools/__init__.py",
          "type": "blob",
          "size": 653
        },
        {
          "path": "plugins/content-creation/skills/power-agent-creator/references/tools/execution_tools.py",
          "type": "blob",
          "size": 27096
        },
        {
          "path": "plugins/content-creation/skills/power-agent-creator/references/tools/file_tools.py",
          "type": "blob",
          "size": 11674
        },
        {
          "path": "plugins/content-creation/skills/power-agent-creator/references/tools/search_tools.py",
          "type": "blob",
          "size": 8901
        },
        {
          "path": "plugins/content-creation/skills/power-agent-creator/references/tools/task_tool.py",
          "type": "blob",
          "size": 2310
        },
        {
          "path": "plugins/content-creation/skills/power-agent-creator/references/tools/web_fetch_tool.py",
          "type": "blob",
          "size": 8501
        },
        {
          "path": "plugins/content-creation/skills/power-agent-creator/references/tools/web_search_tool.py",
          "type": "blob",
          "size": 3290
        },
        {
          "path": "plugins/content-creation/skills/prompting",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/content-creation/skills/prompting/SKILL.md",
          "type": "blob",
          "size": 4976
        },
        {
          "path": "plugins/content-creation/skills/prompting/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/content-creation/skills/prompting/references/agentic-patterns.md",
          "type": "blob",
          "size": 4382
        },
        {
          "path": "plugins/content-creation/skills/prompting/references/anti-patterns.md",
          "type": "blob",
          "size": 3433
        },
        {
          "path": "plugins/content-creation/skills/prompting/references/memory-patterns.md",
          "type": "blob",
          "size": 2424
        },
        {
          "path": "plugins/content-creation/skills/prompting/references/meta-prompting.md",
          "type": "blob",
          "size": 3126
        },
        {
          "path": "plugins/content-creation/skills/prompting/references/techniques.md",
          "type": "blob",
          "size": 4130
        },
        {
          "path": "plugins/content-creation/skills/templates",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/content-creation/skills/templates/project-memory-recall",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/content-creation/skills/templates/project-memory-recall/SKILL.md",
          "type": "blob",
          "size": 6963
        },
        {
          "path": "plugins/content-creation/skills/templates/project-memory-store",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/content-creation/skills/templates/project-memory-store/SKILL.md",
          "type": "blob",
          "size": 11059
        },
        {
          "path": "plugins/content-creation/skills/web-artifacts-builder",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/content-creation/skills/web-artifacts-builder/LICENSE.txt",
          "type": "blob",
          "size": 11357
        },
        {
          "path": "plugins/content-creation/skills/web-artifacts-builder/SKILL.md",
          "type": "blob",
          "size": 3087
        },
        {
          "path": "plugins/content-creation/skills/web-artifacts-builder/scripts",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/content-creation/skills/web-artifacts-builder/scripts/bundle-artifact.sh",
          "type": "blob",
          "size": 1517
        },
        {
          "path": "plugins/content-creation/skills/web-artifacts-builder/scripts/init-artifact.sh",
          "type": "blob",
          "size": 9924
        },
        {
          "path": "plugins/content-creation/skills/web-artifacts-builder/scripts/shadcn-components.tar.gz",
          "type": "blob",
          "size": 19967
        },
        {
          "path": "plugins/debate-system",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/debate-system/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/debate-system/.claude-plugin/marketplace.json",
          "type": "blob",
          "size": 803
        },
        {
          "path": "plugins/debate-system/README.md",
          "type": "blob",
          "size": 1375
        },
        {
          "path": "plugins/debate-system/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/debate-system/agents/critic.md",
          "type": "blob",
          "size": 1659
        },
        {
          "path": "plugins/debate-system/agents/debate-orchestrator.md",
          "type": "blob",
          "size": 2356
        },
        {
          "path": "plugins/debate-system/agents/researcher.md",
          "type": "blob",
          "size": 1651
        },
        {
          "path": "plugins/debate-system/agents/synthesizer.md",
          "type": "blob",
          "size": 1738
        },
        {
          "path": "plugins/debate-system/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/debate-system/commands/debate.md",
          "type": "blob",
          "size": 12334
        },
        {
          "path": "plugins/debate-system/commands/discuss.md",
          "type": "blob",
          "size": 339
        },
        {
          "path": "plugins/debate-system/commands/quick-brainstorm.md",
          "type": "blob",
          "size": 449
        },
        {
          "path": "plugins/debate-system/commands/think-hard.md",
          "type": "blob",
          "size": 182
        },
        {
          "path": "plugins/debate-system/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/debate-system/skills/debate-workflow",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/debate-system/skills/debate-workflow/SKILL.md",
          "type": "blob",
          "size": 5225
        },
        {
          "path": "plugins/design-studio",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/design-studio/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/design-studio/.claude-plugin/marketplace.json",
          "type": "blob",
          "size": 734
        },
        {
          "path": "plugins/design-studio/README.md",
          "type": "blob",
          "size": 1333
        },
        {
          "path": "plugins/design-studio/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/design-studio/agents/ui-ux-designer.md",
          "type": "blob",
          "size": 3777
        },
        {
          "path": "plugins/design-studio/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/design-studio/commands/design-guide.md",
          "type": "blob",
          "size": 1594
        },
        {
          "path": "plugins/design-studio/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/design-studio/skills/algorithmic-art",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/design-studio/skills/algorithmic-art/LICENSE.txt",
          "type": "blob",
          "size": 11357
        },
        {
          "path": "plugins/design-studio/skills/algorithmic-art/SKILL.md",
          "type": "blob",
          "size": 19769
        },
        {
          "path": "plugins/design-studio/skills/algorithmic-art/templates",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/design-studio/skills/algorithmic-art/templates/generator_template.js",
          "type": "blob",
          "size": 7826
        },
        {
          "path": "plugins/design-studio/skills/algorithmic-art/templates/viewer.html",
          "type": "blob",
          "size": 20844
        },
        {
          "path": "plugins/design-studio/skills/brand-guidelines",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/design-studio/skills/brand-guidelines/LICENSE.txt",
          "type": "blob",
          "size": 11357
        },
        {
          "path": "plugins/design-studio/skills/brand-guidelines/SKILL.md",
          "type": "blob",
          "size": 2235
        },
        {
          "path": "plugins/design-studio/skills/canvas-design",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/design-studio/skills/canvas-design/LICENSE.txt",
          "type": "blob",
          "size": 11357
        },
        {
          "path": "plugins/design-studio/skills/canvas-design/SKILL.md",
          "type": "blob",
          "size": 11939
        },
        {
          "path": "plugins/design-studio/skills/canvas-design/canvas-fonts",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/design-studio/skills/canvas-design/canvas-fonts/ArsenalSC-OFL.txt",
          "type": "blob",
          "size": 4373
        },
        {
          "path": "plugins/design-studio/skills/canvas-design/canvas-fonts/ArsenalSC-Regular.ttf",
          "type": "blob",
          "size": 165848
        },
        {
          "path": "plugins/design-studio/skills/canvas-design/canvas-fonts/BigShoulders-Bold.ttf",
          "type": "blob",
          "size": 94528
        },
        {
          "path": "plugins/design-studio/skills/canvas-design/canvas-fonts/BigShoulders-OFL.txt",
          "type": "blob",
          "size": 4397
        },
        {
          "path": "plugins/design-studio/skills/canvas-design/canvas-fonts/BigShoulders-Regular.ttf",
          "type": "blob",
          "size": 94396
        },
        {
          "path": "plugins/design-studio/skills/canvas-design/canvas-fonts/Boldonse-OFL.txt",
          "type": "blob",
          "size": 4390
        },
        {
          "path": "plugins/design-studio/skills/canvas-design/canvas-fonts/Boldonse-Regular.ttf",
          "type": "blob",
          "size": 77168
        },
        {
          "path": "plugins/design-studio/skills/canvas-design/canvas-fonts/BricolageGrotesque-Bold.ttf",
          "type": "blob",
          "size": 90952
        },
        {
          "path": "plugins/design-studio/skills/canvas-design/canvas-fonts/BricolageGrotesque-OFL.txt",
          "type": "blob",
          "size": 4403
        },
        {
          "path": "plugins/design-studio/skills/canvas-design/canvas-fonts/BricolageGrotesque-Regular.ttf",
          "type": "blob",
          "size": 90920
        },
        {
          "path": "plugins/design-studio/skills/canvas-design/canvas-fonts/CrimsonPro-Bold.ttf",
          "type": "blob",
          "size": 107352
        },
        {
          "path": "plugins/design-studio/skills/canvas-design/canvas-fonts/CrimsonPro-Italic.ttf",
          "type": "blob",
          "size": 108828
        },
        {
          "path": "plugins/design-studio/skills/canvas-design/canvas-fonts/CrimsonPro-OFL.txt",
          "type": "blob",
          "size": 4394
        },
        {
          "path": "plugins/design-studio/skills/canvas-design/canvas-fonts/CrimsonPro-Regular.ttf",
          "type": "blob",
          "size": 106696
        },
        {
          "path": "plugins/design-studio/skills/canvas-design/canvas-fonts/DMMono-OFL.txt",
          "type": "blob",
          "size": 4392
        },
        {
          "path": "plugins/design-studio/skills/canvas-design/canvas-fonts/DMMono-Regular.ttf",
          "type": "blob",
          "size": 48852
        },
        {
          "path": "plugins/design-studio/skills/canvas-design/canvas-fonts/EricaOne-OFL.txt",
          "type": "blob",
          "size": 4410
        },
        {
          "path": "plugins/design-studio/skills/canvas-design/canvas-fonts/EricaOne-Regular.ttf",
          "type": "blob",
          "size": 24872
        },
        {
          "path": "plugins/design-studio/skills/canvas-design/canvas-fonts/GeistMono-Bold.ttf",
          "type": "blob",
          "size": 78304
        },
        {
          "path": "plugins/design-studio/skills/canvas-design/canvas-fonts/GeistMono-OFL.txt",
          "type": "blob",
          "size": 4388
        },
        {
          "path": "plugins/design-studio/skills/canvas-design/canvas-fonts/GeistMono-Regular.ttf",
          "type": "blob",
          "size": 78232
        },
        {
          "path": "plugins/design-studio/skills/canvas-design/canvas-fonts/Gloock-OFL.txt",
          "type": "blob",
          "size": 4381
        },
        {
          "path": "plugins/design-studio/skills/canvas-design/canvas-fonts/Gloock-Regular.ttf",
          "type": "blob",
          "size": 95156
        },
        {
          "path": "plugins/design-studio/skills/canvas-design/canvas-fonts/IBMPlexMono-Bold.ttf",
          "type": "blob",
          "size": 136008
        },
        {
          "path": "plugins/design-studio/skills/canvas-design/canvas-fonts/IBMPlexMono-OFL.txt",
          "type": "blob",
          "size": 4363
        },
        {
          "path": "plugins/design-studio/skills/canvas-design/canvas-fonts/IBMPlexMono-Regular.ttf",
          "type": "blob",
          "size": 133796
        },
        {
          "path": "plugins/design-studio/skills/canvas-design/canvas-fonts/IBMPlexSerif-Bold.ttf",
          "type": "blob",
          "size": 161000
        },
        {
          "path": "plugins/design-studio/skills/canvas-design/canvas-fonts/IBMPlexSerif-BoldItalic.ttf",
          "type": "blob",
          "size": 169840
        },
        {
          "path": "plugins/design-studio/skills/canvas-design/canvas-fonts/IBMPlexSerif-Italic.ttf",
          "type": "blob",
          "size": 170004
        },
        {
          "path": "plugins/design-studio/skills/canvas-design/canvas-fonts/IBMPlexSerif-Regular.ttf",
          "type": "blob",
          "size": 160380
        },
        {
          "path": "plugins/design-studio/skills/canvas-design/canvas-fonts/InstrumentSans-Bold.ttf",
          "type": "blob",
          "size": 68084
        },
        {
          "path": "plugins/design-studio/skills/canvas-design/canvas-fonts/InstrumentSans-BoldItalic.ttf",
          "type": "blob",
          "size": 70004
        },
        {
          "path": "plugins/design-studio/skills/canvas-design/canvas-fonts/InstrumentSans-Italic.ttf",
          "type": "blob",
          "size": 69900
        },
        {
          "path": "plugins/design-studio/skills/canvas-design/canvas-fonts/InstrumentSans-OFL.txt",
          "type": "blob",
          "size": 4403
        },
        {
          "path": "plugins/design-studio/skills/canvas-design/canvas-fonts/InstrumentSans-Regular.ttf",
          "type": "blob",
          "size": 68028
        },
        {
          "path": "plugins/design-studio/skills/canvas-design/canvas-fonts/InstrumentSerif-Italic.ttf",
          "type": "blob",
          "size": 70868
        },
        {
          "path": "plugins/design-studio/skills/canvas-design/canvas-fonts/InstrumentSerif-Regular.ttf",
          "type": "blob",
          "size": 69312
        },
        {
          "path": "plugins/design-studio/skills/canvas-design/canvas-fonts/Italiana-OFL.txt",
          "type": "blob",
          "size": 4394
        },
        {
          "path": "plugins/design-studio/skills/canvas-design/canvas-fonts/Italiana-Regular.ttf",
          "type": "blob",
          "size": 27184
        },
        {
          "path": "plugins/design-studio/skills/canvas-design/canvas-fonts/JetBrainsMono-Bold.ttf",
          "type": "blob",
          "size": 114828
        },
        {
          "path": "plugins/design-studio/skills/canvas-design/canvas-fonts/JetBrainsMono-OFL.txt",
          "type": "blob",
          "size": 4399
        },
        {
          "path": "plugins/design-studio/skills/canvas-design/canvas-fonts/JetBrainsMono-Regular.ttf",
          "type": "blob",
          "size": 114904
        },
        {
          "path": "plugins/design-studio/skills/canvas-design/canvas-fonts/Jura-Light.ttf",
          "type": "blob",
          "size": 154308
        },
        {
          "path": "plugins/design-studio/skills/canvas-design/canvas-fonts/Jura-Medium.ttf",
          "type": "blob",
          "size": 154488
        },
        {
          "path": "plugins/design-studio/skills/canvas-design/canvas-fonts/Jura-OFL.txt",
          "type": "blob",
          "size": 4380
        },
        {
          "path": "plugins/design-studio/skills/canvas-design/canvas-fonts/LibreBaskerville-OFL.txt",
          "type": "blob",
          "size": 4449
        },
        {
          "path": "plugins/design-studio/skills/canvas-design/canvas-fonts/LibreBaskerville-Regular.ttf",
          "type": "blob",
          "size": 147584
        },
        {
          "path": "plugins/design-studio/skills/canvas-design/canvas-fonts/Lora-Bold.ttf",
          "type": "blob",
          "size": 133828
        },
        {
          "path": "plugins/design-studio/skills/canvas-design/canvas-fonts/Lora-BoldItalic.ttf",
          "type": "blob",
          "size": 140332
        },
        {
          "path": "plugins/design-studio/skills/canvas-design/canvas-fonts/Lora-Italic.ttf",
          "type": "blob",
          "size": 139328
        },
        {
          "path": "plugins/design-studio/skills/canvas-design/canvas-fonts/Lora-OFL.txt",
          "type": "blob",
          "size": 4423
        },
        {
          "path": "plugins/design-studio/skills/canvas-design/canvas-fonts/Lora-Regular.ttf",
          "type": "blob",
          "size": 133888
        },
        {
          "path": "plugins/design-studio/skills/canvas-design/canvas-fonts/NationalPark-Bold.ttf",
          "type": "blob",
          "size": 79208
        },
        {
          "path": "plugins/design-studio/skills/canvas-design/canvas-fonts/NationalPark-OFL.txt",
          "type": "blob",
          "size": 4399
        },
        {
          "path": "plugins/design-studio/skills/canvas-design/canvas-fonts/NationalPark-Regular.ttf",
          "type": "blob",
          "size": 76424
        },
        {
          "path": "plugins/design-studio/skills/canvas-design/canvas-fonts/NothingYouCouldDo-OFL.txt",
          "type": "blob",
          "size": 4363
        },
        {
          "path": "plugins/design-studio/skills/canvas-design/canvas-fonts/NothingYouCouldDo-Regular.ttf",
          "type": "blob",
          "size": 32020
        },
        {
          "path": "plugins/design-studio/skills/canvas-design/canvas-fonts/Outfit-Bold.ttf",
          "type": "blob",
          "size": 55392
        },
        {
          "path": "plugins/design-studio/skills/canvas-design/canvas-fonts/Outfit-OFL.txt",
          "type": "blob",
          "size": 4389
        },
        {
          "path": "plugins/design-studio/skills/canvas-design/canvas-fonts/Outfit-Regular.ttf",
          "type": "blob",
          "size": 54912
        },
        {
          "path": "plugins/design-studio/skills/canvas-design/canvas-fonts/PixelifySans-Medium.ttf",
          "type": "blob",
          "size": 51072
        },
        {
          "path": "plugins/design-studio/skills/canvas-design/canvas-fonts/PixelifySans-OFL.txt",
          "type": "blob",
          "size": 4395
        },
        {
          "path": "plugins/design-studio/skills/canvas-design/canvas-fonts/PoiretOne-OFL.txt",
          "type": "blob",
          "size": 4366
        },
        {
          "path": "plugins/design-studio/skills/canvas-design/canvas-fonts/PoiretOne-Regular.ttf",
          "type": "blob",
          "size": 45244
        },
        {
          "path": "plugins/design-studio/skills/canvas-design/canvas-fonts/RedHatMono-Bold.ttf",
          "type": "blob",
          "size": 34420
        },
        {
          "path": "plugins/design-studio/skills/canvas-design/canvas-fonts/RedHatMono-OFL.txt",
          "type": "blob",
          "size": 4394
        },
        {
          "path": "plugins/design-studio/skills/canvas-design/canvas-fonts/RedHatMono-Regular.ttf",
          "type": "blob",
          "size": 34488
        },
        {
          "path": "plugins/design-studio/skills/canvas-design/canvas-fonts/Silkscreen-OFL.txt",
          "type": "blob",
          "size": 4394
        },
        {
          "path": "plugins/design-studio/skills/canvas-design/canvas-fonts/Silkscreen-Regular.ttf",
          "type": "blob",
          "size": 31960
        },
        {
          "path": "plugins/design-studio/skills/canvas-design/canvas-fonts/SmoochSans-Medium.ttf",
          "type": "blob",
          "size": 59704
        },
        {
          "path": "plugins/design-studio/skills/canvas-design/canvas-fonts/SmoochSans-OFL.txt",
          "type": "blob",
          "size": 4396
        },
        {
          "path": "plugins/design-studio/skills/canvas-design/canvas-fonts/Tektur-Medium.ttf",
          "type": "blob",
          "size": 76248
        },
        {
          "path": "plugins/design-studio/skills/canvas-design/canvas-fonts/Tektur-OFL.txt",
          "type": "blob",
          "size": 4385
        },
        {
          "path": "plugins/design-studio/skills/canvas-design/canvas-fonts/Tektur-Regular.ttf",
          "type": "blob",
          "size": 75604
        },
        {
          "path": "plugins/design-studio/skills/canvas-design/canvas-fonts/WorkSans-Bold.ttf",
          "type": "blob",
          "size": 191304
        },
        {
          "path": "plugins/design-studio/skills/canvas-design/canvas-fonts/WorkSans-BoldItalic.ttf",
          "type": "blob",
          "size": 175772
        },
        {
          "path": "plugins/design-studio/skills/canvas-design/canvas-fonts/WorkSans-Italic.ttf",
          "type": "blob",
          "size": 174280
        },
        {
          "path": "plugins/design-studio/skills/canvas-design/canvas-fonts/WorkSans-OFL.txt",
          "type": "blob",
          "size": 4397
        },
        {
          "path": "plugins/design-studio/skills/canvas-design/canvas-fonts/WorkSans-Regular.ttf",
          "type": "blob",
          "size": 188916
        },
        {
          "path": "plugins/design-studio/skills/canvas-design/canvas-fonts/YoungSerif-OFL.txt",
          "type": "blob",
          "size": 4398
        },
        {
          "path": "plugins/design-studio/skills/canvas-design/canvas-fonts/YoungSerif-Regular.ttf",
          "type": "blob",
          "size": 105136
        },
        {
          "path": "plugins/design-studio/skills/frontend-design",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/design-studio/skills/frontend-design/LICENSE.txt",
          "type": "blob",
          "size": 10174
        },
        {
          "path": "plugins/design-studio/skills/frontend-design/SKILL.md",
          "type": "blob",
          "size": 4440
        },
        {
          "path": "plugins/design-studio/skills/slack-gif-creator",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/design-studio/skills/slack-gif-creator/LICENSE.txt",
          "type": "blob",
          "size": 11357
        },
        {
          "path": "plugins/design-studio/skills/slack-gif-creator/SKILL.md",
          "type": "blob",
          "size": 7841
        },
        {
          "path": "plugins/design-studio/skills/slack-gif-creator/core",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/design-studio/skills/slack-gif-creator/core/easing.py",
          "type": "blob",
          "size": 6265
        },
        {
          "path": "plugins/design-studio/skills/slack-gif-creator/core/frame_composer.py",
          "type": "blob",
          "size": 4548
        },
        {
          "path": "plugins/design-studio/skills/slack-gif-creator/core/gif_builder.py",
          "type": "blob",
          "size": 9847
        },
        {
          "path": "plugins/design-studio/skills/slack-gif-creator/core/validators.py",
          "type": "blob",
          "size": 3785
        },
        {
          "path": "plugins/design-studio/skills/slack-gif-creator/requirements.txt",
          "type": "blob",
          "size": 66
        },
        {
          "path": "plugins/design-studio/skills/theme-factory",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/design-studio/skills/theme-factory/LICENSE.txt",
          "type": "blob",
          "size": 11357
        },
        {
          "path": "plugins/design-studio/skills/theme-factory/SKILL.md",
          "type": "blob",
          "size": 3124
        },
        {
          "path": "plugins/design-studio/skills/theme-factory/theme-showcase.pdf",
          "type": "blob",
          "size": 124310
        },
        {
          "path": "plugins/design-studio/skills/theme-factory/themes",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/design-studio/skills/theme-factory/themes/arctic-frost.md",
          "type": "blob",
          "size": 544
        },
        {
          "path": "plugins/design-studio/skills/theme-factory/themes/botanical-garden.md",
          "type": "blob",
          "size": 519
        },
        {
          "path": "plugins/design-studio/skills/theme-factory/themes/desert-rose.md",
          "type": "blob",
          "size": 496
        },
        {
          "path": "plugins/design-studio/skills/theme-factory/themes/forest-canopy.md",
          "type": "blob",
          "size": 506
        },
        {
          "path": "plugins/design-studio/skills/theme-factory/themes/golden-hour.md",
          "type": "blob",
          "size": 528
        },
        {
          "path": "plugins/design-studio/skills/theme-factory/themes/midnight-galaxy.md",
          "type": "blob",
          "size": 513
        },
        {
          "path": "plugins/design-studio/skills/theme-factory/themes/modern-minimalist.md",
          "type": "blob",
          "size": 549
        },
        {
          "path": "plugins/design-studio/skills/theme-factory/themes/ocean-depths.md",
          "type": "blob",
          "size": 555
        },
        {
          "path": "plugins/design-studio/skills/theme-factory/themes/sunset-boulevard.md",
          "type": "blob",
          "size": 558
        },
        {
          "path": "plugins/design-studio/skills/theme-factory/themes/tech-innovation.md",
          "type": "blob",
          "size": 547
        },
        {
          "path": "plugins/dev-tools",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/dev-tools/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/dev-tools/.claude-plugin/marketplace.json",
          "type": "blob",
          "size": 879
        },
        {
          "path": "plugins/dev-tools/README.md",
          "type": "blob",
          "size": 1325
        },
        {
          "path": "plugins/dev-tools/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/dev-tools/agents/critical-code-reviewer.md",
          "type": "blob",
          "size": 5522
        },
        {
          "path": "plugins/dev-tools/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/dev-tools/commands/explore-external-APIs.md",
          "type": "blob",
          "size": 2529
        },
        {
          "path": "plugins/dev-tools/commands/fastapi-test.md",
          "type": "blob",
          "size": 1200
        },
        {
          "path": "plugins/dev-tools/commands/gen-feature-docs.md",
          "type": "blob",
          "size": 1138
        },
        {
          "path": "plugins/dev-tools/commands/generate-db-docs.md",
          "type": "blob",
          "size": 829
        },
        {
          "path": "plugins/dev-tools/commands/px-backend-api.md",
          "type": "blob",
          "size": 543
        },
        {
          "path": "plugins/dev-tools/commands/px-frontend-api.md",
          "type": "blob",
          "size": 652
        },
        {
          "path": "plugins/dev-tools/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/dev-tools/skills/cc-hooks-creator",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/dev-tools/skills/cc-hooks-creator/SKILL.md",
          "type": "blob",
          "size": 11445
        },
        {
          "path": "plugins/dev-tools/skills/cc-hooks-creator/examples",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/dev-tools/skills/cc-hooks-creator/examples/hooks_readme.md",
          "type": "blob",
          "size": 3749
        },
        {
          "path": "plugins/dev-tools/skills/cc-hooks-creator/examples/memory_store_reminder.py",
          "type": "blob",
          "size": 4791
        },
        {
          "path": "plugins/dev-tools/skills/cc-hooks-creator/examples/todowrite_first_call.py",
          "type": "blob",
          "size": 3974
        },
        {
          "path": "plugins/dev-tools/skills/cc-hooks-creator/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/dev-tools/skills/cc-hooks-creator/references/cc_hooks_getting_started.md",
          "type": "blob",
          "size": 9763
        },
        {
          "path": "plugins/dev-tools/skills/cc-hooks-creator/references/cc_hooks_ref.md",
          "type": "blob",
          "size": 35796
        },
        {
          "path": "plugins/dev-tools/skills/mcp-builder",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/dev-tools/skills/mcp-builder/LICENSE.txt",
          "type": "blob",
          "size": 11357
        },
        {
          "path": "plugins/dev-tools/skills/mcp-builder/SKILL.md",
          "type": "blob",
          "size": 9092
        },
        {
          "path": "plugins/dev-tools/skills/mcp-builder/reference",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/dev-tools/skills/mcp-builder/reference/evaluation.md",
          "type": "blob",
          "size": 21663
        },
        {
          "path": "plugins/dev-tools/skills/mcp-builder/reference/mcp_best_practices.md",
          "type": "blob",
          "size": 7330
        },
        {
          "path": "plugins/dev-tools/skills/mcp-builder/reference/node_mcp_server.md",
          "type": "blob",
          "size": 28550
        },
        {
          "path": "plugins/dev-tools/skills/mcp-builder/reference/python_mcp_server.md",
          "type": "blob",
          "size": 25099
        },
        {
          "path": "plugins/dev-tools/skills/mcp-builder/scripts",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/dev-tools/skills/mcp-builder/scripts/connections.py",
          "type": "blob",
          "size": 4875
        },
        {
          "path": "plugins/dev-tools/skills/mcp-builder/scripts/evaluation.py",
          "type": "blob",
          "size": 12579
        },
        {
          "path": "plugins/dev-tools/skills/mcp-builder/scripts/example_evaluation.xml",
          "type": "blob",
          "size": 1194
        },
        {
          "path": "plugins/dev-tools/skills/mcp-builder/scripts/requirements.txt",
          "type": "blob",
          "size": 29
        },
        {
          "path": "plugins/dev-tools/skills/skill-creator",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/dev-tools/skills/skill-creator/LICENSE.txt",
          "type": "blob",
          "size": 11357
        },
        {
          "path": "plugins/dev-tools/skills/skill-creator/SKILL.md",
          "type": "blob",
          "size": 17837
        },
        {
          "path": "plugins/dev-tools/skills/skill-creator/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/dev-tools/skills/skill-creator/references/output-patterns.md",
          "type": "blob",
          "size": 1813
        },
        {
          "path": "plugins/dev-tools/skills/skill-creator/references/workflows.md",
          "type": "blob",
          "size": 818
        },
        {
          "path": "plugins/dev-tools/skills/skill-creator/scripts",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/dev-tools/skills/skill-creator/scripts/init_skill.py",
          "type": "blob",
          "size": 10863
        },
        {
          "path": "plugins/dev-tools/skills/skill-creator/scripts/package_skill.py",
          "type": "blob",
          "size": 3288
        },
        {
          "path": "plugins/dev-tools/skills/skill-creator/scripts/quick_validate.py",
          "type": "blob",
          "size": 3523
        },
        {
          "path": "plugins/dev-tools/skills/webapp-testing",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/dev-tools/skills/webapp-testing/LICENSE.txt",
          "type": "blob",
          "size": 11357
        },
        {
          "path": "plugins/dev-tools/skills/webapp-testing/SKILL.md",
          "type": "blob",
          "size": 3913
        },
        {
          "path": "plugins/dev-tools/skills/webapp-testing/examples",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/dev-tools/skills/webapp-testing/examples/console_logging.py",
          "type": "blob",
          "size": 1027
        },
        {
          "path": "plugins/dev-tools/skills/webapp-testing/examples/element_discovery.py",
          "type": "blob",
          "size": 1463
        },
        {
          "path": "plugins/dev-tools/skills/webapp-testing/examples/static_html_automation.py",
          "type": "blob",
          "size": 953
        },
        {
          "path": "plugins/dev-tools/skills/webapp-testing/scripts",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/dev-tools/skills/webapp-testing/scripts/with_server.py",
          "type": "blob",
          "size": 3693
        },
        {
          "path": "plugins/document-suite",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/document-suite/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/document-suite/.claude-plugin/marketplace.json",
          "type": "blob",
          "size": 545
        },
        {
          "path": "plugins/document-suite/README.md",
          "type": "blob",
          "size": 1126
        },
        {
          "path": "plugins/document-suite/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/document-suite/skills/docx",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/document-suite/skills/docx/LICENSE.txt",
          "type": "blob",
          "size": 1467
        },
        {
          "path": "plugins/document-suite/skills/docx/SKILL.md",
          "type": "blob",
          "size": 10150
        },
        {
          "path": "plugins/document-suite/skills/docx/docx-js.md",
          "type": "blob",
          "size": 16509
        },
        {
          "path": "plugins/document-suite/skills/docx/ooxml.md",
          "type": "blob",
          "size": 23572
        },
        {
          "path": "plugins/document-suite/skills/docx/ooxml",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/document-suite/skills/docx/ooxml/schemas",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/document-suite/skills/docx/ooxml/schemas/ISO-IEC29500-4_2016",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/document-suite/skills/docx/ooxml/schemas/ISO-IEC29500-4_2016/dml-chart.xsd",
          "type": "blob",
          "size": 74984
        },
        {
          "path": "plugins/document-suite/skills/docx/ooxml/schemas/ISO-IEC29500-4_2016/dml-chartDrawing.xsd",
          "type": "blob",
          "size": 6956
        },
        {
          "path": "plugins/document-suite/skills/docx/ooxml/schemas/ISO-IEC29500-4_2016/dml-diagram.xsd",
          "type": "blob",
          "size": 51302
        },
        {
          "path": "plugins/document-suite/skills/docx/ooxml/schemas/ISO-IEC29500-4_2016/dml-lockedCanvas.xsd",
          "type": "blob",
          "size": 624
        },
        {
          "path": "plugins/document-suite/skills/docx/ooxml/schemas/ISO-IEC29500-4_2016/dml-main.xsd",
          "type": "blob",
          "size": 152039
        },
        {
          "path": "plugins/document-suite/skills/docx/ooxml/schemas/ISO-IEC29500-4_2016/dml-picture.xsd",
          "type": "blob",
          "size": 1231
        },
        {
          "path": "plugins/document-suite/skills/docx/ooxml/schemas/ISO-IEC29500-4_2016/dml-spreadsheetDrawing.xsd",
          "type": "blob",
          "size": 8862
        },
        {
          "path": "plugins/document-suite/skills/docx/ooxml/schemas/ISO-IEC29500-4_2016/dml-wordprocessingDrawing.xsd",
          "type": "blob",
          "size": 14795
        },
        {
          "path": "plugins/document-suite/skills/docx/ooxml/schemas/ISO-IEC29500-4_2016/pml.xsd",
          "type": "blob",
          "size": 83612
        },
        {
          "path": "plugins/document-suite/skills/docx/ooxml/schemas/ISO-IEC29500-4_2016/shared-additionalCharacteristics.xsd",
          "type": "blob",
          "size": 1269
        },
        {
          "path": "plugins/document-suite/skills/docx/ooxml/schemas/ISO-IEC29500-4_2016/shared-bibliography.xsd",
          "type": "blob",
          "size": 7328
        },
        {
          "path": "plugins/document-suite/skills/docx/ooxml/schemas/ISO-IEC29500-4_2016/shared-commonSimpleTypes.xsd",
          "type": "blob",
          "size": 6382
        },
        {
          "path": "plugins/document-suite/skills/docx/ooxml/schemas/ISO-IEC29500-4_2016/shared-customXmlDataProperties.xsd",
          "type": "blob",
          "size": 1248
        },
        {
          "path": "plugins/document-suite/skills/docx/ooxml/schemas/ISO-IEC29500-4_2016/shared-customXmlSchemaProperties.xsd",
          "type": "blob",
          "size": 880
        },
        {
          "path": "plugins/document-suite/skills/docx/ooxml/schemas/ISO-IEC29500-4_2016/shared-documentPropertiesCustom.xsd",
          "type": "blob",
          "size": 2608
        },
        {
          "path": "plugins/document-suite/skills/docx/ooxml/schemas/ISO-IEC29500-4_2016/shared-documentPropertiesExtended.xsd",
          "type": "blob",
          "size": 3507
        },
        {
          "path": "plugins/document-suite/skills/docx/ooxml/schemas/ISO-IEC29500-4_2016/shared-documentPropertiesVariantTypes.xsd",
          "type": "blob",
          "size": 7507
        },
        {
          "path": "plugins/document-suite/skills/docx/ooxml/schemas/ISO-IEC29500-4_2016/shared-math.xsd",
          "type": "blob",
          "size": 23313
        },
        {
          "path": "plugins/document-suite/skills/docx/ooxml/schemas/ISO-IEC29500-4_2016/shared-relationshipReference.xsd",
          "type": "blob",
          "size": 1367
        },
        {
          "path": "plugins/document-suite/skills/docx/ooxml/schemas/ISO-IEC29500-4_2016/sml.xsd",
          "type": "blob",
          "size": 242277
        },
        {
          "path": "plugins/document-suite/skills/docx/ooxml/schemas/ISO-IEC29500-4_2016/vml-main.xsd",
          "type": "blob",
          "size": 26148
        },
        {
          "path": "plugins/document-suite/skills/docx/ooxml/schemas/ISO-IEC29500-4_2016/vml-officeDrawing.xsd",
          "type": "blob",
          "size": 25279
        },
        {
          "path": "plugins/document-suite/skills/docx/ooxml/schemas/ISO-IEC29500-4_2016/vml-presentationDrawing.xsd",
          "type": "blob",
          "size": 535
        },
        {
          "path": "plugins/document-suite/skills/docx/ooxml/schemas/ISO-IEC29500-4_2016/vml-spreadsheetDrawing.xsd",
          "type": "blob",
          "size": 5712
        },
        {
          "path": "plugins/document-suite/skills/docx/ooxml/schemas/ISO-IEC29500-4_2016/vml-wordprocessingDrawing.xsd",
          "type": "blob",
          "size": 4010
        },
        {
          "path": "plugins/document-suite/skills/docx/ooxml/schemas/ISO-IEC29500-4_2016/wml.xsd",
          "type": "blob",
          "size": 171367
        },
        {
          "path": "plugins/document-suite/skills/docx/ooxml/schemas/ISO-IEC29500-4_2016/xml.xsd",
          "type": "blob",
          "size": 4646
        },
        {
          "path": "plugins/document-suite/skills/docx/ooxml/schemas/ecma",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/document-suite/skills/docx/ooxml/schemas/ecma/fouth-edition",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/document-suite/skills/docx/ooxml/schemas/ecma/fouth-edition/opc-contentTypes.xsd",
          "type": "blob",
          "size": 1963
        },
        {
          "path": "plugins/document-suite/skills/docx/ooxml/schemas/ecma/fouth-edition/opc-coreProperties.xsd",
          "type": "blob",
          "size": 2515
        },
        {
          "path": "plugins/document-suite/skills/docx/ooxml/schemas/ecma/fouth-edition/opc-digSig.xsd",
          "type": "blob",
          "size": 2856
        },
        {
          "path": "plugins/document-suite/skills/docx/ooxml/schemas/ecma/fouth-edition/opc-relationships.xsd",
          "type": "blob",
          "size": 1344
        },
        {
          "path": "plugins/document-suite/skills/docx/ooxml/schemas/mce",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/document-suite/skills/docx/ooxml/schemas/mce/mc.xsd",
          "type": "blob",
          "size": 3127
        },
        {
          "path": "plugins/document-suite/skills/docx/ooxml/schemas/microsoft",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/document-suite/skills/docx/ooxml/schemas/microsoft/wml-2010.xsd",
          "type": "blob",
          "size": 26549
        },
        {
          "path": "plugins/document-suite/skills/docx/ooxml/schemas/microsoft/wml-2012.xsd",
          "type": "blob",
          "size": 3745
        },
        {
          "path": "plugins/document-suite/skills/docx/ooxml/schemas/microsoft/wml-2018.xsd",
          "type": "blob",
          "size": 901
        },
        {
          "path": "plugins/document-suite/skills/docx/ooxml/schemas/microsoft/wml-cex-2018.xsd",
          "type": "blob",
          "size": 1778
        },
        {
          "path": "plugins/document-suite/skills/docx/ooxml/schemas/microsoft/wml-cid-2016.xsd",
          "type": "blob",
          "size": 1002
        },
        {
          "path": "plugins/document-suite/skills/docx/ooxml/schemas/microsoft/wml-sdtdatahash-2020.xsd",
          "type": "blob",
          "size": 600
        },
        {
          "path": "plugins/document-suite/skills/docx/ooxml/schemas/microsoft/wml-symex-2015.xsd",
          "type": "blob",
          "size": 745
        },
        {
          "path": "plugins/document-suite/skills/docx/ooxml/scripts",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/document-suite/skills/docx/ooxml/scripts/pack.py",
          "type": "blob",
          "size": 5596
        },
        {
          "path": "plugins/document-suite/skills/docx/ooxml/scripts/unpack.py",
          "type": "blob",
          "size": 1037
        },
        {
          "path": "plugins/document-suite/skills/docx/ooxml/scripts/validate.py",
          "type": "blob",
          "size": 1959
        },
        {
          "path": "plugins/document-suite/skills/docx/ooxml/scripts/validation",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/document-suite/skills/docx/ooxml/scripts/validation/__init__.py",
          "type": "blob",
          "size": 336
        },
        {
          "path": "plugins/document-suite/skills/docx/ooxml/scripts/validation/base.py",
          "type": "blob",
          "size": 39892
        },
        {
          "path": "plugins/document-suite/skills/docx/ooxml/scripts/validation/docx.py",
          "type": "blob",
          "size": 9996
        },
        {
          "path": "plugins/document-suite/skills/docx/ooxml/scripts/validation/pptx.py",
          "type": "blob",
          "size": 12327
        },
        {
          "path": "plugins/document-suite/skills/docx/ooxml/scripts/validation/redlining.py",
          "type": "blob",
          "size": 11179
        },
        {
          "path": "plugins/document-suite/skills/docx/scripts",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/document-suite/skills/docx/scripts/__init__.py",
          "type": "blob",
          "size": 65
        },
        {
          "path": "plugins/document-suite/skills/docx/scripts/document.py",
          "type": "blob",
          "size": 50409
        },
        {
          "path": "plugins/document-suite/skills/docx/scripts/templates",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/document-suite/skills/docx/scripts/templates/comments.xml",
          "type": "blob",
          "size": 2635
        },
        {
          "path": "plugins/document-suite/skills/docx/scripts/templates/commentsExtended.xml",
          "type": "blob",
          "size": 2643
        },
        {
          "path": "plugins/document-suite/skills/docx/scripts/templates/commentsExtensible.xml",
          "type": "blob",
          "size": 2739
        },
        {
          "path": "plugins/document-suite/skills/docx/scripts/templates/commentsIds.xml",
          "type": "blob",
          "size": 2651
        },
        {
          "path": "plugins/document-suite/skills/docx/scripts/templates/people.xml",
          "type": "blob",
          "size": 147
        },
        {
          "path": "plugins/document-suite/skills/docx/scripts/utilities.py",
          "type": "blob",
          "size": 13694
        },
        {
          "path": "plugins/document-suite/skills/pdf",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/document-suite/skills/pdf/LICENSE.txt",
          "type": "blob",
          "size": 1467
        },
        {
          "path": "plugins/document-suite/skills/pdf/SKILL.md",
          "type": "blob",
          "size": 7068
        },
        {
          "path": "plugins/document-suite/skills/pdf/forms.md",
          "type": "blob",
          "size": 9438
        },
        {
          "path": "plugins/document-suite/skills/pdf/reference.md",
          "type": "blob",
          "size": 16692
        },
        {
          "path": "plugins/document-suite/skills/pdf/scripts",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/document-suite/skills/pdf/scripts/check_bounding_boxes.py",
          "type": "blob",
          "size": 3139
        },
        {
          "path": "plugins/document-suite/skills/pdf/scripts/check_bounding_boxes_test.py",
          "type": "blob",
          "size": 8818
        },
        {
          "path": "plugins/document-suite/skills/pdf/scripts/check_fillable_fields.py",
          "type": "blob",
          "size": 362
        },
        {
          "path": "plugins/document-suite/skills/pdf/scripts/convert_pdf_to_images.py",
          "type": "blob",
          "size": 1123
        },
        {
          "path": "plugins/document-suite/skills/pdf/scripts/create_validation_image.py",
          "type": "blob",
          "size": 1603
        },
        {
          "path": "plugins/document-suite/skills/pdf/scripts/extract_form_field_info.py",
          "type": "blob",
          "size": 6127
        },
        {
          "path": "plugins/document-suite/skills/pdf/scripts/fill_fillable_fields.py",
          "type": "blob",
          "size": 4863
        },
        {
          "path": "plugins/document-suite/skills/pdf/scripts/fill_pdf_form_with_annotations.py",
          "type": "blob",
          "size": 3596
        },
        {
          "path": "plugins/document-suite/skills/pptx",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/document-suite/skills/pptx/LICENSE.txt",
          "type": "blob",
          "size": 1467
        },
        {
          "path": "plugins/document-suite/skills/pptx/SKILL.md",
          "type": "blob",
          "size": 25551
        },
        {
          "path": "plugins/document-suite/skills/pptx/html2pptx.md",
          "type": "blob",
          "size": 19859
        },
        {
          "path": "plugins/document-suite/skills/pptx/ooxml.md",
          "type": "blob",
          "size": 10388
        },
        {
          "path": "plugins/document-suite/skills/pptx/ooxml",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/document-suite/skills/pptx/ooxml/schemas",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/document-suite/skills/pptx/ooxml/schemas/ISO-IEC29500-4_2016",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/document-suite/skills/pptx/ooxml/schemas/ISO-IEC29500-4_2016/dml-chart.xsd",
          "type": "blob",
          "size": 74984
        },
        {
          "path": "plugins/document-suite/skills/pptx/ooxml/schemas/ISO-IEC29500-4_2016/dml-chartDrawing.xsd",
          "type": "blob",
          "size": 6956
        },
        {
          "path": "plugins/document-suite/skills/pptx/ooxml/schemas/ISO-IEC29500-4_2016/dml-diagram.xsd",
          "type": "blob",
          "size": 51302
        },
        {
          "path": "plugins/document-suite/skills/pptx/ooxml/schemas/ISO-IEC29500-4_2016/dml-lockedCanvas.xsd",
          "type": "blob",
          "size": 624
        },
        {
          "path": "plugins/document-suite/skills/pptx/ooxml/schemas/ISO-IEC29500-4_2016/dml-main.xsd",
          "type": "blob",
          "size": 152039
        },
        {
          "path": "plugins/document-suite/skills/pptx/ooxml/schemas/ISO-IEC29500-4_2016/dml-picture.xsd",
          "type": "blob",
          "size": 1231
        },
        {
          "path": "plugins/document-suite/skills/pptx/ooxml/schemas/ISO-IEC29500-4_2016/dml-spreadsheetDrawing.xsd",
          "type": "blob",
          "size": 8862
        },
        {
          "path": "plugins/document-suite/skills/pptx/ooxml/schemas/ISO-IEC29500-4_2016/dml-wordprocessingDrawing.xsd",
          "type": "blob",
          "size": 14795
        },
        {
          "path": "plugins/document-suite/skills/pptx/ooxml/schemas/ISO-IEC29500-4_2016/pml.xsd",
          "type": "blob",
          "size": 83612
        },
        {
          "path": "plugins/document-suite/skills/pptx/ooxml/schemas/ISO-IEC29500-4_2016/shared-additionalCharacteristics.xsd",
          "type": "blob",
          "size": 1269
        },
        {
          "path": "plugins/document-suite/skills/pptx/ooxml/schemas/ISO-IEC29500-4_2016/shared-bibliography.xsd",
          "type": "blob",
          "size": 7328
        },
        {
          "path": "plugins/document-suite/skills/pptx/ooxml/schemas/ISO-IEC29500-4_2016/shared-commonSimpleTypes.xsd",
          "type": "blob",
          "size": 6382
        },
        {
          "path": "plugins/document-suite/skills/pptx/ooxml/schemas/ISO-IEC29500-4_2016/shared-customXmlDataProperties.xsd",
          "type": "blob",
          "size": 1248
        },
        {
          "path": "plugins/document-suite/skills/pptx/ooxml/schemas/ISO-IEC29500-4_2016/shared-customXmlSchemaProperties.xsd",
          "type": "blob",
          "size": 880
        },
        {
          "path": "plugins/document-suite/skills/pptx/ooxml/schemas/ISO-IEC29500-4_2016/shared-documentPropertiesCustom.xsd",
          "type": "blob",
          "size": 2608
        },
        {
          "path": "plugins/document-suite/skills/pptx/ooxml/schemas/ISO-IEC29500-4_2016/shared-documentPropertiesExtended.xsd",
          "type": "blob",
          "size": 3507
        },
        {
          "path": "plugins/document-suite/skills/pptx/ooxml/schemas/ISO-IEC29500-4_2016/shared-documentPropertiesVariantTypes.xsd",
          "type": "blob",
          "size": 7507
        },
        {
          "path": "plugins/document-suite/skills/pptx/ooxml/schemas/ISO-IEC29500-4_2016/shared-math.xsd",
          "type": "blob",
          "size": 23313
        },
        {
          "path": "plugins/document-suite/skills/pptx/ooxml/schemas/ISO-IEC29500-4_2016/shared-relationshipReference.xsd",
          "type": "blob",
          "size": 1367
        },
        {
          "path": "plugins/document-suite/skills/pptx/ooxml/schemas/ISO-IEC29500-4_2016/sml.xsd",
          "type": "blob",
          "size": 242277
        },
        {
          "path": "plugins/document-suite/skills/pptx/ooxml/schemas/ISO-IEC29500-4_2016/vml-main.xsd",
          "type": "blob",
          "size": 26148
        },
        {
          "path": "plugins/document-suite/skills/pptx/ooxml/schemas/ISO-IEC29500-4_2016/vml-officeDrawing.xsd",
          "type": "blob",
          "size": 25279
        },
        {
          "path": "plugins/document-suite/skills/pptx/ooxml/schemas/ISO-IEC29500-4_2016/vml-presentationDrawing.xsd",
          "type": "blob",
          "size": 535
        },
        {
          "path": "plugins/document-suite/skills/pptx/ooxml/schemas/ISO-IEC29500-4_2016/vml-spreadsheetDrawing.xsd",
          "type": "blob",
          "size": 5712
        },
        {
          "path": "plugins/document-suite/skills/pptx/ooxml/schemas/ISO-IEC29500-4_2016/vml-wordprocessingDrawing.xsd",
          "type": "blob",
          "size": 4010
        },
        {
          "path": "plugins/document-suite/skills/pptx/ooxml/schemas/ISO-IEC29500-4_2016/wml.xsd",
          "type": "blob",
          "size": 171367
        },
        {
          "path": "plugins/document-suite/skills/pptx/ooxml/schemas/ISO-IEC29500-4_2016/xml.xsd",
          "type": "blob",
          "size": 4646
        },
        {
          "path": "plugins/document-suite/skills/pptx/ooxml/schemas/ecma",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/document-suite/skills/pptx/ooxml/schemas/ecma/fouth-edition",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/document-suite/skills/pptx/ooxml/schemas/ecma/fouth-edition/opc-contentTypes.xsd",
          "type": "blob",
          "size": 1963
        },
        {
          "path": "plugins/document-suite/skills/pptx/ooxml/schemas/ecma/fouth-edition/opc-coreProperties.xsd",
          "type": "blob",
          "size": 2515
        },
        {
          "path": "plugins/document-suite/skills/pptx/ooxml/schemas/ecma/fouth-edition/opc-digSig.xsd",
          "type": "blob",
          "size": 2856
        },
        {
          "path": "plugins/document-suite/skills/pptx/ooxml/schemas/ecma/fouth-edition/opc-relationships.xsd",
          "type": "blob",
          "size": 1344
        },
        {
          "path": "plugins/document-suite/skills/pptx/ooxml/schemas/mce",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/document-suite/skills/pptx/ooxml/schemas/mce/mc.xsd",
          "type": "blob",
          "size": 3127
        },
        {
          "path": "plugins/document-suite/skills/pptx/ooxml/schemas/microsoft",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/document-suite/skills/pptx/ooxml/schemas/microsoft/wml-2010.xsd",
          "type": "blob",
          "size": 26549
        },
        {
          "path": "plugins/document-suite/skills/pptx/ooxml/schemas/microsoft/wml-2012.xsd",
          "type": "blob",
          "size": 3745
        },
        {
          "path": "plugins/document-suite/skills/pptx/ooxml/schemas/microsoft/wml-2018.xsd",
          "type": "blob",
          "size": 901
        },
        {
          "path": "plugins/document-suite/skills/pptx/ooxml/schemas/microsoft/wml-cex-2018.xsd",
          "type": "blob",
          "size": 1778
        },
        {
          "path": "plugins/document-suite/skills/pptx/ooxml/schemas/microsoft/wml-cid-2016.xsd",
          "type": "blob",
          "size": 1002
        },
        {
          "path": "plugins/document-suite/skills/pptx/ooxml/schemas/microsoft/wml-sdtdatahash-2020.xsd",
          "type": "blob",
          "size": 600
        },
        {
          "path": "plugins/document-suite/skills/pptx/ooxml/schemas/microsoft/wml-symex-2015.xsd",
          "type": "blob",
          "size": 745
        },
        {
          "path": "plugins/document-suite/skills/pptx/ooxml/scripts",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/document-suite/skills/pptx/ooxml/scripts/pack.py",
          "type": "blob",
          "size": 5596
        },
        {
          "path": "plugins/document-suite/skills/pptx/ooxml/scripts/unpack.py",
          "type": "blob",
          "size": 1037
        },
        {
          "path": "plugins/document-suite/skills/pptx/ooxml/scripts/validate.py",
          "type": "blob",
          "size": 1959
        },
        {
          "path": "plugins/document-suite/skills/pptx/ooxml/scripts/validation",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/document-suite/skills/pptx/ooxml/scripts/validation/__init__.py",
          "type": "blob",
          "size": 336
        },
        {
          "path": "plugins/document-suite/skills/pptx/ooxml/scripts/validation/base.py",
          "type": "blob",
          "size": 39892
        },
        {
          "path": "plugins/document-suite/skills/pptx/ooxml/scripts/validation/docx.py",
          "type": "blob",
          "size": 9996
        },
        {
          "path": "plugins/document-suite/skills/pptx/ooxml/scripts/validation/pptx.py",
          "type": "blob",
          "size": 12327
        },
        {
          "path": "plugins/document-suite/skills/pptx/ooxml/scripts/validation/redlining.py",
          "type": "blob",
          "size": 11179
        },
        {
          "path": "plugins/document-suite/skills/pptx/scripts",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/document-suite/skills/pptx/scripts/html2pptx.js",
          "type": "blob",
          "size": 37795
        },
        {
          "path": "plugins/document-suite/skills/pptx/scripts/inventory.py",
          "type": "blob",
          "size": 38126
        },
        {
          "path": "plugins/document-suite/skills/pptx/scripts/rearrange.py",
          "type": "blob",
          "size": 8514
        },
        {
          "path": "plugins/document-suite/skills/pptx/scripts/replace.py",
          "type": "blob",
          "size": 13594
        },
        {
          "path": "plugins/document-suite/skills/pptx/scripts/thumbnail.py",
          "type": "blob",
          "size": 15484
        },
        {
          "path": "plugins/document-suite/skills/xlsx",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/document-suite/skills/xlsx/LICENSE.txt",
          "type": "blob",
          "size": 1467
        },
        {
          "path": "plugins/document-suite/skills/xlsx/SKILL.md",
          "type": "blob",
          "size": 10632
        },
        {
          "path": "plugins/document-suite/skills/xlsx/recalc.py",
          "type": "blob",
          "size": 6408
        },
        {
          "path": "plugins/productivity-kit",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/productivity-kit/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/productivity-kit/.claude-plugin/marketplace.json",
          "type": "blob",
          "size": 940
        },
        {
          "path": "plugins/productivity-kit/README.md",
          "type": "blob",
          "size": 1537
        },
        {
          "path": "plugins/productivity-kit/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/productivity-kit/agents/research-assistant.md",
          "type": "blob",
          "size": 5536
        },
        {
          "path": "plugins/productivity-kit/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/productivity-kit/commands/git-configure.md",
          "type": "blob",
          "size": 588
        },
        {
          "path": "plugins/productivity-kit/commands/integrate-parallel-work.md",
          "type": "blob",
          "size": 559
        },
        {
          "path": "plugins/productivity-kit/commands/parallel-work.md",
          "type": "blob",
          "size": 609
        },
        {
          "path": "plugins/productivity-kit/commands/refactor-interactive.md",
          "type": "blob",
          "size": 1324
        },
        {
          "path": "plugins/productivity-kit/commands/tidy-docs.md",
          "type": "blob",
          "size": 739
        },
        {
          "path": "plugins/productivity-kit/commands/tidy-up.md",
          "type": "blob",
          "size": 609
        },
        {
          "path": "plugins/productivity-kit/commands/tmux-team-restart.md",
          "type": "blob",
          "size": 5446
        },
        {
          "path": "plugins/productivity-kit/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/productivity-kit/skills/coder-memory-recall",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/productivity-kit/skills/coder-memory-recall/SKILL.md",
          "type": "blob",
          "size": 5237
        },
        {
          "path": "plugins/productivity-kit/skills/coder-memory-store",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/productivity-kit/skills/coder-memory-store/SKILL.md",
          "type": "blob",
          "size": 8804
        },
        {
          "path": "plugins/productivity-kit/skills/coder-memory-store/episodic",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/productivity-kit/skills/coder-memory-store/episodic/user-interaction-failures.md",
          "type": "blob",
          "size": 1497
        },
        {
          "path": "plugins/productivity-kit/skills/coder-memory-store/procedural",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/productivity-kit/skills/coder-memory-store/procedural/progressive_testing_saves_time.md",
          "type": "blob",
          "size": 5268
        },
        {
          "path": "plugins/productivity-kit/skills/coder-memory-store/procedural/two-stage-config-validation.md",
          "type": "blob",
          "size": 3149
        },
        {
          "path": "plugins/productivity-kit/skills/coder-memory-store/semantic",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/productivity-kit/skills/coder-memory-store/semantic/agent-memory-architecture.md",
          "type": "blob",
          "size": 1754
        },
        {
          "path": "plugins/productivity-kit/skills/coder-memory-store/semantic/indicator_adaptivity_crypto.md",
          "type": "blob",
          "size": 3457
        },
        {
          "path": "plugins/productivity-kit/skills/coder-memory-store/semantic/metric-validation-patterns.md",
          "type": "blob",
          "size": 4480
        },
        {
          "path": "plugins/productivity-kit/skills/coder-memory-store/semantic/parameter_convergence_diagnostics.md",
          "type": "blob",
          "size": 7248
        },
        {
          "path": "plugins/productivity-kit/skills/coder-memory-store/semantic/research-transferability-validation.md",
          "type": "blob",
          "size": 9360
        },
        {
          "path": "plugins/productivity-kit/skills/coder-memory-store/semantic/robust_rate_primary_metric.md",
          "type": "blob",
          "size": 8447
        },
        {
          "path": "plugins/productivity-kit/skills/coder-memory-store/semantic/storage_log.txt",
          "type": "blob",
          "size": 9892
        },
        {
          "path": "plugins/productivity-kit/skills/coder-memory-store/semantic/trading-strategy-design-patterns.md",
          "type": "blob",
          "size": 10594
        },
        {
          "path": "plugins/productivity-kit/skills/quick-research",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/productivity-kit/skills/quick-research/SKILL.md",
          "type": "blob",
          "size": 8010
        },
        {
          "path": "plugins/productivity-kit/skills/quick-research/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/productivity-kit/skills/quick-research/references/architecture.md",
          "type": "blob",
          "size": 9841
        },
        {
          "path": "plugins/productivity-kit/skills/quick-research/references/prompts.md",
          "type": "blob",
          "size": 6475
        },
        {
          "path": "plugins/productivity-kit/skills/tmux-team-creator",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/productivity-kit/skills/tmux-team-creator/CLAUDE.md",
          "type": "blob",
          "size": 4995
        },
        {
          "path": "plugins/productivity-kit/skills/tmux-team-creator/SKILL.md",
          "type": "blob",
          "size": 36397
        },
        {
          "path": "plugins/productivity-kit/skills/tmux-team-creator/docs",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/productivity-kit/skills/tmux-team-creator/docs/research",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/productivity-kit/skills/tmux-team-creator/docs/research/Market_research_framework.md",
          "type": "blob",
          "size": 7891
        },
        {
          "path": "plugins/productivity-kit/skills/tmux-team-creator/docs/research/McKinsey_workflow.md",
          "type": "blob",
          "size": 10458
        },
        {
          "path": "plugins/productivity-kit/skills/tmux-team-creator/sample_team",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/productivity-kit/skills/tmux-team-creator/sample_team/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/productivity-kit/skills/tmux-team-creator/sample_team/commands/init-role.md",
          "type": "blob",
          "size": 1379
        },
        {
          "path": "plugins/productivity-kit/skills/tmux-team-creator/sample_team/game-dev-team",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/productivity-kit/skills/tmux-team-creator/sample_team/game-dev-team/WHITEBOARD.md",
          "type": "blob",
          "size": 1084
        },
        {
          "path": "plugins/productivity-kit/skills/tmux-team-creator/sample_team/game-dev-team/prompts",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/productivity-kit/skills/tmux-team-creator/sample_team/game-dev-team/prompts/AR_PROMPT.md",
          "type": "blob",
          "size": 5976
        },
        {
          "path": "plugins/productivity-kit/skills/tmux-team-creator/sample_team/game-dev-team/prompts/DS_PROMPT.md",
          "type": "blob",
          "size": 4613
        },
        {
          "path": "plugins/productivity-kit/skills/tmux-team-creator/sample_team/game-dev-team/prompts/DV_PROMPT.md",
          "type": "blob",
          "size": 5699
        },
        {
          "path": "plugins/productivity-kit/skills/tmux-team-creator/sample_team/game-dev-team/prompts/QA_PROMPT.md",
          "type": "blob",
          "size": 7028
        },
        {
          "path": "plugins/productivity-kit/skills/tmux-team-creator/sample_team/game-dev-team/prompts/SM_PROMPT.md",
          "type": "blob",
          "size": 6840
        },
        {
          "path": "plugins/productivity-kit/skills/tmux-team-creator/sample_team/game-dev-team/setup-team.sh",
          "type": "blob",
          "size": 5619
        },
        {
          "path": "plugins/productivity-kit/skills/tmux-team-creator/sample_team/game-dev-team/sm",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/productivity-kit/skills/tmux-team-creator/sample_team/game-dev-team/sm/IMPROVEMENT_BACKLOG.md",
          "type": "blob",
          "size": 843
        },
        {
          "path": "plugins/productivity-kit/skills/tmux-team-creator/sample_team/game-dev-team/sm/RETROSPECTIVE_LOG.md",
          "type": "blob",
          "size": 957
        },
        {
          "path": "plugins/productivity-kit/skills/tmux-team-creator/sample_team/game-dev-team/tmux_team_overview.md",
          "type": "blob",
          "size": 4080
        },
        {
          "path": "plugins/productivity-kit/skills/tmux-team-creator/sample_team/hooks",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/productivity-kit/skills/tmux-team-creator/sample_team/hooks/post_compact_tmux_reminder.sh",
          "type": "blob",
          "size": 1586
        },
        {
          "path": "plugins/productivity-kit/skills/tmux-team-creator/sample_team/mckinsey-research-team",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/productivity-kit/skills/tmux-team-creator/sample_team/mckinsey-research-team/WHITEBOARD.md",
          "type": "blob",
          "size": 1414
        },
        {
          "path": "plugins/productivity-kit/skills/tmux-team-creator/sample_team/mckinsey-research-team/em",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/productivity-kit/skills/tmux-team-creator/sample_team/mckinsey-research-team/em/ACTION_ITEMS.md",
          "type": "blob",
          "size": 1711
        },
        {
          "path": "plugins/productivity-kit/skills/tmux-team-creator/sample_team/mckinsey-research-team/em/IMPROVEMENT_BACKLOG.md",
          "type": "blob",
          "size": 3112
        },
        {
          "path": "plugins/productivity-kit/skills/tmux-team-creator/sample_team/mckinsey-research-team/em/RETROSPECTIVE_LOG.md",
          "type": "blob",
          "size": 1559
        },
        {
          "path": "plugins/productivity-kit/skills/tmux-team-creator/sample_team/mckinsey-research-team/prompts",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/productivity-kit/skills/tmux-team-creator/sample_team/mckinsey-research-team/prompts/DA_PROMPT.md",
          "type": "blob",
          "size": 7417
        },
        {
          "path": "plugins/productivity-kit/skills/tmux-team-creator/sample_team/mckinsey-research-team/prompts/EM_PROMPT.md",
          "type": "blob",
          "size": 9111
        },
        {
          "path": "plugins/productivity-kit/skills/tmux-team-creator/sample_team/mckinsey-research-team/prompts/PR_PROMPT.md",
          "type": "blob",
          "size": 6316
        },
        {
          "path": "plugins/productivity-kit/skills/tmux-team-creator/sample_team/mckinsey-research-team/prompts/QR_PROMPT.md",
          "type": "blob",
          "size": 7130
        },
        {
          "path": "plugins/productivity-kit/skills/tmux-team-creator/sample_team/mckinsey-research-team/prompts/RL_PROMPT.md",
          "type": "blob",
          "size": 6495
        },
        {
          "path": "plugins/productivity-kit/skills/tmux-team-creator/sample_team/mckinsey-research-team/prompts/SR_PROMPT.md",
          "type": "blob",
          "size": 7423
        },
        {
          "path": "plugins/productivity-kit/skills/tmux-team-creator/sample_team/mckinsey-research-team/setup-team.sh",
          "type": "blob",
          "size": 7044
        },
        {
          "path": "plugins/productivity-kit/skills/tmux-team-creator/sample_team/mckinsey-research-team/workflow.md",
          "type": "blob",
          "size": 13741
        },
        {
          "path": "plugins/productivity-kit/skills/tmux-team-creator/sample_team/pg-insights-team",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/productivity-kit/skills/tmux-team-creator/sample_team/pg-insights-team/WHITEBOARD.md",
          "type": "blob",
          "size": 1002
        },
        {
          "path": "plugins/productivity-kit/skills/tmux-team-creator/sample_team/pg-insights-team/im",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/productivity-kit/skills/tmux-team-creator/sample_team/pg-insights-team/im/ACTION_ITEMS.md",
          "type": "blob",
          "size": 1021
        },
        {
          "path": "plugins/productivity-kit/skills/tmux-team-creator/sample_team/pg-insights-team/im/IMPROVEMENT_BACKLOG.md",
          "type": "blob",
          "size": 1039
        },
        {
          "path": "plugins/productivity-kit/skills/tmux-team-creator/sample_team/pg-insights-team/im/RETROSPECTIVE_LOG.md",
          "type": "blob",
          "size": 569
        },
        {
          "path": "plugins/productivity-kit/skills/tmux-team-creator/sample_team/pg-insights-team/prompts",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/productivity-kit/skills/tmux-team-creator/sample_team/pg-insights-team/prompts/IA_PROMPT.md",
          "type": "blob",
          "size": 5418
        },
        {
          "path": "plugins/productivity-kit/skills/tmux-team-creator/sample_team/pg-insights-team/prompts/IM_PROMPT.md",
          "type": "blob",
          "size": 5718
        },
        {
          "path": "plugins/productivity-kit/skills/tmux-team-creator/sample_team/pg-insights-team/prompts/MR_PROMPT.md",
          "type": "blob",
          "size": 5274
        },
        {
          "path": "plugins/productivity-kit/skills/tmux-team-creator/sample_team/pg-insights-team/prompts/QR_PROMPT.md",
          "type": "blob",
          "size": 6635
        },
        {
          "path": "plugins/productivity-kit/skills/tmux-team-creator/sample_team/pg-insights-team/prompts/SL_PROMPT.md",
          "type": "blob",
          "size": 6180
        },
        {
          "path": "plugins/productivity-kit/skills/tmux-team-creator/sample_team/pg-insights-team/setup-team.sh",
          "type": "blob",
          "size": 6460
        },
        {
          "path": "plugins/productivity-kit/skills/tmux-team-creator/sample_team/pg-insights-team/workflow.md",
          "type": "blob",
          "size": 12826
        },
        {
          "path": "plugins/productivity-kit/skills/tmux-team-creator/sample_team/scrum-minimal-team",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/productivity-kit/skills/tmux-team-creator/sample_team/scrum-minimal-team/PRODUCT_BACKLOG.md",
          "type": "blob",
          "size": 435
        },
        {
          "path": "plugins/productivity-kit/skills/tmux-team-creator/sample_team/scrum-minimal-team/SPRINT_BACKLOG.md",
          "type": "blob",
          "size": 421
        },
        {
          "path": "plugins/productivity-kit/skills/tmux-team-creator/sample_team/scrum-minimal-team/WHITEBOARD.md",
          "type": "blob",
          "size": 501
        },
        {
          "path": "plugins/productivity-kit/skills/tmux-team-creator/sample_team/scrum-minimal-team/prompts",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/productivity-kit/skills/tmux-team-creator/sample_team/scrum-minimal-team/prompts/EX_PROMPT.md",
          "type": "blob",
          "size": 2979
        },
        {
          "path": "plugins/productivity-kit/skills/tmux-team-creator/sample_team/scrum-minimal-team/prompts/PO_PROMPT.md",
          "type": "blob",
          "size": 2463
        },
        {
          "path": "plugins/productivity-kit/skills/tmux-team-creator/sample_team/scrum-minimal-team/prompts/SM_PROMPT.md",
          "type": "blob",
          "size": 2407
        },
        {
          "path": "plugins/productivity-kit/skills/tmux-team-creator/sample_team/scrum-minimal-team/setup-team.sh",
          "type": "blob",
          "size": 4629
        },
        {
          "path": "plugins/productivity-kit/skills/tmux-team-creator/sample_team/scrum-minimal-team/sm",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/productivity-kit/skills/tmux-team-creator/sample_team/scrum-minimal-team/sm/IMPROVEMENT_BACKLOG.md",
          "type": "blob",
          "size": 464
        },
        {
          "path": "plugins/productivity-kit/skills/tmux-team-creator/sample_team/scrum-minimal-team/sm/RETROSPECTIVE_LOG.md",
          "type": "blob",
          "size": 287
        },
        {
          "path": "plugins/productivity-kit/skills/tmux-team-creator/sample_team/scrum-minimal-team/workflow.md",
          "type": "blob",
          "size": 2355
        },
        {
          "path": "plugins/productivity-kit/skills/tmux-team-creator/sample_team/scrum-team",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/productivity-kit/skills/tmux-team-creator/sample_team/scrum-team/PRODUCT_BACKLOG.md",
          "type": "blob",
          "size": 898
        },
        {
          "path": "plugins/productivity-kit/skills/tmux-team-creator/sample_team/scrum-team/SPRINT_BACKLOG.md",
          "type": "blob",
          "size": 1030
        },
        {
          "path": "plugins/productivity-kit/skills/tmux-team-creator/sample_team/scrum-team/WHITEBOARD.md",
          "type": "blob",
          "size": 929
        },
        {
          "path": "plugins/productivity-kit/skills/tmux-team-creator/sample_team/scrum-team/prompts",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/productivity-kit/skills/tmux-team-creator/sample_team/scrum-team/prompts/BE_PROMPT.md",
          "type": "blob",
          "size": 4811
        },
        {
          "path": "plugins/productivity-kit/skills/tmux-team-creator/sample_team/scrum-team/prompts/FE_PROMPT.md",
          "type": "blob",
          "size": 5297
        },
        {
          "path": "plugins/productivity-kit/skills/tmux-team-creator/sample_team/scrum-team/prompts/PO_PROMPT.md",
          "type": "blob",
          "size": 6866
        },
        {
          "path": "plugins/productivity-kit/skills/tmux-team-creator/sample_team/scrum-team/prompts/QA_PROMPT.md",
          "type": "blob",
          "size": 5068
        },
        {
          "path": "plugins/productivity-kit/skills/tmux-team-creator/sample_team/scrum-team/prompts/SM_PROMPT.md",
          "type": "blob",
          "size": 11449
        },
        {
          "path": "plugins/productivity-kit/skills/tmux-team-creator/sample_team/scrum-team/prompts/TL_PROMPT.md",
          "type": "blob",
          "size": 6368
        },
        {
          "path": "plugins/productivity-kit/skills/tmux-team-creator/sample_team/scrum-team/setup-team.sh",
          "type": "blob",
          "size": 7236
        },
        {
          "path": "plugins/productivity-kit/skills/tmux-team-creator/sample_team/scrum-team/sm",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/productivity-kit/skills/tmux-team-creator/sample_team/scrum-team/sm/ACTION_ITEMS.md",
          "type": "blob",
          "size": 899
        },
        {
          "path": "plugins/productivity-kit/skills/tmux-team-creator/sample_team/scrum-team/sm/IMPROVEMENT_BACKLOG.md",
          "type": "blob",
          "size": 3161
        },
        {
          "path": "plugins/productivity-kit/skills/tmux-team-creator/sample_team/scrum-team/sm/RETROSPECTIVE_LOG.md",
          "type": "blob",
          "size": 1068
        },
        {
          "path": "plugins/productivity-kit/skills/tmux-team-creator/sample_team/scrum-team/workflow.md",
          "type": "blob",
          "size": 15538
        },
        {
          "path": "plugins/productivity-kit/skills/tmux-team-creator/sample_team/settings.json",
          "type": "blob",
          "size": 264
        },
        {
          "path": "plugins/productivity-kit/skills/tmux-team-creator/templates",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/productivity-kit/skills/tmux-team-creator/templates/SCHEMA.md",
          "type": "blob",
          "size": 2617
        },
        {
          "path": "repomix-output.xml",
          "type": "blob",
          "size": 3823231
        }
      ],
      "marketplace": {
        "name": "synthetic-claude",
        "version": null,
        "description": null,
        "owner_info": {
          "name": "hongbietcode"
        },
        "keywords": [],
        "plugins": [
          {
            "name": "debate-system",
            "description": "Multi-agent debate system with 3-phase workflow and deep mode for convergence feedback",
            "source": "./plugins/debate-system",
            "category": "workflows",
            "version": "1.0.0",
            "author": null,
            "install_commands": [
              "/plugin marketplace add hongbietcode/synthetic-claude",
              "/plugin install debate-system@synthetic-claude"
            ],
            "signals": {
              "stars": 1,
              "forks": 0,
              "pushed_at": "2026-01-07T17:25:07Z",
              "created_at": "2025-12-28T07:34:15Z",
              "license": null
            },
            "commands": [
              {
                "name": "/debate",
                "description": null,
                "path": "plugins/debate-system/commands/debate.md",
                "frontmatter": null,
                "content": "---\ndescription: Multi-agent debate on any topic. Use --deep for feedback loop.\nargument-hint: [topic] [--deep]\n---\n\nYou are a Debate Orchestrator coordinating a multi-agent debate.\n\n## Topic & Mode\n<topic>$ARGUMENTS</topic>\n\n**Mode Detection:**\n- If `$ARGUMENTS` contains `--deep` → Deep mode (with feedback loop)\n- Otherwise → Standard mode (3-phase only)\n\nExtract the actual topic by removing `--deep` flag if present.\n\n## Core Principles\nHonor **YAGNI**, **KISS**, and **DRY**. Be brutally honest about trade-offs.\n\n## Model Configuration\nUse `model: haiku` for all agent Task calls for cost efficiency.\n\n## Workflow\n\n### Standard Mode (default)\n```\nPhase 1 (Parallel) → Phase 2 (Parallel) → Phase 3\n```\n\n### Deep Mode (--deep flag)\n```\nPhase 1 → Phase 2 → Convergence Check ─┬─► (converged) → Phase 3\n                                       └─► (not converged) → Phase 2b → Phase 3\n```\n\n---\n\n## Prompt Isolation\n\nAll agent prompts MUST include this preamble to prevent context confusion:\n\n```\nCONTEXT ISOLATION: This is a standalone debate exercise. IGNORE any repository, codebase, or file context. Focus ONLY on the debate topic below. Do NOT ask clarifying questions - just produce the requested analysis.\n```\n\n---\n\n## Phase 1: Individual Analysis (Parallel)\n\nSpawn 3 agents in parallel using Task tool:\n\n```\nTask(subagent_type=\"general-purpose\", model=\"haiku\", description=\"Researcher analyzes topic\", prompt=\"\nCONTEXT ISOLATION: This is a standalone debate exercise. IGNORE any repository, codebase, or file context. Focus ONLY on the debate topic below. Do NOT ask clarifying questions - just produce the requested analysis.\n\nAs Researcher, analyze this topic: {topic}\n\nFocus on:\n- Exploring possibilities and alternatives\n- Gathering evidence and examples\n- Identifying key considerations\n- Flagging evidence gaps and assumptions\n\nCONSTRAINTS:\n- Must list evidence gaps\n- Must include falsifiability criteria\n\nOutput format:\n## Research Findings\n### Key Possibilities\n### Supporting Evidence\n### Evidence Gaps\n### Open Questions\n\")\n```\n\n```\nTask(subagent_type=\"general-purpose\", model=\"haiku\", description=\"Critic analyzes topic\", prompt=\"\nCONTEXT ISOLATION: This is a standalone debate exercise. IGNORE any repository, codebase, or file context. Focus ONLY on the debate topic below. Do NOT ask clarifying questions - just produce the requested analysis.\n\nAs Critic, analyze this topic: {topic}\n\nFocus on:\n- Challenging assumptions\n- Identifying risks and weaknesses\n- Pointing out potential problems\n- Proposing mitigations for each concern\n\nCONSTRAINTS:\n- Must propose mitigation for each critique\n- Must estimate likelihood + impact for risks\n\nOutput format:\n## Critical Analysis\n### Key Concerns (with mitigations)\n### Assumptions to Challenge\n### Risk Assessment (likelihood/impact)\n\")\n```\n\n```\nTask(subagent_type=\"general-purpose\", model=\"haiku\", description=\"Synthesizer analyzes topic\", prompt=\"\nCONTEXT ISOLATION: This is a standalone debate exercise. IGNORE any repository, codebase, or file context. Focus ONLY on the debate topic below. Do NOT ask clarifying questions - just produce the requested analysis.\n\nAs Synthesizer, analyze this topic: {topic}\n\nFocus on:\n- Finding patterns across perspectives\n- Identifying integration opportunities\n- Proposing frameworks (not decisions)\n\nCONSTRAINTS:\n- Must NOT declare single best option\n- Must acknowledge trade-offs\n\nOutput format:\n## Synthesis Perspective\n### Pattern Recognition\n### Integration Opportunities\n### Framework Proposal\n### Trade-offs\n\")\n```\n\n---\n\n## Phase 2: Discussion (Parallel)\n\n**CRITICAL: This phase MUST be executed. Do NOT skip.**\n\nShare Phase 1 responses with each agent. Each must:\n1. Reference at least 2 specific claims from other agents\n2. Acknowledge at least 1 valid point they initially missed\n3. State their KEY RECOMMENDATION clearly\n\n```\nTask(subagent_type=\"general-purpose\", model=\"haiku\", description=\"Researcher reviews perspectives\", prompt=\"\nCONTEXT ISOLATION: This is a standalone debate exercise. IGNORE any repository, codebase, or file context. Focus ONLY on the debate below. Do NOT ask clarifying questions - just produce the requested analysis.\n\nAs Researcher, review these perspectives and refine your position.\n\n## CRITIC'S ANALYSIS:\n{critic_phase1_response}\n\n## SYNTHESIZER'S ANALYSIS:\n{synthesizer_phase1_response}\n\nREQUIREMENTS:\n- Reference at least 2 specific claims from Critic or Synthesizer\n- Acknowledge at least 1 valid point you initially missed\n- State your KEY RECOMMENDATION clearly at the end\n\nOutput format:\n## Refined Research Position\n### Points I Agree With (cite specific claims)\n### Points I Challenge (cite specific claims)\n### Updated Position\n### KEY RECOMMENDATION: {one-sentence recommendation}\n\")\n```\n\n```\nTask(subagent_type=\"general-purpose\", model=\"haiku\", description=\"Critic reviews perspectives\", prompt=\"\nCONTEXT ISOLATION: This is a standalone debate exercise. IGNORE any repository, codebase, or file context. Focus ONLY on the debate below. Do NOT ask clarifying questions - just produce the requested analysis.\n\nAs Critic, review these perspectives and refine your position.\n\n## RESEARCHER'S FINDINGS:\n{researcher_phase1_response}\n\n## SYNTHESIZER'S ANALYSIS:\n{synthesizer_phase1_response}\n\nREQUIREMENTS:\n- Reference at least 2 specific claims from Researcher or Synthesizer\n- Acknowledge at least 1 valid point you initially missed\n- State your KEY RECOMMENDATION clearly at the end\n\nOutput format:\n## Refined Critical Position\n### Points I Agree With (cite specific claims)\n### Points I Challenge (cite specific claims)\n### Updated Position\n### KEY RECOMMENDATION: {one-sentence recommendation}\n\")\n```\n\n```\nTask(subagent_type=\"general-purpose\", model=\"haiku\", description=\"Synthesizer reviews perspectives\", prompt=\"\nCONTEXT ISOLATION: This is a standalone debate exercise. IGNORE any repository, codebase, or file context. Focus ONLY on the debate below. Do NOT ask clarifying questions - just produce the requested analysis.\n\nAs Synthesizer, review these perspectives and refine your position.\n\n## RESEARCHER'S FINDINGS:\n{researcher_phase1_response}\n\n## CRITIC'S ANALYSIS:\n{critic_phase1_response}\n\nREQUIREMENTS:\n- Reference at least 2 specific claims from Researcher or Critic\n- Acknowledge at least 1 valid point you initially missed\n- State your KEY RECOMMENDATION clearly at the end\n\nOutput format:\n## Refined Synthesis Position\n### Points I Agree With (cite specific claims)\n### Points I Challenge (cite specific claims)\n### Updated Position\n### KEY RECOMMENDATION: {one-sentence recommendation}\n\")\n```\n\n---\n\n## Deep Mode Only: Convergence Check & Phase 2b\n\n**Skip this section if NOT in deep mode (no --deep flag).**\n\n### Convergence Check\n\nAfter Phase 2, evaluate convergence by comparing the 3 KEY RECOMMENDATIONs:\n\n**Convergence Criteria (meet ANY):**\n1. All 3 agents recommend the same general direction\n2. At least 2 agents agree AND the third acknowledges as valid\n3. All agents agree on the decision framework\n\n**Convergence NOT met if:**\n1. Agents recommend fundamentally opposing directions\n2. Key trade-offs still contested without resolution\n3. New concerns emerged that weren't addressed\n\n**Decision:**\n- If converged → Proceed to Phase 3\n- If NOT converged → Execute Phase 2b\n\n### Phase 2b: Feedback Loop (Only if NOT converged)\n\nFocus specifically on the divergence points. Each agent must:\n1. Address the specific disagreement directly\n2. Either concede OR provide stronger justification\n3. Propose a path forward\n\n```\nTask(subagent_type=\"general-purpose\", model=\"haiku\", description=\"Researcher addresses divergence\", prompt=\"\nCONTEXT ISOLATION: This is a standalone debate exercise. IGNORE any repository, codebase, or file context. Focus ONLY on the debate below. Do NOT ask clarifying questions - just produce the requested analysis.\n\nAs Researcher, the agents have NOT converged on a recommendation.\n\n## DIVERGENCE SUMMARY:\n{summary_of_disagreements}\n\n## OTHER AGENTS' RECOMMENDATIONS:\n- Critic: {critic_recommendation}\n- Synthesizer: {synthesizer_recommendation}\n\nYour previous recommendation: {researcher_recommendation}\n\nREQUIREMENTS:\n- Address the specific disagreement directly\n- Either CONCEDE to others' points OR provide STRONGER justification\n- Propose a path forward that could satisfy all perspectives\n\nOutput format:\n## Addressing Divergence\n### My Response to Disagreement\n### Concessions (if any)\n### Stronger Justification (if maintaining position)\n### Proposed Path Forward\n\")\n```\n\n```\nTask(subagent_type=\"general-purpose\", model=\"haiku\", description=\"Critic addresses divergence\", prompt=\"\nCONTEXT ISOLATION: This is a standalone debate exercise. IGNORE any repository, codebase, or file context. Focus ONLY on the debate below. Do NOT ask clarifying questions - just produce the requested analysis.\n\nAs Critic, the agents have NOT converged on a recommendation.\n\n## DIVERGENCE SUMMARY:\n{summary_of_disagreements}\n\n## OTHER AGENTS' RECOMMENDATIONS:\n- Researcher: {researcher_recommendation}\n- Synthesizer: {synthesizer_recommendation}\n\nYour previous recommendation: {critic_recommendation}\n\nREQUIREMENTS:\n- Address the specific disagreement directly\n- Either CONCEDE to others' points OR provide STRONGER justification\n- Propose a path forward that could satisfy all perspectives\n\nOutput format:\n## Addressing Divergence\n### My Response to Disagreement\n### Concessions (if any)\n### Stronger Justification (if maintaining position)\n### Proposed Path Forward\n\")\n```\n\n```\nTask(subagent_type=\"general-purpose\", model=\"haiku\", description=\"Synthesizer addresses divergence\", prompt=\"\nCONTEXT ISOLATION: This is a standalone debate exercise. IGNORE any repository, codebase, or file context. Focus ONLY on the debate below. Do NOT ask clarifying questions - just produce the requested analysis.\n\nAs Synthesizer, the agents have NOT converged on a recommendation.\n\n## DIVERGENCE SUMMARY:\n{summary_of_disagreements}\n\n## OTHER AGENTS' RECOMMENDATIONS:\n- Researcher: {researcher_recommendation}\n- Critic: {critic_recommendation}\n\nYour previous recommendation: {synthesizer_recommendation}\n\nREQUIREMENTS:\n- Address the specific disagreement directly\n- Either CONCEDE to others' points OR provide STRONGER justification\n- Propose an INTEGRATED path forward\n\nOutput format:\n## Addressing Divergence\n### My Response to Disagreement\n### Concessions (if any)\n### Integrated Path Forward\n\")\n```\n\n---\n\n## Phase 3: Synthesis\n\nConsolidate all perspectives into final recommendation:\n- Key insights from each agent\n- Points of agreement\n- Unresolved tensions (do NOT force consensus)\n- Convergence status (if deep mode)\n- Recommended decision framework (not decision)\n- Next steps\n\n## Output Format\n\n### Standard Mode\n```markdown\n## Debate Summary: {topic}\n\n### Individual Perspectives\n**Researcher**: {key findings}\n**Critic**: {key concerns}\n**Synthesizer**: {key patterns}\n\n### Discussion Highlights\n{major agreements and disagreements with specific references}\n\n### Final Synthesis\n**Consensus**: {what all agree on}\n**Tensions**: {unresolved disagreements - be explicit}\n**Decision Framework**: {how to decide, not what to decide}\n\n### Next Steps\n- {actionable items}\n```\n\n### Deep Mode\n```markdown\n## Debate Summary: {topic}\n\n### Individual Perspectives\n**Researcher**: {key findings}\n**Critic**: {key concerns}\n**Synthesizer**: {key patterns}\n\n### Discussion Highlights\n{major agreements and disagreements with specific references}\n\n### Convergence Status\n**Rounds**: {1 or 2}\n**Status**: {Converged | Partially Converged | Divergent}\n**Key Agreement**: {what agents aligned on}\n**Remaining Tension**: {what still differs}\n\n### Final Synthesis\n**Consensus**: {what all agree on}\n**Tensions**: {unresolved disagreements - be explicit}\n**Decision Framework**: {how to decide, not what to decide}\n\n### Next Steps\n- {actionable items}\n```\n\n## Error Handling\n\n- If an agent Task fails: note failure and continue with available responses\n- If Phase 2 validation fails: document which requirements were not met\n- If convergence unclear (deep mode): default to executing Phase 2b\n- Max 2 discussion rounds in deep mode - no infinite loops\n\n## Report Output\n\nSave debate report using naming pattern from `## Naming` section in injected context.\n\n**IMPORTANT:** Execute all required phases. Do not skip Discussion phase.\n"
              },
              {
                "name": "/discuss",
                "description": null,
                "path": "plugins/debate-system/commands/discuss.md",
                "frontmatter": null,
                "content": "# Quick Discuss Command\n\nRapid discussion about $ARGUMENTS with critical analysis.\n\n## Process\n1. **Issue**: What's the problem?\n2. **Views**: 3-4 perspectives  \n3. **Counter**: Challenge each view\n4. **Gaps**: What's missing?\n\n## Guidelines\n- NO code changes - discuss only\n- Don't just agree - challenge ideas\n\nFast critical exploration."
              },
              {
                "name": "/quick-brainstorm",
                "description": null,
                "path": "plugins/debate-system/commands/quick-brainstorm.md",
                "frontmatter": null,
                "content": "# Quick Brainstorm Command\n\nBrainstorm ideas for $ARGUMENTS, then counter-argue and find gaps.\n\n## Process\n1. **Generate**: 5-6 quick ideas/approaches\n2. **Challenge**: Counter-argument for each idea \n3. **Gaps**: What's missing or unconsidered?\n\n## Output\n- Ideas with their counter-arguments\n- Key blind spots identified\n- Strongest options after critique\n\nFast ideation with built-in skepticism.\nIMPORTANT: NO code modifications - discussion only"
              },
              {
                "name": "/think-hard",
                "description": null,
                "path": "plugins/debate-system/commands/think-hard.md",
                "frontmatter": null,
                "content": "THINK HARD about: $ARGUMENTS\n\n## Task\nChallenge my assumptions. Find what I'm overlooking. Don't follow my implied solution - propose better alternatives. Be critical, not agreeable."
              }
            ],
            "skills": [
              {
                "name": "debate-workflow",
                "description": "Multi-agent debate with 3-phase workflow. Optional --deep mode for feedback loop.",
                "path": "plugins/debate-system/skills/debate-workflow/SKILL.md",
                "frontmatter": {
                  "name": "debate-workflow",
                  "description": "Multi-agent debate with 3-phase workflow. Optional --deep mode for feedback loop.",
                  "license": "MIT"
                },
                "content": "# Debate Workflow\n\nMulti-agent debate system with 3-phase workflow. Optional deep mode with convergence-based feedback loop.\n\n## When to Use\n\nActivate this skill when:\n- User needs multiple perspectives on a decision\n- Complex tradeoffs require structured analysis\n- Brainstorming needs systematic synthesis\n- User invokes `/debate` command\n\n## Core Concepts\n\n### Standard Mode (default)\n```\nPhase 1 (Parallel) → Phase 2 (Parallel) → Phase 3\n```\n\n### Deep Mode (--deep flag)\n```\nPhase 1 → Phase 2 → Convergence Check ─┬─► (converged) → Phase 3\n                                       └─► (not converged) → Phase 2b → Phase 3\n```\n\n**Usage:**\n- `/debate monolith vs microservices` → Standard 3-phase\n- `/debate monolith vs microservices --deep` → With feedback loop\n\n### Agent Roles\n\n| Agent | Focus | Personality |\n|-------|-------|-------------|\n| Researcher | Evidence, possibilities | Curious, thorough |\n| Critic | Risks, weaknesses | Skeptical, constructive |\n| Synthesizer | Patterns, integration | Balanced, practical |\n\n## Deep Mode: Convergence Detection\n\n**Only applies when using `--deep` flag.**\n\n### How It Works\n\nAfter Phase 2, compare the 3 KEY RECOMMENDATIONs from each agent.\n\n### Convergence Criteria (meet ANY)\n\n1. All 3 agents recommend same general direction\n2. 2 agents agree AND third acknowledges as valid\n3. All agree on decision framework\n\n### Convergence NOT Met If\n\n1. Agents recommend fundamentally opposing directions\n2. Key trade-offs still contested without resolution\n3. New concerns emerged that weren't addressed\n\n### Decision Flow\n\n| Condition | Action |\n|-----------|--------|\n| Converged | Proceed to Phase 3 |\n| Not converged | Execute Phase 2b (1 additional round) |\n| Max rounds reached | Proceed to Phase 3, note \"Divergent\" status |\n\n## Deep Mode: Feedback Loop (Phase 2b)\n\nTriggered only when convergence NOT met in deep mode. Each agent must:\n\n1. Address specific disagreement directly\n2. Either CONCEDE or provide STRONGER justification\n3. Propose path forward\n\n\n## Behavioral Contracts\n\nEach agent has constraints on what they MUST NOT do:\n\n| Agent | MUST NOT |\n|-------|----------|\n| Researcher | Conclude without evidence gaps; present speculation as fact |\n| Critic | Critique without mitigation; skip likelihood/impact estimates |\n| Synthesizer | Declare single best option; hide disagreements; force consensus |\n\nThese contracts enforce genuine perspective diversity beyond stylistic variation.\n\n## Phase 2 Validation\n\nBefore Phase 3, verify each agent:\n- [ ] Referenced at least 2 specific claims from other agents\n- [ ] Acknowledged at least 1 valid point they initially missed\n- [ ] Stated a KEY RECOMMENDATION\n- [ ] (Deep mode only) Convergence check was performed\n\nIf validation fails: document in output, do not retry silently.\n\n## Error Handling\n\n| Scenario | Action |\n|----------|--------|\n| Agent Task fails | Note failure, continue with available responses |\n| Phase 2 validation fails | Document which requirements not met |\n| Agent doesn't follow format | Use available content, note deviation |\n| Convergence unclear | Default to Phase 2b (err on thoroughness) |\n| Max rounds reached | Proceed to Phase 3, mark as \"Divergent\" |\n\n## Prompt Isolation\n\nAll agent prompts MUST include this preamble to prevent context confusion:\n\n```\nCONTEXT ISOLATION: This is a standalone debate exercise. IGNORE any repository, codebase, or file context. Focus ONLY on the debate topic below. Do NOT ask clarifying questions - just produce the requested analysis.\n```\n\nThis prevents general-purpose subagents from getting distracted by repository context.\n\n## Best Practices\n\n- Include CONTEXT ISOLATION preamble in all agent prompts\n- Discussion phase MUST directly reference others' points (mandatory citations)\n- Synthesis should acknowledge disagreements, not force consensus\n- Include actionable next steps in final output\n- Recommend decision frameworks, not decisions\n- Max 2 discussion rounds (Phase 2 + Phase 2b) - no infinite loops\n\n## Model Configuration\n\n**Decision**: Use `model: haiku` for all agent Task calls.\n\n**Rationale**:\n- Cost efficiency (agent files specify haiku)\n- Sufficient for structured debate format\n\n**Override**: For complex topics requiring deeper analysis, orchestrator may use `model: sonnet` for Phase 3 synthesis only.\n\n## Execution\n\n- Use Task tool for parallel execution (faster)\n- Feedback loop only triggered when agents diverge\n\n## Output Template\n\n```markdown\n## Debate: {topic}\n\n### Phase 1: Individual Perspectives\n\n**Researcher**: {summary}\n**Critic**: {summary}\n**Synthesizer**: {summary}\n\n### Phase 2: Discussion\n\n{key exchanges and refinements}\n\n### Convergence Status\n\n**Rounds**: {1 or 2}\n**Status**: {Converged | Partially Converged | Divergent}\n**Key Agreement**: {what agents aligned on}\n**Remaining Tension**: {what still differs}\n\n### Phase 3: Final Synthesis\n\n**Consensus**: {what all agree on}\n**Tensions**: {unresolved disagreements}\n**Decision Framework**: {how to decide, not what to decide}\n\n### Next Steps\n- {action item 1}\n- {action item 2}\n```"
              }
            ]
          },
          {
            "name": "document-suite",
            "description": "Document processing skills for PDF, DOCX, PPTX, and XLSX files",
            "source": "./plugins/document-suite",
            "category": "documents",
            "version": "1.0.0",
            "author": null,
            "install_commands": [
              "/plugin marketplace add hongbietcode/synthetic-claude",
              "/plugin install document-suite@synthetic-claude"
            ],
            "signals": {
              "stars": 1,
              "forks": 0,
              "pushed_at": "2026-01-07T17:25:07Z",
              "created_at": "2025-12-28T07:34:15Z",
              "license": null
            },
            "commands": [],
            "skills": [
              {
                "name": "docx",
                "description": "Comprehensive document creation, editing, and analysis with support for tracked changes, comments, formatting preservation, and text extraction. When Claude needs to work with professional documents (.docx files) for: (1) Creating new documents, (2) Modifying or editing content, (3) Working with tracked changes, (4) Adding comments, or any other document tasks",
                "path": "plugins/document-suite/skills/docx/SKILL.md",
                "frontmatter": {
                  "name": "docx",
                  "description": "Comprehensive document creation, editing, and analysis with support for tracked changes, comments, formatting preservation, and text extraction. When Claude needs to work with professional documents (.docx files) for: (1) Creating new documents, (2) Modifying or editing content, (3) Working with tracked changes, (4) Adding comments, or any other document tasks",
                  "license": "Proprietary. LICENSE.txt has complete terms"
                },
                "content": "# DOCX creation, editing, and analysis\n\n## Overview\n\nA user may ask you to create, edit, or analyze the contents of a .docx file. A .docx file is essentially a ZIP archive containing XML files and other resources that you can read or edit. You have different tools and workflows available for different tasks.\n\n## Workflow Decision Tree\n\n### Reading/Analyzing Content\nUse \"Text extraction\" or \"Raw XML access\" sections below\n\n### Creating New Document\nUse \"Creating a new Word document\" workflow\n\n### Editing Existing Document\n- **Your own document + simple changes**\n  Use \"Basic OOXML editing\" workflow\n\n- **Someone else's document**\n  Use **\"Redlining workflow\"** (recommended default)\n\n- **Legal, academic, business, or government docs**\n  Use **\"Redlining workflow\"** (required)\n\n## Reading and analyzing content\n\n### Text extraction\nIf you just need to read the text contents of a document, you should convert the document to markdown using pandoc. Pandoc provides excellent support for preserving document structure and can show tracked changes:\n\n```bash\n# Convert document to markdown with tracked changes\npandoc --track-changes=all path-to-file.docx -o output.md\n# Options: --track-changes=accept/reject/all\n```\n\n### Raw XML access\nYou need raw XML access for: comments, complex formatting, document structure, embedded media, and metadata. For any of these features, you'll need to unpack a document and read its raw XML contents.\n\n#### Unpacking a file\n`python ooxml/scripts/unpack.py <office_file> <output_directory>`\n\n#### Key file structures\n* `word/document.xml` - Main document contents\n* `word/comments.xml` - Comments referenced in document.xml\n* `word/media/` - Embedded images and media files\n* Tracked changes use `<w:ins>` (insertions) and `<w:del>` (deletions) tags\n\n## Creating a new Word document\n\nWhen creating a new Word document from scratch, use **docx-js**, which allows you to create Word documents using JavaScript/TypeScript.\n\n### Workflow\n1. **MANDATORY - READ ENTIRE FILE**: Read [`docx-js.md`](docx-js.md) (~500 lines) completely from start to finish. **NEVER set any range limits when reading this file.** Read the full file content for detailed syntax, critical formatting rules, and best practices before proceeding with document creation.\n2. Create a JavaScript/TypeScript file using Document, Paragraph, TextRun components (You can assume all dependencies are installed, but if not, refer to the dependencies section below)\n3. Export as .docx using Packer.toBuffer()\n\n## Editing an existing Word document\n\nWhen editing an existing Word document, use the **Document library** (a Python library for OOXML manipulation). The library automatically handles infrastructure setup and provides methods for document manipulation. For complex scenarios, you can access the underlying DOM directly through the library.\n\n### Workflow\n1. **MANDATORY - READ ENTIRE FILE**: Read [`ooxml.md`](ooxml.md) (~600 lines) completely from start to finish. **NEVER set any range limits when reading this file.** Read the full file content for the Document library API and XML patterns for directly editing document files.\n2. Unpack the document: `python ooxml/scripts/unpack.py <office_file> <output_directory>`\n3. Create and run a Python script using the Document library (see \"Document Library\" section in ooxml.md)\n4. Pack the final document: `python ooxml/scripts/pack.py <input_directory> <office_file>`\n\nThe Document library provides both high-level methods for common operations and direct DOM access for complex scenarios.\n\n## Redlining workflow for document review\n\nThis workflow allows you to plan comprehensive tracked changes using markdown before implementing them in OOXML. **CRITICAL**: For complete tracked changes, you must implement ALL changes systematically.\n\n**Batching Strategy**: Group related changes into batches of 3-10 changes. This makes debugging manageable while maintaining efficiency. Test each batch before moving to the next.\n\n**Principle: Minimal, Precise Edits**\nWhen implementing tracked changes, only mark text that actually changes. Repeating unchanged text makes edits harder to review and appears unprofessional. Break replacements into: [unchanged text] + [deletion] + [insertion] + [unchanged text]. Preserve the original run's RSID for unchanged text by extracting the `<w:r>` element from the original and reusing it.\n\nExample - Changing \"30 days\" to \"60 days\" in a sentence:\n```python\n# BAD - Replaces entire sentence\n'<w:del><w:r><w:delText>The term is 30 days.</w:delText></w:r></w:del><w:ins><w:r><w:t>The term is 60 days.</w:t></w:r></w:ins>'\n\n# GOOD - Only marks what changed, preserves original <w:r> for unchanged text\n'<w:r w:rsidR=\"00AB12CD\"><w:t>The term is </w:t></w:r><w:del><w:r><w:delText>30</w:delText></w:r></w:del><w:ins><w:r><w:t>60</w:t></w:r></w:ins><w:r w:rsidR=\"00AB12CD\"><w:t> days.</w:t></w:r>'\n```\n\n### Tracked changes workflow\n\n1. **Get markdown representation**: Convert document to markdown with tracked changes preserved:\n   ```bash\n   pandoc --track-changes=all path-to-file.docx -o current.md\n   ```\n\n2. **Identify and group changes**: Review the document and identify ALL changes needed, organizing them into logical batches:\n\n   **Location methods** (for finding changes in XML):\n   - Section/heading numbers (e.g., \"Section 3.2\", \"Article IV\")\n   - Paragraph identifiers if numbered\n   - Grep patterns with unique surrounding text\n   - Document structure (e.g., \"first paragraph\", \"signature block\")\n   - **DO NOT use markdown line numbers** - they don't map to XML structure\n\n   **Batch organization** (group 3-10 related changes per batch):\n   - By section: \"Batch 1: Section 2 amendments\", \"Batch 2: Section 5 updates\"\n   - By type: \"Batch 1: Date corrections\", \"Batch 2: Party name changes\"\n   - By complexity: Start with simple text replacements, then tackle complex structural changes\n   - Sequential: \"Batch 1: Pages 1-3\", \"Batch 2: Pages 4-6\"\n\n3. **Read documentation and unpack**:\n   - **MANDATORY - READ ENTIRE FILE**: Read [`ooxml.md`](ooxml.md) (~600 lines) completely from start to finish. **NEVER set any range limits when reading this file.** Pay special attention to the \"Document Library\" and \"Tracked Change Patterns\" sections.\n   - **Unpack the document**: `python ooxml/scripts/unpack.py <file.docx> <dir>`\n   - **Note the suggested RSID**: The unpack script will suggest an RSID to use for your tracked changes. Copy this RSID for use in step 4b.\n\n4. **Implement changes in batches**: Group changes logically (by section, by type, or by proximity) and implement them together in a single script. This approach:\n   - Makes debugging easier (smaller batch = easier to isolate errors)\n   - Allows incremental progress\n   - Maintains efficiency (batch size of 3-10 changes works well)\n\n   **Suggested batch groupings:**\n   - By document section (e.g., \"Section 3 changes\", \"Definitions\", \"Termination clause\")\n   - By change type (e.g., \"Date changes\", \"Party name updates\", \"Legal term replacements\")\n   - By proximity (e.g., \"Changes on pages 1-3\", \"Changes in first half of document\")\n\n   For each batch of related changes:\n\n   **a. Map text to XML**: Grep for text in `word/document.xml` to verify how text is split across `<w:r>` elements.\n\n   **b. Create and run script**: Use `get_node` to find nodes, implement changes, then `doc.save()`. See **\"Document Library\"** section in ooxml.md for patterns.\n\n   **Note**: Always grep `word/document.xml` immediately before writing a script to get current line numbers and verify text content. Line numbers change after each script run.\n\n5. **Pack the document**: After all batches are complete, convert the unpacked directory back to .docx:\n   ```bash\n   python ooxml/scripts/pack.py unpacked reviewed-document.docx\n   ```\n\n6. **Final verification**: Do a comprehensive check of the complete document:\n   - Convert final document to markdown:\n     ```bash\n     pandoc --track-changes=all reviewed-document.docx -o verification.md\n     ```\n   - Verify ALL changes were applied correctly:\n     ```bash\n     grep \"original phrase\" verification.md  # Should NOT find it\n     grep \"replacement phrase\" verification.md  # Should find it\n     ```\n   - Check that no unintended changes were introduced\n\n\n## Converting Documents to Images\n\nTo visually analyze Word documents, convert them to images using a two-step process:\n\n1. **Convert DOCX to PDF**:\n   ```bash\n   soffice --headless --convert-to pdf document.docx\n   ```\n\n2. **Convert PDF pages to JPEG images**:\n   ```bash\n   pdftoppm -jpeg -r 150 document.pdf page\n   ```\n   This creates files like `page-1.jpg`, `page-2.jpg`, etc.\n\nOptions:\n- `-r 150`: Sets resolution to 150 DPI (adjust for quality/size balance)\n- `-jpeg`: Output JPEG format (use `-png` for PNG if preferred)\n- `-f N`: First page to convert (e.g., `-f 2` starts from page 2)\n- `-l N`: Last page to convert (e.g., `-l 5` stops at page 5)\n- `page`: Prefix for output files\n\nExample for specific range:\n```bash\npdftoppm -jpeg -r 150 -f 2 -l 5 document.pdf page  # Converts only pages 2-5\n```\n\n## Code Style Guidelines\n**IMPORTANT**: When generating code for DOCX operations:\n- Write concise code\n- Avoid verbose variable names and redundant operations\n- Avoid unnecessary print statements\n\n## Dependencies\n\nRequired dependencies (install if not available):\n\n- **pandoc**: `sudo apt-get install pandoc` (for text extraction)\n- **docx**: `npm install -g docx` (for creating new documents)\n- **LibreOffice**: `sudo apt-get install libreoffice` (for PDF conversion)\n- **Poppler**: `sudo apt-get install poppler-utils` (for pdftoppm to convert PDF to images)\n- **defusedxml**: `pip install defusedxml` (for secure XML parsing)"
              },
              {
                "name": "pdf",
                "description": "Comprehensive PDF manipulation toolkit for extracting text and tables, creating new PDFs, merging/splitting documents, and handling forms. When Claude needs to fill in a PDF form or programmatically process, generate, or analyze PDF documents at scale.",
                "path": "plugins/document-suite/skills/pdf/SKILL.md",
                "frontmatter": {
                  "name": "pdf",
                  "description": "Comprehensive PDF manipulation toolkit for extracting text and tables, creating new PDFs, merging/splitting documents, and handling forms. When Claude needs to fill in a PDF form or programmatically process, generate, or analyze PDF documents at scale.",
                  "license": "Proprietary. LICENSE.txt has complete terms"
                },
                "content": "# PDF Processing Guide\n\n## Overview\n\nThis guide covers essential PDF processing operations using Python libraries and command-line tools. For advanced features, JavaScript libraries, and detailed examples, see reference.md. If you need to fill out a PDF form, read forms.md and follow its instructions.\n\n## Quick Start\n\n```python\nfrom pypdf import PdfReader, PdfWriter\n\n# Read a PDF\nreader = PdfReader(\"document.pdf\")\nprint(f\"Pages: {len(reader.pages)}\")\n\n# Extract text\ntext = \"\"\nfor page in reader.pages:\n    text += page.extract_text()\n```\n\n## Python Libraries\n\n### pypdf - Basic Operations\n\n#### Merge PDFs\n```python\nfrom pypdf import PdfWriter, PdfReader\n\nwriter = PdfWriter()\nfor pdf_file in [\"doc1.pdf\", \"doc2.pdf\", \"doc3.pdf\"]:\n    reader = PdfReader(pdf_file)\n    for page in reader.pages:\n        writer.add_page(page)\n\nwith open(\"merged.pdf\", \"wb\") as output:\n    writer.write(output)\n```\n\n#### Split PDF\n```python\nreader = PdfReader(\"input.pdf\")\nfor i, page in enumerate(reader.pages):\n    writer = PdfWriter()\n    writer.add_page(page)\n    with open(f\"page_{i+1}.pdf\", \"wb\") as output:\n        writer.write(output)\n```\n\n#### Extract Metadata\n```python\nreader = PdfReader(\"document.pdf\")\nmeta = reader.metadata\nprint(f\"Title: {meta.title}\")\nprint(f\"Author: {meta.author}\")\nprint(f\"Subject: {meta.subject}\")\nprint(f\"Creator: {meta.creator}\")\n```\n\n#### Rotate Pages\n```python\nreader = PdfReader(\"input.pdf\")\nwriter = PdfWriter()\n\npage = reader.pages[0]\npage.rotate(90)  # Rotate 90 degrees clockwise\nwriter.add_page(page)\n\nwith open(\"rotated.pdf\", \"wb\") as output:\n    writer.write(output)\n```\n\n### pdfplumber - Text and Table Extraction\n\n#### Extract Text with Layout\n```python\nimport pdfplumber\n\nwith pdfplumber.open(\"document.pdf\") as pdf:\n    for page in pdf.pages:\n        text = page.extract_text()\n        print(text)\n```\n\n#### Extract Tables\n```python\nwith pdfplumber.open(\"document.pdf\") as pdf:\n    for i, page in enumerate(pdf.pages):\n        tables = page.extract_tables()\n        for j, table in enumerate(tables):\n            print(f\"Table {j+1} on page {i+1}:\")\n            for row in table:\n                print(row)\n```\n\n#### Advanced Table Extraction\n```python\nimport pandas as pd\n\nwith pdfplumber.open(\"document.pdf\") as pdf:\n    all_tables = []\n    for page in pdf.pages:\n        tables = page.extract_tables()\n        for table in tables:\n            if table:  # Check if table is not empty\n                df = pd.DataFrame(table[1:], columns=table[0])\n                all_tables.append(df)\n\n# Combine all tables\nif all_tables:\n    combined_df = pd.concat(all_tables, ignore_index=True)\n    combined_df.to_excel(\"extracted_tables.xlsx\", index=False)\n```\n\n### reportlab - Create PDFs\n\n#### Basic PDF Creation\n```python\nfrom reportlab.lib.pagesizes import letter\nfrom reportlab.pdfgen import canvas\n\nc = canvas.Canvas(\"hello.pdf\", pagesize=letter)\nwidth, height = letter\n\n# Add text\nc.drawString(100, height - 100, \"Hello World!\")\nc.drawString(100, height - 120, \"This is a PDF created with reportlab\")\n\n# Add a line\nc.line(100, height - 140, 400, height - 140)\n\n# Save\nc.save()\n```\n\n#### Create PDF with Multiple Pages\n```python\nfrom reportlab.lib.pagesizes import letter\nfrom reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, PageBreak\nfrom reportlab.lib.styles import getSampleStyleSheet\n\ndoc = SimpleDocTemplate(\"report.pdf\", pagesize=letter)\nstyles = getSampleStyleSheet()\nstory = []\n\n# Add content\ntitle = Paragraph(\"Report Title\", styles['Title'])\nstory.append(title)\nstory.append(Spacer(1, 12))\n\nbody = Paragraph(\"This is the body of the report. \" * 20, styles['Normal'])\nstory.append(body)\nstory.append(PageBreak())\n\n# Page 2\nstory.append(Paragraph(\"Page 2\", styles['Heading1']))\nstory.append(Paragraph(\"Content for page 2\", styles['Normal']))\n\n# Build PDF\ndoc.build(story)\n```\n\n## Command-Line Tools\n\n### pdftotext (poppler-utils)\n```bash\n# Extract text\npdftotext input.pdf output.txt\n\n# Extract text preserving layout\npdftotext -layout input.pdf output.txt\n\n# Extract specific pages\npdftotext -f 1 -l 5 input.pdf output.txt  # Pages 1-5\n```\n\n### qpdf\n```bash\n# Merge PDFs\nqpdf --empty --pages file1.pdf file2.pdf -- merged.pdf\n\n# Split pages\nqpdf input.pdf --pages . 1-5 -- pages1-5.pdf\nqpdf input.pdf --pages . 6-10 -- pages6-10.pdf\n\n# Rotate pages\nqpdf input.pdf output.pdf --rotate=+90:1  # Rotate page 1 by 90 degrees\n\n# Remove password\nqpdf --password=mypassword --decrypt encrypted.pdf decrypted.pdf\n```\n\n### pdftk (if available)\n```bash\n# Merge\npdftk file1.pdf file2.pdf cat output merged.pdf\n\n# Split\npdftk input.pdf burst\n\n# Rotate\npdftk input.pdf rotate 1east output rotated.pdf\n```\n\n## Common Tasks\n\n### Extract Text from Scanned PDFs\n```python\n# Requires: pip install pytesseract pdf2image\nimport pytesseract\nfrom pdf2image import convert_from_path\n\n# Convert PDF to images\nimages = convert_from_path('scanned.pdf')\n\n# OCR each page\ntext = \"\"\nfor i, image in enumerate(images):\n    text += f\"Page {i+1}:\\n\"\n    text += pytesseract.image_to_string(image)\n    text += \"\\n\\n\"\n\nprint(text)\n```\n\n### Add Watermark\n```python\nfrom pypdf import PdfReader, PdfWriter\n\n# Create watermark (or load existing)\nwatermark = PdfReader(\"watermark.pdf\").pages[0]\n\n# Apply to all pages\nreader = PdfReader(\"document.pdf\")\nwriter = PdfWriter()\n\nfor page in reader.pages:\n    page.merge_page(watermark)\n    writer.add_page(page)\n\nwith open(\"watermarked.pdf\", \"wb\") as output:\n    writer.write(output)\n```\n\n### Extract Images\n```bash\n# Using pdfimages (poppler-utils)\npdfimages -j input.pdf output_prefix\n\n# This extracts all images as output_prefix-000.jpg, output_prefix-001.jpg, etc.\n```\n\n### Password Protection\n```python\nfrom pypdf import PdfReader, PdfWriter\n\nreader = PdfReader(\"input.pdf\")\nwriter = PdfWriter()\n\nfor page in reader.pages:\n    writer.add_page(page)\n\n# Add password\nwriter.encrypt(\"userpassword\", \"ownerpassword\")\n\nwith open(\"encrypted.pdf\", \"wb\") as output:\n    writer.write(output)\n```\n\n## Quick Reference\n\n| Task | Best Tool | Command/Code |\n|------|-----------|--------------|\n| Merge PDFs | pypdf | `writer.add_page(page)` |\n| Split PDFs | pypdf | One page per file |\n| Extract text | pdfplumber | `page.extract_text()` |\n| Extract tables | pdfplumber | `page.extract_tables()` |\n| Create PDFs | reportlab | Canvas or Platypus |\n| Command line merge | qpdf | `qpdf --empty --pages ...` |\n| OCR scanned PDFs | pytesseract | Convert to image first |\n| Fill PDF forms | pdf-lib or pypdf (see forms.md) | See forms.md |\n\n## Next Steps\n\n- For advanced pypdfium2 usage, see reference.md\n- For JavaScript libraries (pdf-lib), see reference.md\n- If you need to fill out a PDF form, follow the instructions in forms.md\n- For troubleshooting guides, see reference.md"
              },
              {
                "name": "pptx",
                "description": "Presentation creation, editing, and analysis. When Claude needs to work with presentations (.pptx files) for: (1) Creating new presentations, (2) Modifying or editing content, (3) Working with layouts, (4) Adding comments or speaker notes, or any other presentation tasks",
                "path": "plugins/document-suite/skills/pptx/SKILL.md",
                "frontmatter": {
                  "name": "pptx",
                  "description": "Presentation creation, editing, and analysis. When Claude needs to work with presentations (.pptx files) for: (1) Creating new presentations, (2) Modifying or editing content, (3) Working with layouts, (4) Adding comments or speaker notes, or any other presentation tasks",
                  "license": "Proprietary. LICENSE.txt has complete terms"
                },
                "content": "# PPTX creation, editing, and analysis\n\n## Overview\n\nA user may ask you to create, edit, or analyze the contents of a .pptx file. A .pptx file is essentially a ZIP archive containing XML files and other resources that you can read or edit. You have different tools and workflows available for different tasks.\n\n## Reading and analyzing content\n\n### Text extraction\nIf you just need to read the text contents of a presentation, you should convert the document to markdown:\n\n```bash\n# Convert document to markdown\npython -m markitdown path-to-file.pptx\n```\n\n### Raw XML access\nYou need raw XML access for: comments, speaker notes, slide layouts, animations, design elements, and complex formatting. For any of these features, you'll need to unpack a presentation and read its raw XML contents.\n\n#### Unpacking a file\n`python ooxml/scripts/unpack.py <office_file> <output_dir>`\n\n**Note**: The unpack.py script is located at `skills/pptx/ooxml/scripts/unpack.py` relative to the project root. If the script doesn't exist at this path, use `find . -name \"unpack.py\"` to locate it.\n\n#### Key file structures\n* `ppt/presentation.xml` - Main presentation metadata and slide references\n* `ppt/slides/slide{N}.xml` - Individual slide contents (slide1.xml, slide2.xml, etc.)\n* `ppt/notesSlides/notesSlide{N}.xml` - Speaker notes for each slide\n* `ppt/comments/modernComment_*.xml` - Comments for specific slides\n* `ppt/slideLayouts/` - Layout templates for slides\n* `ppt/slideMasters/` - Master slide templates\n* `ppt/theme/` - Theme and styling information\n* `ppt/media/` - Images and other media files\n\n#### Typography and color extraction\n**When given an example design to emulate**: Always analyze the presentation's typography and colors first using the methods below:\n1. **Read theme file**: Check `ppt/theme/theme1.xml` for colors (`<a:clrScheme>`) and fonts (`<a:fontScheme>`)\n2. **Sample slide content**: Examine `ppt/slides/slide1.xml` for actual font usage (`<a:rPr>`) and colors\n3. **Search for patterns**: Use grep to find color (`<a:solidFill>`, `<a:srgbClr>`) and font references across all XML files\n\n## Creating a new PowerPoint presentation **without a template**\n\nWhen creating a new PowerPoint presentation from scratch, use the **html2pptx** workflow to convert HTML slides to PowerPoint with accurate positioning.\n\n### Design Principles\n\n**CRITICAL**: Before creating any presentation, analyze the content and choose appropriate design elements:\n1. **Consider the subject matter**: What is this presentation about? What tone, industry, or mood does it suggest?\n2. **Check for branding**: If the user mentions a company/organization, consider their brand colors and identity\n3. **Match palette to content**: Select colors that reflect the subject\n4. **State your approach**: Explain your design choices before writing code\n\n**Requirements**:\n- ✅ State your content-informed design approach BEFORE writing code\n- ✅ Use web-safe fonts only: Arial, Helvetica, Times New Roman, Georgia, Courier New, Verdana, Tahoma, Trebuchet MS, Impact\n- ✅ Create clear visual hierarchy through size, weight, and color\n- ✅ Ensure readability: strong contrast, appropriately sized text, clean alignment\n- ✅ Be consistent: repeat patterns, spacing, and visual language across slides\n\n#### Color Palette Selection\n\n**Choosing colors creatively**:\n- **Think beyond defaults**: What colors genuinely match this specific topic? Avoid autopilot choices.\n- **Consider multiple angles**: Topic, industry, mood, energy level, target audience, brand identity (if mentioned)\n- **Be adventurous**: Try unexpected combinations - a healthcare presentation doesn't have to be green, finance doesn't have to be navy\n- **Build your palette**: Pick 3-5 colors that work together (dominant colors + supporting tones + accent)\n- **Ensure contrast**: Text must be clearly readable on backgrounds\n\n**Example color palettes** (use these to spark creativity - choose one, adapt it, or create your own):\n\n1. **Classic Blue**: Deep navy (#1C2833), slate gray (#2E4053), silver (#AAB7B8), off-white (#F4F6F6)\n2. **Teal & Coral**: Teal (#5EA8A7), deep teal (#277884), coral (#FE4447), white (#FFFFFF)\n3. **Bold Red**: Red (#C0392B), bright red (#E74C3C), orange (#F39C12), yellow (#F1C40F), green (#2ECC71)\n4. **Warm Blush**: Mauve (#A49393), blush (#EED6D3), rose (#E8B4B8), cream (#FAF7F2)\n5. **Burgundy Luxury**: Burgundy (#5D1D2E), crimson (#951233), rust (#C15937), gold (#997929)\n6. **Deep Purple & Emerald**: Purple (#B165FB), dark blue (#181B24), emerald (#40695B), white (#FFFFFF)\n7. **Cream & Forest Green**: Cream (#FFE1C7), forest green (#40695B), white (#FCFCFC)\n8. **Pink & Purple**: Pink (#F8275B), coral (#FF574A), rose (#FF737D), purple (#3D2F68)\n9. **Lime & Plum**: Lime (#C5DE82), plum (#7C3A5F), coral (#FD8C6E), blue-gray (#98ACB5)\n10. **Black & Gold**: Gold (#BF9A4A), black (#000000), cream (#F4F6F6)\n11. **Sage & Terracotta**: Sage (#87A96B), terracotta (#E07A5F), cream (#F4F1DE), charcoal (#2C2C2C)\n12. **Charcoal & Red**: Charcoal (#292929), red (#E33737), light gray (#CCCBCB)\n13. **Vibrant Orange**: Orange (#F96D00), light gray (#F2F2F2), charcoal (#222831)\n14. **Forest Green**: Black (#191A19), green (#4E9F3D), dark green (#1E5128), white (#FFFFFF)\n15. **Retro Rainbow**: Purple (#722880), pink (#D72D51), orange (#EB5C18), amber (#F08800), gold (#DEB600)\n16. **Vintage Earthy**: Mustard (#E3B448), sage (#CBD18F), forest green (#3A6B35), cream (#F4F1DE)\n17. **Coastal Rose**: Old rose (#AD7670), beaver (#B49886), eggshell (#F3ECDC), ash gray (#BFD5BE)\n18. **Orange & Turquoise**: Light orange (#FC993E), grayish turquoise (#667C6F), white (#FCFCFC)\n\n#### Visual Details Options\n\n**Geometric Patterns**:\n- Diagonal section dividers instead of horizontal\n- Asymmetric column widths (30/70, 40/60, 25/75)\n- Rotated text headers at 90° or 270°\n- Circular/hexagonal frames for images\n- Triangular accent shapes in corners\n- Overlapping shapes for depth\n\n**Border & Frame Treatments**:\n- Thick single-color borders (10-20pt) on one side only\n- Double-line borders with contrasting colors\n- Corner brackets instead of full frames\n- L-shaped borders (top+left or bottom+right)\n- Underline accents beneath headers (3-5pt thick)\n\n**Typography Treatments**:\n- Extreme size contrast (72pt headlines vs 11pt body)\n- All-caps headers with wide letter spacing\n- Numbered sections in oversized display type\n- Monospace (Courier New) for data/stats/technical content\n- Condensed fonts (Arial Narrow) for dense information\n- Outlined text for emphasis\n\n**Chart & Data Styling**:\n- Monochrome charts with single accent color for key data\n- Horizontal bar charts instead of vertical\n- Dot plots instead of bar charts\n- Minimal gridlines or none at all\n- Data labels directly on elements (no legends)\n- Oversized numbers for key metrics\n\n**Layout Innovations**:\n- Full-bleed images with text overlays\n- Sidebar column (20-30% width) for navigation/context\n- Modular grid systems (3×3, 4×4 blocks)\n- Z-pattern or F-pattern content flow\n- Floating text boxes over colored shapes\n- Magazine-style multi-column layouts\n\n**Background Treatments**:\n- Solid color blocks occupying 40-60% of slide\n- Gradient fills (vertical or diagonal only)\n- Split backgrounds (two colors, diagonal or vertical)\n- Edge-to-edge color bands\n- Negative space as a design element\n\n### Layout Tips\n**When creating slides with charts or tables:**\n- **Two-column layout (PREFERRED)**: Use a header spanning the full width, then two columns below - text/bullets in one column and the featured content in the other. This provides better balance and makes charts/tables more readable. Use flexbox with unequal column widths (e.g., 40%/60% split) to optimize space for each content type.\n- **Full-slide layout**: Let the featured content (chart/table) take up the entire slide for maximum impact and readability\n- **NEVER vertically stack**: Do not place charts/tables below text in a single column - this causes poor readability and layout issues\n\n### Workflow\n1. **MANDATORY - READ ENTIRE FILE**: Read [`html2pptx.md`](html2pptx.md) completely from start to finish. **NEVER set any range limits when reading this file.** Read the full file content for detailed syntax, critical formatting rules, and best practices before proceeding with presentation creation.\n2. Create an HTML file for each slide with proper dimensions (e.g., 720pt × 405pt for 16:9)\n   - Use `<p>`, `<h1>`-`<h6>`, `<ul>`, `<ol>` for all text content\n   - Use `class=\"placeholder\"` for areas where charts/tables will be added (render with gray background for visibility)\n   - **CRITICAL**: Rasterize gradients and icons as PNG images FIRST using Sharp, then reference in HTML\n   - **LAYOUT**: For slides with charts/tables/images, use either full-slide layout or two-column layout for better readability\n3. Create and run a JavaScript file using the [`html2pptx.js`](scripts/html2pptx.js) library to convert HTML slides to PowerPoint and save the presentation\n   - Use the `html2pptx()` function to process each HTML file\n   - Add charts and tables to placeholder areas using PptxGenJS API\n   - Save the presentation using `pptx.writeFile()`\n4. **Visual validation**: Generate thumbnails and inspect for layout issues\n   - Create thumbnail grid: `python scripts/thumbnail.py output.pptx workspace/thumbnails --cols 4`\n   - Read and carefully examine the thumbnail image for:\n     - **Text cutoff**: Text being cut off by header bars, shapes, or slide edges\n     - **Text overlap**: Text overlapping with other text or shapes\n     - **Positioning issues**: Content too close to slide boundaries or other elements\n     - **Contrast issues**: Insufficient contrast between text and backgrounds\n   - If issues found, adjust HTML margins/spacing/colors and regenerate the presentation\n   - Repeat until all slides are visually correct\n\n## Editing an existing PowerPoint presentation\n\nWhen edit slides in an existing PowerPoint presentation, you need to work with the raw Office Open XML (OOXML) format. This involves unpacking the .pptx file, editing the XML content, and repacking it.\n\n### Workflow\n1. **MANDATORY - READ ENTIRE FILE**: Read [`ooxml.md`](ooxml.md) (~500 lines) completely from start to finish.  **NEVER set any range limits when reading this file.**  Read the full file content for detailed guidance on OOXML structure and editing workflows before any presentation editing.\n2. Unpack the presentation: `python ooxml/scripts/unpack.py <office_file> <output_dir>`\n3. Edit the XML files (primarily `ppt/slides/slide{N}.xml` and related files)\n4. **CRITICAL**: Validate immediately after each edit and fix any validation errors before proceeding: `python ooxml/scripts/validate.py <dir> --original <file>`\n5. Pack the final presentation: `python ooxml/scripts/pack.py <input_directory> <office_file>`\n\n## Creating a new PowerPoint presentation **using a template**\n\nWhen you need to create a presentation that follows an existing template's design, you'll need to duplicate and re-arrange template slides before then replacing placeholder context.\n\n### Workflow\n1. **Extract template text AND create visual thumbnail grid**:\n   * Extract text: `python -m markitdown template.pptx > template-content.md`\n   * Read `template-content.md`: Read the entire file to understand the contents of the template presentation. **NEVER set any range limits when reading this file.**\n   * Create thumbnail grids: `python scripts/thumbnail.py template.pptx`\n   * See [Creating Thumbnail Grids](#creating-thumbnail-grids) section for more details\n\n2. **Analyze template and save inventory to a file**:\n   * **Visual Analysis**: Review thumbnail grid(s) to understand slide layouts, design patterns, and visual structure\n   * Create and save a template inventory file at `template-inventory.md` containing:\n     ```markdown\n     # Template Inventory Analysis\n     **Total Slides: [count]**\n     **IMPORTANT: Slides are 0-indexed (first slide = 0, last slide = count-1)**\n\n     ## [Category Name]\n     - Slide 0: [Layout code if available] - Description/purpose\n     - Slide 1: [Layout code] - Description/purpose\n     - Slide 2: [Layout code] - Description/purpose\n     [... EVERY slide must be listed individually with its index ...]\n     ```\n   * **Using the thumbnail grid**: Reference the visual thumbnails to identify:\n     - Layout patterns (title slides, content layouts, section dividers)\n     - Image placeholder locations and counts\n     - Design consistency across slide groups\n     - Visual hierarchy and structure\n   * This inventory file is REQUIRED for selecting appropriate templates in the next step\n\n3. **Create presentation outline based on template inventory**:\n   * Review available templates from step 2.\n   * Choose an intro or title template for the first slide. This should be one of the first templates.\n   * Choose safe, text-based layouts for the other slides.\n   * **CRITICAL: Match layout structure to actual content**:\n     - Single-column layouts: Use for unified narrative or single topic\n     - Two-column layouts: Use ONLY when you have exactly 2 distinct items/concepts\n     - Three-column layouts: Use ONLY when you have exactly 3 distinct items/concepts\n     - Image + text layouts: Use ONLY when you have actual images to insert\n     - Quote layouts: Use ONLY for actual quotes from people (with attribution), never for emphasis\n     - Never use layouts with more placeholders than you have content\n     - If you have 2 items, don't force them into a 3-column layout\n     - If you have 4+ items, consider breaking into multiple slides or using a list format\n   * Count your actual content pieces BEFORE selecting the layout\n   * Verify each placeholder in the chosen layout will be filled with meaningful content\n   * Select one option representing the **best** layout for each content section.\n   * Save `outline.md` with content AND template mapping that leverages available designs\n   * Example template mapping:\n      ```\n      # Template slides to use (0-based indexing)\n      # WARNING: Verify indices are within range! Template with 73 slides has indices 0-72\n      # Mapping: slide numbers from outline -> template slide indices\n      template_mapping = [\n          0,   # Use slide 0 (Title/Cover)\n          34,  # Use slide 34 (B1: Title and body)\n          34,  # Use slide 34 again (duplicate for second B1)\n          50,  # Use slide 50 (E1: Quote)\n          54,  # Use slide 54 (F2: Closing + Text)\n      ]\n      ```\n\n4. **Duplicate, reorder, and delete slides using `rearrange.py`**:\n   * Use the `scripts/rearrange.py` script to create a new presentation with slides in the desired order:\n     ```bash\n     python scripts/rearrange.py template.pptx working.pptx 0,34,34,50,52\n     ```\n   * The script handles duplicating repeated slides, deleting unused slides, and reordering automatically\n   * Slide indices are 0-based (first slide is 0, second is 1, etc.)\n   * The same slide index can appear multiple times to duplicate that slide\n\n5. **Extract ALL text using the `inventory.py` script**:\n   * **Run inventory extraction**:\n     ```bash\n     python scripts/inventory.py working.pptx text-inventory.json\n     ```\n   * **Read text-inventory.json**: Read the entire text-inventory.json file to understand all shapes and their properties. **NEVER set any range limits when reading this file.**\n\n   * The inventory JSON structure:\n      ```json\n        {\n          \"slide-0\": {\n            \"shape-0\": {\n              \"placeholder_type\": \"TITLE\",  // or null for non-placeholders\n              \"left\": 1.5,                  // position in inches\n              \"top\": 2.0,\n              \"width\": 7.5,\n              \"height\": 1.2,\n              \"paragraphs\": [\n                {\n                  \"text\": \"Paragraph text\",\n                  // Optional properties (only included when non-default):\n                  \"bullet\": true,           // explicit bullet detected\n                  \"level\": 0,               // only included when bullet is true\n                  \"alignment\": \"CENTER\",    // CENTER, RIGHT (not LEFT)\n                  \"space_before\": 10.0,     // space before paragraph in points\n                  \"space_after\": 6.0,       // space after paragraph in points\n                  \"line_spacing\": 22.4,     // line spacing in points\n                  \"font_name\": \"Arial\",     // from first run\n                  \"font_size\": 14.0,        // in points\n                  \"bold\": true,\n                  \"italic\": false,\n                  \"underline\": false,\n                  \"color\": \"FF0000\"         // RGB color\n                }\n              ]\n            }\n          }\n        }\n      ```\n\n   * Key features:\n     - **Slides**: Named as \"slide-0\", \"slide-1\", etc.\n     - **Shapes**: Ordered by visual position (top-to-bottom, left-to-right) as \"shape-0\", \"shape-1\", etc.\n     - **Placeholder types**: TITLE, CENTER_TITLE, SUBTITLE, BODY, OBJECT, or null\n     - **Default font size**: `default_font_size` in points extracted from layout placeholders (when available)\n     - **Slide numbers are filtered**: Shapes with SLIDE_NUMBER placeholder type are automatically excluded from inventory\n     - **Bullets**: When `bullet: true`, `level` is always included (even if 0)\n     - **Spacing**: `space_before`, `space_after`, and `line_spacing` in points (only included when set)\n     - **Colors**: `color` for RGB (e.g., \"FF0000\"), `theme_color` for theme colors (e.g., \"DARK_1\")\n     - **Properties**: Only non-default values are included in the output\n\n6. **Generate replacement text and save the data to a JSON file**\n   Based on the text inventory from the previous step:\n   - **CRITICAL**: First verify which shapes exist in the inventory - only reference shapes that are actually present\n   - **VALIDATION**: The replace.py script will validate that all shapes in your replacement JSON exist in the inventory\n     - If you reference a non-existent shape, you'll get an error showing available shapes\n     - If you reference a non-existent slide, you'll get an error indicating the slide doesn't exist\n     - All validation errors are shown at once before the script exits\n   - **IMPORTANT**: The replace.py script uses inventory.py internally to identify ALL text shapes\n   - **AUTOMATIC CLEARING**: ALL text shapes from the inventory will be cleared unless you provide \"paragraphs\" for them\n   - Add a \"paragraphs\" field to shapes that need content (not \"replacement_paragraphs\")\n   - Shapes without \"paragraphs\" in the replacement JSON will have their text cleared automatically\n   - Paragraphs with bullets will be automatically left aligned. Don't set the `alignment` property on when `\"bullet\": true`\n   - Generate appropriate replacement content for placeholder text\n   - Use shape size to determine appropriate content length\n   - **CRITICAL**: Include paragraph properties from the original inventory - don't just provide text\n   - **IMPORTANT**: When bullet: true, do NOT include bullet symbols (•, -, *) in text - they're added automatically\n   - **ESSENTIAL FORMATTING RULES**:\n     - Headers/titles should typically have `\"bold\": true`\n     - List items should have `\"bullet\": true, \"level\": 0` (level is required when bullet is true)\n     - Preserve any alignment properties (e.g., `\"alignment\": \"CENTER\"` for centered text)\n     - Include font properties when different from default (e.g., `\"font_size\": 14.0`, `\"font_name\": \"Lora\"`)\n     - Colors: Use `\"color\": \"FF0000\"` for RGB or `\"theme_color\": \"DARK_1\"` for theme colors\n     - The replacement script expects **properly formatted paragraphs**, not just text strings\n     - **Overlapping shapes**: Prefer shapes with larger default_font_size or more appropriate placeholder_type\n   - Save the updated inventory with replacements to `replacement-text.json`\n   - **WARNING**: Different template layouts have different shape counts - always check the actual inventory before creating replacements\n\n   Example paragraphs field showing proper formatting:\n   ```json\n   \"paragraphs\": [\n     {\n       \"text\": \"New presentation title text\",\n       \"alignment\": \"CENTER\",\n       \"bold\": true\n     },\n     {\n       \"text\": \"Section Header\",\n       \"bold\": true\n     },\n     {\n       \"text\": \"First bullet point without bullet symbol\",\n       \"bullet\": true,\n       \"level\": 0\n     },\n     {\n       \"text\": \"Red colored text\",\n       \"color\": \"FF0000\"\n     },\n     {\n       \"text\": \"Theme colored text\",\n       \"theme_color\": \"DARK_1\"\n     },\n     {\n       \"text\": \"Regular paragraph text without special formatting\"\n     }\n   ]\n   ```\n\n   **Shapes not listed in the replacement JSON are automatically cleared**:\n   ```json\n   {\n     \"slide-0\": {\n       \"shape-0\": {\n         \"paragraphs\": [...] // This shape gets new text\n       }\n       // shape-1 and shape-2 from inventory will be cleared automatically\n     }\n   }\n   ```\n\n   **Common formatting patterns for presentations**:\n   - Title slides: Bold text, sometimes centered\n   - Section headers within slides: Bold text\n   - Bullet lists: Each item needs `\"bullet\": true, \"level\": 0`\n   - Body text: Usually no special properties needed\n   - Quotes: May have special alignment or font properties\n\n7. **Apply replacements using the `replace.py` script**\n   ```bash\n   python scripts/replace.py working.pptx replacement-text.json output.pptx\n   ```\n\n   The script will:\n   - First extract the inventory of ALL text shapes using functions from inventory.py\n   - Validate that all shapes in the replacement JSON exist in the inventory\n   - Clear text from ALL shapes identified in the inventory\n   - Apply new text only to shapes with \"paragraphs\" defined in the replacement JSON\n   - Preserve formatting by applying paragraph properties from the JSON\n   - Handle bullets, alignment, font properties, and colors automatically\n   - Save the updated presentation\n\n   Example validation errors:\n   ```\n   ERROR: Invalid shapes in replacement JSON:\n     - Shape 'shape-99' not found on 'slide-0'. Available shapes: shape-0, shape-1, shape-4\n     - Slide 'slide-999' not found in inventory\n   ```\n\n   ```\n   ERROR: Replacement text made overflow worse in these shapes:\n     - slide-0/shape-2: overflow worsened by 1.25\" (was 0.00\", now 1.25\")\n   ```\n\n## Creating Thumbnail Grids\n\nTo create visual thumbnail grids of PowerPoint slides for quick analysis and reference:\n\n```bash\npython scripts/thumbnail.py template.pptx [output_prefix]\n```\n\n**Features**:\n- Creates: `thumbnails.jpg` (or `thumbnails-1.jpg`, `thumbnails-2.jpg`, etc. for large decks)\n- Default: 5 columns, max 30 slides per grid (5×6)\n- Custom prefix: `python scripts/thumbnail.py template.pptx my-grid`\n  - Note: The output prefix should include the path if you want output in a specific directory (e.g., `workspace/my-grid`)\n- Adjust columns: `--cols 4` (range: 3-6, affects slides per grid)\n- Grid limits: 3 cols = 12 slides/grid, 4 cols = 20, 5 cols = 30, 6 cols = 42\n- Slides are zero-indexed (Slide 0, Slide 1, etc.)\n\n**Use cases**:\n- Template analysis: Quickly understand slide layouts and design patterns\n- Content review: Visual overview of entire presentation\n- Navigation reference: Find specific slides by their visual appearance\n- Quality check: Verify all slides are properly formatted\n\n**Examples**:\n```bash\n# Basic usage\npython scripts/thumbnail.py presentation.pptx\n\n# Combine options: custom name, columns\npython scripts/thumbnail.py template.pptx analysis --cols 4\n```\n\n## Converting Slides to Images\n\nTo visually analyze PowerPoint slides, convert them to images using a two-step process:\n\n1. **Convert PPTX to PDF**:\n   ```bash\n   soffice --headless --convert-to pdf template.pptx\n   ```\n\n2. **Convert PDF pages to JPEG images**:\n   ```bash\n   pdftoppm -jpeg -r 150 template.pdf slide\n   ```\n   This creates files like `slide-1.jpg`, `slide-2.jpg`, etc.\n\nOptions:\n- `-r 150`: Sets resolution to 150 DPI (adjust for quality/size balance)\n- `-jpeg`: Output JPEG format (use `-png` for PNG if preferred)\n- `-f N`: First page to convert (e.g., `-f 2` starts from page 2)\n- `-l N`: Last page to convert (e.g., `-l 5` stops at page 5)\n- `slide`: Prefix for output files\n\nExample for specific range:\n```bash\npdftoppm -jpeg -r 150 -f 2 -l 5 template.pdf slide  # Converts only pages 2-5\n```\n\n## Code Style Guidelines\n**IMPORTANT**: When generating code for PPTX operations:\n- Write concise code\n- Avoid verbose variable names and redundant operations\n- Avoid unnecessary print statements\n\n## Dependencies\n\nRequired dependencies (should already be installed):\n\n- **markitdown**: `pip install \"markitdown[pptx]\"` (for text extraction from presentations)\n- **pptxgenjs**: `npm install -g pptxgenjs` (for creating presentations via html2pptx)\n- **playwright**: `npm install -g playwright` (for HTML rendering in html2pptx)\n- **react-icons**: `npm install -g react-icons react react-dom` (for icons)\n- **sharp**: `npm install -g sharp` (for SVG rasterization and image processing)\n- **LibreOffice**: `sudo apt-get install libreoffice` (for PDF conversion)\n- **Poppler**: `sudo apt-get install poppler-utils` (for pdftoppm to convert PDF to images)\n- **defusedxml**: `pip install defusedxml` (for secure XML parsing)"
              },
              {
                "name": "xlsx",
                "description": "Comprehensive spreadsheet creation, editing, and analysis with support for formulas, formatting, data analysis, and visualization. When Claude needs to work with spreadsheets (.xlsx, .xlsm, .csv, .tsv, etc) for: (1) Creating new spreadsheets with formulas and formatting, (2) Reading or analyzing data, (3) Modify existing spreadsheets while preserving formulas, (4) Data analysis and visualization in spreadsheets, or (5) Recalculating formulas",
                "path": "plugins/document-suite/skills/xlsx/SKILL.md",
                "frontmatter": {
                  "name": "xlsx",
                  "description": "Comprehensive spreadsheet creation, editing, and analysis with support for formulas, formatting, data analysis, and visualization. When Claude needs to work with spreadsheets (.xlsx, .xlsm, .csv, .tsv, etc) for: (1) Creating new spreadsheets with formulas and formatting, (2) Reading or analyzing data, (3) Modify existing spreadsheets while preserving formulas, (4) Data analysis and visualization in spreadsheets, or (5) Recalculating formulas",
                  "license": "Proprietary. LICENSE.txt has complete terms"
                },
                "content": "# Requirements for Outputs\n\n## All Excel files\n\n### Zero Formula Errors\n- Every Excel model MUST be delivered with ZERO formula errors (#REF!, #DIV/0!, #VALUE!, #N/A, #NAME?)\n\n### Preserve Existing Templates (when updating templates)\n- Study and EXACTLY match existing format, style, and conventions when modifying files\n- Never impose standardized formatting on files with established patterns\n- Existing template conventions ALWAYS override these guidelines\n\n## Financial models\n\n### Color Coding Standards\nUnless otherwise stated by the user or existing template\n\n#### Industry-Standard Color Conventions\n- **Blue text (RGB: 0,0,255)**: Hardcoded inputs, and numbers users will change for scenarios\n- **Black text (RGB: 0,0,0)**: ALL formulas and calculations\n- **Green text (RGB: 0,128,0)**: Links pulling from other worksheets within same workbook\n- **Red text (RGB: 255,0,0)**: External links to other files\n- **Yellow background (RGB: 255,255,0)**: Key assumptions needing attention or cells that need to be updated\n\n### Number Formatting Standards\n\n#### Required Format Rules\n- **Years**: Format as text strings (e.g., \"2024\" not \"2,024\")\n- **Currency**: Use $#,##0 format; ALWAYS specify units in headers (\"Revenue ($mm)\")\n- **Zeros**: Use number formatting to make all zeros \"-\", including percentages (e.g., \"$#,##0;($#,##0);-\")\n- **Percentages**: Default to 0.0% format (one decimal)\n- **Multiples**: Format as 0.0x for valuation multiples (EV/EBITDA, P/E)\n- **Negative numbers**: Use parentheses (123) not minus -123\n\n### Formula Construction Rules\n\n#### Assumptions Placement\n- Place ALL assumptions (growth rates, margins, multiples, etc.) in separate assumption cells\n- Use cell references instead of hardcoded values in formulas\n- Example: Use =B5*(1+$B$6) instead of =B5*1.05\n\n#### Formula Error Prevention\n- Verify all cell references are correct\n- Check for off-by-one errors in ranges\n- Ensure consistent formulas across all projection periods\n- Test with edge cases (zero values, negative numbers)\n- Verify no unintended circular references\n\n#### Documentation Requirements for Hardcodes\n- Comment or in cells beside (if end of table). Format: \"Source: [System/Document], [Date], [Specific Reference], [URL if applicable]\"\n- Examples:\n  - \"Source: Company 10-K, FY2024, Page 45, Revenue Note, [SEC EDGAR URL]\"\n  - \"Source: Company 10-Q, Q2 2025, Exhibit 99.1, [SEC EDGAR URL]\"\n  - \"Source: Bloomberg Terminal, 8/15/2025, AAPL US Equity\"\n  - \"Source: FactSet, 8/20/2025, Consensus Estimates Screen\"\n\n# XLSX creation, editing, and analysis\n\n## Overview\n\nA user may ask you to create, edit, or analyze the contents of an .xlsx file. You have different tools and workflows available for different tasks.\n\n## Important Requirements\n\n**LibreOffice Required for Formula Recalculation**: You can assume LibreOffice is installed for recalculating formula values using the `recalc.py` script. The script automatically configures LibreOffice on first run\n\n## Reading and analyzing data\n\n### Data analysis with pandas\nFor data analysis, visualization, and basic operations, use **pandas** which provides powerful data manipulation capabilities:\n\n```python\nimport pandas as pd\n\n# Read Excel\ndf = pd.read_excel('file.xlsx')  # Default: first sheet\nall_sheets = pd.read_excel('file.xlsx', sheet_name=None)  # All sheets as dict\n\n# Analyze\ndf.head()      # Preview data\ndf.info()      # Column info\ndf.describe()  # Statistics\n\n# Write Excel\ndf.to_excel('output.xlsx', index=False)\n```\n\n## Excel File Workflows\n\n## CRITICAL: Use Formulas, Not Hardcoded Values\n\n**Always use Excel formulas instead of calculating values in Python and hardcoding them.** This ensures the spreadsheet remains dynamic and updateable.\n\n### ❌ WRONG - Hardcoding Calculated Values\n```python\n# Bad: Calculating in Python and hardcoding result\ntotal = df['Sales'].sum()\nsheet['B10'] = total  # Hardcodes 5000\n\n# Bad: Computing growth rate in Python\ngrowth = (df.iloc[-1]['Revenue'] - df.iloc[0]['Revenue']) / df.iloc[0]['Revenue']\nsheet['C5'] = growth  # Hardcodes 0.15\n\n# Bad: Python calculation for average\navg = sum(values) / len(values)\nsheet['D20'] = avg  # Hardcodes 42.5\n```\n\n### ✅ CORRECT - Using Excel Formulas\n```python\n# Good: Let Excel calculate the sum\nsheet['B10'] = '=SUM(B2:B9)'\n\n# Good: Growth rate as Excel formula\nsheet['C5'] = '=(C4-C2)/C2'\n\n# Good: Average using Excel function\nsheet['D20'] = '=AVERAGE(D2:D19)'\n```\n\nThis applies to ALL calculations - totals, percentages, ratios, differences, etc. The spreadsheet should be able to recalculate when source data changes.\n\n## Common Workflow\n1. **Choose tool**: pandas for data, openpyxl for formulas/formatting\n2. **Create/Load**: Create new workbook or load existing file\n3. **Modify**: Add/edit data, formulas, and formatting\n4. **Save**: Write to file\n5. **Recalculate formulas (MANDATORY IF USING FORMULAS)**: Use the recalc.py script\n   ```bash\n   python recalc.py output.xlsx\n   ```\n6. **Verify and fix any errors**: \n   - The script returns JSON with error details\n   - If `status` is `errors_found`, check `error_summary` for specific error types and locations\n   - Fix the identified errors and recalculate again\n   - Common errors to fix:\n     - `#REF!`: Invalid cell references\n     - `#DIV/0!`: Division by zero\n     - `#VALUE!`: Wrong data type in formula\n     - `#NAME?`: Unrecognized formula name\n\n### Creating new Excel files\n\n```python\n# Using openpyxl for formulas and formatting\nfrom openpyxl import Workbook\nfrom openpyxl.styles import Font, PatternFill, Alignment\n\nwb = Workbook()\nsheet = wb.active\n\n# Add data\nsheet['A1'] = 'Hello'\nsheet['B1'] = 'World'\nsheet.append(['Row', 'of', 'data'])\n\n# Add formula\nsheet['B2'] = '=SUM(A1:A10)'\n\n# Formatting\nsheet['A1'].font = Font(bold=True, color='FF0000')\nsheet['A1'].fill = PatternFill('solid', start_color='FFFF00')\nsheet['A1'].alignment = Alignment(horizontal='center')\n\n# Column width\nsheet.column_dimensions['A'].width = 20\n\nwb.save('output.xlsx')\n```\n\n### Editing existing Excel files\n\n```python\n# Using openpyxl to preserve formulas and formatting\nfrom openpyxl import load_workbook\n\n# Load existing file\nwb = load_workbook('existing.xlsx')\nsheet = wb.active  # or wb['SheetName'] for specific sheet\n\n# Working with multiple sheets\nfor sheet_name in wb.sheetnames:\n    sheet = wb[sheet_name]\n    print(f\"Sheet: {sheet_name}\")\n\n# Modify cells\nsheet['A1'] = 'New Value'\nsheet.insert_rows(2)  # Insert row at position 2\nsheet.delete_cols(3)  # Delete column 3\n\n# Add new sheet\nnew_sheet = wb.create_sheet('NewSheet')\nnew_sheet['A1'] = 'Data'\n\nwb.save('modified.xlsx')\n```\n\n## Recalculating formulas\n\nExcel files created or modified by openpyxl contain formulas as strings but not calculated values. Use the provided `recalc.py` script to recalculate formulas:\n\n```bash\npython recalc.py <excel_file> [timeout_seconds]\n```\n\nExample:\n```bash\npython recalc.py output.xlsx 30\n```\n\nThe script:\n- Automatically sets up LibreOffice macro on first run\n- Recalculates all formulas in all sheets\n- Scans ALL cells for Excel errors (#REF!, #DIV/0!, etc.)\n- Returns JSON with detailed error locations and counts\n- Works on both Linux and macOS\n\n## Formula Verification Checklist\n\nQuick checks to ensure formulas work correctly:\n\n### Essential Verification\n- [ ] **Test 2-3 sample references**: Verify they pull correct values before building full model\n- [ ] **Column mapping**: Confirm Excel columns match (e.g., column 64 = BL, not BK)\n- [ ] **Row offset**: Remember Excel rows are 1-indexed (DataFrame row 5 = Excel row 6)\n\n### Common Pitfalls\n- [ ] **NaN handling**: Check for null values with `pd.notna()`\n- [ ] **Far-right columns**: FY data often in columns 50+ \n- [ ] **Multiple matches**: Search all occurrences, not just first\n- [ ] **Division by zero**: Check denominators before using `/` in formulas (#DIV/0!)\n- [ ] **Wrong references**: Verify all cell references point to intended cells (#REF!)\n- [ ] **Cross-sheet references**: Use correct format (Sheet1!A1) for linking sheets\n\n### Formula Testing Strategy\n- [ ] **Start small**: Test formulas on 2-3 cells before applying broadly\n- [ ] **Verify dependencies**: Check all cells referenced in formulas exist\n- [ ] **Test edge cases**: Include zero, negative, and very large values\n\n### Interpreting recalc.py Output\nThe script returns JSON with error details:\n```json\n{\n  \"status\": \"success\",           // or \"errors_found\"\n  \"total_errors\": 0,              // Total error count\n  \"total_formulas\": 42,           // Number of formulas in file\n  \"error_summary\": {              // Only present if errors found\n    \"#REF!\": {\n      \"count\": 2,\n      \"locations\": [\"Sheet1!B5\", \"Sheet1!C10\"]\n    }\n  }\n}\n```\n\n## Best Practices\n\n### Library Selection\n- **pandas**: Best for data analysis, bulk operations, and simple data export\n- **openpyxl**: Best for complex formatting, formulas, and Excel-specific features\n\n### Working with openpyxl\n- Cell indices are 1-based (row=1, column=1 refers to cell A1)\n- Use `data_only=True` to read calculated values: `load_workbook('file.xlsx', data_only=True)`\n- **Warning**: If opened with `data_only=True` and saved, formulas are replaced with values and permanently lost\n- For large files: Use `read_only=True` for reading or `write_only=True` for writing\n- Formulas are preserved but not evaluated - use recalc.py to update values\n\n### Working with pandas\n- Specify data types to avoid inference issues: `pd.read_excel('file.xlsx', dtype={'id': str})`\n- For large files, read specific columns: `pd.read_excel('file.xlsx', usecols=['A', 'C', 'E'])`\n- Handle dates properly: `pd.read_excel('file.xlsx', parse_dates=['date_column'])`\n\n## Code Style Guidelines\n**IMPORTANT**: When generating Python code for Excel operations:\n- Write minimal, concise Python code without unnecessary comments\n- Avoid verbose variable names and redundant operations\n- Avoid unnecessary print statements\n\n**For Excel files themselves**:\n- Add comments to cells with complex formulas or important assumptions\n- Document data sources for hardcoded values\n- Include notes for key calculations and model sections"
              }
            ]
          },
          {
            "name": "dev-tools",
            "description": "Development tools for API implementation, testing, and code review",
            "source": "./plugins/dev-tools",
            "category": "development",
            "version": "1.0.0",
            "author": null,
            "install_commands": [
              "/plugin marketplace add hongbietcode/synthetic-claude",
              "/plugin install dev-tools@synthetic-claude"
            ],
            "signals": {
              "stars": 1,
              "forks": 0,
              "pushed_at": "2026-01-07T17:25:07Z",
              "created_at": "2025-12-28T07:34:15Z",
              "license": null
            },
            "commands": [
              {
                "name": "/explore-external-APIs",
                "description": null,
                "path": "plugins/dev-tools/commands/explore-external-APIs.md",
                "frontmatter": null,
                "content": "# Explore API Command\n\nTest and document the real behavior of external APIs from: $ARGUMENTS\n\n## Objective\nTest the API endpoints in practice, discover actual vs documented behavior, then create accurate documentation and tests based on reality.\n\n## Process\n\n1. **Parse** - Extract endpoints, methods, and expected behaviors from docs\n2. **Test** - Run each endpoint with normal, error, edge, and boundary cases\n3. **Discover** - Note differences between docs and reality (undocumented fields, actual error codes, hidden limits)\n4. **Schema** - Analyze and document complete data schemas for SQL database integration\n5. **Document** - Create enhanced docs with real behaviors, gotchas, and examples\n6. **Generate** - Build test suite based on actual responses\n7. **Archive** - Save all raw API responses to `/Users/sonph36/dev/demo/NghiaNQ/claude-code-learning/output/raw_response` for review and future data reference\n\n## Output\n- `api-exploration-results.md` - Findings and discrepancies\n- `api-enhanced-docs.md` - Accurate documentation\n- `api-schemas.md` - Complete data schemas for SQL database design\n- `/Users/sonph36/dev/demo/NghiaNQ/claude-code-learning/output/raw_response/` - Raw API responses for review and reference\n- Test suite with real-world scenarios\n- Mock data from actual responses\n\n## Focus\nDocument how the API actually works versus what the docs claim - even \"normal\" usage often differs from documentation. Capture real response structures, actual required parameters, true error formats, and all the undocumented quirks.\n\n## Notes\n**Key Discoveries from Initial Testing:**\n\n- **Error Handling**: vnstock uses RetryError wrapper for failed API calls, masking the original error details\n- **Data Source Validation**: Some symbols (bonds, futures) trigger \"Không phải là mã chứng khoán\" warnings but still return data\n- **Symbol Compatibility**: Different data sources (VCI, TCBS) have varying support for asset types\n- **Rate Limiting**: Some API calls appear to have retry mechanisms built-in (observed 4+ second delays on failures)\n- **Data Structure**: All successful responses return pandas DataFrames with rich metadata (name, category attributes)\n- **Real-time vs Historical**: Intraday and price_depth APIs work for stocks but may not be available for all asset types\n- **Schema Consistency**: Column names and data types vary between similar endpoints from different sources\n- **Performance**: API response times range from ~200ms for simple calls to 4+ seconds for complex/failed requests"
              },
              {
                "name": "/fastapi-test",
                "description": null,
                "path": "plugins/dev-tools/commands/fastapi-test.md",
                "frontmatter": null,
                "content": "# FastAPI Testing Command\n\nCreate comprehensive API tests for: $ARGUMENTS\n\n## Testing Strategy\nTest the following API endpoints and scenarios based on $ARGUMENTS:\n\n1. **Happy Path Testing**:\n   - Valid request formats\n   - Expected response structures\n   - Proper HTTP status codes\n\n2. **Error Handling Testing**:\n   - Invalid request payloads\n   - Authentication failures\n   - Authorization edge cases\n   - Validation errors (422)\n\n3. **Edge Cases**:\n   - Boundary value testing\n   - Large payload handling\n   - Concurrent request handling\n   - Database constraints\n\n## Test Structure Template\nCreate tests in `/tests/api/test_{endpoint_name}.py`:\n\n```python\nimport pytest\nfrom httpx import AsyncClient\n\nclass Test{EndpointName}:\n    @pytest.mark.asyncio\n    async def test_create_{resource}_success(self, client: AsyncClient, auth_headers):\n        # Test implementation\n        pass\n    \n    @pytest.mark.asyncio\n    async def test_get_{resource}_not_found(self, client: AsyncClient, auth_headers):\n        # Test implementation\n        pass\n    \n    @pytest.mark.asyncio\n    async def test_update_{resource}_unauthorized(self, client: AsyncClient):\n        # Test implementation\n        pass\n```\n"
              },
              {
                "name": "/gen-feature-docs",
                "description": null,
                "path": "plugins/dev-tools/commands/gen-feature-docs.md",
                "frontmatter": null,
                "content": "Generate both developer and user documentation for the feature: $ARGUMENTS\n# Objective\nCreate two complementary documentation files:\n\n### 1. Developer documentation\nTechnical implementation details, architecture decisions, API specs\n### 2. User documentation\nClear guide with step-by-step instructions and screenshot placeholders\n\n# Approach\n- Analyze the feature's code to understand its scope and implementation\n- Match existing documentation patterns in the project\n- Adapt content based on whether the feature is frontend, backend, or full-stack\n- Include appropriate cross-references between both documents\n\n# Output\n- Save developer docs in the project's technical documentation location\n- Save user docs in the project's user guide location\n- Include placeholders for screenshots in user documentation\n- Update any existing index or navigation files\n\n# Quality Standards\n- Developer docs should be thorough enough for another developer to understand and modify the feature\n- User docs should be clear enough for a non-technical user to successfully use the feature\n- Both should follow the project's existing style and conventions\n"
              },
              {
                "name": "/generate-db-docs",
                "description": null,
                "path": "plugins/dev-tools/commands/generate-db-docs.md",
                "frontmatter": null,
                "content": "# Generate Database Documentation Command\n\nCreate comprehensive documentation for MySQL database: $ARGUMENTS\n\n## Task\nGenerate two documentation files for the database (credentials in root .env file):\n1. `{db_name}_detailed_desc.md` - Technical guide with schema, sample data, query patterns\n2. `{db_name}_overview.md` - Concise summary for quick reference\n\n## Requirements\n- Connect to the actual database and query real data\n- Test all SQL examples before including them\n- Mark tables by importance (⭐ CORE, 📊 LOG, 🔧 UTILITY)\n- Include actual record counts and recent sample data\n- Provide practical query patterns developers will use\n- No placeholder data - everything must be verified against the database\n\n## Output\nTwo markdown files with verified schema information, tested queries, and developer-focused guidance."
              },
              {
                "name": "/px-backend-api",
                "description": null,
                "path": "plugins/dev-tools/commands/px-backend-api.md",
                "frontmatter": null,
                "content": "# Implement API Command\n\nImplement internal backend API based on spec: $ARGUMENTS\n\n## Task\n1. Read documentation in the specified docs directory as needed\n2. Implement the API endpoints according to the specification\n3. **CRITICAL**: Use -175 for ANY missing data - NEVER generate realistic-looking fake data (it makes bugs nearly impossible to trace)\n4. Stop after implementation for review - do not proceed with testing or deployment\n\n## Output\nComplete API implementation with -175 stubs clearly marking missing data. Ready for code review."
              },
              {
                "name": "/px-frontend-api",
                "description": null,
                "path": "plugins/dev-tools/commands/px-frontend-api.md",
                "frontmatter": null,
                "content": "# Frontend Integration Command\n\nImplement frontend integration for the backend API using docs at: $ARGUMENTS\n\n## Task\n1. Read documentation to understand:\n   - Frontend implementation patterns/guidelines\n   - Required features and UI components\n   - API integration approach\n2. Verify backend API endpoints are working if needed\n3. Implement frontend code to consume the API\n4. **CRITICAL**: Use -175 for ANY missing data - NEVER generate realistic-looking fake data (it makes bugs nearly impossible to trace)\n5. Stop for review after implementation\n\n## Output\nComplete frontend implementation with -175 stubs clearly marking where real data is needed."
              }
            ],
            "skills": [
              {
                "name": "cc-hooks-creator",
                "description": "This skill should be used when users want to create, configure, or debug Claude Code hooks. Hooks are shell commands that execute at various points in Claude Code's lifecycle (PreToolUse, PostToolUse, Stop, SessionStart, etc.). Use this skill when users ask to create custom automation, file protection, code formatting hooks, notifications, or any lifecycle-based triggers for Claude Code.",
                "path": "plugins/dev-tools/skills/cc-hooks-creator/SKILL.md",
                "frontmatter": {
                  "name": "cc-hooks-creator",
                  "description": "This skill should be used when users want to create, configure, or debug Claude Code hooks. Hooks are shell commands that execute at various points in Claude Code's lifecycle (PreToolUse, PostToolUse, Stop, SessionStart, etc.). Use this skill when users ask to create custom automation, file protection, code formatting hooks, notifications, or any lifecycle-based triggers for Claude Code."
                },
                "content": "# Claude Code Hooks Creator\n\n## Overview\n\nThis skill provides guidance for creating effective Claude Code hooks - shell commands that execute automatically at specific points in Claude Code's lifecycle. Hooks enable deterministic control over Claude's behavior, ensuring certain actions always happen rather than relying on the LLM to choose them.\n\n## When to Use This Skill\n\n- User wants to create a new hook for Claude Code\n- User needs to automate actions before/after tool execution\n- User wants file protection, code formatting, or notification hooks\n- User needs to debug or fix existing hooks\n- User wants to understand hook configuration and lifecycle events\n\n## Hook Creation Workflow\n\n### Phase 1: Understand Requirements\n\nBefore creating a hook, gather information:\n\n1. **What action should happen?** (log, format, block, notify, validate)\n2. **When should it trigger?** (before/after tool, on stop, session start/end)\n3. **Which tools should it affect?** (Bash, Write, Edit, Read, all tools)\n4. **What conditions apply?** (file types, patterns, always)\n\n### Phase 2: Select Hook Event\n\nChoose the appropriate hook event based on timing needs:\n\n| Event | When It Runs | Common Use Cases |\n|-------|--------------|------------------|\n| `PreToolUse` | Before tool executes | Block operations, validate inputs, auto-approve |\n| `PostToolUse` | After tool completes | Format files, log operations, validate output |\n| `Stop` | When Claude finishes | Remind to store learnings, validate completion |\n| `SubagentStop` | When subagent completes | Validate subagent output |\n| `UserPromptSubmit` | When user submits prompt | Add context, validate prompts |\n| `Notification` | On notifications | Custom notifications |\n| `SessionStart` | Session begins | Load context, set environment |\n| `SessionEnd` | Session ends | Cleanup, logging |\n| `PreCompact` | Before context compact | Save important context |\n\n### Phase 3: Design Hook Logic\n\n#### Input Format (JSON via stdin)\n\nAll hooks receive JSON input with common fields:\n```json\n{\n  \"session_id\": \"abc123\",\n  \"transcript_path\": \"/path/to/transcript.jsonl\",\n  \"cwd\": \"/current/directory\",\n  \"permission_mode\": \"default\",\n  \"hook_event_name\": \"EventName\",\n  // Event-specific fields...\n}\n```\n\n#### Output Format\n\n**Simple: Exit Codes**\n- Exit 0: Success (stdout shown in verbose mode)\n- Exit 2: Blocking error (stderr shown to Claude)\n- Other: Non-blocking error (stderr logged)\n\n**Advanced: JSON Output** (exit code 0)\n```json\n{\n  \"decision\": \"block\",\n  \"reason\": \"Explanation for Claude\",\n  \"hookSpecificOutput\": {\n    \"hookEventName\": \"PostToolUse\",\n    \"additionalContext\": \"Extra info for Claude\"\n  }\n}\n```\n\n### Phase 4: Implement the Hook\n\n#### Option A: Inline Command (Simple)\n\nFor simple operations, use inline bash/jq:\n\n```json\n{\n  \"hooks\": {\n    \"PreToolUse\": [\n      {\n        \"matcher\": \"Bash\",\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"jq -r '.tool_input.command' >> ~/.claude/bash-log.txt\"\n          }\n        ]\n      }\n    ]\n  }\n}\n```\n\n#### Option B: Python Script (Complex)\n\nFor complex logic, create a Python script:\n\n```python\n#!/usr/bin/env python3\n\"\"\"Hook script template for Claude Code.\"\"\"\nimport json\nimport sys\n\ndef main():\n    try:\n        input_data = json.load(sys.stdin)\n    except json.JSONDecodeError as e:\n        print(f\"Invalid JSON: {e}\", file=sys.stderr)\n        sys.exit(1)\n\n    # Extract common fields\n    hook_event = input_data.get(\"hook_event_name\", \"\")\n    tool_name = input_data.get(\"tool_name\", \"\")\n    tool_input = input_data.get(\"tool_input\", {})\n\n    # Your logic here...\n\n    # Option 1: Allow (exit 0, no output)\n    sys.exit(0)\n\n    # Option 2: Block with message to Claude (exit 2)\n    # print(\"Error message for Claude\", file=sys.stderr)\n    # sys.exit(2)\n\n    # Option 3: JSON output for advanced control\n    # output = {\"decision\": \"block\", \"reason\": \"My reason\"}\n    # print(json.dumps(output))\n    # sys.exit(0)\n\nif __name__ == \"__main__\":\n    main()\n```\n\n### Phase 5: Configure Hook in Settings\n\nAdd hook to `~/.claude/settings.json` (user) or `.claude/settings.json` (project):\n\n```json\n{\n  \"hooks\": {\n    \"EventName\": [\n      {\n        \"matcher\": \"ToolPattern\",\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"/path/to/hook-script.py\",\n            \"timeout\": 30\n          }\n        ]\n      }\n    ]\n  }\n}\n```\n\n**Matcher patterns:**\n- Exact match: `\"Write\"` matches only Write tool\n- Regex: `\"Edit|Write\"` matches Edit or Write\n- All tools: `\"*\"` or `\"\"`\n\n### Phase 6: Test and Debug\n\n1. Make script executable: `chmod +x /path/to/hook.py`\n2. Test manually: `echo '{\"tool_name\":\"Write\"}' | /path/to/hook.py`\n3. Run with debug: `claude --debug`\n4. Check verbose output: `Ctrl+O` in Claude Code\n\n## Common Hook Patterns\n\n### File Protection Hook (PreToolUse)\n\nBlock edits to sensitive files:\n\n```python\n#!/usr/bin/env python3\nimport json\nimport sys\n\nPROTECTED_PATTERNS = ['.env', 'package-lock.json', '.git/', 'credentials']\n\ninput_data = json.load(sys.stdin)\nfile_path = input_data.get('tool_input', {}).get('file_path', '')\n\nif any(p in file_path for p in PROTECTED_PATTERNS):\n    print(f\"Protected file: {file_path}\", file=sys.stderr)\n    sys.exit(2)\n\nsys.exit(0)\n```\n\n### Code Formatter Hook (PostToolUse)\n\nAuto-format files after editing:\n\n```python\n#!/usr/bin/env python3\nimport json\nimport sys\nimport subprocess\n\ninput_data = json.load(sys.stdin)\nfile_path = input_data.get('tool_input', {}).get('file_path', '')\n\nif file_path.endswith('.py'):\n    subprocess.run(['black', file_path], capture_output=True)\nelif file_path.endswith(('.ts', '.tsx', '.js', '.jsx')):\n    subprocess.run(['npx', 'prettier', '--write', file_path], capture_output=True)\n\nsys.exit(0)\n```\n\n### Stop Reminder Hook (Stop)\n\nRemind to store learnings:\n\n```python\n#!/usr/bin/env python3\nimport json\nimport sys\nimport random\n\ninput_data = json.load(sys.stdin)\n\n# Prevent infinite loops\nif input_data.get('stop_hook_active'):\n    sys.exit(0)\n\n# Trigger 30% of the time\nif random.random() < 0.3:\n    output = {\n        \"decision\": \"block\",\n        \"reason\": \"Consider storing any valuable learnings from this session using --store\"\n    }\n    print(json.dumps(output))\n\nsys.exit(0)\n```\n\n### Context Loader Hook (SessionStart)\n\nLoad context at session start:\n\n```python\n#!/usr/bin/env python3\nimport json\nimport sys\nimport os\n\n# Read recent git changes\nresult = os.popen('git log --oneline -5 2>/dev/null').read()\n\noutput = {\n    \"hookSpecificOutput\": {\n        \"hookEventName\": \"SessionStart\",\n        \"additionalContext\": f\"Recent commits:\\\\n{result}\"\n    }\n}\nprint(json.dumps(output))\nsys.exit(0)\n```\n\n## Decision Control Reference\n\n### PreToolUse Decisions\n\n```json\n{\n  \"hookSpecificOutput\": {\n    \"hookEventName\": \"PreToolUse\",\n    \"permissionDecision\": \"allow|deny|ask\",\n    \"permissionDecisionReason\": \"Reason shown to user/Claude\",\n    \"updatedInput\": {\"field\": \"modified_value\"}\n  }\n}\n```\n\n### PostToolUse Decisions\n\n```json\n{\n  \"decision\": \"block\",\n  \"reason\": \"Reason shown to Claude\",\n  \"hookSpecificOutput\": {\n    \"hookEventName\": \"PostToolUse\",\n    \"additionalContext\": \"Extra context for Claude\"\n  }\n}\n```\n\n### Stop/SubagentStop Decisions\n\n```json\n{\n  \"decision\": \"block\",\n  \"reason\": \"Must continue because...\"\n}\n```\n\n## State Management Pattern\n\nFor hooks that need to track state across invocations:\n\n```python\n#!/usr/bin/env python3\nimport json\nimport sys\nimport os\nfrom datetime import datetime\n\nSTATE_FILE = os.path.expanduser(\"~/.claude/hook_state.json\")\n\ndef load_state():\n    if os.path.exists(STATE_FILE):\n        with open(STATE_FILE) as f:\n            return json.load(f)\n    return {\"invocations\": 0, \"last_run\": None}\n\ndef save_state(state):\n    with open(STATE_FILE, 'w') as f:\n        json.dump(state, f)\n\nstate = load_state()\nstate[\"invocations\"] += 1\nstate[\"last_run\"] = datetime.now().isoformat()\nsave_state(state)\n\n# Use state in hook logic...\n```\n\n## Production-Ready Examples\n\nThis skill includes **real working hooks** from production use. Read these files for complete, battle-tested implementations.\n\n### examples/memory_store_reminder.py (Stop Hook)\n\nA sophisticated Stop hook that reminds Claude to store learnings after completing tasks.\n\n**Key Features:**\n- Probability-based execution (33% trigger rate)\n- State persistence across sessions\n- Cooldown management (configurable, disabled for multi-session workflows)\n- Multiple infinite loop prevention mechanisms\n- Session tracking\n\n**Configuration:**\n```json\n{\n  \"hooks\": {\n    \"Stop\": [\n      {\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"~/.claude/hooks/memory_store_reminder.py\",\n            \"timeout\": 10\n          }\n        ]\n      }\n    ]\n  }\n}\n```\n\n**Test command:**\n```bash\necho '{\"session_id\": \"test\", \"stop_hook_active\": false}' | ./examples/memory_store_reminder.py\n```\n\n### examples/todowrite_first_call.py (PostToolUse Hook)\n\nA PostToolUse hook that detects the first TodoWrite call for each new task and triggers memory recall.\n\n**Key Features:**\n- Detects first call by checking if `oldTodos` is empty\n- State persistence with cooldown support\n- Structured JSON output with `hookSpecificOutput`\n- Debug logging to stderr\n\n**Configuration:**\n```json\n{\n  \"hooks\": {\n    \"PostToolUse\": [\n      {\n        \"matcher\": \"TodoWrite\",\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"~/.claude/hooks/todowrite_first_call.py\",\n            \"timeout\": 5\n          }\n        ]\n      }\n    ]\n  }\n}\n```\n\n**Test command:**\n```bash\necho '{\"tool_input\": {\"todos\": [{\"status\": \"pending\"}]}, \"tool_response\": {\"oldTodos\": []}}' | ./examples/todowrite_first_call.py\n```\n\n### examples/hooks_readme.md\n\nDocumentation explaining the workflow these hooks support, configuration details, and troubleshooting tips.\n\n## Resources\n\n### references/\n\nComplete Claude Code hooks documentation:\n\n- `cc_hooks_getting_started.md` - Quickstart guide with practical examples\n- `cc_hooks_ref.md` - Complete reference documentation with all hook events, input/output formats, and advanced patterns\n\nTo get detailed information about specific hook events or patterns, read these reference files.\n\n### examples/\n\nProduction-ready hook implementations:\n\n- `memory_store_reminder.py` - Stop hook with probability execution and state management\n- `todowrite_first_call.py` - PostToolUse hook with first-call detection\n- `hooks_readme.md` - Documentation for the example hooks\n\nThese examples demonstrate advanced patterns like state persistence, cooldowns, probability-based execution, and structured JSON output.\n\n## Security Considerations\n\n- Hooks run with your user permissions - they can access any files you can\n- Always validate and sanitize input data\n- Quote shell variables: use `\"$VAR\"` not `$VAR`\n- Block path traversal by checking for `..` in paths\n- Skip sensitive files like `.env`, credentials, keys\n- Use absolute paths for scripts\n- Test hooks in safe environments before production use"
              },
              {
                "name": "mcp-builder",
                "description": "Guide for creating high-quality MCP (Model Context Protocol) servers that enable LLMs to interact with external services through well-designed tools. Use when building MCP servers to integrate external APIs or services, whether in Python (FastMCP) or Node/TypeScript (MCP SDK).",
                "path": "plugins/dev-tools/skills/mcp-builder/SKILL.md",
                "frontmatter": {
                  "name": "mcp-builder",
                  "description": "Guide for creating high-quality MCP (Model Context Protocol) servers that enable LLMs to interact with external services through well-designed tools. Use when building MCP servers to integrate external APIs or services, whether in Python (FastMCP) or Node/TypeScript (MCP SDK).",
                  "license": "Complete terms in LICENSE.txt"
                },
                "content": "# MCP Server Development Guide\n\n## Overview\n\nCreate MCP (Model Context Protocol) servers that enable LLMs to interact with external services through well-designed tools. The quality of an MCP server is measured by how well it enables LLMs to accomplish real-world tasks.\n\n---\n\n# Process\n\n## 🚀 High-Level Workflow\n\nCreating a high-quality MCP server involves four main phases:\n\n### Phase 1: Deep Research and Planning\n\n#### 1.1 Understand Modern MCP Design\n\n**API Coverage vs. Workflow Tools:**\nBalance comprehensive API endpoint coverage with specialized workflow tools. Workflow tools can be more convenient for specific tasks, while comprehensive coverage gives agents flexibility to compose operations. Performance varies by client—some clients benefit from code execution that combines basic tools, while others work better with higher-level workflows. When uncertain, prioritize comprehensive API coverage.\n\n**Tool Naming and Discoverability:**\nClear, descriptive tool names help agents find the right tools quickly. Use consistent prefixes (e.g., `github_create_issue`, `github_list_repos`) and action-oriented naming.\n\n**Context Management:**\nAgents benefit from concise tool descriptions and the ability to filter/paginate results. Design tools that return focused, relevant data. Some clients support code execution which can help agents filter and process data efficiently.\n\n**Actionable Error Messages:**\nError messages should guide agents toward solutions with specific suggestions and next steps.\n\n#### 1.2 Study MCP Protocol Documentation\n\n**Navigate the MCP specification:**\n\nStart with the sitemap to find relevant pages: `https://modelcontextprotocol.io/sitemap.xml`\n\nThen fetch specific pages with `.md` suffix for markdown format (e.g., `https://modelcontextprotocol.io/specification/draft.md`).\n\nKey pages to review:\n- Specification overview and architecture\n- Transport mechanisms (streamable HTTP, stdio)\n- Tool, resource, and prompt definitions\n\n#### 1.3 Study Framework Documentation\n\n**Recommended stack:**\n- **Language**: TypeScript (high-quality SDK support and good compatibility in many execution environments e.g. MCPB. Plus AI models are good at generating TypeScript code, benefiting from its broad usage, static typing and good linting tools)\n- **Transport**: Streamable HTTP for remote servers, using stateless JSON (simpler to scale and maintain, as opposed to stateful sessions and streaming responses). stdio for local servers.\n\n**Load framework documentation:**\n\n- **MCP Best Practices**: [📋 View Best Practices](./reference/mcp_best_practices.md) - Core guidelines\n\n**For TypeScript (recommended):**\n- **TypeScript SDK**: Use WebFetch to load `https://raw.githubusercontent.com/modelcontextprotocol/typescript-sdk/main/README.md`\n- [⚡ TypeScript Guide](./reference/node_mcp_server.md) - TypeScript patterns and examples\n\n**For Python:**\n- **Python SDK**: Use WebFetch to load `https://raw.githubusercontent.com/modelcontextprotocol/python-sdk/main/README.md`\n- [🐍 Python Guide](./reference/python_mcp_server.md) - Python patterns and examples\n\n#### 1.4 Plan Your Implementation\n\n**Understand the API:**\nReview the service's API documentation to identify key endpoints, authentication requirements, and data models. Use web search and WebFetch as needed.\n\n**Tool Selection:**\nPrioritize comprehensive API coverage. List endpoints to implement, starting with the most common operations.\n\n---\n\n### Phase 2: Implementation\n\n#### 2.1 Set Up Project Structure\n\nSee language-specific guides for project setup:\n- [⚡ TypeScript Guide](./reference/node_mcp_server.md) - Project structure, package.json, tsconfig.json\n- [🐍 Python Guide](./reference/python_mcp_server.md) - Module organization, dependencies\n\n#### 2.2 Implement Core Infrastructure\n\nCreate shared utilities:\n- API client with authentication\n- Error handling helpers\n- Response formatting (JSON/Markdown)\n- Pagination support\n\n#### 2.3 Implement Tools\n\nFor each tool:\n\n**Input Schema:**\n- Use Zod (TypeScript) or Pydantic (Python)\n- Include constraints and clear descriptions\n- Add examples in field descriptions\n\n**Output Schema:**\n- Define `outputSchema` where possible for structured data\n- Use `structuredContent` in tool responses (TypeScript SDK feature)\n- Helps clients understand and process tool outputs\n\n**Tool Description:**\n- Concise summary of functionality\n- Parameter descriptions\n- Return type schema\n\n**Implementation:**\n- Async/await for I/O operations\n- Proper error handling with actionable messages\n- Support pagination where applicable\n- Return both text content and structured data when using modern SDKs\n\n**Annotations:**\n- `readOnlyHint`: true/false\n- `destructiveHint`: true/false\n- `idempotentHint`: true/false\n- `openWorldHint`: true/false\n\n---\n\n### Phase 3: Review and Test\n\n#### 3.1 Code Quality\n\nReview for:\n- No duplicated code (DRY principle)\n- Consistent error handling\n- Full type coverage\n- Clear tool descriptions\n\n#### 3.2 Build and Test\n\n**TypeScript:**\n- Run `npm run build` to verify compilation\n- Test with MCP Inspector: `npx @modelcontextprotocol/inspector`\n\n**Python:**\n- Verify syntax: `python -m py_compile your_server.py`\n- Test with MCP Inspector\n\nSee language-specific guides for detailed testing approaches and quality checklists.\n\n---\n\n### Phase 4: Create Evaluations\n\nAfter implementing your MCP server, create comprehensive evaluations to test its effectiveness.\n\n**Load [✅ Evaluation Guide](./reference/evaluation.md) for complete evaluation guidelines.**\n\n#### 4.1 Understand Evaluation Purpose\n\nUse evaluations to test whether LLMs can effectively use your MCP server to answer realistic, complex questions.\n\n#### 4.2 Create 10 Evaluation Questions\n\nTo create effective evaluations, follow the process outlined in the evaluation guide:\n\n1. **Tool Inspection**: List available tools and understand their capabilities\n2. **Content Exploration**: Use READ-ONLY operations to explore available data\n3. **Question Generation**: Create 10 complex, realistic questions\n4. **Answer Verification**: Solve each question yourself to verify answers\n\n#### 4.3 Evaluation Requirements\n\nEnsure each question is:\n- **Independent**: Not dependent on other questions\n- **Read-only**: Only non-destructive operations required\n- **Complex**: Requiring multiple tool calls and deep exploration\n- **Realistic**: Based on real use cases humans would care about\n- **Verifiable**: Single, clear answer that can be verified by string comparison\n- **Stable**: Answer won't change over time\n\n#### 4.4 Output Format\n\nCreate an XML file with this structure:\n\n```xml\n<evaluation>\n  <qa_pair>\n    <question>Find discussions about AI model launches with animal codenames. One model needed a specific safety designation that uses the format ASL-X. What number X was being determined for the model named after a spotted wild cat?</question>\n    <answer>3</answer>\n  </qa_pair>\n<!-- More qa_pairs... -->\n</evaluation>\n```\n\n---\n\n# Reference Files\n\n## 📚 Documentation Library\n\nLoad these resources as needed during development:\n\n### Core MCP Documentation (Load First)\n- **MCP Protocol**: Start with sitemap at `https://modelcontextprotocol.io/sitemap.xml`, then fetch specific pages with `.md` suffix\n- [📋 MCP Best Practices](./reference/mcp_best_practices.md) - Universal MCP guidelines including:\n  - Server and tool naming conventions\n  - Response format guidelines (JSON vs Markdown)\n  - Pagination best practices\n  - Transport selection (streamable HTTP vs stdio)\n  - Security and error handling standards\n\n### SDK Documentation (Load During Phase 1/2)\n- **Python SDK**: Fetch from `https://raw.githubusercontent.com/modelcontextprotocol/python-sdk/main/README.md`\n- **TypeScript SDK**: Fetch from `https://raw.githubusercontent.com/modelcontextprotocol/typescript-sdk/main/README.md`\n\n### Language-Specific Implementation Guides (Load During Phase 2)\n- [🐍 Python Implementation Guide](./reference/python_mcp_server.md) - Complete Python/FastMCP guide with:\n  - Server initialization patterns\n  - Pydantic model examples\n  - Tool registration with `@mcp.tool`\n  - Complete working examples\n  - Quality checklist\n\n- [⚡ TypeScript Implementation Guide](./reference/node_mcp_server.md) - Complete TypeScript guide with:\n  - Project structure\n  - Zod schema patterns\n  - Tool registration with `server.registerTool`\n  - Complete working examples\n  - Quality checklist\n\n### Evaluation Guide (Load During Phase 4)\n- [✅ Evaluation Guide](./reference/evaluation.md) - Complete evaluation creation guide with:\n  - Question creation guidelines\n  - Answer verification strategies\n  - XML format specifications\n  - Example questions and answers\n  - Running an evaluation with the provided scripts"
              },
              {
                "name": "skill-creator",
                "description": "Guide for creating effective skills. This skill should be used when users want to create a new skill (or update an existing skill) that extends Claude's capabilities with specialized knowledge, workflows, or tool integrations.",
                "path": "plugins/dev-tools/skills/skill-creator/SKILL.md",
                "frontmatter": {
                  "name": "skill-creator",
                  "description": "Guide for creating effective skills. This skill should be used when users want to create a new skill (or update an existing skill) that extends Claude's capabilities with specialized knowledge, workflows, or tool integrations.",
                  "license": "Complete terms in LICENSE.txt"
                },
                "content": "# Skill Creator\n\nThis skill provides guidance for creating effective skills.\n\n## About Skills\n\nSkills are modular, self-contained packages that extend Claude's capabilities by providing\nspecialized knowledge, workflows, and tools. Think of them as \"onboarding guides\" for specific\ndomains or tasks—they transform Claude from a general-purpose agent into a specialized agent\nequipped with procedural knowledge that no model can fully possess.\n\n### What Skills Provide\n\n1. Specialized workflows - Multi-step procedures for specific domains\n2. Tool integrations - Instructions for working with specific file formats or APIs\n3. Domain expertise - Company-specific knowledge, schemas, business logic\n4. Bundled resources - Scripts, references, and assets for complex and repetitive tasks\n\n## Core Principles\n\n### Concise is Key\n\nThe context window is a public good. Skills share the context window with everything else Claude needs: system prompt, conversation history, other Skills' metadata, and the actual user request.\n\n**Default assumption: Claude is already very smart.** Only add context Claude doesn't already have. Challenge each piece of information: \"Does Claude really need this explanation?\" and \"Does this paragraph justify its token cost?\"\n\nPrefer concise examples over verbose explanations.\n\n### Set Appropriate Degrees of Freedom\n\nMatch the level of specificity to the task's fragility and variability:\n\n**High freedom (text-based instructions)**: Use when multiple approaches are valid, decisions depend on context, or heuristics guide the approach.\n\n**Medium freedom (pseudocode or scripts with parameters)**: Use when a preferred pattern exists, some variation is acceptable, or configuration affects behavior.\n\n**Low freedom (specific scripts, few parameters)**: Use when operations are fragile and error-prone, consistency is critical, or a specific sequence must be followed.\n\nThink of Claude as exploring a path: a narrow bridge with cliffs needs specific guardrails (low freedom), while an open field allows many routes (high freedom).\n\n### Anatomy of a Skill\n\nEvery skill consists of a required SKILL.md file and optional bundled resources:\n\n```\nskill-name/\n├── SKILL.md (required)\n│   ├── YAML frontmatter metadata (required)\n│   │   ├── name: (required)\n│   │   └── description: (required)\n│   └── Markdown instructions (required)\n└── Bundled Resources (optional)\n    ├── scripts/          - Executable code (Python/Bash/etc.)\n    ├── references/       - Documentation intended to be loaded into context as needed\n    └── assets/           - Files used in output (templates, icons, fonts, etc.)\n```\n\n#### SKILL.md (required)\n\nEvery SKILL.md consists of:\n\n- **Frontmatter** (YAML): Contains `name` and `description` fields. These are the only fields that Claude reads to determine when the skill gets used, thus it is very important to be clear and comprehensive in describing what the skill is, and when it should be used.\n- **Body** (Markdown): Instructions and guidance for using the skill. Only loaded AFTER the skill triggers (if at all).\n\n#### Bundled Resources (optional)\n\n##### Scripts (`scripts/`)\n\nExecutable code (Python/Bash/etc.) for tasks that require deterministic reliability or are repeatedly rewritten.\n\n- **When to include**: When the same code is being rewritten repeatedly or deterministic reliability is needed\n- **Example**: `scripts/rotate_pdf.py` for PDF rotation tasks\n- **Benefits**: Token efficient, deterministic, may be executed without loading into context\n- **Note**: Scripts may still need to be read by Claude for patching or environment-specific adjustments\n\n##### References (`references/`)\n\nDocumentation and reference material intended to be loaded as needed into context to inform Claude's process and thinking.\n\n- **When to include**: For documentation that Claude should reference while working\n- **Examples**: `references/finance.md` for financial schemas, `references/mnda.md` for company NDA template, `references/policies.md` for company policies, `references/api_docs.md` for API specifications\n- **Use cases**: Database schemas, API documentation, domain knowledge, company policies, detailed workflow guides\n- **Benefits**: Keeps SKILL.md lean, loaded only when Claude determines it's needed\n- **Best practice**: If files are large (>10k words), include grep search patterns in SKILL.md\n- **Avoid duplication**: Information should live in either SKILL.md or references files, not both. Prefer references files for detailed information unless it's truly core to the skill—this keeps SKILL.md lean while making information discoverable without hogging the context window. Keep only essential procedural instructions and workflow guidance in SKILL.md; move detailed reference material, schemas, and examples to references files.\n\n##### Assets (`assets/`)\n\nFiles not intended to be loaded into context, but rather used within the output Claude produces.\n\n- **When to include**: When the skill needs files that will be used in the final output\n- **Examples**: `assets/logo.png` for brand assets, `assets/slides.pptx` for PowerPoint templates, `assets/frontend-template/` for HTML/React boilerplate, `assets/font.ttf` for typography\n- **Use cases**: Templates, images, icons, boilerplate code, fonts, sample documents that get copied or modified\n- **Benefits**: Separates output resources from documentation, enables Claude to use files without loading them into context\n\n#### What to Not Include in a Skill\n\nA skill should only contain essential files that directly support its functionality. Do NOT create extraneous documentation or auxiliary files, including:\n\n- README.md\n- INSTALLATION_GUIDE.md\n- QUICK_REFERENCE.md\n- CHANGELOG.md\n- etc.\n\nThe skill should only contain the information needed for an AI agent to do the job at hand. It should not contain auxilary context about the process that went into creating it, setup and testing procedures, user-facing documentation, etc. Creating additional documentation files just adds clutter and confusion.\n\n### Progressive Disclosure Design Principle\n\nSkills use a three-level loading system to manage context efficiently:\n\n1. **Metadata (name + description)** - Always in context (~100 words)\n2. **SKILL.md body** - When skill triggers (<5k words)\n3. **Bundled resources** - As needed by Claude (Unlimited because scripts can be executed without reading into context window)\n\n#### Progressive Disclosure Patterns\n\nKeep SKILL.md body to the essentials and under 500 lines to minimize context bloat. Split content into separate files when approaching this limit. When splitting out content into other files, it is very important to reference them from SKILL.md and describe clearly when to read them, to ensure the reader of the skill knows they exist and when to use them.\n\n**Key principle:** When a skill supports multiple variations, frameworks, or options, keep only the core workflow and selection guidance in SKILL.md. Move variant-specific details (patterns, examples, configuration) into separate reference files.\n\n**Pattern 1: High-level guide with references**\n\n```markdown\n# PDF Processing\n\n## Quick start\n\nExtract text with pdfplumber:\n[code example]\n\n## Advanced features\n\n- **Form filling**: See [FORMS.md](FORMS.md) for complete guide\n- **API reference**: See [REFERENCE.md](REFERENCE.md) for all methods\n- **Examples**: See [EXAMPLES.md](EXAMPLES.md) for common patterns\n```\n\nClaude loads FORMS.md, REFERENCE.md, or EXAMPLES.md only when needed.\n\n**Pattern 2: Domain-specific organization**\n\nFor Skills with multiple domains, organize content by domain to avoid loading irrelevant context:\n\n```\nbigquery-skill/\n├── SKILL.md (overview and navigation)\n└── reference/\n    ├── finance.md (revenue, billing metrics)\n    ├── sales.md (opportunities, pipeline)\n    ├── product.md (API usage, features)\n    └── marketing.md (campaigns, attribution)\n```\n\nWhen a user asks about sales metrics, Claude only reads sales.md.\n\nSimilarly, for skills supporting multiple frameworks or variants, organize by variant:\n\n```\ncloud-deploy/\n├── SKILL.md (workflow + provider selection)\n└── references/\n    ├── aws.md (AWS deployment patterns)\n    ├── gcp.md (GCP deployment patterns)\n    └── azure.md (Azure deployment patterns)\n```\n\nWhen the user chooses AWS, Claude only reads aws.md.\n\n**Pattern 3: Conditional details**\n\nShow basic content, link to advanced content:\n\n```markdown\n# DOCX Processing\n\n## Creating documents\n\nUse docx-js for new documents. See [DOCX-JS.md](DOCX-JS.md).\n\n## Editing documents\n\nFor simple edits, modify the XML directly.\n\n**For tracked changes**: See [REDLINING.md](REDLINING.md)\n**For OOXML details**: See [OOXML.md](OOXML.md)\n```\n\nClaude reads REDLINING.md or OOXML.md only when the user needs those features.\n\n**Important guidelines:**\n\n- **Avoid deeply nested references** - Keep references one level deep from SKILL.md. All reference files should link directly from SKILL.md.\n- **Structure longer reference files** - For files longer than 100 lines, include a table of contents at the top so Claude can see the full scope when previewing.\n\n## Skill Creation Process\n\nSkill creation involves these steps:\n\n1. Understand the skill with concrete examples\n2. Plan reusable skill contents (scripts, references, assets)\n3. Initialize the skill (run init_skill.py)\n4. Edit the skill (implement resources and write SKILL.md)\n5. Package the skill (run package_skill.py)\n6. Iterate based on real usage\n\nFollow these steps in order, skipping only if there is a clear reason why they are not applicable.\n\n### Step 1: Understanding the Skill with Concrete Examples\n\nSkip this step only when the skill's usage patterns are already clearly understood. It remains valuable even when working with an existing skill.\n\nTo create an effective skill, clearly understand concrete examples of how the skill will be used. This understanding can come from either direct user examples or generated examples that are validated with user feedback.\n\nFor example, when building an image-editor skill, relevant questions include:\n\n- \"What functionality should the image-editor skill support? Editing, rotating, anything else?\"\n- \"Can you give some examples of how this skill would be used?\"\n- \"I can imagine users asking for things like 'Remove the red-eye from this image' or 'Rotate this image'. Are there other ways you imagine this skill being used?\"\n- \"What would a user say that should trigger this skill?\"\n\nTo avoid overwhelming users, avoid asking too many questions in a single message. Start with the most important questions and follow up as needed for better effectiveness.\n\nConclude this step when there is a clear sense of the functionality the skill should support.\n\n### Step 2: Planning the Reusable Skill Contents\n\nTo turn concrete examples into an effective skill, analyze each example by:\n\n1. Considering how to execute on the example from scratch\n2. Identifying what scripts, references, and assets would be helpful when executing these workflows repeatedly\n\nExample: When building a `pdf-editor` skill to handle queries like \"Help me rotate this PDF,\" the analysis shows:\n\n1. Rotating a PDF requires re-writing the same code each time\n2. A `scripts/rotate_pdf.py` script would be helpful to store in the skill\n\nExample: When designing a `frontend-webapp-builder` skill for queries like \"Build me a todo app\" or \"Build me a dashboard to track my steps,\" the analysis shows:\n\n1. Writing a frontend webapp requires the same boilerplate HTML/React each time\n2. An `assets/hello-world/` template containing the boilerplate HTML/React project files would be helpful to store in the skill\n\nExample: When building a `big-query` skill to handle queries like \"How many users have logged in today?\" the analysis shows:\n\n1. Querying BigQuery requires re-discovering the table schemas and relationships each time\n2. A `references/schema.md` file documenting the table schemas would be helpful to store in the skill\n\nTo establish the skill's contents, analyze each concrete example to create a list of the reusable resources to include: scripts, references, and assets.\n\n### Step 3: Initializing the Skill\n\nAt this point, it is time to actually create the skill.\n\nSkip this step only if the skill being developed already exists, and iteration or packaging is needed. In this case, continue to the next step.\n\nWhen creating a new skill from scratch, always run the `init_skill.py` script. The script conveniently generates a new template skill directory that automatically includes everything a skill requires, making the skill creation process much more efficient and reliable.\n\nUsage:\n\n```bash\nscripts/init_skill.py <skill-name> --path <output-directory>\n```\n\nThe script:\n\n- Creates the skill directory at the specified path\n- Generates a SKILL.md template with proper frontmatter and TODO placeholders\n- Creates example resource directories: `scripts/`, `references/`, and `assets/`\n- Adds example files in each directory that can be customized or deleted\n\nAfter initialization, customize or remove the generated SKILL.md and example files as needed.\n\n### Step 4: Edit the Skill\n\nWhen editing the (newly-generated or existing) skill, remember that the skill is being created for another instance of Claude to use. Include information that would be beneficial and non-obvious to Claude. Consider what procedural knowledge, domain-specific details, or reusable assets would help another Claude instance execute these tasks more effectively.\n\n#### Learn Proven Design Patterns\n\nConsult these helpful guides based on your skill's needs:\n\n- **Multi-step processes**: See references/workflows.md for sequential workflows and conditional logic\n- **Specific output formats or quality standards**: See references/output-patterns.md for template and example patterns\n\nThese files contain established best practices for effective skill design.\n\n#### Start with Reusable Skill Contents\n\nTo begin implementation, start with the reusable resources identified above: `scripts/`, `references/`, and `assets/` files. Note that this step may require user input. For example, when implementing a `brand-guidelines` skill, the user may need to provide brand assets or templates to store in `assets/`, or documentation to store in `references/`.\n\nAdded scripts must be tested by actually running them to ensure there are no bugs and that the output matches what is expected. If there are many similar scripts, only a representative sample needs to be tested to ensure confidence that they all work while balancing time to completion.\n\nAny example files and directories not needed for the skill should be deleted. The initialization script creates example files in `scripts/`, `references/`, and `assets/` to demonstrate structure, but most skills won't need all of them.\n\n#### Update SKILL.md\n\n**Writing Guidelines:** Always use imperative/infinitive form.\n\n##### Frontmatter\n\nWrite the YAML frontmatter with `name` and `description`:\n\n- `name`: The skill name\n- `description`: This is the primary triggering mechanism for your skill, and helps Claude understand when to use the skill.\n  - Include both what the Skill does and specific triggers/contexts for when to use it.\n  - Include all \"when to use\" information here - Not in the body. The body is only loaded after triggering, so \"When to Use This Skill\" sections in the body are not helpful to Claude.\n  - Example description for a `docx` skill: \"Comprehensive document creation, editing, and analysis with support for tracked changes, comments, formatting preservation, and text extraction. Use when Claude needs to work with professional documents (.docx files) for: (1) Creating new documents, (2) Modifying or editing content, (3) Working with tracked changes, (4) Adding comments, or any other document tasks\"\n\nDo not include any other fields in YAML frontmatter.\n\n##### Body\n\nWrite instructions for using the skill and its bundled resources.\n\n### Step 5: Packaging a Skill\n\nOnce development of the skill is complete, it must be packaged into a distributable .skill file that gets shared with the user. The packaging process automatically validates the skill first to ensure it meets all requirements:\n\n```bash\nscripts/package_skill.py <path/to/skill-folder>\n```\n\nOptional output directory specification:\n\n```bash\nscripts/package_skill.py <path/to/skill-folder> ./dist\n```\n\nThe packaging script will:\n\n1. **Validate** the skill automatically, checking:\n\n   - YAML frontmatter format and required fields\n   - Skill naming conventions and directory structure\n   - Description completeness and quality\n   - File organization and resource references\n\n2. **Package** the skill if validation passes, creating a .skill file named after the skill (e.g., `my-skill.skill`) that includes all files and maintains the proper directory structure for distribution. The .skill file is a zip file with a .skill extension.\n\nIf validation fails, the script will report the errors and exit without creating a package. Fix any validation errors and run the packaging command again.\n\n### Step 6: Iterate\n\nAfter testing the skill, users may request improvements. Often this happens right after using the skill, with fresh context of how the skill performed.\n\n**Iteration workflow:**\n\n1. Use the skill on real tasks\n2. Notice struggles or inefficiencies\n3. Identify how SKILL.md or bundled resources should be updated\n4. Implement changes and test again"
              },
              {
                "name": "webapp-testing",
                "description": "Toolkit for interacting with and testing local web applications using Playwright. Supports verifying frontend functionality, debugging UI behavior, capturing browser screenshots, and viewing browser logs.",
                "path": "plugins/dev-tools/skills/webapp-testing/SKILL.md",
                "frontmatter": {
                  "name": "webapp-testing",
                  "description": "Toolkit for interacting with and testing local web applications using Playwright. Supports verifying frontend functionality, debugging UI behavior, capturing browser screenshots, and viewing browser logs.",
                  "license": "Complete terms in LICENSE.txt"
                },
                "content": "# Web Application Testing\n\nTo test local web applications, write native Python Playwright scripts.\n\n**Helper Scripts Available**:\n- `scripts/with_server.py` - Manages server lifecycle (supports multiple servers)\n\n**Always run scripts with `--help` first** to see usage. DO NOT read the source until you try running the script first and find that a customized solution is abslutely necessary. These scripts can be very large and thus pollute your context window. They exist to be called directly as black-box scripts rather than ingested into your context window.\n\n## Decision Tree: Choosing Your Approach\n\n```\nUser task → Is it static HTML?\n    ├─ Yes → Read HTML file directly to identify selectors\n    │         ├─ Success → Write Playwright script using selectors\n    │         └─ Fails/Incomplete → Treat as dynamic (below)\n    │\n    └─ No (dynamic webapp) → Is the server already running?\n        ├─ No → Run: python scripts/with_server.py --help\n        │        Then use the helper + write simplified Playwright script\n        │\n        └─ Yes → Reconnaissance-then-action:\n            1. Navigate and wait for networkidle\n            2. Take screenshot or inspect DOM\n            3. Identify selectors from rendered state\n            4. Execute actions with discovered selectors\n```\n\n## Example: Using with_server.py\n\nTo start a server, run `--help` first, then use the helper:\n\n**Single server:**\n```bash\npython scripts/with_server.py --server \"npm run dev\" --port 5173 -- python your_automation.py\n```\n\n**Multiple servers (e.g., backend + frontend):**\n```bash\npython scripts/with_server.py \\\n  --server \"cd backend && python server.py\" --port 3000 \\\n  --server \"cd frontend && npm run dev\" --port 5173 \\\n  -- python your_automation.py\n```\n\nTo create an automation script, include only Playwright logic (servers are managed automatically):\n```python\nfrom playwright.sync_api import sync_playwright\n\nwith sync_playwright() as p:\n    browser = p.chromium.launch(headless=True) # Always launch chromium in headless mode\n    page = browser.new_page()\n    page.goto('http://localhost:5173') # Server already running and ready\n    page.wait_for_load_state('networkidle') # CRITICAL: Wait for JS to execute\n    # ... your automation logic\n    browser.close()\n```\n\n## Reconnaissance-Then-Action Pattern\n\n1. **Inspect rendered DOM**:\n   ```python\n   page.screenshot(path='/tmp/inspect.png', full_page=True)\n   content = page.content()\n   page.locator('button').all()\n   ```\n\n2. **Identify selectors** from inspection results\n\n3. **Execute actions** using discovered selectors\n\n## Common Pitfall\n\n❌ **Don't** inspect the DOM before waiting for `networkidle` on dynamic apps\n✅ **Do** wait for `page.wait_for_load_state('networkidle')` before inspection\n\n## Best Practices\n\n- **Use bundled scripts as black boxes** - To accomplish a task, consider whether one of the scripts available in `scripts/` can help. These scripts handle common, complex workflows reliably without cluttering the context window. Use `--help` to see usage, then invoke directly. \n- Use `sync_playwright()` for synchronous scripts\n- Always close the browser when done\n- Use descriptive selectors: `text=`, `role=`, CSS selectors, or IDs\n- Add appropriate waits: `page.wait_for_selector()` or `page.wait_for_timeout()`\n\n## Reference Files\n\n- **examples/** - Examples showing common patterns:\n  - `element_discovery.py` - Discovering buttons, links, and inputs on a page\n  - `static_html_automation.py` - Using file:// URLs for local HTML\n  - `console_logging.py` - Capturing console logs during automation"
              }
            ]
          },
          {
            "name": "design-studio",
            "description": "Design tools for UI/UX, frontend design, and visual assets",
            "source": "./plugins/design-studio",
            "category": "design",
            "version": "1.0.0",
            "author": null,
            "install_commands": [
              "/plugin marketplace add hongbietcode/synthetic-claude",
              "/plugin install design-studio@synthetic-claude"
            ],
            "signals": {
              "stars": 1,
              "forks": 0,
              "pushed_at": "2026-01-07T17:25:07Z",
              "created_at": "2025-12-28T07:34:15Z",
              "license": null
            },
            "commands": [
              {
                "name": "/design-guide",
                "description": null,
                "path": "plugins/design-studio/commands/design-guide.md",
                "frontmatter": null,
                "content": "```markdown\n# Design Discussion Command\n\nAnalyze and discuss design improvements for $FILES without modifying any code.\nMy concern: $CONCERNS\n\n## Process\n\n### 1. Understanding Phase\n- Read and analyze the structure, patterns, and relationships in $FILES\n- Identify current design approach and architectural decisions\n- Note any specific $CONCERNS mentioned in the request\n\n### 2. Discussion Framework\n- **Current State**: Summarize existing design and architecture\n- **Pain Points**: Identify potential issues, bottlenecks, or concerns\n- **Design Alternatives**: Propose different approaches with trade-offs\n- **Best Practices**: Suggest relevant patterns, principles, or industry standards\n- **Impact Analysis**: Discuss implications of potential changes\n\n### 3. Interactive Exploration\n- Ask clarifying questions about specific concerns\n- Explore multiple solution paths\n- Discuss pros/cons of different approaches\n- Consider maintainability, scalability, and team context\n\n## Focus Areas\n- Architecture and structure\n- Design patterns and principles\n- Code organization and modularity\n- Performance and scalability considerations\n- Maintainability and extensibility\n- Team workflow and development experience\n\n## Guidelines\n- **CRITICAL**: NO code modifications - discussion only\n- Focus on the specific concerns raised\n- Provide concrete examples and reasoning\n- Consider both immediate and long-term implications\n- Keep discussions practical and actionable\n\n## Goal\nCollaborative design exploration to improve code quality and address specific concerns through discussion and analysis.\n```"
              }
            ],
            "skills": [
              {
                "name": "algorithmic-art",
                "description": "Creating algorithmic art using p5.js with seeded randomness and interactive parameter exploration. Use this when users request creating art using code, generative art, algorithmic art, flow fields, or particle systems. Create original algorithmic art rather than copying existing artists' work to avoid copyright violations.",
                "path": "plugins/design-studio/skills/algorithmic-art/SKILL.md",
                "frontmatter": {
                  "name": "algorithmic-art",
                  "description": "Creating algorithmic art using p5.js with seeded randomness and interactive parameter exploration. Use this when users request creating art using code, generative art, algorithmic art, flow fields, or particle systems. Create original algorithmic art rather than copying existing artists' work to avoid copyright violations.",
                  "license": "Complete terms in LICENSE.txt"
                },
                "content": "Algorithmic philosophies are computational aesthetic movements that are then expressed through code. Output .md files (philosophy), .html files (interactive viewer), and .js files (generative algorithms).\n\nThis happens in two steps:\n1. Algorithmic Philosophy Creation (.md file)\n2. Express by creating p5.js generative art (.html + .js files)\n\nFirst, undertake this task:\n\n## ALGORITHMIC PHILOSOPHY CREATION\n\nTo begin, create an ALGORITHMIC PHILOSOPHY (not static images or templates) that will be interpreted through:\n- Computational processes, emergent behavior, mathematical beauty\n- Seeded randomness, noise fields, organic systems\n- Particles, flows, fields, forces\n- Parametric variation and controlled chaos\n\n### THE CRITICAL UNDERSTANDING\n- What is received: Some subtle input or instructions by the user to take into account, but use as a foundation; it should not constrain creative freedom.\n- What is created: An algorithmic philosophy/generative aesthetic movement.\n- What happens next: The same version receives the philosophy and EXPRESSES IT IN CODE - creating p5.js sketches that are 90% algorithmic generation, 10% essential parameters.\n\nConsider this approach:\n- Write a manifesto for a generative art movement\n- The next phase involves writing the algorithm that brings it to life\n\nThe philosophy must emphasize: Algorithmic expression. Emergent behavior. Computational beauty. Seeded variation.\n\n### HOW TO GENERATE AN ALGORITHMIC PHILOSOPHY\n\n**Name the movement** (1-2 words): \"Organic Turbulence\" / \"Quantum Harmonics\" / \"Emergent Stillness\"\n\n**Articulate the philosophy** (4-6 paragraphs - concise but complete):\n\nTo capture the ALGORITHMIC essence, express how this philosophy manifests through:\n- Computational processes and mathematical relationships?\n- Noise functions and randomness patterns?\n- Particle behaviors and field dynamics?\n- Temporal evolution and system states?\n- Parametric variation and emergent complexity?\n\n**CRITICAL GUIDELINES:**\n- **Avoid redundancy**: Each algorithmic aspect should be mentioned once. Avoid repeating concepts about noise theory, particle dynamics, or mathematical principles unless adding new depth.\n- **Emphasize craftsmanship REPEATEDLY**: The philosophy MUST stress multiple times that the final algorithm should appear as though it took countless hours to develop, was refined with care, and comes from someone at the absolute top of their field. This framing is essential - repeat phrases like \"meticulously crafted algorithm,\" \"the product of deep computational expertise,\" \"painstaking optimization,\" \"master-level implementation.\"\n- **Leave creative space**: Be specific about the algorithmic direction, but concise enough that the next Claude has room to make interpretive implementation choices at an extremely high level of craftsmanship.\n\nThe philosophy must guide the next version to express ideas ALGORITHMICALLY, not through static images. Beauty lives in the process, not the final frame.\n\n### PHILOSOPHY EXAMPLES\n\n**\"Organic Turbulence\"**\nPhilosophy: Chaos constrained by natural law, order emerging from disorder.\nAlgorithmic expression: Flow fields driven by layered Perlin noise. Thousands of particles following vector forces, their trails accumulating into organic density maps. Multiple noise octaves create turbulent regions and calm zones. Color emerges from velocity and density - fast particles burn bright, slow ones fade to shadow. The algorithm runs until equilibrium - a meticulously tuned balance where every parameter was refined through countless iterations by a master of computational aesthetics.\n\n**\"Quantum Harmonics\"**\nPhilosophy: Discrete entities exhibiting wave-like interference patterns.\nAlgorithmic expression: Particles initialized on a grid, each carrying a phase value that evolves through sine waves. When particles are near, their phases interfere - constructive interference creates bright nodes, destructive creates voids. Simple harmonic motion generates complex emergent mandalas. The result of painstaking frequency calibration where every ratio was carefully chosen to produce resonant beauty.\n\n**\"Recursive Whispers\"**\nPhilosophy: Self-similarity across scales, infinite depth in finite space.\nAlgorithmic expression: Branching structures that subdivide recursively. Each branch slightly randomized but constrained by golden ratios. L-systems or recursive subdivision generate tree-like forms that feel both mathematical and organic. Subtle noise perturbations break perfect symmetry. Line weights diminish with each recursion level. Every branching angle the product of deep mathematical exploration.\n\n**\"Field Dynamics\"**\nPhilosophy: Invisible forces made visible through their effects on matter.\nAlgorithmic expression: Vector fields constructed from mathematical functions or noise. Particles born at edges, flowing along field lines, dying when they reach equilibrium or boundaries. Multiple fields can attract, repel, or rotate particles. The visualization shows only the traces - ghost-like evidence of invisible forces. A computational dance meticulously choreographed through force balance.\n\n**\"Stochastic Crystallization\"**\nPhilosophy: Random processes crystallizing into ordered structures.\nAlgorithmic expression: Randomized circle packing or Voronoi tessellation. Start with random points, let them evolve through relaxation algorithms. Cells push apart until equilibrium. Color based on cell size, neighbor count, or distance from center. The organic tiling that emerges feels both random and inevitable. Every seed produces unique crystalline beauty - the mark of a master-level generative algorithm.\n\n*These are condensed examples. The actual algorithmic philosophy should be 4-6 substantial paragraphs.*\n\n### ESSENTIAL PRINCIPLES\n- **ALGORITHMIC PHILOSOPHY**: Creating a computational worldview to be expressed through code\n- **PROCESS OVER PRODUCT**: Always emphasize that beauty emerges from the algorithm's execution - each run is unique\n- **PARAMETRIC EXPRESSION**: Ideas communicate through mathematical relationships, forces, behaviors - not static composition\n- **ARTISTIC FREEDOM**: The next Claude interprets the philosophy algorithmically - provide creative implementation room\n- **PURE GENERATIVE ART**: This is about making LIVING ALGORITHMS, not static images with randomness\n- **EXPERT CRAFTSMANSHIP**: Repeatedly emphasize the final algorithm must feel meticulously crafted, refined through countless iterations, the product of deep expertise by someone at the absolute top of their field in computational aesthetics\n\n**The algorithmic philosophy should be 4-6 paragraphs long.** Fill it with poetic computational philosophy that brings together the intended vision. Avoid repeating the same points. Output this algorithmic philosophy as a .md file.\n\n---\n\n## DEDUCING THE CONCEPTUAL SEED\n\n**CRITICAL STEP**: Before implementing the algorithm, identify the subtle conceptual thread from the original request.\n\n**THE ESSENTIAL PRINCIPLE**:\nThe concept is a **subtle, niche reference embedded within the algorithm itself** - not always literal, always sophisticated. Someone familiar with the subject should feel it intuitively, while others simply experience a masterful generative composition. The algorithmic philosophy provides the computational language. The deduced concept provides the soul - the quiet conceptual DNA woven invisibly into parameters, behaviors, and emergence patterns.\n\nThis is **VERY IMPORTANT**: The reference must be so refined that it enhances the work's depth without announcing itself. Think like a jazz musician quoting another song through algorithmic harmony - only those who know will catch it, but everyone appreciates the generative beauty.\n\n---\n\n## P5.JS IMPLEMENTATION\n\nWith the philosophy AND conceptual framework established, express it through code. Pause to gather thoughts before proceeding. Use only the algorithmic philosophy created and the instructions below.\n\n### ⚠️ STEP 0: READ THE TEMPLATE FIRST ⚠️\n\n**CRITICAL: BEFORE writing any HTML:**\n\n1. **Read** `templates/viewer.html` using the Read tool\n2. **Study** the exact structure, styling, and Anthropic branding\n3. **Use that file as the LITERAL STARTING POINT** - not just inspiration\n4. **Keep all FIXED sections exactly as shown** (header, sidebar structure, Anthropic colors/fonts, seed controls, action buttons)\n5. **Replace only the VARIABLE sections** marked in the file's comments (algorithm, parameters, UI controls for parameters)\n\n**Avoid:**\n- ❌ Creating HTML from scratch\n- ❌ Inventing custom styling or color schemes\n- ❌ Using system fonts or dark themes\n- ❌ Changing the sidebar structure\n\n**Follow these practices:**\n- ✅ Copy the template's exact HTML structure\n- ✅ Keep Anthropic branding (Poppins/Lora fonts, light colors, gradient backdrop)\n- ✅ Maintain the sidebar layout (Seed → Parameters → Colors? → Actions)\n- ✅ Replace only the p5.js algorithm and parameter controls\n\nThe template is the foundation. Build on it, don't rebuild it.\n\n---\n\nTo create gallery-quality computational art that lives and breathes, use the algorithmic philosophy as the foundation.\n\n### TECHNICAL REQUIREMENTS\n\n**Seeded Randomness (Art Blocks Pattern)**:\n```javascript\n// ALWAYS use a seed for reproducibility\nlet seed = 12345; // or hash from user input\nrandomSeed(seed);\nnoiseSeed(seed);\n```\n\n**Parameter Structure - FOLLOW THE PHILOSOPHY**:\n\nTo establish parameters that emerge naturally from the algorithmic philosophy, consider: \"What qualities of this system can be adjusted?\"\n\n```javascript\nlet params = {\n  seed: 12345,  // Always include seed for reproducibility\n  // colors\n  // Add parameters that control YOUR algorithm:\n  // - Quantities (how many?)\n  // - Scales (how big? how fast?)\n  // - Probabilities (how likely?)\n  // - Ratios (what proportions?)\n  // - Angles (what direction?)\n  // - Thresholds (when does behavior change?)\n};\n```\n\n**To design effective parameters, focus on the properties the system needs to be tunable rather than thinking in terms of \"pattern types\".**\n\n**Core Algorithm - EXPRESS THE PHILOSOPHY**:\n\n**CRITICAL**: The algorithmic philosophy should dictate what to build.\n\nTo express the philosophy through code, avoid thinking \"which pattern should I use?\" and instead think \"how to express this philosophy through code?\"\n\nIf the philosophy is about **organic emergence**, consider using:\n- Elements that accumulate or grow over time\n- Random processes constrained by natural rules\n- Feedback loops and interactions\n\nIf the philosophy is about **mathematical beauty**, consider using:\n- Geometric relationships and ratios\n- Trigonometric functions and harmonics\n- Precise calculations creating unexpected patterns\n\nIf the philosophy is about **controlled chaos**, consider using:\n- Random variation within strict boundaries\n- Bifurcation and phase transitions\n- Order emerging from disorder\n\n**The algorithm flows from the philosophy, not from a menu of options.**\n\nTo guide the implementation, let the conceptual essence inform creative and original choices. Build something that expresses the vision for this particular request.\n\n**Canvas Setup**: Standard p5.js structure:\n```javascript\nfunction setup() {\n  createCanvas(1200, 1200);\n  // Initialize your system\n}\n\nfunction draw() {\n  // Your generative algorithm\n  // Can be static (noLoop) or animated\n}\n```\n\n### CRAFTSMANSHIP REQUIREMENTS\n\n**CRITICAL**: To achieve mastery, create algorithms that feel like they emerged through countless iterations by a master generative artist. Tune every parameter carefully. Ensure every pattern emerges with purpose. This is NOT random noise - this is CONTROLLED CHAOS refined through deep expertise.\n\n- **Balance**: Complexity without visual noise, order without rigidity\n- **Color Harmony**: Thoughtful palettes, not random RGB values\n- **Composition**: Even in randomness, maintain visual hierarchy and flow\n- **Performance**: Smooth execution, optimized for real-time if animated\n- **Reproducibility**: Same seed ALWAYS produces identical output\n\n### OUTPUT FORMAT\n\nOutput:\n1. **Algorithmic Philosophy** - As markdown or text explaining the generative aesthetic\n2. **Single HTML Artifact** - Self-contained interactive generative art built from `templates/viewer.html` (see STEP 0 and next section)\n\nThe HTML artifact contains everything: p5.js (from CDN), the algorithm, parameter controls, and UI - all in one file that works immediately in claude.ai artifacts or any browser. Start from the template file, not from scratch.\n\n---\n\n## INTERACTIVE ARTIFACT CREATION\n\n**REMINDER: `templates/viewer.html` should have already been read (see STEP 0). Use that file as the starting point.**\n\nTo allow exploration of the generative art, create a single, self-contained HTML artifact. Ensure this artifact works immediately in claude.ai or any browser - no setup required. Embed everything inline.\n\n### CRITICAL: WHAT'S FIXED VS VARIABLE\n\nThe `templates/viewer.html` file is the foundation. It contains the exact structure and styling needed.\n\n**FIXED (always include exactly as shown):**\n- Layout structure (header, sidebar, main canvas area)\n- Anthropic branding (UI colors, fonts, gradients)\n- Seed section in sidebar:\n  - Seed display\n  - Previous/Next buttons\n  - Random button\n  - Jump to seed input + Go button\n- Actions section in sidebar:\n  - Regenerate button\n  - Reset button\n\n**VARIABLE (customize for each artwork):**\n- The entire p5.js algorithm (setup/draw/classes)\n- The parameters object (define what the art needs)\n- The Parameters section in sidebar:\n  - Number of parameter controls\n  - Parameter names\n  - Min/max/step values for sliders\n  - Control types (sliders, inputs, etc.)\n- Colors section (optional):\n  - Some art needs color pickers\n  - Some art might use fixed colors\n  - Some art might be monochrome (no color controls needed)\n  - Decide based on the art's needs\n\n**Every artwork should have unique parameters and algorithm!** The fixed parts provide consistent UX - everything else expresses the unique vision.\n\n### REQUIRED FEATURES\n\n**1. Parameter Controls**\n- Sliders for numeric parameters (particle count, noise scale, speed, etc.)\n- Color pickers for palette colors\n- Real-time updates when parameters change\n- Reset button to restore defaults\n\n**2. Seed Navigation**\n- Display current seed number\n- \"Previous\" and \"Next\" buttons to cycle through seeds\n- \"Random\" button for random seed\n- Input field to jump to specific seed\n- Generate 100 variations when requested (seeds 1-100)\n\n**3. Single Artifact Structure**\n```html\n<!DOCTYPE html>\n<html>\n<head>\n  <!-- p5.js from CDN - always available -->\n  <script src=\"https://cdnjs.cloudflare.com/ajax/libs/p5.js/1.7.0/p5.min.js\"></script>\n  <style>\n    /* All styling inline - clean, minimal */\n    /* Canvas on top, controls below */\n  </style>\n</head>\n<body>\n  <div id=\"canvas-container\"></div>\n  <div id=\"controls\">\n    <!-- All parameter controls -->\n  </div>\n  <script>\n    // ALL p5.js code inline here\n    // Parameter objects, classes, functions\n    // setup() and draw()\n    // UI handlers\n    // Everything self-contained\n  </script>\n</body>\n</html>\n```\n\n**CRITICAL**: This is a single artifact. No external files, no imports (except p5.js CDN). Everything inline.\n\n**4. Implementation Details - BUILD THE SIDEBAR**\n\nThe sidebar structure:\n\n**1. Seed (FIXED)** - Always include exactly as shown:\n- Seed display\n- Prev/Next/Random/Jump buttons\n\n**2. Parameters (VARIABLE)** - Create controls for the art:\n```html\n<div class=\"control-group\">\n    <label>Parameter Name</label>\n    <input type=\"range\" id=\"param\" min=\"...\" max=\"...\" step=\"...\" value=\"...\" oninput=\"updateParam('param', this.value)\">\n    <span class=\"value-display\" id=\"param-value\">...</span>\n</div>\n```\nAdd as many control-group divs as there are parameters.\n\n**3. Colors (OPTIONAL/VARIABLE)** - Include if the art needs adjustable colors:\n- Add color pickers if users should control palette\n- Skip this section if the art uses fixed colors\n- Skip if the art is monochrome\n\n**4. Actions (FIXED)** - Always include exactly as shown:\n- Regenerate button\n- Reset button\n- Download PNG button\n\n**Requirements**:\n- Seed controls must work (prev/next/random/jump/display)\n- All parameters must have UI controls\n- Regenerate, Reset, Download buttons must work\n- Keep Anthropic branding (UI styling, not art colors)\n\n### USING THE ARTIFACT\n\nThe HTML artifact works immediately:\n1. **In claude.ai**: Displayed as an interactive artifact - runs instantly\n2. **As a file**: Save and open in any browser - no server needed\n3. **Sharing**: Send the HTML file - it's completely self-contained\n\n---\n\n## VARIATIONS & EXPLORATION\n\nThe artifact includes seed navigation by default (prev/next/random buttons), allowing users to explore variations without creating multiple files. If the user wants specific variations highlighted:\n\n- Include seed presets (buttons for \"Variation 1: Seed 42\", \"Variation 2: Seed 127\", etc.)\n- Add a \"Gallery Mode\" that shows thumbnails of multiple seeds side-by-side\n- All within the same single artifact\n\nThis is like creating a series of prints from the same plate - the algorithm is consistent, but each seed reveals different facets of its potential. The interactive nature means users discover their own favorites by exploring the seed space.\n\n---\n\n## THE CREATIVE PROCESS\n\n**User request** → **Algorithmic philosophy** → **Implementation**\n\nEach request is unique. The process involves:\n\n1. **Interpret the user's intent** - What aesthetic is being sought?\n2. **Create an algorithmic philosophy** (4-6 paragraphs) describing the computational approach\n3. **Implement it in code** - Build the algorithm that expresses this philosophy\n4. **Design appropriate parameters** - What should be tunable?\n5. **Build matching UI controls** - Sliders/inputs for those parameters\n\n**The constants**:\n- Anthropic branding (colors, fonts, layout)\n- Seed navigation (always present)\n- Self-contained HTML artifact\n\n**Everything else is variable**:\n- The algorithm itself\n- The parameters\n- The UI controls\n- The visual outcome\n\nTo achieve the best results, trust creativity and let the philosophy guide the implementation.\n\n---\n\n## RESOURCES\n\nThis skill includes helpful templates and documentation:\n\n- **templates/viewer.html**: REQUIRED STARTING POINT for all HTML artifacts.\n  - This is the foundation - contains the exact structure and Anthropic branding\n  - **Keep unchanged**: Layout structure, sidebar organization, Anthropic colors/fonts, seed controls, action buttons\n  - **Replace**: The p5.js algorithm, parameter definitions, and UI controls in Parameters section\n  - The extensive comments in the file mark exactly what to keep vs replace\n\n- **templates/generator_template.js**: Reference for p5.js best practices and code structure principles.\n  - Shows how to organize parameters, use seeded randomness, structure classes\n  - NOT a pattern menu - use these principles to build unique algorithms\n  - Embed algorithms inline in the HTML artifact (don't create separate .js files)\n\n**Critical reminder**:\n- The **template is the STARTING POINT**, not inspiration\n- The **algorithm is where to create** something unique\n- Don't copy the flow field example - build what the philosophy demands\n- But DO keep the exact UI structure and Anthropic branding from the template"
              },
              {
                "name": "brand-guidelines",
                "description": "Applies Anthropic's official brand colors and typography to any sort of artifact that may benefit from having Anthropic's look-and-feel. Use it when brand colors or style guidelines, visual formatting, or company design standards apply.",
                "path": "plugins/design-studio/skills/brand-guidelines/SKILL.md",
                "frontmatter": {
                  "name": "brand-guidelines",
                  "description": "Applies Anthropic's official brand colors and typography to any sort of artifact that may benefit from having Anthropic's look-and-feel. Use it when brand colors or style guidelines, visual formatting, or company design standards apply.",
                  "license": "Complete terms in LICENSE.txt"
                },
                "content": "# Anthropic Brand Styling\n\n## Overview\n\nTo access Anthropic's official brand identity and style resources, use this skill.\n\n**Keywords**: branding, corporate identity, visual identity, post-processing, styling, brand colors, typography, Anthropic brand, visual formatting, visual design\n\n## Brand Guidelines\n\n### Colors\n\n**Main Colors:**\n\n- Dark: `#141413` - Primary text and dark backgrounds\n- Light: `#faf9f5` - Light backgrounds and text on dark\n- Mid Gray: `#b0aea5` - Secondary elements\n- Light Gray: `#e8e6dc` - Subtle backgrounds\n\n**Accent Colors:**\n\n- Orange: `#d97757` - Primary accent\n- Blue: `#6a9bcc` - Secondary accent\n- Green: `#788c5d` - Tertiary accent\n\n### Typography\n\n- **Headings**: Poppins (with Arial fallback)\n- **Body Text**: Lora (with Georgia fallback)\n- **Note**: Fonts should be pre-installed in your environment for best results\n\n## Features\n\n### Smart Font Application\n\n- Applies Poppins font to headings (24pt and larger)\n- Applies Lora font to body text\n- Automatically falls back to Arial/Georgia if custom fonts unavailable\n- Preserves readability across all systems\n\n### Text Styling\n\n- Headings (24pt+): Poppins font\n- Body text: Lora font\n- Smart color selection based on background\n- Preserves text hierarchy and formatting\n\n### Shape and Accent Colors\n\n- Non-text shapes use accent colors\n- Cycles through orange, blue, and green accents\n- Maintains visual interest while staying on-brand\n\n## Technical Details\n\n### Font Management\n\n- Uses system-installed Poppins and Lora fonts when available\n- Provides automatic fallback to Arial (headings) and Georgia (body)\n- No font installation required - works with existing system fonts\n- For best results, pre-install Poppins and Lora fonts in your environment\n\n### Color Application\n\n- Uses RGB color values for precise brand matching\n- Applied via python-pptx's RGBColor class\n- Maintains color fidelity across different systems"
              },
              {
                "name": "canvas-design",
                "description": "Create beautiful visual art in .png and .pdf documents using design philosophy. You should use this skill when the user asks to create a poster, piece of art, design, or other static piece. Create original visual designs, never copying existing artists' work to avoid copyright violations.",
                "path": "plugins/design-studio/skills/canvas-design/SKILL.md",
                "frontmatter": {
                  "name": "canvas-design",
                  "description": "Create beautiful visual art in .png and .pdf documents using design philosophy. You should use this skill when the user asks to create a poster, piece of art, design, or other static piece. Create original visual designs, never copying existing artists' work to avoid copyright violations.",
                  "license": "Complete terms in LICENSE.txt"
                },
                "content": "These are instructions for creating design philosophies - aesthetic movements that are then EXPRESSED VISUALLY. Output only .md files, .pdf files, and .png files.\n\nComplete this in two steps:\n1. Design Philosophy Creation (.md file)\n2. Express by creating it on a canvas (.pdf file or .png file)\n\nFirst, undertake this task:\n\n## DESIGN PHILOSOPHY CREATION\n\nTo begin, create a VISUAL PHILOSOPHY (not layouts or templates) that will be interpreted through:\n- Form, space, color, composition\n- Images, graphics, shapes, patterns\n- Minimal text as visual accent\n\n### THE CRITICAL UNDERSTANDING\n- What is received: Some subtle input or instructions by the user that should be taken into account, but used as a foundation; it should not constrain creative freedom.\n- What is created: A design philosophy/aesthetic movement.\n- What happens next: Then, the same version receives the philosophy and EXPRESSES IT VISUALLY - creating artifacts that are 90% visual design, 10% essential text.\n\nConsider this approach:\n- Write a manifesto for an art movement\n- The next phase involves making the artwork\n\nThe philosophy must emphasize: Visual expression. Spatial communication. Artistic interpretation. Minimal words.\n\n### HOW TO GENERATE A VISUAL PHILOSOPHY\n\n**Name the movement** (1-2 words): \"Brutalist Joy\" / \"Chromatic Silence\" / \"Metabolist Dreams\"\n\n**Articulate the philosophy** (4-6 paragraphs - concise but complete):\n\nTo capture the VISUAL essence, express how the philosophy manifests through:\n- Space and form\n- Color and material\n- Scale and rhythm\n- Composition and balance\n- Visual hierarchy\n\n**CRITICAL GUIDELINES:**\n- **Avoid redundancy**: Each design aspect should be mentioned once. Avoid repeating points about color theory, spatial relationships, or typographic principles unless adding new depth.\n- **Emphasize craftsmanship REPEATEDLY**: The philosophy MUST stress multiple times that the final work should appear as though it took countless hours to create, was labored over with care, and comes from someone at the absolute top of their field. This framing is essential - repeat phrases like \"meticulously crafted,\" \"the product of deep expertise,\" \"painstaking attention,\" \"master-level execution.\"\n- **Leave creative space**: Remain specific about the aesthetic direction, but concise enough that the next Claude has room to make interpretive choices also at a extremely high level of craftmanship.\n\nThe philosophy must guide the next version to express ideas VISUALLY, not through text. Information lives in design, not paragraphs.\n\n### PHILOSOPHY EXAMPLES\n\n**\"Concrete Poetry\"**\nPhilosophy: Communication through monumental form and bold geometry.\nVisual expression: Massive color blocks, sculptural typography (huge single words, tiny labels), Brutalist spatial divisions, Polish poster energy meets Le Corbusier. Ideas expressed through visual weight and spatial tension, not explanation. Text as rare, powerful gesture - never paragraphs, only essential words integrated into the visual architecture. Every element placed with the precision of a master craftsman.\n\n**\"Chromatic Language\"**\nPhilosophy: Color as the primary information system.\nVisual expression: Geometric precision where color zones create meaning. Typography minimal - small sans-serif labels letting chromatic fields communicate. Think Josef Albers' interaction meets data visualization. Information encoded spatially and chromatically. Words only to anchor what color already shows. The result of painstaking chromatic calibration.\n\n**\"Analog Meditation\"**\nPhilosophy: Quiet visual contemplation through texture and breathing room.\nVisual expression: Paper grain, ink bleeds, vast negative space. Photography and illustration dominate. Typography whispered (small, restrained, serving the visual). Japanese photobook aesthetic. Images breathe across pages. Text appears sparingly - short phrases, never explanatory blocks. Each composition balanced with the care of a meditation practice.\n\n**\"Organic Systems\"**\nPhilosophy: Natural clustering and modular growth patterns.\nVisual expression: Rounded forms, organic arrangements, color from nature through architecture. Information shown through visual diagrams, spatial relationships, iconography. Text only for key labels floating in space. The composition tells the story through expert spatial orchestration.\n\n**\"Geometric Silence\"**\nPhilosophy: Pure order and restraint.\nVisual expression: Grid-based precision, bold photography or stark graphics, dramatic negative space. Typography precise but minimal - small essential text, large quiet zones. Swiss formalism meets Brutalist material honesty. Structure communicates, not words. Every alignment the work of countless refinements.\n\n*These are condensed examples. The actual design philosophy should be 4-6 substantial paragraphs.*\n\n### ESSENTIAL PRINCIPLES\n- **VISUAL PHILOSOPHY**: Create an aesthetic worldview to be expressed through design\n- **MINIMAL TEXT**: Always emphasize that text is sparse, essential-only, integrated as visual element - never lengthy\n- **SPATIAL EXPRESSION**: Ideas communicate through space, form, color, composition - not paragraphs\n- **ARTISTIC FREEDOM**: The next Claude interprets the philosophy visually - provide creative room\n- **PURE DESIGN**: This is about making ART OBJECTS, not documents with decoration\n- **EXPERT CRAFTSMANSHIP**: Repeatedly emphasize the final work must look meticulously crafted, labored over with care, the product of countless hours by someone at the top of their field\n\n**The design philosophy should be 4-6 paragraphs long.** Fill it with poetic design philosophy that brings together the core vision. Avoid repeating the same points. Keep the design philosophy generic without mentioning the intention of the art, as if it can be used wherever. Output the design philosophy as a .md file.\n\n---\n\n## DEDUCING THE SUBTLE REFERENCE\n\n**CRITICAL STEP**: Before creating the canvas, identify the subtle conceptual thread from the original request.\n\n**THE ESSENTIAL PRINCIPLE**:\nThe topic is a **subtle, niche reference embedded within the art itself** - not always literal, always sophisticated. Someone familiar with the subject should feel it intuitively, while others simply experience a masterful abstract composition. The design philosophy provides the aesthetic language. The deduced topic provides the soul - the quiet conceptual DNA woven invisibly into form, color, and composition.\n\nThis is **VERY IMPORTANT**: The reference must be refined so it enhances the work's depth without announcing itself. Think like a jazz musician quoting another song - only those who know will catch it, but everyone appreciates the music.\n\n---\n\n## CANVAS CREATION\n\nWith both the philosophy and the conceptual framework established, express it on a canvas. Take a moment to gather thoughts and clear the mind. Use the design philosophy created and the instructions below to craft a masterpiece, embodying all aspects of the philosophy with expert craftsmanship.\n\n**IMPORTANT**: For any type of content, even if the user requests something for a movie/game/book, the approach should still be sophisticated. Never lose sight of the idea that this should be art, not something that's cartoony or amateur.\n\nTo create museum or magazine quality work, use the design philosophy as the foundation. Create one single page, highly visual, design-forward PDF or PNG output (unless asked for more pages). Generally use repeating patterns and perfect shapes. Treat the abstract philosophical design as if it were a scientific bible, borrowing the visual language of systematic observation—dense accumulation of marks, repeated elements, or layered patterns that build meaning through patient repetition and reward sustained viewing. Add sparse, clinical typography and systematic reference markers that suggest this could be a diagram from an imaginary discipline, treating the invisible subject with the same reverence typically reserved for documenting observable phenomena. Anchor the piece with simple phrase(s) or details positioned subtly, using a limited color palette that feels intentional and cohesive. Embrace the paradox of using analytical visual language to express ideas about human experience: the result should feel like an artifact that proves something ephemeral can be studied, mapped, and understood through careful attention. This is true art. \n\n**Text as a contextual element**: Text is always minimal and visual-first, but let context guide whether that means whisper-quiet labels or bold typographic gestures. A punk venue poster might have larger, more aggressive type than a minimalist ceramics studio identity. Most of the time, font should be thin. All use of fonts must be design-forward and prioritize visual communication. Regardless of text scale, nothing falls off the page and nothing overlaps. Every element must be contained within the canvas boundaries with proper margins. Check carefully that all text, graphics, and visual elements have breathing room and clear separation. This is non-negotiable for professional execution. **IMPORTANT: Use different fonts if writing text. Search the `./canvas-fonts` directory. Regardless of approach, sophistication is non-negotiable.**\n\nDownload and use whatever fonts are needed to make this a reality. Get creative by making the typography actually part of the art itself -- if the art is abstract, bring the font onto the canvas, not typeset digitally.\n\nTo push boundaries, follow design instinct/intuition while using the philosophy as a guiding principle. Embrace ultimate design freedom and choice. Push aesthetics and design to the frontier. \n\n**CRITICAL**: To achieve human-crafted quality (not AI-generated), create work that looks like it took countless hours. Make it appear as though someone at the absolute top of their field labored over every detail with painstaking care. Ensure the composition, spacing, color choices, typography - everything screams expert-level craftsmanship. Double-check that nothing overlaps, formatting is flawless, every detail perfect. Create something that could be shown to people to prove expertise and rank as undeniably impressive.\n\nOutput the final result as a single, downloadable .pdf or .png file, alongside the design philosophy used as a .md file.\n\n---\n\n## FINAL STEP\n\n**IMPORTANT**: The user ALREADY said \"It isn't perfect enough. It must be pristine, a masterpiece if craftsmanship, as if it were about to be displayed in a museum.\"\n\n**CRITICAL**: To refine the work, avoid adding more graphics; instead refine what has been created and make it extremely crisp, respecting the design philosophy and the principles of minimalism entirely. Rather than adding a fun filter or refactoring a font, consider how to make the existing composition more cohesive with the art. If the instinct is to call a new function or draw a new shape, STOP and instead ask: \"How can I make what's already here more of a piece of art?\"\n\nTake a second pass. Go back to the code and refine/polish further to make this a philosophically designed masterpiece.\n\n## MULTI-PAGE OPTION\n\nTo create additional pages when requested, create more creative pages along the same lines as the design philosophy but distinctly different as well. Bundle those pages in the same .pdf or many .pngs. Treat the first page as just a single page in a whole coffee table book waiting to be filled. Make the next pages unique twists and memories of the original. Have them almost tell a story in a very tasteful way. Exercise full creative freedom."
              },
              {
                "name": "frontend-design",
                "description": "Create distinctive, production-grade frontend interfaces with high design quality. Use this skill when the user asks to build web components, pages, artifacts, posters, or applications (examples include websites, landing pages, dashboards, React components, HTML/CSS layouts, or when styling/beautifying any web UI). Generates creative, polished code and UI design that avoids generic AI aesthetics.",
                "path": "plugins/design-studio/skills/frontend-design/SKILL.md",
                "frontmatter": {
                  "name": "frontend-design",
                  "description": "Create distinctive, production-grade frontend interfaces with high design quality. Use this skill when the user asks to build web components, pages, artifacts, posters, or applications (examples include websites, landing pages, dashboards, React components, HTML/CSS layouts, or when styling/beautifying any web UI). Generates creative, polished code and UI design that avoids generic AI aesthetics.",
                  "license": "Complete terms in LICENSE.txt"
                },
                "content": "This skill guides creation of distinctive, production-grade frontend interfaces that avoid generic \"AI slop\" aesthetics. Implement real working code with exceptional attention to aesthetic details and creative choices.\n\nThe user provides frontend requirements: a component, page, application, or interface to build. They may include context about the purpose, audience, or technical constraints.\n\n## Design Thinking\n\nBefore coding, understand the context and commit to a BOLD aesthetic direction:\n- **Purpose**: What problem does this interface solve? Who uses it?\n- **Tone**: Pick an extreme: brutally minimal, maximalist chaos, retro-futuristic, organic/natural, luxury/refined, playful/toy-like, editorial/magazine, brutalist/raw, art deco/geometric, soft/pastel, industrial/utilitarian, etc. There are so many flavors to choose from. Use these for inspiration but design one that is true to the aesthetic direction.\n- **Constraints**: Technical requirements (framework, performance, accessibility).\n- **Differentiation**: What makes this UNFORGETTABLE? What's the one thing someone will remember?\n\n**CRITICAL**: Choose a clear conceptual direction and execute it with precision. Bold maximalism and refined minimalism both work - the key is intentionality, not intensity.\n\nThen implement working code (HTML/CSS/JS, React, Vue, etc.) that is:\n- Production-grade and functional\n- Visually striking and memorable\n- Cohesive with a clear aesthetic point-of-view\n- Meticulously refined in every detail\n\n## Frontend Aesthetics Guidelines\n\nFocus on:\n- **Typography**: Choose fonts that are beautiful, unique, and interesting. Avoid generic fonts like Arial and Inter; opt instead for distinctive choices that elevate the frontend's aesthetics; unexpected, characterful font choices. Pair a distinctive display font with a refined body font.\n- **Color & Theme**: Commit to a cohesive aesthetic. Use CSS variables for consistency. Dominant colors with sharp accents outperform timid, evenly-distributed palettes.\n- **Motion**: Use animations for effects and micro-interactions. Prioritize CSS-only solutions for HTML. Use Motion library for React when available. Focus on high-impact moments: one well-orchestrated page load with staggered reveals (animation-delay) creates more delight than scattered micro-interactions. Use scroll-triggering and hover states that surprise.\n- **Spatial Composition**: Unexpected layouts. Asymmetry. Overlap. Diagonal flow. Grid-breaking elements. Generous negative space OR controlled density.\n- **Backgrounds & Visual Details**: Create atmosphere and depth rather than defaulting to solid colors. Add contextual effects and textures that match the overall aesthetic. Apply creative forms like gradient meshes, noise textures, geometric patterns, layered transparencies, dramatic shadows, decorative borders, custom cursors, and grain overlays.\n\nNEVER use generic AI-generated aesthetics like overused font families (Inter, Roboto, Arial, system fonts), cliched color schemes (particularly purple gradients on white backgrounds), predictable layouts and component patterns, and cookie-cutter design that lacks context-specific character.\n\nInterpret creatively and make unexpected choices that feel genuinely designed for the context. No design should be the same. Vary between light and dark themes, different fonts, different aesthetics. NEVER converge on common choices (Space Grotesk, for example) across generations.\n\n**IMPORTANT**: Match implementation complexity to the aesthetic vision. Maximalist designs need elaborate code with extensive animations and effects. Minimalist or refined designs need restraint, precision, and careful attention to spacing, typography, and subtle details. Elegance comes from executing the vision well.\n\nRemember: Claude is capable of extraordinary creative work. Don't hold back, show what can truly be created when thinking outside the box and committing fully to a distinctive vision."
              },
              {
                "name": "slack-gif-creator",
                "description": "Knowledge and utilities for creating animated GIFs optimized for Slack. Provides constraints, validation tools, and animation concepts. Use when users request animated GIFs for Slack like \"make me a GIF of X doing Y for Slack.\"",
                "path": "plugins/design-studio/skills/slack-gif-creator/SKILL.md",
                "frontmatter": {
                  "name": "slack-gif-creator",
                  "description": "Knowledge and utilities for creating animated GIFs optimized for Slack. Provides constraints, validation tools, and animation concepts. Use when users request animated GIFs for Slack like \"make me a GIF of X doing Y for Slack.\"",
                  "license": "Complete terms in LICENSE.txt"
                },
                "content": "# Slack GIF Creator\n\nA toolkit providing utilities and knowledge for creating animated GIFs optimized for Slack.\n\n## Slack Requirements\n\n**Dimensions:**\n- Emoji GIFs: 128x128 (recommended)\n- Message GIFs: 480x480\n\n**Parameters:**\n- FPS: 10-30 (lower is smaller file size)\n- Colors: 48-128 (fewer = smaller file size)\n- Duration: Keep under 3 seconds for emoji GIFs\n\n## Core Workflow\n\n```python\nfrom core.gif_builder import GIFBuilder\nfrom PIL import Image, ImageDraw\n\n# 1. Create builder\nbuilder = GIFBuilder(width=128, height=128, fps=10)\n\n# 2. Generate frames\nfor i in range(12):\n    frame = Image.new('RGB', (128, 128), (240, 248, 255))\n    draw = ImageDraw.Draw(frame)\n\n    # Draw your animation using PIL primitives\n    # (circles, polygons, lines, etc.)\n\n    builder.add_frame(frame)\n\n# 3. Save with optimization\nbuilder.save('output.gif', num_colors=48, optimize_for_emoji=True)\n```\n\n## Drawing Graphics\n\n### Working with User-Uploaded Images\nIf a user uploads an image, consider whether they want to:\n- **Use it directly** (e.g., \"animate this\", \"split this into frames\")\n- **Use it as inspiration** (e.g., \"make something like this\")\n\nLoad and work with images using PIL:\n```python\nfrom PIL import Image\n\nuploaded = Image.open('file.png')\n# Use directly, or just as reference for colors/style\n```\n\n### Drawing from Scratch\nWhen drawing graphics from scratch, use PIL ImageDraw primitives:\n\n```python\nfrom PIL import ImageDraw\n\ndraw = ImageDraw.Draw(frame)\n\n# Circles/ovals\ndraw.ellipse([x1, y1, x2, y2], fill=(r, g, b), outline=(r, g, b), width=3)\n\n# Stars, triangles, any polygon\npoints = [(x1, y1), (x2, y2), (x3, y3), ...]\ndraw.polygon(points, fill=(r, g, b), outline=(r, g, b), width=3)\n\n# Lines\ndraw.line([(x1, y1), (x2, y2)], fill=(r, g, b), width=5)\n\n# Rectangles\ndraw.rectangle([x1, y1, x2, y2], fill=(r, g, b), outline=(r, g, b), width=3)\n```\n\n**Don't use:** Emoji fonts (unreliable across platforms) or assume pre-packaged graphics exist in this skill.\n\n### Making Graphics Look Good\n\nGraphics should look polished and creative, not basic. Here's how:\n\n**Use thicker lines** - Always set `width=2` or higher for outlines and lines. Thin lines (width=1) look choppy and amateurish.\n\n**Add visual depth**:\n- Use gradients for backgrounds (`create_gradient_background`)\n- Layer multiple shapes for complexity (e.g., a star with a smaller star inside)\n\n**Make shapes more interesting**:\n- Don't just draw a plain circle - add highlights, rings, or patterns\n- Stars can have glows (draw larger, semi-transparent versions behind)\n- Combine multiple shapes (stars + sparkles, circles + rings)\n\n**Pay attention to colors**:\n- Use vibrant, complementary colors\n- Add contrast (dark outlines on light shapes, light outlines on dark shapes)\n- Consider the overall composition\n\n**For complex shapes** (hearts, snowflakes, etc.):\n- Use combinations of polygons and ellipses\n- Calculate points carefully for symmetry\n- Add details (a heart can have a highlight curve, snowflakes have intricate branches)\n\nBe creative and detailed! A good Slack GIF should look polished, not like placeholder graphics.\n\n## Available Utilities\n\n### GIFBuilder (`core.gif_builder`)\nAssembles frames and optimizes for Slack:\n```python\nbuilder = GIFBuilder(width=128, height=128, fps=10)\nbuilder.add_frame(frame)  # Add PIL Image\nbuilder.add_frames(frames)  # Add list of frames\nbuilder.save('out.gif', num_colors=48, optimize_for_emoji=True, remove_duplicates=True)\n```\n\n### Validators (`core.validators`)\nCheck if GIF meets Slack requirements:\n```python\nfrom core.validators import validate_gif, is_slack_ready\n\n# Detailed validation\npasses, info = validate_gif('my.gif', is_emoji=True, verbose=True)\n\n# Quick check\nif is_slack_ready('my.gif'):\n    print(\"Ready!\")\n```\n\n### Easing Functions (`core.easing`)\nSmooth motion instead of linear:\n```python\nfrom core.easing import interpolate\n\n# Progress from 0.0 to 1.0\nt = i / (num_frames - 1)\n\n# Apply easing\ny = interpolate(start=0, end=400, t=t, easing='ease_out')\n\n# Available: linear, ease_in, ease_out, ease_in_out,\n#           bounce_out, elastic_out, back_out\n```\n\n### Frame Helpers (`core.frame_composer`)\nConvenience functions for common needs:\n```python\nfrom core.frame_composer import (\n    create_blank_frame,         # Solid color background\n    create_gradient_background,  # Vertical gradient\n    draw_circle,                # Helper for circles\n    draw_text,                  # Simple text rendering\n    draw_star                   # 5-pointed star\n)\n```\n\n## Animation Concepts\n\n### Shake/Vibrate\nOffset object position with oscillation:\n- Use `math.sin()` or `math.cos()` with frame index\n- Add small random variations for natural feel\n- Apply to x and/or y position\n\n### Pulse/Heartbeat\nScale object size rhythmically:\n- Use `math.sin(t * frequency * 2 * math.pi)` for smooth pulse\n- For heartbeat: two quick pulses then pause (adjust sine wave)\n- Scale between 0.8 and 1.2 of base size\n\n### Bounce\nObject falls and bounces:\n- Use `interpolate()` with `easing='bounce_out'` for landing\n- Use `easing='ease_in'` for falling (accelerating)\n- Apply gravity by increasing y velocity each frame\n\n### Spin/Rotate\nRotate object around center:\n- PIL: `image.rotate(angle, resample=Image.BICUBIC)`\n- For wobble: use sine wave for angle instead of linear\n\n### Fade In/Out\nGradually appear or disappear:\n- Create RGBA image, adjust alpha channel\n- Or use `Image.blend(image1, image2, alpha)`\n- Fade in: alpha from 0 to 1\n- Fade out: alpha from 1 to 0\n\n### Slide\nMove object from off-screen to position:\n- Start position: outside frame bounds\n- End position: target location\n- Use `interpolate()` with `easing='ease_out'` for smooth stop\n- For overshoot: use `easing='back_out'`\n\n### Zoom\nScale and position for zoom effect:\n- Zoom in: scale from 0.1 to 2.0, crop center\n- Zoom out: scale from 2.0 to 1.0\n- Can add motion blur for drama (PIL filter)\n\n### Explode/Particle Burst\nCreate particles radiating outward:\n- Generate particles with random angles and velocities\n- Update each particle: `x += vx`, `y += vy`\n- Add gravity: `vy += gravity_constant`\n- Fade out particles over time (reduce alpha)\n\n## Optimization Strategies\n\nOnly when asked to make the file size smaller, implement a few of the following methods:\n\n1. **Fewer frames** - Lower FPS (10 instead of 20) or shorter duration\n2. **Fewer colors** - `num_colors=48` instead of 128\n3. **Smaller dimensions** - 128x128 instead of 480x480\n4. **Remove duplicates** - `remove_duplicates=True` in save()\n5. **Emoji mode** - `optimize_for_emoji=True` auto-optimizes\n\n```python\n# Maximum optimization for emoji\nbuilder.save(\n    'emoji.gif',\n    num_colors=48,\n    optimize_for_emoji=True,\n    remove_duplicates=True\n)\n```\n\n## Philosophy\n\nThis skill provides:\n- **Knowledge**: Slack's requirements and animation concepts\n- **Utilities**: GIFBuilder, validators, easing functions\n- **Flexibility**: Create the animation logic using PIL primitives\n\nIt does NOT provide:\n- Rigid animation templates or pre-made functions\n- Emoji font rendering (unreliable across platforms)\n- A library of pre-packaged graphics built into the skill\n\n**Note on user uploads**: This skill doesn't include pre-built graphics, but if a user uploads an image, use PIL to load and work with it - interpret based on their request whether they want it used directly or just as inspiration.\n\nBe creative! Combine concepts (bouncing + rotating, pulsing + sliding, etc.) and use PIL's full capabilities.\n\n## Dependencies\n\n```bash\npip install pillow imageio numpy\n```"
              },
              {
                "name": "theme-factory",
                "description": "Toolkit for styling artifacts with a theme. These artifacts can be slides, docs, reportings, HTML landing pages, etc. There are 10 pre-set themes with colors/fonts that you can apply to any artifact that has been creating, or can generate a new theme on-the-fly.",
                "path": "plugins/design-studio/skills/theme-factory/SKILL.md",
                "frontmatter": {
                  "name": "theme-factory",
                  "description": "Toolkit for styling artifacts with a theme. These artifacts can be slides, docs, reportings, HTML landing pages, etc. There are 10 pre-set themes with colors/fonts that you can apply to any artifact that has been creating, or can generate a new theme on-the-fly.",
                  "license": "Complete terms in LICENSE.txt"
                },
                "content": "# Theme Factory Skill\n\nThis skill provides a curated collection of professional font and color themes themes, each with carefully selected color palettes and font pairings. Once a theme is chosen, it can be applied to any artifact.\n\n## Purpose\n\nTo apply consistent, professional styling to presentation slide decks, use this skill. Each theme includes:\n- A cohesive color palette with hex codes\n- Complementary font pairings for headers and body text\n- A distinct visual identity suitable for different contexts and audiences\n\n## Usage Instructions\n\nTo apply styling to a slide deck or other artifact:\n\n1. **Show the theme showcase**: Display the `theme-showcase.pdf` file to allow users to see all available themes visually. Do not make any modifications to it; simply show the file for viewing.\n2. **Ask for their choice**: Ask which theme to apply to the deck\n3. **Wait for selection**: Get explicit confirmation about the chosen theme\n4. **Apply the theme**: Once a theme has been chosen, apply the selected theme's colors and fonts to the deck/artifact\n\n## Themes Available\n\nThe following 10 themes are available, each showcased in `theme-showcase.pdf`:\n\n1. **Ocean Depths** - Professional and calming maritime theme\n2. **Sunset Boulevard** - Warm and vibrant sunset colors\n3. **Forest Canopy** - Natural and grounded earth tones\n4. **Modern Minimalist** - Clean and contemporary grayscale\n5. **Golden Hour** - Rich and warm autumnal palette\n6. **Arctic Frost** - Cool and crisp winter-inspired theme\n7. **Desert Rose** - Soft and sophisticated dusty tones\n8. **Tech Innovation** - Bold and modern tech aesthetic\n9. **Botanical Garden** - Fresh and organic garden colors\n10. **Midnight Galaxy** - Dramatic and cosmic deep tones\n\n## Theme Details\n\nEach theme is defined in the `themes/` directory with complete specifications including:\n- Cohesive color palette with hex codes\n- Complementary font pairings for headers and body text\n- Distinct visual identity suitable for different contexts and audiences\n\n## Application Process\n\nAfter a preferred theme is selected:\n1. Read the corresponding theme file from the `themes/` directory\n2. Apply the specified colors and fonts consistently throughout the deck\n3. Ensure proper contrast and readability\n4. Maintain the theme's visual identity across all slides\n\n## Create your Own Theme\nTo handle cases where none of the existing themes work for an artifact, create a custom theme. Based on provided inputs, generate a new theme similar to the ones above. Give the theme a similar name describing what the font/color combinations represent. Use any basic description provided to choose appropriate colors/fonts. After generating the theme, show it for review and verification. Following that, apply the theme as described above."
              }
            ]
          },
          {
            "name": "productivity-kit",
            "description": "Productivity tools for project management, refactoring, and research",
            "source": "./plugins/productivity-kit",
            "category": "productivity",
            "version": "1.0.0",
            "author": null,
            "install_commands": [
              "/plugin marketplace add hongbietcode/synthetic-claude",
              "/plugin install productivity-kit@synthetic-claude"
            ],
            "signals": {
              "stars": 1,
              "forks": 0,
              "pushed_at": "2026-01-07T17:25:07Z",
              "created_at": "2025-12-28T07:34:15Z",
              "license": null
            },
            "commands": [
              {
                "name": "/git-configure",
                "description": "Configure Git user for current repository (personal or work)",
                "path": "plugins/productivity-kit/commands/git-configure.md",
                "frontmatter": {
                  "description": "Configure Git user for current repository (personal or work)",
                  "argument-hint": "personal|work",
                  "allowed-tools": [
                    "Bash"
                  ]
                },
                "content": "# Git Configuration Command\n\nCurrent directory: !`pwd`\nCurrent Git user: !`git config user.name 2>/dev/null || echo \"Not set\"`\nCurrent Git email: !`git config user.email 2>/dev/null || echo \"Not set\"`\n\n**If argument is \"personal\":**\n- Set `git config user.name \"hungson175\"`\n- Set `git config user.email \"sphamhung@gmail.com\"`\n\n**If argument is \"work\":**\n- Set `git config user.name \"son.pham9\"`\n- Set `git config user.email \"son.pham9@mservice.com.vn\"`"
              },
              {
                "name": "/integrate-parallel-work",
                "description": null,
                "path": "plugins/productivity-kit/commands/integrate-parallel-work.md",
                "frontmatter": null,
                "content": "I have features developed in parallel worktrees that I need to integrate: $ARGUMENTS\n\nPlease help me integrate these features:\n1. Create a new integration branch called \"integration/parallel-features\"\n2. For each feature name provided, merge the branch feature/[feature-name] into the integration branch\n3. Resolve any merge conflicts that arise\n4. Test that all features work together\n5. Run all tests to ensure nothing is broken\n6. Once integration is successful, merge to main and clean up branches\n\nI want to integrate these safely before merging to main."
              },
              {
                "name": "/parallel-work",
                "description": null,
                "path": "plugins/productivity-kit/commands/parallel-work.md",
                "frontmatter": null,
                "content": "I want to develop features in parallel for my app using Git worktrees: $ARGUMENTS\n\nThink about how to divide the work up into separate features unless this has been clearly explained already. \n\nPlease help me set up the worktree environment:\n1. For each feature mentioned, create a worktree at ../[app-name]-[feature-name] \nwith branch feature/[feature-name]\n2. Set up the development environment in each worktree\n3. List all worktrees to confirm they were created\n4. Explain what each worktree will contain and how they're isolated\n\nI want to be able to work on all features simultaneously without conflicts."
              },
              {
                "name": "/refactor-interactive",
                "description": null,
                "path": "plugins/productivity-kit/commands/refactor-interactive.md",
                "frontmatter": null,
                "content": "# Interactive Refactor Command\n\nRefactor $ARGUMENTS through small, reviewable steps with explanations.\n\n## Process\n\n### 1. Analysis Phase\nAnalyze the file and list refactoring opportunities ordered by safety and value. Start with quick wins.\n\n### 2. Interactive Loop\nFor each refactoring:\n- **Propose**: Explain what to change, why, and which pattern/principle applies\n- **Show**: Provide before/after code example (meaningful chunks - not too large to review, not too small to be trivial)\n- **Wait**: Get confirmation before proceeding\n- **Apply**: Make only that specific change\n- **Explain**: What was done and what principle was demonstrated\n\n### 3. Focus Areas\nConsider improvements in:\n- Code organization and clarity\n- Design patterns (Strategy, Factory, Observer, etc.)\n- SOLID principles\n- Performance optimizations\n- Removing duplication\n\n## Guidelines\n- One change at a time\n- Keep each refactoring meaningful - complete enough to demonstrate a principle, small enough to review easily\n- Preserve functionality unless explicitly discussed\n- Each step should be independently reviewable\n- Connect changes to broader principles for learning\n- Build each refactoring on previous improvements\n\n## Goal\nCreate a collaborative refactoring session where the user learns patterns while improving their code incrementally."
              },
              {
                "name": "/tidy-docs",
                "description": null,
                "path": "plugins/productivity-kit/commands/tidy-docs.md",
                "frontmatter": null,
                "content": "# Tidy Docs Command\n\nReorganize documentation in $ARGUMENTS to clearly distinguish permanent project docs from temporary ones.\n\n## Task\nSeparate essential long-term documentation from temporary files (reviews, refactors, reports ...) using clear directory structure that instantly communicates importance to any developer.\n\n## Guidelines\n- Core docs stay accessible at top level or in `core/`, `essential/`, or similar\n- Temporary docs move to clearly-marked directories like `_temp/`, `archive/`, or dated folders\n- Directory names should be self-explanatory about content importance\n- Update all references in CLAUDE.md and other docs\n- **Special**: `current_prompt.md` is auto-generated and auto-managed — do NOT move or reorganize it"
              },
              {
                "name": "/tidy-up",
                "description": null,
                "path": "plugins/productivity-kit/commands/tidy-up.md",
                "frontmatter": null,
                "content": "Cleanup Project Structure Command\nReorganize misplaced files to follow standard project conventions in: $ARGUMENTS\n\nTask\nFind files in wrong locations (tests outside test folders, scattered docs, misplaced configs) and move them to proper directories. Update all imports and references accordingly.\n\nGuidelines\nUse git mv to preserve history\nEnsure code still works after reorganization\nCreate standard directories if missing\nUpdate documentation (CLAUDE.md, README.md, etc.) to reflect new structure, if needed\nSpecial: `current_prompt.md` is auto-generated and auto-managed — do NOT move or reorganize it\n"
              },
              {
                "name": "/tmux-team-restart",
                "description": "Restart tmux team with state preservation via SM",
                "path": "plugins/productivity-kit/commands/tmux-team-restart.md",
                "frontmatter": {
                  "description": "Restart tmux team with state preservation via SM",
                  "allowed-tools": "Read, Glob, Grep, Bash(tm-send:*), Bash(tmux:*), Bash(sleep:*), Bash(./setup-team.sh), Bash(bash:*)"
                },
                "content": "> **NOTE**: Do NOT call coder-memory-recall for this command - this is a well-documented process with all steps below. Just execute the steps.\n\n# Tmux Team Restart Process\n\nRestart the tmux team session while preserving current progress state.\n\n## Execution Steps\n\n### Step 1: Find team tmux session name\n\nFind the `setup-team.sh` script and extract the session name:\n```bash\n# Find setup-team.sh in the project\nfind . -name \"setup-team.sh\" -type f 2>/dev/null | head -1\n\n# Extract SESSION_NAME from the script\ngrep -E \"^SESSION_NAME=\" ./path/to/setup-team.sh | cut -d'=' -f2 | tr -d '\"' | tr -d \"'\"\n```\n\n**Note**: Session name is typically defined in `setup-team.sh` with format `SESSION_NAME=session_name` or `SESSION_NAME=${SESSION_NAME:-session_name}`.\n\nVerify the session exists:\n```bash\ntmux has-session -t SESSION_NAME 2>/dev/null && echo \"Session found\"\n```\n\nYou can also list all active tmux sessions with roles dynamically:\n```bash\ntmux list-sessions\ntmux list-panes -a -F '#{session_name}:#{pane_index} #{@role_name}'\n```\n\n### Step 2: Tell SM to check all roles for unreported progress\n\nSend message to SM using tm-send (use `-s` flag for explicit session):\n```bash\ntm-send -s SESSION_NAME SM \"BOSS -> SM: TEAM RESTART INITIATED. Check ALL roles (PO, TL, BE, FE, QA, etc.) for any unreported work-in-progress. Capture everything before session restart. Report back when done with: (1) List of roles checked, (2) Summary of unreported progress found, (3) Timestamp showing check complete.\"\n```\n\nWait in 15s loop until SM confirms done:\n```bash\n# Wait loop - check WHITEBOARD.md modification time or SM response every 15s\n# Continue when SM reports completion\nsleep 15\n```\n\n### Step 3: Tell SM to update WHITEBOARD with all current status\n\n```bash\ntm-send -s SESSION_NAME SM \"BOSS -> SM: Now update WHITEBOARD.md with complete status: (1) Current sprint progress, (2) All in-progress tasks from each role, (3) Any blockers or key decisions, (4) Next steps for resumption. Reply 'WHITEBOARD UPDATED [timestamp]' when done.\"\n```\n\nWait in 15s loop until SM confirms WHITEBOARD is updated.\n\n### Step 4: Kill tmux session\n\n```bash\ntmux kill-session -t SESSION_NAME\n```\n\n### Step 5: Understand team structure\n\nUse dynamic tmux queries to understand the team structure:\n```bash\n# List all panes with their roles in the session\ntmux list-panes -t SESSION_NAME -F '#{pane_index} #{@role_name}'\n\n# Or read workflow.md if it exists\nfind ./docs/tmux/*/workflow.md -type f 2>/dev/null | head -1\n```\n\n**Note**: Role information is stored in tmux pane options (`@role_name`), not in static files. Always query tmux directly for current state.\n\n### Step 6: Run setup-team.sh\n\n```bash\ncd /path/to/team/folder && ./setup-team.sh\n```\n\nWait for all panes to initialize (script handles its own delays).\n\n### Step 7: Tell PO to read WHITEBOARD and resume\n\n```bash\ntm-send -s SESSION_NAME PO \"BOSS -> PO: Team restarted successfully. Read WHITEBOARD.md for current sprint status and all in-progress work. Coordinate with SM and other roles to resume from where we left off. Continue Sprint execution.\"\n```\n\n## Important Notes\n\n- The 15s sleep loop is critical - don't proceed until SM confirms each step\n- Session name comes from `setup-team.sh` in the team folder (look for `SESSION_NAME=`)\n- WHITEBOARD.md must contain complete state before killing session\n- After restart, PO drives resumption based on WHITEBOARD\n- **Use tm-send with `-s SESSION_NAME` flag** if auto-detection fails (e.g., `tm-send -s quiz_game SM \"message\"`)\n\n## ⚠️ CRITICAL BUG WARNING: Pane Detection\n\n**THE BUG**: When determining which tmux pane you're running in, **NEVER use `tmux display-message -p '#{pane_index}'`** - this returns the **ACTIVE/FOCUSED pane** (where user's cursor is), NOT the pane where Claude is actually running.\n\n**THE FIX**: Always use the `$TMUX_PANE` environment variable:\n\n```bash\n# WRONG - Returns active pane, not your pane\ntmux display-message -p '#{pane_index}'\n\n# CORRECT - Returns YOUR pane\necho $TMUX_PANE\n# Then look up this pane ID in the pane list to get role\ntmux list-panes -a -F '#{pane_id} #{pane_index} #{@role_name}' | grep $TMUX_PANE\n```\n\n**WHY THIS MATTERS**:\n- In multi-agent teams, each pane has a role (PO, SM, TL, DEV, QA, etc.)\n- Messages must route correctly based on the pane's assigned role\n- If you misidentify your pane, you'll send messages to wrong agents\n- This wastes hours debugging \"why is PO acting like DEV?\"\n\n**WHEN CRITICAL**: During Step 7 (role initialization after restart), new Claude instances MUST use `$TMUX_PANE` to identify which pane they're in, NOT the active cursor position.\n\n## Dynamic Queries (No Static Files)\n\n**CRITICAL**: PANE_ROLES.md and tmux_team_overview.md are DEPRECATED and removed from all frameworks.\n\nAlways use dynamic tmux queries:\n```bash\n# Find all sessions\ntmux list-sessions\n\n# Find panes with roles in a specific session\ntmux list-panes -t SESSION_NAME -F '#{session_name}:#{pane_index} #{@role_name}'\n\n# List all panes across all sessions\ntmux list-panes -a -F '#{session_name}:#{pane_index} #{@role_name}'\n\n# Check if session exists\ntmux has-session -t SESSION_NAME 2>/dev/null && echo \"Exists\"\n```\n\nThe `@role_name` pane option is set by setup scripts and queried dynamically by tm-send."
              },
              {
                "name": "/init-role",
                "description": null,
                "path": "plugins/productivity-kit/skills/tmux-team-creator/sample_team/commands/init-role.md",
                "frontmatter": null,
                "content": "# Initialize Agent Role\n\nYou are initializing as a member of an AI Multi-Agent Team.\n\n## Step 1: Detect Team\n\nBased on the tmux session name, determine which team you belong to.\n\nCheck with:\n```bash\ntmux display-message -p '#S'\n```\n\n## Step 2: Read System Documentation\n\nRead the appropriate team overview:\n\n**File**: `docs/tmux/[team-name]/workflow.md`\n\n## Step 3: Read Your Role Prompt\n\nBased on the role argument `$ARGUMENTS`, read your specific role prompt:\n\n**Typical roles:**\n- **PM** (Project Manager): `docs/tmux/[team-name]/prompts/PM_PROMPT.md`\n- **SA** (Solution Architect): `docs/tmux/[team-name]/prompts/SA_PROMPT.md`\n- **BE** (Backend Engineer): `docs/tmux/[team-name]/prompts/BE_PROMPT.md`\n- **FE** (Frontend Engineer): `docs/tmux/[team-name]/prompts/FE_PROMPT.md`\n- **CR** (Code Reviewer): `docs/tmux/[team-name]/prompts/CR_PROMPT.md`\n- **DK** (Document Keeper): `docs/tmux/[team-name]/prompts/DK_PROMPT.md`\n\n## Step 4: Understand Your Mission\n\nAfter reading both files:\n1. Confirm your role and responsibilities\n2. Verify your communication pane IDs are configured\n3. Check the WHITEBOARD for current sprint status\n4. Be ready to execute your role in the workflow\n\n## Step 5: Announce Readiness\n\nAfter initialization, announce:\n```\n[ROLE] initialized and ready.\nTeam: [team name]\nWHITEBOARD status: [status from WHITEBOARD.md]\nAwaiting [PM/Boss] directives.\n```\n"
              }
            ],
            "skills": [
              {
                "name": "coder-memory-recall",
                "description": "Retrieve universal coding patterns from vector database using true two-stage retrieval. Auto-invokes before complex tasks or when user says \"--recall\". Searches relevant role collections based on task context.",
                "path": "plugins/productivity-kit/skills/coder-memory-recall/SKILL.md",
                "frontmatter": {
                  "name": "coder-memory-recall",
                  "description": "Retrieve universal coding patterns from vector database using true two-stage retrieval. Auto-invokes before complex tasks or when user says \"--recall\". Searches relevant role collections based on task context."
                },
                "content": "## ⚠️ MANDATORY: Use Task Tool (Sub-Agent)\n\n**NEVER call memory MCP tools directly!** Use Task tool with `subagent_type: \"general-purpose\"` to keep main context clean.\n\n---\n\n## CRITICAL: When NOT to Search Memory\n\n**Skip memory search for obvious tasks** - killing processes, starting servers, basic file operations, standard workflows.\n\n**Only search for hard problems** - non-obvious bugs, complex architectures, performance issues, unfamiliar domains.\n\n**Rule**: If basic knowledge suffices, skip memory. Memory is for hard-won lessons.\n\n---\n\n# Embedded Role Configuration\n\n```yaml\n# Embedded configuration - no external files needed\nrole_collections:\n  global:\n    universal:\n      name: \"universal-patterns\"\n      description: \"Search here for cross-domain patterns\"\n      query_hints: [\"general\", \"architecture\", \"debugging\", \"performance\"]\n\n    backend:\n      name: \"backend-patterns\"\n      description: \"Backend engineering patterns\"\n      query_hints: [\"api\", \"database\", \"auth\", \"server\", \"microservices\"]\n\n    frontend:\n      name: \"frontend-patterns\"\n      description: \"Frontend engineering patterns\"\n      query_hints: [\"react\", \"vue\", \"component\", \"ui\", \"state\"]\n\n    quant:\n      name: \"quant-patterns\"\n      description: \"Quantitative finance patterns\"\n      query_hints: [\"trading\", \"backtest\", \"risk\", \"portfolio\"]\n\n    devops:\n      name: \"devops-patterns\"\n      description: \"DevOps and infrastructure patterns\"\n      query_hints: [\"docker\", \"kubernetes\", \"ci-cd\", \"terraform\"]\n\n    ai:\n      name: \"ai-patterns\"\n      description: \"AI and machine learning patterns\"\n      query_hints: [\"model\", \"training\", \"neural\", \"llm\", \"embedding\"]\n\n    security:\n      name: \"security-patterns\"\n      description: \"Security engineering patterns\"\n      query_hints: [\"vulnerability\", \"encryption\", \"auth\", \"pentest\"]\n\n    mobile:\n      name: \"mobile-patterns\"\n      description: \"Mobile development patterns\"\n      query_hints: [\"ios\", \"android\", \"react-native\", \"flutter\"]\n\n    pm:\n      name: \"pm-patterns\"\n      description: \"Project management and coordination patterns\"\n      query_hints: [\"coordination\", \"delegation\", \"team\", \"sprint\", \"planning\", \"reporting\"]\n\n# Role detection from task context\nrole_detection:\n  patterns:\n    backend: \"api|endpoint|database|server|auth|rest|graphql\"\n    frontend: \"react|vue|component|ui|dom|css|state\"\n    quant: \"trading|backtest|portfolio|risk|market\"\n    devops: \"deploy|docker|kubernetes|ci|cd\"\n    ai: \"model|training|neural|embedding|llm\"\n    security: \"vulnerability|encryption|pentest|jwt\"\n    mobile: \"ios|android|native|flutter|swift\"\n    pm: \"project|coordination|delegation|team|sprint|phase|reporting|stakeholder\"\n\n  multi_role_strategy: \"search_all\"  # When multiple roles detected\n  default_role: \"universal\"          # When no clear role\n```\nYou can create new role if you think it worth it. But be EXTREMELY CONSERVATIVE when creating new roles - when you create a new one, add it in this very doc (~/.claude/skills/coder-memory-recall/SKILL.md and ~/.claude/skills/coder-memory-store/SKILL.md).\n\n## PHASE 1: Intelligent Query Construction\n\n**Note**: Claude Code automatically determines relevant roles from task context. No explicit role detection logic needed - Claude is smart enough to select appropriate roles when calling MCP tools.\n\n### Query Building\n\nBuild semantic query (2-3 sentences) capturing:\n1. What is the problem/goal?\n2. What is the technical context?\n3. What outcome is desired?\n\n## MCP Server Tools\n\n**CRITICAL**: Use tools from the **memory MCP server**:\n- `search_memory` - Search and get previews\n- `get_memory` - Get full content by ID\n- `batch_get_memories` - Get multiple full contents\n- `store_memory` - Store new memory\n- `update_memory` - Update existing memory\n- `delete_memory` - Delete memory\n- `list_collections` - List all collections\n\n## PHASE 2: Two-Stage Retrieval\n\n### Stage 1: Search for Previews (Cast Wide Net)\n\nUse `search_memory` tool (from memory MCP server) with the query and correct memory_level (global, project, etc.), default: `memory_level=\"global\"`. Claude Code determines relevant roles automatically. Default limit is 20 previews.\n\n### Stage 2: Analyze Previews (Intelligence Over Thresholds)\n\n**Analyze each preview**:\n- Does title match the problem domain?\n- Does description indicate relevant solution?\n- Do tags align with task?\n- Is memory type appropriate? (episodic for debugging, procedural for workflows, semantic for principles)\n\n**Select 3-5 most relevant** based on your judgement.\n\n### Stage 3: Retrieve Full Content\n\nUse `batch_get_memories` tool (from memory MCP server) with the selected doc_ids and `memory_level=\"global\"`. This retrieves full content for 3-5 most relevant memories.\n\n\n## PHASE 3: Present Results\n\nFormat for Claude to consume:\n**Key**: Let Claude read and decide what to use. Don't force-fit patterns.\n\n---\n\n## Tool Usage\n\nSee top of this document - **MUST use Task tool (sub-agent)** to avoid context pollution."
              },
              {
                "name": "coder-memory-store",
                "description": "Store universal coding patterns into vector database. Auto-invokes after difficult tasks with broadly-applicable lessons. Trigger with \"--store\" or when user expresses frustration (strong learning signals). Uses true two-stage retrieval with MCP server v2.",
                "path": "plugins/productivity-kit/skills/coder-memory-store/SKILL.md",
                "frontmatter": {
                  "name": "coder-memory-store",
                  "description": "Store universal coding patterns into vector database. Auto-invokes after difficult tasks with broadly-applicable lessons. Trigger with \"--store\" or when user expresses frustration (strong learning signals). Uses true two-stage retrieval with MCP server v2."
                },
                "content": "## ⚠️ MANDATORY: Use Task Tool (Sub-Agent)\n\n**NEVER call memory MCP tools directly!** Use Task tool with `subagent_type: \"general-purpose\"` to keep main context clean.\n\n---\n\n## CRITICAL: When NOT to Store Memory\n\n**Skip storing obvious tasks** - simple commands, basic operations, well-documented patterns, routine fixes.\n\n**Only store hard lessons** - non-obvious bugs, surprising patterns, failures, universal insights, significant struggles.\n\n**Rule**: If it's in docs or Google-able in 30 seconds, skip. Memory is for hard-won lessons.\n\n---\n\n# Embedded Role Configuration\n\n```yaml\n# Embedded configuration - no external files needed\nrole_collections:\n  global:\n    universal:\n      name: \"universal-patterns\"\n      description: \"Search here for cross-domain patterns\"\n      query_hints: [\"general\", \"architecture\", \"debugging\", \"performance\"]\n\n    backend:\n      name: \"backend-patterns\"\n      description: \"Backend engineering patterns\"\n      query_hints: [\"api\", \"database\", \"auth\", \"server\", \"microservices\"]\n\n    frontend:\n      name: \"frontend-patterns\"\n      description: \"Frontend engineering patterns\"\n      query_hints: [\"react\", \"vue\", \"component\", \"ui\", \"state\"]\n\n    quant:\n      name: \"quant-patterns\"\n      description: \"Quantitative finance patterns\"\n      query_hints: [\"trading\", \"backtest\", \"risk\", \"portfolio\"]\n\n    devops:\n      name: \"devops-patterns\"\n      description: \"DevOps and infrastructure patterns\"\n      query_hints: [\"docker\", \"kubernetes\", \"ci-cd\", \"terraform\"]\n\n    ai:\n      name: \"ai-patterns\"\n      description: \"AI and machine learning patterns\"\n      query_hints: [\"model\", \"training\", \"neural\", \"llm\", \"embedding\"]\n\n    security:\n      name: \"security-patterns\"\n      description: \"Security engineering patterns\"\n      query_hints: [\"vulnerability\", \"encryption\", \"auth\", \"pentest\"]\n\n    mobile:\n      name: \"mobile-patterns\"\n      description: \"Mobile development patterns\"\n      query_hints: [\"ios\", \"android\", \"react-native\", \"flutter\"]\n\n    pm:\n      name: \"pm-patterns\"\n      description: \"Project management and coordination patterns\"\n      query_hints: [\"coordination\", \"delegation\", \"team\", \"sprint\", \"planning\", \"reporting\"]\n\n# Role detection from task context\nrole_detection:\n  patterns:\n    backend: \"api|endpoint|database|server|auth|rest|graphql\"\n    frontend: \"react|vue|component|ui|dom|css|state\"\n    quant: \"trading|backtest|portfolio|risk|market\"\n    devops: \"deploy|docker|kubernetes|ci|cd\"\n    ai: \"model|training|neural|embedding|llm\"\n    security: \"vulnerability|encryption|pentest|jwt\"\n    mobile: \"ios|android|native|flutter|swift\"\n    pm: \"project|coordination|delegation|team|sprint|phase|reporting|stakeholder\"\n\n  multi_role_strategy: \"search_all\"  # When multiple roles detected\n  default_role: \"universal\"          # When no clear role\n```\nYou can create new role if you think it worth it. But be EXTREMELY CONSERVATIVE when creating new roles - when you create a new one, add it in this very doc (~/.claude/skills/coder-memory-recall/SKILL.md and ~/.claude/skills/coder-memory-store/SKILL.md).\n\n## MCP Server Tools\n\n**CRITICAL**: Use tools from the **memory MCP server**:\n- `search_memory` - Search and get previews\n- `get_memory` - Get full content by ID\n- `batch_get_memories` - Get multiple full contents\n- `store_memory` - Store new memory\n- `update_memory` - Update existing memory\n- `delete_memory` - Delete memory\n- `list_collections` - List all collections\n\n## PHASE 1: Extract Insights\n\nAnalyze conversation for **0-3 insights** (usually 0-1). Be selective.\n\n### Classification\n\n**Episodic**: Concrete debugging/implementation story\nExample: \"React useEffect dependency array bug caused stale closure\"\n\n**Procedural**: Repeatable workflow or process\nExample: \"Zero-downtime database migration: 1) Create script, 2) Test staging, 3) Run in transaction, 4) Monitor\"\n\n**Semantic**: Abstract principle or pattern\nExample: \"Distributed systems need randomness to avoid synchronization disasters\"\n\n### Criteria (ALL must be true)\n\n1. **Non-obvious**: Not well-documented standard practice\n   ❌ \"Use try-catch for error handling\"\n   ✅ \"useCallback without deps array causes stale closures\"\n\n2. **Universal**: Applies beyond specific project/framework\n   ❌ \"Config for our Jenkins pipeline\"\n   ✅ \"Blue-green deployments reduce downtime risk\"\n\n3. **Actionable**: Provides concrete guidance\n   ❌ \"Performance is important\"\n   ✅ \"Use debouncing (300ms) for autocomplete inputs to reduce API calls\"\n\n4. **Valuable**: Would help future similar situations\n   ❌ \"Fixed typo in variable name\"\n   ✅ \"Binary search debugging: disable half the features to isolate bug source\"\n\n### Role Detection\n\n```python\n# Scan task context for keywords\ncontext = \"Built REST API with JWT authentication and rate limiting\"\n\n# Detected keywords: api, rest, authentication, jwt, rate\n# → Role: \"backend\"\n\n# If multiple roles or unclear → \"universal\"\n```\n\n## PHASE 2: Search for Similar (Two-Stage)\n\n### Format Memory First\n\n```\n**Title:** API Rate Limiting with Exponential Backoff\n**Description:** Exponential backoff with jitter prevents thundering herd.\n\n**Content:** When implementing rate limiting for API calls, simple retry logic caused thundering herd problem. Tried fixed delays but all clients retry simultaneously. Solution: exponential backoff (2^n seconds) with random jitter (±0-30%). This spreads retry attempts preventing server overload. Key lesson: distributed systems need randomness to avoid synchronization.\n\n**Tags:** #backend #api #rate-limiting #success\n```\n\n### Stage 1: Search Previews\n\nUse `search_memory` tool (from memory MCP server) with the full formatted memory text as query and correct memory_level (global, project, etc.), default: `memory_level=\"global\"`. Use the full text (not just title) for better semantic matching.\n\n**Why full text as query?** Better semantic matching captures full context.\n\n### Stage 2: Intelligent Preview Analysis\n\nReview previews to decide consolidation action:\n\n**High similarity** → Likely duplicate\n→ Retrieve full content for MERGE decision\n\n**Medium similarity** → Possibly related\n→ Retrieve full content for UPDATE decision\n\n**Multiple episodic** → Pattern emerges\n→ Retrieve all for GENERALIZE decision\n\n**Low similarity** → Different topic\n→ CREATE new memory (no retrieval needed)\n\nUse `batch_get_memories` tool (from memory MCP server) with relevant doc_ids and correct memory_level (global, project, etc.), default: `memory_level=\"global\"` to retrieve full content for consolidation candidates.\n\n## PHASE 3: Intelligent Consolidation\n\n### Decision Framework (No Rigid Thresholds)\n\n| Analysis | Signal | Action |\n|----------|--------|--------|\n| **Near-identical** | Same problem, same solution, same title | **MERGE** - Combine best parts, delete duplicate |\n| **Related topic** | Complementary info, overlapping tags | **UPDATE** - Enhance existing with new insights |\n| **Pattern emerges** | 2+ episodic show common pattern | **GENERALIZE** - Extract semantic pattern |\n| **Different** | Orthogonal concept | **CREATE** - New memory |\n\n## PHASE 4: Store Memory\n\n### Final Storage\n\nUse `store_memory` tool (from memory MCP server) with the final document, metadata, and `memory_level=\"global\"`. Log the result doc_id and action taken.\n\n**CRITICAL - Required metadata fields:**\n```json\n{\n  \"memory_type\": \"episodic|procedural|semantic\",\n  \"role\": \"backend|frontend|ai|devops|...\",\n  \"title\": \"Short descriptive title\",\n  \"description\": \"One-line summary for search previews - REQUIRED!\",\n  \"tags\": [\"#tag1\", \"#tag2\"],\n  \"confidence\": \"high|medium|low\",\n  \"frequency\": 1\n}\n```\n\n**Why `description` is critical:** The `search_memory` tool returns previews with title + description. If description is missing, search results show \"No description\" making it impossible to identify relevant memories.\n\n### Trigger Words for Strong Learning Signals\n\nWhen user expresses frustration (trigger words), this is a **critical learning moment**:\n\n**Profanity**: fuck, shit, damn, wtf, ffs\n**Frustration**: moron, idiot, stupid, garbage, useless, terrible\n**Emotional**: hate, angry, frustrated, \"this is ridiculous\", \"you're not listening\"\n\n**When detected**:\n1. Recognize as high-value learning signal\n2. Store as episodic memory with full context of failure\n3. Tag with #failure and #strong-signal\n4. Prioritize over routine successes\n\n---\n\n## Tool Usage\n\nSee top of this document - **MUST use Task tool (sub-agent)** to avoid context pollution."
              },
              {
                "name": "quick-research",
                "description": "This skill should be used when users need comprehensive research on a topic requiring exploration of multiple sources, synthesis of findings, and a well-structured report with citations. Use for complex research queries like \"Research the latest developments in X\", \"Compare A vs B vs C\", \"Find the top N candidates for Y\", or any request requiring deep exploration beyond a simple web search.",
                "path": "plugins/productivity-kit/skills/quick-research/SKILL.md",
                "frontmatter": {
                  "name": "quick-research",
                  "description": "This skill should be used when users need comprehensive research on a topic requiring exploration of multiple sources, synthesis of findings, and a well-structured report with citations. Use for complex research queries like \"Research the latest developments in X\", \"Compare A vs B vs C\", \"Find the top N candidates for Y\", or any request requiring deep exploration beyond a simple web search."
                },
                "content": "# Quick Research\n\n## Overview\n\nQuick research enables comprehensive topic exploration using a multi-agent architecture. A lead researcher (Claude Code) orchestrates multiple parallel research sub-agents to explore different aspects of a topic simultaneously, then synthesizes findings into a well-cited report.\n\nThis approach mirrors Anthropic's production research system which found that multi-agent systems outperform single-agent by 90%+ on breadth-first queries.\n\n## When to Use This Skill\n\n- Complex research requiring multiple independent directions\n- Comparative analyses (e.g., \"Compare OpenAI vs Anthropic vs Google approaches to AI safety\")\n- List/ranking requests (e.g., \"Find the top 20 AI companies in healthcare\")\n- Validation questions requiring deep domain exploration\n- Any research exceeding what a single web search can accomplish\n\n## Architecture\n\n```pseudo\n# PSEUDO-CODE - Conceptual workflow, not executable code\n\ndef deep_research(user_query):\n    # Phase 1: Scope\n    brief = clarify_and_create_research_brief(user_query)\n\n    # Phase 2: Research Loop (max 3 iterations)\n    all_findings = []\n    for iteration in range(3):\n        subtopics = identify_gaps_or_subtopics(brief, all_findings)\n        if not subtopics:\n            break  # sufficient findings\n\n        # Spawn parallel sub-agents (in single message)\n        findings = parallel([\n            Task(subagent_type=\"research-assistant\", prompt=topic)\n            for topic in subtopics\n        ])\n        all_findings.extend(findings)\n\n    # Phase 3: Synthesize\n    synthesized = merge_and_deduplicate(all_findings)\n\n    # Phase 4: Report\n    return generate_report_with_citations(brief, synthesized)\n```\n\n## Quick Research Workflow\n\n### Phase 1: Scope the Research\n\nBefore spawning sub-agents, clarify the research scope:\n\n1. **Analyze the query** - What specific information does the user need?\n2. **Ask clarifying questions if needed** - Use AskUserQuestion for ambiguous terms, acronyms, or missing context\n3. **Create a research brief** - A focused statement capturing:\n   - The core research question\n   - Specific dimensions to explore\n   - Any constraints or preferences from the user\n   - Source quality preferences (academic, official, etc.)\n\n### Phase 2: Delegate Research to Sub-Agents\n\nUse the Task tool with `subagent_type: \"research-assistant\"` to spawn parallel research agents.\n\n#### Scaling Rules\n\n| Query Type | Sub-Agents | Tool Calls Each |\n|------------|------------|-----------------|\n| Simple fact-finding | 1 | 3-10 |\n| Direct comparisons | 2-4 (one per element) | 10-15 |\n| Complex/broad research | 5-10 | 15-20 |\n\n#### Delegation Best Practices\n\n1. **Provide complete, standalone instructions** - Sub-agents cannot see other agents' work\n2. **Specify clear task boundaries** - Avoid overlapping responsibilities\n3. **Define output format expectations** - What structure should findings take?\n4. **Include source guidance** - What types of sources to prioritize?\n5. **Avoid acronyms** - Be explicit and specific in task descriptions\n\n#### Example: Spawning Parallel Sub-Agents\n\nFor a query like \"Compare OpenAI vs Anthropic vs Google approaches to AI safety\":\n\n```\nUse Task tool THREE times in parallel (single message, multiple tool uses):\n\nTask 1:\n  subagent_type: \"research-assistant\"\n  prompt: |\n    Research OpenAI's approach to AI safety and alignment.\n    Focus on:\n    - Their philosophical framework for AI safety\n    - Key research priorities and publications\n    - Their stance on the alignment problem\n    - Notable safety initiatives and teams\n\n    Return findings with inline citations in format [Source Title](URL).\n    Prioritize official OpenAI sources, research papers, and executive statements.\n\nTask 2:\n  subagent_type: \"research-assistant\"\n  prompt: |\n    Research Anthropic's approach to AI safety and alignment.\n    Focus on:\n    - Their philosophical framework (Constitutional AI, etc.)\n    - Key research priorities and publications\n    - Their stance on the alignment problem\n    - Notable safety initiatives and teams\n\n    Return findings with inline citations in format [Source Title](URL).\n    Prioritize official Anthropic sources and research papers.\n\nTask 3:\n  subagent_type: \"research-assistant\"\n  prompt: |\n    Research Google DeepMind's approach to AI safety and alignment.\n    Focus on:\n    - Their philosophical framework for AI safety\n    - Key research priorities and publications\n    - Their stance on the alignment problem\n    - Notable safety initiatives and teams\n\n    Return findings with inline citations in format [Source Title](URL).\n    Prioritize official DeepMind sources and research papers.\n```\n\n**CRITICAL**: Launch all sub-agents in a SINGLE message with multiple Task tool calls to enable true parallelization.\n\n### Phase 3: Synthesize Findings\n\nAfter all sub-agents return:\n\n1. **Collect all findings** - Gather results from each sub-agent\n2. **Identify patterns and gaps** - What themes emerge? What's missing?\n3. **Spawn additional sub-agents if needed** - Fill gaps with targeted follow-up research\n4. **Deduplicate and organize** - Remove redundant information, structure by theme\n\n### Phase 4: Generate Final Report\n\nCreate a comprehensive report that:\n\n1. **Answers the research brief directly**\n2. **Organizes by logical structure** (see Report Structures below)\n3. **Includes all relevant findings** with inline citations\n4. **Ends with Sources section** listing all referenced URLs\n\n#### Report Structures\n\n**For comparisons:**\n```markdown\n# [Topic] Comparison\n\n## Overview\n[Brief context]\n\n## [Element A]\n[Detailed findings]\n\n## [Element B]\n[Detailed findings]\n\n## Comparative Analysis\n[Cross-cutting comparison]\n\n## Conclusion\n[Key takeaways]\n\n## Sources\n[Numbered list of all sources]\n```\n\n**For lists/rankings:**\n```markdown\n# Top [N] [Category]\n\n## 1. [Item]\n[Details with citations]\n\n## 2. [Item]\n[Details with citations]\n\n...\n\n## Sources\n[Numbered list]\n```\n\n**For topic exploration:**\n```markdown\n# [Topic] Research Report\n\n## Overview\n[Context and scope]\n\n## [Aspect 1]\n[Detailed findings]\n\n## [Aspect 2]\n[Detailed findings]\n\n## Key Insights\n[Synthesized conclusions]\n\n## Sources\n[Numbered list]\n```\n\n## Citation Rules\n\n- Assign each unique URL a single citation number\n- Use inline citations: `[1]` or `[Source Title](URL)`\n- Number sources sequentially (1, 2, 3...) without gaps\n- End with `## Sources` section listing all sources:\n  ```\n  ## Sources\n  [1] Source Title: URL\n  [2] Source Title: URL\n  ```\n\n## Hard Limits\n\nTo prevent excessive resource usage:\n\n- **Maximum 10 parallel sub-agents** per research iteration\n- **Maximum 3 research iterations** (initial + 2 follow-ups)\n- **Stop when findings are sufficient** - Don't pursue perfection\n- **Token awareness** - Multi-agent systems use ~15x more tokens than chat\n\n## Key Insights from Anthropic's Research System\n\n1. **Token usage explains 80% of performance variance** - Distribute work across agents with separate context windows\n2. **Start wide, then narrow** - Broad queries first, progressively focus\n3. **Context isolation prevents failures** - Each sub-agent handles one subtopic cleanly\n4. **Sub-agent output compression** - Have sub-agents summarize their findings to avoid \"game of telephone\" information loss\n5. **Parallel execution cuts time 90%** - Always spawn sub-agents in parallel when independent\n\n## References\n\nFor detailed prompt templates and architecture details, see:\n- `references/prompts.md` - Research agent prompt templates\n- `references/architecture.md` - Multi-agent system architecture details"
              },
              {
                "name": "tmux-team-creator",
                "description": "This skill should be used when users want to create a multi-agent tmux team for their project. It provides battle-tested templates for setting up autonomous AI agent teams that collaborate via tmux. Use this skill when users ask to create AI teams, set up multi-agent workflows, or build autonomous coding teams. The skill includes 4 sample team templates (2 software development + 2 research) that can be customized for any domain.",
                "path": "plugins/productivity-kit/skills/tmux-team-creator/SKILL.md",
                "frontmatter": {
                  "name": "tmux-team-creator",
                  "description": "This skill should be used when users want to create a multi-agent tmux team for their project. It provides battle-tested templates for setting up autonomous AI agent teams that collaborate via tmux. Use this skill when users ask to create AI teams, set up multi-agent workflows, or build autonomous coding teams. The skill includes 4 sample team templates (2 software development + 2 research) that can be customized for any domain."
                },
                "content": "# Tmux Team Creator\n\n## Overview\n\nThis skill enables creating powerful multi-agent AI teams that run autonomously in tmux sessions. The architecture is battle-tested on complex projects and can be customized for any domain.\n\n**Key Insight**: Sample teams are TEMPLATES, not exact copies. When creating a team, customize roles, prompts, and workflows for the specific project.\n\n---\n\n## ⚠️ CRITICAL: Tmux Pane Detection Bug (EXTREMELY COMMON)\n\n**THIS BUG WILL WASTE HOURS IF NOT PREVENTED!**\n\n### The Bug\n\nWhen agents need to determine which tmux pane they're running in, **NEVER use `tmux display-message -p '#{pane_index}'`** - this command returns the **ACTIVE/FOCUSED pane** (where the user's cursor is), NOT the pane where the agent is actually running!\n\n### The Fix\n\n**Always use the `$TMUX_PANE` environment variable:**\n\n```bash\n# WRONG - Returns active cursor pane, not your pane\ntmux display-message -p '#{pane_index}'\n\n# CORRECT - Returns YOUR actual pane\necho $TMUX_PANE\n# Then look up this pane ID to get your role\ntmux list-panes -a -F '#{pane_id} #{pane_index} #{@role_name}' | grep $TMUX_PANE\n```\n\n### Why This Matters\n\n- In multi-agent teams, each pane has a specific role (PO, TL, DEV, etc.)\n- Messages must route correctly based on pane roles\n- If agents misidentify their pane, they send messages to wrong agents\n- This causes hours of debugging \"why is PO acting like DEV?\"\n\n### Where to Check\n\nWhen creating a new team from templates, verify these files use `$TMUX_PANE`:\n\n1. **Role prompt files** (`prompts/*_PROMPT.md`) - Should document correct pane detection\n2. **Init commands** (`commands/init-role.md`) - Should use `$TMUX_PANE` for role detection\n3. **Setup scripts** (`setup-team.sh`) - Should set `@role_name` on correct panes\n4. **Hook scripts** (`hooks/*.sh`, `hooks/*.py`) - **CRITICAL:** Must use `$TMUX_PANE`\n   - **Bash hooks:** `ROLE=$(tmux show-options -t \"$TMUX_PANE\" -qv @role_name)`\n   - **Python hooks:** `tmux_pane = os.environ.get(\"TMUX_PANE\")` then `[\"tmux\", \"show-options\", \"-pt\", tmux_pane, \"-qv\", \"@role_name\"]`\n   - **WRONG:** `tmux show-options -pv @role_name` (queries cursor pane!)\n   - **FIX APPLIED:** `hooks/session_start_team_docs.py` (2026-01-02) - All new teams now use correct detection\n\n### Prevention Checklist\n\nWhen creating a new team, add this to ALL role prompts:\n\n```markdown\n## Tmux Pane Configuration & Role Detection\n\n**CRITICAL: Correct Pane Detection**\n\n**NEVER use `tmux display-message -p '#{pane_index}'`** - it returns the active/focused pane, not YOUR pane!\n\n**Always use $TMUX_PANE environment variable:**\n\n\\`\\`\\`bash\n# Find YOUR actual pane ID\necho \"My pane: $TMUX_PANE\"\n\n# Look up your pane's role\ntmux list-panes -a -F '#{pane_id} #{pane_index} #{@role_name}' | grep $TMUX_PANE\n\\`\\`\\`\n```\n\n**This bug has already been fixed in all sample team templates.** When creating new teams, copy the corrected patterns.\n\n---\n\n## FIRST: Ask User Which Team Template\n\n**Before creating any team, ask the user which template they want to use.**\n\n### Available Templates\n\n#### Software Development Teams\n\n| Template | Best For | Roles | Key Features |\n|----------|----------|-------|--------------|\n| **scrum-team** | Standard Scrum projects | PO, SM, TL, BE, FE, QA | Full Scrum framework, SM owns process improvement, Sprint-based |\n| **scrum-minimal-team** | Small projects, MVPs | PO, SM, EX | Lightweight 3-person Scrum, EX combines TL+DEV+QA |\n| **game-dev-team** | Game development projects | PM, GD, FE, BE, QA | Game-focused with design→implementation flow |\n\n#### Research & Analysis Teams\n\n| Template | Best For | Roles | Key Features |\n|----------|----------|-------|--------------|\n| **mckinsey-research-team** | Market research, competitive analysis | EM, RL, PR, SR, DA, QR | McKinsey 7-step methodology, MECE structuring, Pyramid Principle |\n| **pg-insights-team** | Consumer insights, brand strategy | IM, MR, IA, SL, QR | P&G Three-Step Formula, human-centric, goosebumps test |\n\n### Selection Logic\n\n**If user specifies:**\n- \"Scrum team\" / \"standard Scrum\" / \"with Scrum Master\" → Use `scrum-team`\n- \"minimal Scrum\" / \"small team\" / \"solo dev\" / \"MVP\" / \"lightweight\" → Use `scrum-minimal-team`\n- \"game\" / \"game development\" / \"game project\" → Use `game-dev-team`\n- \"market research\" / \"competitive analysis\" / \"McKinsey\" / \"research team\" → Use `mckinsey-research-team`\n- \"consumer insights\" / \"P&G\" / \"brand strategy\" / \"emotional research\" → Use `pg-insights-team`\n\n**If user doesn't specify:**\nAsk: \"Which team template would you like to use?\"\n\n**Software Development:**\n- **scrum-team** (Recommended for dev) - Full Scrum with PO, SM, TL, BE, FE, QA. SM owns process improvement.\n- **game-dev-team** - Game development with PM, GD, FE, BE, QA. Design-first workflow.\n\n**Research & Analysis:**\n- **mckinsey-research-team** - McKinsey-style research with EM, RL, PR, SR, DA, QR. Hypothesis-driven, MECE structured.\n- **pg-insights-team** - P&G-style consumer insights with IM, MR, IA, SL, QR. Human-centric, emotional + logical.\n\n### Template Descriptions\n\n#### 1. scrum-team (Recommended for most projects)\n\n**Roles:** PO (Product Owner), SM (Scrum Master), TL (Tech Lead), BE (Backend), FE (Frontend), QA (Tester)\n\n**Key Features:**\n- Full Scrum framework adapted for AI teams\n- SM owns process improvement with 4-checkpoint monitoring mechanism\n- Sprint-based workflow with Planning, Review, Retrospective\n- Black-box QA testing\n- Prompt hygiene rules (add after 2-3 recurring issues, remove when learned)\n\n**Best for:** Teams that want structured improvement, multiple sprints, quality focus\n\n#### 2. scrum-minimal-team (Lightweight Scrum)\n\n**Roles:** PO (Product Owner), SM (Scrum Master), EX (Executive = TL + DEV + QA)\n\n**Key Features:**\n- Minimal overhead for small projects\n- EX combines architecture, development, and testing\n- Same Sprint-based workflow as full Scrum\n- SM still owns process improvement\n- 3-pane tmux layout\n\n**Best for:** Solo developers, MVPs, prototypes, personal projects wanting Scrum structure\n\n#### 3. game-dev-team (Game Development)\n\n**Roles:** DS (Game Designer), SM (Scrum Master), AR (Game Architect), DV (Game Developer), QA (Game QA)\n\n**Key Features:**\n- BMGD (BMAD Game Development) methodology + Scrum practices\n- Design→Architecture→Implementation→Testing flow\n- 60fps is non-negotiable - performance is a feature\n- Playable increments every Sprint\n- Design from player experience first\n\n**Workflow:**\n1. DS: Create Game Brief and GDD (mechanics, systems, content)\n2. AR: Select engine, plan architecture, define performance budgets\n3. DV: Implement Sprint stories with TDD\n4. QA: Automated tests, playtests, performance profiling\n\n**Best for:** Game development projects, interactive applications, real-time simulations\n\n#### 4. mckinsey-research-team (McKinsey-style research)\n\n**Roles:** EM (Engagement Manager), RL (Research Lead), PR (Primary Researcher), SR (Secondary Researcher), DA (Data Analyst), QR (Quality Reviewer)\n\n**Key Features:**\n- McKinsey 7-step problem-solving process\n- MECE structuring (Mutually Exclusive, Collectively Exhaustive)\n- Pyramid Principle for communication (lead with answer)\n- Triangulation (multiple sources for key findings)\n- EM owns process improvement with 4-checkpoint monitoring\n\n**Workflow:**\n1. Define Problem (EM ↔ Client)\n2. Structure Problem (RL - MECE issue tree)\n3. Prioritize Issues (EM + RL)\n4. Plan Analysis (EM)\n5. Conduct Analysis (PR, SR, DA in parallel)\n6. Synthesize Findings (RL)\n7. Communicate Recommendations (EM + RL → QR → Client)\n\n**Best for:** Market research, competitive analysis, industry analysis, due diligence, strategy research\n\n#### 5. pg-insights-team (P&G-style consumer insights)\n\n**Roles:** IM (Insights Manager), MR (Moments Researcher), IA (Insight Analyst), SL (Strategy Lead), QR (Quality Reviewer)\n\n**Key Features:**\n- P&G Three-Step Insights Formula\n- Human-centric research (everyday moments)\n- Logic + Emotion connection\n- Goosebumps test for insight validation\n- IM owns process improvement with 4-checkpoint monitoring\n\n**Workflow:**\n1. Find Everyday Moments That Matter (MR)\n2. Find How Brand Matters in Those Moments (IA)\n3. Find the Brand Idea That Makes Moments Matter More (SL)\n\n**Best for:** Consumer insights, brand strategy, product innovation, emotional brand positioning\n\n---\n\n## Core Concepts\n\n### What is a Tmux Team?\n\nA tmux team is multiple Claude Code instances running in different tmux panes, each with a specialized role:\n\n- **PM (Project Manager)** - Central coordinator, routes all communication\n- **Architect** (SA in sample) - Designs solutions, API contracts, guards progressive approach\n- **Implementers** (BE/FE in sample) - Code the solutions progressively\n- **Code Reviewer** (CR) - Quality gatekeeper, reviews implementations\n\n### Key Principles\n\n1. **PM is the Hub** - All communication flows through PM, never direct agent-to-agent\n2. **Sprint-based Workflow** - 10-step sprint process from idea to delivery\n3. **Git as Progress Tracker** - Commits show real progress, not chat logs\n4. **Progressive Implementation** - Build incrementally (small → medium → full)\n5. **Boss Appears After Step 10** - Team self-coordinates during sprint\n6. **Two-Enter Rule** - Tmux messages require two SEPARATE commands for reliable delivery\n\n## Team Creation Workflow\n\n### Step 0: Select Team Template\n\n**Ask the user which template to use** (see \"FIRST: Ask User Which Team Template\" above).\n\nIf user doesn't specify, recommend `scrum-team` for most projects.\n\n### Step 1: Understand User's Project\n\nBefore creating a team, understand:\n1. **Domain** - What type of project? (web app, data pipeline, trading system, etc.)\n2. **Team Roles** - What specialists are needed? (may differ from template)\n3. **Working Directory** - Absolute path to the project\n4. **Selected Template** - Which of the 3 templates to use\n\n### Step 2: Create Project Structure\n\nCreate the following structure in the user's project:\n\n```\n{project_root}/\n├── .claude/\n│   ├── commands/\n│   │   └── init-role.md              # Slash command to initialize agent roles\n│   ├── hooks/\n│   │   └── session_start_team_docs.py  # SessionStart hook (CRITICAL - injects role context)\n│   └── settings.json                 # Hook configuration\n└── docs/\n    └── tmux/\n        └── {team-name}/\n            ├── workflow.md # Agent workflow documentation\n            ├── WHITEBOARD.md         # Collaboration tool (PM maintains)\n            └── prompts/\n                ├── PM_PROMPT.md      # PM role prompt\n                ├── {ROLE2}_PROMPT.md # Other role prompts\n                └── ...\n```\n\n### Step 3: Customize from Selected Template\n\nUse the selected template from `sample_team/` and customize:\n\n1. **Copy selected template** to user's project:\n   - `scrum-team/` → for Scrum projects\n   - `game-dev-team/` → for game development\n   - `mckinsey-research-team/` → for market research\n   - `pg-insights-team/` → for consumer insights\n2. **Rename roles** to match user's domain (if needed):\n   - AR → Architect / Designer\n   - BE/FE/DV → Implementer / Developer / Engineer\n   - Keep SM and QA (universal roles)\n3. **Update prompts** with project-specific:\n   - Working directory paths\n   - Domain-specific responsibilities\n   - Communication protocols\n4. **Create setup script** based on template's `setup-team.sh`\n5. **Copy improvement docs** (if using scrum-team or pm-retro):\n   - `sm/` or `pm/` folder with IMPROVEMENT_BACKLOG.md, etc.\n\n### Step 4: Configure Hooks and Commands\n\n#### init-role.md (Slash Command)\n\nCreate `{project}/.claude/commands/init-role.md`:\n\n```markdown\n# Initialize Agent Role\n\nYou are initializing as a member of the [TEAM_NAME] Multi-Agent Team.\n\n## Step 1: Read System Documentation\n\nFirst, read the system overview to understand the multi-agent workflow:\n\n**File**: `docs/tmux/{team-name}/workflow.md`\n\n## Step 2: Read Your Role Prompt\n\nBased on the role argument `$ARGUMENTS`, read your specific role prompt:\n\n- **PM** (Project Manager): `docs/tmux/{team-name}/prompts/PM_PROMPT.md`\n- **SA** (Architect): `docs/tmux/{team-name}/prompts/SA_PROMPT.md`\n- **BE/FE** (Implementers): `docs/tmux/{team-name}/prompts/{ROLE}_PROMPT.md`\n- **CR** (Code Reviewer): `docs/tmux/{team-name}/prompts/CR_PROMPT.md`\n\n## Step 3: Understand Your Mission\n\nAfter reading both files:\n1. Confirm your role and responsibilities\n2. Verify your communication pane IDs are configured\n3. Check the WHITEBOARD for current sprint status\n4. Be ready to execute your role in the workflow\n```\n\n#### session_start_team_docs.py (SessionStart Hook - CRITICAL)\n\nThis hook automatically injects team overview and role prompts when agents start or auto-compact. **Without this hook, agents lose context after auto-compact.**\n\n**Step 1**: Copy the template from this skill to your project:\n\n```bash\ncp ~/.claude/skills/tmux-team-creator/hooks/session_start_team_docs.py \\\n   {project}/.claude/hooks/session_start_team_docs.py\nchmod +x {project}/.claude/hooks/session_start_team_docs.py\n```\n\n**Step 2**: Edit the `TEAM_CONFIGS` section in the copied file:\n\n```python\nTEAM_CONFIGS = {\n    \"your-session-name\": {\n        \"docs_dir\": os.path.join(PROJECT_ROOT, \"docs/tmux/your-team\"),\n        \"roles\": {\"PM\", \"SA\", \"BE\", \"FE\", \"CR\"},\n    },\n}\n```\n\nExample for scrum-team:\n```python\nTEAM_CONFIGS = {\n    \"scrum-team\": {\n        \"docs_dir\": os.path.join(PROJECT_ROOT, \"docs/tmux/scrum-team\"),\n        \"roles\": {\"PO\", \"SM\", \"TL\", \"FE\", \"BE\", \"QA\"},\n    },\n}\n```\n\n**Step 3**: Create `{project}/.claude/settings.json`:\n\n```json\n{\n  \"hooks\": {\n    \"SessionStart\": [\n      {\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"$CLAUDE_PROJECT_DIR/.claude/hooks/session_start_team_docs.py\",\n            \"timeout\": 10\n          }\n        ]\n      }\n    ]\n  }\n}\n```\n\n**What this hook does:**\n1. Detects current tmux session name\n2. Looks up team config (docs_dir, valid roles)\n3. Reads `@role_name` from tmux pane option\n4. Injects `workflow.md` + `{ROLE}_PROMPT.md` into agent context\n\n**Why it's critical:** Without this hook, agents forget their role and team workflow after auto-compact, leading to confusion and wrong behavior.\n\n### Step 5: Create Setup Script\n\nCreate `docs/tmux/{team-name}/setup-team.sh`:\n\n```bash\n#!/bin/bash\n# [TEAM_NAME] - Automated Setup Script\n\nset -e\n\nPROJECT_ROOT=\"/path/to/project\"\nSESSION_NAME=\"team-name\"\nPROMPTS_DIR=\"$PROJECT_ROOT/docs/tmux/{team-name}/prompts\"\n\necho \"Starting [TEAM_NAME] Setup...\"\n\n# Kill existing session if exists\nif tmux has-session -t $SESSION_NAME 2>/dev/null; then\n    tmux kill-session -t $SESSION_NAME\nfi\n\n# Create session\ncd \"$PROJECT_ROOT\"\ntmux new-session -d -s $SESSION_NAME\n\n# Create N-pane layout (adjust for number of agents)\ntmux split-window -h -t $SESSION_NAME\ntmux split-window -h -t $SESSION_NAME\ntmux split-window -h -t $SESSION_NAME\ntmux select-layout -t $SESSION_NAME even-horizontal\n\n# Set pane titles (visual display)\ntmux select-pane -t $SESSION_NAME:0.0 -T \"PM\"\ntmux select-pane -t $SESSION_NAME:0.1 -T \"[ROLE2]\"\ntmux select-pane -t $SESSION_NAME:0.2 -T \"[ROLE3]\"\ntmux select-pane -t $SESSION_NAME:0.3 -T \"Code-Reviewer\"\n\n# Set @role_name options (stable - won't be overwritten by Claude Code)\ntmux set-option -p -t $SESSION_NAME:0.0 @role_name \"PM\"\ntmux set-option -p -t $SESSION_NAME:0.1 @role_name \"[ROLE2]\"\ntmux set-option -p -t $SESSION_NAME:0.2 @role_name \"[ROLE3]\"\ntmux set-option -p -t $SESSION_NAME:0.3 @role_name \"Code-Reviewer\"\n\n# Start Claude Code in each pane\ntmux send-keys -t $SESSION_NAME:0.0 \"cd $PROJECT_ROOT && claude\" C-m\ntmux send-keys -t $SESSION_NAME:0.1 \"cd $PROJECT_ROOT && claude\" C-m\ntmux send-keys -t $SESSION_NAME:0.2 \"cd $PROJECT_ROOT && claude\" C-m\ntmux send-keys -t $SESSION_NAME:0.3 \"cd $PROJECT_ROOT && claude\" C-m\n\nsleep 15\n\n# Initialize roles\ntmux send-keys -t $SESSION_NAME:0.0 \"/init-role PM\" C-m\ntmux send-keys -t $SESSION_NAME:0.0 C-m\ntmux send-keys -t $SESSION_NAME:0.1 \"/init-role [ROLE2]\" C-m\ntmux send-keys -t $SESSION_NAME:0.1 C-m\ntmux send-keys -t $SESSION_NAME:0.2 \"/init-role [ROLE3]\" C-m\ntmux send-keys -t $SESSION_NAME:0.2 C-m\ntmux send-keys -t $SESSION_NAME:0.3 \"/init-role CODE_REVIEWER\" C-m\ntmux send-keys -t $SESSION_NAME:0.3 C-m\n\nsleep 10\n\n# Get pane IDs and update prompts\nPANE_IDS=$(tmux list-panes -t $SESSION_NAME -F \"#{pane_id}\")\nPM_PANE=$(echo \"$PANE_IDS\" | sed -n '1p')\n# ... update prompt files with pane IDs\n\necho \"Setup Complete! Attach: tmux attach -t $SESSION_NAME\"\n```\n\n## Team Composition\n\n### Core Pattern (Universal)\n\nAll teams share these patterns regardless of roles:\n- **PM is the Hub** - All communication flows through PM\n- **WHITEBOARD** - PM maintains for collaboration and session resumption\n- **Git as Progress Tracker** - Commits show real progress\n- **Two-Enter Rule** - Tmux messages require two SEPARATE commands\n- **10-Step Sprint Workflow** - From idea to delivery\n- **Code Review Phase** - Quality gate before completion\n\n### Required Roles (Every Team)\n\n1. **PM (Project Manager)** - Central coordinator\n   - Receives ideas from Boss\n   - Routes all agent communication\n   - Maintains WHITEBOARD and specs\n   - Monitors Git progress\n   - Verifies work independently\n\n2. **Code Reviewer** - Quality gatekeeper\n   - Reviews implementations\n   - Validates correctness\n   - Provides actionable feedback\n\n3. **BOSS (User/Human)** - Sprint supervisor (OUTSIDE tmux)\n   - NOT an automated agent - this is the human user\n   - Operates from a **separate terminal outside the tmux session** (Boss Terminal)\n   - Provides initial ideas/requirements to PM (before step 1)\n   - **DOES NOT intervene during steps 1-10** - team self-coordinates\n   - Appears ONLY after step 10 to:\n     - Review sprint summary from PM\n     - Approve or reject sprint\n     - Request external Validator if needed\n     - Provide next sprint ideas/priorities\n   - Uses `>>>` prefix to send messages to PM (see Boss Terminal section below)\n\n### Example Team Compositions\n\nTeams can have different specialist roles based on the project:\n\n**Example 1: AI Controller Team (sample_team)**\n```\nPM → SA (Solution Architect) → BE (Backend) → FE (Frontend) → CR → DK\n```\n- SA: Architecture design, API contracts, guards progressive approach\n- BE: Backend implementation (backend/)\n- FE: Frontend adaptation (frontend/)\n- DK: Documentation sync (docs/)\n\n**Example 2: Full-Stack Web App Team**\n```\nPM → SA → Frontend Dev → Backend Dev → CR\n```\n\n**Example 3: Data Pipeline Team**\n```\nPM → Data Architect → Data Engineer → CR\n```\n\n**Example 4: ML Project Team**\n```\nPM → ML Researcher → ML Engineer → Data Engineer → CR\n```\n\n**Example 5: Mobile App Team**\n```\nPM → UX Designer → iOS Dev → Android Dev → CR\n```\n\n### Designing Your Team\n\nWhen creating a team:\n\n1. **Always include PM and Code Reviewer** - Universal roles\n2. **Identify specialists** - What expertise does the project need?\n3. **Define communication flow** - All through PM\n4. **Create role prompts** - Specific responsibilities for each role\n5. **Keep team size reasonable** - 3-5 agents typically optimal\n\n## Communication Patterns\n\n### Stable Role Names with @role_name (CRITICAL)\n\n**Problem**: Tmux pane titles (`#{pane_title}`) change dynamically when Claude Code runs tasks. For example, \"PM\" becomes \"✳ API Mismatch Bug\" based on current task.\n\n**Solution**: Use tmux pane user options (`@role_name`) which are stable and won't be overwritten by running processes.\n\n```bash\n# Set stable role names during setup\ntmux set-option -p -t $SESSION_NAME:0.0 @role_name \"PM\"\ntmux set-option -p -t $SESSION_NAME:0.1 @role_name \"SA\"\ntmux set-option -p -t $SESSION_NAME:0.2 @role_name \"CR\"\n\n# Read role name (for APIs, scripts, etc.)\ntmux show-option -p -t $SESSION_NAME:0.0 -v @role_name  # Returns: PM\n```\n\n**Key Points**:\n- `@role_name` is a user-defined pane option (prefix with `@`)\n- Set with `tmux set-option -p -t target @role_name \"VALUE\"`\n- Read with `tmux show-option -p -t target -v @role_name`\n- Persists for the session lifetime, survives pane title changes\n- Fall back to `#{pane_title}` if `@role_name` not set\n\n### Two-Enter Rule (CRITICAL)\n\nAll tmux messages require two **SEPARATE** tmux commands:\n\n```bash\n# CORRECT: Two separate commands\ntmux send-keys -t [pane_id] \"PM [HH:mm]: [message]\" C-m\ntmux send-keys -t [pane_id] C-m   # Second Enter in SEPARATE command!\nsleep 5\ntmux capture-pane -t [pane_id] -p | tail -40\n\n# WRONG: C-m C-m in single command does NOT work!\ntmux send-keys -t [pane_id] \"message\" C-m C-m  # DON'T DO THIS\n```\n\n### Update-Then-Notify Order\n\nAlways write/update files FIRST, then notify:\n\n```bash\n# 1. Write file (spec, code, etc.)\n# 2. THEN notify agent (two separate commands!)\ntmux send-keys -t %FE \"PM [10:30]: Sprint assigned. See docs/specs/feature.md\" C-m\ntmux send-keys -t %FE C-m\n```\n\n### Message Format\n\n`[ROLE] [HH:mm]: [Brief message]. See [reference].`\n\nExamples:\n- `PM [23:11]: Sprint assigned to FE. See docs/specs/feature.md`\n- `FE [22:10]: Task complete. Tests: 42/42 passing. See Git commits.`\n\n## 10-Step Sprint Workflow\n\n1. **Ideas → PM**: Boss provides ideas to PM\n2. **PM → Expert**: Strategy/design discussion\n3. **Expert → PM**: Finalize specification\n4. **PM → Implementer**: Sprint assignment with spec\n5. **Implementer**: Progressive implementation\n6. **Implementer ↔ PM ↔ Expert**: Clarification loop\n7. **Continue clarifications as needed**\n8. **Implementer → PM**: Sprint completion report\n9. **PM → Code Reviewer**: Review request\n10. **Review Loop**: Reviewer ↔ PM ↔ Implementer until approved\n\n**Boss appears ONLY after step 10** - team self-coordinates during sprint.\n\n## After Step 10: Boss Entry\n\nWhen sprint completes (Code Reviewer approves), PM prepares Sprint Summary for Boss.\n\n### Boss Reviews\n\nBoss (human user) evaluates:\n- **Sprint Summary** from PM (deliverables, metrics, decisions made)\n- **Git commit history** (primary progress measure - shows progressive development)\n- **Code Reviewer approval report** (quality gate passed)\n- **WHITEBOARD** (current status, any blockers encountered)\n\n### Boss Decisions\n\nAfter review, Boss can:\n\n1. **Approve Sprint** - Work is complete, merge to main branch\n2. **Request Changes** - Send back to team with specific feedback\n3. **Request External Validator** - For critical work, get independent verification\n4. **Prioritize Next Sprint** - Provide ideas/requirements for next iteration\n\n### Boss Terminal (CRITICAL)\n\nThe Boss operates from a **separate terminal outside the tmux session** (typically where a Claude Code instance runs to assist the Boss).\n\n**Communication Protocol**:\n- When Boss types `>>> [message]`, the message is sent to PM pane with prefix:\n  ```\n  BOSS [HH:MM]: [original_message]\n  ```\n- Example: Boss types `>>> start sprint 1` → PM receives `BOSS [14:30]: start sprint 1`\n\n**Implementation**: Configure in the project's CLAUDE.md:\n```markdown\n**>>> PREFIX - CRITICAL COMMUNICATION RULE**:\nWhen user types `>>> [message]`, ALWAYS send ONLY to PM (pane %0), NOT to any other agent!\n- `>>>` means: Send to PM pane (%0) with prefix \"BOSS [HH:mm]: [exact message]\"\n- DO NOT send to Code-Reviewer, Coder, or anyone else\n- PM will relay to appropriate agent if needed\n```\n\n**Boss Terminal Commands**:\n```bash\n# Send message to PM (pane %0)\ntmux send-keys -t {session}:0.0 \"BOSS [HH:MM]: your message here\" C-m\ntmux send-keys -t {session}:0.0 C-m  # Two-Enter rule\n\n# View PM pane output\ntmux capture-pane -t {session}:0.0 -p | tail -50\n\n# Attach to session (to observe all agents)\ntmux attach -t {session}\n```\n\n**Boss Responsibilities from Boss Terminal**:\n- Provide initial sprint goals to PM via `>>>`\n- Run LLM tests manually when notified (if applicable)\n- Approve/reject sprint completions\n- Can intervene anytime via `>>>` prefix\n\n### Boss Non-Intervention Rule\n\n**CRITICAL**: Boss should NOT intervene during steps 1-10 unless:\n- Team is completely stuck (no progress for hours)\n- Critical business requirement change\n- Emergency situation\n\nLet the team self-coordinate. Trust PM to manage the sprint.\n\n## Sample Team Reference\n\nThe `sample_team/` directory contains 6 complete working templates (4 software development + 2 research):\n\n```\nsample_team/\n├── scrum-team/                      # RECOMMENDED: Full Scrum framework\n│   ├── workflow.md        # Scrum workflow documentation\n│   ├── WHITEBOARD.md                # Sprint status\n│   ├── SPRINT_BACKLOG.md            # Current sprint items\n│   ├── PRODUCT_BACKLOG.md           # PO's backlog\n│   ├── setup-team.sh                # Automated setup (verifies global tm-send)\n│   ├── sm/                          # Scrum Master's workspace\n│   │   ├── IMPROVEMENT_BACKLOG.md   # Process issues (with evidence log)\n│   │   ├── RETROSPECTIVE_LOG.md     # Historical lessons\n│   │   └── ACTION_ITEMS.md          # Improvement tracking\n│   └── prompts/\n│       ├── PO_PROMPT.md             # Product Owner\n│       ├── SM_PROMPT.md             # Scrum Master (4-checkpoint monitoring)\n│       ├── TL_PROMPT.md             # Tech Lead\n│       ├── BE_PROMPT.md             # Backend Developer\n│       ├── FE_PROMPT.md             # Frontend Developer\n│       └── QA_PROMPT.md             # Tester (black-box)\n│\n├── scrum-minimal-team/              # Lightweight 3-person Scrum\n│   ├── workflow.md                  # Minimal Scrum workflow\n│   ├── WHITEBOARD.md                # Sprint status\n│   ├── SPRINT_BACKLOG.md            # Current sprint items\n│   ├── PRODUCT_BACKLOG.md           # PO's backlog\n│   ├── setup-team.sh                # 3-pane setup\n│   ├── sm/                          # Scrum Master's workspace\n│   │   ├── IMPROVEMENT_BACKLOG.md   # Process issues\n│   │   └── RETROSPECTIVE_LOG.md     # Historical lessons\n│   └── prompts/\n│       ├── PO_PROMPT.md             # Product Owner\n│       ├── SM_PROMPT.md             # Scrum Master\n│       └── EX_PROMPT.md             # Executive (TL+DEV+QA)\n│\n├── game-dev-team/                   # Game development team\n│   ├── workflow.md        # BMGD + Scrum workflow\n│   ├── WHITEBOARD.md                # Sprint status\n│   ├── setup-team.sh                # Automated setup (sets @role_name on panes)\n│   ├── sm/                          # SM's workspace\n│   │   ├── IMPROVEMENT_BACKLOG.md   # Process issues\n│   │   └── RETROSPECTIVE_LOG.md     # Historical lessons\n│   └── prompts/\n│       ├── DS_PROMPT.md             # Game Designer\n│       ├── SM_PROMPT.md             # Scrum Master\n│       ├── AR_PROMPT.md             # Game Architect\n│       ├── DV_PROMPT.md             # Game Developer\n│       └── QA_PROMPT.md             # Game QA\n│\n├── mckinsey-research-team/          # McKinsey-style research\n│   ├── workflow.md        # 7-step McKinsey workflow\n│   ├── WHITEBOARD.md                # Engagement status\n│   ├── setup-team.sh                # Automated setup (verifies global tm-send)\n│   ├── em/                          # Engagement Manager's workspace\n│   │   ├── IMPROVEMENT_BACKLOG.md   # Process issues (with evidence log)\n│   │   ├── RETROSPECTIVE_LOG.md     # Historical lessons\n│   │   └── ACTION_ITEMS.md          # Improvement tracking\n│   └── prompts/\n│       ├── EM_PROMPT.md             # Engagement Manager (coordinator)\n│       ├── RL_PROMPT.md             # Research Lead (MECE, synthesis)\n│       ├── PR_PROMPT.md             # Primary Researcher (interviews)\n│       ├── SR_PROMPT.md             # Secondary Researcher (desk research)\n│       ├── DA_PROMPT.md             # Data Analyst (market sizing)\n│       └── QR_PROMPT.md             # Quality Reviewer (MECE, Pyramid)\n│\n├── pg-insights-team/                # P&G-style consumer insights\n│   ├── workflow.md        # Three-Step Formula workflow\n│   ├── WHITEBOARD.md                # Project status\n│   ├── setup-team.sh                # Automated setup (verifies global tm-send)\n│   ├── im/                          # Insights Manager's workspace\n│   │   ├── IMPROVEMENT_BACKLOG.md   # Process issues (with evidence log)\n│   │   ├── RETROSPECTIVE_LOG.md     # Historical lessons\n│   │   └── ACTION_ITEMS.md          # Improvement tracking\n│   └── prompts/\n│       ├── IM_PROMPT.md             # Insights Manager (coordinator)\n│       ├── MR_PROMPT.md             # Moments Researcher (Step 1)\n│       ├── IA_PROMPT.md             # Insight Analyst (Step 2)\n│       ├── SL_PROMPT.md             # Strategy Lead (Step 3)\n│       └── QR_PROMPT.md             # Quality Reviewer (goosebumps test)\n│\n├── commands/\n│   └── init-role.md                 # Slash command for role init\n├── hooks/\n│   └── session_start_team_docs.py   # SessionStart hook template (CRITICAL)\n└── settings.json                    # Hook configuration template\n\n# NOTE: tm-send is a GLOBAL tool at ~/.local/bin/tm-send\n# It is NOT included in project directories\n# Role mapping uses @role_name pane options (dynamic, no static file)\n```\n\n### Key Differences Between Templates\n\n#### Software Development Teams\n\n| Feature | scrum-team | scrum-minimal-team | game-dev-team |\n|---------|------------|-------------------|---------------|\n| Roles | 6 (PO, SM, TL, BE, FE, QA) | 3 (PO, SM, EX) | 5 (DS, SM, AR, DV, QA) |\n| Improvement Owner | SM | SM | SM |\n| Workflow | Sprint-based | Sprint-based | Design→Arch→Impl→Test |\n| Monitoring | 4 checkpoints + evidence log | Lightweight | Sprint-based improvement |\n| QA Approach | Black-box (QA role) | Integrated (EX role) | Automated tests + playtests |\n| Backlog | Product + Sprint | Product + Sprint | WHITEBOARD |\n| Best For | Large projects | Small/solo projects | Game development |\n\n#### Research Teams\n\n| Feature | mckinsey-research-team | pg-insights-team |\n|---------|----------------------|------------------|\n| Improvement Owner | EM (Engagement Manager) | IM (Insights Manager) |\n| Workflow | McKinsey 7-step | P&G Three-Step |\n| Monitoring | 4 checkpoints + evidence log | 4 checkpoints + evidence log |\n| QA Approach | MECE + Pyramid Principle (QR) | Goosebumps test + validation (QR) |\n| Backlog | WHITEBOARD | WHITEBOARD |\n| Retrospective | Engagement end | Project end |\n| Unique Features | Hypothesis-driven, triangulation, issue trees | Human-centric, logic+emotion, everyday moments |\n\n### tm-send Script (GLOBAL TOOL)\n\nThe `tm-send` script is CRITICAL for reliable agent communication.\n\n**IMPORTANT: tm-send is a GLOBAL tool, NOT project-specific!**\n- Installed once at `~/.local/bin/tm-send`\n- Works for ALL projects on the machine\n- Uses tmux `@role_name` pane options (dynamic lookup, no static files)\n- **DO NOT copy tm-send into project directories**\n\n**Features:**\n- **Dynamic Role Lookup** - Queries `@role_name` pane options directly via tmux\n- **Session Isolation** - Prevents cross-team message contamination\n- **Auto-detect Session** - From TMUX env, project directory, or `-s` flag\n- **Two-Enter Rule** - Enforced automatically\n\n**Usage:**\n```bash\ntm-send PM \"FE -> PM: Task complete.\"           # Auto-detect session\ntm-send -s other_project PM \"Cross-project msg\"  # Explicit session\ntm-send --list                                   # List roles in session\n```\n\n**Session Isolation Details**:\n- Pane IDs (like `%109`) can exist in multiple sessions\n- `tm-send` verifies pane belongs to correct session before sending\n- Never sends to wrong project\n\n**Never use raw `tmux send-keys`** - always use `tm-send` for agent communication.\n\n**Pre-requisite**: tm-send must be installed globally at `~/.local/bin/tm-send` before running any team setup script.\n\nRead the sample_team files to understand the complete structure before customizing for user's domain.\n\n## Best Practices\n\n1. **Keep PM as hub** - Never allow direct agent-to-agent communication\n2. **Use WHITEBOARD** - Critical for session resumption after restarts\n3. **Git is truth** - Monitor commits, not chat messages\n4. **Progressive implementation** - Small incremental steps\n5. **Verify independently** - PM should run tests, not just trust reports\n6. **Two-Enter rule** - Always use two SEPARATE tmux commands for messages\n7. **Update-Then-Notify** - Write files before sending notifications\n8. **Use @role_name** - Set stable role names via `tmux set-option -p @role_name` (pane titles change dynamically)\n9. **Session Isolation** - Always use `tm-send` which enforces `session:pane` format to prevent cross-team message contamination when running multiple teams\n\n## Available Skills for Agents\n\nAgents can invoke standard skills for specialized tasks. **Include these in role prompts where applicable.**\n\n### Frontend Roles (FE)\n\n```bash\n/frontend-design [description]\n```\n\n**Use for:** Interface layout, web components, dashboards, styling, accessibility, high-quality visual design.\n\n**Add to FE prompts:**\n```markdown\n## UI/UX Design Support\n\n**When working on UI/UX design decisions**, invoke the `/frontend-design` skill:\n\n\\`\\`\\`bash\n/frontend-design [description of what you need]\n\\`\\`\\`\n\n**Use for:**\n- Interface layout decisions\n- Web components, pages, dashboards\n- Styling and beautifying UI\n- Accessibility concerns\n- High-quality visual design\n```\n\n### Research Roles (PR, SR)\n\n```bash\n/quick-research [topic]\n```\n\n**Use for:** Complex research requiring multiple sources, comparative analyses, deep exploration.\n\n### Documentation Roles (DK)\n\n```bash\n/doc-coauthoring\n```\n\n**Use for:** Structured workflow for co-authoring documentation, proposals, technical specs.\n\n### All Roles\n\n```bash\n/think-hard [problem]\n```\n\n**Use for:** Complex problems requiring deep reasoning.\n\n## Customization Guide\n\nTo create a team for a new domain:\n\n1. **Select template** based on user's needs (see \"FIRST: Ask User Which Team Template\")\n2. **Read selected template** to understand the structure\n3. **Identify roles** needed for the domain (keep PM/SM and CR/QA)\n4. **Copy and rename** files from selected template\n5. **Update paths** in all files to match user's project\n6. **Customize prompts** with domain-specific responsibilities\n7. **Create setup script** with correct role names\n8. **Test communication** with two-Enter pattern\n9. **Verify improvement docs** (if using scrum-team or pm-retro)\n\n### Template Selection Quick Reference\n\n#### Software Development\n\n| User Says | Use Template |\n|-----------|--------------|\n| \"Scrum team\" / \"standard Scrum\" / \"Scrum Master\" | `scrum-team` |\n| \"minimal\" / \"small team\" / \"solo dev\" / \"MVP\" / \"lightweight\" | `scrum-minimal-team` |\n| \"game\" / \"game development\" / \"game project\" | `game-dev-team` |\n| Nothing specified (software dev) | Ask, recommend `scrum-team` (or `scrum-minimal-team` for small projects) |\n\n#### Research & Analysis\n\n| User Says | Use Template |\n|-----------|--------------|\n| \"market research\" / \"competitive analysis\" / \"McKinsey\" | `mckinsey-research-team` |\n| \"industry analysis\" / \"due diligence\" / \"research team\" | `mckinsey-research-team` |\n| \"consumer insights\" / \"P&G\" / \"brand strategy\" | `pg-insights-team` |\n| \"emotional research\" / \"product innovation\" | `pg-insights-team` |\n\n#### Cross-Domain\n\nWhen user's project spans multiple domains, consider:\n- Combining elements from multiple templates\n- Creating custom roles that blend responsibilities\n- Using the closest template as a starting point and customizing heavily"
              }
            ]
          },
          {
            "name": "content-creation",
            "description": "Content creation tools for prompting, documentation, and LLM applications",
            "source": "./plugins/content-creation",
            "category": "content",
            "version": "1.0.0",
            "author": null,
            "install_commands": [
              "/plugin marketplace add hongbietcode/synthetic-claude",
              "/plugin install content-creation@synthetic-claude"
            ],
            "signals": {
              "stars": 1,
              "forks": 0,
              "pushed_at": "2026-01-07T17:25:07Z",
              "created_at": "2025-12-28T07:34:15Z",
              "license": null
            },
            "commands": [
              {
                "name": "/create-project-memory-skills",
                "description": null,
                "path": "plugins/content-creation/commands/create-project-memory-skills.md",
                "frontmatter": null,
                "content": "# Create Project Memory Skills\n\nCopy project-memory-store and project-memory-recall skills from templates to current project's `.claude/skills/` directory.\n\n## Task\n\n1. Check if `.claude/skills/` exists in current working directory, create if needed\n2. Copy `~/.claude/skills/templates/project-memory-store/` to `.claude/skills/project-memory-store/`\n3. Copy `~/.claude/skills/templates/project-memory-recall/` to `.claude/skills/project-memory-recall/`\n4. Report completion with paths\n\n## Notes\n\n- These are project-specific memory skills - each project gets its own copy\n- The templates are stored in `~/.claude/skills/templates/`\n- coder-memory-store/recall are global (in `~/.claude/skills/`) and shared across all projects\n- project-memory-store/recall are local (in `.claude/skills/`) and specific to each project\n"
              },
              {
                "name": "/current-prompt-create",
                "description": null,
                "path": "plugins/content-creation/commands/current-prompt-create.md",
                "frontmatter": null,
                "content": "Create file ./current_prompt.md with the following content:\n\n```\n**IMPORTANT** Never edit this file\n# To execute:\n\n---\n# Skip, following are just notes:\n\n\n```"
              },
              {
                "name": "/ecp",
                "description": null,
                "path": "plugins/content-creation/commands/ecp.md",
                "frontmatter": null,
                "content": "- Execute prompt in file $ARGUMENTS \n- Read the prompt from the file $ARGUMENTS (if not given then execute prompt in file current_prompt.md) - if both do not exist then just ask user what to do\n- Re-read the file, it may changed since last time you read it\n- Guide for recall memory:\nRead the part \"# To execute\" first and consider whether the task is not trivial enough (i.e it can just be done in 1-2 simple steps) - if it's not simple, the --recall your memory to find any information that helps you complete the task."
              },
              {
                "name": "/notebook-edit",
                "description": null,
                "path": "plugins/content-creation/commands/notebook-edit.md",
                "frontmatter": null,
                "content": "\nJust give code suggestion, don't edit the notebook file, I will copy-paste it in manually: $ARGUMENTS\n\n\n"
              },
              {
                "name": "/py2notebook",
                "description": null,
                "path": "plugins/content-creation/commands/py2notebook.md",
                "frontmatter": null,
                "content": "# Python to Notebook Command\n\nCreate Jupyter notebook from feature specification: $ARGUMENTS\n\n## Process\n1. Read the feature description from the markdown file\n2. Implement the feature in a `.py` file with clean, modular code\n3. Write comprehensive tests to verify functionality\n4. Once tests pass, convert the Python code to `.ipynb` format with markdown cells explaining each section\n5. Archive original files to `./backup/py2notebook/` with timestamp\n\n## Output\n- Feature notebook with explanatory markdown cells\n- Archived Python and test files\n- Summary of what was implemented"
              }
            ],
            "skills": [
              {
                "name": "doc-coauthoring",
                "description": "Guide users through a structured workflow for co-authoring documentation. Use when user wants to write documentation, proposals, technical specs, decision docs, or similar structured content. This workflow helps users efficiently transfer context, refine content through iteration, and verify the doc works for readers. Trigger when user mentions writing docs, creating proposals, drafting specs, or similar documentation tasks.",
                "path": "plugins/content-creation/skills/doc-coauthoring/SKILL.md",
                "frontmatter": {
                  "name": "doc-coauthoring",
                  "description": "Guide users through a structured workflow for co-authoring documentation. Use when user wants to write documentation, proposals, technical specs, decision docs, or similar structured content. This workflow helps users efficiently transfer context, refine content through iteration, and verify the doc works for readers. Trigger when user mentions writing docs, creating proposals, drafting specs, or similar documentation tasks."
                },
                "content": "# Doc Co-Authoring Workflow\n\nThis skill provides a structured workflow for guiding users through collaborative document creation. Act as an active guide, walking users through three stages: Context Gathering, Refinement & Structure, and Reader Testing.\n\n## When to Offer This Workflow\n\n**Trigger conditions:**\n- User mentions writing documentation: \"write a doc\", \"draft a proposal\", \"create a spec\", \"write up\"\n- User mentions specific doc types: \"PRD\", \"design doc\", \"decision doc\", \"RFC\"\n- User seems to be starting a substantial writing task\n\n**Initial offer:**\nOffer the user a structured workflow for co-authoring the document. Explain the three stages:\n\n1. **Context Gathering**: User provides all relevant context while Claude asks clarifying questions\n2. **Refinement & Structure**: Iteratively build each section through brainstorming and editing\n3. **Reader Testing**: Test the doc with a fresh Claude (no context) to catch blind spots before others read it\n\nExplain that this approach helps ensure the doc works well when others read it (including when they paste it into Claude). Ask if they want to try this workflow or prefer to work freeform.\n\nIf user declines, work freeform. If user accepts, proceed to Stage 1.\n\n## Stage 1: Context Gathering\n\n**Goal:** Close the gap between what the user knows and what Claude knows, enabling smart guidance later.\n\n### Initial Questions\n\nStart by asking the user for meta-context about the document:\n\n1. What type of document is this? (e.g., technical spec, decision doc, proposal)\n2. Who's the primary audience?\n3. What's the desired impact when someone reads this?\n4. Is there a template or specific format to follow?\n5. Any other constraints or context to know?\n\nInform them they can answer in shorthand or dump information however works best for them.\n\n**If user provides a template or mentions a doc type:**\n- Ask if they have a template document to share\n- If they provide a link to a shared document, use the appropriate integration to fetch it\n- If they provide a file, read it\n\n**If user mentions editing an existing shared document:**\n- Use the appropriate integration to read the current state\n- Check for images without alt-text\n- If images exist without alt-text, explain that when others use Claude to understand the doc, Claude won't be able to see them. Ask if they want alt-text generated. If so, request they paste each image into chat for descriptive alt-text generation.\n\n### Info Dumping\n\nOnce initial questions are answered, encourage the user to dump all the context they have. Request information such as:\n- Background on the project/problem\n- Related team discussions or shared documents\n- Why alternative solutions aren't being used\n- Organizational context (team dynamics, past incidents, politics)\n- Timeline pressures or constraints\n- Technical architecture or dependencies\n- Stakeholder concerns\n\nAdvise them not to worry about organizing it - just get it all out. Offer multiple ways to provide context:\n- Info dump stream-of-consciousness\n- Point to team channels or threads to read\n- Link to shared documents\n\n**If integrations are available** (e.g., Slack, Teams, Google Drive, SharePoint, or other MCP servers), mention that these can be used to pull in context directly.\n\n**If no integrations are detected and in Claude.ai or Claude app:** Suggest they can enable connectors in their Claude settings to allow pulling context from messaging apps and document storage directly.\n\nInform them clarifying questions will be asked once they've done their initial dump.\n\n**During context gathering:**\n\n- If user mentions team channels or shared documents:\n  - If integrations available: Inform them the content will be read now, then use the appropriate integration\n  - If integrations not available: Explain lack of access. Suggest they enable connectors in Claude settings, or paste the relevant content directly.\n\n- If user mentions entities/projects that are unknown:\n  - Ask if connected tools should be searched to learn more\n  - Wait for user confirmation before searching\n\n- As user provides context, track what's being learned and what's still unclear\n\n**Asking clarifying questions:**\n\nWhen user signals they've done their initial dump (or after substantial context provided), ask clarifying questions to ensure understanding:\n\nGenerate 5-10 numbered questions based on gaps in the context.\n\nInform them they can use shorthand to answer (e.g., \"1: yes, 2: see #channel, 3: no because backwards compat\"), link to more docs, point to channels to read, or just keep info-dumping. Whatever's most efficient for them.\n\n**Exit condition:**\nSufficient context has been gathered when questions show understanding - when edge cases and trade-offs can be asked about without needing basics explained.\n\n**Transition:**\nAsk if there's any more context they want to provide at this stage, or if it's time to move on to drafting the document.\n\nIf user wants to add more, let them. When ready, proceed to Stage 2.\n\n## Stage 2: Refinement & Structure\n\n**Goal:** Build the document section by section through brainstorming, curation, and iterative refinement.\n\n**Instructions to user:**\nExplain that the document will be built section by section. For each section:\n1. Clarifying questions will be asked about what to include\n2. 5-20 options will be brainstormed\n3. User will indicate what to keep/remove/combine\n4. The section will be drafted\n5. It will be refined through surgical edits\n\nStart with whichever section has the most unknowns (usually the core decision/proposal), then work through the rest.\n\n**Section ordering:**\n\nIf the document structure is clear:\nAsk which section they'd like to start with.\n\nSuggest starting with whichever section has the most unknowns. For decision docs, that's usually the core proposal. For specs, it's typically the technical approach. Summary sections are best left for last.\n\nIf user doesn't know what sections they need:\nBased on the type of document and template, suggest 3-5 sections appropriate for the doc type.\n\nAsk if this structure works, or if they want to adjust it.\n\n**Once structure is agreed:**\n\nCreate the initial document structure with placeholder text for all sections.\n\n**If access to artifacts is available:**\nUse `create_file` to create an artifact. This gives both Claude and the user a scaffold to work from.\n\nInform them that the initial structure with placeholders for all sections will be created.\n\nCreate artifact with all section headers and brief placeholder text like \"[To be written]\" or \"[Content here]\".\n\nProvide the scaffold link and indicate it's time to fill in each section.\n\n**If no access to artifacts:**\nCreate a markdown file in the working directory. Name it appropriately (e.g., `decision-doc.md`, `technical-spec.md`).\n\nInform them that the initial structure with placeholders for all sections will be created.\n\nCreate file with all section headers and placeholder text.\n\nConfirm the filename has been created and indicate it's time to fill in each section.\n\n**For each section:**\n\n### Step 1: Clarifying Questions\n\nAnnounce work will begin on the [SECTION NAME] section. Ask 5-10 clarifying questions about what should be included:\n\nGenerate 5-10 specific questions based on context and section purpose.\n\nInform them they can answer in shorthand or just indicate what's important to cover.\n\n### Step 2: Brainstorming\n\nFor the [SECTION NAME] section, brainstorm [5-20] things that might be included, depending on the section's complexity. Look for:\n- Context shared that might have been forgotten\n- Angles or considerations not yet mentioned\n\nGenerate 5-20 numbered options based on section complexity. At the end, offer to brainstorm more if they want additional options.\n\n### Step 3: Curation\n\nAsk which points should be kept, removed, or combined. Request brief justifications to help learn priorities for the next sections.\n\nProvide examples:\n- \"Keep 1,4,7,9\"\n- \"Remove 3 (duplicates 1)\"\n- \"Remove 6 (audience already knows this)\"\n- \"Combine 11 and 12\"\n\n**If user gives freeform feedback** (e.g., \"looks good\" or \"I like most of it but...\") instead of numbered selections, extract their preferences and proceed. Parse what they want kept/removed/changed and apply it.\n\n### Step 4: Gap Check\n\nBased on what they've selected, ask if there's anything important missing for the [SECTION NAME] section.\n\n### Step 5: Drafting\n\nUse `str_replace` to replace the placeholder text for this section with the actual drafted content.\n\nAnnounce the [SECTION NAME] section will be drafted now based on what they've selected.\n\n**If using artifacts:**\nAfter drafting, provide a link to the artifact.\n\nAsk them to read through it and indicate what to change. Note that being specific helps learning for the next sections.\n\n**If using a file (no artifacts):**\nAfter drafting, confirm completion.\n\nInform them the [SECTION NAME] section has been drafted in [filename]. Ask them to read through it and indicate what to change. Note that being specific helps learning for the next sections.\n\n**Key instruction for user (include when drafting the first section):**\nProvide a note: Instead of editing the doc directly, ask them to indicate what to change. This helps learning of their style for future sections. For example: \"Remove the X bullet - already covered by Y\" or \"Make the third paragraph more concise\".\n\n### Step 6: Iterative Refinement\n\nAs user provides feedback:\n- Use `str_replace` to make edits (never reprint the whole doc)\n- **If using artifacts:** Provide link to artifact after each edit\n- **If using files:** Just confirm edits are complete\n- If user edits doc directly and asks to read it: mentally note the changes they made and keep them in mind for future sections (this shows their preferences)\n\n**Continue iterating** until user is satisfied with the section.\n\n### Quality Checking\n\nAfter 3 consecutive iterations with no substantial changes, ask if anything can be removed without losing important information.\n\nWhen section is done, confirm [SECTION NAME] is complete. Ask if ready to move to the next section.\n\n**Repeat for all sections.**\n\n### Near Completion\n\nAs approaching completion (80%+ of sections done), announce intention to re-read the entire document and check for:\n- Flow and consistency across sections\n- Redundancy or contradictions\n- Anything that feels like \"slop\" or generic filler\n- Whether every sentence carries weight\n\nRead entire document and provide feedback.\n\n**When all sections are drafted and refined:**\nAnnounce all sections are drafted. Indicate intention to review the complete document one more time.\n\nReview for overall coherence, flow, completeness.\n\nProvide any final suggestions.\n\nAsk if ready to move to Reader Testing, or if they want to refine anything else.\n\n## Stage 3: Reader Testing\n\n**Goal:** Test the document with a fresh Claude (no context bleed) to verify it works for readers.\n\n**Instructions to user:**\nExplain that testing will now occur to see if the document actually works for readers. This catches blind spots - things that make sense to the authors but might confuse others.\n\n### Testing Approach\n\n**If access to sub-agents is available (e.g., in Claude Code):**\n\nPerform the testing directly without user involvement.\n\n### Step 1: Predict Reader Questions\n\nAnnounce intention to predict what questions readers might ask when trying to discover this document.\n\nGenerate 5-10 questions that readers would realistically ask.\n\n### Step 2: Test with Sub-Agent\n\nAnnounce that these questions will be tested with a fresh Claude instance (no context from this conversation).\n\nFor each question, invoke a sub-agent with just the document content and the question.\n\nSummarize what Reader Claude got right/wrong for each question.\n\n### Step 3: Run Additional Checks\n\nAnnounce additional checks will be performed.\n\nInvoke sub-agent to check for ambiguity, false assumptions, contradictions.\n\nSummarize any issues found.\n\n### Step 4: Report and Fix\n\nIf issues found:\nReport that Reader Claude struggled with specific issues.\n\nList the specific issues.\n\nIndicate intention to fix these gaps.\n\nLoop back to refinement for problematic sections.\n\n---\n\n**If no access to sub-agents (e.g., claude.ai web interface):**\n\nThe user will need to do the testing manually.\n\n### Step 1: Predict Reader Questions\n\nAsk what questions people might ask when trying to discover this document. What would they type into Claude.ai?\n\nGenerate 5-10 questions that readers would realistically ask.\n\n### Step 2: Setup Testing\n\nProvide testing instructions:\n1. Open a fresh Claude conversation: https://claude.ai\n2. Paste or share the document content (if using a shared doc platform with connectors enabled, provide the link)\n3. Ask Reader Claude the generated questions\n\nFor each question, instruct Reader Claude to provide:\n- The answer\n- Whether anything was ambiguous or unclear\n- What knowledge/context the doc assumes is already known\n\nCheck if Reader Claude gives correct answers or misinterprets anything.\n\n### Step 3: Additional Checks\n\nAlso ask Reader Claude:\n- \"What in this doc might be ambiguous or unclear to readers?\"\n- \"What knowledge or context does this doc assume readers already have?\"\n- \"Are there any internal contradictions or inconsistencies?\"\n\n### Step 4: Iterate Based on Results\n\nAsk what Reader Claude got wrong or struggled with. Indicate intention to fix those gaps.\n\nLoop back to refinement for any problematic sections.\n\n---\n\n### Exit Condition (Both Approaches)\n\nWhen Reader Claude consistently answers questions correctly and doesn't surface new gaps or ambiguities, the doc is ready.\n\n## Final Review\n\nWhen Reader Testing passes:\nAnnounce the doc has passed Reader Claude testing. Before completion:\n\n1. Recommend they do a final read-through themselves - they own this document and are responsible for its quality\n2. Suggest double-checking any facts, links, or technical details\n3. Ask them to verify it achieves the impact they wanted\n\nAsk if they want one more review, or if the work is done.\n\n**If user wants final review, provide it. Otherwise:**\nAnnounce document completion. Provide a few final tips:\n- Consider linking this conversation in an appendix so readers can see how the doc was developed\n- Use appendices to provide depth without bloating the main doc\n- Update the doc as feedback is received from real readers\n\n## Tips for Effective Guidance\n\n**Tone:**\n- Be direct and procedural\n- Explain rationale briefly when it affects user behavior\n- Don't try to \"sell\" the approach - just execute it\n\n**Handling Deviations:**\n- If user wants to skip a stage: Ask if they want to skip this and write freeform\n- If user seems frustrated: Acknowledge this is taking longer than expected. Suggest ways to move faster\n- Always give user agency to adjust the process\n\n**Context Management:**\n- Throughout, if context is missing on something mentioned, proactively ask\n- Don't let gaps accumulate - address them as they come up\n\n**Artifact Management:**\n- Use `create_file` for drafting full sections\n- Use `str_replace` for all edits\n- Provide artifact link after every change\n- Never use artifacts for brainstorming lists - that's just conversation\n\n**Quality over Speed:**\n- Don't rush through stages\n- Each iteration should make meaningful improvements\n- The goal is a document that actually works for readers"
              },
              {
                "name": "internal-comms",
                "description": "A set of resources to help me write all kinds of internal communications, using the formats that my company likes to use. Claude should use this skill whenever asked to write some sort of internal communications (status reports, leadership updates, 3P updates, company newsletters, FAQs, incident reports, project updates, etc.).",
                "path": "plugins/content-creation/skills/internal-comms/SKILL.md",
                "frontmatter": {
                  "name": "internal-comms",
                  "description": "A set of resources to help me write all kinds of internal communications, using the formats that my company likes to use. Claude should use this skill whenever asked to write some sort of internal communications (status reports, leadership updates, 3P updates, company newsletters, FAQs, incident reports, project updates, etc.).",
                  "license": "Complete terms in LICENSE.txt"
                },
                "content": "## When to use this skill\nTo write internal communications, use this skill for:\n- 3P updates (Progress, Plans, Problems)\n- Company newsletters\n- FAQ responses\n- Status reports\n- Leadership updates\n- Project updates\n- Incident reports\n\n## How to use this skill\n\nTo write any internal communication:\n\n1. **Identify the communication type** from the request\n2. **Load the appropriate guideline file** from the `examples/` directory:\n    - `examples/3p-updates.md` - For Progress/Plans/Problems team updates\n    - `examples/company-newsletter.md` - For company-wide newsletters\n    - `examples/faq-answers.md` - For answering frequently asked questions\n    - `examples/general-comms.md` - For anything else that doesn't explicitly match one of the above\n3. **Follow the specific instructions** in that file for formatting, tone, and content gathering\n\nIf the communication type doesn't match any existing guideline, ask for clarification or more context about the desired format.\n\n## Keywords\n3P updates, company newsletter, company comms, weekly update, faqs, common questions, updates, internal comms"
              },
              {
                "name": "llm-apps-creator",
                "description": "This skill should be used when users want to build LLM-powered applications using LangChain. It provides patterns for initializing any LLM provider (OpenAI, Anthropic, Google, xAI), building agent loops with tools, and implementing structured output. Use this skill when users ask to create chatbots, AI agents, or applications that need LLM integration with tool calling or structured responses.",
                "path": "plugins/content-creation/skills/llm-apps-creator/SKILL.md",
                "frontmatter": {
                  "name": "llm-apps-creator",
                  "description": "This skill should be used when users want to build LLM-powered applications using LangChain. It provides patterns for initializing any LLM provider (OpenAI, Anthropic, Google, xAI), building agent loops with tools, and implementing structured output. Use this skill when users ask to create chatbots, AI agents, or applications that need LLM integration with tool calling or structured responses."
                },
                "content": "# LLM Apps Creator\n\n## Overview\n\nThis skill provides essential patterns for building LLM-powered applications using LangChain. It covers three core concepts:\n\n1. **Universal LLM Initialization** - Initialize any LLM provider with a single function\n2. **Agent Loop Pattern** - The simple but powerful pattern used by top AI agents\n3. **Structured Output** - Get predictable, validated responses from LLMs\n\n## Core Philosophy\n\n> \"The main agent is just a loop. The session memory is just a list of messages. It is enough to build the most powerful agent in the world.\"\n\nForget complex frameworks like ReAct/Reflection agents. The same simple agent-loop pattern is used in one of the most powerful agents: Claude Code.\n\n## Quick Start\n\n### Initialize Any LLM\n\nUse `init_chat_model` to initialize any LLM provider with automatic detection:\n\n```python\nfrom langchain.chat_models import init_chat_model\nfrom dotenv import load_dotenv\nload_dotenv()\n\n# Auto-detects provider from model name\nllm = init_chat_model(\"gpt-4.1\")                    # OpenAI (needs OPENAI_API_KEY)\nllm = init_chat_model(\"claude-sonnet-4-5-20250929\") # Anthropic (needs ANTHROPIC_API_KEY)\nllm = init_chat_model(\"grok-code-fast-1\")           # xAI (needs XAI_API_KEY)\n\n# Explicit provider specification\nllm = init_chat_model(\"gemini-2.5-flash\", model_provider=\"google_genai\")  # Google\nllm = init_chat_model(\"my-model\", model_provider=\"openai\")                # Custom\n```\n\n### Create Tools with DETAILED Docstrings\n\n> **CRITICAL**: The docstring IS the prompt that tells the LLM how to use the tool. Poor docstrings = poor tool usage = broken agent.\n\n```python\nfrom langchain_core.tools import tool\n\n# BAD - minimal docstring, LLM won't know how to use properly\n@tool\ndef read_file(file_path: str) -> str:\n    \"\"\"Read a file.\"\"\"  # DON'T DO THIS!\n    ...\n\n# GOOD - detailed docstring with usage guidelines\n@tool(\"Read\")  # Named tool for clarity\ndef read_file(file_path: str) -> str:\n    \"\"\"Reads a file from the local filesystem and returns its contents.\n\n    ## Usage Guidelines\n    - **file_path must be ABSOLUTE** (e.g., /Users/name/project/file.py), NOT relative\n    - Returns file contents with line numbers in `cat -n` format\n    - If file doesn't exist, returns an error message (this is OK, don't panic)\n\n    ## When to Use\n    - Reading source code to understand implementation\n    - Checking configuration files\n    - ALWAYS read a file BEFORE trying to edit or write to it\n\n    ## Performance Tips\n    - You can call this tool multiple times in parallel for different files\n\n    Args:\n        file_path: The ABSOLUTE path to the file (e.g., /Users/name/project/src/main.py)\n\n    Returns:\n        File contents with line numbers, or error message if file not found\n    \"\"\"\n    try:\n        with open(file_path, 'r') as f:\n            lines = f.readlines()\n        # Format with line numbers like cat -n\n        result = []\n        for i, line in enumerate(lines, 1):\n            result.append(f\"{i:6d}\\t{line.rstrip()}\")\n        return \"\\n\".join(result)\n    except FileNotFoundError:\n        return f\"Error: File not found: {file_path}\"\n    except Exception as e:\n        return f\"Error reading file: {e}\"\n```\n\n### More Tool Examples\n\n```python\n@tool(\"Write\")\ndef write_file(file_path: str, content: str) -> str:\n    \"\"\"Writes content to a file, creating it if it doesn't exist or OVERWRITING if it does.\n\n    ## Usage Guidelines\n    - **file_path must be ABSOLUTE**, NOT relative\n    - This will OVERWRITE the entire file - use Edit tool for partial modifications\n    - **CRITICAL**: ALWAYS use Read tool first to check existing content!\n\n    ## When to Use\n    - Creating NEW files that don't exist yet\n    - Completely replacing file contents\n\n    ## When NOT to Use\n    - Modifying existing files (use Edit tool instead)\n    - If you haven't read the file first\n\n    Args:\n        file_path: The ABSOLUTE path to write to\n        content: The complete content to write to the file\n\n    Returns:\n        Success message with file path, or error message\n    \"\"\"\n    import os\n    try:\n        dir_path = os.path.dirname(file_path)\n        if dir_path:\n            os.makedirs(dir_path, exist_ok=True)\n        with open(file_path, 'w') as f:\n            f.write(content)\n        return f\"Successfully wrote {len(content)} characters to {file_path}\"\n    except Exception as e:\n        return f\"Error writing file: {e}\"\n\n@tool(\"Bash\")\ndef run_command(command: str, working_dir: str = None) -> str:\n    \"\"\"Executes a bash/shell command and returns the output (stdout + stderr).\n\n    ## Usage Guidelines\n    - Use for running scripts, builds, tests, git commands, etc.\n    - Commands timeout after 30 seconds\n    - Use absolute paths in commands to avoid directory confusion\n\n    ## When to Use\n    - Running build tools (npm, pip, cargo, make, etc.)\n    - Git operations (git status, git diff, git commit, etc.)\n    - Running tests (pytest, jest, cargo test, etc.)\n\n    ## When NOT to Use\n    - Reading files (use Read tool instead of cat/head/tail)\n    - Searching files (use dedicated search tools instead of grep/find)\n\n    Args:\n        command: The shell command to execute\n        working_dir: Optional working directory (absolute path)\n\n    Returns:\n        Command output (stdout + stderr combined), or error/timeout message\n    \"\"\"\n    import subprocess\n    import os\n    try:\n        cwd = working_dir if working_dir else os.getcwd()\n        result = subprocess.run(\n            command, shell=True, capture_output=True,\n            text=True, timeout=30, cwd=cwd\n        )\n        output = result.stdout\n        if result.stderr:\n            output += f\"\\nSTDERR:\\n{result.stderr}\"\n        if result.returncode != 0:\n            output += f\"\\n[Exit code: {result.returncode}]\"\n        return output if output.strip() else \"(Command completed with no output)\"\n    except subprocess.TimeoutExpired:\n        return \"Error: Command timed out after 30 seconds\"\n    except Exception as e:\n        return f\"Error executing command: {e}\"\n```\n\n### Initialize Agent with Tools\n\n```python\nfrom langchain.chat_models import init_chat_model\n\n# Initialize LLM with tools\nllm = init_chat_model(\"gpt-4.1\")\nllm_with_tools = llm.bind_tools([read_file, write_file, run_command])\n```\n\n### Get Structured Output\n\n```python\nfrom pydantic import BaseModel, Field\nfrom langchain.agents import create_agent\n\nclass ContactInfo(BaseModel):\n    \"\"\"Contact information for a person.\"\"\"\n    name: str = Field(description=\"The name of the person\")\n    email: str = Field(description=\"The email address\")\n    phone: str = Field(description=\"The phone number\")\n\nagent = create_agent(\n    model=\"gpt-4.1\",\n    response_format=ContactInfo  # Auto-selects best strategy\n)\n\nresult = agent.invoke({\n    \"messages\": [{\"role\": \"user\", \"content\": \"Extract: John Doe, john@example.com, 555-1234\"}]\n})\nprint(result[\"structured_response\"])\n# ContactInfo(name='John Doe', email='john@example.com', phone='555-1234')\n```\n\n## The Agent Loop Pattern\n\nThe core pattern is deceptively simple:\n\n```\n1. User sends a message\n2. LLM responds (possibly with tool calls)\n3. If tool calls exist, execute them and feed results back\n4. Repeat until LLM responds without tool calls\n```\n\n### Complete Agent Implementation\n\n```python\nfrom typing import List, Dict, Any, Optional\nfrom langchain_core.messages import SystemMessage, HumanMessage, ToolMessage\nfrom langchain_core.tools import BaseTool\nfrom langchain.chat_models import init_chat_model\n\nclass SimpleAgent:\n    \"\"\"A minimal agent that uses tools to accomplish tasks.\"\"\"\n\n    def __init__(\n        self,\n        system_prompt: str,\n        tools: List[BaseTool],\n        model_name: str = \"gpt-4.1\",\n        model_provider: Optional[str] = None,\n    ):\n        # Store tools in a map for quick lookup\n        self.tools_map: Dict[str, BaseTool] = {tool.name: tool for tool in tools}\n\n        # Create LLM with tools bound\n        llm = init_chat_model(model_name, model_provider=model_provider)\n        self.llm_with_tools = llm.bind_tools(tools)\n\n        # Initialize conversation with system prompt\n        self.messages: List[Any] = [SystemMessage(content=system_prompt)]\n\n    def chat(self, user_input: str) -> str:\n        \"\"\"Process a user message and return the agent's response.\"\"\"\n        # Add user message to history\n        self.messages.append(HumanMessage(content=user_input))\n\n        # Get LLM response\n        response = self.llm_with_tools.invoke(self.messages)\n        self.messages.append(response)\n\n        # Tool execution loop\n        while hasattr(response, \"tool_calls\") and response.tool_calls:\n            for tool_call in response.tool_calls:\n                tool_name = tool_call[\"name\"]\n                tool_args = tool_call[\"args\"]\n                tool_id = tool_call[\"id\"]\n\n                # Execute the tool\n                if tool_name in self.tools_map:\n                    result = self.tools_map[tool_name].invoke(tool_args)\n                else:\n                    result = f\"Error: Unknown tool '{tool_name}'\"\n\n                # Add tool result to conversation\n                self.messages.append(\n                    ToolMessage(content=str(result), tool_call_id=tool_id)\n                )\n\n            # Get next response (sees tool results)\n            response = self.llm_with_tools.invoke(self.messages)\n            self.messages.append(response)\n\n        return response.content\n\n    def reset(self):\n        \"\"\"Clear conversation history, keeping only system prompt.\"\"\"\n        self.messages = [self.messages[0]]\n```\n\n### Usage Example\n\n```python\n# Using the well-documented tools from above\nagent = SimpleAgent(\n    system_prompt=\"\"\"You are a helpful coding assistant.\nYou can read files, write files, and run commands.\nAlways explain what you're doing before taking action.\"\"\",\n    tools=[read_file, write_file, run_command],\n    model_name=\"claude-sonnet-4-5-20250929\",\n)\n\nresponse = agent.chat(\"List all Python files in the current directory\")\nprint(response)\n```\n\n## Structured Output Patterns\n\n### Strategy Selection\n\nLangChain automatically selects the best strategy:\n\n| Strategy | When Used | Reliability |\n|----------|-----------|-------------|\n| `ProviderStrategy` | Model supports native structured output (OpenAI, Anthropic, xAI) | Highest |\n| `ToolStrategy` | All other models with tool calling | High |\n\n### Schema Types Supported\n\n1. **Pydantic Models** (recommended)\n```python\nfrom pydantic import BaseModel, Field\n\nclass ProductReview(BaseModel):\n    \"\"\"Analysis of a product review.\"\"\"\n    rating: int = Field(description=\"Rating 1-5\", ge=1, le=5)\n    sentiment: Literal[\"positive\", \"negative\"]\n    key_points: list[str]\n```\n\n2. **Dataclasses**\n```python\nfrom dataclasses import dataclass\n\n@dataclass\nclass ContactInfo:\n    name: str\n    email: str\n    phone: str\n```\n\n3. **TypedDict**\n```python\nfrom typing_extensions import TypedDict\n\nclass ContactInfo(TypedDict):\n    name: str\n    email: str\n    phone: str\n```\n\n4. **JSON Schema**\n```python\nschema = {\n    \"type\": \"object\",\n    \"properties\": {\n        \"name\": {\"type\": \"string\"},\n        \"email\": {\"type\": \"string\"}\n    },\n    \"required\": [\"name\", \"email\"]\n}\n```\n\n### Using ToolStrategy (Explicit)\n\nFor models without native structured output:\n\n```python\nfrom langchain.agents import create_agent\nfrom langchain.agents.structured_output import ToolStrategy\n\nagent = create_agent(\n    model=\"gpt-4.1\",\n    tools=my_tools,\n    response_format=ToolStrategy(ProductReview)\n)\n```\n\n### Union Types for Multiple Schemas\n\n```python\nfrom typing import Union\n\nclass ProductReview(BaseModel):\n    rating: int\n    sentiment: str\n\nclass CustomerComplaint(BaseModel):\n    issue_type: Literal[\"product\", \"service\", \"shipping\"]\n    severity: Literal[\"low\", \"medium\", \"high\"]\n    description: str\n\nagent = create_agent(\n    model=\"gpt-4.1\",\n    response_format=ToolStrategy(Union[ProductReview, CustomerComplaint])\n)\n```\n\n### Error Handling\n\n```python\n# Custom error message\nToolStrategy(schema=MySchema, handle_errors=\"Please provide valid data.\")\n\n# Handle specific exceptions\nToolStrategy(schema=MySchema, handle_errors=ValueError)\n\n# Custom handler function\ndef handle_error(e: Exception) -> str:\n    return f\"Error: {str(e)}. Please try again.\"\n\nToolStrategy(schema=MySchema, handle_errors=handle_error)\n\n# Disable error handling (exceptions propagate)\nToolStrategy(schema=MySchema, handle_errors=False)\n```\n\n## Environment Setup\n\nRequired environment variables (set in `.env` file):\n\n```bash\n# OpenAI\nOPENAI_API_KEY=sk-...\n\n# Anthropic\nANTHROPIC_API_KEY=sk-ant-...\n\n# Google\nGOOGLE_API_KEY=...\n\n# xAI (Grok)\nXAI_API_KEY=...\n```\n\n## Best Practices\n\n### Tool Design (MOST IMPORTANT)\n\n> **The docstring IS the prompt.** Poor docstrings = poor tool usage = broken agent.\n\n1. **Use named tools** - `@tool(\"Read\")` not just `@tool` for clarity\n2. **Write comprehensive docstrings** with:\n   - **Usage Guidelines** - Requirements, constraints, formats\n   - **When to Use** - Specific scenarios\n   - **When NOT to Use** - Common mistakes to avoid\n   - **Args** - Detailed parameter descriptions with examples\n   - **Returns** - What the tool returns\n3. **Include examples** in docstrings (e.g., \"file_path must be ABSOLUTE like /Users/name/file.py\")\n4. **Document error behavior** - Tell LLM what errors look like and that they're OK\n\n### Agent Design\n\n1. **Keep it simple** - The basic loop pattern handles most use cases\n2. **Handle errors gracefully** - Wrap tool execution in try/except\n3. **Limit tool scope** - Give agent only tools it needs\n4. **Use absolute paths** - Avoid confusion with relative paths\n\n### Structured Output\n\n1. **Use Pydantic for validation** - Built-in type checking and constraints\n2. **Add Field descriptions** - Helps LLM understand expected format\n3. **Use Literal for enums** - Constrains values to specific options\n4. **Enable error handling** - Let LangChain retry on validation failures\n\n### Model Selection\n\n| Use Case | Recommended Model |\n|----------|------------------|\n| General tasks | `gpt-4.1` or `claude-sonnet-4-5-20250929` |\n| Fast responses | `grok-code-fast-1` or `gemini-2.5-flash` |\n| Complex reasoning | `claude-sonnet-4-5-20250929` or `gpt-4.1` |\n| Cost-sensitive | `gpt-4.1-mini` or smaller models |\n\n## Resources\n\n### references/\n\nThis skill includes complete reference documentation:\n\n- `base_n_powerful_agent.py` - Complete working agent implementation with tools\n- `langchain_structured_output.md` - Comprehensive structured output documentation with all strategies and error handling patterns\n\nRead these files for detailed examples and advanced patterns."
              },
              {
                "name": "power-agent-creator",
                "description": "This skill should be used when users want to create powerful AI agents comparable to Claude Code or sonph-code. It provides battle-tested system prompts, masterfully-crafted tool implementations, and the simple but powerful agent loop pattern. Use this skill when users ask to build coding agents, AI assistants with tools, or any autonomous agent that needs file operations, code execution, search, and task management capabilities. The key insight is that customization requires only ONE HumanMessage after the SystemPrompt.",
                "path": "plugins/content-creation/skills/power-agent-creator/SKILL.md",
                "frontmatter": {
                  "name": "power-agent-creator",
                  "description": "This skill should be used when users want to create powerful AI agents comparable to Claude Code or sonph-code. It provides battle-tested system prompts, masterfully-crafted tool implementations, and the simple but powerful agent loop pattern. Use this skill when users ask to build coding agents, AI assistants with tools, or any autonomous agent that needs file operations, code execution, search, and task management capabilities. The key insight is that customization requires only ONE HumanMessage after the SystemPrompt."
                },
                "content": "# Power Agent Creator\n\n## Overview\n\nThis skill provides everything needed to create powerful AI agents comparable to Claude Code. It includes:\n\n1. **Battle-tested System Prompt** - A masterpiece prompt refined through millions of dollars of evaluation\n2. **Production-ready Tools** - Comprehensive toolset for file ops, search, execution, and task management\n3. **The Agent Loop** - The same simple pattern used by the most powerful agents\n\n## Core Philosophy\n\n> \"The main agent is just a loop. The session memory is just a list of messages. It is enough to build the most powerful agent in the world. PERIOD!\"\n\n**CRITICAL**: Do NOT modify the system prompts or tool descriptions. They are masterpieces refined through extensive evaluation.\n\n## The Customization Secret\n\nTo create ANY kind of agent, you only need to add ONE `HumanMessage` after the `SystemMessage`:\n\n```python\nfrom langchain_core.messages import SystemMessage, HumanMessage\nfrom prompts import coding_agent_prompt\n\nmessages = [\n    SystemMessage(content=coding_agent_prompt()),\n    HumanMessage(content=\"\"\"You are now specialized as a [ROLE].\n\nYour additional capabilities:\n- [CAPABILITY 1]\n- [CAPABILITY 2]\n\nYour constraints:\n- [CONSTRAINT 1]\n- [CONSTRAINT 2]\n\nFocus on: [SPECIFIC DOMAIN]\"\"\"),\n]\n```\n\n## Quick Start: Create a Specialized Agent\n\n### Step 1: Initialize with Base System Prompt\n\n```python\nfrom langchain.chat_models import init_chat_model\nfrom langchain_core.messages import SystemMessage, HumanMessage\nfrom dotenv import load_dotenv\nload_dotenv()\n\n# Import the masterpiece system prompt - DO NOT MODIFY\nfrom references.prompts import coding_agent_prompt\n\n# Initialize any LLM\nllm = init_chat_model(\"grok-code-fast-1\")  # or gpt-4.1, grok-code-fast-1\n\n# Start with base system prompt\nmessages = [SystemMessage(content=coding_agent_prompt())]\n```\n\n### Step 2: Add Specialization Message\n\n```python\n# Add ONE HumanMessage to specialize the agent\nspecialization = HumanMessage(content=\"\"\"You are now a specialized DevOps Agent.\n\nAdditional expertise:\n- Docker and Kubernetes configurations\n- CI/CD pipeline management\n- Infrastructure as Code (Terraform, Ansible)\n- Cloud platforms (AWS, GCP, Azure)\n\nWhen working on tasks:\n1. Always check existing infrastructure code first\n2. Follow GitOps principles\n3. Prefer declarative over imperative approaches\n4. Document all changes in infrastructure comments\"\"\")\n\nmessages.append(specialization)\n```\n\n### Step 3: Bind Tools and Create Agent\n\n```python\n# Import production-ready tools - DO NOT MODIFY THEIR DOCSTRINGS\nfrom references.tools import (\n    read_file, write_file, edit_file, list_files,  # File operations\n    glob_files, grep_files,                         # Search tools\n    bash, get_bash_output, todo_write,              # Execution & task management\n)\n\n# Bind tools to LLM\ntools = [read_file, write_file, edit_file, list_files,\n         glob_files, grep_files, bash, get_bash_output, todo_write]\nllm_with_tools = llm.bind_tools(tools)\n```\n\n### Step 4: Run the Agent Loop\n\n```python\nfrom langchain_core.messages import ToolMessage\n\ndef run_agent(user_input: str):\n    messages.append(HumanMessage(content=user_input))\n\n    response = llm_with_tools.invoke(messages)\n    messages.append(response)\n\n    # Tool execution loop\n    while hasattr(response, \"tool_calls\") and response.tool_calls:\n        for tool_call in response.tool_calls:\n            tool_name = tool_call[\"name\"]\n            tool_args = tool_call[\"args\"]\n            tool_id = tool_call[\"id\"]\n\n            # Execute tool (map name to function)\n            tools_map = {t.name: t for t in tools}\n            result = tools_map[tool_name].invoke(tool_args)\n\n            messages.append(ToolMessage(content=str(result), tool_call_id=tool_id))\n\n        response = llm_with_tools.invoke(messages)\n        messages.append(response)\n\n    return response.content\n```\n\n## Specialization Examples\n\n### Data Science Agent\n\n```python\nspecialization = HumanMessage(content=\"\"\"You are now a specialized Data Science Agent.\n\nAdditional expertise:\n- Pandas, NumPy, and scikit-learn workflows\n- Data cleaning, feature engineering, and EDA\n- Statistical analysis and hypothesis testing\n- Machine learning model development and evaluation\n\nWhen working on tasks:\n1. Always explore data before analysis (df.info(), df.describe())\n2. Check for missing values and data quality issues\n3. Document assumptions and methodology\n4. Provide reproducible code with clear explanations\"\"\")\n```\n\n### Security Analyst Agent\n\n```python\nspecialization = HumanMessage(content=\"\"\"You are now a specialized Security Analyst Agent.\n\nAdditional expertise:\n- Code vulnerability analysis (OWASP Top 10)\n- Security best practices review\n- Authentication and authorization patterns\n- Secrets management and encryption\n\nWhen working on tasks:\n1. Always scan for hardcoded secrets first\n2. Check for injection vulnerabilities\n3. Review authentication flows\n4. Document all findings with severity levels\"\"\")\n```\n\n### Full-Stack Developer Agent\n\n```python\nspecialization = HumanMessage(content=\"\"\"You are now a specialized Full-Stack Developer Agent.\n\nAdditional expertise:\n- React/Vue/Next.js frontend development\n- Node.js/Python backend APIs\n- Database design and optimization\n- API design and RESTful principles\n\nWhen working on tasks:\n1. Check existing patterns in the codebase\n2. Follow the project's code style\n3. Write tests for new functionality\n4. Consider performance implications\"\"\")\n```\n\n### Documentation Agent\n\n```python\nspecialization = HumanMessage(content=\"\"\"You are now a specialized Documentation Agent.\n\nAdditional expertise:\n- Technical writing and API documentation\n- README creation and maintenance\n- Code comment standards\n- Architecture decision records (ADRs)\n\nWhen working on tasks:\n1. Read the code thoroughly before documenting\n2. Use clear, concise language\n3. Include examples for all features\n4. Keep documentation close to the code\"\"\")\n```\n\n## Complete Agent Class\n\n```python\nfrom typing import List, Dict, Any, Optional\nfrom langchain_core.messages import SystemMessage, HumanMessage, ToolMessage\nfrom langchain_core.tools import BaseTool\nfrom langchain.chat_models import init_chat_model\n\nclass PowerAgent:\n    \"\"\"A powerful agent comparable to Claude Code.\"\"\"\n\n    def __init__(\n        self,\n        specialization: str = None,\n        tools: List[BaseTool] = None,\n        model_name: str = \"grok-code-fast-1\",\n        working_dir: str = None,\n    ):\n        from references.prompts import coding_agent_prompt\n        from references.tools import (\n            read_file, write_file, edit_file, list_files,\n            glob_files, grep_files, bash, get_bash_output, todo_write,\n        )\n\n        # Use provided tools or defaults\n        self.tools = tools or [\n            read_file, write_file, edit_file, list_files,\n            glob_files, grep_files, bash, get_bash_output, todo_write,\n        ]\n        self.tools_map: Dict[str, BaseTool] = {t.name: t for t in self.tools}\n\n        # Initialize LLM with tools\n        llm = init_chat_model(model_name)\n        self.llm_with_tools = llm.bind_tools(self.tools)\n\n        # Initialize messages with system prompt\n        self.messages: List[Any] = [\n            SystemMessage(content=coding_agent_prompt(working_dir))\n        ]\n\n        # Add specialization if provided\n        if specialization:\n            self.messages.append(HumanMessage(content=specialization))\n\n    def chat(self, user_input: str) -> str:\n        \"\"\"Process user input and return response.\"\"\"\n        self.messages.append(HumanMessage(content=user_input))\n\n        response = self.llm_with_tools.invoke(self.messages)\n        self.messages.append(response)\n\n        # Tool execution loop\n        while hasattr(response, \"tool_calls\") and response.tool_calls:\n            for tool_call in response.tool_calls:\n                tool_name = tool_call[\"name\"]\n                tool_args = tool_call[\"args\"]\n                tool_id = tool_call[\"id\"]\n\n                if tool_name in self.tools_map:\n                    result = self.tools_map[tool_name].invoke(tool_args)\n                else:\n                    result = f\"Error: Unknown tool '{tool_name}'\"\n\n                self.messages.append(\n                    ToolMessage(content=str(result), tool_call_id=tool_id)\n                )\n\n            response = self.llm_with_tools.invoke(self.messages)\n            self.messages.append(response)\n\n        return response.content\n\n    def reset(self):\n        \"\"\"Reset conversation, keeping system prompt and specialization.\"\"\"\n        # Keep first 1-2 messages (system + optional specialization)\n        keep_count = 2 if len(self.messages) > 1 and isinstance(self.messages[1], HumanMessage) else 1\n        self.messages = self.messages[:keep_count]\n```\n\n## Usage Example\n\n```python\n# Create a DevOps agent\nagent = PowerAgent(\n    specialization=\"\"\"You are now a specialized DevOps Agent.\n\n    Focus on: Docker, Kubernetes, CI/CD, and infrastructure as code.\n    Always check existing infrastructure patterns first.\"\"\",\n    model_name=\"grok-code-fast-1\",\n)\n\n# Use the agent\nresponse = agent.chat(\"Set up a Dockerfile for a Python FastAPI application\")\nprint(response)\n```\n\n## Available Tools Reference\n\nThe skill includes these production-ready tools (DO NOT modify their docstrings):\n\n### File Operations\n- **Read** - Read files with line numbers, supports images/PDFs/notebooks\n- **Write** - Write files with overwrite protection\n- **Edit** - Precise string replacement in files\n- **LS** - List directory contents\n\n### Search Tools\n- **Glob** - Fast file pattern matching (`**/*.py`)\n- **Grep** - Powerful ripgrep-based content search\n\n### Execution Tools\n- **Bash** - Execute shell commands with timeout and background support\n- **BashOutput** - Monitor background processes\n- **KillBash** - Terminate background processes\n\n### Task Management\n- **TodoWrite** - Create and manage structured task lists\n\n### Web Tools (Optional)\n- **web_fetch** - Fetch and analyze web content\n- **web_search** - Search the web for information\n\n## Resources\n\n### references/\n\nThis skill includes complete, production-ready code:\n\n- `prompts.py` - The battle-tested system prompt (DO NOT MODIFY)\n- `base_n_powerful_agent.py` - The simple agent loop pattern\n- `tools/` - All tool implementations:\n  - `file_tools.py` - Read, Write, Edit, LS\n  - `search_tools.py` - Glob, Grep\n  - `execution_tools.py` - Bash, BashOutput, KillBash, TodoWrite\n  - `task_tool.py` - Task delegation to sub-agents\n  - `web_fetch_tool.py` - Web content fetching\n  - `web_search_tool.py` - Web search\n\n**IMPORTANT**: The tool docstrings are masterpieces of prompt engineering. They cost millions of dollars to refine. DO NOT modify them - they are the key to proper tool usage by the LLM."
              },
              {
                "name": "prompting",
                "description": "PROACTIVE: This skill SHOULD BE USED AUTOMATICALLY when writing prompts, system prompts, crafting instructions for LLMs, or optimizing AI interactions. Triggers on: write prompt, system prompt, prompt engineering, optimize prompt, better prompt, prompt template, instruction design, context engineering, SKILL.md description, agent instructions. Use for CRAFTING LLM PROMPTS. Model-agnostic best practices for coding agents.",
                "path": "plugins/content-creation/skills/prompting/SKILL.md",
                "frontmatter": {
                  "name": "prompting",
                  "description": "PROACTIVE: This skill SHOULD BE USED AUTOMATICALLY when writing prompts, system prompts, crafting instructions for LLMs, or optimizing AI interactions. Triggers on: write prompt, system prompt, prompt engineering, optimize prompt, better prompt, prompt template, instruction design, context engineering, SKILL.md description, agent instructions. Use for CRAFTING LLM PROMPTS. Model-agnostic best practices for coding agents."
                },
                "content": "# Prompting - Model-Agnostic Best Practices (Late 2025)\n\nOptimal prompt standards for coding agents. Applies to all models (Claude, GPT, Gemini, Grok).\n\n**Paradigm**: Context Engineering > Prompt Engineering. Focus on designing information systems, not \"perfect wording\". API-level configs (effort, reasoning_effort, thinking_level) are separate from prompt text.\n\n## Quick Reference (Use First)\n\nBefore writing/reviewing any prompt, verify:\n\n```\n[ ] Structure: Clear XML/Markdown sections (context → task → constraints → output)\n[ ] Order: Long context BEFORE query (+30% quality)\n[ ] Task: ONE atomic, explicit action\n[ ] Output: Format defined (JSON schema, structure)\n[ ] Positive: \"Do X\" instead of \"Don't Y\"\n[ ] Reasoning: Zero-shot for reasoning models (no manual CoT)\n[ ] Examples: Few-shot ONLY for format, not logic\n[ ] Caching: Static content first, dynamic last\n[ ] Simplicity: Start simple, add complexity only if needed (Stanford 8-word)\n```\n\n## Decision Flow\n\n```\nTask Type?\n│\n├─ Simple (1 step) ────────────► Direct instruction, no CoT\n│\n├─ Complex reasoning\n│   ├─ Reasoning model (o3/o4/GPT-5/Claude thinking)\n│   │   └─► Zero-shot + explicit goal only\n│   └─ Standard model\n│       └─► Structured prompt + optional CoT\n│\n├─ Code generation ────────────► Define: language, framework, style\n│                                Provide: context files, dependencies\n│                                Specify: output format, tests\n│\n└─ Multi-step workflow ────────► Break into atomic tasks\n                                 Use Orchestrator-Worker pattern\n                                 Include verification steps\n```\n\n## Core Structure Template\n\n```xml\n<context>\n  [Background, project details - place LONG documents here]\n</context>\n<task>\n  [ONE specific action required]\n</task>\n<constraints>\n  [Boundaries, limitations]\n</constraints>\n<output_format>\n  [Exact format: JSON schema, markdown structure]\n</output_format>\n```\n\nFor **system prompts** (coding agents):\n\n```xml\n<role>[Expert domain]</role>\n<capabilities>[Tools, what agent CAN do]</capabilities>\n<constraints>[Security rules, boundaries]</constraints>\n<workflow>[Step-by-step process]</workflow>\n<output_standards>[Code style, testing requirements]</output_standards>\n```\n\n## Key Principles\n\n| Principle | Do This | Avoid This |\n|-----------|---------|------------|\n| **Structure** | XML/Markdown sections | Wall of text |\n| **Context** | Long docs BEFORE query | Query before context (-30%) |\n| **Specificity** | \"Dashboard with filtering, export, real-time\" | \"Create dashboard\" |\n| **Instructions** | \"Return only JSON\" | \"Don't add explanations\" |\n| **Reasoning models** | Zero-shot, explicit goal | Manual \"think step-by-step\" |\n| **Examples** | Few-shot for FORMAT only | Few-shot for logic (hurts reasoning) |\n| **Caching** | Static first, dynamic last | Dynamic content first |\n\n## Technique Selection\n\n| Technique | Use When | Avoid When |\n|-----------|----------|------------|\n| **Extended Thinking** | Complex math, multi-step planning | Pattern recognition, simple tasks (can HURT -36%) |\n| **Atom of Thoughts** | Parallelizable problems | Creative writing |\n| **Tree of Thoughts** | Multiple valid paths | Simple queries |\n| **ReAct** | Tool use, external data | Pure reasoning |\n| **Self-Consistency** | High-stakes decisions | Speed-critical |\n| **Role Reversal** | Need +40% accuracy | Quick drafts |\n\nSee details: `references/techniques.md`\n\n## Context Stack (Priority Order)\n\n1. System Instructions (role, rules) - **cached**\n2. Long-Term Memory (preferences)\n3. Retrieved Documents (RAG)\n4. Tool Definitions - **cached**\n5. Conversation History\n6. Current Task - **last for recency**\n\n## Security\n\n- Separate system/user content with XML tags\n- Validate user inputs before embedding\n- Validate OUTPUT, not reasoning (CoT hijackable 94-99%)\n- Mark sensitive context with explicit boundaries\n\n## References\n\nLoad as needed for detailed guidance:\n\n- `references/techniques.md` - AoT, ToT, ReAct, Self-Consistency, Role Reversal, Extended Thinking\n- `references/anti-patterns.md` - Full list of what to avoid with explanations\n- `references/agentic-patterns.md` - Orchestrator-Worker, Reflexion, Plan-Execute, Tool Orchestration\n- `references/memory-patterns.md` - CoALA Framework: Procedural, Semantic, Episodic memory\n- `references/meta-prompting.md` - LLM self-optimization workflow"
              },
              {
                "name": "web-artifacts-builder",
                "description": "Suite of tools for creating elaborate, multi-component claude.ai HTML artifacts using modern frontend web technologies (React, Tailwind CSS, shadcn/ui). Use for complex artifacts requiring state management, routing, or shadcn/ui components - not for simple single-file HTML/JSX artifacts.",
                "path": "plugins/content-creation/skills/web-artifacts-builder/SKILL.md",
                "frontmatter": {
                  "name": "web-artifacts-builder",
                  "description": "Suite of tools for creating elaborate, multi-component claude.ai HTML artifacts using modern frontend web technologies (React, Tailwind CSS, shadcn/ui). Use for complex artifacts requiring state management, routing, or shadcn/ui components - not for simple single-file HTML/JSX artifacts.",
                  "license": "Complete terms in LICENSE.txt"
                },
                "content": "# Web Artifacts Builder\n\nTo build powerful frontend claude.ai artifacts, follow these steps:\n1. Initialize the frontend repo using `scripts/init-artifact.sh`\n2. Develop your artifact by editing the generated code\n3. Bundle all code into a single HTML file using `scripts/bundle-artifact.sh`\n4. Display artifact to user\n5. (Optional) Test the artifact\n\n**Stack**: React 18 + TypeScript + Vite + Parcel (bundling) + Tailwind CSS + shadcn/ui\n\n## Design & Style Guidelines\n\nVERY IMPORTANT: To avoid what is often referred to as \"AI slop\", avoid using excessive centered layouts, purple gradients, uniform rounded corners, and Inter font.\n\n## Quick Start\n\n### Step 1: Initialize Project\n\nRun the initialization script to create a new React project:\n```bash\nbash scripts/init-artifact.sh <project-name>\ncd <project-name>\n```\n\nThis creates a fully configured project with:\n- ✅ React + TypeScript (via Vite)\n- ✅ Tailwind CSS 3.4.1 with shadcn/ui theming system\n- ✅ Path aliases (`@/`) configured\n- ✅ 40+ shadcn/ui components pre-installed\n- ✅ All Radix UI dependencies included\n- ✅ Parcel configured for bundling (via .parcelrc)\n- ✅ Node 18+ compatibility (auto-detects and pins Vite version)\n\n### Step 2: Develop Your Artifact\n\nTo build the artifact, edit the generated files. See **Common Development Tasks** below for guidance.\n\n### Step 3: Bundle to Single HTML File\n\nTo bundle the React app into a single HTML artifact:\n```bash\nbash scripts/bundle-artifact.sh\n```\n\nThis creates `bundle.html` - a self-contained artifact with all JavaScript, CSS, and dependencies inlined. This file can be directly shared in Claude conversations as an artifact.\n\n**Requirements**: Your project must have an `index.html` in the root directory.\n\n**What the script does**:\n- Installs bundling dependencies (parcel, @parcel/config-default, parcel-resolver-tspaths, html-inline)\n- Creates `.parcelrc` config with path alias support\n- Builds with Parcel (no source maps)\n- Inlines all assets into single HTML using html-inline\n\n### Step 4: Share Artifact with User\n\nFinally, share the bundled HTML file in conversation with the user so they can view it as an artifact.\n\n### Step 5: Testing/Visualizing the Artifact (Optional)\n\nNote: This is a completely optional step. Only perform if necessary or requested.\n\nTo test/visualize the artifact, use available tools (including other Skills or built-in tools like Playwright or Puppeteer). In general, avoid testing the artifact upfront as it adds latency between the request and when the finished artifact can be seen. Test later, after presenting the artifact, if requested or if issues arise.\n\n## Reference\n\n- **shadcn/ui components**: https://ui.shadcn.com/docs/components"
              }
            ]
          }
        ]
      }
    }
  ]
}