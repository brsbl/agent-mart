{
  "owner": {
    "id": "el-feo",
    "display_name": "Jeb Coleman",
    "type": "User",
    "avatar_url": "https://avatars.githubusercontent.com/u/677379?v=4",
    "url": "https://github.com/el-feo",
    "bio": null,
    "stats": {
      "total_repos": 1,
      "total_plugins": 6,
      "total_commands": 20,
      "total_skills": 20,
      "total_stars": 0,
      "total_forks": 0
    }
  },
  "repos": [
    {
      "full_name": "el-feo/ai-context",
      "url": "https://github.com/el-feo/ai-context",
      "description": "A collection of Claude Code plugins.",
      "homepage": "",
      "signals": {
        "stars": 0,
        "forks": 0,
        "pushed_at": "2026-01-12T05:23:19Z",
        "created_at": "2025-03-11T20:00:10Z",
        "license": "MIT"
      },
      "file_tree": [
        {
          "path": ".claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude-plugin/marketplace.json",
          "type": "blob",
          "size": 2046
        },
        {
          "path": ".claude",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude/settings.local.json",
          "type": "blob",
          "size": 711
        },
        {
          "path": ".github",
          "type": "tree",
          "size": null
        },
        {
          "path": ".github/scripts",
          "type": "tree",
          "size": null
        },
        {
          "path": ".github/scripts/bump-version.sh",
          "type": "blob",
          "size": 2223
        },
        {
          "path": ".github/scripts/check-version-bump.sh",
          "type": "blob",
          "size": 4830
        },
        {
          "path": ".github/workflows",
          "type": "tree",
          "size": null
        },
        {
          "path": ".github/workflows/version-bump.yml",
          "type": "blob",
          "size": 1341
        },
        {
          "path": ".github/workflows/version-check.yml",
          "type": "blob",
          "size": 746
        },
        {
          "path": ".gitignore",
          "type": "blob",
          "size": 384
        },
        {
          "path": "CLAUDE.md",
          "type": "blob",
          "size": 2140
        },
        {
          "path": "LICENSE",
          "type": "blob",
          "size": 1068
        },
        {
          "path": "README.md",
          "type": "blob",
          "size": 3801
        },
        {
          "path": "plugins",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/devops",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/devops/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/devops/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 368
        },
        {
          "path": "plugins/devops/README.md",
          "type": "blob",
          "size": 693
        },
        {
          "path": "plugins/devops/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/devops/commands/github-actions.md",
          "type": "blob",
          "size": 792
        },
        {
          "path": "plugins/devops/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/devops/skills/github-actions",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/devops/skills/github-actions/SKILL.md",
          "type": "blob",
          "size": 12473
        },
        {
          "path": "plugins/devops/skills/github-actions/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/devops/skills/github-actions/references/common-workflows.md",
          "type": "blob",
          "size": 20278
        },
        {
          "path": "plugins/devops/skills/github-actions/references/custom-actions.md",
          "type": "blob",
          "size": 12935
        },
        {
          "path": "plugins/devops/skills/github-actions/references/evaluation-guide.md",
          "type": "blob",
          "size": 14910
        },
        {
          "path": "plugins/devops/skills/github-actions/references/performance-optimization.md",
          "type": "blob",
          "size": 13960
        },
        {
          "path": "plugins/devops/skills/github-actions/references/security-checklist.md",
          "type": "blob",
          "size": 14504
        },
        {
          "path": "plugins/devops/skills/github-actions/references/troubleshooting.md",
          "type": "blob",
          "size": 15752
        },
        {
          "path": "plugins/devops/skills/github-actions/references/workflow-syntax.md",
          "type": "blob",
          "size": 11119
        },
        {
          "path": "plugins/devops/skills/kamal",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/devops/skills/kamal/SKILL.md",
          "type": "blob",
          "size": 8449
        },
        {
          "path": "plugins/devops/skills/kamal/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/devops/skills/kamal/references/commands.md",
          "type": "blob",
          "size": 14467
        },
        {
          "path": "plugins/devops/skills/kamal/references/configuration.md",
          "type": "blob",
          "size": 8752
        },
        {
          "path": "plugins/devops/skills/kamal/references/workflows.md",
          "type": "blob",
          "size": 11893
        },
        {
          "path": "plugins/devops/skills/tailscale",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/devops/skills/tailscale/SKILL.md",
          "type": "blob",
          "size": 10897
        },
        {
          "path": "plugins/devops/skills/tailscale/assets",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/devops/skills/tailscale/assets/example_asset.txt",
          "type": "blob",
          "size": 865
        },
        {
          "path": "plugins/devops/skills/tailscale/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/devops/skills/tailscale/references/acl-examples.md",
          "type": "blob",
          "size": 13105
        },
        {
          "path": "plugins/devops/skills/tailscale/references/api-usage.md",
          "type": "blob",
          "size": 10840
        },
        {
          "path": "plugins/devops/skills/tailscale/references/api_reference.md",
          "type": "blob",
          "size": 960
        },
        {
          "path": "plugins/devops/skills/tailscale/references/cli-reference.md",
          "type": "blob",
          "size": 9920
        },
        {
          "path": "plugins/devops/skills/tailscale/references/production-setup.md",
          "type": "blob",
          "size": 14096
        },
        {
          "path": "plugins/devops/skills/tailscale/references/troubleshooting.md",
          "type": "blob",
          "size": 10886
        },
        {
          "path": "plugins/devops/skills/tailscale/scripts",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/devops/skills/tailscale/scripts/example.py",
          "type": "blob",
          "size": 577
        },
        {
          "path": "plugins/devops/skills/tailscale/scripts/setup_exit_node.sh",
          "type": "blob",
          "size": 2474
        },
        {
          "path": "plugins/devops/skills/tailscale/scripts/setup_subnet_router.sh",
          "type": "blob",
          "size": 2984
        },
        {
          "path": "plugins/general",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/general/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/general/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 254
        },
        {
          "path": "plugins/general/README.md",
          "type": "blob",
          "size": 613
        },
        {
          "path": "plugins/general/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/general/skills/mermaid-diagrams",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/general/skills/mermaid-diagrams/SKILL.md",
          "type": "blob",
          "size": 7366
        },
        {
          "path": "plugins/general/skills/mermaid-diagrams/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/general/skills/mermaid-diagrams/references/advanced-features.md",
          "type": "blob",
          "size": 10365
        },
        {
          "path": "plugins/general/skills/mermaid-diagrams/references/c4-diagrams.md",
          "type": "blob",
          "size": 15266
        },
        {
          "path": "plugins/general/skills/mermaid-diagrams/references/class-diagrams.md",
          "type": "blob",
          "size": 6915
        },
        {
          "path": "plugins/general/skills/mermaid-diagrams/references/erd-diagrams.md",
          "type": "blob",
          "size": 12348
        },
        {
          "path": "plugins/general/skills/mermaid-diagrams/references/flowcharts.md",
          "type": "blob",
          "size": 9844
        },
        {
          "path": "plugins/general/skills/mermaid-diagrams/references/sequence-diagrams.md",
          "type": "blob",
          "size": 9213
        },
        {
          "path": "plugins/ghpm",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/ghpm/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/ghpm/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 665
        },
        {
          "path": "plugins/ghpm/README.md",
          "type": "blob",
          "size": 16074
        },
        {
          "path": "plugins/ghpm/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/ghpm/agents/ci-check-agent.md",
          "type": "blob",
          "size": 5810
        },
        {
          "path": "plugins/ghpm/agents/conflict-resolver-agent.md",
          "type": "blob",
          "size": 18034
        },
        {
          "path": "plugins/ghpm/agents/pr-review-agent.md",
          "type": "blob",
          "size": 15871
        },
        {
          "path": "plugins/ghpm/agents/review-cycle-coordinator-agent.md",
          "type": "blob",
          "size": 18969
        },
        {
          "path": "plugins/ghpm/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/ghpm/commands/changelog.md",
          "type": "blob",
          "size": 6051
        },
        {
          "path": "plugins/ghpm/commands/create-epics.md",
          "type": "blob",
          "size": 13263
        },
        {
          "path": "plugins/ghpm/commands/create-prd.md",
          "type": "blob",
          "size": 19044
        },
        {
          "path": "plugins/ghpm/commands/create-project.md",
          "type": "blob",
          "size": 9550
        },
        {
          "path": "plugins/ghpm/commands/create-tasks.md",
          "type": "blob",
          "size": 15192
        },
        {
          "path": "plugins/ghpm/commands/execute.md",
          "type": "blob",
          "size": 19312
        },
        {
          "path": "plugins/ghpm/commands/qa-create-steps.md",
          "type": "blob",
          "size": 14423
        },
        {
          "path": "plugins/ghpm/commands/qa-create.md",
          "type": "blob",
          "size": 6653
        },
        {
          "path": "plugins/ghpm/commands/qa-execute.md",
          "type": "blob",
          "size": 47510
        },
        {
          "path": "plugins/ghpm/commands/quick-issue.md",
          "type": "blob",
          "size": 10688
        },
        {
          "path": "plugins/ghpm/commands/tdd-task.md",
          "type": "blob",
          "size": 11551
        },
        {
          "path": "plugins/ghpm/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/ghpm/skills/claim-issue.md",
          "type": "blob",
          "size": 7564
        },
        {
          "path": "plugins/ghpmplus",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/ghpmplus/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/ghpmplus/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 573
        },
        {
          "path": "plugins/ghpmplus/README.md",
          "type": "blob",
          "size": 11913
        },
        {
          "path": "plugins/ghpmplus/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/ghpmplus/agents/epic-creator-agent.md",
          "type": "blob",
          "size": 8195
        },
        {
          "path": "plugins/ghpmplus/agents/orchestrator-agent.md",
          "type": "blob",
          "size": 28785
        },
        {
          "path": "plugins/ghpmplus/agents/stub-epic-planner.md",
          "type": "blob",
          "size": 1924
        },
        {
          "path": "plugins/ghpmplus/agents/stub-task-executor.md",
          "type": "blob",
          "size": 2183
        },
        {
          "path": "plugins/ghpmplus/agents/task-creator-agent.md",
          "type": "blob",
          "size": 10517
        },
        {
          "path": "plugins/ghpmplus/agents/task-executor-agent.md",
          "type": "blob",
          "size": 15374
        },
        {
          "path": "plugins/ghpmplus/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/ghpmplus/commands/auto-execute.md",
          "type": "blob",
          "size": 7722
        },
        {
          "path": "plugins/ghpmplus/commands/create-prd.md",
          "type": "blob",
          "size": 19323
        },
        {
          "path": "plugins/ghpmplus/docs",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/ghpmplus/docs/agent-comment-format.md",
          "type": "blob",
          "size": 10511
        },
        {
          "path": "plugins/ghpmplus/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/ghpmplus/skills/worktree-helpers.md",
          "type": "blob",
          "size": 7952
        },
        {
          "path": "plugins/js-ts",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/js-ts/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/js-ts/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 360
        },
        {
          "path": "plugins/js-ts/README.md",
          "type": "blob",
          "size": 671
        },
        {
          "path": "plugins/js-ts/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/js-ts/commands/vitest.md",
          "type": "blob",
          "size": 634
        },
        {
          "path": "plugins/js-ts/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/js-ts/skills/eslint",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/js-ts/skills/eslint/SKILL.md",
          "type": "blob",
          "size": 11476
        },
        {
          "path": "plugins/js-ts/skills/eslint/assets",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/js-ts/skills/eslint/assets/.eslintignore.example",
          "type": "blob",
          "size": 3245
        },
        {
          "path": "plugins/js-ts/skills/eslint/assets/eslint.config.examples.js",
          "type": "blob",
          "size": 12087
        },
        {
          "path": "plugins/js-ts/skills/eslint/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/js-ts/skills/eslint/references/custom_rules.md",
          "type": "blob",
          "size": 13147
        },
        {
          "path": "plugins/js-ts/skills/eslint/references/migration_guide.md",
          "type": "blob",
          "size": 12206
        },
        {
          "path": "plugins/js-ts/skills/eslint/references/rule_reference.md",
          "type": "blob",
          "size": 13247
        },
        {
          "path": "plugins/js-ts/skills/eslint/references/type_aware_linting.md",
          "type": "blob",
          "size": 13070
        },
        {
          "path": "plugins/js-ts/skills/javascript-unit-testing",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/js-ts/skills/javascript-unit-testing/EXAMPLES.md",
          "type": "blob",
          "size": 36021
        },
        {
          "path": "plugins/js-ts/skills/javascript-unit-testing/REFERENCE.md",
          "type": "blob",
          "size": 24470
        },
        {
          "path": "plugins/js-ts/skills/javascript-unit-testing/SKILL.md",
          "type": "blob",
          "size": 11006
        },
        {
          "path": "plugins/js-ts/skills/vitest",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/js-ts/skills/vitest/README.md",
          "type": "blob",
          "size": 3455
        },
        {
          "path": "plugins/js-ts/skills/vitest/SKILL.md",
          "type": "blob",
          "size": 10411
        },
        {
          "path": "plugins/js-ts/skills/vitest/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/js-ts/skills/vitest/references/CONFIG.md",
          "type": "blob",
          "size": 19041
        },
        {
          "path": "plugins/js-ts/skills/vitest/references/MIGRATION.md",
          "type": "blob",
          "size": 20339
        },
        {
          "path": "plugins/js-ts/skills/vitest/references/MIGRATION_SCRIPT.md",
          "type": "blob",
          "size": 6727
        },
        {
          "path": "plugins/js-ts/skills/vitest/scripts",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/js-ts/skills/vitest/scripts/README.md",
          "type": "blob",
          "size": 1290
        },
        {
          "path": "plugins/js-ts/skills/vitest/scripts/comprehensive-migrate.sh",
          "type": "blob",
          "size": 8432
        },
        {
          "path": "plugins/js-ts/skills/vitest/scripts/quick-migrate.sh",
          "type": "blob",
          "size": 2021
        },
        {
          "path": "plugins/ruby-rails",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/ruby-rails/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/ruby-rails/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 257
        },
        {
          "path": "plugins/ruby-rails/README.md",
          "type": "blob",
          "size": 1352
        },
        {
          "path": "plugins/ruby-rails/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/ruby-rails/agents/rails-generator-agent.md",
          "type": "blob",
          "size": 4068
        },
        {
          "path": "plugins/ruby-rails/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/ruby-rails/commands/rails-generators.md",
          "type": "blob",
          "size": 829
        },
        {
          "path": "plugins/ruby-rails/commands/red-green-refactor.md",
          "type": "blob",
          "size": 1090
        },
        {
          "path": "plugins/ruby-rails/commands/review-ruby-code.md",
          "type": "blob",
          "size": 1149
        },
        {
          "path": "plugins/ruby-rails/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/ruby-rails/skills/brakeman",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/ruby-rails/skills/brakeman/SKILL.md",
          "type": "blob",
          "size": 10264
        },
        {
          "path": "plugins/ruby-rails/skills/brakeman/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/ruby-rails/skills/brakeman/references/command_options.md",
          "type": "blob",
          "size": 11886
        },
        {
          "path": "plugins/ruby-rails/skills/brakeman/references/reducing_false_positives.md",
          "type": "blob",
          "size": 13896
        },
        {
          "path": "plugins/ruby-rails/skills/brakeman/references/warning_types.md",
          "type": "blob",
          "size": 16087
        },
        {
          "path": "plugins/ruby-rails/skills/brakeman/scripts",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/ruby-rails/skills/brakeman/scripts/brakeman_helper.rb",
          "type": "blob",
          "size": 7819
        },
        {
          "path": "plugins/ruby-rails/skills/cucumber-gherkin",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/ruby-rails/skills/cucumber-gherkin/SKILL.md",
          "type": "blob",
          "size": 7407
        },
        {
          "path": "plugins/ruby-rails/skills/cucumber-gherkin/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/ruby-rails/skills/cucumber-gherkin/references/best-practices.md",
          "type": "blob",
          "size": 11191
        },
        {
          "path": "plugins/ruby-rails/skills/cucumber-gherkin/references/gherkin-syntax.md",
          "type": "blob",
          "size": 8126
        },
        {
          "path": "plugins/ruby-rails/skills/cucumber-gherkin/references/hooks-config.md",
          "type": "blob",
          "size": 12510
        },
        {
          "path": "plugins/ruby-rails/skills/cucumber-gherkin/references/step-definitions.md",
          "type": "blob",
          "size": 12448
        },
        {
          "path": "plugins/ruby-rails/skills/design-patterns-ruby",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/ruby-rails/skills/design-patterns-ruby/SKILL.md",
          "type": "blob",
          "size": 8063
        },
        {
          "path": "plugins/ruby-rails/skills/design-patterns-ruby/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/ruby-rails/skills/design-patterns-ruby/references/behavioral-patterns.md",
          "type": "blob",
          "size": 19360
        },
        {
          "path": "plugins/ruby-rails/skills/design-patterns-ruby/references/creational-patterns.md",
          "type": "blob",
          "size": 8625
        },
        {
          "path": "plugins/ruby-rails/skills/design-patterns-ruby/references/structural-patterns.md",
          "type": "blob",
          "size": 11524
        },
        {
          "path": "plugins/ruby-rails/skills/postgresql-rails-analyzer",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/ruby-rails/skills/postgresql-rails-analyzer/SKILL.md",
          "type": "blob",
          "size": 8828
        },
        {
          "path": "plugins/ruby-rails/skills/postgresql-rails-analyzer/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/ruby-rails/skills/postgresql-rails-analyzer/references/anti_patterns.md",
          "type": "blob",
          "size": 9366
        },
        {
          "path": "plugins/ruby-rails/skills/postgresql-rails-analyzer/references/performance_guide.md",
          "type": "blob",
          "size": 9349
        },
        {
          "path": "plugins/ruby-rails/skills/postgresql-rails-analyzer/scripts",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/ruby-rails/skills/postgresql-rails-analyzer/scripts/analyze_config.py",
          "type": "blob",
          "size": 9085
        },
        {
          "path": "plugins/ruby-rails/skills/postgresql-rails-analyzer/scripts/analyze_indexes.py",
          "type": "blob",
          "size": 8205
        },
        {
          "path": "plugins/ruby-rails/skills/postgresql-rails-analyzer/scripts/analyze_n_plus_one.py",
          "type": "blob",
          "size": 5652
        },
        {
          "path": "plugins/ruby-rails/skills/rails-generators",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/ruby-rails/skills/rails-generators/SKILL.md",
          "type": "blob",
          "size": 20715
        },
        {
          "path": "plugins/ruby-rails/skills/rails-generators/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/ruby-rails/skills/rails-generators/references/file-actions.md",
          "type": "blob",
          "size": 12620
        },
        {
          "path": "plugins/ruby-rails/skills/rails-generators/references/hooks.md",
          "type": "blob",
          "size": 8565
        },
        {
          "path": "plugins/ruby-rails/skills/rails-generators/references/model-generator.md",
          "type": "blob",
          "size": 11307
        },
        {
          "path": "plugins/ruby-rails/skills/rails-generators/references/service-generator.md",
          "type": "blob",
          "size": 16682
        },
        {
          "path": "plugins/ruby-rails/skills/rails-generators/references/testing-rails.md",
          "type": "blob",
          "size": 17398
        },
        {
          "path": "plugins/ruby-rails/skills/rails",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/ruby-rails/skills/rails/SKILL.md",
          "type": "blob",
          "size": 13744
        },
        {
          "path": "plugins/ruby-rails/skills/rails/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/ruby-rails/skills/rails/references/active_record.md",
          "type": "blob",
          "size": 481985
        },
        {
          "path": "plugins/ruby-rails/skills/rails/references/api_development.md",
          "type": "blob",
          "size": 18643
        },
        {
          "path": "plugins/ruby-rails/skills/rails/references/assets_frontend.md",
          "type": "blob",
          "size": 74711
        },
        {
          "path": "plugins/ruby-rails/skills/rails/references/configuration_internals.md",
          "type": "blob",
          "size": 365189
        },
        {
          "path": "plugins/ruby-rails/skills/rails/references/controllers_views.md",
          "type": "blob",
          "size": 219621
        },
        {
          "path": "plugins/ruby-rails/skills/rails/references/i18n_support.md",
          "type": "blob",
          "size": 175934
        },
        {
          "path": "plugins/ruby-rails/skills/rails/references/jobs_mailers_cable.md",
          "type": "blob",
          "size": 112865
        },
        {
          "path": "plugins/ruby-rails/skills/rails/references/routing.md",
          "type": "blob",
          "size": 49209
        },
        {
          "path": "plugins/ruby-rails/skills/rails/references/security_performance.md",
          "type": "blob",
          "size": 118660
        },
        {
          "path": "plugins/ruby-rails/skills/rails/references/storage_caching.md",
          "type": "blob",
          "size": 83242
        },
        {
          "path": "plugins/ruby-rails/skills/rails/references/testing_debugging.md",
          "type": "blob",
          "size": 121227
        },
        {
          "path": "plugins/ruby-rails/skills/review-ruby-code",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/ruby-rails/skills/review-ruby-code/SKILL.md",
          "type": "blob",
          "size": 13127
        },
        {
          "path": "plugins/ruby-rails/skills/review-ruby-code/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/ruby-rails/skills/review-ruby-code/references/rails-patterns.md",
          "type": "blob",
          "size": 15569
        },
        {
          "path": "plugins/ruby-rails/skills/review-ruby-code/references/sandi-metz-rules.md",
          "type": "blob",
          "size": 10318
        },
        {
          "path": "plugins/ruby-rails/skills/review-ruby-code/references/security-checklist.md",
          "type": "blob",
          "size": 15261
        },
        {
          "path": "plugins/ruby-rails/skills/review-ruby-code/references/solid-principles.md",
          "type": "blob",
          "size": 17029
        },
        {
          "path": "plugins/ruby-rails/skills/review-ruby-code/references/vscode-links.md",
          "type": "blob",
          "size": 8689
        },
        {
          "path": "plugins/ruby-rails/skills/rspec",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/ruby-rails/skills/rspec/SKILL.md",
          "type": "blob",
          "size": 17947
        },
        {
          "path": "plugins/ruby-rails/skills/rspec/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/ruby-rails/skills/rspec/references/best_practices.md",
          "type": "blob",
          "size": 13483
        },
        {
          "path": "plugins/ruby-rails/skills/rspec/references/configuration.md",
          "type": "blob",
          "size": 12575
        },
        {
          "path": "plugins/ruby-rails/skills/rspec/references/core_concepts.md",
          "type": "blob",
          "size": 12996
        },
        {
          "path": "plugins/ruby-rails/skills/rspec/references/factory_bot.md",
          "type": "blob",
          "size": 12830
        },
        {
          "path": "plugins/ruby-rails/skills/rspec/references/matchers.md",
          "type": "blob",
          "size": 16770
        },
        {
          "path": "plugins/ruby-rails/skills/rspec/references/mocking.md",
          "type": "blob",
          "size": 16485
        },
        {
          "path": "plugins/ruby-rails/skills/rspec/references/rails_testing.md",
          "type": "blob",
          "size": 12942
        },
        {
          "path": "plugins/ruby-rails/skills/rubocop",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/ruby-rails/skills/rubocop/SKILL.md",
          "type": "blob",
          "size": 6663
        },
        {
          "path": "plugins/ruby-rails/skills/rubocop/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/ruby-rails/skills/rubocop/references/autocorrect_guide.md",
          "type": "blob",
          "size": 6093
        },
        {
          "path": "plugins/ruby-rails/skills/rubocop/references/configuration_guide.md",
          "type": "blob",
          "size": 10617
        },
        {
          "path": "plugins/ruby-rails/skills/rubocop/references/cop_reference.md",
          "type": "blob",
          "size": 12993
        },
        {
          "path": "plugins/ruby-rails/skills/rubocop/references/custom_cops_guide.md",
          "type": "blob",
          "size": 1798
        },
        {
          "path": "plugins/ruby-rails/skills/rubocop/references/extensions_guide.md",
          "type": "blob",
          "size": 2359
        },
        {
          "path": "plugins/ruby-rails/skills/rubocop/scripts",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/ruby-rails/skills/rubocop/scripts/README.md",
          "type": "blob",
          "size": 287
        },
        {
          "path": "plugins/ruby-rails/skills/ruby",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/ruby-rails/skills/ruby/SKILL.md",
          "type": "blob",
          "size": 32433
        },
        {
          "path": "plugins/ruby-rails/skills/ruby/docs",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/ruby-rails/skills/ruby/docs/QUICK_REFERENCE.md",
          "type": "blob",
          "size": 8279
        },
        {
          "path": "plugins/ruby-rails/skills/ruby/examples",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/ruby-rails/skills/ruby/examples/bank_account_example.rb",
          "type": "blob",
          "size": 7249
        },
        {
          "path": "plugins/ruby-rails/skills/rubycritic",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/ruby-rails/skills/rubycritic/SKILL.md",
          "type": "blob",
          "size": 7368
        },
        {
          "path": "plugins/ruby-rails/skills/rubycritic/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/ruby-rails/skills/rubycritic/references/code_smells.md",
          "type": "blob",
          "size": 3996
        },
        {
          "path": "plugins/ruby-rails/skills/rubycritic/references/configuration.md",
          "type": "blob",
          "size": 7242
        },
        {
          "path": "plugins/ruby-rails/skills/rubycritic/references/error-handling.md",
          "type": "blob",
          "size": 12367
        },
        {
          "path": "plugins/ruby-rails/skills/rubycritic/references/git-hooks.md",
          "type": "blob",
          "size": 13281
        },
        {
          "path": "plugins/ruby-rails/skills/rubycritic/scripts",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/ruby-rails/skills/rubycritic/scripts/check_quality.sh",
          "type": "blob",
          "size": 3863
        },
        {
          "path": "plugins/ruby-rails/skills/sandi-metz-reviewer",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/ruby-rails/skills/sandi-metz-reviewer/SKILL.md",
          "type": "blob",
          "size": 7909
        },
        {
          "path": "plugins/ruby-rails/skills/sandi-metz-reviewer/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/ruby-rails/skills/sandi-metz-reviewer/references/principles_examples.md",
          "type": "blob",
          "size": 6998
        },
        {
          "path": "plugins/ruby-rails/skills/sandi-metz-reviewer/scripts",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/ruby-rails/skills/sandi-metz-reviewer/scripts/code_reviewer.rb",
          "type": "blob",
          "size": 17520
        },
        {
          "path": "plugins/ruby-rails/skills/simplecov",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/ruby-rails/skills/simplecov/LICENSE.txt",
          "type": "blob",
          "size": 1085
        },
        {
          "path": "plugins/ruby-rails/skills/simplecov/README.md",
          "type": "blob",
          "size": 5710
        },
        {
          "path": "plugins/ruby-rails/skills/simplecov/SKILL.md",
          "type": "blob",
          "size": 17943
        },
        {
          "path": "plugins/ruby-rails/skills/simplecov/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/ruby-rails/skills/simplecov/references/advanced_patterns.md",
          "type": "blob",
          "size": 13665
        },
        {
          "path": "plugins/ruby-rails/skills/simplecov/references/ci_cd_integration.md",
          "type": "blob",
          "size": 16831
        },
        {
          "path": "plugins/ruby-rails/skills/simplecov/references/rubycritic_integration.md",
          "type": "blob",
          "size": 14800
        },
        {
          "path": "plugins/ruby-rails/skills/simplecov/scripts",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/ruby-rails/skills/simplecov/scripts/collate_coverage.rb",
          "type": "blob",
          "size": 1712
        },
        {
          "path": "plugins/ruby-rails/skills/simplecov/scripts/combined_quality_report.rb",
          "type": "blob",
          "size": 12040
        },
        {
          "path": "plugins/ruby-rails/skills/simplecov/scripts/coverage_analyzer.rb",
          "type": "blob",
          "size": 11018
        },
        {
          "path": "plugins/ruby-rails/skills/simplecov/scripts/coverage_summary.rb",
          "type": "blob",
          "size": 1797
        },
        {
          "path": "plugins/ruby-rails/skills/simplecov/scripts/diagnose_coverage.rb",
          "type": "blob",
          "size": 3396
        },
        {
          "path": "plugins/ruby-rails/skills/simplecov/scripts/track_quality_history.rb",
          "type": "blob",
          "size": 3785
        },
        {
          "path": "tools",
          "type": "tree",
          "size": null
        },
        {
          "path": "tools/analyze_coverage.rb",
          "type": "blob",
          "size": 2612
        }
      ],
      "marketplace": {
        "name": "jebs-dev-tools",
        "version": null,
        "description": null,
        "owner_info": {
          "name": "Jeb Coleman"
        },
        "keywords": [],
        "plugins": [
          {
            "name": "ruby-rails",
            "description": "Ruby on Rails development toolkit with skills for Rails, Ruby, RSpec, RuboCop, SimpleCov, Brakeman, and code review with Sandi Metz principles",
            "source": "./plugins/ruby-rails",
            "category": null,
            "version": "0.1.0",
            "author": {
              "name": "Jeb Coleman"
            },
            "install_commands": [
              "/plugin marketplace add el-feo/ai-context",
              "/plugin install ruby-rails@jebs-dev-tools"
            ],
            "signals": {
              "stars": 0,
              "forks": 0,
              "pushed_at": "2026-01-12T05:23:19Z",
              "created_at": "2025-03-11T20:00:10Z",
              "license": "MIT"
            },
            "commands": [
              {
                "name": "/rails-generators",
                "description": "Create expert-level Ruby on Rails generators for models, services, controllers, and full-stack features",
                "path": "plugins/ruby-rails/commands/rails-generators.md",
                "frontmatter": {
                  "description": "Create expert-level Ruby on Rails generators for models, services, controllers, and full-stack features",
                  "argument-hint": [
                    "generator type or task description"
                  ],
                  "allowed-tools": "Skill(rails-generators)"
                },
                "content": "<objective>\nDelegate Rails generator creation tasks to the rails-generators skill for: $ARGUMENTS\n\nThis routes to specialized skill containing generator patterns, Thor DSL, testing strategies, and best practices for Rails code generation.\n</objective>\n\n<process>\n1. Use Skill tool to invoke rails-generators skill\n2. Pass user's request: $ARGUMENTS\n3. Let skill handle generator creation, testing, and implementation\n</process>\n\n<success_criteria>\n- Skill successfully invoked\n- Arguments passed correctly to skill\n- User receives comprehensive Rails generator guidance with working examples\n</success_criteria>"
              },
              {
                "name": "/red-green-refactor",
                "description": "Start a TDD session using the red-green-refactor cycle",
                "path": "plugins/ruby-rails/commands/red-green-refactor.md",
                "frontmatter": {
                  "description": "Start a TDD session using the red-green-refactor cycle",
                  "allowed-tools": [
                    "Read",
                    "Edit",
                    "Write",
                    "Skill(ruby)",
                    "Skill(javascript)",
                    "Skill(rubycritic)",
                    "Skill(simplecov)",
                    "Skill(rubocop)"
                  ]
                },
                "content": "<objective>\nDuring this session we will be practicing TDD in the red-green-refactor cycle.\n</objective>\n\n<process>\n1. **Red Phase**: Write a test for the smallest possible unit of functionality. Run the test and it should fail.\n2. **Green Phase**: Write the code to make the test pass.\n3. **Refactor Phase**: Once the test passes, refactor the code to be more readable and maintainable.\n</process>\n\n<rules>\n- If more than one test fails, focus on the most important test to fix first\n- During a fix phase, only run the failing test until it passes\n- Do NOT use the TODO tool to track tasks during this session\n- Rely on the human user to tell you what the next step is\n</rules>\n\n<success_criteria>\nEach cycle completes when:\n\n- A single failing test exists (red)\n- Minimal code is written to pass that test (green)\n- Code is cleaned up without changing behavior (refactor)\n</success_criteria>"
              },
              {
                "name": "/review-ruby-code",
                "description": "Review Ruby/Rails code with Sandi Metz rules and SOLID principles",
                "path": "plugins/ruby-rails/commands/review-ruby-code.md",
                "frontmatter": {
                  "description": "Review Ruby/Rails code with Sandi Metz rules and SOLID principles",
                  "argument-hint": [
                    {
                      "optional": "specific files or all changes"
                    }
                  ],
                  "allowed-tools": "Skill(review-ruby-code)"
                },
                "content": "<objective>\nDelegate Ruby and Rails code review to the review-ruby-code skill for: $ARGUMENTS\n\nThis routes to specialized skill containing OOP design principles, Rails patterns, security checks, and code review best practices. The skill will analyze changed files in the current branch, run rubycritic and simplecov, and generate a comprehensive REVIEW.md with VSCode-compatible links.\n</objective>\n\n<process>\n1. Use Skill tool to invoke review-ruby-code skill\n2. Pass user's request: $ARGUMENTS\n3. Let skill handle workflow:\n   - Detect base branch from git\n   - Identify changed files\n   - Run rubycritic and simplecov\n   - Analyze OOP design, Rails patterns, security, and test coverage\n   - Generate REVIEW.md with clickable links to code\n</process>\n\n<success_criteria>\n- Skill successfully invoked\n- Arguments passed correctly to skill\n- REVIEW.md generated with comprehensive code review\n- All code references have VSCode-compatible links\n</success_criteria>"
              }
            ],
            "skills": [
              {
                "name": "brakeman",
                "description": "Static analysis security vulnerability scanner for Ruby on Rails applications. Use when analyzing Rails code for security issues, running security audits, reviewing code for vulnerabilities, setting up security scanning in CI/CD, managing security warnings, or investigating specific vulnerability types (SQL injection, XSS, command injection, etc.). Also use when configuring Brakeman, reducing false positives, or integrating with automated workflows.",
                "path": "plugins/ruby-rails/skills/brakeman/SKILL.md",
                "frontmatter": {
                  "name": "brakeman",
                  "description": "Static analysis security vulnerability scanner for Ruby on Rails applications. Use when analyzing Rails code for security issues, running security audits, reviewing code for vulnerabilities, setting up security scanning in CI/CD, managing security warnings, or investigating specific vulnerability types (SQL injection, XSS, command injection, etc.). Also use when configuring Brakeman, reducing false positives, or integrating with automated workflows."
                },
                "content": "# Brakeman Security Scanner\n\n## Overview\n\nBrakeman is a static analysis tool that checks Ruby on Rails applications for security vulnerabilities without requiring a running application. It analyzes source code to detect common security issues including SQL injection, cross-site scripting (XSS), command injection, mass assignment, and many other vulnerability types.\n\n## Installation\n\nVerify Brakeman is installed before running scans. If not present, install using one of these methods:\n\n```bash\n# Using RubyGems (recommended)\ngem install brakeman\n\n# Using Bundler (add to Gemfile)\ngroup :development do\n  gem 'brakeman', require: false\nend\n\n# Using Docker\ndocker pull presidentbeef/brakeman\n```\n\nBrakeman requires Ruby 3.0.0+ to run, but can analyze code written with Ruby 2.0+ syntax. It works with Rails 2.3.x through 8.x.\n\n## Basic Usage\n\n### Quick Scan\n\nRun a basic security scan from the Rails application root:\n\n```bash\nbrakeman\n```\n\nFrom outside the Rails root:\n\n```bash\nbrakeman /path/to/rails/application\n```\n\n### Output Formats\n\nGenerate reports in various formats:\n\n```bash\n# HTML report\nbrakeman -o report.html\n\n# JSON report (useful for comparison and automation)\nbrakeman -o report.json\n\n# Multiple output formats simultaneously\nbrakeman -o report.html -o report.json\n\n# Output to console with color and file\nbrakeman --color -o /dev/stdout -o report.json\n\n# Quiet mode (suppress informational messages)\nbrakeman -q\n```\n\nAvailable output formats: `text`, `html`, `tabs`, `json`, `junit`, `markdown`, `csv`, `codeclimate`, `sonar`\n\n## Workflow Decision Tree\n\n```\nIs Brakeman already installed?\n├─ No → Install using gem, bundler, or docker\n└─ Yes → Continue\n\nWhat is the goal?\n├─ Initial security assessment → Run basic scan: `brakeman`\n├─ Generate report for review → Choose format: `brakeman -o report.html`\n├─ CI/CD integration → Use JSON output: `brakeman -o report.json`\n├─ Too many warnings → Adjust confidence level or filter checks\n├─ False positives → Use interactive ignore tool: `brakeman -I`\n├─ Compare with previous scan → Use --compare flag\n└─ Configuration needed → Create config/brakeman.yml\n```\n\n## Confidence Levels\n\nBrakeman assigns confidence levels to each warning:\n\n- **High**: Simple warning or user input very likely being used unsafely\n- **Medium**: Unsafe use of variable that may or may not be user input\n- **Weak**: User input indirectly used in potentially unsafe manner\n\nFilter warnings by confidence level:\n\n```bash\n# Only high confidence warnings\nbrakeman -w3\n\n# High and medium confidence warnings\nbrakeman -w2\n\n# All warnings (default)\nbrakeman -w1\n```\n\n## Managing Warnings\n\n### Filtering Checks\n\nRun only specific checks:\n\n```bash\n# Run only SQL and XSS checks\nbrakeman -t SQL,CrossSiteScripting\n\n# Skip specific checks\nbrakeman -x DefaultRoutes,Redirect\n\n# Skip multiple checks\nbrakeman -x DefaultRoutes,Redirect,SQL\n```\n\nUse `brakeman --checks` to list all available check names (case-sensitive).\n\n### Interactive Ignore Configuration\n\nManage false positives interactively:\n\n```bash\nbrakeman -I\n```\n\nThis launches an interactive tool that:\n1. Presents each warning with context\n2. Allows you to ignore, skip, or add notes\n3. Saves configuration to `config/brakeman.ignore`\n\nOptions during interactive review:\n- `i` - Add warning to ignore list\n- `n` - Add warning to ignore list with note (recommended)\n- `s` - Skip this warning\n- `u` - Remove from ignore list\n- `a` - Ignore remaining warnings\n- `k` - Skip remaining warnings\n- `q` - Quit without saving\n\nAlways add notes when ignoring warnings to document why they're false positives.\n\n### Show Ignored Warnings\n\nTemporarily view ignored warnings without affecting exit code:\n\n```bash\nbrakeman --show-ignored\n```\n\n## Comparing Scans\n\nTrack security improvements or regressions by comparing scans:\n\n```bash\n# Generate baseline report\nbrakeman -o baseline.json\n\n# Run new scan and compare\nbrakeman --compare baseline.json\n```\n\nOutput shows:\n- Fixed warnings (resolved since baseline)\n- New warnings (introduced since baseline)\n\n## Configuration\n\n### Configuration Files\n\nStore Brakeman options in YAML configuration files. Default locations (checked in order):\n1. `./config/brakeman.yml`\n2. `~/.brakeman/config.yml`\n3. `/etc/brakeman/config.yml`\n\nSpecify a custom configuration file:\n\n```bash\nbrakeman -c custom_config.yml\n```\n\n### Generate Configuration\n\nOutput current options to create a configuration file:\n\n```bash\nbrakeman -C --skip-files plugins/ > config/brakeman.yml\n```\n\nCommand-line options override configuration file settings.\n\n### Example Configuration\n\n```yaml\n---\n:skip_files:\n  - vendor/\n  - lib/legacy/\n:confidence_level: 2\n:output_files:\n  - reports/brakeman.html\n  - reports/brakeman.json\n:quiet: true\n```\n\n## Performance Optimization\n\nSpeed up scans with faster mode (skips some features):\n\n```bash\nbrakeman --faster\n```\n\nEquivalent to: `--skip-libs --no-branching`\n\n**Warning**: May miss some vulnerabilities. Use only when scan speed is critical.\n\nSkip problematic files or directories:\n\n```bash\nbrakeman --skip-files file1.rb,vendor/,legacy/\n```\n\n## Advanced Options\n\n### Safe Methods\n\nMark custom sanitizing methods as safe to reduce false positives:\n\n```bash\nbrakeman --safe-methods sanitize_input,clean_html\n```\n\n### Exit Codes\n\nControl exit code behavior:\n\n```bash\n# Don't exit with error on warnings\nbrakeman --no-exit-on-warn\n\n# Don't exit with error on scanning errors\nbrakeman --no-exit-on-error\n\n# Both\nbrakeman --no-exit-on-warn --no-exit-on-error\n```\n\nDefault behavior: Non-zero exit code if warnings found or errors encountered.\n\n### Debugging\n\nEnable verbose debugging output:\n\n```bash\nbrakeman -d\n```\n\n## CI/CD Integration\n\n### GitHub Actions\n\nSeveral Brakeman actions available on GitHub Marketplace. Search for \"brakeman\" in GitHub Actions.\n\n### Jenkins\n\nBrakeman plugin available for Jenkins/Hudson integration. See documentation at brakemanscanner.org/docs/jenkins/\n\n### Guard\n\nFor continuous testing during development:\n\n```bash\ngem install guard-brakeman\n```\n\n### Generic CI Integration\n\n```bash\n#!/bin/bash\n# Example CI script\n\n# Run Brakeman and save results\nbrakeman -o brakeman-report.json -o brakeman-report.html --no-exit-on-warn\n\n# Check if there are any high confidence warnings\nif brakeman -w3 --quiet; then\n  echo \"No high confidence security warnings found\"\n  exit 0\nelse\n  echo \"High confidence security warnings detected!\"\n  exit 1\nfi\n```\n\n## Warning Types Reference\n\nBrakeman detects 30+ vulnerability types. For detailed descriptions and remediation guidance, see `references/warning_types.md`.\n\nCommon warning types include:\n- SQL Injection\n- Cross-Site Scripting (XSS)\n- Command Injection\n- Mass Assignment\n- Cross-Site Request Forgery (CSRF)\n- Remote Code Execution\n- Path Traversal\n- Unsafe Redirects\n- File Access\n- Authentication Issues\n- SSL Verification Bypass\n- Unmaintained Dependencies\n- And many more...\n\n## Command Reference\n\nFor comprehensive option reference including less common flags and detailed explanations, see `references/command_options.md`.\n\n## Best Practices\n\n1. **Run regularly**: Integrate into development workflow and CI/CD pipeline\n2. **Start with high confidence**: Use `-w3` initially to focus on critical issues\n3. **Document ignored warnings**: Always add notes explaining why warnings are ignored\n4. **Compare scans**: Use `--compare` to track security posture over time\n5. **Review all warnings**: Even weak warnings can indicate real vulnerabilities\n6. **Keep Brakeman updated**: Security checks improve with each release\n7. **Don't ignore blindly**: Investigate each warning before marking as false positive\n8. **Use configuration files**: Maintain consistent scan settings across team\n9. **Generate multiple formats**: HTML for review, JSON for automation\n10. **Test ignored warnings periodically**: Re-review with `--show-ignored`\n\n## Common Workflows\n\n### Initial Security Audit\n\n```bash\n# 1. Run comprehensive scan\nbrakeman -o initial-audit.html -o initial-audit.json\n\n# 2. Review high confidence warnings first\nbrakeman -w3 -o high-confidence.html\n\n# 3. Interactively manage false positives\nbrakeman -I\n\n# 4. Save configuration for future scans\nbrakeman -C > config/brakeman.yml\n```\n\n### CI/CD Security Gate\n\n```bash\n# Fail build only on high confidence warnings\nbrakeman -w3 --no-exit-on-error\n```\n\n### Tracking Improvements\n\n```bash\n# Baseline scan\nbrakeman -o baseline.json\n\n# After fixes, compare\nbrakeman --compare baseline.json -o improvements.json\n```\n\n### Reducing Noise\n\n```bash\n# Focus on specific vulnerability types\nbrakeman -t SQL,CrossSiteScripting,CommandInjection -w2\n\n# Or exclude noisy checks\nbrakeman -x DefaultRoutes,Redirect -w2\n```\n\n## Troubleshooting\n\n**Problem**: Too many weak confidence warnings\n**Solution**: Use `-w2` or `-w3` to filter by confidence level\n\n**Problem**: Scanning is very slow\n**Solution**: Use `--faster` flag or `--skip-files` to exclude large directories\n\n**Problem**: False positives for custom sanitization\n**Solution**: Use `--safe-methods` to mark methods as safe\n\n**Problem**: Warnings about database values\n**Solution**: Consider if database values truly safe; if yes, adjust with `--interprocedural` or configuration\n\n**Problem**: Can't parse certain files\n**Solution**: Use `--skip-files` to exclude problematic files\n\n## Resources\n\n### references/warning_types.md\nComprehensive descriptions of all 30+ vulnerability types Brakeman can detect, including examples and remediation guidance.\n\n### references/command_options.md\nComplete command-line reference with detailed explanations of all available options and flags.\n\n### references/reducing_false_positives.md\nStrategies and techniques for minimizing false positives while maintaining security coverage."
              },
              {
                "name": "cucumber-gherkin",
                "description": "Comprehensive BDD testing with Cucumber and Gherkin syntax. Use when writing feature files (.feature), step definitions, hooks, or implementing Behaviour-Driven Development. Covers Gherkin keywords (Feature, Scenario, Given/When/Then, Background, Scenario Outline, Rule), step definition patterns for Ruby/JavaScript/Java/Python, hooks (Before/After/BeforeAll/AfterAll), tags, data tables, doc strings, and best practices. Triggers on cucumber, gherkin, BDD, feature files, step definitions, acceptance testing, executable specifications.",
                "path": "plugins/ruby-rails/skills/cucumber-gherkin/SKILL.md",
                "frontmatter": {
                  "name": "cucumber-gherkin",
                  "description": "Comprehensive BDD testing with Cucumber and Gherkin syntax. Use when writing feature files (.feature), step definitions, hooks, or implementing Behaviour-Driven Development. Covers Gherkin keywords (Feature, Scenario, Given/When/Then, Background, Scenario Outline, Rule), step definition patterns for Ruby/JavaScript/Java/Python, hooks (Before/After/BeforeAll/AfterAll), tags, data tables, doc strings, and best practices. Triggers on cucumber, gherkin, BDD, feature files, step definitions, acceptance testing, executable specifications."
                },
                "content": "# Cucumber & Gherkin Skill\n\nBDD testing framework with plain-text executable specifications. Gherkin syntax with step definitions in Ruby, JavaScript, Java, or Python.\n\n## Core Concepts\n\n**Cucumber** reads executable specifications in plain text and validates software behavior. **Gherkin** is the structured grammar making plain text machine-readable.\n\n```\n┌────────────┐                 ┌──────────────┐                 ┌───────────┐\n│   Steps    │                 │     Step     │                 │           │\n│ in Gherkin ├──matched with──>│ Definitions  ├───manipulates──>│  System   │\n└────────────┘                 └──────────────┘                 └───────────┘\n```\n\n## Gherkin Syntax Quick Reference\n\n### Primary Keywords\n\n```gherkin\nFeature: Short description\n  Optional multi-line description explaining the feature.\n  \n  Background:\n    Given common setup steps for all scenarios\n  \n  Rule: Business rule grouping (Gherkin 6+)\n    \n    Scenario: Concrete example illustrating the rule\n      Given an initial context (past tense, setup)\n      When an action occurs (present tense, trigger)\n      Then expected outcome (assertion)\n      And additional step\n      But negative assertion\n    \n    Scenario Outline: Parameterized scenario\n      Given there are <start> items\n      When I remove <remove> items\n      Then I should have <remaining> items\n      \n      Examples:\n        | start | remove | remaining |\n        |    12 |      5 |         7 |\n        |    20 |      5 |        15 |\n```\n\n### Step Keywords\n\n| Keyword | Purpose | Example |\n|---------|---------|---------|\n| `Given` | Setup/precondition | `Given I am logged in as \"admin\"` |\n| `When` | Action/trigger | `When I click the submit button` |\n| `Then` | Assertion/outcome | `Then I should see \"Success\"` |\n| `And` | Continue previous type | `And I have 3 items in my cart` |\n| `But` | Negative continuation | `But I should not see \"Error\"` |\n| `*` | Bullet-style step | `* I have eggs` |\n\n### Data Structures\n\n**Data Tables** - tabular data:\n```gherkin\nGiven the following users exist:\n  | name   | email              | role  |\n  | Alice  | alice@example.com  | admin |\n  | Bob    | bob@example.com    | user  |\n```\n\n**Doc Strings** - multi-line text:\n```gherkin\nGiven a blog post with content:\n  \"\"\"markdown\n  # My Post Title\n  \n  This is the content of my blog post.\n  \"\"\"\n```\n\n### Tags\n\n```gherkin\n@smoke @critical\nFeature: User authentication\n\n  @wip\n  Scenario: Login with valid credentials\n    ...\n  \n  @slow @database\n  Scenario: Bulk user import\n    ...\n```\n\nTag expressions: `@smoke and not @slow`, `@gui or @api`, `(@smoke or @critical) and not @wip`\n\n## Step Definitions\n\nMatch Gherkin steps to code. Use Cucumber Expressions (preferred) or Regular Expressions.\n\n### Ruby\n\n```ruby\nGiven('I have {int} cucumbers in my belly') do |count|\n  @belly = Belly.new\n  @belly.eat(count)\nend\n\nWhen('I wait {int} hour(s)') do |hours|\n  @belly.wait(hours)\nend\n\nThen('my belly should growl') do\n  expect(@belly.growling?).to be true\nend\n\n# With data table\nGiven('the following users exist:') do |table|\n  table.hashes.each do |row|\n    User.create!(row)\n  end\nend\n```\n\n### JavaScript\n\n```javascript\nconst { Given, When, Then } = require('@cucumber/cucumber');\n\nGiven('I have {int} cucumbers in my belly', function(count) {\n  this.belly = new Belly();\n  this.belly.eat(count);\n});\n\nWhen('I wait {int} hour(s)', async function(hours) {\n  await this.belly.wait(hours);\n});\n\nThen('my belly should growl', function() {\n  expect(this.belly.isGrowling()).toBe(true);\n});\n\n// With data table\nGiven('the following users exist:', async function(dataTable) {\n  for (const row of dataTable.hashes()) {\n    await User.create(row);\n  }\n});\n```\n\n### Java\n\n```java\npublic class StepDefinitions {\n    @Given(\"I have {int} cucumbers in my belly\")\n    public void iHaveCucumbersInMyBelly(int count) {\n        belly = new Belly();\n        belly.eat(count);\n    }\n    \n    @When(\"I wait {int} hour(s)\")\n    public void iWaitHours(int hours) {\n        belly.wait(hours);\n    }\n    \n    @Then(\"my belly should growl\")\n    public void myBellyShouldGrowl() {\n        assertTrue(belly.isGrowling());\n    }\n}\n```\n\n## Cucumber Expressions\n\nBuilt-in parameter types: `{int}`, `{float}`, `{word}`, `{string}`, `{}` (anonymous)\n\nOptional text: `cucumber(s)` matches \"cucumber\" or \"cucumbers\"\nAlternative text: `color/colour` matches \"color\" or \"colour\"\n\n## Hooks\n\n### Scenario Hooks\n\n```ruby\n# Ruby\nBefore do |scenario|\n  # runs before each scenario\nend\n\nAfter do |scenario|\n  # runs after each scenario\n  screenshot if scenario.failed?\nend\n```\n\n```javascript\n// JavaScript\nconst { Before, After } = require('@cucumber/cucumber');\n\nBefore(async function(scenario) {\n  // runs before each scenario\n});\n\nAfter(async function(scenario) {\n  // runs after each scenario\n  if (scenario.result.status === 'FAILED') {\n    await this.screenshot();\n  }\n});\n```\n\n### Conditional Hooks (with tags)\n\n```ruby\nBefore('@database') do\n  DatabaseCleaner.start\nend\n\nAfter('@database') do\n  DatabaseCleaner.clean\nend\n```\n\n```javascript\nBefore({ tags: '@browser and not @headless' }, async function() {\n  this.browser = await launchBrowser();\n});\n```\n\n### Global Hooks\n\n```ruby\nBeforeAll do\n  # once before any scenario\nend\n\nAfterAll do\n  # once after all scenarios\nend\n```\n\n## Best Practices\n\n### Declarative over Imperative\n\n**Good (declarative):**\n```gherkin\nWhen \"Bob\" logs in\nThen he sees his dashboard\n```\n\n**Avoid (imperative):**\n```gherkin\nWhen I visit \"/login\"\nAnd I enter \"bob\" in \"username\"\nAnd I enter \"secret\" in \"password\"\nAnd I click \"Login\"\nThen I should see \"Dashboard\"\n```\n\n### Focus on Behavior, Not Implementation\n\n- Describe *what* the system does, not *how*\n- Use domain language stakeholders understand\n- Keep scenarios short (3-5 steps recommended)\n- One behavior per scenario\n\n### Background Usage\n\n- Keep backgrounds short (≤4 lines)\n- Use only for essential shared context\n- Move implementation details to step definitions\n\n## Running Cucumber\n\n```bash\n# Ruby\nbundle exec cucumber\ncucumber --tags \"@smoke and not @wip\"\ncucumber features/login.feature:10  # specific line\n\n# JavaScript\nnpx cucumber-js\nnpx cucumber-js --tags \"@smoke\"\n\n# Java (with Maven)\nmvn test -Dcucumber.filter.tags=\"@smoke\"\n```\n\n## Additional References\n\nFor comprehensive details, see reference files:\n\n- `references/gherkin-syntax.md` - Complete Gherkin language reference\n- `references/step-definitions.md` - Step definition patterns by language\n- `references/hooks-config.md` - Hooks, configuration, and runners\n- `references/best-practices.md` - Anti-patterns and advanced patterns"
              },
              {
                "name": "design-patterns-ruby",
                "description": "Comprehensive Ruby implementations of Gang of Four (GoF) design patterns. Use when implementing object-oriented design solutions, refactoring to reduce coupling, solving architecture problems, or when user mentions specific patterns (Factory, Singleton, Observer, Strategy, etc.) in Ruby context.",
                "path": "plugins/ruby-rails/skills/design-patterns-ruby/SKILL.md",
                "frontmatter": {
                  "name": "design-patterns-ruby",
                  "description": "Comprehensive Ruby implementations of Gang of Four (GoF) design patterns. Use when implementing object-oriented design solutions, refactoring to reduce coupling, solving architecture problems, or when user mentions specific patterns (Factory, Singleton, Observer, Strategy, etc.) in Ruby context."
                },
                "content": "<objective>\nProvide Ruby implementations and guidance for all 23 GoF design patterns. Help agents identify which pattern solves a given problem and implement it idiomatically in Ruby.\n</objective>\n\n<quick_start>\n<pattern_selection>\n**Object Creation Problems** → Creational Patterns\n\n- Decouple creation from usage → Factory Method\n- Families of related objects → Abstract Factory\n- Complex objects with many params → Builder\n- Clone without concrete class dependency → Prototype\n- Single shared instance → Singleton\n\n**Structural Problems** → Structural Patterns\n\n- Incompatible interfaces → Adapter\n- Multiple independent dimensions → Bridge\n- Tree structures treated uniformly → Composite\n- Add behavior dynamically → Decorator\n- Simplify complex subsystems → Facade\n- Memory with many similar objects → Flyweight\n- Access control/logging/caching → Proxy\n\n**Behavioral Problems** → Behavioral Patterns\n\n- Multiple handlers in sequence → Chain of Responsibility\n- Decouple UI from business logic → Command\n- Traverse without exposing internals → Iterator\n- Reduce chaotic dependencies → Mediator\n- Undo/restore functionality → Memento\n- Notify about state changes → Observer\n- Behavior varies by state → State\n- Switch algorithms at runtime → Strategy\n- Algorithm skeleton with custom steps → Template Method\n- Operations on complex structures → Visitor\n</pattern_selection>\n\n<ruby_abstract_method>\nRuby doesn't have built-in abstract methods. Use:\n\n```ruby\ndef abstract_method\n  raise NotImplementedError, \"#{self.class} has not implemented method '#{__method__}'\"\nend\n```\n\n</ruby_abstract_method>\n</quick_start>\n\n<when_to_use>\nUse this skill when encountering:\n\n- \"How do I create objects without specifying exact classes?\" → Factory Method/Abstract Factory\n- \"Constructor has too many parameters\" → Builder\n- \"Need to copy objects without knowing their concrete type\" → Prototype\n- \"Ensure only one instance exists\" → Singleton\n- \"Legacy class interface doesn't match what I need\" → Adapter\n- \"Class explosion from combining multiple features\" → Bridge\n- \"Work with tree/hierarchy uniformly\" → Composite\n- \"Add features without modifying class\" → Decorator\n- \"Simplify interaction with complex library\" → Facade\n- \"Too many similar objects consuming memory\" → Flyweight\n- \"Control access/add logging to object\" → Proxy\n- \"Request goes through chain of handlers\" → Chain of Responsibility\n- \"Need undo/redo or queue operations\" → Command\n- \"Custom iteration over collection\" → Iterator\n- \"Components too tightly coupled\" → Mediator\n- \"Save and restore object state\" → Memento\n- \"Notify multiple objects of changes\" → Observer\n- \"Object behavior depends on state\" → State\n- \"Swap algorithms at runtime\" → Strategy\n- \"Subclasses customize algorithm steps\" → Template Method\n- \"Add operations to class hierarchy\" → Visitor\n</when_to_use>\n\n<pattern_quick_reference>\n<creational>\n**Factory Method** - Define interface for creation, let subclasses decide type\n\n```ruby\nclass Creator\n  def factory_method\n    raise NotImplementedError\n  end\n\n  def operation\n    product = factory_method\n    \"Working with #{product.operation}\"\n  end\nend\n\nclass ConcreteCreator < Creator\n  def factory_method\n    ConcreteProduct.new\n  end\nend\n```\n\nFile: `Ruby/src/factory_method/conceptual/main.rb`\n\n**Singleton** (thread-safe)\n\n```ruby\nclass Singleton\n  @instance_mutex = Mutex.new\n  private_class_method :new\n\n  def self.instance\n    return @instance if @instance\n    @instance_mutex.synchronize { @instance ||= new }\n    @instance\n  end\nend\n```\n\nFile: `Ruby/src/singleton/conceptual/thread_safe/main.rb`\n\nSee [references/creational-patterns.md](references/creational-patterns.md) for Abstract Factory, Builder, Prototype.\n</creational>\n\n<structural>\n**Decorator** - Wrap objects to add behavior dynamically\n```ruby\nclass Decorator < Component\n  def initialize(component)\n    @component = component\n  end\n\n  def operation\n    @component.operation\n  end\nend\n\nclass ConcreteDecorator < Decorator\n  def operation\n    \"Decorated(#{@component.operation})\"\n  end\nend\n\n# Stack decorators\n\ndecorated = DecoratorB.new(DecoratorA.new(ConcreteComponent.new))\n\n```\nFile: `Ruby/src/decorator/conceptual/main.rb`\n\n**Adapter** - Convert interface to expected format\n```ruby\nclass Adapter < Target\n  def initialize(adaptee)\n    @adaptee = adaptee\n  end\n\n  def request\n    \"Adapted: #{@adaptee.specific_request}\"\n  end\nend\n```\n\nFile: `Ruby/src/adapter/conceptual/main.rb`\n\nSee [references/structural-patterns.md](references/structural-patterns.md) for Bridge, Composite, Facade, Flyweight, Proxy.\n</structural>\n\n<behavioral>\n**Strategy** - Swap algorithms at runtime\n```ruby\nclass Context\n  attr_writer :strategy\n\n  def initialize(strategy)\n    @strategy = strategy\n  end\n\n  def execute\n    @strategy.do_algorithm(data)\n  end\nend\n\n# Switch strategy at runtime\n\ncontext = Context.new(StrategyA.new)\ncontext.strategy = StrategyB.new\n\n```\nFile: `Ruby/src/strategy/conceptual/main.rb`\n\n**Observer** - Notify subscribers of state changes\n```ruby\nclass Subject\n  def initialize\n    @observers = []\n  end\n\n  def attach(observer)\n    @observers << observer\n  end\n\n  def detach(observer)\n    @observers.delete(observer)\n  end\n\n  def notify\n    @observers.each { |observer| observer.update(self) }\n  end\nend\n```\n\nFile: `Ruby/src/observer/conceptual/main.rb`\n\n**State** - Object behavior changes based on internal state\n\n```ruby\nclass Context\n  attr_accessor :state\n\n  def transition_to(state)\n    @state = state\n    @state.context = self\n  end\n\n  def request\n    @state.handle\n  end\nend\n```\n\nFile: `Ruby/src/state/conceptual/main.rb`\n\nSee [references/behavioral-patterns.md](references/behavioral-patterns.md) for Chain of Responsibility, Command, Iterator, Mediator, Memento, Template Method, Visitor.\n</behavioral>\n</pattern_quick_reference>\n\n<ruby_idioms>\n<deep_copy>\nFor Prototype pattern, use Marshal for deep copying:\n\n```ruby\nMarshal.load(Marshal.dump(object))\n```\n\n</deep_copy>\n\n<thread_safety>\nFor Singleton and shared resources, use Mutex:\n\n```ruby\n@mutex = Mutex.new\n@mutex.synchronize { @instance ||= new }\n```\n\n</thread_safety>\n\n<private_constructor>\nFor Singleton pattern:\n\n```ruby\nprivate_class_method :new\n```\n\n</private_constructor>\n\n<accessors>\n- `attr_reader :name` - read-only\n- `attr_writer :name` - write-only\n- `attr_accessor :name` - read/write\n</accessors>\n\n<type_docs>\nUse YARD-style documentation:\n\n```ruby\n# @param [String] value\n# @return [Boolean]\ndef method(value)\nend\n```\n\n</type_docs>\n</ruby_idioms>\n\n<running_examples>\n\n```bash\nruby Ruby/src/<pattern>/conceptual/main.rb\n\n# Examples:\nruby Ruby/src/singleton/conceptual/thread_safe/main.rb\nruby Ruby/src/observer/conceptual/main.rb\nruby Ruby/src/strategy/conceptual/main.rb\nruby Ruby/src/decorator/conceptual/main.rb\n```\n\nRequires Ruby 3.2+.\n</running_examples>\n\n<detailed_references>\n\n- [references/creational-patterns.md](references/creational-patterns.md) - Factory Method, Abstract Factory, Builder, Prototype, Singleton\n- [references/structural-patterns.md](references/structural-patterns.md) - Adapter, Bridge, Composite, Decorator, Facade, Flyweight, Proxy\n- [references/behavioral-patterns.md](references/behavioral-patterns.md) - Chain of Responsibility, Command, Iterator, Mediator, Memento, Observer, State, Strategy, Template Method, Visitor\n</detailed_references>\n\n<success_criteria>\n\n- Pattern correctly solves the identified design problem\n- Ruby idioms used appropriately (NotImplementedError, Marshal, Mutex)\n- Code follows Ruby conventions (snake_case, attr_* accessors)\n- Example runs without errors via `ruby Ruby/src/<pattern>/conceptual/main.rb`\n</success_criteria>"
              },
              {
                "name": "postgresql-rails-analyzer",
                "description": "Comprehensive PostgreSQL configuration and usage analysis for Rails applications. Use when Claude Code needs to analyze a Rails codebase for database performance issues, optimization opportunities, or best practice violations. Detects N+1 queries, missing indexes, suboptimal database configurations, anti-patterns, and provides actionable recommendations. Ideal for performance audits, optimization tasks, or when users ask to \"analyze the database\", \"check for N+1 queries\", \"optimize PostgreSQL\", \"review database performance\", or \"suggest database improvements\".",
                "path": "plugins/ruby-rails/skills/postgresql-rails-analyzer/SKILL.md",
                "frontmatter": {
                  "name": "postgresql-rails-analyzer",
                  "description": "Comprehensive PostgreSQL configuration and usage analysis for Rails applications. Use when Claude Code needs to analyze a Rails codebase for database performance issues, optimization opportunities, or best practice violations. Detects N+1 queries, missing indexes, suboptimal database configurations, anti-patterns, and provides actionable recommendations. Ideal for performance audits, optimization tasks, or when users ask to \"analyze the database\", \"check for N+1 queries\", \"optimize PostgreSQL\", \"review database performance\", or \"suggest database improvements\"."
                },
                "content": "# PostgreSQL Rails Analyzer\n\nAnalyze Rails applications for PostgreSQL performance issues and provide actionable optimization recommendations based on \"High Performance PostgreSQL for Rails\" best practices.\n\n## Overview\n\nThis skill performs comprehensive analysis of Rails applications to identify:\n\n- N+1 query problems and missing eager loading\n- Missing or suboptimal indexes\n- Database configuration issues\n- Common anti-patterns\n- Performance optimization opportunities\n\n## Analysis Scripts\n\nRun these scripts from the Rails application root directory to analyze different aspects of the codebase:\n\n### 1. N+1 Query Analysis\n\n```bash\npython3 scripts/analyze_n_plus_one.py\n```\n\nDetects potential N+1 query issues by analyzing:\n\n- Controller actions for queries without eager loading\n- View files for association access patterns\n- Missing `includes`, `preload`, or `eager_load` calls\n\n### 2. Index Analysis\n\n```bash\npython3 scripts/analyze_indexes.py\n```\n\nIdentifies indexing opportunities:\n\n- Foreign keys without indexes (critical)\n- Boolean columns that could benefit from partial indexes\n- Columns frequently used in WHERE clauses\n- Missing composite indexes\n\n### 3. Configuration Analysis\n\n```bash\npython3 scripts/analyze_config.py\n```\n\nReviews database.yml for:\n\n- Connection pool sizing\n- Timeout configurations (statement_timeout, lock_timeout)\n- Prepared statements settings\n- SSL/TLS configuration\n- Connection reaping configuration\n- Recommended PostgreSQL extensions\n\n## Workflow\n\nWhen a user requests PostgreSQL analysis, follow this workflow:\n\n### Step 1: Understand the Request\n\nClarify what the user wants to analyze:\n\n- Full performance audit?\n- Specific issue (slow queries, N+1 problems)?\n- Configuration review?\n- Schema optimization?\n\n### Step 2: Run Appropriate Analysis Scripts\n\nBased on the request, run one or more analysis scripts:\n\n```bash\n# For comprehensive analysis, run all three\npython3 scripts/analyze_n_plus_one.py\npython3 scripts/analyze_indexes.py\npython3 scripts/analyze_config.py\n```\n\n### Step 3: Review Results\n\nExamine the output from each script, which categorizes issues by severity:\n\n- **WARNING**: High-priority issues that likely impact performance\n- **INFO**: Optimization opportunities and best practice recommendations\n\n### Step 4: Provide Recommendations\n\nCreate a prioritized list of actionable recommendations:\n\n1. **Critical Issues** (fix immediately)\n   - Foreign keys without indexes\n   - N+1 queries in hot paths\n   - Missing statement timeouts\n\n2. **Performance Optimizations** (high impact)\n   - Add partial indexes for boolean columns\n   - Implement counter caches\n   - Enable eager loading in specific queries\n\n3. **Best Practices** (lower priority, preventative)\n   - Configuration tuning\n   - Connection pool optimization\n   - Enable monitoring extensions\n\n### Step 5: Generate Migration Code\n\nFor index and schema recommendations, provide ready-to-use migration code:\n\n```ruby\nclass AddPerformanceIndexes < ActiveRecord::Migration[7.0]\n  def change\n    # Add foreign key index\n    add_index :posts, :user_id, algorithm: :concurrently\n\n    # Add partial index for boolean column\n    add_index :users, :active, where: \"active = false\", algorithm: :concurrently\n\n    # Add composite index\n    add_index :orders, [:status, :created_at], algorithm: :concurrently\n  end\nend\n```\n\nNote: Use `algorithm: :concurrently` for production migrations to avoid locking tables.\n\n### Step 6: Reference Additional Documentation\n\nWhen users need deeper understanding, refer them to:\n\n- `references/performance_guide.md` - Comprehensive best practices guide\n- `references/anti_patterns.md` - Common mistakes and solutions\n\nLoad these references when:\n\n- User asks \"how do I fix this?\"\n- User wants to understand why something is a problem\n- User needs examples of solutions\n- User asks about specific patterns (e.g., \"what's a partial index?\")\n\n## Common User Requests\n\n### \"Analyze my Rails app for performance issues\"\n\nRun all three analysis scripts and provide a comprehensive report organized by priority.\n\n### \"Check for N+1 queries\"\n\nRun `analyze_n_plus_one.py` and explain each detected issue with suggested fixes using `includes`, `preload`, or `eager_load`.\n\n### \"Why are my queries slow?\"\n\n1. Run index analysis\n2. Review database configuration\n3. Check for N+1 patterns\n4. Suggest EXPLAIN ANALYZE for specific slow queries\n\n### \"Review my database.yml\"\n\nRun `analyze_config.py` and explain each configuration recommendation with context about why it matters.\n\n### \"Should I add an index?\"\n\nRun index analysis and evaluate:\n\n- Is there a foreign key without an index?\n- Is the column used in WHERE clauses frequently?\n- Would a partial or composite index be more appropriate?\n\n## Key Principles\n\n### Always Explain Why\n\nDon't just list issues - explain:\n\n- Why it's a problem\n- What impact it has on performance\n- How to fix it\n- Trade-offs of the solution\n\n### Provide Context\n\nReference specific chapters from \"High Performance PostgreSQL for Rails\" when relevant:\n\n- Chapter 2: Administration Basics\n- Chapter 5: Optimizing Active Record\n- Chapter 7: Improving Query Performance\n- Chapter 8: Optimized Indexes for Fast Retrieval\n\n### Be Pragmatic\n\nNot every detected issue requires immediate action. Help users prioritize:\n\n- What will have the biggest impact?\n- What's easiest to fix?\n- What can wait?\n\n### Show, Don't Tell\n\nAlways provide concrete examples and migration code, not just abstract recommendations.\n\n## Advanced Analysis\n\nFor deeper analysis beyond the scripts, manually review:\n\n### Schema Design\n\n- Check for appropriate data types (bigint for high-volume PKs, jsonb vs json)\n- Verify constraints are in place (NOT NULL, CHECK, FOREIGN KEY)\n- Identify missing validation constraints\n\n### Query Patterns\n\n- Use `rails c` to run EXPLAIN ANALYZE on slow queries\n- Check for sequential scans on large tables\n- Identify expensive joins\n\n### Model Code\n\n- Look for missing counter caches\n- Check for potential batch operation opportunities\n- Identify queries that could use `find_each` instead of `each`\n\n## Limitations\n\nThese analysis scripts use static analysis and may produce:\n\n- **False positives**: Flagging issues that aren't actually problems in practice\n- **False negatives**: Missing issues that require runtime analysis\n\nAlways recommend:\n\n- Testing fixes in a staging environment\n- Using EXPLAIN ANALYZE to verify query performance\n- Monitoring production impact after changes\n\n## Tools Integration\n\nSuggest complementary tools for ongoing monitoring:\n\n- **PgHero**: PostgreSQL performance dashboard\n- **pg_stat_statements**: Query performance tracking\n- **Bullet gem**: Runtime N+1 query detection\n- **Rails query logging**: Enable in development\n\n## Example Output Format\n\nWhen providing analysis results, use this format:\n\n```text\nPostgreSQL Performance Analysis Report\n=====================================\n\n🔍 Analysis Summary:\n- Scanned X files\n- Found Y issues\n- Z high-priority recommendations\n\n⚠️  CRITICAL ISSUES (fix immediately):\n1. Missing foreign key index on posts.user_id\n   Impact: Slow joins, cascading delete performance\n   Fix: add_index :posts, :user_id, algorithm: :concurrently\n\n2. N+1 query in PostsController#index\n   Impact: 1 + N queries instead of 2 queries\n   Fix: Use .includes(:user) on line 12\n\n💡 OPTIMIZATION OPPORTUNITIES:\n1. Partial index for users.active column\n   Impact: Faster queries for inactive users\n   Fix: add_index :users, :active, where: \"active = false\"\n\n📊 CONFIGURATION RECOMMENDATIONS:\n1. Set statement_timeout to prevent runaway queries\n   Add to database.yml: statement_timeout: 30000\n\n✅ BEST PRACTICES:\n- Enable pg_stat_statements for query monitoring\n- Consider adding counter caches for frequently counted associations\n```\n\n## Tips for Claude Code\n\nWhen using this skill in Claude Code:\n\n1. Always navigate to the Rails root directory first\n2. Run scripts with Python 3 (`python3`, not `python`)\n3. Parse script output carefully - it's formatted for human readability\n4. Provide migration code in addition to recommendations\n5. Ask clarifying questions if the codebase structure is unusual\n6. Offer to create migration files directly if the user requests it"
              },
              {
                "name": "rails-generators",
                "description": "Create expert-level Ruby on Rails generators for models, services, controllers, and full-stack features. Use when building custom generators, scaffolds, or code generation tools for Rails applications, or when the user mentions Rails generators, Thor DSL, or automated code generation.",
                "path": "plugins/ruby-rails/skills/rails-generators/SKILL.md",
                "frontmatter": {
                  "name": "rails-generators",
                  "description": "Create expert-level Ruby on Rails generators for models, services, controllers, and full-stack features. Use when building custom generators, scaffolds, or code generation tools for Rails applications, or when the user mentions Rails generators, Thor DSL, or automated code generation."
                },
                "content": "<objective>\nBuild production-ready Rails generators that automate repetitive coding tasks and enforce architectural patterns. This skill covers creating custom generators for models, service objects, API scaffolds, and complete features with migrations, tests, and documentation.\n</objective>\n\n<quick_start>\n<basic_generator>\nCreate a simple service object generator:\n\n```ruby\n# lib/generators/service/service_generator.rb\nmodule Generators\n  class ServiceGenerator < Rails::Generators::NamedBase\n    source_root File.expand_path('templates', __dir__)\n\n    def create_service_file\n      template 'service.rb.tt', \"app/services/#{file_name}_service.rb\"\n    end\n\n    def create_service_test\n      template 'service_test.rb.tt', \"test/services/#{file_name}_service_test.rb\"\n    end\n  end\nend\n```\n\nTemplate file (templates/service.rb.tt):\n```ruby\nclass <%= class_name %>Service\n  def initialize\n  end\n\n  def call\n    # Implementation goes here\n  end\nend\n```\n\nInvoke with: `rails generate service payment_processor`\n</basic_generator>\n\n<usage_pattern>\n**Generator location**: `lib/generators/[name]/[name]_generator.rb`\n**Template location**: `lib/generators/[name]/templates/`\n**Test location**: `test/generators/[name]_generator_test.rb`\n</usage_pattern>\n</quick_start>\n\n<context>\n<when_to_create>\nCreate custom generators when you need to:\n\n- **Enforce architectural patterns**: Service objects, form objects, presenters, query objects\n- **Reduce boilerplate**: API controllers with standard CRUD, serializers, policy objects\n- **Maintain consistency**: Team conventions for file structure, naming, and organization\n- **Automate complex setup**: Multi-file features with migrations, tests, and documentation\n- **Override Rails defaults**: Customize scaffold behavior for your application's needs\n</when_to_create>\n\n<rails_8_updates>\nRails 8 introduced the authentication generator (`rails generate authentication`) which demonstrates modern generator patterns including:\n- ActionCable integration for real-time features\n- Controller concerns for shared behavior\n- Mailer generation with templates\n- Comprehensive view scaffolding\n\nStudy Rails 8 built-in generators for current best practices.\n</rails_8_updates>\n</context>\n\n<workflow>\n<step_1>\n**Choose base class**:\n\n- `Rails::Generators::Base`: Simple generators without required arguments\n- `Rails::Generators::NamedBase`: Generators requiring a name argument\n\n```ruby\nclass ServiceGenerator < Rails::Generators::NamedBase\n  # Automatically provides: name, class_name, file_name, plural_name\nend\n```\n</step_1>\n\n<step_2>\n**Define source root and options**:\n\n```ruby\nsource_root File.expand_path('templates', __dir__)\n\nclass_option :namespace, type: :string, default: nil, desc: \"Namespace for the service\"\nclass_option :skip_tests, type: :boolean, default: false, desc: \"Skip test files\"\n```\n\nAccess options with: `options[:namespace]`\n</step_2>\n\n<step_3>\n**Add public methods** (executed in definition order):\n\n```ruby\ndef create_service_file\n  template 'service.rb.tt', service_file_path\nend\n\ndef create_test_file\n  return if options[:skip_tests]\n  template 'service_test.rb.tt', test_file_path\nend\n\nprivate\n\ndef service_file_path\n  if options[:namespace]\n    \"app/services/#{options[:namespace]}/#{file_name}_service.rb\"\n  else\n    \"app/services/#{file_name}_service.rb\"\n  end\nend\n```\n</step_3>\n\n<step_4>\n**Create ERB templates** (`.tt` extension):\n\n```erb\n<% if options[:namespace] -%>\nmodule <%= options[:namespace].camelize %>\n  class <%= class_name %>Service\n    def call\n      # Implementation\n    end\n  end\nend\n<% else -%>\nclass <%= class_name %>Service\n  def call\n    # Implementation\n  end\nend\n<% end -%>\n```\n\n**Important**: Use `<%%` to output literal `<%` in generated files.\n</step_4>\n\n<step_5>\n**Test the generator** (see [Testing](#testing) section):\n\n```ruby\nrails generate service payment_processor --namespace=billing\nrails generate service notifier --skip-tests\n```\n</step_5>\n</workflow>\n\n<common_patterns>\n<model_generator>\n**Custom model with associations and scopes**:\n\n```ruby\nclass CustomModelGenerator < Rails::Generators::NamedBase\n  source_root File.expand_path('templates', __dir__)\n\n  class_option :parent, type: :string, desc: \"Parent model for belongs_to\"\n  class_option :scope, type: :array, desc: \"Scopes to generate\"\n\n  def create_migration\n    migration_template 'migration.rb.tt',\n      \"db/migrate/create_#{table_name}.rb\"\n  end\n\n  def create_model_file\n    template 'model.rb.tt', \"app/models/#{file_name}.rb\"\n  end\n\n  def create_test_file\n    template 'model_test.rb.tt', \"test/models/#{file_name}_test.rb\"\n  end\nend\n```\n\nSee [references/model-generator.md](references/model-generator.md) for complete example.\n</model_generator>\n\n<service_object_generator>\n**Service object with result object pattern**:\n\n```ruby\nclass ServiceGenerator < Rails::Generators::NamedBase\n  source_root File.expand_path('templates', __dir__)\n\n  class_option :result_object, type: :boolean, default: true\n\n  def create_service\n    template 'service.rb.tt', \"app/services/#{file_name}_service.rb\"\n  end\n\n  def create_result_object\n    return unless options[:result_object]\n    template 'result.rb.tt', \"app/services/#{file_name}_result.rb\"\n  end\nend\n```\n\nSee [references/service-generator.md](references/service-generator.md) for complete example.\n</service_object_generator>\n\n<api_controller_generator>\n**API controller with serializer**:\n\n```ruby\nclass ApiControllerGenerator < Rails::Generators::NamedBase\n  source_root File.expand_path('templates', __dir__)\n\n  class_option :serializer, type: :string, default: 'active_model_serializers'\n  class_option :actions, type: :array, default: %w[index show create update destroy]\n\n  def create_controller\n    template 'controller.rb.tt',\n      \"app/controllers/api/v1/#{file_name.pluralize}_controller.rb\"\n  end\n\n  def create_serializer\n    template \"serializer_#{options[:serializer]}.rb.tt\",\n      \"app/serializers/#{file_name}_serializer.rb\"\n  end\n\n  def add_routes\n    route \"namespace :api do\\n    namespace :v1 do\\n      resources :#{file_name.pluralize}\\n    end\\n  end\"\n  end\nend\n```\n\nSee [references/api-generator.md](references/api-generator.md) for complete example.\n</api_controller_generator>\n\n<full_stack_scaffold>\n**Complete feature scaffold**:\n\n```ruby\nclass FeatureGenerator < Rails::Generators::NamedBase\n  source_root File.expand_path('templates', __dir__)\n\n  class_option :api, type: :boolean, default: false\n\n  def create_model\n    invoke 'model', [name], migration: true\n  end\n\n  def create_controller\n    if options[:api]\n      invoke 'api_controller', [name]\n    else\n      invoke 'controller', [name], actions: %w[index show new create edit update destroy]\n    end\n  end\n\n  def create_views\n    return if options[:api]\n    %w[index show new edit _form].each do |view|\n      template \"views/#{view}.html.erb.tt\",\n        \"app/views/#{file_name.pluralize}/#{view}.html.erb\"\n    end\n  end\n\n  def create_tests\n    invoke 'test_unit:model', [name]\n    invoke 'test_unit:controller', [name]\n    invoke 'test_unit:system', [name] unless options[:api]\n  end\nend\n```\n\nSee [references/scaffold-generator.md](references/scaffold-generator.md) for complete example.\n</full_stack_scaffold>\n</common_patterns>\n\n<advanced_features>\n<hooks>\n**Generator hooks** enable modular composition and test framework integration:\n\n```ruby\nclass ServiceGenerator < Rails::Generators::NamedBase\n  hook_for :test_framework, as: :service\nend\n```\n\nThis automatically invokes `test_unit:service` or `rspec:service` based on configuration.\n\n**Creating hook responders**:\n\n```ruby\n# lib/generators/rspec/service/service_generator.rb\nmodule Rspec\n  module Generators\n    class ServiceGenerator < Rails::Generators::NamedBase\n      source_root File.expand_path('templates', __dir__)\n\n      def create_service_spec\n        template 'service_spec.rb.tt',\n          \"spec/services/#{file_name}_service_spec.rb\"\n      end\n    end\n  end\nend\n```\n\nSee [references/hooks.md](references/hooks.md) for hook patterns and fallback configuration.\n</hooks>\n\n<generator_composition>\n**Invoke other generators** from your generator:\n\n```ruby\ndef create_dependencies\n  invoke 'model', [name], migration: true\n  invoke 'service', [\"#{name}_processor\"]\n  invoke 'serializer', [name]\nend\n```\n\n**Conditional invocation**:\n\n```ruby\ndef create_optional_files\n  invoke 'mailer', [name] if options[:mailer]\n  invoke 'job', [\"#{name}_job\"] if options[:background_job]\nend\n```\n</generator_composition>\n\n<namespacing>\n**Namespace generators** for organization:\n\n```ruby\n# lib/generators/admin/resource/resource_generator.rb\nmodule Admin\n  module Generators\n    class ResourceGenerator < Rails::Generators::NamedBase\n      source_root File.expand_path('templates', __dir__)\n\n      def create_admin_resource\n        template 'resource.rb.tt',\n          \"app/admin/#{file_name}.rb\"\n      end\n    end\n  end\nend\n```\n\nInvoke with: `rails generate admin:resource User`\n\n**Generator search path**:\n1. `rails/generators/[name]/[name]_generator.rb`\n2. `generators/[name]/[name]_generator.rb`\n3. `rails/generators/[name]_generator.rb`\n4. `generators/[name]_generator.rb`\n\nSee [references/namespacing.md](references/namespacing.md) for fallback patterns.\n</namespacing>\n\n<file_manipulation>\n**Thor::Actions methods** available in generators:\n\n```ruby\n# Create files\ncreate_file 'config/settings.yml', yaml_content\ncopy_file 'template.rb', 'config/template.rb'\ntemplate 'config.rb.tt', 'config/settings.rb'\n\n# Modify existing files\ninsert_into_file 'config/routes.rb', route_content, after: \"Rails.application.routes.draw do\\n\"\ngsub_file 'config/application.rb', /old_value/, 'new_value'\ncomment_lines 'config/environments/production.rb', /config.assets.compile/\n\n# Directory operations\nempty_directory 'app/services'\ndirectory 'templates/views', 'app/views/admin'\n\n# Rails-specific helpers\ninitializer 'service_config.rb', config_content\nlib 'custom_validator.rb', validator_content\nrakefile 'import_tasks.rake', rake_content\nroute \"namespace :api do\\n  resources :users\\n end\"\n```\n\nSee [references/file-actions.md](references/file-actions.md) for complete reference.\n</file_manipulation>\n\n<template_system>\n**ERB template features**:\n\n```erb\n<%# Variables from generator available automatically %>\nclass <%= class_name %>Service\n  <%- if options[:async] -%>\n  include AsyncService\n  <%- end -%>\n\n  def initialize(<%= attributes.map(&:name).join(', ') %>)\n    <%- attributes.each do |attr| -%>\n    @<%= attr.name %> = <%= attr.name %>\n    <%- end -%>\n  end\nend\n```\n\n**Escaping for nested ERB** (template generates another template):\n\n```erb\n<%# This will be evaluated when user uses the generated file %>\n<%%= render partial: 'form', locals: { <%= singular_name %>: @<%= singular_name %> } %>\n```\n\n**Conditional whitespace control** with `-`:\n- `<%-` suppresses leading whitespace\n- `-%>` suppresses trailing whitespace\n\nSee [references/templates.md](references/templates.md) for template patterns.\n</template_system>\n</advanced_features>\n\n<testing>\n<rails_test_framework>\n**Testing with Rails::Generators::Testing::Behavior**:\n\n```ruby\nrequire 'test_helper'\nrequire 'generators/service/service_generator'\n\nclass ServiceGeneratorTest < Rails::Generators::TestCase\n  tests ServiceGenerator\n  destination File.expand_path('../tmp', __dir__)\n  setup :prepare_destination\n\n  test \"generates service file\" do\n    run_generator [\"payment_processor\"]\n\n    assert_file \"app/services/payment_processor_service.rb\" do |content|\n      assert_match(/class PaymentProcessorService/, content)\n      assert_match(/def call/, content)\n    end\n  end\n\n  test \"generates with namespace option\" do\n    run_generator [\"payment\", \"--namespace=billing\"]\n\n    assert_file \"app/services/billing/payment_service.rb\" do |content|\n      assert_match(/module Billing/, content)\n      assert_match(/class PaymentService/, content)\n    end\n  end\n\n  test \"skips tests when flag provided\" do\n    run_generator [\"payment\", \"--skip-tests\"]\n\n    assert_file \"app/services/payment_service.rb\"\n    assert_no_file \"test/services/payment_service_test.rb\"\n  end\nend\n```\n\n**Available assertions**:\n- `assert_file(path) { |content| ... }` - File exists with expected content\n- `assert_no_file(path)` - File does not exist\n- `assert_migration(path)` - Migration file exists\n- `assert_class_method(method, content)` - Class method defined\n- `assert_instance_method(method, content)` - Instance method defined\n\nSee [references/testing-rails.md](references/testing-rails.md) for comprehensive testing patterns.\n</rails_test_framework>\n\n<rspec_testing>\n**Testing with RSpec and generator_spec**:\n\nAdd to Gemfile: `gem 'generator_spec', group: :development`\n\n```ruby\nrequire 'generator_spec'\n\nRSpec.describe ServiceGenerator, type: :generator do\n  destination File.expand_path('../../tmp', __FILE__)\n\n  before do\n    prepare_destination\n  end\n\n  context \"with default options\" do\n    before do\n      run_generator [\"payment_processor\"]\n    end\n\n    it \"creates service file\" do\n      expect(destination_root).to have_structure {\n        directory \"app/services\" do\n          file \"payment_processor_service.rb\" do\n            contains \"class PaymentProcessorService\"\n            contains \"def call\"\n          end\n        end\n      }\n    end\n\n    it \"creates test file\" do\n      expect(destination_root).to have_structure {\n        directory \"test/services\" do\n          file \"payment_processor_service_test.rb\"\n        end\n      }\n    end\n  end\n\n  context \"with namespace option\" do\n    before do\n      run_generator [\"payment\", \"--namespace=billing\"]\n    end\n\n    it \"creates namespaced service\" do\n      assert_file \"app/services/billing/payment_service.rb\" do |content|\n        expect(content).to match(/module Billing/)\n        expect(content).to match(/class PaymentService/)\n      end\n    end\n  end\nend\n```\n\n**Alternative: Test against dummy app**:\n\n```ruby\nRSpec.describe \"ServiceGenerator\" do\n  it \"generates correct service file\" do\n    Dir.chdir(dummy_app_path) do\n      `rails generate service payment_processor`\n\n      service_file = File.read('app/services/payment_processor_service.rb')\n      expect(service_file).to include('class PaymentProcessorService')\n\n      # Cleanup\n      FileUtils.rm_rf('app/services/payment_processor_service.rb')\n    end\n  end\nend\n```\n\nSee [references/testing-rspec.md](references/testing-rspec.md) for RSpec patterns and generator_spec usage.\n</rspec_testing>\n\n<manual_testing>\n**Manual testing workflow**:\n\n1. Generate in test Rails app:\n```bash\ncd test/dummy\nrails generate service payment_processor --namespace=billing\n```\n\n2. Verify generated files:\n```bash\ntree app/services\ncat app/services/billing/payment_processor_service.rb\n```\n\n3. Test destruction (if implemented):\n```bash\nrails destroy service payment_processor --namespace=billing\n```\n\n4. Test edge cases:\n```bash\nrails generate service payment_processor --skip-tests\nrails generate service payment_processor --namespace=very/deep/namespace\n```\n</manual_testing>\n</testing>\n\n<validation>\n<checklist>\nBefore considering a generator complete, verify:\n\n- [ ] Generator inherits from appropriate base class\n- [ ] `source_root` points to templates directory\n- [ ] All options have appropriate types and defaults\n- [ ] Public methods execute in correct order\n- [ ] Templates use correct ERB syntax (`.tt` extension)\n- [ ] File paths handle namespacing correctly\n- [ ] Generator works with and without options\n- [ ] Tests cover default behavior and all options\n- [ ] Generator can be destroyed (if applicable)\n- [ ] Documentation includes usage examples\n- [ ] Edge cases handled (special characters, deep namespacing)\n</checklist>\n\n<common_issues>\n**Missing source_root**: Templates not found\n```ruby\n# Add this to generator class\nsource_root File.expand_path('templates', __dir__)\n```\n\n**Incorrect template syntax**: File generated with wrong ERB tags\n```ruby\n# Use <%% for literal ERB in generated files\n<%%= @user.name %>  # Generates: <%= @user.name %>\n```\n\n**Option not recognized**: Check option definition\n```ruby\nclass_option :namespace, type: :string  # Not :namespace_option\n# Access with: options[:namespace]\n```\n\n**Method order issues**: Methods execute in definition order\n```ruby\n# This runs first\ndef create_model\nend\n\n# This runs second\ndef create_controller\nend\n```\n</common_issues>\n</validation>\n\n<examples>\n<service_with_dependencies>\n**Service generator with dependency injection**:\n\n```ruby\nclass AdvancedServiceGenerator < Rails::Generators::NamedBase\n  source_root File.expand_path('templates', __dir__)\n\n  class_option :dependencies, type: :array, default: []\n  class_option :async, type: :boolean, default: false\n\n  def create_service\n    template 'service.rb.tt', service_path\n  end\n\n  def create_test\n    template 'service_test.rb.tt', test_path\n  end\n\n  private\n\n  def service_path\n    \"app/services/#{file_name}_service.rb\"\n  end\n\n  def test_path\n    \"test/services/#{file_name}_service_test.rb\"\n  end\n\n  def dependency_params\n    options[:dependencies].map { |dep| \"#{dep}:\" }.join(', ')\n  end\nend\n```\n\nTemplate (service.rb.tt):\n```erb\nclass <%= class_name %>Service\n  <%- if options[:async] -%>\n  include ActiveJob::Helpers\n  <%- end -%>\n\n  <%- if options[:dependencies].any? -%>\n  def initialize(<%= dependency_params %>)\n    <%- options[:dependencies].each do |dep| -%>\n    @<%= dep %> = <%= dep %>\n    <%- end -%>\n  end\n  <%- else -%>\n  def initialize\n  end\n  <%- end -%>\n\n  def call\n    # Implementation\n  end\nend\n```\n</service_with_dependencies>\n\n<query_object_generator>\n**Query object generator**:\n\n```ruby\nclass QueryGenerator < Rails::Generators::NamedBase\n  source_root File.expand_path('templates', __dir__)\n\n  class_option :model, type: :string, required: true\n  class_option :scopes, type: :array, default: []\n\n  def create_query\n    template 'query.rb.tt', \"app/queries/#{file_name}_query.rb\"\n  end\n\n  def create_test\n    template 'query_test.rb.tt', \"test/queries/#{file_name}_query_test.rb\"\n  end\nend\n```\n</query_object_generator>\n</examples>\n\n<reference_guides>\n**Detailed references**:\n\n- [Model generator patterns](references/model-generator.md) - Custom models with migrations and associations\n- [Service generator patterns](references/service-generator.md) - Service objects with result objects\n- [API generator patterns](references/api-generator.md) - Controllers, serializers, and routes\n- [Scaffold patterns](references/scaffold-generator.md) - Full-stack feature generation\n- [Hooks and composition](references/hooks.md) - Generator hooks and fallbacks\n- [Namespacing](references/namespacing.md) - Organizing generators with namespaces\n- [File manipulation](references/file-actions.md) - Thor::Actions reference\n- [Template system](references/templates.md) - ERB template patterns\n- [Rails testing](references/testing-rails.md) - Rails::Generators::TestCase patterns\n- [RSpec testing](references/testing-rspec.md) - generator_spec and RSpec patterns\n</reference_guides>\n\n<success_criteria>\nA well-built Rails generator has:\n\n- Clear inheritance from Rails::Generators::Base or NamedBase\n- Properly configured source_root pointing to templates\n- Well-defined class_option declarations with appropriate types\n- Public methods that execute in logical order\n- ERB templates with correct syntax and variable interpolation\n- Comprehensive tests covering default and optional behaviors\n- Error handling for edge cases (missing arguments, invalid options)\n- Documentation with usage examples\n- Consistent naming following Rails conventions\n- Works correctly with generator hooks and composition\n</success_criteria>\n\n**Sources**:\n- [Creating and Customizing Rails Generators & Templates — Ruby on Rails Guides](https://guides.rubyonrails.org/generators.html)\n- [Rails 8 adds built in authentication generator | Saeloun Blog](https://blog.saeloun.com/2025/05/12/rails-8-adds-built-in-authentication-generator/)\n- [Shaping Rails to Your Needs, Customizing Rails Generators using Thor Templates | Saeloun Blog](https://blog.saeloun.com/2023/05/31/customizing-rails-generators-using-thor-templates/)\n- [Generators · rails/thor Wiki · GitHub](https://github.com/rails/thor/wiki/Generators)\n- [GitHub: generator_spec](https://github.com/stevehodgkiss/generator_spec)\n- [A Deep Dive Into RSpec Tests in Ruby on Rails | AppSignal Blog](https://blog.appsignal.com/2024/02/07/a-deep-dive-into-rspec-tests-in-ruby-on-rails.html)"
              },
              {
                "name": "rails",
                "description": "Comprehensive Ruby on Rails v8.1 development guide with detailed documentation for Active Record, controllers, views, routing, testing, jobs, mailers, and more. Use when working on Rails applications, building Rails features, debugging Rails code, writing migrations, setting up associations, configuring Rails apps, or answering questions about Rails best practices and patterns.",
                "path": "plugins/ruby-rails/skills/rails/SKILL.md",
                "frontmatter": {
                  "name": "rails",
                  "description": "Comprehensive Ruby on Rails v8.1 development guide with detailed documentation for Active Record, controllers, views, routing, testing, jobs, mailers, and more. Use when working on Rails applications, building Rails features, debugging Rails code, writing migrations, setting up associations, configuring Rails apps, or answering questions about Rails best practices and patterns."
                },
                "content": "<objective>\nProvide comprehensive guidance for Ruby on Rails development based on the official Rails Guides v8.1.1. Use this skill for all Rails-related development tasks, from basic CRUD operations to advanced features like Action Cable, Active Job, and performance tuning.\n</objective>\n\n<context>\nRails follows the \"Convention over Configuration\" principle. When building Rails applications:\n\n- Follow Rails naming conventions for models, controllers, and routes\n- Use Rails generators for consistency\n- Leverage Rails magic (associations, validations, callbacks) rather than reinventing\n- Write tests using Rails testing conventions\n- Use Rails helpers and built-in functionality before custom code\n</context>\n\n<quick_start>\n<common_commands>\n```bash\n# Database\nrails db:create              # Create database\nrails db:migrate             # Run pending migrations\nrails db:rollback            # Rollback last migration\n\n# Console and server\nrails console                # Start Rails console\nrails server                 # Start development server\nrails test                   # Run all tests\n\n# Generators\nrails generate model NAME    # Generate model\nrails generate controller NAME # Generate controller\nrails generate scaffold NAME # Generate full CRUD\n```\n</common_commands>\n\n<typical_workflow>\n1. Generate model: `rails generate model Article title:string body:text`\n2. Run migration: `rails db:migrate`\n3. Add associations and validations to model\n4. Generate controller: `rails generate controller Articles`\n5. Define routes in `config/routes.rb`\n6. Build views with ERB templates\n7. Write tests and iterate\n</typical_workflow>\n</quick_start>\n\n<reference_guides>\nThis skill includes detailed reference documentation organized by topic. **Always consult the relevant reference file** when working on specific Rails components:\n\n**Active Record** ([references/active_record.md](references/active_record.md))\n\nRead this when working with:\n- Models and database operations (CRUD, queries, scopes)\n- Database migrations and schema changes\n- Model associations (has_many, belongs_to, has_one, has_and_belongs_to_many)\n- Validations and custom validators\n- Callbacks and lifecycle hooks\n- PostgreSQL-specific features\n- Multiple database configurations\n- Composite primary keys\n- Encryption\n\nCommon patterns:\n- Defining associations: Always specify inverse_of for better performance\n- Writing migrations: Use reversible changes when possible\n- Query optimization: Use includes/joins to avoid N+1 queries\n- Validations: Validate at the model level, not just in controllers\n\n**Controllers & Views** ([references/controllers_views.md](references/controllers_views.md))\n\nRead this when working with:\n- Action Controller basics and advanced topics\n- Rendering views, partials, and layouts\n- Strong parameters and params handling\n- Action View helpers and form builders\n- Request/response cycle\n- Filters (before_action, after_action, around_action)\n- Streaming and file downloads\n\nCommon patterns:\n- Use strong parameters to whitelist permitted attributes\n- Keep controllers thin - business logic belongs in models\n- Use partials for reusable view components\n- Leverage view helpers for common formatting tasks\n\n**Routing** ([references/routing.md](references/routing.md))\n\nRead this when working with:\n- Defining routes (resources, match, get, post, etc.)\n- RESTful routing conventions\n- Nested routes and namespaces\n- Route constraints and custom matchers\n- Route helpers and URL generation\n- Routing concerns for DRY routes\n\nCommon patterns:\n- Use `resources` for RESTful routes\n- Nest routes only when truly hierarchical (limit to 1 level deep)\n- Use shallow nesting for cleaner URLs\n- Utilize route concerns for shared routing patterns\n\n**Testing & Debugging** ([references/testing_debugging.md](references/testing_debugging.md))\n\nRead this when working with:\n- Writing unit tests (models, helpers)\n- Controller tests and integration tests\n- System tests with browser automation\n- Fixtures, factories, and test data\n- Testing mailers, jobs, and cables\n- Debugging techniques (byebug, rails console)\n- Rails logger and debugging helpers\n\nCommon patterns:\n- Write tests first (TDD) or immediately after (test-driven design)\n- Use fixtures for simple cases, factories for complex scenarios\n- Test edge cases and error conditions\n- Use system tests for critical user flows\n\n**Jobs, Mailers & Cable** ([references/jobs_mailers_cable.md](references/jobs_mailers_cable.md))\n\nRead this when working with:\n- Active Job for background processing\n- Action Mailer for email sending\n- Action Mailbox for receiving emails\n- Action Cable for WebSocket connections\n- Queue adapters (Sidekiq, Resque, etc.)\n- Email delivery and testing\n\nCommon patterns:\n- Always use Active Job for async work (don't block requests)\n- Test mailers with ActionMailer::TestCase\n- Use Action Cable for real-time features (chat, notifications)\n- Configure proper queue backends for production\n\n**Assets & Frontend** ([references/assets_frontend.md](references/assets_frontend.md))\n\nRead this when working with:\n- Asset pipeline and Sprockets\n- JavaScript bundling (import maps, esbuild, webpack)\n- CSS and preprocessors (Sass, Tailwind)\n- Action Text for rich text editing\n- Frontend frameworks integration\n\nCommon patterns:\n- Use asset helpers (image_tag, javascript_include_tag, etc.)\n- Configure proper asset compilation for production\n- Leverage Rails UJS/Turbo for dynamic interactions\n- Use Action Text for WYSIWYG content\n\n**Storage & Caching** ([references/storage_caching.md](references/storage_caching.md))\n\nRead this when working with:\n- Active Storage for file uploads\n- Attaching files to models\n- Image variants and transformations\n- Caching strategies (page, action, fragment, low-level)\n- Cache stores (Redis, Memcached)\n- Russian Doll caching patterns\n\nCommon patterns:\n- Use Active Storage for all file uploads\n- Generate image variants on-demand\n- Cache expensive computations and queries\n- Use fragment caching for dynamic pages\n\n**Configuration & Internals** ([references/configuration_internals.md](references/configuration_internals.md))\n\nRead this when working with:\n- Rails configuration options\n- Environment-specific settings\n- Initialization process\n- Autoloading and eager loading\n- Threading and concurrency\n- Rack integration\n- Rails engines\n- Command-line tools and generators\n- Custom generators\n\nCommon patterns:\n- Keep environment configs DRY using shared settings\n- Use Rails.application.config for app-wide settings\n- Understand autoloading in development vs eager loading in production\n- Create custom generators for repeated patterns\n\n**Security & Performance** ([references/security_performance.md](references/security_performance.md))\n\nRead this when working with:\n- Security best practices\n- XSS, CSRF, SQL injection prevention\n- Authentication and authorization patterns\n- Performance tuning and optimization\n- Database query optimization\n- Asset optimization\n- Error reporting and monitoring\n\nCommon patterns:\n- Always use strong parameters (never trust user input)\n- Enable CSRF protection (on by default)\n- Use prepared statements to prevent SQL injection\n- Add database indexes for frequently queried columns\n- Profile before optimizing (use tools like rack-mini-profiler)\n\n**I18n & Support** ([references/i18n_support.md](references/i18n_support.md))\n\nRead this when working with:\n- Internationalization (I18n) setup\n- Locale files and translations\n- Active Support core extensions\n- Time zones and date formatting\n- Active Support instrumentation\n- Custom extensions and monkey patches\n\nCommon patterns:\n- Use I18n.t for all user-facing strings\n- Organize translations by controller/view hierarchy\n- Leverage Active Support extensions (1.day.ago, \"hello\".pluralize)\n- Use instrumentation for performance monitoring\n\n**API Development** ([references/api_development.md](references/api_development.md))\n\nRead this when working with:\n- Building JSON APIs with Rails\n- API-only applications\n- Serialization patterns\n- Authentication for APIs (tokens, JWT)\n- API versioning strategies\n- CORS configuration\n\nCommon patterns:\n- Use Rails API mode for API-only apps\n- Implement proper authentication (OAuth, JWT, API keys)\n- Version your APIs from the start\n- Use proper HTTP status codes and error responses\n</reference_guides>\n\n<workflow>\n<starting_new_feature>\n**Plan the data model**\n- Identify models and their relationships\n- Sketch out the database schema\n- Consider validations and constraints\n\n**Generate migrations and models**\n```bash\nrails generate model Article title:string body:text published_at:datetime\nrails generate migration AddUserRefToArticles user:references\n```\n\n**Set up associations and validations**\n- Define relationships in models\n- Add validations for data integrity\n- Write model tests\n\n**Create controllers and routes**\n```bash\nrails generate controller Articles index show new create edit update destroy\n```\n- Or use `rails generate scaffold` for full CRUD\n\n**Build views**\n- Create templates using ERB or other templating engines\n- Use partials for reusable components\n- Leverage form helpers\n\n**Write tests**\n- Model tests for validations and associations\n- Controller tests for actions\n- System tests for user flows\n\n**Iterate and refactor**\n- Extract common logic to concerns or service objects\n- Optimize database queries\n- Improve user experience\n</starting_new_feature>\n</workflow>\n\n<best_practices>\n<code_organization>\n- Keep controllers thin (delegate to models/services)\n- Use concerns for shared behavior\n- Extract complex queries to scopes or query objects\n- Use service objects for complex business logic\n</code_organization>\n\n<database>\n- Always add indexes for foreign keys\n- Use database constraints where appropriate\n- Write reversible migrations\n- Use database-level validations when possible\n</database>\n\n<performance>\n- Eager load associations to avoid N+1 queries\n- Use counter caches for expensive counts\n- Implement caching strategically\n- Profile before optimizing\n</performance>\n\n<security>\n- Never trust user input (use strong parameters)\n- Keep Rails and gems updated\n- Use HTTPS in production\n- Implement proper authorization (use gems like Pundit/CanCanCan)\n</security>\n\n<testing>\n- Aim for high model test coverage\n- Write integration tests for critical paths\n- Use fixtures or factories, not both\n- Keep tests fast and focused\n</testing>\n</best_practices>\n\n<common_patterns>\n<model_example>\n```ruby\nclass Article < ApplicationRecord\n  belongs_to :user\n  has_many :comments, dependent: :destroy\n  has_many_attached :images\n\n  validates :title, presence: true, length: { minimum: 5 }\n  validates :body, presence: true\n\n  scope :published, -> { where.not(published_at: nil) }\n  scope :recent, -> { order(created_at: :desc).limit(10) }\n\n  def published?\n    published_at.present? && published_at <= Time.current\n  end\nend\n```\n</model_example>\n\n<controller_example>\n```ruby\nclass ArticlesController < ApplicationController\n  before_action :set_article, only: [:show, :edit, :update, :destroy]\n  before_action :authenticate_user!, except: [:index, :show]\n\n  def index\n    @articles = Article.published.includes(:user)\n  end\n\n  def show\n  end\n\n  def create\n    @article = current_user.articles.build(article_params)\n\n    if @article.save\n      redirect_to @article, notice: 'Article was successfully created.'\n    else\n      render :new, status: :unprocessable_entity\n    end\n  end\n\n  private\n\n  def set_article\n    @article = Article.find(params[:id])\n  end\n\n  def article_params\n    params.require(:article).permit(:title, :body, :published_at, images: [])\n  end\nend\n```\n</controller_example>\n\n<routes_example>\n```ruby\n# config/routes.rb\nRails.application.routes.draw do\n  root 'articles#index'\n\n  resources :articles do\n    resources :comments, only: [:create, :destroy]\n  end\n\n  namespace :admin do\n    resources :articles\n  end\nend\n```\n</routes_example>\n</common_patterns>\n\n<version_notes>\nThis skill is based on Rails 8.1.1. Key recent features:\n\n- Solid Queue, Solid Cache, and Solid Cable for built-in infrastructure\n- Enhanced Turbo integration\n- Improved authentication generators\n- Better type checking with RBS support\n- Progressive Web App features\n\nWhen working with older Rails versions, check the upgrade guides in the references for migration paths and deprecated features.\n</version_notes>\n\n<troubleshooting>\nWhen stuck on a Rails problem:\n\n1. Check the relevant reference file first\n2. Use `rails console` to experiment with code\n3. Review the Rails guides at guides.rubyonrails.org\n4. Check the API documentation at api.rubyonrails.org\n5. Search GitHub issues for known problems\n\nRemember: Rails is designed to make common tasks easy and follow sensible conventions. If something feels too difficult, there's likely a Rails way to do it more simply.\n</troubleshooting>\n\n<success_criteria>\nYou're using this skill effectively when:\n\n- You consult the appropriate reference file before implementing Rails features\n- You follow Rails conventions (RESTful routes, naming patterns, file organization)\n- You leverage Rails generators and built-in functionality\n- Your code follows the best practices outlined above\n- Tests are written alongside feature development\n- Security and performance considerations are addressed proactively\n</success_criteria>"
              },
              {
                "name": "review-ruby-code",
                "description": "Comprehensive Ruby and Rails code review using Sandi Metz rules and SOLID principles. Automatically runs rubycritic and simplecov, analyzes changed files in current branch vs base branch, identifies OOP violations, Rails anti-patterns, security issues, and test coverage gaps. Outputs REVIEW.md with VSCode-compatible file links. Use when reviewing Ruby/Rails code, conducting code reviews, checking for design issues, or when user mentions code review, pull request review, or code quality analysis.",
                "path": "plugins/ruby-rails/skills/review-ruby-code/SKILL.md",
                "frontmatter": {
                  "name": "review-ruby-code",
                  "description": "Comprehensive Ruby and Rails code review using Sandi Metz rules and SOLID principles. Automatically runs rubycritic and simplecov, analyzes changed files in current branch vs base branch, identifies OOP violations, Rails anti-patterns, security issues, and test coverage gaps. Outputs REVIEW.md with VSCode-compatible file links. Use when reviewing Ruby/Rails code, conducting code reviews, checking for design issues, or when user mentions code review, pull request review, or code quality analysis."
                },
                "content": "<objective>\nPerform comprehensive code reviews of Ruby and Rails applications by analyzing changes in the current branch against the base branch. Apply Sandi Metz rules and SOLID principles to identify design issues, detect Rails anti-patterns and performance problems, flag security vulnerabilities, and assess test coverage. Generate a structured REVIEW.md file with VSCode-compatible links to every referenced line of code, incorporating findings from rubycritic and simplecov.\n</objective>\n\n<quick_start>\n<basic_usage>\n1. Ensure you're on a feature branch (not main/master/dev)\n2. Run `git fetch` to update remote refs\n3. Auto-detect base branch from git configuration\n4. Get diff of changed files: `git diff --name-only base-branch...HEAD`\n5. Run rubycritic and simplecov on changed files\n6. Analyze each changed file for OOP, Rails, security, and test issues\n7. Generate REVIEW.md with findings and VSCode links\n</basic_usage>\n\n<vscode_link_format>\nEvery code reference must use this format:\n```markdown\n[description](file:///absolute/path/to/file.rb#L42)\n```\n\nExample:\n```markdown\n[UserService#create_user violates SRP](file:///Users/dev/app/services/user_service.rb#L15)\n```\n\nClicking opens the file at the specified line in VSCode.\n</vscode_link_format>\n</quick_start>\n\n<workflow>\n<step_1_detect_base_branch>\nAuto-detect the base branch using git configuration:\n\n```bash\n# Get default branch from remote\ngit remote show origin | grep 'HEAD branch' | cut -d' ' -f5\n\n# Or detect from common naming\ngit branch -r | grep -E 'origin/(main|master|develop)' | head -n1\n```\n\nIf detection fails, default to `main`.\n</step_1_detect_base_branch>\n\n<step_2_identify_changes>\nGet list of changed Ruby files:\n\n```bash\ngit diff --name-only --diff-filter=ACMR base-branch...HEAD | grep '\\.rb$'\n```\n\nFocus only on added, changed, modified, or renamed files (exclude deleted).\n</step_2_identify_changes>\n\n<step_3_run_analysis_tools>\nExecute rubycritic and simplecov:\n\n```bash\n# Run rubycritic on changed files\nrubycritic $(git diff --name-only base-branch...HEAD | grep '\\.rb$' | tr '\\n' ' ')\n\n# Run test suite with simplecov\nCOVERAGE=true bundle exec rspec\n```\n\nParse output to extract:\n- **RubyCritic**: Complexity scores, code smells, churn, duplication\n- **SimpleCov**: Coverage percentages, uncovered lines, missing test files\n</step_3_run_analysis_tools>\n\n<step_4_analyze_each_file>\nFor each changed file, review in this order:\n\n**1. OOP Design Review** (see [references/sandi-metz-rules.md](references/sandi-metz-rules.md) and [references/solid-principles.md](references/solid-principles.md))\n- Check Sandi Metz rules violations\n- Identify SOLID principle violations\n- Look for design patterns misuse\n- Assess class cohesion and coupling\n\n**2. Rails Patterns Review** (see [references/rails-patterns.md](references/rails-patterns.md))\n- Detect N+1 queries\n- Review callback usage\n- Check scope and query object patterns\n- Validate service object implementations\n- Review concerns for proper abstraction\n\n**3. Security Review** (see [references/security-checklist.md](references/security-checklist.md))\n- SQL injection vulnerabilities\n- XSS vulnerabilities\n- Mass assignment issues\n- Authentication/authorization gaps\n- Input validation missing\n\n**4. Test Coverage Review**\n- Compare changed files with simplecov output\n- Identify untested methods\n- Check test quality and patterns\n- Recommend missing test scenarios\n</step_4_analyze_each_file>\n\n<step_5_analyze_codebase_patterns>\nBefore making suggestions, understand larger patterns:\n\n```bash\n# Find similar patterns in codebase\ngrep -r \"class.*Service\" app/services/\ngrep -r \"include Concerns\" app/models/\n\n# Check existing architectural patterns\nls app/services/ app/queries/ app/decorators/ app/presenters/\n```\n\n**Ensure suggestions align with established patterns:**\n- If codebase uses service objects, recommend service objects\n- If codebase uses decorators, recommend decorators\n- Match naming conventions and file structure\n- Respect existing abstraction layers\n</step_5_analyze_codebase_patterns>\n\n<step_6_generate_review_md>\nCreate REVIEW.md with this structure:\n\n```markdown\n# Code Review - [Branch Name]\n\n**Base Branch**: [detected-branch]\n**Changed Files**: [count]\n**Review Date**: [date]\n\n---\n\n## Summary\n\n[High-level overview of changes and main findings]\n\n## Critical Issues\n\n[Issues requiring immediate attention - security, major bugs]\n\n## Design & Architecture\n\n### OOP Violations\n\n[Sandi Metz and SOLID violations with VSCode links]\n\n### Rails Patterns\n\n[N+1 queries, callback issues, anti-patterns with VSCode links]\n\n## Security Concerns\n\n[Security vulnerabilities with VSCode links]\n\n## Test Coverage\n\n[Coverage gaps and missing tests with VSCode links]\n\n## Tool Reports\n\n### RubyCritic Summary\n- **Complexity**: [score]\n- **Duplication**: [score]\n- **Code Smells**: [count]\n\n### SimpleCov Summary\n- **Total Coverage**: [percentage]\n- **Files with < 90% coverage**: [list]\n\n---\n\n## Recommendations\n\n[Prioritized list of improvements considering codebase patterns]\n\n## Positive Observations\n\n[Well-designed code, good patterns, improvements from previous reviews]\n```\n\nEvery code reference MUST include VSCode-compatible link.\n</step_6_generate_review_md>\n</workflow>\n\n<tool_integration>\n<rubycritic_integration>\nRubyCritic analyzes code quality and complexity.\n\n**Run on changed files only:**\n```bash\nrubycritic --format json --no-browser $(git diff --name-only base...HEAD | grep '\\.rb$')\n```\n\n**Extract from JSON output:**\n- Complexity score per file\n- Code smells (complexity, duplication, method length)\n- Churn rate (files changed frequently)\n\nIncorporate findings into \"Tool Reports\" section of REVIEW.md.\n</rubycritic_integration>\n\n<simplecov_integration>\nSimpleCov tracks test coverage.\n\n**Trigger coverage run:**\n```bash\nCOVERAGE=true bundle exec rspec\n```\n\n**Read from coverage/.resultset.json:**\n- Overall coverage percentage\n- Per-file coverage\n- Uncovered lines\n\nCross-reference with changed files to identify coverage gaps.\n\nIf simplecov not configured, check for existing skill:\n```bash\n# Check if simplecov skill exists\nls ~/.claude/skills/simplecov/\n```\n\nUse Skill tool to invoke simplecov skill for setup guidance if needed.\n</simplecov_integration>\n\n<skill_invocation>\nIf rubycritic or simplecov skills exist, invoke them:\n\n```\nSkill(rubycritic)  # For RubyCritic setup and advanced usage\nSkill(simplecov)   # For SimpleCov setup and configuration\n```\n\nThese skills provide deeper integration patterns and troubleshooting.\n</skill_invocation>\n</tool_integration>\n\n<review_areas>\n<oop_design_review>\nApply both Sandi Metz rules and SOLID principles:\n\n**Sandi Metz Rules:**\n1. Classes ≤ 100 lines\n2. Methods ≤ 5 lines\n3. Methods ≤ 4 parameters\n4. Controllers instantiate ≤ 1 object\n5. Views reference ≤ 1 instance variable\n\n**SOLID Principles:**\n- **S**ingle Responsibility: One reason to change\n- **O**pen/Closed: Open for extension, closed for modification\n- **L**iskov Substitution: Subtypes must be substitutable\n- **I**nterface Segregation: Many specific interfaces > one general\n- **D**ependency Inversion: Depend on abstractions, not concretions\n\nSee detailed guides:\n- [references/sandi-metz-rules.md](references/sandi-metz-rules.md)\n- [references/solid-principles.md](references/solid-principles.md)\n</oop_design_review>\n\n<rails_patterns_review>\nCheck for Rails-specific issues:\n\n**Performance:**\n- N+1 queries (missing `includes`, `preload`, `eager_load`)\n- Inefficient database queries\n- Missing database indexes\n- Memory-intensive operations\n\n**Patterns:**\n- Callback overuse (prefer service objects)\n- Fat models (extract to concerns, services, or queries)\n- Business logic in controllers\n- Missing query objects for complex queries\n\n**Best Practices:**\n- Strong parameters properly configured\n- Scopes returning ActiveRecord::Relation\n- Proper use of concerns vs. mixins\n- Background job usage for slow operations\n\nSee: [references/rails-patterns.md](references/rails-patterns.md)\n</rails_patterns_review>\n\n<security_review>\nCheck for common vulnerabilities:\n\n**SQL Injection:**\n- Raw SQL without parameterization\n- String interpolation in `where` clauses\n- Unsafe use of `sanitize_sql_array`\n\n**XSS:**\n- `html_safe` or `raw` on user input\n- Missing escaping in views\n- Unsafe rendering of user content\n\n**Mass Assignment:**\n- Missing strong parameters\n- `permit!` usage\n- Unprotected attributes\n\n**Authorization:**\n- Missing authorization checks\n- Inconsistent permission patterns\n- Direct object references without verification\n\nSee: [references/security-checklist.md](references/security-checklist.md)\n</security_review>\n\n<test_coverage_review>\nAssess test quality and completeness:\n\n**Coverage Analysis:**\n- Methods without any tests\n- Edge cases not covered\n- Error handling paths untested\n- Integration points missing tests\n\n**Test Quality:**\n- Tests testing implementation vs. behavior\n- Brittle tests with excessive mocking\n- Missing integration/system tests\n- Slow tests that could be unit tests\n\n**Recommendations:**\n- Specific test scenarios to add\n- Refactoring to improve testability\n- Mock/stub suggestions\n- Coverage improvement strategy\n</test_coverage_review>\n</review_areas>\n\n<codebase_pattern_recognition>\n<understanding_context>\nBefore making recommendations, understand existing patterns:\n\n**Architectural Layers:**\n```bash\n# Discover what layers exist\nfind app -type d -maxdepth 1 | sort\n```\n\nCommon patterns:\n- `/services` - Business logic extraction\n- `/queries` - Complex database queries\n- `/decorators` or `/presenters` - View logic\n- `/policies` - Authorization logic\n- `/forms` - Form objects for complex validations\n- `/serializers` - API response formatting\n\n**Naming Conventions:**\n```bash\n# Understand naming patterns\nls app/services/ | head -10\nls app/models/concerns/ | head -10\n```\n\nCheck for patterns like:\n- `UserCreationService` vs. `Users::Creator`\n- `Authenticatable` vs. `Authentication`\n- File organization (flat vs. namespaced)\n</understanding_context>\n\n<matching_suggestions_to_patterns>\n**Rule**: Recommendations must match existing codebase patterns.\n\nExamples:\n- If codebase has `/services` with `VerbNounService` naming → recommend similar\n- If codebase uses concerns heavily → suggest concern extraction\n- If codebase uses namespaced modules → follow namespace structure\n- If tests use FactoryBot → recommend FactoryBot in test suggestions\n\n**Anti-pattern**: Suggesting decorator pattern when codebase has no decorators.\n**Better**: Suggest service object if that's the established pattern.\n</matching_suggestions_to_patterns>\n</codebase_pattern_recognition>\n\n<validation>\nBefore finalizing REVIEW.md, validate:\n\n**Link Format:**\n- [ ] Every code reference has VSCode link\n- [ ] Links use absolute paths\n- [ ] Line numbers are accurate\n- [ ] Links follow format: `file:///absolute/path#L42`\n\n**Content Completeness:**\n- [ ] All changed files reviewed\n- [ ] RubyCritic findings incorporated\n- [ ] SimpleCov findings incorporated\n- [ ] Each section has specific examples with links\n\n**Quality:**\n- [ ] Suggestions match codebase patterns\n- [ ] Critical issues clearly marked\n- [ ] Positive observations included\n- [ ] Recommendations are actionable and prioritized\n</validation>\n\n<success_criteria>\nA successful review has:\n\n1. **Accurate scope**: Only reviews changed files in branch vs. base\n2. **Comprehensive coverage**: Addresses OOP, Rails, security, and tests\n3. **Tool integration**: Includes rubycritic and simplecov findings\n4. **Clickable links**: Every code reference has working VSCode link\n5. **Contextual suggestions**: Recommendations align with codebase patterns\n6. **Actionable findings**: Clear, specific, prioritized improvements\n7. **Balanced perspective**: Includes positive observations alongside issues\n8. **Structured output**: REVIEW.md follows consistent format\n</success_criteria>\n\n<reference_guides>\n**Core Principles:**\n- [references/sandi-metz-rules.md](references/sandi-metz-rules.md) - POODR rules and Law of Demeter\n- [references/solid-principles.md](references/solid-principles.md) - Detailed SOLID principle explanations with Ruby examples\n\n**Domain-Specific:**\n- [references/rails-patterns.md](references/rails-patterns.md) - Rails anti-patterns, N+1 queries, callback issues, best practices\n- [references/security-checklist.md](references/security-checklist.md) - Security vulnerability patterns and detection strategies\n\n**Technical Reference:**\n- [references/vscode-links.md](references/vscode-links.md) - VSCode link format specifications and examples\n</reference_guides>"
              },
              {
                "name": "rspec",
                "description": "Comprehensive RSpec testing for Ruby and Rails applications. Covers model specs, request specs, system specs, factories, mocks, and TDD workflow. Automatically triggers on RSpec-related keywords and testing scenarios.",
                "path": "plugins/ruby-rails/skills/rspec/SKILL.md",
                "frontmatter": {
                  "name": "rspec",
                  "description": "Comprehensive RSpec testing for Ruby and Rails applications. Covers model specs, request specs, system specs, factories, mocks, and TDD workflow. Automatically triggers on RSpec-related keywords and testing scenarios."
                },
                "content": "# RSpec Testing Skill\n\nExpert guidance for writing comprehensive tests in RSpec for Ruby and Rails applications. This skill provides immediate, actionable testing strategies with deep-dive references for complex scenarios.\n\n## Quick Start\n\n### Basic RSpec Structure\n\n```ruby\n# spec/models/user_spec.rb\nRSpec.describe User, type: :model do\n  describe '#full_name' do\n    it 'returns the first and last name' do\n      user = User.new(first_name: 'John', last_name: 'Doe')\n      expect(user.full_name).to eq('John Doe')\n    end\n  end\nend\n```\n\n**Key concepts:**\n\n- `describe`: Groups related tests (classes, methods)\n- `context`: Describes specific scenarios\n- `it`: Individual test example\n- `expect`: Makes assertions using matchers\n\n### Running Tests\n\n```bash\n# Run all specs\nbundle exec rspec\n\n# Run specific file\nbundle exec rspec spec/models/user_spec.rb\n\n# Run specific line\nbundle exec rspec spec/models/user_spec.rb:12\n\n# Run with documentation format\nbundle exec rspec --format documentation\n\n# Run only failures from last run\nbundle exec rspec --only-failures\n```\n\n## Core Testing Patterns\n\n### 1. Model Specs\n\nTest business logic, validations, associations, and methods:\n\n```ruby\nRSpec.describe Article, type: :model do\n  # Test validations\n  describe 'validations' do\n    it { should validate_presence_of(:title) }\n    it { should validate_length_of(:title).is_at_most(100) }\n  end\n\n  # Test associations\n  describe 'associations' do\n    it { should belong_to(:author) }\n    it { should have_many(:comments) }\n  end\n\n  # Test instance methods\n  describe '#published?' do\n    context 'when publish_date is in the past' do\n      it 'returns true' do\n        article = Article.new(publish_date: 1.day.ago)\n        expect(article.published?).to be true\n      end\n    end\n\n    context 'when publish_date is in the future' do\n      it 'returns false' do\n        article = Article.new(publish_date: 1.day.from_now)\n        expect(article.published?).to be false\n      end\n    end\n  end\n\n  # Test scopes\n  describe '.recent' do\n    it 'returns articles from the last 30 days' do\n      old = create(:article, created_at: 31.days.ago)\n      recent = create(:article, created_at: 1.day.ago)\n\n      expect(Article.recent).to include(recent)\n      expect(Article.recent).not_to include(old)\n    end\n  end\nend\n```\n\n### 2. Request Specs\n\nTest HTTP requests and responses across the entire stack:\n\n```ruby\nRSpec.describe 'Articles API', type: :request do\n  describe 'GET /articles' do\n    it 'returns all articles' do\n      create_list(:article, 3)\n\n      get '/articles'\n\n      expect(response).to have_http_status(:success)\n      expect(JSON.parse(response.body).size).to eq(3)\n    end\n  end\n\n  describe 'POST /articles' do\n    context 'with valid params' do\n      it 'creates a new article' do\n        article_params = { article: { title: 'New Article', body: 'Content' } }\n\n        expect {\n          post '/articles', params: article_params\n        }.to change(Article, :count).by(1)\n\n        expect(response).to have_http_status(:created)\n      end\n    end\n\n    context 'with invalid params' do\n      it 'returns errors' do\n        invalid_params = { article: { title: '' } }\n\n        post '/articles', params: invalid_params\n\n        expect(response).to have_http_status(:unprocessable_entity)\n      end\n    end\n  end\n\n  describe 'authentication' do\n    it 'requires authentication for create' do\n      post '/articles', params: { article: { title: 'Test' } }\n\n      expect(response).to have_http_status(:unauthorized)\n    end\n\n    it 'allows authenticated users to create' do\n      user = create(:user)\n\n      post '/articles',\n        params: { article: { title: 'Test' } },\n        headers: { 'Authorization' => \"Bearer #{user.token}\" }\n\n      expect(response).to have_http_status(:created)\n    end\n  end\nend\n```\n\n### 3. System Specs (End-to-End)\n\nTest user workflows through the browser with Capybara:\n\n```ruby\nRSpec.describe 'Article management', type: :system do\n  before { driven_by(:selenium_chrome_headless) }\n\n  scenario 'user creates an article' do\n    visit new_article_path\n\n    fill_in 'Title', with: 'My Article'\n    fill_in 'Body', with: 'Article content'\n    click_button 'Create Article'\n\n    expect(page).to have_content('Article was successfully created')\n    expect(page).to have_content('My Article')\n  end\n\n  scenario 'user edits an article' do\n    article = create(:article, title: 'Original Title')\n\n    visit article_path(article)\n    click_link 'Edit'\n\n    fill_in 'Title', with: 'Updated Title'\n    click_button 'Update Article'\n\n    expect(page).to have_content('Updated Title')\n    expect(page).not_to have_content('Original Title')\n  end\n\n  # Test JavaScript interactions\n  scenario 'user filters articles', js: true do\n    create(:article, title: 'Ruby Article', category: 'ruby')\n    create(:article, title: 'Python Article', category: 'python')\n\n    visit articles_path\n\n    select 'Ruby', from: 'filter'\n\n    expect(page).to have_content('Ruby Article')\n    expect(page).not_to have_content('Python Article')\n  end\nend\n```\n\n## Factory Bot Integration\n\n### Defining Factories\n\n```ruby\n# spec/factories/users.rb\nFactoryBot.define do\n  factory :user do\n    first_name { 'John' }\n    last_name { 'Doe' }\n    sequence(:email) { |n| \"user#{n}@example.com\" }\n    password { 'password123' }\n\n    # Traits for variations\n    trait :admin do\n      role { 'admin' }\n    end\n\n    trait :with_articles do\n      transient do\n        articles_count { 3 }\n      end\n\n      after(:create) do |user, evaluator|\n        create_list(:article, evaluator.articles_count, author: user)\n      end\n    end\n  end\n\n  factory :article do\n    sequence(:title) { |n| \"Article #{n}\" }\n    body { 'Article content' }\n    association :author, factory: :user\n  end\nend\n\n# Using factories\nuser = create(:user)                        # Persisted\nuser = build(:user)                         # Not persisted\nadmin = create(:user, :admin)               # With trait\nuser = create(:user, :with_articles)        # With association\nusers = create_list(:user, 5)               # Multiple records\nattributes = attributes_for(:user)          # Hash of attributes\n```\n\n## Essential Matchers\n\n### Equality and Identity\n\n```ruby\nexpect(actual).to eq(expected)           # ==\nexpect(actual).to eql(expected)          # .eql?\nexpect(actual).to be(expected)           # .equal?\nexpect(actual).to equal(expected)        # same object\n```\n\n### Truthiness and Types\n\n```ruby\nexpect(actual).to be_truthy              # not nil or false\nexpect(actual).to be_falsy               # nil or false\nexpect(actual).to be_nil\nexpect(actual).to be_a(Class)\nexpect(actual).to be_an_instance_of(Class)\n```\n\n### Collections\n\n```ruby\nexpect(array).to include(item)\nexpect(array).to contain_exactly(1, 2, 3)   # any order\nexpect(array).to match_array([1, 2, 3])     # any order\nexpect(array).to start_with(1, 2)\nexpect(array).to end_with(2, 3)\n```\n\n### Errors and Changes\n\n```ruby\nexpect { action }.to raise_error(ErrorClass)\nexpect { action }.to raise_error('message')\nexpect { action }.to change(User, :count).by(1)\nexpect { action }.to change { user.reload.name }.from('old').to('new')\n```\n\n### Rails-Specific\n\n```ruby\nexpect(response).to have_http_status(:success)\nexpect(response).to have_http_status(200)\nexpect(response).to redirect_to(path)\nexpect { action }.to have_enqueued_job(JobClass)\n```\n\n## Mocks, Stubs, and Doubles\n\n### Test Doubles\n\n```ruby\n# Basic double\nbook = double('book', title: 'RSpec Book', pages: 300)\n\n# Verifying double (checks against real class)\nbook = instance_double('Book', title: 'RSpec Book')\n```\n\n### Stubbing Methods\n\n```ruby\n# On test doubles\nallow(book).to receive(:title).and_return('New Title')\nallow(book).to receive(:available?).and_return(true)\n\n# On real objects\nuser = User.new\nallow(user).to receive(:admin?).and_return(true)\n\n# Chaining\nallow(user).to receive_message_chain(:articles, :published).and_return([article])\n```\n\n### Message Expectations\n\n```ruby\n# Expect method to be called\nexpect(mailer).to receive(:deliver).and_return(true)\n\n# With specific arguments\nexpect(service).to receive(:call).with(user, { notify: true })\n\n# Number of times\nexpect(logger).to receive(:info).once\nexpect(logger).to receive(:info).twice\nexpect(logger).to receive(:info).exactly(3).times\nexpect(logger).to receive(:info).at_least(:once)\n```\n\n### Spies\n\n```ruby\n# Create spy\ninvitation = spy('invitation')\nuser.accept_invitation(invitation)\n\n# Verify after the fact\nexpect(invitation).to have_received(:accept)\nexpect(invitation).to have_received(:accept).with(mailer)\n```\n\n## DRY Testing Techniques\n\n### Before Hooks\n\n```ruby\nRSpec.describe ArticlesController do\n  before(:each) do\n    @user = create(:user)\n    sign_in @user\n  end\n\n  # OR using subject\n  subject { create(:article) }\n\n  it 'has a title' do\n    expect(subject.title).to be_present\n  end\nend\n```\n\n### Let and Let\n\n```ruby\ndescribe Article do\n  let(:article) { create(:article) }           # Lazy-loaded\n  let!(:published) { create(:article, :published) }  # Eager-loaded\n\n  it 'can access article' do\n    expect(article).to be_valid\n  end\nend\n```\n\n### Shared Examples\n\n```ruby\n# Define shared examples\nRSpec.shared_examples 'a timestamped model' do\n  it 'has created_at' do\n    expect(subject).to respond_to(:created_at)\n  end\n\n  it 'has updated_at' do\n    expect(subject).to respond_to(:updated_at)\n  end\nend\n\n# Use shared examples\ndescribe Article do\n  it_behaves_like 'a timestamped model'\nend\n\ndescribe Comment do\n  it_behaves_like 'a timestamped model'\nend\n```\n\n### Shared Contexts\n\n```ruby\nRSpec.shared_context 'authenticated user' do\n  let(:current_user) { create(:user) }\n\n  before do\n    sign_in current_user\n  end\nend\n\ndescribe ArticlesController do\n  include_context 'authenticated user'\n\n  # Tests use current_user and are signed in\nend\n```\n\n## TDD Workflow\n\n### Red-Green-Refactor Cycle\n\n1. **Red**: Write a failing test first\n\n```ruby\ndescribe User do\n  it 'has a full name' do\n    user = User.new(first_name: 'John', last_name: 'Doe')\n    expect(user.full_name).to eq('John Doe')\n  end\nend\n# Fails: undefined method `full_name'\n```\n\n2. **Green**: Write minimal code to pass\n\n```ruby\nclass User\n  def full_name\n    \"#{first_name} #{last_name}\"\n  end\nend\n# Passes!\n```\n\n3. **Refactor**: Improve code while keeping tests green\n\n### Testing Strategy\n\n**Start with system specs** for user-facing features:\n\n- Tests complete workflows\n- Highest confidence\n- Slowest to run\n\n**Drop to request specs** for API/controller logic:\n\n- Test HTTP interactions\n- Faster than system specs\n- Cover authentication, authorization, edge cases\n\n**Use model specs** for business logic:\n\n- Test calculations, validations, scopes\n- Fast and focused\n- Most of your test suite\n\n## Configuration Best Practices\n\n### spec/rails_helper.rb\n\n```ruby\nrequire 'spec_helper'\nENV['RAILS_ENV'] ||= 'test'\nrequire_relative '../config/environment'\nabort(\"Run in production!\") if Rails.env.production?\nrequire 'rspec/rails'\n\n# Auto-require support files\nDir[Rails.root.join('spec', 'support', '**', '*.rb')].sort.each { |f| require f }\n\nRSpec.configure do |config|\n  # Use transactional fixtures\n  config.use_transactional_fixtures = true\n\n  # Infer spec type from file location\n  config.infer_spec_type_from_file_location!\n\n  # Filter Rails backtrace\n  config.filter_rails_from_backtrace!\n\n  # Include FactoryBot methods\n  config.include FactoryBot::Syntax::Methods\n\n  # Include request helpers\n  config.include RequestHelpers, type: :request\n\n  # Capybara configuration for system specs\n  config.before(:each, type: :system) do\n    driven_by :selenium_chrome_headless\n  end\nend\n```\n\n### spec/spec_helper.rb\n\n```ruby\nRSpec.configure do |config|\n  # Show detailed failure messages\n  config.example_status_persistence_file_path = \"spec/examples.txt\"\n\n  # Disable monkey patching (use expect syntax only)\n  config.disable_monkey_patching!\n\n  # Output warnings\n  config.warnings = true\n\n  # Profile slowest tests\n  config.profile_examples = 10 if ENV['PROFILE']\n\n  # Run specs in random order\n  config.order = :random\n  Kernel.srand config.seed\nend\n```\n\n## Common Patterns\n\n### Testing Background Jobs\n\n```ruby\ndescribe 'background jobs', type: :job do\n  it 'enqueues the job' do\n    expect {\n      SendEmailJob.perform_later(user)\n    }.to have_enqueued_job(SendEmailJob).with(user)\n  end\n\n  it 'performs the job' do\n    expect {\n      SendEmailJob.perform_now(user)\n    }.to change { ActionMailer::Base.deliveries.count }.by(1)\n  end\nend\n```\n\n### Testing Mailers\n\n```ruby\ndescribe UserMailer, type: :mailer do\n  describe '#welcome_email' do\n    let(:user) { create(:user) }\n    let(:mail) { UserMailer.welcome_email(user) }\n\n    it 'renders the subject' do\n      expect(mail.subject).to eq('Welcome!')\n    end\n\n    it 'renders the receiver email' do\n      expect(mail.to).to eq([user.email])\n    end\n\n    it 'renders the sender email' do\n      expect(mail.from).to eq(['noreply@example.com'])\n    end\n\n    it 'contains the user name' do\n      expect(mail.body.encoded).to include(user.name)\n    end\n  end\nend\n```\n\n### Testing File Uploads\n\n```ruby\ndescribe 'file upload', type: :system do\n  it 'allows user to upload avatar' do\n    user = create(:user)\n    sign_in user\n\n    visit edit_profile_path\n    attach_file 'Avatar', Rails.root.join('spec', 'fixtures', 'avatar.jpg')\n    click_button 'Update Profile'\n\n    expect(page).to have_content('Profile updated')\n    expect(user.reload.avatar).to be_attached\n  end\nend\n```\n\n## Performance Tips\n\n1. **Use let instead of before** for lazy loading\n2. **Avoid database calls** when testing logic (use mocks)\n3. **Use build instead of create** when persistence isn't needed\n4. **Use build_stubbed** for non-persisted objects with associations\n5. **Tag slow tests** and exclude them during development:\n\n   ```ruby\n   it 'slow test', :slow do\n     # test code\n   end\n\n   # Run with: rspec --tag ~slow\n   ```\n\n## When to Use Each Spec Type\n\n- **Model specs**: Business logic, calculations, validations, scopes\n- **Request specs**: API endpoints, authentication, authorization, JSON responses\n- **System specs**: User workflows, JavaScript interactions, form submissions\n- **Mailer specs**: Email content, recipients, attachments\n- **Job specs**: Background job enqueueing and execution\n- **Helper specs**: View helper methods\n- **Routing specs**: Custom routes (usually not needed)\n\n## Quick Reference\n\n**Most Common Commands:**\n\n```bash\nrspec                          # Run all specs\nrspec spec/models              # Run model specs\nrspec --tag ~slow              # Exclude slow specs\nrspec --only-failures          # Rerun failures\nrspec --format documentation   # Readable output\nrspec --profile               # Show slowest specs\n```\n\n**Most Common Matchers:**\n\n- `eq(expected)` - value equality\n- `be_truthy` / `be_falsy` - truthiness\n- `include(item)` - collection membership\n- `raise_error(Error)` - exceptions\n- `change { }.by(n)` - state changes\n\n**Most Common Stubs:**\n\n- `allow(obj).to receive(:method)` - stub method\n- `expect(obj).to receive(:method)` - expect call\n- `double('name', method: value)` - create double\n\n---\n\n## Reference Documentation\n\nFor detailed information on specific topics, see the references directory:\n\n- **[Core Concepts](./references/core_concepts.md)** - Describe blocks, contexts, hooks, subject, let\n- **[Matchers Guide](./references/matchers.md)** - Complete matcher reference with examples\n- **[Mocking and Stubbing](./references/mocking.md)** - Test doubles, stubs, spies, message expectations\n- **[Rails Testing](./references/rails_testing.md)** - Rails-specific spec types and helpers\n- **[Factory Bot](./references/factory_bot.md)** - Test data strategies and patterns\n- **[Best Practices](./references/best_practices.md)** - Testing philosophy, patterns, and anti-patterns\n- **[Configuration](./references/configuration.md)** - Setup, formatters, and optimization\n\n## Common Scenarios\n\n### Debugging Failing Tests\n\n```ruby\n# Use save_and_open_page in system specs\nscenario 'user creates article' do\n  visit new_article_path\n  save_and_open_page  # Opens browser with current page state\n  # ...\nend\n\n# Print response body in request specs\nit 'creates article' do\n  post '/articles', params: { ... }\n  puts response.body  # Debug API responses\n  expect(response).to be_successful\nend\n\n# Use binding.pry for interactive debugging\nit 'calculates total' do\n  order = create(:order)\n  binding.pry  # Pause execution here\n  expect(order.total).to eq(100)\nend\n```\n\n### Testing Complex Queries\n\n```ruby\ndescribe '.search' do\n  let!(:ruby_article) { create(:article, title: 'Ruby Guide', body: 'Ruby content') }\n  let!(:rails_article) { create(:article, title: 'Rails Guide', body: 'Rails content') }\n\n  it 'finds articles by title' do\n    results = Article.search('Ruby')\n    expect(results).to include(ruby_article)\n    expect(results).not_to include(rails_article)\n  end\n\n  it 'finds articles by body' do\n    results = Article.search('Rails content')\n    expect(results).to include(rails_article)\n  end\nend\n```\n\n### Testing Callbacks\n\n```ruby\ndescribe 'callbacks' do\n  describe 'after_create' do\n    it 'sends welcome email' do\n      expect(UserMailer).to receive(:welcome_email)\n        .with(an_instance_of(User))\n        .and_return(double(deliver_later: true))\n\n      create(:user)\n    end\n  end\n\n  describe 'before_save' do\n    it 'normalizes email' do\n      user = create(:user, email: 'USER@EXAMPLE.COM')\n      expect(user.email).to eq('user@example.com')\n    end\n  end\nend\n```\n\nThis skill provides comprehensive RSpec testing guidance. For specific scenarios or advanced techniques, refer to the detailed reference documentation in the `references/` directory."
              },
              {
                "name": "rubocop",
                "description": "Ruby static code analyzer and formatter for enforcing style guidelines, detecting bugs, and improving code quality. Supports Rails, RSpec, and Performance extensions with safe autocorrection capabilities.",
                "path": "plugins/ruby-rails/skills/rubocop/SKILL.md",
                "frontmatter": {
                  "name": "rubocop",
                  "description": "Ruby static code analyzer and formatter for enforcing style guidelines, detecting bugs, and improving code quality. Supports Rails, RSpec, and Performance extensions with safe autocorrection capabilities."
                },
                "content": "# RuboCop Code Analysis & Formatting\n\nRuboCop is Ruby's premier static code analyzer (linter) and formatter, based on the community-driven Ruby Style Guide. This skill enables comprehensive code analysis, automatic formatting, and enforcement of coding standards across Ruby projects including Rails applications.\n\n## When to Use This Skill\n\nClaude automatically uses this skill when users:\n\n- Ask to \"check\", \"lint\", \"analyze\", or \"review\" Ruby code\n- Request code formatting or style improvements\n- Want to enforce coding standards or style guidelines\n- Need to detect potential bugs or code smells\n- Ask about RuboCop configuration or setup\n- Request Rails, RSpec, or performance-specific analysis\n- Want to run autocorrections on Ruby code\n\n## Core Capabilities\n\n**Code Analysis & Linting**\n- Detects style violations, bugs, and code smells across all cop departments\n- Supports Rails, RSpec, Performance, and custom cop extensions\n- Provides detailed offense reports with line numbers and descriptions\n\n**Automatic Code Correction**\n- Safe autocorrection (`-a`) for guaranteed-safe fixes\n- Unsafe autocorrection (`-A`) for broader but riskier corrections\n- Layout-only fixes (`-x`) for formatting without logic changes\n\n**Configuration & Customization**\n- Flexible `.rubocop.yml` configuration\n- Per-project and per-directory configuration inheritance\n- Selective cop enabling/disabling and severity adjustment\n- Custom cop development support\n\n**Extension Integration**\n- **rubocop-rails**: Rails best practices and conventions\n- **rubocop-rspec**: RSpec-specific analysis\n- **rubocop-performance**: Performance optimization checks\n\n## Quick Analysis Workflow\n\n### Run Basic Analysis\n\n```bash\n# Analyze current directory\nrubocop\n\n# Analyze specific files/directories\nrubocop app spec lib/important_file.rb\n\n# Show only correctable offenses\nrubocop --display-only-correctable\n```\n\n### Apply Corrections\n\n```bash\n# Safe autocorrection only (recommended)\nrubocop -a\n\n# All corrections including unsafe\nrubocop -A\n\n# Layout/formatting corrections only\nrubocop -x\n\n# Autocorrect specific cops\nrubocop -a --only Style/StringLiterals,Layout/TrailingWhitespace\n```\n\n### Targeted Analysis\n\n```bash\n# Run only specific cops\nrubocop --only Style/StringLiterals,Naming/MethodName\n\n# Run all cops except specified\nrubocop --except Metrics/MethodLength\n\n# Run only lint cops\nrubocop --lint\n\n# Check only Rails-specific issues\nrubocop --only Rails\n```\n\n## Configuration Essentials\n\n### Basic .rubocop.yml Setup\n\n```yaml\n# Enable extensions\nplugins:\n  - rubocop-rails\n  - rubocop-rspec\n  - rubocop-performance\n\nAllCops:\n  TargetRubyVersion: 3.2\n  NewCops: enable  # Auto-enable new cops\n  Exclude:\n    - 'db/schema.rb'\n    - 'vendor/**/*'\n    - 'node_modules/**/*'\n\n# Adjust specific cops\nStyle/StringLiterals:\n  EnforcedStyle: double_quotes\n\nMetrics/MethodLength:\n  Max: 15\n  Exclude:\n    - 'spec/**/*'\n```\n\n### Common Configuration Patterns\n\n**Inherit from shared config:**\n```yaml\ninherit_from:\n  - .rubocop_todo.yml\n  - config/rubocop_defaults.yml\n```\n\n**Rails-specific settings:**\n```yaml\nRails:\n  Enabled: true\n\nRails/ApplicationRecord:\n  Enabled: true\n  Exclude:\n    - 'db/migrate/**'\n```\n\n**RSpec configuration:**\n```yaml\nRSpec/ExampleLength:\n  Max: 10\n\nRSpec/MultipleExpectations:\n  Max: 3\n```\n\n## Analysis Interpretation\n\n### Understanding Offense Output\n\n```\napp/models/user.rb:15:3: C: Style/StringLiterals: Prefer single-quoted strings...\n  name = \"John Doe\"\n         ^^^^^^^^^^\n```\n\n**Format breakdown:**\n- `app/models/user.rb:15:3` - File path, line number, column number\n- `C:` - Severity (C=Convention, W=Warning, E=Error, F=Fatal)\n- `Style/StringLiterals` - Cop department and name\n- Message explains the issue and often suggests fixes\n\n### Severity Levels\n\n- **Convention (C)**: Style/formatting issues\n- **Warning (W)**: Potential problems that should be reviewed\n- **Error (E)**: Definite problems that need fixing\n- **Fatal (F)**: Syntax errors preventing analysis\n\n## Common Workflows\n\n### Initial Project Setup\n\n```bash\n# Generate initial configuration\nrubocop --init\n\n# Generate .rubocop_todo.yml for existing violations\nrubocop --auto-gen-config\n\n# Use todo file to gradually fix issues\n# .rubocop.yml:\ninherit_from: .rubocop_todo.yml\n```\n\n### Pre-commit Integration\n\n```bash\n# Check staged files only\ngit diff --name-only --cached | grep '\\.rb$' | xargs rubocop\n\n# With autocorrection\ngit diff --name-only --cached | grep '\\.rb$' | xargs rubocop -a\n```\n\n### CI/CD Integration\n\n```bash\n# Exit with error code if offenses found\nrubocop --format progress --fail-level warning\n\n# Generate formatted reports\nrubocop --format json --out rubocop-report.json\nrubocop --format html --out rubocop-report.html\n```\n\n### Parallel Execution\n\n```bash\n# Use all available CPUs (enabled by default)\nrubocop --parallel\n\n# Limit CPU usage\nPARALLEL_PROCESSOR_COUNT=2 rubocop\n```\n\n## Extension-Specific Features\n\n### Rails Analysis\n\nDetects Rails-specific issues:\n- ActiveRecord best practices\n- Controller and routing conventions\n- Migration safety checks\n- SQL injection risks\n\n### RSpec Analysis\n\nEnforces RSpec best practices:\n- Example organization and naming\n- Let vs instance variable usage\n- Expectation patterns\n- Test file structure\n\n### Performance Analysis\n\nIdentifies performance optimizations:\n- Inefficient collection methods\n- String concatenation issues\n- Unnecessary array allocations\n- Regex compilation optimizations\n\n## Troubleshooting\n\n**\"Unknown cop\" errors:**\n- Ensure required gems are installed (`rubocop-rails`, `rubocop-rspec`, etc.)\n- Add to `.rubocop.yml`: `plugins: [rubocop-rails]`\n\n**Autocorrection not working:**\n- Some cops don't support autocorrection\n- Use `-A` for unsafe corrections\n- Check cop is enabled in configuration\n\n**Performance issues:**\n- Use `--parallel` for faster execution\n- Add `UseCache: true` under `AllCops` in config\n- Exclude large generated files\n\n## Additional Resources\n\n- [Configuration Guide](references/configuration_guide.md) - Comprehensive configuration reference\n- [Cop Reference](references/cop_reference.md) - All cop departments and their responsibilities\n- [Extensions Guide](references/extensions_guide.md) - Rails, RSpec, Performance extension details\n- [Autocorrect Guide](references/autocorrect_guide.md) - Safe vs unsafe corrections explained\n- [Custom Cops Guide](references/custom_cops_guide.md) - Creating custom cops for your project"
              },
              {
                "name": "ruby",
                "description": "Comprehensive Ruby development skill covering language fundamentals, object-oriented design patterns, error handling strategies, performance optimization, modern Ruby 3.x features (pattern matching, ractors, typed Ruby), testing patterns, metaprogramming, concurrency, and Rails-specific best practices. Use when writing Ruby code, refactoring, implementing design patterns, handling exceptions, optimizing performance, writing tests, or applying Ruby idioms and conventions.",
                "path": "plugins/ruby-rails/skills/ruby/SKILL.md",
                "frontmatter": {
                  "name": "ruby",
                  "description": "Comprehensive Ruby development skill covering language fundamentals, object-oriented design patterns, error handling strategies, performance optimization, modern Ruby 3.x features (pattern matching, ractors, typed Ruby), testing patterns, metaprogramming, concurrency, and Rails-specific best practices. Use when writing Ruby code, refactoring, implementing design patterns, handling exceptions, optimizing performance, writing tests, or applying Ruby idioms and conventions."
                },
                "content": "# Ruby Development Skill\n\n## Purpose\n\nThis skill provides comprehensive guidance for Ruby development, covering language fundamentals, object-oriented design, error handling, performance optimization, and modern Ruby (3.x+) features. It synthesizes knowledge from Ruby internals, best practices, and official documentation to help Claude write idiomatic, maintainable, and performant Ruby code.\n\n## When to Use This Skill\n\nUse this skill when:\n\n- Writing or reviewing Ruby code\n- Debugging Ruby applications\n- Optimizing Ruby performance\n- Implementing object-oriented designs\n- Handling errors and exceptions\n- Working with Ruby's standard library\n- Using modern Ruby features (pattern matching, types, fibers, ractors)\n- Building Rails applications or Ruby gems\n\n## Ruby Philosophy and Core Principles\n\n### Matz's Design Philosophy\n\nRuby is designed to make programmers happy. It prioritizes:\n\n1. **Developer Productivity** - Write less code to accomplish more\n2. **Readability** - Code should read like natural language\n3. **Flexibility** - Multiple ways to accomplish tasks (TMTOWTDI - There's More Than One Way To Do It)\n4. **Object-Oriented Everything** - Everything is an object, including primitives\n5. **Duck Typing** - \"If it walks like a duck and quacks like a duck, it's a duck\"\n\n### Ruby's Core Characteristics\n\n```ruby\n# Everything is an object\n5.times { puts \"Hello\" }          # Integer is an object\n\"hello\".upcase                    # String is an object\nnil.class                         # => NilClass\n\n# Blocks are first-class citizens\n[1, 2, 3].map { |n| n * 2 }      # => [2, 4, 6]\n\n# Open classes - can modify any class\nclass String\n  def shout\n    \"#{upcase}!\"\n  end\nend\n\n\"hello\".shout                     # => \"HELLO!\"\n\n# Duck typing - focus on behavior, not type\ndef process(thing)\n  thing.call if thing.respond_to?(:call)\nend\n```\n\n## Object-Oriented Design in Ruby\n\n### The Ruby Object Model\n\nUnderstanding Ruby's object model is crucial for effective programming:\n\n```ruby\n# Class hierarchy\nclass Animal\n  def speak\n    \"Some sound\"\n  end\nend\n\nclass Dog < Animal\n  def speak\n    \"Woof!\"\n  end\nend\n\n# Every class is an instance of Class\nDog.class                         # => Class\nDog.superclass                    # => Animal\nAnimal.superclass                 # => Object\nObject.superclass                 # => BasicObject\n\n# Singleton methods (eigenclass/metaclass)\ndog = Dog.new\ndef dog.name\n  \"Buddy\"\nend\n\ndog.name                          # => \"Buddy\"\nDog.new.name                      # NoMethodError\n```\n\n### Composition Over Inheritance\n\nPrefer composition and modules over deep inheritance hierarchies:\n\n```ruby\n# ❌ Bad: Deep inheritance\nclass Vehicle\nend\n\nclass LandVehicle < Vehicle\nend\n\nclass Car < LandVehicle\nend\n\nclass SportsCar < Car\nend\n\n# ✅ Good: Composition with modules\nmodule Drivable\n  def drive\n    \"Driving...\"\n  end\nend\n\nmodule Flyable\n  def fly\n    \"Flying...\"\n  end\nend\n\nclass Car\n  include Drivable\nend\n\nclass Plane\n  include Flyable\n  include Drivable  # Can taxi on ground\nend\n```\n\n### Single Responsibility Principle\n\nEach class should have one reason to change:\n\n```ruby\n# ❌ Bad: Multiple responsibilities\nclass User\n  def save\n    # Database logic\n  end\n\n  def send_email\n    # Email logic\n  end\n\n  def generate_report\n    # Report logic\n  end\nend\n\n# ✅ Good: Separate concerns\nclass User\n  def save\n    UserRepository.new.save(self)\n  end\nend\n\nclass UserMailer\n  def send_welcome_email(user)\n    # Email logic\n  end\nend\n\nclass UserReportGenerator\n  def generate(user)\n    # Report logic\n  end\nend\n```\n\n### Dependency Injection\n\nInject dependencies rather than hardcoding them:\n\n```ruby\n# ❌ Bad: Hard dependency\nclass OrderProcessor\n  def process(order)\n    PaymentGateway.new.charge(order.amount)\n    EmailService.new.send_confirmation(order)\n  end\nend\n\n# ✅ Good: Dependency injection\nclass OrderProcessor\n  def initialize(payment_gateway: PaymentGateway.new,\n                 email_service: EmailService.new)\n    @payment_gateway = payment_gateway\n    @email_service = email_service\n  end\n\n  def process(order)\n    @payment_gateway.charge(order.amount)\n    @email_service.send_confirmation(order)\n  end\nend\n```\n\n### Law of Demeter (Principle of Least Knowledge)\n\nAvoid reaching through multiple objects:\n\n```ruby\n# ❌ Bad: Train wreck\ncustomer.orders.last.line_items.first.price\n\n# ✅ Good: Delegate or encapsulate\nclass Customer\n  def last_order_first_item_price\n    orders.last&.first_item_price\n  end\nend\n\nclass Order\n  def first_item_price\n    line_items.first&.price\n  end\nend\n\ncustomer.last_order_first_item_price\n```\n\n## Error Handling and Exceptions\n\n### The Exception Hierarchy\n\n```\nException\n├── NoMemoryError\n├── ScriptError\n│   ├── LoadError\n│   ├── NotImplementedError\n│   └── SyntaxError\n├── SignalException\n│   └── Interrupt\n├── StandardError (Default rescue catches this)\n│   ├── ArgumentError\n│   ├── IOError\n│   │   └── EOFError\n│   ├── IndexError\n│   ├── LocalJumpError\n│   ├── NameError\n│   │   └── NoMethodError\n│   ├── RangeError\n│   ├── RegexpError\n│   ├── RuntimeError (Default raise creates this)\n│   ├── SecurityError\n│   ├── SystemCallError\n│   ├── ThreadError\n│   ├── TypeError\n│   └── ZeroDivisionError\n├── SystemExit\n└── SystemStackError\n```\n\n### Exception Handling Best Practices\n\n#### 1. Exceptions Should Be Exceptional\n\nUse exceptions for exceptional cases, not control flow:\n\n```ruby\n# ❌ Bad: Using exceptions for control flow\ndef find_user(id)\n  user = User.find(id)\nrescue ActiveRecord::RecordNotFound\n  nil\nend\n\n# ✅ Good: Use explicit checks\ndef find_user(id)\n  User.find_by(id: id)\nend\n```\n\n#### 2. Rescue Specific Exceptions\n\nAlways rescue specific exceptions, never bare rescue:\n\n```ruby\n# ❌ Bad: Catches everything, including SystemExit\nbegin\n  dangerous_operation\nrescue\n  # Too broad!\nend\n\n# ✅ Good: Rescue specific exceptions\nbegin\n  dangerous_operation\nrescue NetworkError, TimeoutError => e\n  logger.error(\"Network issue: #{e.message}\")\n  retry_operation\nend\n```\n\n#### 3. Fail Fast, Fail Loudly\n\nLet errors propagate unless you can handle them meaningfully:\n\n```ruby\n# ❌ Bad: Swallowing exceptions\ndef process_data(data)\n  result = parse(data)\nrescue => e\n  nil  # Silent failure!\nend\n\n# ✅ Good: Let it fail or handle meaningfully\ndef process_data(data)\n  parse(data)\nrescue ParseError => e\n  logger.error(\"Failed to parse data: #{e.message}\")\n  raise  # Re-raise to propagate\nend\n```\n\n#### 4. Use ensure for Cleanup\n\nAlways use `ensure` for cleanup code:\n\n```ruby\n# ✅ Proper resource management\ndef process_file(filename)\n  file = File.open(filename)\n  process(file)\nensure\n  file&.close\nend\n\n# Better: Use blocks that auto-close\ndef process_file(filename)\n  File.open(filename) do |file|\n    process(file)\n  end  # Automatically closed\nend\n```\n\n#### 5. Custom Exceptions for Domain Logic\n\nCreate custom exceptions for your domain:\n\n```ruby\n# Define custom exceptions\nclass PaymentError < StandardError; end\nclass InsufficientFundsError < PaymentError; end\nclass InvalidCardError < PaymentError; end\n\n# Use them meaningfully\ndef charge_card(card, amount)\n  raise InvalidCardError, \"Card expired\" if card.expired?\n  raise InsufficientFundsError if balance < amount\n\n  process_charge(card, amount)\nend\n\n# Caller can handle appropriately\nbegin\n  charge_card(card, 100)\nrescue InsufficientFundsError => e\n  notify_user(\"Insufficient funds\")\nrescue InvalidCardError => e\n  notify_user(\"Please update your card\")\nrescue PaymentError => e\n  # Catch all payment errors\n  logger.error(\"Payment failed: #{e.message}\")\nend\n```\n\n#### 6. The Weirich raise/fail Convention\n\nUse `fail` for exceptions you expect to be rescued, `raise` for re-raising:\n\n```ruby\ndef process_order(order)\n  fail ArgumentError, \"Order cannot be nil\" if order.nil?\n\n  begin\n    payment_gateway.charge(order)\n  rescue PaymentError => e\n    logger.error(\"Payment failed: #{e.message}\")\n    raise  # Re-raise with raise\n  end\nend\n```\n\n#### 7. Provide Context in Exceptions\n\nInclude helpful information in exception messages:\n\n```ruby\n# ❌ Bad: Vague message\nraise \"Invalid input\"\n\n# ✅ Good: Descriptive message with context\nraise ArgumentError, \"Expected positive integer for age, got: #{age.inspect}\"\n```\n\n### Alternative Error Handling Patterns\n\n#### Result Objects\n\nReturn result objects instead of raising exceptions:\n\n```ruby\nclass Result\n  attr_reader :value, :error\n\n  def initialize(value: nil, error: nil)\n    @value = value\n    @error = error\n  end\n\n  def success?\n    error.nil?\n  end\n\n  def failure?\n    !success?\n  end\nend\n\ndef divide(a, b)\n  return Result.new(error: \"Division by zero\") if b.zero?\n  Result.new(value: a / b)\nend\n\nresult = divide(10, 2)\nif result.success?\n  puts result.value\nelse\n  puts \"Error: #{result.error}\"\nend\n```\n\n#### Caller-Supplied Fallback Strategy\n\nLet callers define error handling:\n\n```ruby\ndef fetch_user(id, &fallback)\n  User.find(id)\nrescue ActiveRecord::RecordNotFound => e\n  fallback ? fallback.call(e) : raise\nend\n\n# Usage\nuser = fetch_user(999) { |e| User.new(name: \"Guest\") }\n```\n\n## Ruby Performance and Optimization\n\n### Understanding Ruby's VM (YARV)\n\nRuby 3.x uses YARV (Yet Another Ruby VM) with JIT compilation:\n\n```ruby\n# Enable JIT (YJIT in Ruby 3.1+)\n# Run with: ruby --yjit your_script.rb\n\n# Check JIT status\nputs \"JIT enabled: #{defined?(RubyVM::YJIT)}\"\n\n# Profile JIT compilation\nRubyVM::YJIT.runtime_stats if defined?(RubyVM::YJIT)\n```\n\n### Memory Management and Garbage Collection\n\nRuby uses generational garbage collection:\n\n```ruby\n# Check GC stats\nGC.stat\n# => {:count=>23, :heap_allocated_pages=>145, ...}\n\n# Manual GC control (rarely needed)\nGC.disable  # Disable GC temporarily\n# ... do intensive work\nGC.enable\nGC.start    # Force GC\n\n# Monitor object allocations\nbefore = GC.stat(:total_allocated_objects)\n# ... your code\nafter = GC.stat(:total_allocated_objects)\nputs \"Allocated: #{after - before} objects\"\n```\n\n### Performance Best Practices\n\n#### 1. Avoid Creating Unnecessary Objects\n\n```ruby\n# ❌ Bad: Creates many string objects\n1000.times do |i|\n  \"User #{i}\"  # New string each time\nend\n\n# ✅ Good: Reuse strings with interpolation\ntemplate = \"User %d\"\n1000.times do |i|\n  template % i\nend\n\n# ✅ Even better: Use frozen strings\nMESSAGE = \"Processing\".freeze\n```\n\n#### 2. Use Symbols for Repeated Strings\n\n```ruby\n# ❌ Bad: Creates new string objects\nhash = { \"name\" => \"John\", \"age\" => 30 }\n\n# ✅ Good: Symbols are immutable and reused\nhash = { name: \"John\", age: 30 }\n```\n\n#### 3. Prefer Enumerable Methods Over Loops\n\n```ruby\n# ❌ Bad: Manual loop\nresult = []\narray.each do |item|\n  result << item * 2 if item > 0\nend\n\n# ✅ Good: Chained enumerable methods\nresult = array.select { |item| item > 0 }\n              .map { |item| item * 2 }\n\n# ✅ Even better: Single pass with each_with_object\nresult = array.each_with_object([]) do |item, acc|\n  acc << item * 2 if item > 0\nend\n```\n\n#### 4. Use Lazy Enumerables for Large Collections\n\n```ruby\n# ❌ Bad: Creates intermediate arrays\n(1..1_000_000).select { |n| n.even? }\n              .map { |n| n * 2 }\n              .first(10)\n\n# ✅ Good: Lazy evaluation\n(1..1_000_000).lazy\n              .select { |n| n.even? }\n              .map { |n| n * 2 }\n              .first(10)\n```\n\n#### 5. Cache Expensive Computations\n\n```ruby\n# ❌ Bad: Recomputes every time\nclass User\n  def full_name\n    \"#{first_name} #{last_name}\".strip\n  end\nend\n\n# ✅ Good: Memoization\nclass User\n  def full_name\n    @full_name ||= \"#{first_name} #{last_name}\".strip\n  end\nend\n\n# ⚠️ Careful with nil/false values\ndef expensive_check\n  return @result if defined?(@result)\n  @result = compute_result\nend\n```\n\n## Modern Ruby Features (3.x+)\n\n### Pattern Matching (Ruby 2.7+)\n\n```ruby\n# Basic pattern matching\ncase [1, 2, 3]\nin [a, b, c]\n  puts \"#{a}, #{b}, #{c}\"\nend\n\n# Hash patterns\ncase { name: \"John\", age: 30 }\nin { name: \"John\", age: age }\n  puts \"John is #{age}\"\nin { name:, age: }  # Variable punning\n  puts \"#{name} is #{age}\"\nend\n\n# Array patterns with rest\ncase [1, 2, 3, 4, 5]\nin [first, *rest, last]\n  puts \"First: #{first}, Last: #{last}, Rest: #{rest}\"\nend\n\n# Rightward assignment (Ruby 3.0+)\n{ name: \"John\", age: 30 } => { name:, age: }\nputs name  # => \"John\"\n\n# Guard clauses\ncase value\nin String => s if s.length > 10\n  puts \"Long string: #{s}\"\nin String => s\n  puts \"Short string: #{s}\"\nend\n```\n\n### Endless Method Definition (Ruby 3.0+)\n\n```ruby\n# Traditional\ndef square(x)\n  x * x\nend\n\n# Endless method (for simple one-liners)\ndef square(x) = x * x\ndef full_name = \"#{first_name} #{last_name}\"\ndef admin? = role == \"admin\"\n```\n\n### Numbered Parameters (Ruby 2.7+)\n\n```ruby\n# Traditional block parameters\n[1, 2, 3].map { |n| n * 2 }\n\n# Numbered parameters\n[1, 2, 3].map { _1 * 2 }\n\n# Multiple numbered parameters\nhash.map { [_1, _2 * 2] }\n```\n\n### Rightward Assignment (Ruby 3.0+)\n\n```ruby\n# Traditional assignment\nresult = compute_value()\nputs result\n\n# Rightward assignment (useful in method chains)\ncompute_value() => result\nputs result\n\n# Useful for debugging\ncalculate_price.tap { p _1 } => price\n```\n\n### Ractors (Ruby 3.0+) - True Parallelism\n\n```ruby\n# Create parallel-safe ractor\nr = Ractor.new do\n  received = Ractor.receive\n  received * 2\nend\n\nr.send(21)\nr.take  # => 42\n\n# Multiple ractors\nresults = 4.times.map do |i|\n  Ractor.new(i) do |n|\n    # Heavy computation\n    (1..1000000).reduce(:+) + n\n  end\nend\n\nresults.map(&:take)  # Runs in parallel\n```\n\n### Typed Ruby with RBS (Ruby 3.0+)\n\n```ruby\n# Define types in .rbs files\n# user.rbs\nclass User\n  attr_reader name: String\n  attr_reader age: Integer\n\n  def initialize: (name: String, age: Integer) -> void\n  def adult?: () -> bool\nend\n\n# Use TypeProf to generate signatures\n# $ typeprof user.rb\n\n# Validate with Steep or RBS\n# $ steep check\n```\n\n### Fiber Scheduler (Ruby 3.0+) - Non-blocking I/O\n\n```ruby\nrequire 'async'\n\n# Async execution with fibers\nAsync do\n  Async do\n    puts \"Task 1 start\"\n    sleep 2\n    puts \"Task 1 end\"\n  end\n\n  Async do\n    puts \"Task 2 start\"\n    sleep 1\n    puts \"Task 2 end\"\n  end\nend\n# Both tasks run concurrently\n```\n\n## Ruby Standard Library Essentials\n\n### Working with Collections\n\n```ruby\n# Array operations\narr = [1, 2, 3, 4, 5]\n\narr.first(2)                # => [1, 2]\narr.last(2)                 # => [4, 5]\narr.sample                  # Random element\narr.shuffle                 # Randomize order\narr.rotate(2)               # => [3, 4, 5, 1, 2]\narr.combination(2).to_a     # All 2-element combinations\narr.permutation(2).to_a     # All 2-element permutations\n\n# Hash operations\nhash = { a: 1, b: 2, c: 3 }\n\nhash.fetch(:d, 0)           # => 0 (default value)\nhash.dig(:nested, :key)     # Safe nested access\nhash.transform_values(&:to_s)  # => { a: \"1\", b: \"2\", c: \"3\" }\nhash.slice(:a, :b)          # => { a: 1, b: 2 }\nhash.merge(d: 4)            # Non-destructive merge\n\n# Set operations\nrequire 'set'\ns1 = Set[1, 2, 3]\ns2 = Set[2, 3, 4]\n\ns1 | s2                     # Union => #<Set: {1, 2, 3, 4}>\ns1 & s2                     # Intersection => #<Set: {2, 3}>\ns1 - s2                     # Difference => #<Set: {1}>\n```\n\n### String Manipulation\n\n```ruby\n# String methods\nstr = \"  Hello, World!  \"\n\nstr.strip                   # => \"Hello, World!\"\nstr.split(\", \")             # => [\"Hello\", \"World!\"]\nstr.gsub(\"World\", \"Ruby\")   # => \"  Hello, Ruby!  \"\nstr.scan(/\\w+/)             # => [\"Hello\", \"World\"]\nstr.start_with?(\"Hello\")    # => false (has spaces)\nstr.include?(\"World\")       # => true\n\n# String interpolation\nname = \"John\"\nage = 30\n\"#{name} is #{age}\"         # => \"John is 30\"\n\"2 + 2 = #{2 + 2}\"          # => \"2 + 2 = 4\"\n\n# Heredocs\ntext = <<~TEXT\n  This is a heredoc.\n  Indentation is removed.\n  Very useful for multi-line strings.\nTEXT\n\n# Frozen strings (immutable)\nCONSTANT = \"immutable\".freeze\n# Or with magic comment:\n# frozen_string_literal: true\n```\n\n### File I/O\n\n```ruby\n# Reading files\ncontent = File.read(\"file.txt\")\nlines = File.readlines(\"file.txt\")\n\n# Block-based reading (auto-closes)\nFile.open(\"file.txt\") do |file|\n  file.each_line do |line|\n    puts line\n  end\nend\n\n# Writing files\nFile.write(\"output.txt\", \"Hello, World!\")\n\nFile.open(\"output.txt\", \"w\") do |file|\n  file.puts \"Line 1\"\n  file.puts \"Line 2\"\nend\n\n# File operations\nFile.exist?(\"file.txt\")\nFile.directory?(\"path\")\nFile.size(\"file.txt\")\nFile.mtime(\"file.txt\")      # Modification time\n\n# Directory operations\nDir.glob(\"**/*.rb\")         # Find all Ruby files recursively\nDir.foreach(\"path\") { |file| puts file }\nDir.mkdir(\"new_dir\")\n```\n\n### Regular Expressions\n\n```ruby\n# Pattern matching\ntext = \"Hello, my email is john@example.com\"\n\n# Match operator\ntext =~ /\\w+@\\w+\\.\\w+/      # => 18 (match position)\n\n# Match method\nmatch = text.match(/(\\w+)@(\\w+)\\.(\\w+)/)\nmatch[0]                     # => \"john@example.com\"\nmatch[1]                     # => \"john\"\nmatch[2]                     # => \"example\"\n\n# Named captures\nmatch = text.match(/(?<user>\\w+)@(?<domain>\\w+)\\.(?<tld>\\w+)/)\nmatch[:user]                 # => \"john\"\nmatch[:domain]               # => \"example\"\n\n# Scan for all matches\nemails = text.scan(/\\w+@\\w+\\.\\w+/)\n\n# Replace with regex\ntext.gsub(/\\b\\w{4}\\b/, \"****\")  # Mask 4-letter words\n```\n\n## Testing Ruby Code\n\n### Minitest (Standard Library)\n\n```ruby\nrequire 'minitest/autorun'\n\nclass UserTest < Minitest::Test\n  def setup\n    @user = User.new(name: \"John\", age: 30)\n  end\n\n  def test_adult_with_age_over_18\n    assert @user.adult?\n  end\n\n  def test_name_is_capitalized\n    assert_equal \"John\", @user.name\n  end\n\n  def test_invalid_age_raises_error\n    assert_raises(ArgumentError) do\n      User.new(name: \"John\", age: -5)\n    end\n  end\n\n  def teardown\n    # Cleanup if needed\n  end\nend\n```\n\n### RSpec (Popular Testing Framework)\n\n```ruby\nrequire 'rspec'\n\nRSpec.describe User do\n  let(:user) { User.new(name: \"John\", age: 30) }\n\n  describe '#adult?' do\n    context 'when age is over 18' do\n      it 'returns true' do\n        expect(user.adult?).to be true\n      end\n    end\n\n    context 'when age is under 18' do\n      let(:user) { User.new(name: \"Jane\", age: 15) }\n\n      it 'returns false' do\n        expect(user.adult?).to be false\n      end\n    end\n  end\n\n  describe '#initialize' do\n    it 'raises error for negative age' do\n      expect { User.new(name: \"John\", age: -5) }\n        .to raise_error(ArgumentError, /negative age/)\n    end\n  end\n\n  describe '#name' do\n    it 'returns capitalized name' do\n      expect(user.name).to eq(\"John\")\n    end\n  end\nend\n```\n\n### Testing Best Practices\n\n```ruby\n# 1. Use descriptive test names\ndef test_user_is_adult_when_age_is_over_18\n  # Clear what is being tested\nend\n\n# 2. Arrange-Act-Assert pattern\ndef test_order_total\n  # Arrange\n  order = Order.new\n  order.add_item(item: \"Book\", price: 10)\n  order.add_item(item: \"Pen\", price: 2)\n\n  # Act\n  total = order.total\n\n  # Assert\n  assert_equal 12, total\nend\n\n# 3. Test one thing per test\n# ❌ Bad: Tests multiple things\ndef test_user\n  assert user.valid?\n  assert_equal \"John\", user.name\n  assert_equal 30, user.age\nend\n\n# ✅ Good: Separate tests\ndef test_user_is_valid\n  assert user.valid?\nend\n\ndef test_user_name\n  assert_equal \"John\", user.name\nend\n\n# 4. Use fixtures/factories for test data\n# factories.rb\nFactoryBot.define do\n  factory :user do\n    name { \"John\" }\n    age { 30 }\n    email { \"john@example.com\" }\n  end\nend\n\n# In tests\nuser = create(:user)\nuser_attrs = attributes_for(:user)\n```\n\n## Common Ruby Patterns and Idioms\n\n### Method Chaining (Fluent Interface)\n\n```ruby\nclass QueryBuilder\n  def initialize\n    @conditions = []\n    @order = nil\n  end\n\n  def where(condition)\n    @conditions << condition\n    self  # Return self for chaining\n  end\n\n  def order(field)\n    @order = field\n    self\n  end\n\n  def to_sql\n    sql = \"SELECT * FROM users\"\n    sql += \" WHERE #{@conditions.join(' AND ')}\" unless @conditions.empty?\n    sql += \" ORDER BY #{@order}\" if @order\n    sql\n  end\nend\n\n# Usage\nquery = QueryBuilder.new\n         .where(\"age > 18\")\n         .where(\"active = true\")\n         .order(\"name\")\n         .to_sql\n```\n\n### Builder Pattern\n\n```ruby\nclass UserBuilder\n  def initialize\n    @user = User.new\n  end\n\n  def with_name(name)\n    @user.name = name\n    self\n  end\n\n  def with_email(email)\n    @user.email = email\n    self\n  end\n\n  def build\n    @user\n  end\nend\n\n# Usage\nuser = UserBuilder.new\n        .with_name(\"John\")\n        .with_email(\"john@example.com\")\n        .build\n```\n\n### Null Object Pattern\n\n```ruby\nclass NullUser\n  def name\n    \"Guest\"\n  end\n\n  def admin?\n    false\n  end\n\n  def logged_in?\n    false\n  end\nend\n\nclass UserSession\n  def current_user\n    @current_user || NullUser.new\n  end\nend\n\n# Usage - no nil checks needed\nsession = UserSession.new\nputs session.current_user.name  # \"Guest\" instead of error\n```\n\n### Strategy Pattern\n\n```ruby\n# Define strategies\nclass CreditCardPayment\n  def process(amount)\n    # Credit card logic\n  end\nend\n\nclass PayPalPayment\n  def process(amount)\n    # PayPal logic\n  end\nend\n\n# Use strategy\nclass Order\n  def initialize(payment_strategy)\n    @payment_strategy = payment_strategy\n  end\n\n  def checkout(amount)\n    @payment_strategy.process(amount)\n  end\nend\n\n# Usage\norder = Order.new(CreditCardPayment.new)\norder.checkout(100)\n```\n\n### Observer Pattern\n\n```ruby\nrequire 'observer'\n\nclass Order\n  include Observable\n\n  attr_reader :status\n\n  def status=(new_status)\n    @status = new_status\n    changed\n    notify_observers(self)\n  end\nend\n\nclass Logger\n  def update(order)\n    puts \"Order status changed to: #{order.status}\"\n  end\nend\n\nclass Emailer\n  def update(order)\n    puts \"Sending email about: #{order.status}\"\n  end\nend\n\n# Usage\norder = Order.new\norder.add_observer(Logger.new)\norder.add_observer(Emailer.new)\norder.status = \"shipped\"\n```\n\n## Ruby Code Style and Conventions\n\n### Naming Conventions\n\n```ruby\n# Classes and Modules: PascalCase\nclass UserAccount\nend\n\nmodule PaymentProcessing\nend\n\n# Methods and Variables: snake_case\ndef calculate_total_price\n  total_amount = 0\nend\n\n# Constants: SCREAMING_SNAKE_CASE\nMAX_RETRIES = 3\nDEFAULT_TIMEOUT = 30\n\n# Predicate methods: end with ?\ndef valid?\n  errors.empty?\nend\n\ndef admin?\n  role == 'admin'\nend\n\n# Dangerous methods: end with !\ndef save!  # Raises exception on failure\n  raise \"Invalid\" unless valid?\n  persist\nend\n\ndef downcase!  # Mutates the object\n  @value = @value.downcase\nend\n```\n\n### Code Organization\n\n```ruby\n# Class organization\nclass User\n  # 1. Extend and include statements\n  extend SomeModule\n  include AnotherModule\n\n  # 2. Constants\n  MAX_NAME_LENGTH = 100\n\n  # 3. Attribute macros\n  attr_reader :id\n  attr_accessor :name\n\n  # 4. Class methods\n  def self.find(id)\n    # ...\n  end\n\n  # 5. Initialization\n  def initialize(name)\n    @name = name\n  end\n\n  # 6. Public instance methods\n  def full_name\n    \"#{first_name} #{last_name}\"\n  end\n\n  # 7. Protected methods\n  protected\n\n  def internal_helper\n    # ...\n  end\n\n  # 8. Private methods\n  private\n\n  def calculate_something\n    # ...\n  end\nend\n```\n\n### Ruby Style Guidelines\n\n```ruby\n# Use 2 spaces for indentation\ndef method_name\n  if condition\n    do_something\n  end\nend\n\n# Avoid ternary operators for multi-line\n# ❌ Bad\nresult = some_long_condition ?\n         long_true_value :\n         long_false_value\n\n# ✅ Good\nresult = if some_long_condition\n          long_true_value\n        else\n          long_false_value\n        end\n\n# Use %w for word arrays\n# ❌ Bad\nSTATES = ['draft', 'published', 'archived']\n\n# ✅ Good\nSTATES = %w[draft published archived]\n\n# Use symbols for hash keys\n# ❌ Bad (when strings aren't needed)\n{ 'name' => 'John', 'age' => 30 }\n\n# ✅ Good\n{ name: 'John', age: 30 }\n\n# Use guard clauses\n# ❌ Bad\ndef process(value)\n  if value\n    if value.valid?\n      # ... main logic\n    end\n  end\nend\n\n# ✅ Good\ndef process(value)\n  return unless value\n  return unless value.valid?\n\n  # ... main logic\nend\n\n# Avoid returning from ensure\n# ❌ Bad - return value is ignored\ndef bad_example\n  return 42\nensure\n  return 0  # This overrides!\nend\n\n# ✅ Good\ndef good_example\n  result = 42\nensure\n  cleanup\nend\n```\n\n## Debugging Ruby Code\n\n### Using pry for Debugging\n\n```ruby\nrequire 'pry'\n\ndef complex_method(data)\n  result = transform(data)\n  binding.pry  # Execution pauses here\n  result * 2\nend\n\n# In pry session:\n# - ls: List available methods\n# - show-method method_name: Show method source\n# - cd object: Enter object context\n# - whereami: Show context\n# - continue: Resume execution\n```\n\n### Using ruby/debug (Ruby 3.1+)\n\n```ruby\nrequire 'debug'\n\ndef calculate(x, y)\n  debugger  # Execution pauses here\n  result = x + y\n  result\nend\n\n# Commands:\n# - step: Step into\n# - next: Step over\n# - continue: Resume\n# - info: Show information\n# - break: Set breakpoint\n```\n\n### Logging Best Practices\n\n```ruby\nrequire 'logger'\n\nlogger = Logger.new(STDOUT)\nlogger.level = Logger::INFO\n\n# Different log levels\nlogger.debug(\"Detailed debug information\")\nlogger.info(\"Informational messages\")\nlogger.warn(\"Warning messages\")\nlogger.error(\"Error messages\")\nlogger.fatal(\"Fatal errors\")\n\n# Structured logging\nlogger.info(\"User logged in\") do\n  { user_id: 123, ip: \"192.168.1.1\" }\nend\n```\n\n## Concurrency and Threading\n\n### Thread Basics\n\n```ruby\n# Create threads\nthreads = 3.times.map do |i|\n  Thread.new(i) do |thread_num|\n    puts \"Thread #{thread_num} starting\"\n    sleep 1\n    puts \"Thread #{thread_num} done\"\n  end\nend\n\n# Wait for all threads\nthreads.each(&:join)\n\n# Thread-local variables\nThread.current[:user_id] = 123\nThread.current[:user_id]  # => 123\n```\n\n### Thread Safety\n\n```ruby\n# ❌ Bad: Race condition\nclass Counter\n  def initialize\n    @count = 0\n  end\n\n  def increment\n    @count += 1  # Not atomic!\n  end\nend\n\n# ✅ Good: Thread-safe with mutex\nclass Counter\n  def initialize\n    @count = 0\n    @mutex = Mutex.new\n  end\n\n  def increment\n    @mutex.synchronize do\n      @count += 1\n    end\n  end\nend\n\n# ✅ Better: Use Concurrent::AtomicFixnum\nrequire 'concurrent'\n\ncounter = Concurrent::AtomicFixnum.new(0)\ncounter.increment\n```\n\n### Ractors for Parallelism (Ruby 3.0+)\n\n```ruby\n# True parallel execution\ndef parallel_map(array, &block)\n  ractors = array.map do |item|\n    Ractor.new(item, block) do |value, transform|\n      transform.call(value)\n    end\n  end\n\n  ractors.map(&:take)\nend\n\n# Usage\nresults = parallel_map([1, 2, 3, 4]) { |n| n * 2 }\n# => [2, 4, 6, 8]\n```\n\n## Metaprogramming\n\n### method_missing\n\n```ruby\nclass DynamicAccessor\n  def initialize(data)\n    @data = data\n  end\n\n  def method_missing(method, *args)\n    if @data.key?(method)\n      @data[method]\n    else\n      super\n    end\n  end\n\n  def respond_to_missing?(method, include_private = false)\n    @data.key?(method) || super\n  end\nend\n\n# Usage\nobj = DynamicAccessor.new(name: \"John\", age: 30)\nobj.name  # => \"John\"\nobj.age   # => 30\n```\n\n### define_method\n\n```ruby\nclass Model\n  %w[name email age].each do |attr|\n    define_method(attr) do\n      instance_variable_get(\"@#{attr}\")\n    end\n\n    define_method(\"#{attr}=\") do |value|\n      instance_variable_set(\"@#{attr}\", value)\n    end\n  end\nend\n\n# Creates name, name=, email, email=, age, age= methods\n```\n\n### class_eval and instance_eval\n\n```ruby\n# class_eval: Evaluates in class context\nString.class_eval do\n  def shout\n    upcase + \"!\"\n  end\nend\n\n\"hello\".shout  # => \"HELLO!\"\n\n# instance_eval: Evaluates in instance context\nstr = \"hello\"\nstr.instance_eval do\n  def custom_method\n    \"Custom: #{self}\"\n  end\nend\n\nstr.custom_method  # => \"Custom: hello\"\n```\n\n## Memory and Performance Profiling\n\n### Benchmark Module\n\n```ruby\nrequire 'benchmark'\n\nn = 1_000_000\nBenchmark.bm(20) do |x|\n  x.report(\"Array#each:\") do\n    arr = []\n    n.times { |i| arr << i }\n  end\n\n  x.report(\"Array#map:\") do\n    (0...n).map { |i| i }\n  end\n\n  x.report(\"Array.new:\") do\n    Array.new(n) { |i| i }\n  end\nend\n```\n\n### Memory Profiler\n\n```ruby\nrequire 'memory_profiler'\n\nreport = MemoryProfiler.report do\n  # Code to profile\n  1000.times { \"string\" + \"concatenation\" }\nend\n\nreport.pretty_print\n```\n\n### Ruby Profiler\n\n```ruby\nrequire 'ruby-prof'\n\nresult = RubyProf.profile do\n  # Code to profile\n  10_000.times { expensive_operation }\nend\n\nprinter = RubyProf::FlatPrinter.new(result)\nprinter.print(STDOUT)\n```\n\n## Common Pitfalls and How to Avoid Them\n\n### 1. Modifying Collections During Iteration\n\n```ruby\n# ❌ Bad: Modifies while iterating\narray = [1, 2, 3, 4, 5]\narray.each do |item|\n  array.delete(item) if item.even?  # Unpredictable!\nend\n\n# ✅ Good: Use reject or delete_if\narray.reject! { |item| item.even? }\n# Or\narray.delete_if { |item| item.even? }\n```\n\n### 2. Unintended Global Variable Modification\n\n```ruby\n# ❌ Bad: Global variable\n$user_count = 0\n\n# ✅ Good: Class or instance variable\nclass UserCounter\n  @count = 0\n\n  class << self\n    attr_accessor :count\n  end\nend\n```\n\n### 3. String Concatenation in Loops\n\n```ruby\n# ❌ Bad: Creates many string objects\nresult = \"\"\n1000.times { |i| result += \"#{i} \" }\n\n# ✅ Good: Use array join\nresult = 1000.times.map { |i| \"#{i} \" }.join\n\n# ✅ Better: Use string builder\nresult = String.new\n1000.times { |i| result << \"#{i} \" }\n```\n\n### 4. Forgetting to Return Values\n\n```ruby\n# ❌ Bad: No explicit return\ndef calculate\n  total = items.sum\n  # Implicitly returns total, but unclear\nend\n\n# ✅ Good: Explicit return for clarity\ndef calculate\n  total = items.sum\n  return total\nend\n\n# ✅ Best: Last expression is return value\ndef calculate\n  items.sum\nend\n```\n\n## Framework-Specific Guidance\n\n### Rails-Specific Best Practices\n\n```ruby\n# Use scopes for reusable queries\nclass User < ApplicationRecord\n  scope :active, -> { where(active: true) }\n  scope :recent, -> { where('created_at > ?', 1.week.ago) }\nend\n\n# Use concerns for shared behavior\nmodule Timestampable\n  extend ActiveSupport::Concern\n\n  included do\n    before_save :update_timestamp\n  end\n\n  def update_timestamp\n    self.updated_at = Time.current\n  end\nend\n\n# Use strong parameters\nclass UsersController < ApplicationController\n  def create\n    @user = User.new(user_params)\n    # ...\n  end\n\n  private\n\n  def user_params\n    params.require(:user).permit(:name, :email, :age)\n  end\nend\n\n# Eager loading to avoid N+1 queries\n# ❌ Bad: N+1 query\nusers = User.all\nusers.each { |user| puts user.posts.count }\n\n# ✅ Good: Eager load\nusers = User.includes(:posts).all\nusers.each { |user| puts user.posts.count }\n```\n\n## Quick Reference Commands\n\n```bash\n# Ruby version\nruby -v\n\n# Run Ruby file\nruby script.rb\n\n# Interactive Ruby (IRB)\nirb\n\n# Execute inline Ruby\nruby -e \"puts 'Hello, World!'\"\n\n# Check syntax without executing\nruby -c script.rb\n\n# Run with warnings\nruby -w script.rb\n\n# Install gem\ngem install gem_name\n\n# List installed gems\ngem list\n\n# Update gems\ngem update\n\n# Bundle install (Rails)\nbundle install\n\n# Run tests\nruby test/my_test.rb\nrake test\nrspec spec/\n\n# Ruby documentation\nri String#upcase\nri Array\n\n# Generate documentation\nrdoc\nyard doc\n```\n\n## Resources and Further Learning\n\n- **Official Ruby Documentation**: <https://docs.ruby-lang.org>\n- **Ruby Style Guide**: <https://rubystyle.guide>\n- **Ruby Weekly Newsletter**: <https://rubyweekly.com>\n- **The Ruby Toolbox**: <https://www.ruby-toolbox.com>\n- **RubyGems**: <https://rubygems.org>\n\n## Summary\n\nRuby is designed for developer happiness and productivity. When writing Ruby code:\n\n1. **Write readable code** - Code is read more than it's written\n2. **Follow conventions** - Consistency helps teams collaborate\n3. **Test thoroughly** - Tests give confidence in refactoring\n4. **Handle errors explicitly** - Fail fast and provide context\n5. **Optimize when necessary** - Profile before optimizing\n6. **Embrace Ruby's features** - Use blocks, modules, and metaprogramming appropriately\n7. **Stay current** - Ruby 3.x brings significant improvements\n\nRemember: Ruby rewards simple, expressive code that clearly communicates intent."
              },
              {
                "name": "rubycritic",
                "description": "Integrate RubyCritic to analyze Ruby code quality and maintain high standards throughout development. Use when working on Ruby projects to check code smells, complexity, and duplication. Triggers include creating/editing Ruby files, refactoring code, reviewing code quality, or when user requests code analysis or quality checks.",
                "path": "plugins/ruby-rails/skills/rubycritic/SKILL.md",
                "frontmatter": {
                  "name": "rubycritic",
                  "description": "Integrate RubyCritic to analyze Ruby code quality and maintain high standards throughout development. Use when working on Ruby projects to check code smells, complexity, and duplication. Triggers include creating/editing Ruby files, refactoring code, reviewing code quality, or when user requests code analysis or quality checks."
                },
                "content": "<objective>\nMaintain high code quality standards in Ruby projects by integrating RubyCritic analysis into the development workflow. Automatically detect code smells, complexity issues, and duplication, providing actionable guidance for improvements.\n</objective>\n\n<quick_start>\nRun quality check on Ruby files:\n\n```bash\nscripts/check_quality.sh [path/to/ruby/files]\n```\n\nIf no path is provided, analyzes the current directory. The script automatically installs RubyCritic if missing.\n\n**Immediate feedback**:\n- Overall score (0-100)\n- File ratings (A-F)\n- Specific code smells detected\n</quick_start>\n\n<workflow>\n<automated_quality_checks>\n**Proactive analysis**: Run RubyCritic automatically after significant code changes:\n\n- After creating new Ruby files or classes\n- After implementing complex methods (>10 lines)\n- After refactoring existing code\n- Before marking tasks as complete\n- Before committing code\n\n**Integration pattern**:\n1. Make code changes\n2. Run `scripts/check_quality.sh [changed_files]`\n3. Review output for issues\n4. Address critical smells (if any)\n5. Re-run to verify improvements\n6. Proceed with next task\n\n**When to skip**: Simple variable renames, comment changes, or minor formatting adjustments don't require quality checks.\n</automated_quality_checks>\n\n<interpreting_results>\n**Overall Score**:\n- 95+ (excellent) - Maintain this standard\n- 90-94 (good) - Minor improvements possible\n- 80-89 (acceptable) - Consider refactoring\n- Below 80 - Prioritize improvements\n\n**File Ratings**:\n- A/B - Acceptable quality\n- C - Needs attention\n- D/F - Requires refactoring\n\n**Issue Types**:\n- **Code Smells** (Reek) - Design and readability issues\n- **Complexity** (Flog) - Overly complex methods\n- **Duplication** (Flay) - Repeated code patterns\n</interpreting_results>\n\n<responding_to_issues>\n**Priority order**:\n1. **Critical smells** - Long parameter lists, high complexity, feature envy\n2. **Duplication** - Extract shared methods or modules\n3. **Minor smells** - Unused parameters, duplicate method calls\n4. **Style issues** - Naming, organization\n\n**Incremental fixing**:\n- Fix one issue at a time\n- Run analysis after each fix\n- Verify score improves\n- Explain significant improvements to user\n\n**When scores drop**:\n- Identify which file/method caused the drop\n- Review recent changes in that area\n- Fix immediately before continuing\n- Don't accumulate technical debt\n</responding_to_issues>\n\n<error_handling>\n**Common errors and solutions**:\n\n**\"RubyCritic not found\"**: Script auto-installs, but if it fails:\n- Check Ruby is installed: `ruby --version`\n- Manually install: `gem install rubycritic`\n- Or add to Gemfile: `gem 'rubycritic', require: false`\n\n**\"No files to analyze\"**: Verify path contains `.rb` files\n- Check path is correct\n- Use explicit path: `scripts/check_quality.sh app/models`\n\n**\"Bundler error\"**: Gemfile.lock conflict\n- Run `bundle install` first\n- Or use system gem: `gem install rubycritic && rubycritic [path]`\n\n**Analysis hangs**: Large codebase\n- Analyze specific directories instead of entire project\n- Use `--no-browser` flag to skip HTML generation\n- Consider `.rubycritic.yml` to exclude paths\n\nFor additional error scenarios, see [references/error-handling.md](references/error-handling.md)\n</error_handling>\n</workflow>\n\n<git_hooks_integration>\n**Pre-commit quality checks**: Automatically run RubyCritic before commits:\n\n```bash\n# .git/hooks/pre-commit\n#!/bin/bash\n# Get staged Ruby files\nRUBY_FILES=$(git diff --cached --name-only --diff-filter=ACM | grep '\\.rb$')\n\nif [ -n \"$RUBY_FILES\" ]; then\n  echo \"Running RubyCritic on staged files...\"\n  scripts/check_quality.sh $RUBY_FILES\n\n  if [ $? -ne 0 ]; then\n    echo \"Quality check failed. Fix issues or use --no-verify to skip.\"\n    exit 1\n  fi\nfi\n```\n\n**CI integration**: Add to GitHub Actions, GitLab CI, or other CI systems:\n\n```yaml\n# .github/workflows/quality.yml\n- name: Run RubyCritic\n  run: |\n    gem install rubycritic\n    rubycritic --format json --minimum-score 90\n```\n\nFor complete git hooks setup and CI examples, see [references/git-hooks.md](references/git-hooks.md)\n</git_hooks_integration>\n\n<configuration>\n**Basic configuration** (`.rubycritic.yml`):\n\n```yaml\nminimum_score: 95\nformats:\n  - console\npaths:\n  - 'app/'\n  - 'lib/'\nno_browser: true\n```\n\n**Common options**:\n- `minimum_score`: Fail if score below this threshold\n- `formats`: Output formats (console, html, json)\n- `paths`: Directories to analyze\n- `no_browser`: Don't auto-open HTML report\n\nFor advanced configuration and custom thresholds, see [references/configuration.md](references/configuration.md)\n</configuration>\n\n<common_patterns>\n**Quick quality check during development**:\n```bash\n# Check recently modified files\nscripts/check_quality.sh $(git diff --name-only | grep '\\.rb$')\n```\n\n**Generate detailed HTML report**:\n```bash\nbundle exec rubycritic --format html app/\n# Opens browser with detailed analysis\n```\n\n**Compare with main branch** (CI mode):\n```bash\nrubycritic --mode-ci --branch main app/\n# Shows only changes from main branch\n```\n\n**Check specific file types**:\n```bash\nscripts/check_quality.sh app/models/*.rb\nscripts/check_quality.sh app/services/**/*.rb\n```\n</common_patterns>\n\n<code_smell_reference>\nFor detailed examples of common code smells and how to fix them, see [references/code_smells.md](references/code_smells.md)\n\n**Quick reference**:\n- **Control Parameter** - Replace boolean params with separate methods\n- **Feature Envy** - Move method to the class it uses most\n- **Long Parameter List** - Use parameter objects or hashes\n- **High Complexity** - Extract methods, use early returns\n- **Duplication** - Extract to shared methods or modules\n</code_smell_reference>\n\n<installation>\n**Automatic installation**: The `check_quality.sh` script handles installation automatically:\n\n- Detects if RubyCritic is installed\n- Uses bundler if Gemfile present\n- Falls back to system gem installation\n- Adds to Gemfile development group if needed\n\n**Manual installation**:\n\nWith Bundler:\n```ruby\n# Gemfile\ngroup :development do\n  gem 'rubycritic', require: false\nend\n```\n\nSystem-wide:\n```bash\ngem install rubycritic\n```\n</installation>\n\n<success_criteria>\nRubyCritic is successfully integrated when:\n\n- Quality checks run automatically after significant code changes\n- Overall score maintained at 90+ (or project-defined threshold)\n- Critical code smells addressed immediately\n- Quality improvements explained to user when significant\n- No quality regressions introduced by changes\n- Files maintain A or B ratings\n</success_criteria>\n\n<reference_guides>\n**Detailed references**:\n- [references/code_smells.md](references/code_smells.md) - Common smells and fixes with examples\n- [references/configuration.md](references/configuration.md) - Advanced RubyCritic configuration\n- [references/git-hooks.md](references/git-hooks.md) - Pre-commit hooks and CI integration\n- [references/error-handling.md](references/error-handling.md) - Troubleshooting common errors\n</reference_guides>"
              },
              {
                "name": "sandi-metz-reviewer",
                "description": "Code review agent based on Sandi Metz's object-oriented design principles from \"Practical Object-Oriented Design in Ruby\" and \"99 Bottles of OOP\". Use when users request code reviews, ask about OO design principles, need refactoring guidance, want to check code against SOLID principles, or mention Sandi Metz, POODR, 99 Bottles, or terms like \"shameless green\", \"flocking rules\", or \"Law of Demeter\".",
                "path": "plugins/ruby-rails/skills/sandi-metz-reviewer/SKILL.md",
                "frontmatter": {
                  "name": "sandi-metz-reviewer",
                  "description": "Code review agent based on Sandi Metz's object-oriented design principles from \"Practical Object-Oriented Design in Ruby\" and \"99 Bottles of OOP\". Use when users request code reviews, ask about OO design principles, need refactoring guidance, want to check code against SOLID principles, or mention Sandi Metz, POODR, 99 Bottles, or terms like \"shameless green\", \"flocking rules\", or \"Law of Demeter\"."
                },
                "content": "# Sandi Metz Code Reviewer\n\nReview code using Sandi Metz's principles: Single Responsibility, SOLID, Law of Demeter, \"Tell Don't Ask\", and the four famous rules (classes ≤100 lines, methods ≤5 lines, parameters ≤4, instance variables ≤4).\n\n## Quick Start\n\nFor code review requests, follow this workflow:\n\n1. **Parse the code** - Understand structure: classes, methods, dependencies\n2. **Apply checks** - Run through all principle categories\n3. **Provide feedback** - Clear issues with actionable suggestions\n4. **Format output** - Organized by principle with severity levels\n\n## Review Checks\n\n### 1. Sandi Metz's Four Rules\n\nCheck every class and method:\n\n- **Classes**: Max 100 lines\n- **Methods**: Max 5 lines (excluding blank lines and end statements)\n- **Parameters**: Max 4 per method\n- **Instance Variables**: Max 4 per class\n\n**Violation format**: \"Class 'OrderManager' has 127 lines (max: 100)\"\n**Suggestion**: \"Extract responsibilities into collaborating classes. Ask: Can this class be described in one sentence?\"\n\n### 2. Single Responsibility Principle (SRP)\n\nIndicators of violations:\n\n- Class has >7 public methods → Too many responsibilities\n- Method name contains \"and\" → Doing multiple things\n- Method doesn't use any instance variables → Feature Envy, belongs elsewhere\n- Hard to describe class in one sentence → Multiple responsibilities\n\n**Key question to suggest**: \"Can you describe this class/method in one sentence without using 'and'?\"\n\n### 3. Dependency Management\n\nCheck for:\n\n- **Explicit instantiation** (`ClassName.new`) → Suggest dependency injection\n- **Message chains** (`object.property.method.value`) → Law of Demeter violation\n- **Inappropriate intimacy** (accessing internals of other objects) → Use proper interfaces\n\n**Law of Demeter**: \"Only talk to immediate friends\"\n- ✅ `self.method`\n- ✅ `method_parameter.method`\n- ✅ `@instance_variable.method`\n- ❌ `object.attribute.another_attribute.method`\n\n### 4. Tell, Don't Ask\n\nAnti-pattern:\n```ruby\nif user.admin?\n  user.delete_all\nend\n```\n\nBetter:\n```ruby\nuser.perform_admin_action(:delete_all)\n```\n\n**Principle**: Objects should make their own decisions, not have their state queried and then acted upon.\n\n### 5. Open/Closed Principle\n\nIdentify candidates for polymorphism:\n\n- **Case statements** on type → Create subclasses with polymorphic behavior\n- **If-elsif chains** based on type → Replace with strategy pattern\n- **Type checking** (`if object.is_a?(Type)`) → Use duck typing or polymorphism\n\n**Pattern from 99 Bottles**: Replace conditionals with polymorphic message sends to objects that know their own behavior.\n\n### 6. Code Smells (18 types)\n\n**Structural**:\n- Long Method (>5 lines)\n- Large Class (>100 lines) \n- Long Parameter List (>4 params)\n- Data Clump (same params together repeatedly)\n\n**Coupling**:\n- Feature Envy (method uses data from another class more than own)\n- Message Chains (Law of Demeter violations)\n- Inappropriate Intimacy (classes too tightly coupled)\n\n**Conditional Logic**:\n- Conditional Complexity (nested if-elsif)\n- Case Statements (candidate for polymorphism)\n- Speculative Generality (code added \"just in case\")\n\n**Naming**:\n- Vague names (Manager, Handler, Processor, Data)\n- Methods with \"and\" (doing multiple things)\n- Flag parameters (boolean params that change behavior)\n\n**Comments**:\n- Comments explaining \"what\" code does → Code should be self-documenting\n- Keep comments that explain \"why\" decisions were made\n\n### 7. Naming Conventions\n\nPoor names that indicate design problems:\n\n- **Classes**: Manager, Handler, Processor, Controller, Helper, Util\n- **Methods**: process, handle, manage, do, data, info\n- **With \"and\"**: `save_and_send` → Should be two methods\n\n**Principle**: Names should reveal intent. If you can't name it clearly, it probably has unclear responsibilities.\n\n## Output Format\n\nStructure feedback by principle area:\n\n```\n📏 SANDI METZ'S FOUR RULES\n✓ Pass: Class 'Order' size good (45 lines)\n⚠️  Warning: Method 'process' has 12 lines (max: 5) [line 23]\n    💡 Extract smaller methods with intention-revealing names\n\n🎯 SINGLE RESPONSIBILITY\nℹ️  Info: Class 'OrderManager' has 9 public methods [line 1]\n    💡 Ask: Can this class be described in one sentence?\n\n🔗 DEPENDENCIES\n❌ Error: Message chain detected: customer.address.street.name [line 45]\n    💡 Use delegation. Add customer.street_name method\n\n💬 TELL, DON'T ASK  \n⚠️  Warning: Conditional based on object query [line 67]\n    💡 Let objects make their own decisions\n\n📊 SUMMARY\n✓ Passes: 12\nℹ️  Info: 5\n⚠️  Warnings: 8\n❌ Errors: 2\n```\n\n## Severity Levels\n\n- **❌ Error**: Serious violations (accessing internals, tight coupling)\n- **⚠️  Warning**: Rule violations, should be fixed\n- **ℹ️  Info**: Suggestions, best practices\n- **✓ Pass**: Correctly following principles\n\n## Shameless Green Philosophy\n\nFrom 99 Bottles of OOP - encourage this refactoring approach:\n\n1. **Start with Shameless Green** - Write simplest code that works\n2. **Wait for duplication** - Don't abstract too early\n3. **Follow Flocking Rules**:\n   - Find things that are most alike\n   - Find smallest difference between them  \n   - Make simplest change to remove difference\n4. **Converge on abstractions** - Let patterns emerge\n\n**Key wisdom**: \"Make the change easy, then make the easy change\"\n\n## Refactoring Patterns\n\nSuggest these when appropriate:\n\n**Extract Method**: When methods too long\n```ruby\n# Before: 15-line method\n# After: 3-line method calling 3 extracted methods (each ≤5 lines)\n```\n\n**Extract Class**: When classes have too many responsibilities\n```ruby\n# Before: OrderManager with 8 instance variables\n# After: Order + Payment + Shipping (each with ≤4 instance variables)\n```\n\n**Replace Conditional with Polymorphism**: For case/if-elsif on type\n```ruby\n# Before: case type when 'book'... when 'electronics'...\n# After: Book.price, Electronics.price (each knows own behavior)\n```\n\n**Introduce Parameter Object**: For long parameter lists\n```ruby\n# Before: create_order(name, email, street, city, state, zip)\n# After: create_order(customer_info)\n```\n\n## Code Examples\n\nWhen showing before/after examples, keep them concise:\n\n**Before** (violations):\n```ruby\nclass OrderManager\n  def process(name, email, address, phone, items, discount, method)\n    # 20 lines of nested conditionals\n  end\nend\n```\n\n**After** (principles applied):\n```ruby\nclass Order\n  def total\n    items.sum(&:price) - discount.amount\n  end\nend\n\nclass Discount\n  def amount\n    # polymorphic behavior\n  end\nend\n```\n\n## When Breaking Rules is OK\n\nSandi Metz: \"Break them only if you have a good reason and you've tried not to.\"\n\nIf user has broken a rule intentionally, acknowledge it and ask if they want alternatives or if the violation is justified.\n\n## References\n\nFor deeper understanding, the skill is based on:\n- **Practical Object-Oriented Design in Ruby** (POODR) by Sandi Metz\n- **99 Bottles of OOP** by Sandi Metz, Katrina Owen, TJ Stankus\n\nKey talks (available online):\n- \"Nothing is Something\" - RailsConf 2015\n- \"All the Little Things\" - RailsConf 2014\n\n## Execution Notes\n\n- Focus on one principle area at a time\n- Provide specific line numbers when possible\n- Always include actionable suggestions, not just criticism\n- Celebrate what's done well (✓ Pass messages)\n- Keep feedback encouraging - design is about making code easier to change, not achieving perfection"
              },
              {
                "name": "simplecov",
                "description": "Comprehensive test coverage analysis and improvement for Ruby and Rails applications using SimpleCov and SimpleCov Console formatter. Automatically runs coverage reports, identifies gaps, suggests tests, and enforces coverage standards. Integrates with RubyCritic for holistic code quality. Use when running tests, analyzing coverage, improving test suites, or setting up coverage tracking in Ruby/Rails projects.",
                "path": "plugins/ruby-rails/skills/simplecov/SKILL.md",
                "frontmatter": {
                  "name": "simplecov",
                  "description": "Comprehensive test coverage analysis and improvement for Ruby and Rails applications using SimpleCov and SimpleCov Console formatter. Automatically runs coverage reports, identifies gaps, suggests tests, and enforces coverage standards. Integrates with RubyCritic for holistic code quality. Use when running tests, analyzing coverage, improving test suites, or setting up coverage tracking in Ruby/Rails projects."
                },
                "content": "# SimpleCov Test Coverage Agent\n\n## Overview\n\nMaintain high test coverage in Ruby and Rails applications through automated analysis using SimpleCov as the coverage engine and SimpleCov Console for terminal output. This skill identifies coverage gaps, suggests targeted tests, and enforces quality standards alongside RubyCritic for comprehensive code quality feedback.\n\n## Core Capabilities\n\n### 1. Setup and Configuration\n\nConfigure SimpleCov for any Ruby/Rails project with best practices:\n\n**Initial Setup:**\n\n```bash\n# Add to Gemfile\necho \"gem 'simplecov', require: false, group: :test\" >> Gemfile\necho \"gem 'simplecov-console', require: false, group: :test\" >> Gemfile\nbundle install\n```\n\n**Create .simplecov Configuration:**\n\n```ruby\nSimpleCov.start 'rails' do\n  formatter SimpleCov::Formatter::MultiFormatter.new([\n    SimpleCov::Formatter::HTMLFormatter,\n    SimpleCov::Formatter::Console\n  ])\n\n  # Enable branch coverage (Ruby 2.5+)\n  enable_coverage :branch\n  primary_coverage :branch\n\n  # Set thresholds\n  minimum_coverage line: 90, branch: 80\n  minimum_coverage_by_file 80\n  refuse_coverage_drop :line, :branch\n\n  # Standard Rails filters\n  add_filter '/test/'\n  add_filter '/spec/'\n  add_filter '/config/'\n  add_filter '/vendor/'\n\n  # Organize by application layers\n  add_group 'Controllers', 'app/controllers'\n  add_group 'Models', 'app/models'\n  add_group 'Services', 'app/services'\n  add_group 'Jobs', 'app/jobs'\n  add_group 'Mailers', 'app/mailers'\n  add_group 'Helpers', 'app/helpers'\n  add_group 'Libraries', 'lib'\nend\n```\n\n**Console Formatter Options:**\n\n```ruby\n# Customize output in .simplecov\nSimpleCov::Formatter::Console.use_colors = true\nSimpleCov::Formatter::Console.sort = 'coverage'  # or 'path'\nSimpleCov::Formatter::Console.show_covered = false\nSimpleCov::Formatter::Console.max_rows = 15\nSimpleCov::Formatter::Console.output_style = 'table'  # or 'block'\n```\n\n**Test Helper Integration (CRITICAL - Must be FIRST):**\n\n```ruby\n# test/test_helper.rb or spec/spec_helper.rb\nrequire 'simplecov'\nSimpleCov.start 'rails'\n\n# Now load application\nENV['RAILS_ENV'] ||= 'test'\nrequire_relative '../config/environment'\n# ... rest of test helper\n```\n\n### 2. Running Coverage Analysis\n\n**Standard Test Execution:**\n\n```bash\n# Minitest\nbundle exec rake test\n\n# RSpec\nbundle exec rspec\n\n# Cucumber\nbundle exec cucumber\n\n# Specific test files\nbundle exec ruby -Itest test/models/user_test.rb\n```\n\nSimpleCov automatically tracks coverage and generates reports after test completion.\n\n**Console Output Example:**\n\n```bash\nCOVERAGE: 82.34% -- 2345/2848 lines in 111 files\nBRANCH COVERAGE: 78.50% -- 157/200 branches\n\nshowing bottom (worst) 15 of 69 files\n+----------+----------------------------------------------+-------+--------+----------------------+\n| coverage | file                                         | lines | missed | missing              |\n+----------+----------------------------------------------+-------+--------+----------------------+\n| 22.73%   | lib/websocket_server.rb                      | 22    | 17     | 11, 14, 17-18, 20-22 |\n| 30.77%   | app/models/role.rb                           | 13    | 9      | 28-34, 36-37         |\n| 42.86%   | lib/mail_handler.rb                          | 14    | 8      | 6-8, 12-15, 22       |\n| 45.00%   | app/services/payment_processor.rb            | 80    | 44     | 15-22, 35-48, ...    |\n+----------+----------------------------------------------+-------+--------+----------------------+\n\n42 file(s) with 100% coverage not shown\n```\n\n**HTML Report:**\n\n```bash\n# Open detailed browser report\nopen coverage/index.html  # macOS\nxdg-open coverage/index.html  # Linux\n```\n\n### 3. Identifying and Addressing Coverage Gaps\n\n**Gap Analysis Workflow:**\n\n1. **Locate worst coverage files** from console output\n2. **Examine specific uncovered lines**\n3. **Categorize gap types:**\n   - Edge cases and error conditions\n   - Branch paths (if/else, case/when)\n   - Private methods not exercised through public API\n   - Callback sequences\n   - Complex conditionals\n\n4. **Determine appropriate test type:**\n   - Unit tests: Business logic, calculations, validations\n   - Integration tests: Multi-object workflows\n   - System tests: Full user interactions\n   - Request/controller tests: HTTP endpoints\n\n5. **Write targeted tests**\n6. **Verify improvement**\n\n**Example: Improving Payment Processor Coverage**\n\nSimpleCov shows: `45.00% | app/services/payment_processor.rb | 80 | 44`\n\n```bash\n# View the file with line numbers\ncat -n app/services/payment_processor.rb | grep -A2 -B2 \"15\\|16\\|17\"\n```\n\nUncovered lines reveal:\n\n- Lines 15-18: Retry logic for failed charges\n- Lines 35-40: Refund processing\n- Lines 45-48: Webhook handling\n\n**Add Comprehensive Tests:**\n\n```ruby\n# test/services/payment_processor_test.rb\nrequire 'test_helper'\n\nclass PaymentProcessorTest < ActiveSupport::TestCase\n  test \"retries failed charges up to 3 times\" do\n    order = orders(:pending)\n\n    # Simulate failures then success\n    Stripe::Charge.expects(:create)\n      .times(2)\n      .raises(Stripe::CardError.new('declined', nil))\n    Stripe::Charge.expects(:create)\n      .returns(stripe_charge)\n\n    processor = PaymentProcessor.new(order)\n    assert processor.charge\n    assert_equal 3, processor.attempt_count\n  end\n\n  test \"processes refunds correctly\" do\n    order = orders(:paid)\n\n    processor = PaymentProcessor.new(order)\n    refund = processor.refund_payment\n\n    assert refund.succeeded?\n    assert_equal order.total, refund.amount\n    assert_equal 'refunded', order.reload.status\n  end\n\n  test \"handles webhook events appropriately\" do\n    event = stripe_events(:charge_succeeded)\n\n    processor = PaymentProcessor.new\n    processor.handle_webhook(event)\n\n    order = Order.find_by(stripe_charge_id: event.data.object.id)\n    assert_equal 'paid', order.status\n  end\nend\n```\n\n### 4. Branch Coverage Analysis\n\nBranch coverage tracks whether both paths of conditionals are tested.\n\n**Understanding Branch Reports:**\n\n```\n| 72.22% | app/services/discount_calculator.rb | 4 | 1 | branch: 75% | 4 | 1 | 3[else] |\n```\n\nThis shows:\n\n- Line coverage: 72.22% (4 lines, 1 missed)\n- Branch coverage: 75% (4 branches, 1 missed)\n- Missing branch: Line 3's else path\n\n**Example Code:**\n\n```ruby\ndef calculate_discount(order)\n  return 0 if order.total < 50  # Branch: true/false\n\n  discount = order.total * 0.1\n  discount > 10 ? 10 : discount  # Branch: true/false\nend\n```\n\n**Complete Branch Coverage:**\n\n```ruby\ntest \"returns 0 for small orders\" do\n  order = Order.new(total: 30)\n  assert_equal 0, DiscountCalculator.calculate_discount(order)  # Tests true branch line 2\nend\n\ntest \"returns percentage discount for medium orders\" do\n  order = Order.new(total: 75)\n  assert_equal 7.5, DiscountCalculator.calculate_discount(order)  # Tests false branch line 2, false branch line 5\nend\n\ntest \"caps discount at maximum\" do\n  order = Order.new(total: 200)\n  assert_equal 10, DiscountCalculator.calculate_discount(order)  # Tests true branch line 5\nend\n```\n\n### 5. Multi-Suite Coverage Merging\n\nSimpleCov automatically merges results from multiple test suites run within the merge_timeout (default 10 minutes).\n\n**Configuration:**\n\n```ruby\n# .simplecov\nSimpleCov.start 'rails' do\n  merge_timeout 3600  # 1 hour\n\n  # Optional: explicit command names\n  command_name \"Test Suite #{ENV['TEST_ENV_NUMBER'] || Process.pid}\"\nend\n```\n\n**Running Multiple Suites:**\n\n```bash\n# Run all test types - SimpleCov merges automatically\nbundle exec rake test\nbundle exec rspec\nbundle exec cucumber\n\n# View combined coverage\nopen coverage/index.html\n```\n\n**Parallel Test Support:**\n\n```ruby\n# test/test_helper.rb\nrequire 'simplecov'\n\nSimpleCov.start 'rails' do\n  command_name \"Test #{ENV['TEST_ENV_NUMBER']}\"\nend\n```\n\n```bash\nbundle exec parallel_test test/ -n 4\n```\n\n### 6. CI/CD Integration\n\n**GitHub Actions:**\n\n```yaml\n# .github/workflows/test.yml\nname: Tests with Coverage\n\non: [push, pull_request]\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n\n    steps:\n      - uses: actions/checkout@v3\n\n      - name: Setup Ruby\n        uses: ruby/setup-ruby@v1\n        with:\n          ruby-version: 3.2\n          bundler-cache: true\n\n      - name: Setup Database\n        run: |\n          bundle exec rails db:create\n          bundle exec rails db:schema:load\n\n      - name: Run tests with coverage\n        run: bundle exec rake test\n\n      - name: Check coverage thresholds\n        run: |\n          if [ $? -ne 0 ]; then\n            echo \"❌ Coverage below threshold\"\n            exit 1\n          fi\n\n      - name: Upload coverage artifacts\n        uses: actions/upload-artifact@v3\n        if: always()\n        with:\n          name: coverage-report\n          path: coverage/\n```\n\n**CI-Specific Configuration:**\n\n```ruby\n# .simplecov\nSimpleCov.start 'rails' do\n  if ENV['CI']\n    # Use console formatter only in CI\n    formatter SimpleCov::Formatter::Console\n\n    # Strict enforcement\n    minimum_coverage line: 90, branch: 80\n    refuse_coverage_drop :line, :branch\n\n    # More aggressive thresholds\n    minimum_coverage_by_file 85\n  else\n    # Development: HTML + Console\n    formatter SimpleCov::Formatter::MultiFormatter.new([\n      SimpleCov::Formatter::HTMLFormatter,\n      SimpleCov::Formatter::Console\n    ])\n  end\nend\n```\n\n### 7. Integration with RubyCritic\n\nCombine SimpleCov with RubyCritic for comprehensive code quality analysis:\n\n**Combined Analysis:**\n\n```bash\n# 1. Run tests with coverage\nbundle exec rake test\n\n# 2. Run RubyCritic\nbundle exec rubycritic app lib --format console\n\n# 3. Review both reports\nopen coverage/index.html\nopen tmp/rubycritic/overview.html\n```\n\n**Prioritization Matrix:**\n\n| Complexity | Coverage | Priority | Action                        |\n| ---------- | -------- | -------- | ----------------------------- |\n| High       | Low      | CRITICAL | Add tests + refactor          |\n| High       | High     | High     | Refactor with test safety net |\n| Low        | Low      | Medium   | Add tests                     |\n| Low        | High     | Low      | Well-maintained               |\n\n**Example Combined Analysis:**\n\n```\nSimpleCov: 45% coverage | app/services/order_processor.rb | 80 lines | 44 missed\nRubyCritic: Score D | Complexity 25 | Churn 15\n\nInterpretation:\n- High complexity (25) indicates difficult to understand/maintain\n- High churn (15) shows frequent changes\n- Low coverage (45%) means changes are risky\n\nAction Plan:\n1. Write characterization tests for current behavior (increase coverage to ~70%)\n2. Refactor to reduce complexity while tests protect against regression\n3. Achieve 90%+ coverage on simplified code\n4. Monitor churn - frequent changes may indicate unclear requirements\n```\n\n## Advanced Features\n\n### Conditional Coverage (On-Demand)\n\nRun coverage only when explicitly requested:\n\n```ruby\n# test/test_helper.rb\nSimpleCov.start if ENV['COVERAGE']\n```\n\n```bash\n# Without coverage\nbundle exec rake test\n\n# With coverage\nCOVERAGE=true bundle exec rake test\n```\n\n### Nocov Exclusions\n\nExclude specific code sections:\n\n```ruby\n# :nocov:\ndef debugging_helper\n  # Development-only code not covered\n  puts \"Debug: #{inspect}\"\nend\n# :nocov:\n\n# Custom token\nSimpleCov.nocov_token 'skip_coverage'\n\n# skip_coverage\ndef skip_this_method\nend\n# skip_coverage\n```\n\n### Custom Filters and Groups\n\n**Advanced Filtering:**\n\n```ruby\nSimpleCov.start 'rails' do\n  # Exclude short files\n  add_filter do |source_file|\n    source_file.lines.count < 5\n  end\n\n  # Exclude files by complexity\n  add_filter do |source_file|\n    # Could integrate complexity metrics\n    source_file.lines.count > 500\n  end\n\n  # Array of filters\n  add_filter [\"/test/\", \"/spec/\", \"/config/\"]\nend\n```\n\n**Custom Groups:**\n\n```ruby\nSimpleCov.start 'rails' do\n  add_group \"Services\", \"app/services\"\n  add_group \"Jobs\", \"app/jobs\"\n  add_group \"API\", \"app/controllers/api\"\n\n  add_group \"Long Files\" do |src_file|\n    src_file.lines.count > 100\n  end\n\n  add_group \"Business Logic\" do |src_file|\n    src_file.filename =~ /(models|services|lib)/\n  end\nend\n```\n\n### Subprocess Coverage\n\nTrack coverage in forked processes:\n\n```ruby\nSimpleCov.enable_for_subprocesses true\n\nSimpleCov.at_fork do |pid|\n  SimpleCov.command_name \"#{SimpleCov.command_name} (subprocess: #{pid})\"\n  SimpleCov.print_error_status = false\n  SimpleCov.formatter SimpleCov::Formatter::SimpleFormatter\n  SimpleCov.minimum_coverage 0\n  SimpleCov.start\nend\n```\n\n### Coverage for Spawned Processes\n\nFor processes started with PTY.spawn, Open3.popen, etc:\n\n```ruby\n# .simplecov_spawn.rb\nrequire 'simplecov'\nSimpleCov.command_name 'spawn'\nSimpleCov.at_fork.call(Process.pid)\nSimpleCov.start\n```\n\n```ruby\n# In test\nPTY.spawn('ruby -r./.simplecov_spawn my_script.rb') do\n  # ...\nend\n```\n\n## Troubleshooting\n\n### Coverage Shows 0% or Missing Files\n\n**Problem:** SimpleCov doesn't track files or shows 0%.\n\n**Cause:** SimpleCov loaded after application code.\n\n**Solution:** Ensure SimpleCov starts FIRST:\n\n```ruby\n# ✅ CORRECT\nrequire 'simplecov'\nSimpleCov.start 'rails'\nrequire_relative '../config/environment'\n\n# ❌ WRONG\nrequire_relative '../config/environment'\nrequire 'simplecov'\nSimpleCov.start\n```\n\n### Spring Conflicts\n\n**Problem:** Inaccurate coverage with Spring.\n\n**Solutions:**\n\n```ruby\n# Option 1: Eager load\nrequire 'simplecov'\nSimpleCov.start 'rails'\nRails.application.eager_load!\n\n# Option 2: Disable Spring for coverage\n# DISABLE_SPRING=1 bundle exec rake test\n\n# Option 3: Remove Spring\n# Remove gem 'spring' from Gemfile\n```\n\n### Parallel Test Conflicts\n\n**Problem:** Results overwrite each other.\n\n**Solution:**\n\n```ruby\nSimpleCov.start 'rails' do\n  command_name \"Test #{ENV['TEST_ENV_NUMBER'] || Process.pid}\"\nend\n```\n\n### Branch Coverage Not Showing\n\n**Problem:** Branch coverage is 0% or missing.\n\n**Requirements:**\n\n- Ruby 2.5 or later\n- Must explicitly enable\n\n**Solution:**\n\n```ruby\nSimpleCov.start do\n  enable_coverage :branch\n  primary_coverage :branch\nend\n```\n\n### Old Cached Results\n\n**Problem:** Coverage seems incorrect or stale.\n\n**Solution:**\n\n```bash\n# Clear cache\nrm -rf coverage/\nbundle exec rake test\n\n# Or increase merge timeout\nSimpleCov.merge_timeout 7200  # 2 hours\n```\n\n## Best Practices\n\n### 1. Start Early\n\nSet up SimpleCov at project inception to establish baselines and track progress from day one.\n\n### 2. Set Achievable Thresholds\n\nStart with realistic targets (80-85%) and increase gradually. Avoid demanding 100% immediately.\n\n### 3. Track Both Line and Branch Coverage\n\nBranch coverage reveals untested conditional paths that line coverage misses.\n\n```ruby\nminimum_coverage line: 90, branch: 80\n```\n\n### 4. Prioritize Business Logic\n\nFocus coverage efforts on:\n\n- Domain models\n- Service objects\n- Complex calculations\n- Critical user flows\n\nLess critical:\n\n- View helpers\n- Configuration files\n- Simple CRUD controllers\n\n### 5. Make Coverage Part of Code Review\n\nInclude coverage reports in PR reviews. Block PRs that drop coverage without justification.\n\n```ruby\nrefuse_coverage_drop :line, :branch\n```\n\n### 6. Don't Chase 100% Blindly\n\nFocus on meaningful tests over coverage percentage. Some code (error logging, debugging helpers) may not need testing.\n\n### 7. Use Appropriate Grouping\n\nOrganize reports by architecture to identify weak layers:\n\n```ruby\nadd_group \"Domain Models\", \"app/models\"\nadd_group \"Business Logic\", \"app/services\"\nadd_group \"Background Jobs\", \"app/jobs\"\nadd_group \"API\", \"app/controllers/api\"\n```\n\n### 8. Filter Wisely\n\nExclude generated code, migrations, and test infrastructure:\n\n```ruby\nadd_filter '/db/migrate/'\nadd_filter '/test/'\nadd_filter '/config/initializers/'\nadd_filter '/vendor/'\n```\n\n### 9. Merge All Test Suites\n\nEnsure coverage reflects complete test suite execution:\n\n```bash\nbundle exec rake test      # Unit/integration\nbundle exec rspec          # Specs\nbundle exec cucumber       # Features\n# SimpleCov merges automatically\n```\n\n### 10. Enforce in CI/CD\n\nPrevent coverage degradation by failing builds:\n\n```ruby\nif ENV['CI']\n  minimum_coverage line: 90, branch: 80\n  refuse_coverage_drop :line, :branch\nend\n```\n\n## Common Patterns\n\n### Pre-commit Hook\n\n```bash\n#!/bin/bash\n# .git/hooks/pre-commit\n\necho \"Running tests with coverage...\"\nCOVERAGE=true bundle exec rake test\n\nif [ $? -ne 0 ]; then\n  echo \"❌ Coverage check failed\"\n  exit 1\nfi\n\necho \"✅ Coverage acceptable\"\n```\n\n### Coverage Summary Script\n\n```ruby\n# scripts/coverage_summary.rb\nrequire 'json'\n\ndata = JSON.parse(File.read('coverage/.resultset.json'))\ncoverage = data.values.first.dig('coverage', 'lines')\n\ntotal = coverage.size\ncovered = coverage.compact.count { |x| x > 0 }\npct = (covered.to_f / total * 100).round(2)\n\nputs \"Coverage: #{pct}% (#{covered}/#{total} lines)\"\n\nexit 1 if pct < 90\n```\n\n### Watch Mode for TDD\n\n```bash\n# Use guard-minitest or guard-rspec\nbundle exec guard\n\n# Gemfile\ngroup :development, :test do\n  gem 'guard-minitest'\nend\n\n# Guardfile\nguard :minitest do\n  watch(%r{^test/(.*)/?(.*)_test\\.rb$})\n  watch(%r{^app/(.+)\\.rb$}) { |m| \"test/#{m[1]}_test.rb\" }\nend\n```\n\n## Resources\n\n### Scripts\n\nSee `scripts/` for coverage analysis utilities (if provided).\n\n### References\n\nSee `references/` for:\n\n- Advanced configuration examples\n- CI/CD integration patterns\n- Coverage analysis methodologies\n\n## External References\n\n- [SimpleCov Documentation](https://github.com/simplecov-ruby/simplecov)\n- [SimpleCov Console Formatter](https://github.com/chetan/simplecov-console)\n- [Ruby Coverage Library](https://docs.ruby-lang.org/en/master/Coverage.html)\n- [RubyCritic Integration](https://github.com/whitesmith/rubycritic)"
              }
            ]
          },
          {
            "name": "ghpm",
            "description": "GitHub Project Management workflow for product development: PRD creation, epic/task breakdown, TDD execution, and QA planning",
            "source": "./plugins/ghpm",
            "category": null,
            "version": "0.3.0",
            "author": {
              "name": "Jeb Coleman"
            },
            "install_commands": [
              "/plugin marketplace add el-feo/ai-context",
              "/plugin install ghpm@jebs-dev-tools"
            ],
            "signals": {
              "stars": 0,
              "forks": 0,
              "pushed_at": "2026-01-12T05:23:19Z",
              "created_at": "2025-03-11T20:00:10Z",
              "license": "MIT"
            },
            "commands": [
              {
                "name": "/changelog",
                "description": "Generate a changelog from merged PRs using conventional commits format.",
                "path": "plugins/ghpm/commands/changelog.md",
                "frontmatter": {
                  "description": "Generate a changelog from merged PRs using conventional commits format.",
                  "allowed-tools": [
                    "Bash",
                    "Read",
                    "Write"
                  ],
                  "arguments": {
                    "from": {
                      "description": "Starting reference (tag, commit, or date): from=v1.0.0 or from=2024-01-01",
                      "required": false
                    },
                    "to": {
                      "description": "Ending reference (default: HEAD): to=v1.1.0 or to=main",
                      "required": false
                    },
                    "output": {
                      "description": "Output file path (default: CHANGELOG.md): output=docs/CHANGELOG.md",
                      "required": false
                    }
                  }
                },
                "content": "<objective>\nGenerate a changelog from merged PRs and commits that follow Conventional Commits format. Group changes by type (Features, Bug Fixes, etc.) and include PR/issue references.\n</objective>\n\n<prerequisites>\n- `gh` CLI installed and authenticated (`gh auth status`)\n- Working directory is a git repository with GitHub remote\n- Repository uses Conventional Commits format for PR titles\n</prerequisites>\n\n<arguments>\n**Optional arguments:**\n- `from=<ref>` - Starting reference (tag, commit SHA, or date like `2024-01-01`)\n- `to=<ref>` - Ending reference (default: `HEAD`)\n- `output=<path>` - Output file path (default: `CHANGELOG.md`)\n\n**Default behavior:**\n\n- If no `from` provided, uses the most recent tag\n- If no tags exist, uses the first commit\n</arguments>\n\n<usage_examples>\n**Generate changelog since last tag:**\n\n```bash\n/ghpm:changelog\n```\n\n**Generate changelog between versions:**\n\n```bash\n/ghpm:changelog from=v1.0.0 to=v1.1.0\n```\n\n**Generate changelog to specific file:**\n\n```bash\n/ghpm:changelog output=docs/CHANGELOG.md\n```\n\n**Generate changelog from date:**\n\n```bash\n/ghpm:changelog from=2024-01-01\n```\n\n</usage_examples>\n\n<operating_rules>\n\n- Parse PR titles and commit messages for conventional commit format\n- Group changes by type (feat, fix, refactor, etc.)\n- Include PR numbers and links\n- Include contributor attribution\n- Handle breaking changes specially (highlight at top)\n- Preserve existing changelog content when appending\n</operating_rules>\n\n<changelog_format>\n\n## Output Format\n\n```markdown\n# Changelog\n\n## [Unreleased] OR [vX.Y.Z] - YYYY-MM-DD\n\n### Breaking Changes\n- **scope:** description (#PR) @contributor\n\n### Features\n- **scope:** description (#PR) @contributor\n\n### Bug Fixes\n- **scope:** description (#PR) @contributor\n\n### Performance\n- **scope:** description (#PR) @contributor\n\n### Code Refactoring\n- **scope:** description (#PR) @contributor\n\n### Documentation\n- **scope:** description (#PR) @contributor\n\n### Testing\n- **scope:** description (#PR) @contributor\n\n### Maintenance\n- **scope:** description (#PR) @contributor\n```\n\n### Section Mapping\n\n| Commit Type | Changelog Section |\n| ----------- | ----------------- |\n| `feat`      | Features          |\n| `fix`       | Bug Fixes         |\n| `perf`      | Performance       |\n| `refactor`  | Code Refactoring  |\n| `docs`      | Documentation     |\n| `test`      | Testing           |\n| `chore`     | Maintenance       |\n| `build`     | Maintenance       |\n| `ci`        | Maintenance       |\n| `style`     | (excluded)        |\n| `revert`    | Reverts           |\n\n</changelog_format>\n\n<workflow>\n\n## Step 1: Determine Range\n\n```bash\n# Get most recent tag if from not specified\nFROM_REF=\"${FROM:-$(git describe --tags --abbrev=0 2>/dev/null || git rev-list --max-parents=0 HEAD)}\"\nTO_REF=\"${TO:-HEAD}\"\n\necho \"Generating changelog from $FROM_REF to $TO_REF\"\n```\n\n## Step 2: Fetch Merged PRs\n\n```bash\n# Get merged PRs in range\ngh pr list \\\n  --state merged \\\n  --base main \\\n  --json number,title,author,mergedAt,labels \\\n  --jq '.[] | select(.mergedAt >= \"'$FROM_DATE'\")' \\\n  > /tmp/prs.json\n```\n\nAlternatively, parse git log:\n\n```bash\ngit log \"$FROM_REF\"..\"$TO_REF\" --oneline --format=\"%s|%h|%an\" > /tmp/commits.txt\n```\n\n## Step 3: Parse Conventional Commits\n\nFor each PR title or commit message, extract:\n\n1. **Type**: `feat`, `fix`, `refactor`, etc.\n2. **Scope**: Optional scope in parentheses\n3. **Breaking**: `!` after type or `BREAKING CHANGE:` in body\n4. **Description**: The commit description\n5. **PR number**: `(#123)` reference\n\n**Regex pattern:**\n\n```\n^(feat|fix|refactor|perf|test|docs|chore|build|ci|style|revert)(\\(.+\\))?(!)?:\\s*(.+?)(?:\\s*\\(#(\\d+)\\))?$\n```\n\n## Step 4: Group by Type\n\nOrganize parsed commits into sections:\n\n```\nbreaking_changes = []\nfeatures = []\nfixes = []\nperformance = []\nrefactoring = []\ndocumentation = []\ntesting = []\nmaintenance = []\nreverts = []\n```\n\n## Step 5: Generate Changelog Content\n\nBuild markdown content with:\n\n1. Version header (from `to` ref or \"Unreleased\")\n2. Date (today or tag date)\n3. Sections in order (Breaking Changes first, then Features, etc.)\n4. Only include sections that have entries\n5. Each entry: `- **scope:** description (#PR) @author`\n\n## Step 6: Write Output\n\n```bash\nOUTPUT_FILE=\"${OUTPUT:-CHANGELOG.md}\"\n\n# If file exists, insert new content after header\n# Otherwise create new file\n\n# Write content\ncat > \"$OUTPUT_FILE\" << 'EOF'\n# Changelog\n\n<generated content>\nEOF\n```\n\nIf prepending to existing changelog:\n\n```bash\n# Read existing content (skip header)\nEXISTING=$(tail -n +3 \"$OUTPUT_FILE\")\n\n# Write new content + existing\ncat > \"$OUTPUT_FILE\" << EOF\n# Changelog\n\n<new version content>\n\n$EXISTING\nEOF\n```\n\n</workflow>\n\n<error_handling>\n**If no conventional commits found:**\n\n- Warn user that commits don't follow conventional format\n- Offer to list all commits without categorization\n\n**If no PRs in range:**\n\n- Check if range is valid\n- Suggest alternative range\n- Fall back to commit-based changelog\n\n**If output file not writable:**\n\n- Check permissions\n- Suggest alternative path\n- Output to stdout as fallback\n</error_handling>\n\n<success_criteria>\nCommand completes successfully when:\n\n1. Changelog content is generated\n2. Changes are properly grouped by type\n3. PR numbers and authors are included\n4. Breaking changes are highlighted\n5. Output file is written (or content displayed)\n\n**Output summary:**\n\n```\nChangelog generated:\n- Range: v1.0.0..HEAD\n- PRs processed: 15\n- Features: 5\n- Bug Fixes: 3\n- Refactoring: 4\n- Other: 3\n- Output: CHANGELOG.md\n```\n\n</success_criteria>\n\nProceed now."
              },
              {
                "name": "/create-epics",
                "description": "Break a PRD issue into Epic issues and link them back to the PRD.",
                "path": "plugins/ghpm/commands/create-epics.md",
                "frontmatter": {
                  "description": "Break a PRD issue into Epic issues and link them back to the PRD.",
                  "argument-hint": "prd=#123",
                  "allowed-tools": [
                    "Read",
                    "Bash",
                    "Grep",
                    "Glob"
                  ],
                  "arguments": {
                    "prd": {
                      "description": "PRD issue number (format: prd=#123)",
                      "required": false
                    }
                  }
                },
                "content": "<objective>\nYou are GHPM (GitHub Project Manager). Break a PRD into Epics and publish each Epic as a GitHub Issue. Each Epic is linked as a sub-issue of the PRD. This is the second step in the GHPM workflow (PRD -> Epics -> Tasks -> TDD).\n</objective>\n\n<prerequisites>\n- `gh` CLI installed and authenticated (`gh auth status`)\n- Working directory is a git repository with GitHub remote\n- User has write access to repository issues\n- PRD issue exists with label \"PRD\"\n- Optional: `GHPM_PROJECT` environment variable set for project association\n- Optional: Repository has \"Epic\" label created\n</prerequisites>\n\n<arguments>\n**Optional:**\n- `prd=#123` - PRD issue number to break into Epics\n\n**Resolution order if omitted:**\n\n1. Most recent open issue labeled `PRD`\n\n**Optional environment variables:**\n\n- `GHPM_PROJECT` - GitHub Project name to associate Epics with (e.g., \"OrgName/ProjectName\" or \"ProjectName\")\n</arguments>\n\n<usage_examples>\n**With PRD number:**\n\n```\n/ghpm:create-epics prd=#42\n```\n\n**Auto-resolve most recent PRD:**\n\n```\n/ghpm:create-epics\n```\n\n**With project association:**\n\n```bash\nexport GHPM_PROJECT=\"MyOrg/Q1 Roadmap\"\n/ghpm:create-epics prd=#42\n```\n\n</usage_examples>\n\n<operating_rules>\n\n- Do not ask clarifying questions. If the PRD has ambiguity, encode it as assumptions within each Epic and/or add open questions.\n- Do not create local markdown files. All output goes into GitHub issues/comments.\n- Each Epic issue must be self-contained for its scope and must reference the PRD by number/link.\n- Epics should collectively cover the entire PRD scope without gaps or overlaps.\n\n### Epic Count Guidelines\n\n**Default to 1 Epic.** Only create multiple Epics when the PRD contains truly independent work streams that could be implemented by different people without coordination.\n\n| PRD Type | Epic Count | Justification Required |\n|----------|------------|------------------------|\n| Minimal (docs, config, single-file) | 1 | N/A |\n| Small (single feature) | 1 | N/A |\n| Medium (2-3 independent features) | 2-3 | Each Epic must deliver independent value |\n| Large (platform/system) | 3-5 | Each Epic must be separable work stream |\n\n**Decision questions before creating multiple Epics:**\n1. Would each Epic deliver independent, usable value if the others were never implemented?\n2. Could different developers implement each Epic without needing to coordinate on shared code?\n3. Is there a natural break point where work could pause between Epics?\n\nIf the answer to any question is \"no\", consolidate into fewer Epics.\n\n### Anti-patterns (DO NOT create separate Epics for these)\n\n- **\"Infrastructure\" vs \"Integration\"**: If the infrastructure is just code embedded in the integration, it's one Epic\n- **\"Implementation\" vs \"Documentation\"**: Docs are part of completing a feature, not a separate Epic\n- **\"Backend\" vs \"Frontend\"**: If the feature requires both to be useful, it's one Epic\n- **\"Core\" vs \"Extensions\"**: If extensions depend entirely on core, it's one Epic\n- **Per-file Epics**: Creating Epics for each file touched rather than for outcomes\n\n### Example: Single-Feature PRD → 1 Epic\n\nPRD: \"Add issue claiming workflow to execute, tdd-task, and qa-execute commands\"\n\n❌ **Wrong (3 Epics):**\n1. Epic: Core Claiming Infrastructure\n2. Epic: Command Integration\n3. Epic: Documentation\n\n❌ **Why it's wrong:** The \"infrastructure\" is just a bash function embedded in commands. Documentation is part of completing the feature. All three are tightly coupled.\n\n✅ **Correct (1 Epic):**\n1. Epic: Issue Claiming Workflow\n\n</operating_rules>\n\n<epic_issue_format>\n\n## Required Epic Structure (Issue Body)\n\nUse this streamlined template. Omit optional sections if empty.\n\n```markdown\n# Epic: <Name>\n\n**PRD:** #<PRD_NUMBER>\n\n## Objective\n<1-3 sentences: what this Epic accomplishes and delivers>\n\n## Scope\n<Bulleted list of specific deliverables - merge any \"Key Requirements\" here>\n\n## Acceptance Criteria\n- [ ] Criterion 1\n- [ ] Criterion 2\n- [ ] ...\n\n## Dependencies\n<Only include if external dependencies exist; omit section entirely if none>\n```\n\n### Template Guidance\n\n- **PRD link**: Single line at top, not a separate \"Links\" section\n- **Objective**: Concise statement of what this Epic delivers (not duplicating PRD content)\n- **Scope**: Specific deliverables; merge \"Key Requirements\" here rather than separate section\n- **Acceptance Criteria**: Checkboxes for Epic-level verification\n- **Dependencies**: Only include if there are actual dependencies; omit if none\n\n**Omit these sections** (redundant with PRD or rarely populated):\n- Out of Scope (inherit from PRD)\n- Risks / Edge Cases (inherit from PRD)\n- Notes / Open Questions (use issue comments instead)\n- Key Requirements (merge into Scope)\n\n</epic_issue_format>\n\n<input_validation>\n\n## Validation Checks\n\nBefore proceeding, verify:\n\n```bash\n# 1. Verify gh CLI authentication\ngh auth status || { echo \"ERROR: Not authenticated. Run 'gh auth login'\"; exit 1; }\n\n# 2. Verify in git repository\ngit rev-parse --git-dir > /dev/null 2>&1 || { echo \"ERROR: Not in a git repository\"; exit 1; }\n\n# 3. Verify GitHub remote exists and get repo info\nREPO=$(gh repo view --json nameWithOwner -q .nameWithOwner) || { echo \"ERROR: No GitHub remote found\"; exit 1; }\n\n# 4. Get owner and repo for API calls\nOWNER=$(gh repo view --json owner -q '.owner.login')\nREPO_NAME=$(gh repo view --json name -q '.name')\n```\n\n</input_validation>\n\n<workflow>\n\n## Step 1: Validate Environment\n\nRun input validation checks from previous section.\n\n## Step 2: Resolve PRD Number\n\n```bash\n# If prd=#N provided, extract N\nif [[ \"$ARGUMENTS\" =~ prd=#([0-9]+) ]]; then\n  PRD=\"${BASH_REMATCH[1]}\"\nelse\n  # Find most recent open PRD\n  PRD=$(gh issue list -l PRD -s open --limit 1 --json number -q '.[0].number')\n  if [ -z \"$PRD\" ]; then\n    echo \"ERROR: No open PRD issues found. Create one with /ghpm:create-prd\"\n    exit 1\n  fi\nfi\n\necho \"Using PRD #$PRD\"\n```\n\n## Step 3: Fetch PRD Content\n\n```bash\n# Verify PRD exists and get content\nPRD_DATA=$(gh issue view \"$PRD\" --json title,body,url,number)\nif [ -z \"$PRD_DATA\" ]; then\n  echo \"ERROR: PRD #$PRD not found\"\n  exit 1\nfi\n\nPRD_TITLE=$(echo \"$PRD_DATA\" | jq -r '.title')\nPRD_BODY=$(echo \"$PRD_DATA\" | jq -r '.body')\nPRD_URL=$(echo \"$PRD_DATA\" | jq -r '.url')\n\necho \"PRD: $PRD_TITLE\"\necho \"URL: $PRD_URL\"\n```\n\n## Step 4: Generate Epics\n\nAnalyze the PRD scope and generate the minimum number of Epics needed. For narrow-scope PRDs (documentation updates, configuration changes, single-file modifications), a single Epic is often sufficient. Each Epic should:\n\n- Cover a distinct, cohesive area of functionality\n- Be independently implementable (with dependencies noted)\n- Reference the PRD by number\n- Represent meaningful, separable work (not artificial subdivisions)\n\n## Step 5: Create Epic Issues\n\n```bash\n# For each Epic, create an issue\ngh issue create \\\n  --repo \"$REPO\" \\\n  --title \"Epic: <Name>\" \\\n  --label \"Epic\" \\\n  --body \"$(cat <<'EOF'\n<Generated Epic Content>\nEOF\n)\"\n\n# Capture issue number from output\nEPIC_NUM=<captured from gh issue create output>\nEPIC_URL=<captured from gh issue create output>\n\n# Track created Epics\nCREATED_EPICS+=(\"$EPIC_NUM|Epic: <Name>|$EPIC_URL\")\n```\n\n## Step 6: Add to GitHub Project (Optional)\n\n```bash\nif [ -n \"$GHPM_PROJECT\" ]; then\n  gh issue edit \"$EPIC_NUM\" --add-project \"$GHPM_PROJECT\" 2>/dev/null || {\n    echo \"WARNING: Failed to add Epic #$EPIC_NUM to project '$GHPM_PROJECT'\"\n  }\nfi\n```\n\n## Step 7: Link Epics as Sub-Issues of PRD\n\n```bash\n# Get the PRD's internal issue ID\nPRD_ID=$(gh api \"repos/$OWNER/$REPO_NAME/issues/$PRD\" --jq .id)\n\nfor epic_info in \"${CREATED_EPICS[@]}\"; do\n  EPIC_NUM=$(echo \"$epic_info\" | cut -d'|' -f1)\n\n  # Get the Epic's internal issue ID\n  EPIC_ID=$(gh api \"repos/$OWNER/$REPO_NAME/issues/$EPIC_NUM\" --jq .id)\n\n  # Add Epic as sub-issue of PRD\n  gh api \"repos/$OWNER/$REPO_NAME/issues/$PRD/sub_issues\" \\\n    -X POST \\\n    -F sub_issue_id=\"$EPIC_ID\" \\\n    --silent && echo \"✓ Linked Epic #$EPIC_NUM as sub-issue of PRD #$PRD\" \\\n    || echo \"WARNING: Could not link Epic #$EPIC_NUM as sub-issue\"\ndone\n```\n\n## Step 8: Post PRD Comment with Summary\n\n```bash\nCOMMENT_BODY=\"## Epics Created\n\nThe following Epics have been created from this PRD:\n\n$(for epic_info in \"${CREATED_EPICS[@]}\"; do\n  EPIC_NUM=$(echo \"$epic_info\" | cut -d'|' -f1)\n  EPIC_TITLE=$(echo \"$epic_info\" | cut -d'|' -f2)\n  echo \"- #$EPIC_NUM $EPIC_TITLE\"\ndone)\n\nView sub-issues in the PRD's \\\"Sub-issues\\\" section.\n\n---\n*Generated by GHPM*\"\n\ngh issue comment \"$PRD\" --body \"$COMMENT_BODY\"\n```\n\n</workflow>\n\n<error_handling>\n**If gh CLI not authenticated:**\n\n- Check: `gh auth status`\n- Fix: `gh auth login`\n\n**If not in git repository:**\n\n- Navigate to repository directory\n- Verify with: `git status`\n\n**If no GitHub remote:**\n\n- Check remote: `git remote -v`\n- Add remote if needed: `git remote add origin <url>`\n\n**If PRD not found:**\n\n- Verify PRD number: `gh issue view <number>`\n- Check PRD label exists: `gh issue list -l PRD`\n- Create PRD first: `/ghpm:create-prd <description>`\n\n**If label \"Epic\" doesn't exist:**\n\n- Create it: `gh label create Epic --description \"Epic issue\" --color 1D76DB`\n- Or omit `--label \"Epic\"` from issue creation and continue\n\n**If issue creation fails:**\n\n- Check rate limits: `gh api rate_limit`\n- Verify write permissions: `gh repo view --json viewerPermission -q .viewerPermission`\n- Check repository exists and is accessible\n\n**If sub-issue linking fails:**\n\n- Sub-issues API may not be available for all repositories\n- Command continues with warning\n- Epics are still created and reference PRD in their body\n\n**If project association fails:**\n\n- Verify `GHPM_PROJECT` format is correct\n- Check project exists: `gh project list`\n- Command continues with warning\n</error_handling>\n\n<success_criteria>\nCommand completes successfully when:\n\n1. All Epic issues are created with \"Epic\" label\n2. Each Epic body contains required sections: PRD link, Objective, Scope, Acceptance Criteria\n3. Each Epic references the PRD at the top of the body\n4. All Epics are linked as sub-issues of the PRD (or warnings issued)\n5. Summary comment is posted to PRD\n6. If `GHPM_PROJECT` set, Epics are added to project (or warnings issued)\n7. Optional sections (Dependencies) only included when populated with meaningful content\n\n**Verification:**\n\n```bash\n# View created Epics\ngh issue list -l Epic --json number,title,url\n\n# Verify sub-issues are linked to PRD\ngh api \"repos/$OWNER/$REPO_NAME/issues/$PRD/sub_issues\" --jq '.[] | \"#\\(.number) \\(.title)\"'\n\n# View PRD comments\ngh issue view \"$PRD\" --comments\n```\n\n</success_criteria>\n\n<output>\nAfter completion, report:\n\n1. **PRD:** #<number> - <URL>\n2. **Epics Created:**\n   - #<number> Epic: <Name> - <URL>\n   - #<number> Epic: <Name> - <URL>\n   - ...\n3. **Sub-Issue Linking:**\n   - Success count / Total count\n   - Any warnings\n4. **Project Association:**\n   - Success: \"Added to project '<GHPM_PROJECT>'\"\n   - Failure: \"WARNING: Could not add to project\"\n   - N/A: \"No project specified\"\n5. **Next Step:** \"Run `/ghpm:create-tasks epic=#<number>` to break an Epic into Tasks\"\n\n**Example Output (Minimal PRD - single epic):**\n\n```\nEpics Created Successfully\n\nPRD: #42 - https://github.com/owner/repo/issues/42\n\nEpics Created:\n- #43 Epic: Update README Documentation - https://github.com/owner/repo/issues/43\n\nSub-Issue Linking: 1/1 successful\nProject Association: No project specified\n\nNext Step: Run `/ghpm:create-tasks epic=#43` to break an Epic into Tasks\n```\n\n**Example Output (Large PRD - multiple epics):**\n\n```\nEpics Created Successfully\n\nPRD: #42 - https://github.com/owner/repo/issues/42\n\nEpics Created:\n- #43 Epic: User Authentication - https://github.com/owner/repo/issues/43\n- #44 Epic: Database Schema - https://github.com/owner/repo/issues/44\n- #45 Epic: API Endpoints - https://github.com/owner/repo/issues/45\n- #46 Epic: Frontend Integration - https://github.com/owner/repo/issues/46\n- #47 Epic: Testing & QA - https://github.com/owner/repo/issues/47\n\nSub-Issue Linking: 5/5 successful\nProject Association: Added to project 'Q1 Roadmap'\n\nNext Step: Run `/ghpm:create-tasks epic=#43` to break an Epic into Tasks\n```\n\n</output>\n\n<related_commands>\n**GHPM Workflow:**\n\n1. **Previous:** `/ghpm:create-prd` - Create PRD from user input\n2. **Current:** `/ghpm:create-epics` - Break PRD into Epics\n3. **Next:** `/ghpm:create-tasks epic=#N` - Break Epics into Tasks\n4. **Finally:** `/ghpm:tdd-task [task=#N]` - Implement Tasks with TDD\n\n**Related:**\n\n- `/ghpm:execute epic=#N` - Execute all tasks in an Epic\n- `/ghpm:qa-create` - Create QA issue for testing\n</related_commands>\n\nNow proceed:\n\n- Resolve PRD number from $ARGUMENTS or find most recent.\n- Fetch PRD content and analyze scope.\n- Determine appropriate Epic count based on scope complexity (1 Epic for narrow PRDs, more for larger scope).\n- Generate Epics covering the entire PRD without artificial subdivision.\n- Create each Epic issue via `gh issue create`.\n- Link Epics as sub-issues of the PRD.\n- Post summary comment to PRD."
              },
              {
                "name": "/create-prd",
                "description": "Create a PRD GitHub issue (labeled PRD) from user input and optionally add it to a GitHub Project",
                "path": "plugins/ghpm/commands/create-prd.md",
                "frontmatter": {
                  "description": "Create a PRD GitHub issue (labeled PRD) from user input and optionally add it to a GitHub Project",
                  "argument-hint": "<product idea or feature description>",
                  "allowed-tools": [
                    "Read",
                    "Bash",
                    "Grep",
                    "AskUserQuestion"
                  ]
                },
                "content": "<objective>\nYou are GHPM (GitHub Project Manager). Convert user input into a high-quality Product Requirements Document (PRD) and publish it as a GitHub Issue. This is the first step in the GHPM workflow (PRD -> Epics -> Tasks -> TDD).\n</objective>\n\n<prerequisites>\n- `gh` CLI installed and authenticated (`gh auth status`)\n- Working directory is a git repository with GitHub remote\n- User has write access to repository issues\n- Optional: `GHPM_PROJECT` environment variable pre-set (if not set, user will be prompted to select a project)\n- Optional: Repository has \"PRD\" label created\n</prerequisites>\n\n<arguments>\n**Required:**\n- Product idea, feature description, or problem statement (captured from user input via $ARGUMENTS)\n\n**Optional environment variables:**\n\n- `GHPM_PROJECT` - GitHub Project name to associate issue with. If not set, the command will query available projects for the repository owner and prompt for selection.\n</arguments>\n\n<usage_examples>\n\n**Detailed input (skips clarification):**\n\n```\n/ghpm:create-prd Build a user authentication system with email/password and OAuth support for enterprise customers who need SSO to reduce IT friction during onboarding\n```\n\n→ Detailed input (30+ words, has who/what/why) → Proceeds directly to PRD generation\n\n**Vague input (triggers clarification):**\n\n```\n/ghpm:create-prd Add a dashboard\n```\n\n→ Vague input (4 words, missing who/why/scope) → Presents clarifying questions:\n\n1. Who is the primary user? (Internal team, Customers, Admins, Developers)\n2. What problem does this solve? (Efficiency, Missing capability, UX, Compliance)\n3. What's the scope? (MVP, Feature complete, Production-ready, Enterprise-grade)\n\nAfter user responds → Generates PRD with enriched context\n\n**Complex feature (typically detailed enough):**\n\n```\n/ghpm:create-prd Add real-time collaboration features to the document editor, similar to Google Docs, so remote teams can co-edit documents without version conflicts\n```\n\n→ Detailed input → Proceeds directly to PRD generation\n\n**With project association (auto-prompt):**\n\n```\n/ghpm:create-prd Implement dark mode across the application for users with visual sensitivities to reduce eye strain\n```\n\n→ If `GHPM_PROJECT` not set, prompts: \"Which GitHub Project should this PRD be added to?\" with available projects\n\n**With project pre-set (skip prompt):**\n\n```bash\nexport GHPM_PROJECT=\"MyOrg/Q1 Roadmap\"\n/ghpm:create-prd Implement dark mode across the application for users with visual sensitivities to reduce eye strain\n```\n\n→ Skips project selection prompt and uses pre-set project\n\n</usage_examples>\n\n<operating_rules>\n\n- **For vague input:** Use `AskUserQuestion` tool to gather context before generating the PRD. See `<vagueness_detection>` for criteria.\n- **For detailed input:** Proceed directly to PRD generation. Make reasonable assumptions and explicitly record them under **Assumptions** and **Open Questions**.\n- Do not create or persist local markdown artifacts (no local PRD files). All artifacts must live in GitHub issue bodies/comments.\n- Use Markdown in the issue body. Make the PRD self-contained.\n- Keep scope crisp; if the request is broad, define a \"V1\" and park the rest in **Out of Scope** / **Future Ideas**.\n- Clarification should be quick (max 4 questions) - do not interrogate the user.\n</operating_rules>\n\n<prd_structure>\n\n## Required PRD Structure (Issue Body)\n\nUse this exact outline:\n\n```markdown\n# PRD: <Concise Name>\n\n## Summary\n## Problem / Opportunity\n## Goals (Success Metrics)\n## Non-Goals / Out of Scope\n## Users & Use Cases\n## Requirements\n- Functional Requirements\n- Non-Functional Requirements\n## UX / UI Notes (if relevant)\n## Data / Integrations (if relevant)\n## Risks / Edge Cases\n## Assumptions\n## Open Questions\n## Acceptance Criteria (high level)\n## Rollout / Release Notes (brief)\n## Implementation Notes (non-binding)\n(Keep this section minimal; do not over-prescribe.)\n```\n\n</prd_structure>\n\n<input_validation>\n\n## Validation Checks\n\nBefore proceeding, verify:\n\n```bash\n# 1. Verify gh CLI authentication\ngh auth status || { echo \"ERROR: Not authenticated. Run 'gh auth login'\"; exit 1; }\n\n# 2. Verify in git repository\ngit rev-parse --git-dir > /dev/null 2>&1 || { echo \"ERROR: Not in a git repository\"; exit 1; }\n\n# 3. Verify GitHub remote exists\ngh repo view --json nameWithOwner -q .nameWithOwner || { echo \"ERROR: No GitHub remote found\"; exit 1; }\n```\n\nIf $ARGUMENTS is empty or missing, report an error:\n\n```\nERROR: Product idea or feature description required\nUsage: /ghpm:create-prd <description>\n```\n\n</input_validation>\n\n<vagueness_detection>\n\n## Detecting Vague Input\n\nBefore generating the PRD, evaluate whether user input is sufficiently detailed. Input is considered **vague** if ANY of the following criteria are met:\n\n### Vagueness Criteria\n\n| Criterion           | Threshold                           | Example (Vague)           | Example (Detailed)                                                                                                                             |\n| ------------------- | ----------------------------------- | ------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------- |\n| **Too short**       | < 20 words                          | \"I want a dashboard\"      | \"Build an analytics dashboard for sales managers to track quarterly revenue, pipeline metrics, and team performance with drill-down by region\" |\n| **Missing 'who'**   | No target user/audience mentioned   | \"Add authentication\"      | \"Add OAuth2 authentication for enterprise customers who need SSO\"                                                                              |\n| **Missing 'what'**  | No specific functionality described | \"Improve performance\"     | \"Optimize database queries in the user search endpoint to reduce p95 latency below 200ms\"                                                      |\n| **Missing 'why'**   | No problem/goal articulated         | \"Add export feature\"      | \"Add CSV export for compliance reports so auditors can analyze data offline\"                                                                   |\n| **Ambiguous scope** | Could mean vastly different things  | \"Make it mobile-friendly\" | \"Create responsive layouts for the checkout flow that work on screens 320px to 768px wide\"                                                     |\n\n### Evaluation Process\n\n1. Count words in input (excluding common stop words for accuracy assessment)\n2. Scan for user/audience indicators: \"users\", \"customers\", \"admins\", \"managers\", \"developers\", etc.\n3. Scan for problem/goal indicators: \"so that\", \"in order to\", \"because\", \"to enable\", \"to reduce\", etc.\n4. Assess specificity: Does the input contain concrete details (numbers, specific features, constraints)?\n\n**If 2+ criteria are triggered:** Proceed to clarification step\n**If 0-1 criteria triggered:** Skip clarification, proceed directly to PRD generation\n\n</vagueness_detection>\n\n<clarification_questions>\n\n## Clarifying Questions\n\nWhen vague input is detected, use the `AskUserQuestion` tool to gather context. Select 2-4 questions based on what's missing from the input.\n\n### Question Templates\n\n**Q1: Target Users** (use when 'who' is missing)\n\n```json\n{\n  \"question\": \"Who is the primary user of this feature?\",\n  \"header\": \"Users\",\n  \"multiSelect\": false,\n  \"options\": [\n    {\"label\": \"End users/customers\", \"description\": \"People using the product directly\"},\n    {\"label\": \"Internal team members\", \"description\": \"Employees within the organization\"},\n    {\"label\": \"Administrators\", \"description\": \"Users who configure or manage the system\"},\n    {\"label\": \"Developers/API consumers\", \"description\": \"Technical users integrating with the system\"}\n  ]\n}\n```\n\n**Q2: Problem Being Solved** (use when 'why' is missing)\n\n```json\n{\n  \"question\": \"What problem does this solve for users?\",\n  \"header\": \"Problem\",\n  \"multiSelect\": false,\n  \"options\": [\n    {\"label\": \"Efficiency/speed\", \"description\": \"Reduce time or effort to complete tasks\"},\n    {\"label\": \"Missing capability\", \"description\": \"Enable something users currently cannot do\"},\n    {\"label\": \"User experience\", \"description\": \"Improve usability, accessibility, or satisfaction\"},\n    {\"label\": \"Compliance/security\", \"description\": \"Meet regulatory or security requirements\"}\n  ]\n}\n```\n\n**Q3: Core Capabilities** (use when 'what' is vague)\n\n```json\n{\n  \"question\": \"Which capabilities are most important?\",\n  \"header\": \"Features\",\n  \"multiSelect\": true,\n  \"options\": [\n    {\"label\": \"View/display data\", \"description\": \"Read-only access to information\"},\n    {\"label\": \"Create/edit content\", \"description\": \"CRUD operations on data\"},\n    {\"label\": \"Automation/workflows\", \"description\": \"Automated processes or triggers\"},\n    {\"label\": \"Reporting/analytics\", \"description\": \"Insights, charts, or exports\"}\n  ]\n}\n```\n\n**Q4: Technical Constraints** (use when scope is ambiguous)\n\n```json\n{\n  \"question\": \"Are there specific technical constraints?\",\n  \"header\": \"Constraints\",\n  \"multiSelect\": true,\n  \"options\": [\n    {\"label\": \"Must integrate with existing system\", \"description\": \"Needs to work with current infrastructure\"},\n    {\"label\": \"Performance-critical\", \"description\": \"High throughput or low latency required\"},\n    {\"label\": \"Mobile support required\", \"description\": \"Must work on mobile devices\"},\n    {\"label\": \"No constraints\", \"description\": \"Greenfield implementation\"}\n  ]\n}\n```\n\n**Q5: Scope/Priority** (use when input could mean many things)\n\n```json\n{\n  \"question\": \"What's the scope for the initial version?\",\n  \"header\": \"Scope\",\n  \"multiSelect\": false,\n  \"options\": [\n    {\"label\": \"MVP/proof of concept\", \"description\": \"Minimal viable version to validate the idea\"},\n    {\"label\": \"Feature complete for core use case\", \"description\": \"Fully functional for primary scenario\"},\n    {\"label\": \"Production-ready with edge cases\", \"description\": \"Robust handling of all scenarios\"},\n    {\"label\": \"Enterprise-grade\", \"description\": \"Scalability, security, and compliance built-in\"}\n  ]\n}\n```\n\n### Selecting Questions\n\nBased on vagueness detection results, select appropriate questions:\n\n| Missing Element  | Questions to Ask                                |\n| ---------------- | ----------------------------------------------- |\n| Who (users)      | Q1 (Target Users)                               |\n| Why (problem)    | Q2 (Problem Being Solved)                       |\n| What (features)  | Q3 (Core Capabilities)                          |\n| Scope unclear    | Q4 (Technical Constraints), Q5 (Scope/Priority) |\n| Multiple missing | Combine up to 4 questions maximum               |\n\n### Incorporating Responses\n\nAfter receiving user responses, append them to the original input before generating the PRD:\n\n```\nOriginal input: \"I want a dashboard\"\n\nEnriched context from clarification:\n- Target users: Internal team members\n- Problem: Efficiency/speed - reduce time to complete tasks\n- Capabilities: Reporting/analytics, View/display data\n- Scope: Feature complete for core use case\n\nGenerate PRD using both original input AND enriched context.\n```\n\n</clarification_questions>\n\n<workflow>\n## Step 1: Validate Environment\n\nRun input validation checks from previous section.\n\n## Step 2: Determine Repository and Owner\n\n```bash\nREPO=$(gh repo view --json nameWithOwner -q .nameWithOwner)\nOWNER=$(gh repo view --json owner -q .owner.login)\n```\n\n## Step 3: Select GitHub Project (if not pre-set)\n\nIf `GHPM_PROJECT` environment variable is already set, skip to Step 4.\n\nOtherwise, query available projects for the repository owner and prompt the user to select one:\n\n```bash\n# Get list of projects for the repo owner\nPROJECTS=$(gh project list --owner \"$OWNER\" --format json --limit 20)\n```\n\n**If projects exist:** Use `AskUserQuestion` to let the user select a project.\n\nBuild the question dynamically based on available projects:\n\n```json\n{\n  \"question\": \"Which GitHub Project should this PRD be added to?\",\n  \"header\": \"Project\",\n  \"multiSelect\": false,\n  \"options\": [\n    {\"label\": \"<Project Title 1>\", \"description\": \"Project #<number>\"},\n    {\"label\": \"<Project Title 2>\", \"description\": \"Project #<number>\"},\n    ...\n    {\"label\": \"None\", \"description\": \"Do not add to any project\"}\n  ]\n}\n```\n\n- Include up to 4 projects (the most recently updated, or first 4 returned)\n- Always include \"None\" as the last option\n- If user selects a project, set `GHPM_PROJECT` to the selected project title\n- If user selects \"None\", leave `GHPM_PROJECT` unset\n\n**If no projects exist:** Skip project selection and inform the user:\n\n```\nNo GitHub Projects found for owner '$OWNER'. Skipping project association.\nTo create a project, visit: https://github.com/<owner>?tab=projects\n```\n\n## Step 4: Evaluate Input & Clarify (if needed)\n\nEvaluate user input against the vagueness criteria in `<vagueness_detection>`.\n\n**If input is sufficiently detailed (0-1 criteria triggered):**\n\n- Skip to Step 5 (Draft PRD Content)\n\n**If input is vague (2+ criteria triggered):**\n\n1. Identify which elements are missing (who, what, why, scope)\n2. Select appropriate questions from `<clarification_questions>` (max 4)\n3. Use `AskUserQuestion` tool to present questions:\n\n```\nUse the AskUserQuestion tool with the selected question templates.\nWait for user responses before proceeding.\n```\n\n1. Combine original input with user responses to form enriched context\n2. Proceed to Step 5 with enriched context\n\n**Example clarification flow:**\n\nInput: \"I want a dashboard\"\n\nVagueness analysis:\n\n- ✗ Too short (4 words < 20)\n- ✗ Missing 'who' (no user mentioned)\n- ✗ Missing 'why' (no problem stated)\n- ✓ Has 'what' (dashboard is a feature)\n- ✗ Ambiguous scope (dashboard could mean many things)\n\n→ 4 criteria triggered → Ask Q1 (Users), Q2 (Problem), Q5 (Scope)\n\n## Step 5: Draft PRD Content\n\nBased on user input ($ARGUMENTS) and any enriched context from clarification, generate comprehensive PRD following the structure template.\n\n## Step 6: Create GitHub Issue\n\n```bash\n# Use heredoc to safely handle multiline content\ngh issue create \\\n  --repo \"$REPO\" \\\n  --title \"PRD: <Concise Name>\" \\\n  --label \"PRD\" \\\n  --body \"$(cat <<'EOF'\n<Generated PRD Content>\nEOF\n)\"\n```\n\n## Step 7: Add to GitHub Project\n\nUse the new GitHub Projects API (`gh project item-add`) instead of the deprecated `--add-project` flag.\n\n```bash\nif [ -n \"$GHPM_PROJECT\" ]; then\n  # Get the issue URL (needed for gh project item-add)\n  ISSUE_URL=$(gh issue list --repo \"$REPO\" -l PRD --limit 1 --json url -q '.[0].url')\n\n  # Get project number from the project list\n  # GHPM_PROJECT can be either the project title or number\n  if [[ \"$GHPM_PROJECT\" =~ ^[0-9]+$ ]]; then\n    PROJECT_NUMBER=\"$GHPM_PROJECT\"\n  else\n    # Look up project number by title\n    PROJECT_NUMBER=$(gh project list --owner \"$OWNER\" --format json | \\\n      jq -r --arg title \"$GHPM_PROJECT\" '.projects[] | select(.title == $title) | .number')\n  fi\n\n  if [ -n \"$PROJECT_NUMBER\" ]; then\n    gh project item-add \"$PROJECT_NUMBER\" --owner \"$OWNER\" --url \"$ISSUE_URL\" 2>/dev/null || {\n      echo \"WARNING: Failed to add issue to project '$GHPM_PROJECT'\"\n      ISSUE_NUMBER=$(echo \"$ISSUE_URL\" | grep -oE '[0-9]+$')\n      gh issue comment \"$ISSUE_NUMBER\" --body \"Note: Could not automatically add to project '$GHPM_PROJECT'. Please add manually if needed.\"\n    }\n  else\n    echo \"WARNING: Could not find project '$GHPM_PROJECT'\"\n  fi\nfi\n```\n\n**Note:** The `gh project item-add` command requires:\n- Project number (not title) - we look this up from the project list\n- Owner (user or organization)\n- Issue URL (not issue number)\n\n</workflow>\n\n<error_handling>\n**If gh CLI not authenticated:**\n\n- Check: `gh auth status`\n- Fix: `gh auth login`\n\n**If not in git repository:**\n\n- Navigate to repository directory\n- Verify with: `git status`\n\n**If no GitHub remote:**\n\n- Check remote: `git remote -v`\n- Add remote if needed: `git remote add origin <url>`\n\n**If label \"PRD\" doesn't exist:**\n\n- Create it: `gh label create PRD --description \"Product Requirements Document\" --color 0E8A16`\n- Or omit `--label \"PRD\"` from issue creation and continue\n\n**If issue creation fails:**\n\n- Check rate limits: `gh api rate_limit`\n- Verify write permissions: `gh repo view --json viewerPermission -q .viewerPermission`\n- Check repository exists and is accessible\n\n**If project association fails:**\n\n- Verify `GHPM_PROJECT` is either the project number or exact title\n- Check project exists: `gh project list --owner <OWNER>`\n- Ensure the new Projects API is used (`gh project item-add`), not the deprecated `--add-project` flag\n- Common error: \"Projects (classic) is being deprecated\" means you're using the old API\n- Command will continue and add warning comment to issue\n</error_handling>\n\n<success_criteria>\nCommand completes successfully when:\n\n1. PRD issue is created with \"PRD\" label\n2. Issue body contains all required sections from PRD structure\n3. Issue number and URL are captured\n4. If `GHPM_PROJECT` set, issue is added to project (or warning issued)\n\n**Verification:**\n\n```bash\n# View the created PRD\ngh issue view <issue_number>\n\n# List all PRD issues\ngh issue list -l PRD --json number,title,url\n```\n\n</success_criteria>\n\n<output>\nAfter completion, report:\n\n1. **PRD Issue:** #<number> - <URL>\n2. **Repository:** <owner>/<repo>\n3. **Project Association:**\n   - Success: \"Added to project '<GHPM_PROJECT>'\"\n   - Failure: \"WARNING: Could not add to project (see issue comment)\"\n   - N/A: \"No project specified\"\n4. **Next Step:** \"Run `/ghpm:create-epics prd=#<number>` to break this PRD into Epics\"\n\n**Example Output:**\n\n```\nPRD Created Successfully\n\nPRD Issue: #42 - https://github.com/owner/repo/issues/42\nRepository: owner/repo\nProject Association: Added to project 'Q1 Roadmap'\n\nNext Step: Run `/ghpm:create-epics prd=#42` to break this PRD into Epics\n```\n\n</output>\n\n<related_commands>\n**GHPM Workflow:**\n\n1. **Current:** `/ghpm:create-prd` - Create PRD from user input\n2. **Next:** `/ghpm:create-epics [prd=#N]` - Break PRD into Epics\n3. **Then:** `/ghpm:create-tasks epic=#N` - Break Epics into Tasks\n4. **Finally:** `/ghpm:tdd-task [task=#N]` - Implement Tasks with TDD\n\n**Related:**\n\n- `/gh-create-epic` - Create standalone Epic (not part of GHPM workflow)\n</related_commands>\n\nNow proceed:\n\n1. Validate environment prerequisites.\n2. Determine repository and owner.\n3. If `GHPM_PROJECT` not set: Query projects for owner and prompt user to select one.\n4. Evaluate input against vagueness criteria.\n5. If vague (2+ criteria triggered): Use AskUserQuestion to gather context.\n6. Draft the PRD from $ARGUMENTS (and enriched context if clarified).\n7. Create the issue via `gh issue create`.\n8. Add it to the GitHub project if `GHPM_PROJECT` is set."
              },
              {
                "name": "/create-project",
                "description": "Create a new GitHub Project from template (or blank) and link it to the current repository",
                "path": "plugins/ghpm/commands/create-project.md",
                "frontmatter": {
                  "description": "Create a new GitHub Project from template (or blank) and link it to the current repository",
                  "argument-hint": [
                    "project title"
                  ],
                  "allowed-tools": [
                    "Read",
                    "Bash",
                    "Grep",
                    "AskUserQuestion"
                  ]
                },
                "content": "<objective>\nYou are GHPM (GitHub Project Manager). Create a new GitHub Project, optionally from a template, and link it to the current repository. This command helps bootstrap project management for repositories that don't yet have an associated project.\n</objective>\n\n<prerequisites>\n- `gh` CLI installed and authenticated (`gh auth status`)\n- Working directory is a git repository with GitHub remote\n- User has permission to create projects for the repository owner\n- Token has `project` scope (`gh auth refresh -s project` if needed)\n- Optional: A template project marked with `gh project mark-template`\n</prerequisites>\n\n<arguments>\n**Optional:**\n- Project title (captured from $ARGUMENTS). If not provided, user will be prompted.\n\n**Optional environment variables:**\n\n- `GHPM_TEMPLATE_PROJECT` - Project number to use as template (e.g., \"7\")\n- `GHPM_TEMPLATE_OWNER` - Owner of the template project (defaults to current repo owner)\n</arguments>\n\n<usage_examples>\n\n**With title argument:**\n\n```\n/ghpm:create-project Q1 Roadmap\n```\n\n→ Creates project titled \"Q1 Roadmap\", links to current repo\n\n**Without title (prompts):**\n\n```\n/ghpm:create-project\n```\n\n→ Prompts: \"What should the project be called?\" → Creates and links project\n\n**With template pre-configured:**\n\n```bash\nexport GHPM_TEMPLATE_PROJECT=\"7\"\n/ghpm:create-project Feature Development\n```\n\n→ Copies from template project #7, links to current repo\n\n</usage_examples>\n\n<operating_rules>\n\n- Always prompt for project title if not provided via $ARGUMENTS\n- Check for template projects before creating blank project\n- Link the project to the current repository after creation\n- Set `GHPM_PROJECT` to the new project title for use in subsequent commands\n- Report the project URL so user can configure views manually if needed\n\n</operating_rules>\n\n<input_validation>\n\n## Validation Checks\n\nBefore proceeding, verify:\n\n```bash\n# 1. Verify gh CLI authentication\ngh auth status || { echo \"ERROR: Not authenticated. Run 'gh auth login'\"; exit 1; }\n\n# 2. Verify project scope\ngh auth status 2>&1 | grep -q \"project\" || echo \"WARNING: Token may not have 'project' scope. Run 'gh auth refresh -s project' if project creation fails.\"\n\n# 3. Verify in git repository\ngit rev-parse --git-dir > /dev/null 2>&1 || { echo \"ERROR: Not in a git repository\"; exit 1; }\n\n# 4. Verify GitHub remote exists\ngh repo view --json nameWithOwner -q .nameWithOwner || { echo \"ERROR: No GitHub remote found\"; exit 1; }\n```\n\n</input_validation>\n\n<workflow>\n\n## Step 1: Validate Environment\n\nRun input validation checks from previous section.\n\n## Step 2: Determine Repository and Owner\n\n```bash\nREPO=$(gh repo view --json nameWithOwner -q .nameWithOwner)\nOWNER=$(gh repo view --json owner -q .owner.login)\n```\n\n## Step 3: Get Project Title\n\n**If $ARGUMENTS contains a title:** Use it directly.\n\n```bash\nTITLE=\"$ARGUMENTS\"\n```\n\n**If $ARGUMENTS is empty:** Use `AskUserQuestion` to prompt for the title.\n\n```json\n{\n  \"question\": \"What should the new GitHub Project be called?\",\n  \"header\": \"Title\",\n  \"multiSelect\": false,\n  \"options\": [\n    {\"label\": \"Roadmap\", \"description\": \"General product roadmap\"},\n    {\"label\": \"Sprint Board\", \"description\": \"Agile sprint tracking\"},\n    {\"label\": \"Feature Development\", \"description\": \"Feature work tracking\"}\n  ]\n}\n```\n\n- If user selects an option, use that as `TITLE`\n- If user selects \"Other\" and provides custom text, use that as `TITLE`\n\n## Step 4: Check for Template Project\n\n**If `GHPM_TEMPLATE_PROJECT` is set:**\n\n```bash\nTEMPLATE_OWNER=\"${GHPM_TEMPLATE_OWNER:-$OWNER}\"\nTEMPLATE_NUMBER=\"$GHPM_TEMPLATE_PROJECT\"\n\n# Verify template exists\ngh project view \"$TEMPLATE_NUMBER\" --owner \"$TEMPLATE_OWNER\" --format json > /dev/null 2>&1\n```\n\n**If not set:** Check if owner has any template projects available:\n\n```bash\n# Query for template projects\nTEMPLATES=$(gh api graphql -f query=\"\n{\n  user(login: \\\"$OWNER\\\") {\n    projectsV2(first: 10) {\n      nodes {\n        number\n        title\n        template\n      }\n    }\n  }\n}\" --jq '.data.user.projectsV2.nodes | map(select(.template == true))')\n\n# For organizations, use:\n# gh api graphql -f query=\"{ organization(login: \\\"$OWNER\\\") { ... } }\"\n```\n\n**If templates found:** Use `AskUserQuestion` to let user choose:\n\n```json\n{\n  \"question\": \"Would you like to create from a template project?\",\n  \"header\": \"Template\",\n  \"multiSelect\": false,\n  \"options\": [\n    {\"label\": \"<Template Name 1>\", \"description\": \"Project #<number> - includes pre-configured views\"},\n    {\"label\": \"<Template Name 2>\", \"description\": \"Project #<number> - includes pre-configured views\"},\n    {\"label\": \"Blank project\", \"description\": \"Start fresh with default Table view only\"}\n  ]\n}\n```\n\n## Step 5: Create the Project\n\n**Option A: Copy from template**\n\n```bash\nPROJECT_DATA=$(gh project copy \"$TEMPLATE_NUMBER\" \\\n  --source-owner \"$TEMPLATE_OWNER\" \\\n  --target-owner \"$OWNER\" \\\n  --title \"$TITLE\" \\\n  --format json)\n\nPROJECT_NUMBER=$(echo \"$PROJECT_DATA\" | jq -r '.number')\nPROJECT_URL=$(echo \"$PROJECT_DATA\" | jq -r '.url')\n```\n\n**Option B: Create blank project**\n\n```bash\nPROJECT_DATA=$(gh project create \\\n  --owner \"$OWNER\" \\\n  --title \"$TITLE\" \\\n  --format json)\n\nPROJECT_NUMBER=$(echo \"$PROJECT_DATA\" | jq -r '.number')\nPROJECT_URL=$(echo \"$PROJECT_DATA\" | jq -r '.url')\n```\n\n## Step 6: Link Project to Repository\n\n```bash\ngh project link \"$PROJECT_NUMBER\" --owner \"$OWNER\" --repo \"$REPO\"\n```\n\n## Step 7: Set GHPM_PROJECT Variable\n\nReport the command to set the environment variable:\n\n```bash\nexport GHPM_PROJECT=\"$TITLE\"\n```\n\n</workflow>\n\n<error_handling>\n\n**If gh CLI not authenticated:**\n\n- Check: `gh auth status`\n- Fix: `gh auth login`\n\n**If missing project scope:**\n\n- Check: `gh auth status` (look for \"project\" in scopes)\n- Fix: `gh auth refresh -s project`\n\n**If template project not found:**\n\n- Verify template number: `gh project view <number> --owner <owner>`\n- Fall back to creating blank project\n\n**If project creation fails:**\n\n- Check rate limits: `gh api rate_limit`\n- Verify owner permissions\n- Check if project with same name already exists\n\n**If linking fails:**\n\n- Verify repository exists: `gh repo view`\n- Project may already be linked (not an error)\n\n</error_handling>\n\n<success_criteria>\n\nCommand completes successfully when:\n\n1. Project is created (from template or blank)\n2. Project is linked to current repository\n3. Project number and URL are captured\n4. User is informed how to set `GHPM_PROJECT`\n\n**Verification:**\n\n```bash\n# View the created project\ngh project view <project_number> --owner <owner>\n\n# Verify link to repository\ngh api graphql -f query='\n{\n  repository(owner: \"<owner>\", name: \"<repo>\") {\n    projectsV2(first: 5) {\n      nodes { title number }\n    }\n  }\n}'\n```\n\n</success_criteria>\n\n<output>\n\nAfter completion, report:\n\n1. **Project Created:** \"<TITLE>\" (#<number>)\n2. **URL:** <project_url>\n3. **Repository:** <owner>/<repo>\n4. **Created From:** \"Template: <template_name>\" or \"Blank project\"\n5. **Linked:** Yes/No\n\n**Example Output:**\n\n```\nProject Created Successfully\n\nProject: \"Q1 Roadmap\" (#8)\nURL: https://github.com/users/el-feo/projects/8\nRepository: el-feo/ai-context\nCreated From: Template \"GHPM Template\" (#7)\nLinked: Yes\n\nTo use this project with GHPM commands, run:\n  export GHPM_PROJECT=\"Q1 Roadmap\"\n\nOr add to your shell profile for persistence.\n\nNext Steps:\n- Configure views in the project UI if needed: <project_url>\n- Run `/ghpm:create-prd <description>` to create your first PRD\n```\n\n**If created from blank project, add:**\n\n```\nNote: This project was created without a template.\nVisit the project URL to add custom views (Board, Roadmap, etc.)\n```\n\n</output>\n\n<template_setup>\n\n## Creating a Template Project (One-Time Setup)\n\nTo enable the \"copy from template\" feature, create a template project:\n\n1. **Create a project manually** with your desired configuration:\n   - Add views (Board, Table, Roadmap)\n   - Configure fields (Status, Priority, Sprint, etc.)\n   - Set up filters and groupings\n\n2. **Mark it as a template:**\n\n   ```bash\n   gh project mark-template <project_number> --owner <owner>\n   ```\n\n3. **Optionally set as default template:**\n\n   ```bash\n   export GHPM_TEMPLATE_PROJECT=\"<project_number>\"\n   export GHPM_TEMPLATE_OWNER=\"<owner>\"\n   ```\n\n**Recommended Template Configuration:**\n\n- **Views:**\n  - Table (default) - All items\n  - Board - Grouped by Status\n  - Roadmap - Timeline view\n\n- **Fields:**\n  - Status: Todo, In Progress, In Review, Done\n  - Priority: High, Medium, Low\n  - Type: PRD, Epic, Task\n  - Sprint/Iteration (optional)\n\n</template_setup>\n\n<related_commands>\n\n**GHPM Workflow:**\n\n1. **Current:** `/ghpm:create-project` - Create and link a GitHub Project\n2. **Next:** `/ghpm:create-prd <description>` - Create PRD in the project\n3. **Then:** `/ghpm:create-epics prd=#N` - Break PRD into Epics\n4. **Then:** `/ghpm:create-tasks epic=#N` - Break Epics into Tasks\n5. **Finally:** `/ghpm:tdd-task task=#N` - Implement Tasks with TDD\n\n</related_commands>\n\nNow proceed:\n\n1. Validate environment prerequisites.\n2. Determine repository and owner.\n3. Get project title from $ARGUMENTS or prompt user.\n4. Check for available template projects.\n5. If templates available, ask user to choose template or blank.\n6. Create the project (copy from template or create blank).\n7. Link the project to the current repository.\n8. Report success and next steps."
              },
              {
                "name": "/create-tasks",
                "description": "Break an Epic (or all Epics under a PRD) into atomic Task issues and link them back.",
                "path": "plugins/ghpm/commands/create-tasks.md",
                "frontmatter": {
                  "description": "Break an Epic (or all Epics under a PRD) into atomic Task issues and link them back.",
                  "allowed-tools": [
                    "Read",
                    "Bash",
                    "Grep",
                    "Glob"
                  ],
                  "arguments": {
                    "epic": {
                      "description": "Epic issue number (format: epic=#123)",
                      "required": false
                    },
                    "prd": {
                      "description": "PRD issue number to generate tasks for all linked Epics (format: prd=#123)",
                      "required": false
                    }
                  }
                },
                "content": "<objective>\nYou are GHPM (GitHub Project Manager). Convert an Epic into a set of atomic Task issues (single unit of work) using `gh`. Each task is independently executable and includes all necessary context.\n</objective>\n\n<prerequisites>\n- `gh` CLI installed and authenticated (`gh auth status`)\n- Working directory is a git repository with GitHub remote\n- Target Epic or PRD issue exists and is accessible\n- Optional: `GHPM_PROJECT` environment variable set to project number (e.g., `export GHPM_PROJECT=7`)\n- Optional: GitHub Project has an \"Estimate\" field (Number type) for task sizing\n</prerequisites>\n\n<arguments>\n**Optional arguments:**\n- `epic=#123` - Specific Epic issue number (preferred)\n- `prd=#123` - PRD issue number (generates tasks for all linked Epics)\n\n**Resolution order if omitted:**\n\n1. Most recent open Epic issue:\n   `gh issue list -l Epic -s open --limit 1 --json number -q '.[0].number'`\n</arguments>\n\n<usage_examples>\n**With epic number:**\n\n```bash\n/ghpm:create-tasks epic=#42\n```\n\n**With PRD number (creates tasks for all linked Epics):**\n\n```bash\n/ghpm:create-tasks prd=#10\n```\n\n**Auto-resolve most recent Epic:**\n\n```bash\n/ghpm:create-tasks\n```\n\n</usage_examples>\n\n<operating_rules>\n\n- Do not ask clarifying questions. Make assumptions and record them.\n- Do not create local markdown files. All output goes into GitHub issues/comments.\n- Tasks must be atomic and independently executable by a human or agent.\n- Each Task must include all context needed for its scope (plus links to Epic/PRD).\n- Each Task MUST include a **Commit Type** (`feat`, `fix`, `refactor`, etc.) and **Scope** for conventional commits.\n- **Task count must be proportional to Epic scope** - see guidance below.\n- **Each Task MUST have a Fibonacci estimate** (1, 2, 3, 5, or 8) - see estimation guidance below.\n</operating_rules>\n\n<estimation_guidance>\n\n## Fibonacci Estimation Scale\n\nAssign a Fibonacci estimate to each Task based on relative complexity. Estimates reflect effort/complexity, not hours.\n\n| Estimate | Complexity   | Examples                                                         |\n| -------- | ------------ | ---------------------------------------------------------------- |\n| **1**    | Trivial      | Update README, fix typo, change config value                     |\n| **2**    | Simple       | Add a single test, update documentation section, simple refactor |\n| **3**    | Moderate     | Add simple feature, refactor small module, add validation        |\n| **5**    | Complex      | Multi-file feature, significant refactor, new API endpoint       |\n| **8**    | Very Complex | Cross-cutting feature, complex integration, architectural change |\n\n### Decomposition Rule\n\n**Tasks estimated >8 MUST be decomposed.** If a task would be estimated higher than 8:\n\n1. Do NOT create the task as-is\n2. Break it into smaller, independent tasks\n3. Each sub-task should be estimable at 8 or below\n4. Re-analyze scope to find natural boundaries\n\n### Estimation Heuristics\n\n- **File count**: 1 file = 1-2, 2-3 files = 3, 4+ files = 5-8\n- **Test requirements**: No tests = lower, comprehensive tests = higher\n- **Dependencies**: Self-contained = lower, cross-cutting = higher\n- **Unknowns**: Clear requirements = lower, exploration needed = higher\n\n</estimation_guidance>\n\n<task_count_guidance>\n\n## Determining Appropriate Task Count\n\n**Match task count to Epic complexity, not a fixed range.** Over-decomposition creates overhead without value.\n\n### Heuristics\n\n| Epic Scope                    | Task Count | Example                                          |\n| ----------------------------- | ---------- | ------------------------------------------------ |\n| Single file, simple change    | 1 task     | Update README, fix typo, change config           |\n| Single file, multiple changes | 1-2 tasks  | Refactor a module, update docs with verification |\n| Multiple related files        | 2-4 tasks  | Add feature touching model + controller + view   |\n| Cross-cutting feature         | 4-8 tasks  | New API endpoint with auth, tests, docs          |\n| Large architectural change    | 8-15 tasks | Database migration, new service layer            |\n\n### Signs of Over-Decomposition\n\n- Tasks that would result in the same commit\n- Tasks that can't be meaningfully verified independently\n- \"Verify X\" as a separate task from \"Update X\"\n- Multiple tasks touching the same file for related changes\n\n### Signs of Under-Decomposition\n\n- Task requires multiple unrelated commits\n- Task touches many files across different concerns\n- Task has acceptance criteria spanning multiple features\n\n### Rule of Thumb\n\n**If an Epic affects 1-2 files with a clear scope, 1-2 tasks is usually sufficient.**\n\n</task_count_guidance>\n\n<input_validation>\n\n## Validation Checks\n\nBefore proceeding, validate:\n\n```bash\n# 1. Check gh CLI authentication\ngh auth status || { echo \"ERROR: Not authenticated. Run 'gh auth login'\"; exit 1; }\n\n# 2. Validate issue number format (if provided)\n# Epic and PRD numbers must be positive integers\n\n# 3. Verify issue exists and is accessible\ngh issue view \"$EPIC\" > /dev/null 2>&1 || { echo \"ERROR: Cannot access issue #$EPIC\"; exit 1; }\n```\n\n</input_validation>\n\n<task_issue_format>\n\n## Task Issue Body Template\n\nUse this streamlined template. Tasks link to Epic only (PRD reachable via Epic).\n\n```markdown\n# Task: <Name>\n\n**Epic:** #<EPIC_NUMBER> | **Type:** `<type>` | **Scope:** `<scope>`\n\n## Objective\n<1-2 sentences: what to implement>\n\n## Acceptance Criteria\n- [ ] Criterion 1\n- [ ] Criterion 2\n- [ ] ...\n\n## Test Plan\n<How to verify completion - manual steps, test commands, or verification approach>\n```\n\n### Template Guidance\n\n- **Context line**: Single line with Epic link, commit type, and scope (no PRD link - navigate via Epic)\n- **Objective**: Concise statement merging previous \"Objective\" and \"Scope (In)\" sections\n- **Acceptance Criteria**: Task-level, testable criteria\n- **Test Plan**: How to verify the task is complete\n\n**Omit these sections** (redundant or rarely populated):\n\n- PRD link (reachable via Epic)\n- Scope (In) (merge into Objective)\n- Out of Scope (inherit from Epic)\n- Implementation Notes (use comments if needed)\n- Risks / Edge Cases (inherit from Epic/PRD)\n- Notes / Open Questions (use issue comments instead)\n\n### Commit Type Guidelines\n\nThe **Commit Type** field determines the conventional commit prefix used during implementation:\n\n| Type       | Use When                                            |\n| ---------- | --------------------------------------------------- |\n| `feat`     | Adding new functionality, features, or capabilities |\n| `fix`      | Fixing bugs, errors, or incorrect behavior          |\n| `refactor` | Restructuring code without changing behavior        |\n| `test`     | Adding or improving tests only                      |\n| `docs`     | Documentation changes only                          |\n| `chore`    | Build, CI, dependencies, or tooling changes         |\n\n**How to determine:**\n\n1. Task creates new user-facing behavior → `feat`\n2. Task fixes reported issue/bug → `fix`\n3. Task improves code quality without behavior change → `refactor`\n4. Task adds/updates tests without implementation → `test`\n5. Task updates documentation → `docs`\n6. Task updates build/CI/tooling → `chore`\n\n</task_issue_format>\n\n<workflow>\n\n## Step 1: Resolve Target Epic(s)\n\n```bash\n# If epic=#N provided, use N\nEPIC={provided_epic_number}\n\n# Else if prd=#N provided, find Epics as sub-issues of the PRD\n# NOTE: Use heredoc to avoid shell escaping issues with '!' characters\nOWNER=$(gh repo view --json owner -q '.owner.login')\nREPO=$(gh repo view --json name -q '.name')\n\ncat > /tmp/ghpm-subissues.graphql << 'GRAPHQL'\nquery($owner: String!, $repo: String!, $number: Int!) {\n  repository(owner: $owner, name: $repo) {\n    issue(number: $number) {\n      subIssues(first: 50) {\n        nodes {\n          number\n          title\n          state\n          labels(first: 10) {\n            nodes { name }\n          }\n        }\n      }\n    }\n  }\n}\nGRAPHQL\n\ngh api graphql -F owner=\"$OWNER\" -F repo=\"$REPO\" -F number=$PRD \\\n  -f query=\"$(cat /tmp/ghpm-subissues.graphql)\" \\\n  --jq '.data.repository.issue.subIssues.nodes[] | select(.state == \"OPEN\") | select(.labels.nodes[].name == \"Epic\") | [.number, .title] | @tsv'\n\n# Else pick most recent open Epic\ngh issue list -l Epic -s open --limit 1 --json number -q '.[0].number'\n```\n\n## Step 2: Fetch Epic Context\n\nFor each Epic:\n\n```bash\n# Fetch Epic body and metadata\ngh issue view \"$EPIC\" --json title,body,url,labels -q '.'\n```\n\n**Extract from Epic:**\n\n- Objective and scope\n- PRD reference (look for `PRD: #123` or similar pattern)\n- Acceptance criteria to decompose\n\n## Step 3: Generate Task Issues\n\nFor each Epic, generate the appropriate number of atomic tasks based on the task count guidance above.\n\nCreate each task:\n\n```bash\n# Create the task issue\nTASK_URL=$(gh issue create \\\n  --title \"Task: <Name>\" \\\n  --label \"Task\" \\\n  --body \"<Task markdown from template>\")\n\n# Extract task number from URL\nTASK_NUM=$(echo \"$TASK_URL\" | grep -oE '[0-9]+$')\n\n# Set the estimate value determined during task planning (1, 2, 3, 5, or 8)\nESTIMATE=<fibonacci_number>  # Replace with actual estimate, e.g., ESTIMATE=3\n```\n\nIf `$GHPM_PROJECT` is set (project number), add the task to the project and set the Estimate field:\n\n```bash\n# Add task to project and set estimate (if GHPM_PROJECT is set)\nif [ -n \"$GHPM_PROJECT\" ]; then\n  # Add to project (GHPM_PROJECT should be the project number, e.g., \"7\")\n  ITEM_ID=$(gh project item-add \"$GHPM_PROJECT\" --owner \"$OWNER\" --url \"$TASK_URL\" --format json 2>/dev/null | jq -r '.id')\n\n  if [ -n \"$ITEM_ID\" ] && [ \"$ITEM_ID\" != \"null\" ]; then\n    # Get project ID and Estimate field ID\n    PROJECT_DATA=$(gh project view \"$GHPM_PROJECT\" --owner \"$OWNER\" --format json 2>/dev/null)\n    PROJECT_ID=$(echo \"$PROJECT_DATA\" | jq -r '.id')\n    ESTIMATE_FIELD_ID=$(gh project field-list \"$GHPM_PROJECT\" --owner \"$OWNER\" --format json 2>/dev/null | jq -r '.fields[] | select(.name == \"Estimate\") | .id')\n\n    if [ -n \"$ESTIMATE_FIELD_ID\" ] && [ \"$ESTIMATE_FIELD_ID\" != \"null\" ]; then\n      # Set estimate value (ESTIMATE is the Fibonacci number assigned to this task)\n      gh project item-edit --project-id \"$PROJECT_ID\" --id \"$ITEM_ID\" --field-id \"$ESTIMATE_FIELD_ID\" --number \"$ESTIMATE\" 2>/dev/null \\\n        && echo \"✓ Set estimate $ESTIMATE for Task #$TASK_NUM\" \\\n        || echo \"WARNING: Could not set estimate for Task #$TASK_NUM\"\n    else\n      echo \"WARNING: Estimate field not found in project. Add a Number field named 'Estimate'.\"\n    fi\n  else\n    echo \"WARNING: Could not add Task #$TASK_NUM to project '$GHPM_PROJECT'\"\n  fi\nfi\n```\n\n## Step 4: Link Tasks as Sub-Issues of Epic\n\n**IMPORTANT:** Tasks MUST be linked as sub-issues of the Epic, not just listed in a comment.\n\nFor each created task, link it as a sub-issue:\n\n```bash\n# Get the Epic's internal issue ID\nEPIC_ID=$(gh api repos/{owner}/{repo}/issues/$EPIC --jq .id)\n\n# Get the Task's internal issue ID\nTASK_ID=$(gh api repos/{owner}/{repo}/issues/$TASK_NUM --jq .id)\n\n# Add task as sub-issue of Epic\ngh api repos/{owner}/{repo}/issues/$EPIC/sub_issues \\\n  -X POST \\\n  -F sub_issue_id=$TASK_ID \\\n  --silent || echo \"Warning: Could not link Task #$TASK_NUM as sub-issue\"\n```\n\nAfter all tasks are created and linked, optionally comment on the Epic with a summary:\n\n```bash\ngh issue comment \"$EPIC\" --body \"$(cat <<'EOF'\n## Tasks Created\n\nCreated and linked as sub-issues:\n\n- #<TASK_1> Task: <Name>\n- #<TASK_2> Task: <Name>\n...\n\nView sub-issues in the Epic's \"Sub-issues\" section.\nEOF\n)\"\n```\n\n## Step 5: Update PRD (if known)\n\nIf PRD is known, comment on the PRD (one comment per Epic, avoid spam):\n\n```bash\ngh issue comment \"$PRD\" --body \"Tasks created for Epic #$EPIC - see checklist on the Epic.\"\n```\n\n</workflow>\n\n<error_handling>\n**If gh CLI not authenticated:**\n\n- Check: `gh auth status`\n- Fix: `gh auth login`\n\n**If Epic/PRD not found:**\n\n- Verify issue number is correct\n- Check repository access permissions\n- Confirm issue is not closed/deleted\n\n**If issue creation fails:**\n\n- Check rate limits: `gh api rate_limit`\n- Verify label \"Task\" exists or omit label\n- Check repository write permissions\n\n**If sub-issue linking fails:**\n\n- Continue with next task (don't block on linking failures)\n- Log warning in output summary with specific task number\n- Common causes: task already has a parent, duplicate sub-issue, API error\n- Verify with: `gh api repos/{owner}/{repo}/issues/$EPIC/sub_issues`\n\n**If project association fails:**\n\n- Continue without project association\n- Log warning in output summary\n- Verify `$GHPM_PROJECT` value is correct\n\n**If Estimate field is missing from project:**\n\n- Log warning: \"Estimate field not found in project. Add a Number field named 'Estimate'.\"\n- Continue without setting estimate\n- Tasks are still created and linked correctly\n- Provide setup instructions in warning\n\n**If task would exceed estimate of 8:**\n\n- Do NOT create the task\n- Log: \"Task scope too large (would be >8). Decomposing into smaller tasks.\"\n- Break task into smaller units (each ≤8)\n- Create the smaller tasks instead\n</error_handling>\n\n<success_criteria>\nCommand completes successfully when:\n\n1. All target Epics have been processed\n2. Each Epic has an appropriate number of Task issues (per task count guidance)\n3. Each Task issue contains required sections: Context line (Epic, Type, Scope), Objective, Acceptance Criteria, Test Plan\n4. Each Task has a Fibonacci estimate (1, 2, 3, 5, or 8) - no task exceeds 8\n5. Each Task is linked as a sub-issue of its Epic\n6. If `GHPM_PROJECT` set, Estimate field is populated (or warning issued if field missing)\n7. PRD is notified (if applicable)\n8. Optional sections omitted when not populated with meaningful content\n\n**Verification:**\n\n```bash\n# List created tasks\ngh issue list -l Task -s open --limit 50 --json number,title\n\n# Verify sub-issues are linked to Epic\ngh api repos/{owner}/{repo}/issues/$EPIC/sub_issues --jq '.[] | [.number, .title] | @tsv'\n\n# View Epic to confirm (sub-issues appear in issue view)\ngh issue view \"$EPIC\"\n```\n\n</success_criteria>\n\n<output>\nAfter completion, report:\n\n1. **Epic(s) processed:** # and URL for each\n2. **Tasks created:** Issue numbers, URLs, and estimates\n\n   | Task | Title      | Estimate |\n   | ---- | ---------- | -------- |\n   | #N   | Task: Name | 3        |\n\n3. **Sub-issue linking:** Success/failure for each task linked to Epic\n4. **Total tasks:** Count per Epic, total estimate points\n5. **Project association:** Success/failure status (if `$GHPM_PROJECT` set)\n6. **Estimate field:** Success/failure for setting estimates (if `$GHPM_PROJECT` set)\n7. **Warnings:** Any issues encountered (e.g., sub-issue linking failed, project add failed, Estimate field missing)\n</output>\n\nProceed now."
              },
              {
                "name": "/execute",
                "description": "Execute a Task or Epic, routing to TDD or non-TDD workflow based on commit type.",
                "path": "plugins/ghpm/commands/execute.md",
                "frontmatter": {
                  "description": "Execute a Task or Epic, routing to TDD or non-TDD workflow based on commit type.",
                  "allowed-tools": [
                    "Read",
                    "Edit",
                    "Write",
                    "Bash",
                    "Grep",
                    "Glob",
                    "SlashCommand",
                    "Task",
                    "Skill(ruby)",
                    "Skill(javascript)",
                    "Skill(rspec)",
                    "Skill(javascript-unit-testing)",
                    "Skill(rubycritic)",
                    "Skill(simplecov)"
                  ],
                  "arguments": {
                    "task": {
                      "description": "Task issue number (format: task=#123)",
                      "required": false
                    },
                    "epic": {
                      "description": "Epic issue number to execute all tasks (format: epic=#123)",
                      "required": false
                    }
                  }
                },
                "content": "<objective>\nExecute a GitHub Task (or all Tasks under an Epic) by routing to the appropriate workflow:\n\n- **TDD workflow** (`/ghpm:tdd-task`): For `feat`, `fix`, `refactor` commit types\n- **Non-TDD workflow**: For `test`, `docs`, `chore`, `style`, `perf` commit types\n\nBoth workflows produce identical outputs: conventional commits, Task Report, and a PR that closes the Task.\n</objective>\n\n<arguments>\n**Optional arguments:**\n- `task=#123` - Specific task issue number\n- `epic=#123` - Epic issue number (executes all open tasks under the epic)\n\n**Resolution order if omitted:**\n\n1. If branch name matches `ghpm/task-<N>-*` or `task-<N>-*`, use N\n2. Most recent open issue labeled `Task` assigned to @me:\n   `gh issue list -l Task -a @me -s open --limit 1 --json number -q '.[0].number'`\n3. Most recent open Task:\n   `gh issue list -l Task -s open --limit 1 --json number -q '.[0].number'`\n</arguments>\n\n<usage_examples>\n**Execute a single task (auto-routes based on commit type):**\n\n```bash\n/ghpm:execute task=#42\n```\n\n**Execute all tasks under an epic:**\n\n```bash\n/ghpm:execute epic=#10\n```\n\n**Auto-resolve from branch or GitHub:**\n\n```bash\n/ghpm:execute\n```\n\n</usage_examples>\n\n<operating_rules>\n\n- Always create a feature branch before making changes. Never commit directly to main/master.\n- No local markdown artifacts. Do not write local status files; only code changes + GitHub issue/PR updates.\n- Do NOT use the TodoWrite tool to track tasks during this session.\n- Do not silently expand scope. If needed, create a new follow-up Task issue and link it.\n- All commits and PR titles MUST follow Conventional Commits format for changelog generation.\n- When routing to TDD, delegate fully to `/ghpm:tdd-task` - do not duplicate its workflow.\n- When handling an Epic, process tasks sequentially (one PR per task, not batched).\n  - **Exception:** If multiple tasks modify the same file(s), batch them into a single PR with separate commits per task. Each commit must reference its task number.\n- Minimize noise: comment at meaningful milestones.\n</operating_rules>\n\n<routing_logic>\n\n## Determining Workflow Type\n\nRead the Task issue body and extract the **Commit Type** field:\n\n```\n- Commit Type: `<type>`\n```\n\n### Step 1: Check for Non-TDD Patterns (Override)\n\nBefore applying commit-type routing, check if the task matches these Non-TDD patterns:\n\n**Auto-route to Non-TDD if:**\n\n- Target files are non-code: `*.md`, `*.yml`, `*.yaml`, `*.json`, `*.toml`, `*.txt`\n- Task creates/modifies slash commands: path matches `commands/**/*.md` or `.claude/commands/**/*.md`\n- Task creates/modifies skills: path matches `skills/**/*.md` or `.claude/skills/**/*.md`\n- Task title contains: \"Create ... command\", \"Add ... slash command\", \"Update ... documentation\"\n- Scope indicates non-code: `docs`, `commands`, `skills`, `config`\n\nThese patterns indicate work where TDD is not applicable (tests cannot be written for markdown/config files).\n\n### Step 2: Apply Commit-Type Routing\n\nIf no Non-TDD pattern matched, route based on commit type:\n\n**Route to TDD workflow (`/ghpm:tdd-task`):**\n\n- `feat` - New features benefit from test-first development (when targeting code files)\n- `fix` - Bug fixes need tests to verify the fix\n- `refactor` - Refactoring requires tests to ensure behavior is preserved\n\n**Route to Non-TDD workflow (execute directly):**\n\n- `test` - Adding tests doesn't need TDD (you're already writing tests)\n- `docs` - Documentation changes don't need tests\n- `chore` - Build/CI/tooling changes typically don't need unit tests\n- `style` - Formatting changes don't need tests\n- `perf` - Performance changes may have benchmarks, not TDD cycles\n\n**If Commit Type is missing or unclear:**\n\n- Analyze the Task title and objective\n- Check target file extensions to determine if code or non-code\n- Default to TDD workflow for code changes (`.rb`, `.js`, `.ts`, `.py`, `.go`, etc.)\n- Default to Non-TDD for non-code changes (`.md`, `.yml`, `.json`, etc.)\n\n</routing_logic>\n\n<conventional_commits>\n\n## Conventional Commits Format\n\nAll commits and PR titles must follow the [Conventional Commits](https://www.conventionalcommits.org/) specification.\n\n### Format\n\n```\n<type>[optional scope]: <description> (#<issue>)\n```\n\n### Commit Types\n\n| Type       | Description                                | Changelog Section |\n| ---------- | ------------------------------------------ | ----------------- |\n| `feat`     | New feature or capability                  | Features          |\n| `fix`      | Bug fix                                    | Bug Fixes         |\n| `refactor` | Code restructuring without behavior change | Code Refactoring  |\n| `perf`     | Performance improvement                    | Performance       |\n| `test`     | Adding or updating tests                   | Testing           |\n| `docs`     | Documentation only changes                 | Documentation     |\n| `style`    | Formatting, whitespace (no code change)    | (excluded)        |\n| `chore`    | Build, CI, dependencies, tooling           | Maintenance       |\n\n</conventional_commits>\n\n<workflow>\n\n## Step 0: Resolve Target Task(s)\n\n### If `epic=#N` provided\n\n```bash\nEPIC=$N\n\n# Get repository owner and name\nOWNER=$(gh repo view --json owner -q '.owner.login')\nREPO=$(gh repo view --json name -q '.name')\n\n# Fetch all open sub-issues (Tasks) under this Epic using GraphQL API\n# GitHub sub-issues are linked via parent-child relationship, NOT by text mention\n# NOTE: Use heredoc to avoid shell escaping issues with '!' characters\ncat > /tmp/ghpm-subissues.graphql << 'GRAPHQL'\nquery($owner: String!, $repo: String!, $number: Int!) {\n  repository(owner: $owner, name: $repo) {\n    issue(number: $number) {\n      subIssues(first: 50) {\n        nodes {\n          number\n          title\n          state\n          labels(first: 10) {\n            nodes { name }\n          }\n        }\n      }\n    }\n  }\n}\nGRAPHQL\n\ngh api graphql -F owner=\"$OWNER\" -F repo=\"$REPO\" -F number=$EPIC \\\n  -f query=\"$(cat /tmp/ghpm-subissues.graphql)\" \\\n  --jq '.data.repository.issue.subIssues.nodes[] | select(.state == \"OPEN\") | select(.labels.nodes[].name == \"Task\") | [.number, .title] | @tsv'\n```\n\n## Step 0.5: Analyze Task Dependencies (Epic Mode Only)\n\nBefore processing tasks, analyze all task bodies to detect interdependencies:\n\n1. **Fetch all task bodies** for the Epic\n2. **Extract target file paths** from each task (look for file paths in Implementation Notes, Scope, or infer from task title/objective)\n3. **Group tasks by target file** - if multiple tasks modify the same file, they are interdependent\n4. **Determine execution strategy:**\n\n| Scenario | Strategy |\n|----------|----------|\n| All tasks target different files | Process sequentially, one PR per task |\n| Multiple tasks target same file | Batch into single PR with separate commits |\n| Tasks have explicit dependencies | Process in dependency order |\n\n**For batched tasks:**\n- Create a single branch named after the first task: `ghpm/task-$FIRST_TASK-<epic-slug>`\n- Make separate commits per task, each referencing its task number\n- Create single PR that closes all batched tasks\n- Comment PR URL on all batched task issues\n\nProcess tasks using Steps 1-6, applying batching strategy where applicable.\n\n### If `task=#N` provided\n\n```bash\nTASK=$N\n```\n\n### If no argument provided\n\n```bash\n# 1. Try branch name\nBRANCH=$(git rev-parse --abbrev-ref HEAD)\n# Extract task number from ghpm/task-<N>-* or task-<N>-*\n\n# 2. Most recent assigned Task\nTASK=$(gh issue list -l Task -a @me -s open --limit 1 --json number -q '.[0].number')\n\n# 3. Most recent open Task\nTASK=$(gh issue list -l Task -s open --limit 1 --json number -q '.[0].number')\n```\n\n## Step 0.9: Validate Task Status\n\nBefore proceeding with any task, check if it's already closed or marked as done:\n\n```bash\n# Fetch issue state and labels\nISSUE_DATA=$(gh issue view \"$TASK\" --json state,labels,projectItems -q '.')\nSTATE=$(echo \"$ISSUE_DATA\" | jq -r '.state')\n\n# Check if issue is closed\nif [ \"$STATE\" = \"CLOSED\" ]; then\n  echo \"Task #$TASK is already CLOSED. Skipping.\"\n  # If processing an Epic, continue to next task; otherwise exit\n  exit 0  # or continue to next task in Epic mode\nfi\n\n# Check for \"Done\" label\nDONE_LABEL=$(echo \"$ISSUE_DATA\" | jq -r '.labels[]?.name | select(. == \"Done\" or . == \"done\" or . == \"DONE\")')\nif [ -n \"$DONE_LABEL\" ]; then\n  echo \"Task #$TASK has 'Done' label. Skipping.\"\n  exit 0\nfi\n\n# Check project status field (if linked to a project)\nPROJECT_STATUS=$(echo \"$ISSUE_DATA\" | jq -r '.projectItems[]?.status?.name // empty')\nif [ \"$PROJECT_STATUS\" = \"Done\" ] || [ \"$PROJECT_STATUS\" = \"Completed\" ]; then\n  echo \"Task #$TASK has project status '$PROJECT_STATUS'. Skipping.\"\n  exit 0\nfi\n```\n\n**Behavior:**\n- If task is CLOSED → skip and report \"Task #N is already closed\"\n- If task has \"Done\" label → skip and report \"Task #N is marked as done\"\n- If task's project status is \"Done\" or \"Completed\" → skip and report status\n- For Epic mode: continue to next task after skipping\n- For single task mode: exit with informational message\n\n## Step 0.95: Claim Issue\n\nBefore starting any work, claim the issue to prevent duplicate work and enable progress tracking.\n\n**Important for Epic mode:** Claim each sub-task sequentially as its execution begins, NOT all tasks at once upfront.\n\n```bash\n# Get current GitHub user\nCURRENT_USER=$(gh api user -q '.login')\nif [ -z \"$CURRENT_USER\" ]; then\n  echo \"ERROR: Could not determine current GitHub user. Run 'gh auth login'\"\n  exit 1\nfi\n\n# Check existing assignees\nASSIGNEES=$(gh issue view \"$TASK\" --json assignees -q '.assignees[].login')\n\n# Handle assignment scenarios\nif [ -z \"$ASSIGNEES\" ]; then\n  # No assignees - claim the issue\n  gh issue edit \"$TASK\" --add-assignee @me\n  echo \"✓ Assigned to @$CURRENT_USER\"\n\n  # Post audit comment\n  TIMESTAMP=$(date -u +\"%Y-%m-%d %H:%M:%S UTC\")\n  gh issue comment \"$TASK\" --body \"🏷️ Claimed by @$CURRENT_USER at $TIMESTAMP\"\n\nelif echo \"$ASSIGNEES\" | grep -qx \"$CURRENT_USER\"; then\n  # Already assigned to current user - proceed\n  echo \"✓ Already assigned to you (@$CURRENT_USER)\"\n\nelse\n  # Assigned to another user - abort\n  EXISTING_ASSIGNEE=$(echo \"$ASSIGNEES\" | head -1)\n  echo \"✗ Task #$TASK is already claimed by @$EXISTING_ASSIGNEE\"\n  # For Epic mode: continue to next task\n  # For single task mode: exit with error\n  exit 1\nfi\n\n# Update project status to \"In Progress\" (best-effort)\nif [ -n \"$GHPM_PROJECT\" ]; then\n  OWNER=$(gh repo view --json owner -q '.owner.login')\n  # Note: Project status update is best-effort and may require manual verification\n  echo \"Note: Project status update to 'In Progress' is best-effort\"\nfi\n\n# Warn on orphaned state (In Progress without assignee)\nif [ -z \"$ASSIGNEES\" ] && [ -n \"$GHPM_PROJECT\" ]; then\n  PROJECT_STATUS=$(gh issue view \"$TASK\" --json projectItems -q '.projectItems[0].status.name // empty' 2>/dev/null)\n  if [ \"$PROJECT_STATUS\" = \"In Progress\" ]; then\n    echo \"⚠ Warning: Task #$TASK had status 'In Progress' but no assignee\"\n  fi\nfi\n```\n\n**UX Output:**\n\n| Scenario | Output |\n|----------|--------|\n| Success (new claim) | `✓ Assigned to @username` |\n| Self-claim | `✓ Already assigned to you (@username)` |\n| Conflict | `✗ Task #N is already claimed by @another-user` |\n| Orphaned state | `⚠ Warning: Task #N had status 'In Progress' but no assignee` |\n\n**Behavior:**\n\n- Claiming occurs BEFORE any work begins (before context hydration)\n- For `task=#N` mode: claim single task before execution\n- For `epic=#N` mode: claim each sub-task ONLY when its execution begins (not all at once)\n- On conflict, command aborts cleanly with no partial work on that task\n- On self-claim, command proceeds normally\n- All claiming operations complete within 3 seconds\n\n## Step 1: Hydrate Context and Determine Routing\n\n```bash\n# Fetch issue details\ngh issue view \"$TASK\" --json title,body,url,labels,comments -q '.'\n```\n\n**Extract from issue:**\n\n- Commit Type (from body: `Commit Type: \\`<type>\\``)\n- Scope (from body: `Scope: \\`<scope>\\``)\n- Target file paths (from Implementation Notes or infer from task)\n- Acceptance criteria\n- Test plan (or infer if missing)\n- Epic/PRD links\n\n**Determine workflow (see <routing_logic> for details):**\n\n```\n1. Check Non-TDD Patterns (Override):\n   If target files are non-code (*.md, *.yml, *.json, etc.):\n       → Route to Non-TDD workflow (Step 2B)\n   If task creates slash commands or skills:\n       → Route to Non-TDD workflow (Step 2B)\n\n2. Apply Commit-Type Routing:\n   If Commit Type in [feat, fix, refactor] AND targeting code files:\n       → Route to TDD workflow (Step 2A)\n   Else if Commit Type in [test, docs, chore, style, perf]:\n       → Route to Non-TDD workflow (Step 2B)\n   Else:\n       → Analyze task content and make best judgment\n```\n\n## Step 2A: TDD Workflow (Delegate)\n\nFor `feat`, `fix`, `refactor` tasks, delegate to the TDD command:\n\n```bash\n/ghpm:tdd-task task=#$TASK\n```\n\nThe TDD command handles all subsequent steps. Proceed to next task if processing an Epic.\n\n## Step 2B: Non-TDD Workflow (Execute Directly)\n\nFor `test`, `docs`, `chore`, `style`, `perf` tasks, execute directly.\n\n### Step 2B.1: Post Implementation Plan\n\nComment on the Task with your implementation plan:\n\n```markdown\n## Implementation Plan\n\n- **Objective:** <from task>\n- **Commit Type:** `<type>`\n- **Scope:** `<scope>`\n- **What will be changed:**\n- **Verification approach:** (manual verification, existing tests, linting, etc.)\n- **Milestones:**\n```\n\nExecute:\n\n```bash\ngh issue comment \"$TASK\" --body \"<markdown>\"\n```\n\n### Step 2B.2: Create Working Branch\n\n```bash\ngit checkout -b \"ghpm/task-$TASK-<short-slug>\"\n```\n\nComment branch name to the issue.\n\n### Step 2B.3: Execute the Work\n\nFor each milestone:\n\n1. Make the changes\n2. Verify the changes work (run existing tests, manual verification, linting)\n3. Commit using conventional commit format:\n\n   ```\n   <type>(<scope>): <description> (#$TASK)\n   ```\n\n**Commit patterns by type:**\n\n- `test`: `test(<scope>): add tests for <behavior> (#$TASK)`\n- `docs`: `docs(<scope>): update documentation for <topic> (#$TASK)`\n- `chore`: `chore(<scope>): update <tooling/config> (#$TASK)`\n- `style`: `style(<scope>): format <files/code> (#$TASK)`\n- `perf`: `perf(<scope>): optimize <operation> (#$TASK)`\n\nAfter meaningful progress, comment on the Task with:\n\n- What changed\n- Verification performed\n- Commit hash(es) made\n- Any decisions/rationale\n\n### Step 2B.4: Update Task Report\n\nEdit the issue body to append:\n\n```markdown\n## Task Report (auto)\n\n### Implementation summary\n\n### Files changed\n\n### How to validate\n\n### Verification performed\n\n### Decision log\n\n### Follow-ups (if any)\n```\n\nExecute:\n\n```bash\ngh issue edit \"$TASK\" --body \"<updated markdown>\"\n```\n\n### Step 2B.5: Open PR\n\nPush branch and create PR:\n\n```bash\ngit push -u origin HEAD\n\ngh pr create --title \"<type>(<scope>): <description> (#$TASK)\" --body \"$(cat <<'EOF'\nCloses #$TASK\n\n## Summary\n\n- ...\n\n## Verification\n\n- <what was verified and how>\n\n## Commits\n\n<list of conventional commits made>\nEOF\n)\"\n```\n\nComment the PR URL back onto the Task:\n\n```bash\ngh issue comment \"$TASK\" --body \"PR created: <PR_URL>\"\n```\n\n### Step 2B.6: Verify CI Status\n\nAfter creating the PR, use the CI Check agent to verify GitHub Actions pass:\n\n```\nUse the Task tool with subagent_type=\"ghpm:ci-check\" to:\n1. Monitor CI status for the newly created PR\n2. Analyze any failures to determine if they're in-scope (related to PR changes) or out-of-scope (pre-existing)\n3. Attempt to fix in-scope failures\n4. Create follow-up issues for out-of-scope failures\n5. Report CI status back to the PR as a comment\n```\n\nThe agent will:\n- Wait for CI to complete (up to 10 minutes)\n- If all checks pass, comment success on the PR\n- If checks fail, analyze logs and categorize failures\n- Fix in-scope failures and push additional commits\n- Create follow-up issues for pre-existing failures\n- Post a CI Check Report comment on the PR\n\n**Note:** This step is advisory. If the CI check agent is not available or fails, proceed to the next step. The PR can still be merged manually after addressing CI issues.\n\n## Step 3: Process Next Task (Epic Mode)\n\nIf processing an Epic, move to the next task and repeat from Step 1.\n\nAfter all tasks are complete, comment on the Epic:\n\n```bash\ngh issue comment \"$EPIC\" --body \"$(cat <<'EOF'\n## Execution Complete\n\nAll tasks have been executed. PRs created:\n\n- #<TASK_1>: <PR_URL_1>\n- #<TASK_2>: <PR_URL_2>\n...\nEOF\n)\"\n```\n\n</workflow>\n\n<success_criteria>\nCommand completes when:\n\n**For single task:**\n\n- Task is executed (via TDD or Non-TDD workflow)\n- Task Report section is updated in the issue body\n- PR is created with `Closes #$TASK` in the body\n- PR URL is commented back to the Task\n- CI status is verified (CI Check agent invoked if available)\n\n**For epic (independent tasks):**\n\n- All open tasks under the Epic are processed\n- Each task has its own PR\n- Summary comment posted on Epic with all PR URLs\n\n**For epic (interdependent tasks - same target file):**\n\n- All interdependent tasks batched into single PR\n- Each task has its own commit referencing its task number\n- PR closes all batched tasks (`Closes #T1, Closes #T2, ...`)\n- PR URL commented on all batched task issues\n- Summary comment on Epic shows task-to-PR mapping\n</success_criteria>\n\n<error_handling>\n**If Commit Type cannot be determined:**\n\n- Check target file extensions first (Non-TDD patterns take priority)\n- Analyze task title and objective\n- Look for keywords: \"add\", \"implement\", \"create\" → TDD (if code); \"update docs\", \"fix CI\" → Non-TDD\n- Default to TDD for code files, Non-TDD for non-code files\n\n**If target files cannot be determined:**\n\n- Check task scope field for hints (`ghpm`, `commands`, `docs` → Non-TDD)\n- Look for file paths in Implementation Notes section\n- Ask in task comment if truly ambiguous (rare - most tasks indicate target)\n\n**If task is already in progress (branch exists):**\n\n- Check out existing branch instead of creating new\n- Continue from where left off\n\n**If delegation to /ghpm:tdd-task fails:**\n\n- Fall back to executing TDD workflow directly\n- Comment error details on Task issue\n\n**If verification fails (tests fail, lint errors):**\n\n- Do not proceed to PR\n- Comment on issue with failure details\n- Debug and fix before continuing\n</error_handling>\n\n<output>\nAfter completion, report:\n\n1. **Tasks executed:** Issue numbers and workflow type used\n2. **PRs created:** PR numbers and URLs (note batched tasks if applicable)\n3. **Routing decisions:** For each task, explain:\n   - Commit type detected\n   - Target file type (code vs non-code)\n   - Pattern matched (if Non-TDD override applied)\n   - Final workflow chosen and why\n4. **Batching decisions:** If tasks were batched, explain why (shared target files)\n5. **Warnings:** Any issues encountered\n</output>\n\nProceed now."
              },
              {
                "name": "/qa-create-steps",
                "description": "Create QA Step issues as sub-issues of a QA Issue",
                "path": "plugins/ghpm/commands/qa-create-steps.md",
                "frontmatter": {
                  "description": "Create QA Step issues as sub-issues of a QA Issue",
                  "allowed-tools": [
                    "Read",
                    "Bash",
                    "Grep",
                    "Glob"
                  ],
                  "arguments": {
                    "qa": {
                      "description": "QA issue number (format: qa=#123)",
                      "required": false
                    }
                  }
                },
                "content": "<qa_step_issue_template>\n\n## QA Step Issue Body Template\n\n```markdown\n# QA Step: <Brief Description>\n\n## Scenario\n\nAs a <role>,\nGiven <precondition>,\nWhen <action>,\nThen <expected outcome>\n\n## Parent QA Issue\n\n- QA: #<QA_NUMBER>\n\n## Test Details\n\n- **URL/Page:** <starting URL or page>\n- **Prerequisites:** <any setup needed>\n- **Test Data:** <if applicable>\n\n## Execution Log\n\n- [ ] Pass / Fail\n- **Executed by:** (not yet executed)\n- **Timestamp:** (pending)\n- **Notes:** (none)\n\n## Bugs Found\n\n(None)\n```\n\n### Template Field Descriptions\n\n| Field | Description |\n|-------|-------------|\n| `<Brief Description>` | Concise 3-8 word summary of what is being tested |\n| `<role>` | User role or persona (e.g., \"logged-in user\", \"admin\", \"guest\") |\n| `<precondition>` | Starting state before action (e.g., \"I am on the dashboard page\") |\n| `<action>` | Single user action being tested (e.g., \"I click the Submit button\") |\n| `<expected outcome>` | Observable result (e.g., \"I should see a success message\") |\n| `<QA_NUMBER>` | Parent QA Issue number |\n| `<URL/Page>` | Starting URL or page name |\n| `<Prerequisites>` | Any setup required before testing |\n| `<Test Data>` | Specific test data needed (if any) |\n\n### Given/When/Then Format Guidelines\n\n- **Given** describes the initial state or preconditions\n- **When** describes a single, atomic user action\n- **Then** describes the expected observable outcome\n- Keep each step atomic (one action per QA Step)\n- Use clear, specific language that is machine-parseable\n\n</qa_step_issue_template>\n\n<objective>\nYou are GHPM (GitHub Project Manager). Generate QA Step issues for systematic acceptance testing and link them as sub-issues of the specified QA Issue. Each QA Step follows the Given/When/Then format for consistent, machine-parseable test scenarios.\n</objective>\n\n<prerequisites>\n- `gh` CLI installed and authenticated (`gh auth status`)\n- Working directory is a git repository with GitHub remote\n- Target QA Issue exists and is accessible\n- QA Issue should have a linked PRD for context\n</prerequisites>\n\n<arguments>\n**Optional arguments:**\n- `qa=#123` - QA issue number\n\n**Resolution order if omitted:**\n\n1. Most recent open QA issue:\n   `gh issue list -l QA -s open --limit 1 --json number -q '.[0].number'`\n</arguments>\n\n<usage_examples>\n**With QA number:**\n\n```bash\n/ghpm:qa-create-steps qa=#42\n```\n\n**Auto-resolve most recent QA issue:**\n\n```bash\n/ghpm:qa-create-steps\n```\n\n</usage_examples>\n\n<workflow>\n\n## Step 1: Resolve Target QA Issue\n\n```bash\n# If qa=#N provided, use N\nQA={provided_qa_number}\n\n# Else pick most recent open QA issue\nQA=$(gh issue list -l QA -s open --limit 1 --json number -q '.[0].number')\n\nif [ -z \"$QA\" ]; then\n  echo \"Error: No open QA issue found. Specify qa=#N or create a QA issue first.\"\n  exit 1\nfi\n\n# Validate QA number is positive integer\nif ! [[ \"$QA\" =~ ^[0-9]+$ ]]; then\n  echo \"Error: Invalid QA number. Use format: qa=#123\"\n  exit 1\nfi\n```\n\n## Step 2: Fetch QA Issue and PRD Context\n\n```bash\n# Fetch QA Issue details\nQA_DATA=$(gh issue view \"$QA\" --json title,body,url -q '.')\nQA_TITLE=$(echo \"$QA_DATA\" | jq -r '.title')\nQA_BODY=$(echo \"$QA_DATA\" | jq -r '.body')\nQA_URL=$(echo \"$QA_DATA\" | jq -r '.url')\n\nif [ -z \"$QA_TITLE\" ]; then\n  echo \"Error: Could not fetch QA Issue #$QA. Check if it exists and is accessible.\"\n  exit 1\nfi\n\necho \"QA Issue #$QA: $QA_TITLE\"\necho \"URL: $QA_URL\"\n\n# Extract PRD reference from QA Issue body (look for \"PRD: #123\" pattern)\nPRD=$(echo \"$QA_BODY\" | grep -oE 'PRD: #[0-9]+' | head -1 | grep -oE '[0-9]+')\n\nif [ -n \"$PRD\" ]; then\n  # Fetch PRD details for additional context\n  PRD_DATA=$(gh issue view \"$PRD\" --json title,body -q '.')\n  PRD_TITLE=$(echo \"$PRD_DATA\" | jq -r '.title')\n  PRD_BODY=$(echo \"$PRD_DATA\" | jq -r '.body')\n  echo \"Parent PRD #$PRD: $PRD_TITLE\"\nelse\n  echo \"Warning: No PRD reference found in QA Issue. Generating steps from QA Issue context only.\"\nfi\n```\n\n## Step 3: Generate QA Steps from Context\n\nAnalyze the QA Issue and PRD context to generate 5-20 QA Steps that:\n\n1. Cover all acceptance criteria from the PRD\n2. Test key user flows and interactions\n3. Include both happy path and critical error cases\n4. Are atomic (one user action per step)\n\n### Step Generation Strategy\n\n```\nFor each acceptance criterion in the PRD:\n  1. Identify the user role performing the action\n  2. Determine the precondition (starting state)\n  3. Extract the specific user action\n  4. Define the expected observable outcome\n  5. Note any test data or prerequisites needed\n```\n\n### Step Categories to Cover\n\n| Category | Examples |\n|----------|----------|\n| **Happy Path** | Core user flows work as expected |\n| **Validation** | Required fields, format validation |\n| **Edge Cases** | Empty states, boundary values |\n| **Error Handling** | Invalid input, network errors |\n| **Permissions** | Access control, role-based behavior |\n\n### Generation Guidelines\n\n- **Be specific**: \"I click the Submit button\" not \"I submit the form\"\n- **Be observable**: \"I should see a success message\" not \"The form is submitted\"\n- **Be atomic**: One action per step, split complex flows into multiple steps\n- **Be consistent**: Use the same terminology as the PRD/QA Issue\n- **Target 5-20 steps**: Enough for thorough coverage, not so many as to be overwhelming\n\n### Example Generated Steps\n\nGiven a PRD for \"User Login Feature\", generate steps like:\n\n1. **QA Step: Valid login with correct credentials**\n   - As a guest user,\n   - Given I am on the login page,\n   - When I enter valid credentials and click Login,\n   - Then I should be redirected to the dashboard\n\n2. **QA Step: Login with invalid password**\n   - As a guest user,\n   - Given I am on the login page,\n   - When I enter a valid email but incorrect password,\n   - Then I should see an error message \"Invalid credentials\"\n\n3. **QA Step: Login form validation**\n   - As a guest user,\n   - Given I am on the login page,\n   - When I click Login without entering any credentials,\n   - Then I should see validation errors for email and password fields\n\n## Step 4: Create QA Step Issues with QA-Step Label\n\n```bash\n# Get repository owner and name\nOWNER=$(gh repo view --json owner -q '.owner.login')\nREPO=$(gh repo view --json name -q '.name')\n\n# Ensure QA-Step label exists (create if not)\ngh label create QA-Step --description \"QA Step for acceptance testing\" --color 9B59B6 2>/dev/null || true\n```\n\nFor each generated QA Step, create a GitHub issue:\n\n```bash\n# For each step, create issue with populated template\nSTEP_TITLE=\"QA Step: <Brief Description>\"\n\nSTEP_BODY=$(cat <<BODY\n# QA Step: <Brief Description>\n\n## Scenario\n\nAs a <role>,\nGiven <precondition>,\nWhen <action>,\nThen <expected outcome>\n\n## Parent QA Issue\n\n- QA: #$QA\n\n## Test Details\n\n- **URL/Page:** <starting URL or page>\n- **Prerequisites:** <any setup needed>\n- **Test Data:** <if applicable>\n\n## Execution Log\n\n- [ ] Pass / Fail\n- **Executed by:** (not yet executed)\n- **Timestamp:** (pending)\n- **Notes:** (none)\n\n## Bugs Found\n\n(None)\nBODY\n)\n\n# Create the QA Step issue\nSTEP_URL=$(gh issue create \\\n  --title \"$STEP_TITLE\" \\\n  --label \"QA-Step\" \\\n  --body \"$STEP_BODY\")\n\n# Extract step number from URL\nSTEP_NUM=$(echo \"$STEP_URL\" | grep -oE '[0-9]+$')\n\necho \"Created QA Step #$STEP_NUM: $STEP_URL\"\n\n# Store step number and title for later use\nSTEP_NUMBERS+=(\"$STEP_NUM\")\nSTEP_TITLES[\"$STEP_NUM\"]=\"$STEP_TITLE\"\n```\n\n### Issue Creation Notes\n\n- Create all steps before proceeding to linking\n- If any step creation fails, log the error and continue with remaining steps\n- Track created step numbers for sub-issue linking and checklist generation\n\n## Step 5: Link QA Steps as Sub-Issues of QA Issue\n\n**IMPORTANT:** QA Steps MUST be linked as sub-issues of the QA Issue, not just listed in a comment.\n\nFor each created QA Step, link it as a sub-issue:\n\n```bash\n# Get the QA Step's internal issue ID\nSTEP_ID=$(gh api repos/$OWNER/$REPO/issues/$STEP_NUM --jq .id)\n\n# Add QA Step as sub-issue of QA Issue\ngh api repos/$OWNER/$REPO/issues/$QA/sub_issues \\\n  -X POST \\\n  -F sub_issue_id=$STEP_ID \\\n  --silent && echo \"Linked QA Step #$STEP_NUM as sub-issue of QA #$QA\" \\\n  || echo \"Warning: Could not link QA Step #$STEP_NUM as sub-issue\"\n```\n\n### Sub-Issue Linking Notes\n\n- Link all steps after creation completes\n- If linking fails for a step, log warning and continue with remaining steps\n- Sub-issues should appear in the QA Issue's \"Sub-issues\" section\n- Verify linking with: `gh api repos/$OWNER/$REPO/issues/$QA/sub_issues --jq '.[] | [.number, .title] | @tsv'`\n\n### Add QA Steps to GitHub Project (Optional)\n\nFor each created QA Step, add it to the GitHub Project if `GHPM_PROJECT` is set:\n\n```bash\n# If GHPM_PROJECT is set, add QA Step to project (best-effort)\nif [ -n \"$GHPM_PROJECT\" ]; then\n  gh project item-add \"$GHPM_PROJECT\" --owner \"$OWNER\" --url \"$STEP_URL\" \\\n    && echo \"Added QA Step #$STEP_NUM to project: $GHPM_PROJECT\" \\\n    || echo \"Warning: Could not add QA Step #$STEP_NUM to project\"\nfi\n```\n\n### Fallback if Sub-Issues Not Supported\n\nIf the sub-issues API is not available (older GitHub Enterprise, etc.):\n\n1. Log a warning that sub-issue linking is not available\n2. Continue to Step 6 (checklist comment) which provides alternative tracking\n3. Consider adding a comment on each QA Step referencing the parent QA Issue\n\n## Step 6: Add QA Issue Comment with QA Steps Checklist\n\nPost a comment on the QA Issue with a checklist of all created QA Steps for tracking:\n\n```bash\n# Build checklist from created steps\nCHECKLIST=\"\"\nfor step_num in \"${STEP_NUMBERS[@]}\"; do\n  step_title=\"${STEP_TITLES[$step_num]}\"\n  CHECKLIST=\"$CHECKLIST\n- [ ] #$step_num $step_title\"\ndone\n\n# Post comment on QA Issue\ngh issue comment \"$QA\" --body \"$(cat <<COMMENT\n## QA Steps\n\nThe following QA Steps have been created for acceptance testing:\n$CHECKLIST\n\n### Execution Instructions\n\n1. Execute each step in order\n2. Mark the checkbox when the step passes\n3. If a step fails, create a Bug issue and link it in the step's \"Bugs Found\" section\n4. Update each step's Execution Log with results\nCOMMENT\n)\"\n\necho \"Posted QA Steps checklist comment on QA Issue #$QA\"\n```\n\n### Checklist Format\n\nThe checklist follows this format for consistent tracking:\n\n```markdown\n## QA Steps\n\nThe following QA Steps have been created for acceptance testing:\n\n- [ ] #101 QA Step: Valid login with correct credentials\n- [ ] #102 QA Step: Login with invalid password\n- [ ] #103 QA Step: Login form validation\n...\n\n### Execution Instructions\n\n1. Execute each step in order\n2. Mark the checkbox when the step passes\n3. If a step fails, create a Bug issue and link it in the step's \"Bugs Found\" section\n4. Update each step's Execution Log with results\n```\n\n</workflow>\n\n<operating_rules>\n\n- Do not ask clarifying questions. Make assumptions and record them in the QA Steps.\n- Do not create local markdown files. All output goes into GitHub issues/comments.\n- QA Steps must be atomic and independently testable.\n- Each QA Step must follow the Given/When/Then format consistently.\n- Generate 5-20 QA Steps per QA Issue that fully cover the acceptance criteria.\n- Each QA Step MUST be linked as a sub-issue of the parent QA Issue.\n\n</operating_rules>\n\n<input_validation>\n\n## Validation Checks\n\nBefore proceeding, validate:\n\n```bash\n# 1. Check gh CLI authentication\ngh auth status || { echo \"ERROR: Not authenticated. Run 'gh auth login'\"; exit 1; }\n\n# 2. Validate QA issue number format (if provided)\n# QA number must be a positive integer\nif [[ -n \"$QA\" && ! \"$QA\" =~ ^[0-9]+$ ]]; then\n  echo \"ERROR: Invalid QA number. Use format: qa=#123\"\n  exit 1\nfi\n\n# 3. Verify QA issue exists and is accessible\ngh issue view \"$QA\" > /dev/null 2>&1 || { echo \"ERROR: Cannot access QA issue #$QA\"; exit 1; }\n```\n\n</input_validation>\n\n<error_handling>\n\n**If gh CLI not authenticated:**\n\n- Check: `gh auth status`\n- Fix: `gh auth login`\n\n**If QA Issue not found:**\n\n- Verify issue number is correct\n- Check repository access permissions\n- Confirm issue is not closed/deleted\n\n**If no open QA Issue found (auto-resolve):**\n\n- Create a QA Issue first using `/ghpm:qa-create`\n- Or specify an explicit QA number with `qa=#N`\n\n**If PRD reference not found in QA Issue:**\n\n- Continue with QA Issue context only\n- Log warning: \"No PRD reference found. Generating steps from QA Issue context only.\"\n\n**If QA Step creation fails:**\n\n- Check rate limits: `gh api rate_limit`\n- Verify label \"QA-Step\" exists or create it\n- Check repository write permissions\n- Log error and continue with remaining steps\n\n**If sub-issue linking fails:**\n\n- Continue with next step (don't block on linking failures)\n- Log warning in output summary with specific step number\n- Common causes: step already has a parent, duplicate sub-issue, API error\n- Checklist comment provides alternative tracking\n\n**If project add fails:**\n\n- Print warning and continue (best-effort)\n- Common causes: project not found, user lacks project permissions\n- Do not block QA Step creation on project failures\n\n</error_handling>\n\n<success_criteria>\n\nCommand completes successfully when:\n\n1. Target QA Issue has been resolved (explicit or auto-detected)\n2. PRD context has been fetched (if available)\n3. 5-20 QA Step issues have been created with `QA-Step` label\n4. Each QA Step follows the Given/When/Then format\n5. Each QA Step is linked as a sub-issue of the QA Issue\n6. QA Steps added to `GHPM_PROJECT` when set (best-effort)\n7. Checklist comment has been posted on the QA Issue\n\n**Verification:**\n\n```bash\n# List created QA Steps\ngh issue list -l QA-Step -s open --limit 50 --json number,title\n\n# Verify sub-issues are linked to QA Issue\ngh api repos/{owner}/{repo}/issues/$QA/sub_issues --jq '.[] | [.number, .title] | @tsv'\n\n# View QA Issue to confirm (sub-issues and checklist appear)\ngh issue view \"$QA\"\n```\n\n</success_criteria>\n\n<output>\n\nAfter completion, report:\n\n1. **QA Issue processed:** # and URL\n2. **PRD context:** # and title (if found)\n3. **QA Steps created:** Issue numbers and titles\n4. **Sub-issue linking:** Success/failure for each step\n5. **Project association:** Success/warning/skipped for each step\n6. **Total steps:** Count\n7. **Warnings:** Any issues encountered (PRD not found, linking failures, project failures, etc.)\n\n</output>\n\nProceed now."
              },
              {
                "name": "/qa-create",
                "description": "Create a QA Issue as sub-issue of a PRD",
                "path": "plugins/ghpm/commands/qa-create.md",
                "frontmatter": {
                  "description": "Create a QA Issue as sub-issue of a PRD",
                  "allowed-tools": [
                    "Read",
                    "Bash",
                    "Grep",
                    "Glob"
                  ],
                  "arguments": {
                    "prd": {
                      "description": "PRD issue number (format: prd=#123)",
                      "required": false
                    }
                  }
                },
                "content": "<objective>\nYou are GHPM (GitHub Project Manager). Create a QA Issue for acceptance testing and link it as a sub-issue of the specified PRD.\n</objective>\n\n<arguments>\n**Optional arguments:**\n- `prd=#123` - PRD issue number to create QA Issue for\n\n**Resolution order if omitted:**\n\n1. Most recent open issue labeled `PRD`:\n   `gh issue list -l PRD -s open --limit 1 --json number -q '.[0].number'`\n</arguments>\n\n<usage_examples>\n**With PRD number:**\n\n```bash\n/ghpm:qa-create prd=#42\n```\n\n**Auto-resolve most recent PRD:**\n\n```bash\n/ghpm:qa-create\n```\n\n</usage_examples>\n\n<qa_issue_template>\n\n## QA Issue Body Template\n\n```markdown\n# QA: <PRD Title> - Acceptance Testing\n\n## Overview\n\n<Brief description derived from PRD objective>\n\n## Parent PRD\n\n- PRD: #<PRD_NUMBER>\n\n## QA Steps\n\n(Populated by /ghpm:qa-create-steps)\n- [ ] (No steps created yet)\n\n## Status\n\n- [ ] All steps created\n- [ ] All steps passed\n- [ ] Bugs found: (none)\n```\n\n</qa_issue_template>\n\n<workflow>\n\n## Step 1: Resolve PRD Number\n\n```bash\n# If prd=#N is provided, use N\nPRD={provided_prd_number}\n\n# Else: auto-resolve to most recent open PRD\nPRD=$(gh issue list -l PRD -s open --limit 1 --json number -q '.[0].number')\n\nif [ -z \"$PRD\" ]; then\n  echo \"Error: No open PRD found. Specify prd=#N or create a PRD first.\"\n  exit 1\nfi\n\n# Validate PRD number is positive integer\nif ! [[ \"$PRD\" =~ ^[0-9]+$ ]]; then\n  echo \"Error: Invalid PRD number. Use format: prd=#123\"\n  exit 1\nfi\n```\n\n## Step 2: Fetch PRD Details\n\n```bash\n# Fetch PRD title, body, and URL\nPRD_DATA=$(gh issue view \"$PRD\" --json title,body,url -q '.')\nPRD_TITLE=$(echo \"$PRD_DATA\" | jq -r '.title')\nPRD_URL=$(echo \"$PRD_DATA\" | jq -r '.url')\n\nif [ -z \"$PRD_TITLE\" ]; then\n  echo \"Error: Could not fetch PRD #$PRD. Check if it exists and is accessible.\"\n  exit 1\nfi\n\necho \"PRD #$PRD: $PRD_TITLE\"\necho \"URL: $PRD_URL\"\n```\n\n## Step 3: Ensure QA Label Exists\n\n```bash\n# Create QA label if it doesn't exist (ignore error if already exists)\ngh label create QA --description \"QA Issue for acceptance testing\" --color 6B3FA0 2>/dev/null || true\n```\n\n## Step 4: Create QA Issue\n\n```bash\n# Build QA Issue body from template\nQA_TITLE=\"QA: $PRD_TITLE - Acceptance Testing\"\n\nQA_BODY=$(cat <<BODY\n# QA: $PRD_TITLE - Acceptance Testing\n\n## Overview\n\nAcceptance testing for PRD: $PRD_TITLE\n\n## Parent PRD\n\n- PRD: #$PRD\n\n## QA Steps\n\n(Populated by /ghpm:qa-create-steps)\n- [ ] (No steps created yet)\n\n## Status\n\n- [ ] All steps created\n- [ ] All steps passed\n- [ ] Bugs found: (none)\nBODY\n)\n\n# Create the QA Issue\nQA_URL=$(gh issue create --title \"$QA_TITLE\" --label \"QA\" --body \"$QA_BODY\")\nQA_NUMBER=$(echo \"$QA_URL\" | grep -oE '[0-9]+$')\n\necho \"Created QA Issue #$QA_NUMBER: $QA_URL\"\n```\n\n## Step 5: Link QA Issue as Sub-Issue of PRD\n\n```bash\n# Get repository owner and name\nOWNER=$(gh repo view --json owner -q '.owner.login')\nREPO=$(gh repo view --json name -q '.name')\n\n# Get the QA Issue's internal ID\nQA_ID=$(gh api repos/$OWNER/$REPO/issues/$QA_NUMBER --jq .id)\n\n# Add QA Issue as sub-issue of PRD\ngh api repos/$OWNER/$REPO/issues/$PRD/sub_issues \\\n  -X POST \\\n  -F sub_issue_id=$QA_ID \\\n  --silent && echo \"Linked QA Issue #$QA_NUMBER as sub-issue of PRD #$PRD\" \\\n  || echo \"Warning: Could not link QA Issue as sub-issue (feature may not be available)\"\n```\n\n## Step 6: Add to GitHub Project (Optional)\n\n```bash\n# If GHPM_PROJECT is set, add QA Issue to project (best-effort)\nif [ -n \"$GHPM_PROJECT\" ]; then\n  gh project item-add \"$GHPM_PROJECT\" --owner \"$OWNER\" --url \"$QA_URL\" \\\n    && echo \"Added QA Issue to project: $GHPM_PROJECT\" \\\n    || echo \"Warning: Could not add QA Issue to project\"\nfi\n```\n\n## Step 7: Comment on PRD with QA Issue Link\n\n```bash\ngh issue comment \"$PRD\" --body \"$(cat <<COMMENT\n## QA\n\n- [ ] #$QA_NUMBER $QA_TITLE\n\nQA Issue created for acceptance testing.\nCOMMENT\n)\"\n\necho \"Posted QA link comment on PRD #$PRD\"\n```\n\n</workflow>\n\n<operating_rules>\n\n- Do not ask clarifying questions. If the PRD has ambiguity, derive a reasonable overview from the PRD objective.\n- Do not create local markdown files. All output goes into GitHub issues/comments.\n- Execute all `gh` commands directly via bash tool.\n- If sub-issue linking fails, continue with the remaining steps (best-effort).\n\n</operating_rules>\n\n<input_validation>\n\n## Validation Checks\n\nBefore proceeding, validate:\n\n```bash\n# 1. Check gh CLI authentication\ngh auth status || { echo \"ERROR: Not authenticated. Run 'gh auth login'\"; exit 1; }\n\n# 2. Validate PRD number format (if provided)\n# PRD number must be a positive integer\nif [[ -n \"$PRD\" && ! \"$PRD\" =~ ^[0-9]+$ ]]; then\n  echo \"ERROR: Invalid PRD number. Use format: prd=#123\"\n  exit 1\nfi\n\n# 3. Verify PRD issue exists and is accessible\ngh issue view \"$PRD\" > /dev/null 2>&1 || { echo \"ERROR: Cannot access PRD #$PRD\"; exit 1; }\n```\n\n</input_validation>\n\n<error_handling>\n\n**If gh CLI not authenticated:**\n\n- Check: `gh auth status`\n- Fix: `gh auth login`\n\n**If PRD number invalid:**\n\n- Print error: \"Invalid PRD number. Use format: prd=#123\"\n- Do not proceed\n\n**If PRD not found or inaccessible:**\n\n- Print error: \"Could not fetch PRD #N. Check if it exists and you have access.\"\n- Do not proceed\n\n**If QA Issue creation fails:**\n\n- Print error and stop\n- Do not proceed with linking or comments\n\n**If sub-issue linking fails:**\n\n- Print warning, continue with remaining steps\n- Common causes: feature not available, API changes\n\n**If project add fails:**\n\n- Print warning, continue with remaining steps\n- Continue to complete command\n\n</error_handling>\n\n<success_criteria>\n\nCommand completes successfully when:\n\n1. PRD has been resolved (explicit or auto-detected)\n2. QA Issue created with correct title format and QA label\n3. QA Issue body contains all required sections\n4. QA Issue linked as sub-issue of PRD (or warning printed)\n5. PRD has comment linking to QA Issue\n6. Summary printed with all relevant URLs\n\n**Verification:**\n\n```bash\n# Check QA Issue was created\ngh issue view \"$QA_NUMBER\"\n\n# Check sub-issue is linked to PRD\ngh api repos/{owner}/{repo}/issues/$PRD/sub_issues --jq '.[] | [.number, .title] | @tsv'\n\n# Check PRD has comment with QA link\ngh issue view \"$PRD\" --json comments -q '.comments[-1].body'\n```\n\n</success_criteria>\n\n<output>\n\nAfter completion, report:\n\n1. **PRD processed:** # and URL\n2. **QA Issue created:** # and URL\n3. **Sub-issue linking:** Success/warning\n4. **Project association:** Success/warning/skipped\n5. **PRD comment:** Posted\n\n</output>\n\nProceed now."
              },
              {
                "name": "/qa-execute",
                "description": "Execute QA Steps using Playwright automation",
                "path": "plugins/ghpm/commands/qa-execute.md",
                "frontmatter": {
                  "description": "Execute QA Steps using Playwright automation",
                  "allowed-tools": [
                    "Read",
                    "Bash",
                    "Grep",
                    "Glob"
                  ],
                  "arguments": {
                    "qa": {
                      "description": "QA issue number (format: qa=#123)",
                      "required": false
                    },
                    "step": {
                      "description": "Specific QA Step to execute (format: step=#123)",
                      "required": false
                    }
                  }
                },
                "content": "<objective>\nYou are GHPM (GitHub Project Manager). Execute QA Steps using Playwright browser automation, recording pass/fail results on GitHub issues and triggering bug creation on failures.\n</objective>\n\n<arguments>\n**Optional arguments:**\n- `qa=#123` - Execute all QA Steps linked to this QA Issue\n- `step=#123` - Execute a specific QA Step\n\n**Resolution order if omitted:**\n\n1. Most recent open QA issue with QA Steps:\n   `gh issue list -l QA -s open --limit 1 --json number -q '.[0].number'`\n</arguments>\n\n<usage_examples>\n**Execute a single QA Step:**\n\n```bash\n/ghpm:qa-execute step=#42\n```\n\n**Execute all Steps in a QA Issue:**\n\n```bash\n/ghpm:qa-execute qa=#10\n```\n\n**Auto-resolve most recent QA Issue:**\n\n```bash\n/ghpm:qa-execute\n```\n\n</usage_examples>\n\n<workflow>\n\n## Step 0: Resolve Target QA Steps\n\n### If `step=#N` provided (single Step execution)\n\n```bash\nSTEP=$N\n\n# Fetch Step details\nSTEP_DATA=$(gh issue view \"$STEP\" --json title,body,url,labels -q '.')\nSTEP_TITLE=$(echo \"$STEP_DATA\" | jq -r '.title')\nSTEP_BODY=$(echo \"$STEP_DATA\" | jq -r '.body')\n\n# Verify it's a QA Step\nHAS_LABEL=$(echo \"$STEP_DATA\" | jq -r '.labels[].name' | grep -c \"QA-Step\" || true)\nif [ \"$HAS_LABEL\" -eq 0 ]; then\n  echo \"Warning: Issue #$STEP does not have QA-Step label. Proceeding anyway.\"\nfi\n\n# Extract parent QA Issue number from body\nQA=$(echo \"$STEP_BODY\" | grep -oE 'QA: #[0-9]+' | head -1 | grep -oE '[0-9]+')\n\nSTEPS_TO_EXECUTE=(\"$STEP\")\n```\n\n### If `qa=#N` provided (all Steps in QA Issue)\n\n```bash\nQA=$N\nOWNER=$(gh repo view --json owner -q '.owner.login')\nREPO=$(gh repo view --json name -q '.name')\n\n# Fetch all QA Steps linked as sub-issues of this QA Issue\ncat > /tmp/ghpm-qa-subissues.graphql << 'GRAPHQL'\nquery($owner: String!, $repo: String!, $number: Int!) {\n  repository(owner: $owner, name: $repo) {\n    issue(number: $number) {\n      subIssues(first: 50) {\n        nodes {\n          number\n          title\n          state\n          labels(first: 10) {\n            nodes { name }\n          }\n        }\n      }\n    }\n  }\n}\nGRAPHQL\n\n# Get open QA Steps\nSTEPS_TO_EXECUTE=$(gh api graphql -F owner=\"$OWNER\" -F repo=\"$REPO\" -F number=$QA \\\n  -f query=\"$(cat /tmp/ghpm-qa-subissues.graphql)\" \\\n  --jq '.data.repository.issue.subIssues.nodes[] | select(.state == \"OPEN\") | select(.labels.nodes[].name == \"QA-Step\") | .number')\n\nif [ -z \"$STEPS_TO_EXECUTE\" ]; then\n  echo \"Error: No open QA Steps found for QA Issue #$QA\"\n  exit 1\nfi\n\necho \"Found $(echo \"$STEPS_TO_EXECUTE\" | wc -l | tr -d ' ') QA Steps to execute\"\n```\n\n### If no argument provided (auto-resolve)\n\n```bash\n# Find most recent open QA issue\nQA=$(gh issue list -l QA -s open --limit 1 --json number -q '.[0].number')\n\nif [ -z \"$QA\" ]; then\n  echo \"Error: No open QA issue found. Specify qa=#N or step=#N\"\n  exit 1\nfi\n\necho \"Auto-resolved to QA Issue #$QA\"\n\n# Then fetch Steps as above\n```\n\n## Step 1: Fetch Step Details\n\nFor each Step to execute, fetch the full details:\n\n```bash\nfor STEP in $STEPS_TO_EXECUTE; do\n  STEP_DATA=$(gh issue view \"$STEP\" --json title,body,url -q '.')\n  STEP_TITLE=$(echo \"$STEP_DATA\" | jq -r '.title')\n  STEP_BODY=$(echo \"$STEP_DATA\" | jq -r '.body')\n  STEP_URL=$(echo \"$STEP_DATA\" | jq -r '.url')\n\n  echo \"Processing: #$STEP - $STEP_TITLE\"\n\n  # Extract Given/When/Then from body\n  # Look for Scenario section\n  SCENARIO=$(echo \"$STEP_BODY\" | sed -n '/## Scenario/,/## /p' | head -n -1)\n\n  # Extract Test Details\n  URL_PAGE=$(echo \"$STEP_BODY\" | grep -oE '\\*\\*URL/Page:\\*\\* .+' | sed 's/\\*\\*URL\\/Page:\\*\\* //')\n\n  # Continue to parsing and execution...\ndone\n```\n\n## Step 2: Parse Given/When/Then into Playwright Actions\n\nParse the Scenario section to extract actionable Playwright commands.\n\n### Parser Pattern Reference\n\n| Pattern | Playwright Action |\n|---------|-------------------|\n| `Given I am on <URL>` | `await page.goto('<URL>')` |\n| `Given I am on the <page> page` | `await page.goto(baseUrl + '/<page>')` |\n| `When I click <element>` | `await page.click('<selector>')` |\n| `When I click the <text> button` | `await page.click('button:has-text(\"<text>\")')` |\n| `When I click the <text> link` | `await page.click('a:has-text(\"<text>\")')` |\n| `When I type <text> into <field>` | `await page.fill('<selector>', '<text>')` |\n| `When I enter <text> in the <field> field` | `await page.fill('[name=\"<field>\"], [placeholder*=\"<field>\"]', '<text>')` |\n| `When I select <option> from <dropdown>` | `await page.selectOption('<selector>', '<option>')` |\n| `When I check <checkbox>` | `await page.check('<selector>')` |\n| `When I uncheck <checkbox>` | `await page.uncheck('<selector>')` |\n| `When I wait for <seconds> seconds` | `await page.waitForTimeout(<seconds> * 1000)` |\n| `Then I should see <text>` | `await expect(page.locator('body')).toContainText('<text>')` |\n| `Then I should see the <text> button` | `await expect(page.locator('button:has-text(\"<text>\")')).toBeVisible()` |\n| `Then I should be on <URL>` | `await expect(page).toHaveURL('<URL>')` |\n| `Then I should be redirected to <page>` | `await expect(page).toHaveURL(/<page>/)` |\n| `Then the <field> field should contain <value>` | `await expect(page.locator('<selector>')).toHaveValue('<value>')` |\n| `Then I should not see <text>` | `await expect(page.locator('body')).not.toContainText('<text>')` |\n\n### Parsing Logic\n\n```javascript\nfunction parseScenario(scenario) {\n  const actions = [];\n  const lines = scenario.split('\\n').map(l => l.trim()).filter(l => l);\n\n  for (const line of lines) {\n    // Given - Setup/Navigation\n    if (/^Given I am on (.+)$/i.test(line)) {\n      const url = line.match(/^Given I am on (.+)$/i)[1];\n      actions.push({ type: 'navigate', url: url.replace(/['\"]/g, '') });\n    }\n\n    // When - Actions\n    else if (/^When I click (?:the )?(.+?) button$/i.test(line)) {\n      const text = line.match(/^When I click (?:the )?(.+?) button$/i)[1];\n      actions.push({ type: 'click', selector: `button:has-text(\"${text}\")` });\n    }\n    else if (/^When I click (?:the )?(.+?) link$/i.test(line)) {\n      const text = line.match(/^When I click (?:the )?(.+?) link$/i)[1];\n      actions.push({ type: 'click', selector: `a:has-text(\"${text}\")` });\n    }\n    else if (/^When I click (.+)$/i.test(line)) {\n      const element = line.match(/^When I click (.+)$/i)[1];\n      actions.push({ type: 'click', selector: element });\n    }\n    else if (/^When I (?:type|enter) ['\"\"]?(.+?)['\"\"]? (?:into|in) (?:the )?(.+?)(?: field)?$/i.test(line)) {\n      const match = line.match(/^When I (?:type|enter) ['\"\"]?(.+?)['\"\"]? (?:into|in) (?:the )?(.+?)(?: field)?$/i);\n      actions.push({ type: 'fill', selector: match[2], value: match[1] });\n    }\n    else if (/^When I select ['\"\"]?(.+?)['\"\"]? from (.+)$/i.test(line)) {\n      const match = line.match(/^When I select ['\"\"]?(.+?)['\"\"]? from (.+)$/i);\n      actions.push({ type: 'select', selector: match[2], value: match[1] });\n    }\n    else if (/^When I wait for (\\d+) seconds?$/i.test(line)) {\n      const seconds = line.match(/^When I wait for (\\d+) seconds?$/i)[1];\n      actions.push({ type: 'wait', duration: parseInt(seconds) * 1000 });\n    }\n\n    // Then - Assertions\n    else if (/^Then I should see ['\"\"]?(.+?)['\"\"]?$/i.test(line)) {\n      const text = line.match(/^Then I should see ['\"\"]?(.+?)['\"\"]?$/i)[1];\n      actions.push({ type: 'assertText', text });\n    }\n    else if (/^Then I should be on (.+)$/i.test(line)) {\n      const url = line.match(/^Then I should be on (.+)$/i)[1];\n      actions.push({ type: 'assertURL', url: url.replace(/['\"]/g, '') });\n    }\n    else if (/^Then I should be redirected to (.+)$/i.test(line)) {\n      const page = line.match(/^Then I should be redirected to (.+)$/i)[1];\n      actions.push({ type: 'assertURLContains', pattern: page });\n    }\n    else if (/^Then I should not see ['\"\"]?(.+?)['\"\"]?$/i.test(line)) {\n      const text = line.match(/^Then I should not see ['\"\"]?(.+?)['\"\"]?$/i)[1];\n      actions.push({ type: 'assertNoText', text });\n    }\n\n    // Unparseable line\n    else if (line && !line.startsWith('As a')) {\n      console.warn(`Warning: Could not parse line: \"${line}\"`);\n      actions.push({ type: 'unparseable', line });\n    }\n  }\n\n  return actions;\n}\n```\n\n### Handling Unparseable Steps\n\nWhen a step cannot be parsed:\n\n1. Log warning with the unparseable line\n2. Add to actions array with type `unparseable`\n3. During execution, skip unparseable actions but include in report\n4. Do not fail the entire step for unparseable clauses\n\n## Step 3: Execute Playwright Actions\n\n### Step 3.0: Claim Step Before Execution\n\nBefore executing any step, claim it to prevent duplicate work and enable progress tracking.\n\n**Important for QA mode:** Claim each step only when its execution begins, NOT all steps at once upfront. This allows other workers to claim and execute other steps.\n\n```bash\n# Get current GitHub user\nCURRENT_USER=$(gh api user -q '.login')\nif [ -z \"$CURRENT_USER\" ]; then\n  echo \"ERROR: Could not determine current GitHub user. Run 'gh auth login'\"\n  exit 1\nfi\n\n# Check existing assignees on the QA Step\nASSIGNEES=$(gh issue view \"$STEP\" --json assignees -q '.assignees[].login')\n\n# Handle assignment scenarios\nif [ -z \"$ASSIGNEES\" ]; then\n  # No assignees - claim the step\n  gh issue edit \"$STEP\" --add-assignee @me\n  echo \"✓ Assigned to @$CURRENT_USER\"\n\n  # Post audit comment\n  TIMESTAMP=$(date -u +\"%Y-%m-%d %H:%M:%S UTC\")\n  gh issue comment \"$STEP\" --body \"🏷️ Claimed by @$CURRENT_USER at $TIMESTAMP\"\n\nelif echo \"$ASSIGNEES\" | grep -qx \"$CURRENT_USER\"; then\n  # Already assigned to current user - proceed\n  echo \"✓ Already assigned to you (@$CURRENT_USER)\"\n\nelse\n  # Assigned to another user - abort this step only\n  EXISTING_ASSIGNEE=$(echo \"$ASSIGNEES\" | head -1)\n  echo \"✗ Step #$STEP is already claimed by @$EXISTING_ASSIGNEE\"\n  # Continue to next step (don't abort entire QA run)\n  continue\nfi\n\n# Update project status to \"In Progress\" (best-effort)\nif [ -n \"$GHPM_PROJECT\" ]; then\n  OWNER=$(gh repo view --json owner -q '.owner.login')\n  echo \"Note: Project status update to 'In Progress' is best-effort\"\nfi\n\n# Warn on orphaned state (In Progress without assignee)\nif [ -z \"$ASSIGNEES\" ] && [ -n \"$GHPM_PROJECT\" ]; then\n  PROJECT_STATUS=$(gh issue view \"$STEP\" --json projectItems -q '.projectItems[0].status.name // empty' 2>/dev/null)\n  if [ \"$PROJECT_STATUS\" = \"In Progress\" ]; then\n    echo \"⚠ Warning: Step #$STEP had status 'In Progress' but no assignee\"\n  fi\nfi\n```\n\n**UX Output:**\n\n| Scenario | Output |\n|----------|--------|\n| Success (new claim) | `✓ Assigned to @username` |\n| Self-claim | `✓ Already assigned to you (@username)` |\n| Conflict | `✗ Step #N is already claimed by @another-user` |\n| Orphaned state | `⚠ Warning: Step #N had status 'In Progress' but no assignee` |\n\n**Behavior:**\n\n- For `step=#N` mode: claim the single step before execution\n- For `qa=#N` mode: claim each step ONLY when its execution begins (not all upfront)\n- On conflict, skip that step and continue to next (other workers can still execute other steps)\n- On self-claim, proceed normally\n- All claiming operations complete within 3 seconds\n\n### Step 3.1: Execute Playwright\n\nExecute the parsed actions in a browser using Playwright.\n\n### Browser Launch Configuration\n\n```javascript\nconst { chromium, expect } = require('@playwright/test');\n\nasync function executeStep(stepNumber, actions, options = {}) {\n  const {\n    headless = true,\n    timeout = 30000,\n    viewport = { width: 1280, height: 720 },\n    baseUrl = ''\n  } = options;\n\n  const browser = await chromium.launch({ headless });\n  const context = await browser.newContext({ viewport });\n  const page = await context.newPage();\n\n  page.setDefaultTimeout(timeout);\n\n  const results = {\n    stepNumber,\n    pass: true,\n    actions: [],\n    error: null,\n    screenshot: null\n  };\n\n  try {\n    for (const action of actions) {\n      const actionResult = { action, success: false, error: null };\n\n      try {\n        switch (action.type) {\n          case 'navigate':\n            const url = action.url.startsWith('http') ? action.url : baseUrl + action.url;\n            await page.goto(url, { waitUntil: 'networkidle' });\n            actionResult.success = true;\n            break;\n\n          case 'click':\n            await page.click(action.selector);\n            actionResult.success = true;\n            break;\n\n          case 'fill':\n            // Try common selector patterns\n            const fillSelector = action.selector.startsWith('[') || action.selector.startsWith('#') || action.selector.startsWith('.')\n              ? action.selector\n              : `[name=\"${action.selector}\"], [placeholder*=\"${action.selector}\" i], label:has-text(\"${action.selector}\") + input`;\n            await page.fill(fillSelector, action.value);\n            actionResult.success = true;\n            break;\n\n          case 'select':\n            const selectSelector = action.selector.startsWith('[') || action.selector.startsWith('#')\n              ? action.selector\n              : `select[name=\"${action.selector}\"]`;\n            await page.selectOption(selectSelector, action.value);\n            actionResult.success = true;\n            break;\n\n          case 'wait':\n            await page.waitForTimeout(action.duration);\n            actionResult.success = true;\n            break;\n\n          case 'assertText':\n            await expect(page.locator('body')).toContainText(action.text, { timeout });\n            actionResult.success = true;\n            break;\n\n          case 'assertNoText':\n            await expect(page.locator('body')).not.toContainText(action.text, { timeout });\n            actionResult.success = true;\n            break;\n\n          case 'assertURL':\n            await expect(page).toHaveURL(action.url, { timeout });\n            actionResult.success = true;\n            break;\n\n          case 'assertURLContains':\n            await expect(page).toHaveURL(new RegExp(action.pattern), { timeout });\n            actionResult.success = true;\n            break;\n\n          case 'unparseable':\n            // Skip but log\n            actionResult.skipped = true;\n            actionResult.success = true;\n            console.log(`Skipped unparseable action: ${action.line}`);\n            break;\n\n          default:\n            actionResult.error = `Unknown action type: ${action.type}`;\n        }\n      } catch (actionError) {\n        actionResult.error = actionError.message;\n        results.pass = false;\n        results.error = actionError.message;\n        // Capture screenshot on failure (handled in Step 4)\n        break; // Stop execution on first failure\n      }\n\n      results.actions.push(actionResult);\n    }\n  } finally {\n    await browser.close();\n  }\n\n  return results;\n}\n```\n\n### Execution Flow\n\n1. Launch headless Chromium browser\n2. Create new page with configured viewport\n3. Execute each action in sequence\n4. Stop on first failure and capture error\n5. Close browser and return results\n\n### Timeout and Wait Handling\n\n- Default action timeout: 30 seconds\n- Navigation waits for `networkidle` state\n- Explicit waits via `When I wait for X seconds`\n- Assertions have configurable timeout\n\n## Step 4: Capture Screenshot on Failure\n\nWhen a QA Step fails, capture a screenshot of the current page state for inclusion in bug reports.\n\n### Screenshot Capture Implementation\n\nUpdate the executeStep function to capture screenshots on failure:\n\n```javascript\nasync function executeStep(stepNumber, actions, options = {}) {\n  // ... browser launch code from Step 3 ...\n\n  try {\n    for (const action of actions) {\n      const actionResult = { action, success: false, error: null };\n\n      try {\n        // ... action execution code from Step 3 ...\n      } catch (actionError) {\n        actionResult.error = actionError.message;\n        results.pass = false;\n        results.error = actionError.message;\n\n        // Capture screenshot on failure\n        const screenshotPath = `/tmp/qa-screenshot-step-${stepNumber}-${Date.now()}.png`;\n        try {\n          await page.screenshot({\n            path: screenshotPath,\n            fullPage: true\n          });\n          results.screenshot = screenshotPath;\n          console.log(`Screenshot captured: ${screenshotPath}`);\n        } catch (screenshotError) {\n          console.warn(`Failed to capture screenshot: ${screenshotError.message}`);\n        }\n\n        break; // Stop execution on first failure\n      }\n\n      results.actions.push(actionResult);\n    }\n  } finally {\n    await browser.close();\n  }\n\n  return results;\n}\n```\n\n### Screenshot Configuration\n\n| Option | Default | Description |\n|--------|---------|-------------|\n| `fullPage` | `true` | Capture entire scrollable page |\n| `path` | `/tmp/qa-screenshot-step-{N}-{timestamp}.png` | File path |\n| `type` | `png` | Image format (png for quality) |\n\n### Screenshot Handling Notes\n\n1. **Temp directory**: Screenshots saved to `/tmp/` for accessibility\n2. **Naming convention**: `qa-screenshot-step-{stepNumber}-{timestamp}.png`\n3. **Full page**: Captures entire page, not just viewport\n4. **Error resilience**: Screenshot failure doesn't fail the test (warns only)\n5. **No screenshot on pass**: Only captured when test fails\n\n### Accessing Screenshots\n\nThe screenshot path is returned in the results object:\n\n```javascript\nconst results = await executeStep(42, actions);\nif (!results.pass && results.screenshot) {\n  console.log(`Failure screenshot: ${results.screenshot}`);\n  // Pass to bug creation workflow\n}\n```\n\n## Step 5: Handle Pass Result with GitHub Comment\n\nWhen a QA Step passes, post a success comment on the Step issue.\n\n### Pass Comment Template\n\n```bash\ngh issue comment \"$STEP\" --body \"$(cat <<'COMMENT'\n## ✅ Passed\n\n- **Executed by:** AI (Claude Code)\n- **Timestamp:** $(date -u +\"%Y-%m-%d %H:%M:%S UTC\")\n- **Result:** All assertions passed\n\n### Actions Executed\n\n- Navigate to <URL>\n- Click <element>\n- Fill <field> with <value>\n- Assert text \"<text>\" visible\nCOMMENT\n)\"\n```\n\n### Pass Handler Implementation\n\n```javascript\nasync function handlePassResult(stepNumber, results) {\n  const timestamp = new Date().toISOString().replace('T', ' ').replace(/\\.\\d+Z$/, ' UTC');\n\n  // Build action summary\n  const actionSummary = results.actions\n    .filter(a => a.success && !a.skipped)\n    .map(a => {\n      switch (a.action.type) {\n        case 'navigate': return `- Navigate to ${a.action.url}`;\n        case 'click': return `- Click \\`${a.action.selector}\\``;\n        case 'fill': return `- Fill \\`${a.action.selector}\\` with \"${a.action.value}\"`;\n        case 'select': return `- Select \"${a.action.value}\" from \\`${a.action.selector}\\``;\n        case 'wait': return `- Wait ${a.action.duration / 1000} seconds`;\n        case 'assertText': return `- Assert text \"${a.action.text}\" visible`;\n        case 'assertNoText': return `- Assert text \"${a.action.text}\" not visible`;\n        case 'assertURL': return `- Assert URL is ${a.action.url}`;\n        case 'assertURLContains': return `- Assert URL contains \"${a.action.pattern}\"`;\n        default: return `- ${a.action.type}`;\n      }\n    })\n    .join('\\n');\n\n  const comment = `## ✅ Passed\n\n- **Executed by:** AI (Claude Code)\n- **Timestamp:** ${timestamp}\n- **Result:** All assertions passed\n\n### Actions Executed\n\n${actionSummary}`;\n\n  // Post comment using gh CLI\n  const { execSync } = require('child_process');\n  execSync(`gh issue comment ${stepNumber} --body \"${comment.replace(/\"/g, '\\\\\"')}\"`, {\n    stdio: 'inherit'\n  });\n\n  console.log(`Posted pass comment on QA Step #${stepNumber}`);\n}\n```\n\n### Pass Comment Format\n\n| Field | Value |\n|-------|-------|\n| Emoji | ✅ |\n| Executed by | AI (Claude Code) |\n| Timestamp | UTC timestamp |\n| Result | All assertions passed |\n| Actions | Bulleted list of executed actions |\n\n## Step 6: Handle Fail Result and Trigger Bug Creation\n\nWhen a QA Step fails, post a failure comment and trigger the bug creation workflow.\n\n### Fail Comment Template\n\n```bash\ngh issue comment \"$STEP\" --body \"$(cat <<'COMMENT'\n## ❌ Failed\n\n- **Executed by:** AI (Claude Code)\n- **Timestamp:** $(date -u +\"%Y-%m-%d %H:%M:%S UTC\")\n- **Error:** <error message>\n\n### Failed Action\n\n- **Action:** <action that failed>\n- **Expected:** <what was expected>\n- **Actual:** <what happened>\n\n### Screenshot\n\n📸 Screenshot captured for bug report\n\n### Bug Report\n\n🐛 Creating bug issue...\nCOMMENT\n)\"\n```\n\n### Fail Handler Implementation\n\n```javascript\n// Bug creation must complete within 30 seconds per NFR2 (Task #43)\nconst BUG_CREATION_TIMEOUT_MS = 30000;\n\nasync function handleFailResult(stepNumber, stepTitle, stepBody, results, qaNumber) {\n  const startTime = Date.now();\n  const timestamp = new Date().toISOString().replace('T', ' ').replace(/\\.\\d+Z$/, ' UTC');\n\n  // Helper to check if we're approaching timeout\n  const checkTimeout = (operation) => {\n    const elapsed = Date.now() - startTime;\n    if (elapsed > BUG_CREATION_TIMEOUT_MS * 0.9) {\n      console.warn(`Warning: Bug creation approaching 30s timeout at ${operation} (${elapsed}ms elapsed)`);\n    }\n    return elapsed;\n  };\n\n  // Find the failed action\n  const failedAction = results.actions.find(a => a.error);\n  const failedActionDesc = failedAction\n    ? describeAction(failedAction.action)\n    : 'Unknown action';\n\n  // Extract scenario from step body\n  const scenarioMatch = stepBody.match(/## Scenario\\s+([\\s\\S]*?)(?=##|$)/);\n  const scenario = scenarioMatch ? scenarioMatch[1].trim() : 'Scenario not found';\n\n  // Build failure comment\n  const comment = `## ❌ Failed\n\n- **Executed by:** AI (Claude Code)\n- **Timestamp:** ${timestamp}\n- **Error:** ${results.error}\n\n### Failed Action\n\n\\`\\`\\`\n${failedActionDesc}\n\\`\\`\\`\n\n### Scenario\n\n\\`\\`\\`\n${scenario}\n\\`\\`\\`\n\n### Screenshot\n\n${results.screenshot ? '📸 Screenshot captured: `' + results.screenshot + '`' : '⚠️ No screenshot available'}\n\n### Bug Report\n\n🐛 Creating bug issue...`;\n\n  // Post failure comment (Task #43 timing: ~2s)\n  checkTimeout('post failure comment');\n  const { execSync } = require('child_process');\n  execSync(`gh issue comment ${stepNumber} --body \"${comment.replace(/\"/g, '\\\\\"').replace(/`/g, '\\\\`')}\"`, {\n    stdio: 'inherit'\n  });\n\n  // Bug creation timing breakdown (Task #43 - NFR2):\n  // - Post failure comment: ~2s\n  // - Fetch QA Issue for PRD: ~1s\n  // - Process screenshot: ~2-5s\n  // - Build bug body: ~0.1s\n  // - Create bug issue: ~2s\n  // - Link as sub-issue: ~2s\n  // - Update Bugs Found: ~2s\n  // - Post bug link comment: ~1s\n  // Total estimated: 12-17s (well under 30s target)\n\n  // Trigger bug creation workflow (Epic #9)\n  // Pass context: step number, error, screenshot path, scenario\n  const bugContext = {\n    qaStep: stepNumber,\n    qaIssue: qaNumber,\n    title: `Bug: ${stepTitle.replace('QA Step: ', '')} - Failed`,\n    error: results.error,\n    scenario: scenario,\n    screenshot: results.screenshot,\n    timestamp: timestamp\n  };\n\n  // Create bug issue with full template (Epic #9 implementation)\n  // Build traceability chain: Bug → QA Step → QA Issue → PRD (Task #42)\n  // Chain traversal:\n  //   1. Bug knows QA Step number (passed in as stepNumber)\n  //   2. QA Step body contains QA Issue reference (passed in as qaNumber)\n  //   3. QA Issue body contains PRD reference (extracted below)\n  const qaIssueData = JSON.parse(\n    execSync(`gh issue view ${qaNumber} --json body,title`, { encoding: 'utf-8' })\n  );\n  // Look for PRD reference in various formats: \"PRD: #123\", \"PRD #123\", \"PRD: 123\"\n  const prdPatterns = [\n    /PRD:\\s*#(\\d+)/i,\n    /PRD\\s*#(\\d+)/i,\n    /PRD:\\s*(\\d+)/i,\n    /-\\s*PRD:\\s*#(\\d+)/i,\n    /\\*\\*PRD:\\*\\*\\s*#(\\d+)/i\n  ];\n  let prdNumber = null;\n  for (const pattern of prdPatterns) {\n    const match = qaIssueData.body.match(pattern);\n    if (match) {\n      prdNumber = match[1];\n      break;\n    }\n  }\n  // If still not found, it might be in the title or not linked\n  if (!prdNumber) {\n    console.warn('Warning: Could not find PRD reference in QA Issue body');\n    prdNumber = 'Not linked';\n  }\n\n  // Extract Then clause for expected behavior\n  const thenMatch = scenario.match(/Then\\s+(.+?)(?:\\n|$)/i);\n  const expectedBehavior = thenMatch ? thenMatch[1].trim() : 'As specified in the QA Step assertions';\n\n  // Process screenshot for attachment (Task #38)\n  let screenshotSection;\n  if (results.screenshot) {\n    const screenshotInfo = await uploadScreenshotToGitHub(results.screenshot);\n    if (screenshotInfo) {\n      screenshotSection = screenshotInfo.note;\n    } else {\n      screenshotSection = `📸 Screenshot captured but upload failed.\\n\\nLocal path: \\`${results.screenshot}\\``;\n    }\n  } else {\n    screenshotSection = '⚠️ No screenshot available';\n  }\n\n  // Build bug body with full template structure (FR6 from PRD #5)\n  // All references use #<NUMBER> format for clickable GitHub links\n  const prdReference = /^\\d+$/.test(prdNumber) ? `#${prdNumber}` : prdNumber;\n  const bugBody = `# Bug: ${stepTitle.replace('QA Step: ', '')}\n\n## Source\n\n- **QA Step:** #${stepNumber}\n- **QA Issue:** #${qaNumber}\n- **PRD:** ${prdReference}\n\n## Reproduction Steps\n\n${generateReproductionSteps(scenario, results.error)}\n\n## Expected Behavior\n\n${expectedBehavior}\n\n## Actual Behavior\n\n${results.error}\n\n## Screenshot\n\n${screenshotSection}\n\n## Environment\n\n- **Browser:** Chromium (Playwright)\n- **Viewport:** 1280x720\n- **Timestamp:** ${timestamp}\n- **Executor:** AI (Claude Code)\n`;\n\n  // Ensure required labels exist (create if missing)\n  try {\n    execSync('gh label create bug --color D73A4A --description \"Something isn\\'t working\" 2>/dev/null || true', { stdio: 'pipe' });\n    execSync('gh label create QA-Bug --color B60205 --description \"Bug found via QA automation\" 2>/dev/null || true', { stdio: 'pipe' });\n  } catch (e) {\n    // Labels may already exist, continue\n  }\n\n  // Generate error summary for title (truncate if too long)\n  const errorSummary = results.error.length > 50\n    ? results.error.substring(0, 47) + '...'\n    : results.error;\n\n  // Clean step title for bug title\n  const cleanStepTitle = stepTitle\n    .replace(/^QA Step:\\s*/i, '')\n    .replace(/^Step:\\s*/i, '');\n\n  const bugTitle = `Bug: ${cleanStepTitle} - ${errorSummary}`;\n\n  // Write body to temp file to avoid shell escaping issues\n  const fs = require('fs');\n  const tempBodyFile = `/tmp/bug-body-${stepNumber}-${Date.now()}.md`;\n  fs.writeFileSync(tempBodyFile, bugBody);\n\n  // Create bug issue with both labels\n  const bugUrl = execSync(\n    `gh issue create --title \"${bugTitle.replace(/\"/g, '\\\\\"')}\" --label \"bug,QA-Bug\" --body-file \"${tempBodyFile}\"`,\n    { encoding: 'utf-8' }\n  ).trim();\n\n  // Clean up temp file\n  fs.unlinkSync(tempBodyFile);\n\n  const bugNumber = bugUrl.match(/\\/(\\d+)$/)?.[1];\n\n  // Link Bug as sub-issue of QA Step (Task #39)\n  // This creates third-level nesting: PRD → QA → Step → Bug\n  let subIssueLinkSuccess = false;\n  try {\n    // Get repo info\n    const repoInfo = JSON.parse(\n      execSync('gh repo view --json owner,name', { encoding: 'utf-8' })\n    );\n    const owner = repoInfo.owner.login;\n    const repo = repoInfo.name;\n\n    // Get the Bug's internal issue ID (different from issue number)\n    const bugId = JSON.parse(\n      execSync(`gh api repos/${owner}/${repo}/issues/${bugNumber} --jq '.id'`, { encoding: 'utf-8' }).trim()\n    );\n\n    // Add Bug as sub-issue of QA Step\n    execSync(\n      `gh api repos/${owner}/${repo}/issues/${stepNumber}/sub_issues -X POST -F sub_issue_id=${bugId} --silent`,\n      { stdio: 'pipe' }\n    );\n    subIssueLinkSuccess = true;\n    console.log(`Linked Bug #${bugNumber} as sub-issue of QA Step #${stepNumber}`);\n  } catch (linkError) {\n    // Sub-issue linking may fail if:\n    // - Feature not available in this GitHub instance\n    // - Third-level nesting not supported\n    // - Bug already has a parent\n    console.warn(`Warning: Could not link Bug #${bugNumber} as sub-issue of Step #${stepNumber}: ${linkError.message}`);\n    // Continue without sub-issue link - the body reference is sufficient\n  }\n\n  // Update the failure comment with bug link\n  const linkNote = subIssueLinkSuccess\n    ? '(linked as sub-issue)'\n    : '(sub-issue link failed, see bug body for traceability)';\n  execSync(`gh issue comment ${stepNumber} --body \"🐛 Bug created: ${bugUrl} ${linkNote}\"`, {\n    stdio: 'inherit'\n  });\n\n  // Update QA Step's Bugs Found section with bug link (Task #41)\n  // Skip if we're running low on time (Task #43)\n  const elapsedBeforeBugsUpdate = checkTimeout('before bugs found update');\n  if (elapsedBeforeBugsUpdate < BUG_CREATION_TIMEOUT_MS * 0.8) {\n    try {\n      await updateBugsFoundSection(stepNumber, bugNumber, stepTitle);\n      console.log(`Updated Bugs Found section in QA Step #${stepNumber}`);\n    } catch (updateError) {\n      console.warn(`Warning: Could not update Bugs Found section: ${updateError.message}`);\n      // Non-critical - the comment already links to the bug\n    }\n  } else {\n    console.log('Skipping Bugs Found update to meet 30s target');\n  }\n\n  // Add Bug to GitHub Project if GHPM_PROJECT is set (Task #48)\n  // Skip if we're running low on time (Task #43)\n  const elapsedBeforeProjectAdd = checkTimeout('before project add');\n  if (elapsedBeforeProjectAdd < BUG_CREATION_TIMEOUT_MS * 0.85) {\n    if (process.env.GHPM_PROJECT) {\n      try {\n        const repoInfo = JSON.parse(\n          execSync('gh repo view --json owner,name', { encoding: 'utf-8' })\n        );\n        const owner = repoInfo.owner.login;\n        execSync(\n          `gh project item-add \"${process.env.GHPM_PROJECT}\" --owner \"${owner}\" --url \"${bugUrl}\"`,\n          { stdio: 'pipe' }\n        );\n        console.log(`Added Bug #${bugNumber} to project: ${process.env.GHPM_PROJECT}`);\n      } catch (projectError) {\n        console.warn(`Warning: Could not add Bug #${bugNumber} to project: ${projectError.message}`);\n        // Non-critical - continue without project association\n      }\n    }\n  } else {\n    console.log('Skipping project add to meet 30s target');\n  }\n\n  // Log total bug creation time (Task #43 - NFR2 compliance)\n  const totalTime = Date.now() - startTime;\n  const timeStatus = totalTime <= BUG_CREATION_TIMEOUT_MS ? '✅' : '⚠️';\n  console.log(`${timeStatus} Bug creation completed in ${totalTime}ms (target: ${BUG_CREATION_TIMEOUT_MS}ms)`);\n\n  if (totalTime > BUG_CREATION_TIMEOUT_MS) {\n    console.warn(`Warning: Bug creation exceeded 30s target. Consider optimizing screenshot upload or parallel execution.`);\n  }\n\n  console.log(`Posted fail comment and created bug #${bugNumber} for QA Step #${stepNumber}`);\n\n  return bugNumber;\n}\n\n// Update QA Step's Bugs Found section with bug link (Task #41)\nasync function updateBugsFoundSection(stepNumber, bugNumber, bugTitle) {\n  const fs = require('fs');\n\n  // Fetch current step body\n  const stepData = JSON.parse(\n    execSync(`gh issue view ${stepNumber} --json body`, { encoding: 'utf-8' })\n  );\n  let body = stepData.body;\n\n  // Format: - #<BUG_NUMBER> Bug: <Title>\n  const cleanBugTitle = bugTitle\n    .replace(/^QA Step:\\s*/i, '')\n    .replace(/^Step:\\s*/i, '');\n  const bugLink = `- #${bugNumber} Bug: ${cleanBugTitle}`;\n\n  // Find Bugs Found section and update it\n  // Pattern: ## Bugs Found\\n\\n(None) or ## Bugs Found\\n\\n- #123 ...\n  const bugsFoundRegex = /## Bugs Found\\s*\\n\\n(\\(None\\)|[-*][\\s\\S]*?)(?=\\n##|\\n*$)/;\n\n  if (bugsFoundRegex.test(body)) {\n    body = body.replace(bugsFoundRegex, (match, existingContent) => {\n      if (existingContent.trim() === '(None)') {\n        // Replace \"(None)\" with bug link\n        return `## Bugs Found\\n\\n${bugLink}`;\n      } else {\n        // Append to existing bug list\n        return `## Bugs Found\\n\\n${existingContent.trim()}\\n${bugLink}`;\n      }\n    });\n  } else {\n    // If no Bugs Found section exists, append it\n    body = body.trimEnd() + `\\n\\n## Bugs Found\\n\\n${bugLink}`;\n  }\n\n  // Write updated body to temp file and update issue\n  const tempFile = `/tmp/qa-step-body-${stepNumber}-${Date.now()}.md`;\n  fs.writeFileSync(tempFile, body);\n\n  execSync(`gh issue edit ${stepNumber} --body-file \"${tempFile}\"`, {\n    stdio: 'pipe'\n  });\n\n  // Clean up temp file\n  fs.unlinkSync(tempFile);\n}\n\n// Upload screenshot to GitHub and return markdown image embed (Task #38)\nasync function uploadScreenshotToGitHub(screenshotPath) {\n  if (!screenshotPath) return null;\n\n  const fs = require('fs');\n  const path = require('path');\n\n  // Check if file exists\n  if (!fs.existsSync(screenshotPath)) {\n    console.warn(`Screenshot file not found: ${screenshotPath}`);\n    return null;\n  }\n\n  try {\n    // Get file stats for size check\n    const stats = fs.statSync(screenshotPath);\n    const fileSizeMB = stats.size / (1024 * 1024);\n\n    // Compress if over 5MB (GitHub has 10MB limit)\n    if (fileSizeMB > 5) {\n      console.log(`Screenshot is ${fileSizeMB.toFixed(2)}MB, may need compression`);\n      // Note: Compression would require additional tools like sharp\n      // For now, proceed and let GitHub reject if too large\n    }\n\n    // Get repo info\n    const repoInfo = JSON.parse(\n      execSync('gh repo view --json owner,name', { encoding: 'utf-8' })\n    );\n    const owner = repoInfo.owner.login;\n    const repo = repoInfo.name;\n\n    // GitHub's file upload for issues uses the uploads endpoint\n    // We can use gh api with file upload to create an asset\n    // However, direct issue image upload requires special handling\n\n    // Alternative approach: Upload via issue comment which auto-uploads images\n    // Create a temp issue comment with the image, extract the URL, then delete\n    // This is the most reliable way to get a GitHub-hosted image URL\n\n    // For now, we'll embed the local path and note that manual upload may be needed\n    // A production implementation would use GitHub's upload API or a separate image host\n\n    // Read file as base64 for inline embedding (works in some contexts)\n    const imageData = fs.readFileSync(screenshotPath);\n    const base64 = imageData.toString('base64');\n    const filename = path.basename(screenshotPath);\n    const mimeType = 'image/png';\n\n    // Return markdown with note about screenshot location\n    return {\n      markdown: `![Screenshot](${screenshotPath})`,\n      localPath: screenshotPath,\n      base64: base64,\n      filename: filename,\n      note: `📸 Screenshot saved locally: \\`${screenshotPath}\\`\\n\\n_To attach: drag and drop the screenshot file into this issue on GitHub._`\n    };\n  } catch (error) {\n    console.warn(`Failed to process screenshot: ${error.message}`);\n    return null;\n  }\n}\n\nfunction describeAction(action) {\n  switch (action.type) {\n    case 'navigate': return `Navigate to ${action.url}`;\n    case 'click': return `Click ${action.selector}`;\n    case 'fill': return `Fill ${action.selector} with \"${action.value}\"`;\n    case 'select': return `Select \"${action.value}\" from ${action.selector}`;\n    case 'assertText': return `Assert text \"${action.text}\" is visible`;\n    case 'assertNoText': return `Assert text \"${action.text}\" is not visible`;\n    case 'assertURL': return `Assert URL is ${action.url}`;\n    case 'assertURLContains': return `Assert URL contains \"${action.pattern}\"`;\n    default: return JSON.stringify(action);\n  }\n}\n\n// Generate numbered reproduction steps from Given/When/Then scenario (Task #40)\n// Converts Given/When clauses to numbered action steps and adds failure observation\nfunction generateReproductionSteps(scenario, error) {\n  const steps = [];\n  const lines = scenario.split('\\n').map(l => l.trim()).filter(l => l);\n  let expectedBehavior = null;\n\n  let stepNum = 1;\n  for (const line of lines) {\n    if (/^Given\\s+/i.test(line)) {\n      // Convert Given to setup step\n      let action = line.replace(/^Given\\s+/i, '');\n      // Transform common patterns to clearer language\n      action = action.replace(/^I am on the /, 'Navigate to the ');\n      action = action.replace(/^I am on /, 'Navigate to ');\n      action = action.replace(/^I have /, 'Ensure ');\n      action = action.replace(/^the /, 'Ensure the ');\n      steps.push(`${stepNum}. ${action.charAt(0).toUpperCase() + action.slice(1)}`);\n      stepNum++;\n    } else if (/^When\\s+/i.test(line)) {\n      // Convert When to action step\n      let action = line.replace(/^When\\s+/i, '');\n      // Transform first-person to imperative\n      action = action.replace(/^I click /, 'Click ');\n      action = action.replace(/^I type /, 'Type ');\n      action = action.replace(/^I enter /, 'Enter ');\n      action = action.replace(/^I select /, 'Select ');\n      action = action.replace(/^I submit /, 'Submit ');\n      action = action.replace(/^I scroll /, 'Scroll ');\n      action = action.replace(/^I wait /, 'Wait ');\n      steps.push(`${stepNum}. ${action.charAt(0).toUpperCase() + action.slice(1)}`);\n      stepNum++;\n    } else if (/^And\\s+/i.test(line)) {\n      // And clauses continue previous context\n      let action = line.replace(/^And\\s+/i, '');\n      // Apply same transformations\n      action = action.replace(/^I click /, 'Click ');\n      action = action.replace(/^I type /, 'Type ');\n      action = action.replace(/^I enter /, 'Enter ');\n      action = action.replace(/^I select /, 'Select ');\n      action = action.replace(/^I should see /, 'Should see ');\n      steps.push(`${stepNum}. ${action.charAt(0).toUpperCase() + action.slice(1)}`);\n      stepNum++;\n    } else if (/^Then\\s+/i.test(line)) {\n      // Capture expected behavior from Then clause (used in step observation)\n      expectedBehavior = line.replace(/^Then\\s+/i, '').replace(/^I should /, 'Should ');\n    }\n    // Skip other lines (comments, blank, etc.)\n  }\n\n  // Handle empty scenario\n  if (steps.length === 0) {\n    steps.push('1. (Scenario steps could not be parsed)');\n    stepNum = 2;\n  }\n\n  // Add failure observation as final step, including what was expected\n  const expectedNote = expectedBehavior ? ` (expected: ${expectedBehavior})` : '';\n  steps.push(`${stepNum}. **Observe:** ${error}${expectedNote}`);\n\n  return steps.join('\\n');\n}\n```\n\n### Fail Comment Format\n\n| Field | Value |\n|-------|-------|\n| Emoji | ❌ |\n| Executed by | AI (Claude Code) |\n| Timestamp | UTC timestamp |\n| Error | Error message from Playwright |\n| Failed Action | Description of the action that failed |\n| Scenario | The Given/When/Then from the step |\n| Screenshot | Path to captured screenshot |\n| Bug Report | Link to created bug issue |\n\n### Bug Issue Template Structure (FR6 from PRD #5)\n\nThe created bug issue follows this template:\n\n```markdown\n# Bug: <Brief Description>\n\n## Source\n- QA Step: #<step_number>\n- QA Issue: #<qa_number>\n- PRD: #<prd_number>\n\n## Reproduction Steps\n1. Navigate to <URL>\n2. <action from When clause>\n3. <additional actions>\n4. **Observe:** <error message>\n\n## Expected Behavior\n<from the QA Step's Then clause>\n\n## Actual Behavior\n<what actually happened / error message>\n\n## Screenshot\n📸 Screenshot attached below (or warning if unavailable)\n\n## Environment\n- Browser: Chromium (Playwright)\n- Viewport: 1280x720\n- Timestamp: <execution time>\n- Executor: AI (Claude Code)\n```\n\nThe bug issue includes:\n\n1. **Source**: Full traceability chain (QA Step → QA Issue → PRD)\n2. **Reproduction Steps**: Numbered list generated from Given/When/Then + failure observation\n3. **Expected Behavior**: Extracted from Then clause\n4. **Actual Behavior**: Error message from Playwright\n5. **Screenshot**: Attached screenshot (when available)\n6. **Environment**: Browser, viewport, timestamp details\n\n## Step 7: Update QA Step Execution Log Section\n\nUpdate the Execution Log section in the QA Step issue body with execution results.\n\n### Execution Log Section Format\n\nThe QA Step issue body contains an Execution Log section:\n\n```markdown\n## Execution Log\n\n- [ ] Pass / Fail\n- **Executed by:** (not yet executed)\n- **Timestamp:** (pending)\n- **Notes:** (none)\n```\n\nAfter execution, update to:\n\n**On Pass:**\n\n```markdown\n## Execution Log\n\n- [x] Pass / ~~Fail~~\n- **Executed by:** AI (Claude Code)\n- **Timestamp:** 2025-01-15 14:30:00 UTC\n- **Notes:** All 5 actions completed successfully\n```\n\n**On Fail:**\n\n```markdown\n## Execution Log\n\n- [ ] ~~Pass~~ / Fail\n- **Executed by:** AI (Claude Code)\n- **Timestamp:** 2025-01-15 14:30:00 UTC\n- **Notes:** Failed at action 3: Assert text \"Welcome\" visible - Bug #123 created\n```\n\n### Update Implementation\n\n```javascript\nasync function updateExecutionLog(stepNumber, results, bugNumber = null) {\n  const timestamp = new Date().toISOString().replace('T', ' ').replace(/\\.\\d+Z$/, ' UTC');\n\n  // Fetch current issue body\n  const { execSync } = require('child_process');\n  const issueData = JSON.parse(\n    execSync(`gh issue view ${stepNumber} --json body`, { encoding: 'utf-8' })\n  );\n  let body = issueData.body;\n\n  // Build new Execution Log content\n  let newExecutionLog;\n  if (results.pass) {\n    const actionCount = results.actions.filter(a => a.success).length;\n    newExecutionLog = `## Execution Log\n\n- [x] Pass / ~~Fail~~\n- **Executed by:** AI (Claude Code)\n- **Timestamp:** ${timestamp}\n- **Notes:** All ${actionCount} actions completed successfully`;\n  } else {\n    const failedIndex = results.actions.findIndex(a => a.error);\n    const notes = bugNumber\n      ? `Failed at action ${failedIndex + 1}: ${results.error} - Bug #${bugNumber} created`\n      : `Failed at action ${failedIndex + 1}: ${results.error}`;\n    newExecutionLog = `## Execution Log\n\n- [ ] ~~Pass~~ / Fail\n- **Executed by:** AI (Claude Code)\n- **Timestamp:** ${timestamp}\n- **Notes:** ${notes}`;\n  }\n\n  // Replace Execution Log section in body\n  // Match from \"## Execution Log\" to next \"##\" or end of string\n  const executionLogRegex = /## Execution Log[\\s\\S]*?(?=##[^#]|$)/;\n\n  if (executionLogRegex.test(body)) {\n    body = body.replace(executionLogRegex, newExecutionLog + '\\n\\n');\n  } else {\n    // If no Execution Log section exists, append it\n    body = body + '\\n\\n' + newExecutionLog;\n  }\n\n  // Update issue body\n  // Write body to temp file to avoid shell escaping issues\n  const fs = require('fs');\n  const tempFile = `/tmp/qa-step-body-${stepNumber}.md`;\n  fs.writeFileSync(tempFile, body);\n\n  execSync(`gh issue edit ${stepNumber} --body-file \"${tempFile}\"`, {\n    stdio: 'inherit'\n  });\n\n  // Clean up temp file\n  fs.unlinkSync(tempFile);\n\n  console.log(`Updated Execution Log for QA Step #${stepNumber}`);\n}\n```\n\n### Update Notes\n\n1. **Preserve other sections**: Only replace the Execution Log section\n2. **Shell escaping**: Use temp file to avoid issues with special characters\n3. **Pass/Fail checkbox**: Use strikethrough to indicate the opposite result\n4. **Bug reference**: Include bug number in notes when applicable\n\n</workflow>\n\n<operating_rules>\n\n- Do not ask clarifying questions. Make reasonable assumptions and proceed.\n- Do not create local markdown files. All output goes into GitHub issues/comments.\n- Execute steps sequentially, posting results after each step completes.\n- If a step fails, continue to the next step (don't abort entire QA run).\n- Minimize noise: only comment at meaningful milestones (pass/fail results).\n- Never retry failed steps automatically (manual retry or bug triage expected).\n\n</operating_rules>\n\n<prerequisites>\n\nBefore execution, verify:\n\n```bash\n# 1. Check gh CLI authentication\ngh auth status || { echo \"ERROR: Not authenticated. Run 'gh auth login'\"; exit 1; }\n\n# 2. Check Playwright installation\nnpx playwright --version || { echo \"ERROR: Playwright not installed. Run 'npm install -D @playwright/test'\"; exit 1; }\n\n# 3. Check browser availability\nnpx playwright install chromium --dry-run 2>/dev/null || {\n  echo \"WARNING: Chromium may not be installed. Run 'npx playwright install chromium'\"\n}\n```\n\n</prerequisites>\n\n<input_validation>\n\n## Validation Checks\n\n```bash\n# Validate step number format (if provided)\nif [[ -n \"$STEP\" && ! \"$STEP\" =~ ^[0-9]+$ ]]; then\n  echo \"ERROR: Invalid step number. Use format: step=#123\"\n  exit 1\nfi\n\n# Validate QA number format (if provided)\nif [[ -n \"$QA\" && ! \"$QA\" =~ ^[0-9]+$ ]]; then\n  echo \"ERROR: Invalid QA number. Use format: qa=#123\"\n  exit 1\nfi\n\n# Verify issue exists and is accessible\nif [[ -n \"$STEP\" ]]; then\n  gh issue view \"$STEP\" > /dev/null 2>&1 || { echo \"ERROR: Cannot access QA Step #$STEP\"; exit 1; }\nfi\n\nif [[ -n \"$QA\" ]]; then\n  gh issue view \"$QA\" > /dev/null 2>&1 || { echo \"ERROR: Cannot access QA Issue #$QA\"; exit 1; }\nfi\n```\n\n</input_validation>\n\n<error_handling>\n\n## Common Errors and Recovery\n\n**If gh CLI not authenticated:**\n\n- Check: `gh auth status`\n- Fix: `gh auth login`\n\n**If Playwright not installed:**\n\n- Check: `npx playwright --version`\n- Fix: `npm install -D @playwright/test && npx playwright install chromium`\n\n**If browser not installed:**\n\n- Check: `npx playwright install chromium --dry-run`\n- Fix: `npx playwright install chromium`\n\n**If QA Step/Issue not found:**\n\n- Verify issue number is correct\n- Check repository access permissions\n- Confirm issue is not closed/deleted\n\n**If no QA Steps found for QA Issue:**\n\n- Verify QA Steps are linked as sub-issues\n- Check that QA Steps have the `QA-Step` label\n- Confirm QA Steps are in OPEN state\n\n**If Given/When/Then parsing fails:**\n\n- Log warning with unparseable line\n- Skip unparseable actions during execution\n- Include unparseable lines in execution report\n\n**If Playwright action fails:**\n\n- Capture screenshot before closing browser\n- Post failure comment with error details\n- Create bug issue with context\n- Continue to next QA Step (don't abort run)\n\n**If screenshot capture fails:**\n\n- Log warning but don't fail the step\n- Note \"No screenshot available\" in bug report\n\n**If GitHub API rate limited:**\n\n- Check: `gh api rate_limit`\n- Wait and retry, or authenticate with higher-privilege token\n\n</error_handling>\n\n<success_criteria>\n\nCommand completes successfully when:\n\n1. Target QA Steps have been resolved (from argument or auto-resolved)\n2. Each QA Step has been executed through Playwright\n3. Pass results: ✅ comment posted, Execution Log updated\n4. Fail results: ❌ comment posted, bug created, Execution Log updated\n5. Bug issues added to `GHPM_PROJECT` when set (best-effort)\n6. All steps processed (failures don't abort the run)\n\n**Verification:**\n\n```bash\n# Check execution comments on QA Steps\ngh issue view \"$STEP\" --json comments -q '.comments[-1].body'\n\n# Check Execution Log was updated\ngh issue view \"$STEP\" --json body -q '.body' | grep -A5 \"## Execution Log\"\n\n# Check bugs created for failures\ngh issue list -l Bug --json number,title\n```\n\n</success_criteria>\n\n<output>\n\nAfter completion, report:\n\n1. **QA Steps executed:** Count and issue numbers\n2. **Results:**\n   - Passed: Count and step numbers\n   - Failed: Count, step numbers, and bug numbers created\n3. **Project association:** Success/warning/skipped for bugs\n4. **Unparseable steps:** Count and warnings\n5. **Execution time:** Total duration\n6. **Errors:** Any issues encountered\n\n**Example output:**\n\n```\n## QA Execution Complete\n\n- **QA Issue:** #42\n- **Steps executed:** 5\n\n### Results\n\n| Step | Title | Result | Bug |\n|------|-------|--------|-----|\n| #101 | Valid login | ✅ Pass | - |\n| #102 | Invalid password | ✅ Pass | - |\n| #103 | Form validation | ❌ Fail | #150 |\n| #104 | Password reset | ✅ Pass | - |\n| #105 | Logout | ✅ Pass | - |\n\n### Summary\n\n- **Passed:** 4\n- **Failed:** 1\n- **Bugs created:** 1 (#150)\n- **Execution time:** 2m 34s\n```\n\n</output>\n\nProceed now."
              },
              {
                "name": "/quick-issue",
                "description": "Create a GitHub issue and branch in one step for quick bug fixes and small tasks, bypassing the PRD workflow.",
                "path": "plugins/ghpm/commands/quick-issue.md",
                "frontmatter": {
                  "description": "Create a GitHub issue and branch in one step for quick bug fixes and small tasks, bypassing the PRD workflow.",
                  "argument-hint": "<issue description>",
                  "allowed-tools": [
                    "Bash"
                  ]
                },
                "content": "<objective>\nCreate a GitHub issue and working branch in a single step, enabling developers to quickly start work on bug fixes, small enhancements, and maintenance tasks without going through the full PRD workflow. The command creates the issue, labels it with standard GitHub labels based on the work type, creates and checks out a feature branch, and optionally adds the issue to a GitHub Project.\n</objective>\n\n<prerequisites>\n- `gh` CLI installed and authenticated (`gh auth status`)\n- Working directory is a git repository with GitHub remote\n- User has write access to repository issues\n- Git working directory is clean (no uncommitted changes)\n- Optional: `GHPM_PROJECT` environment variable set for project association\n</prerequisites>\n\n<arguments>\n**Required:**\n- Issue description/title (captured from user input via $ARGUMENTS)\n\n**Optional flags (in $ARGUMENTS):**\n- `--label <name>` - Add a label (can be used multiple times)\n- `--no-branch` - Create issue only, skip branch creation\n- `--type <fix|feat|chore>` - Set work type (default: `fix`)\n  - `fix` → adds `bug` label, creates `fix/` branch\n  - `feat` → adds `enhancement` label, creates `feat/` branch\n  - `chore` → no automatic label, creates `chore/` branch\n\n**Optional environment variables:**\n- `GHPM_PROJECT` - GitHub Project number to add issue to (e.g., `export GHPM_PROJECT=7`)\n</arguments>\n\n<usage_examples>\n**Bug fix (default):**\n\n```bash\n/ghpm:quick-issue Fix the login redirect loop when session expires\n```\n\nOutput:\n```\n✓ Issue #42 created: \"Fix the login redirect loop when session expires\"\n  https://github.com/owner/repo/issues/42\n  Labels: bug\n✓ Branch created: fix/issue-42-login-redirect-loop\n✓ Switched to branch fix/issue-42-login-redirect-loop\n\nReady to work on issue #42. What would you like me to do first?\n```\n\n**New feature:**\n\n```bash\n/ghpm:quick-issue Add dark mode toggle --type feat\n```\n→ Labels: `enhancement`\n→ Branch: `feat/issue-43-dark-mode-toggle`\n\n**Maintenance/chore:**\n\n```bash\n/ghpm:quick-issue Update dependencies to latest versions --type chore\n```\n→ Labels: (none by default)\n→ Branch: `chore/issue-44-update-dependencies`\n\n**With additional labels:**\n\n```bash\n/ghpm:quick-issue Fix slow dashboard loading --label performance --label high-priority\n```\n→ Labels: `bug`, `performance`, `high-priority`\n\n**Issue only (no branch):**\n\n```bash\n/ghpm:quick-issue Update README with new API docs --type chore --no-branch\n```\n\n**With project association:**\n\n```bash\nexport GHPM_PROJECT=7\n/ghpm:quick-issue Fix broken date formatting in reports\n```\n→ Issue added to project #7\n\n</usage_examples>\n\n<operating_rules>\n- Do not ask clarifying questions. Create the issue immediately with the provided description.\n- The issue description becomes both the issue title and the summary in the body.\n- Labels are determined by the `--type` flag using standard GitHub labels:\n  - `fix` (default) → `bug` label\n  - `feat` → `enhancement` label\n  - `chore` → no automatic label\n- Additional labels can be added with `--label` flag.\n- Branch names are sanitized: lowercase, special characters removed, truncated to 50 chars.\n- Default type is `fix` (assumes most quick issues are bug fixes).\n- If `--no-branch` is specified, skip branch creation entirely.\n- On any error, provide actionable guidance for resolution.\n</operating_rules>\n\n<workflow>\n\n## Step 1: Validate Environment\n\n```bash\n# 1. Verify gh CLI authentication\ngh auth status || { echo \"ERROR: Not authenticated. Run 'gh auth login'\"; exit 1; }\n\n# 2. Verify in git repository\ngit rev-parse --git-dir > /dev/null 2>&1 || { echo \"ERROR: Not in a git repository\"; exit 1; }\n\n# 3. Verify GitHub remote exists\nREPO=$(gh repo view --json nameWithOwner -q .nameWithOwner) || { echo \"ERROR: No GitHub remote found\"; exit 1; }\nOWNER=$(gh repo view --json owner -q '.owner.login')\n```\n\n## Step 2: Parse Arguments\n\nExtract from $ARGUMENTS:\n- Issue description (everything that's not a flag)\n- `--label <name>` if present (can appear multiple times)\n- `--no-branch` flag\n- `--type <fix|feat|chore>` if present (default: `fix`)\n\n```bash\n# Example parsing\nDESCRIPTION=\"<extracted description>\"\nEXTRA_LABELS=()  # array of additional labels from --label flags\nNO_BRANCH=false  # or true if --no-branch present\nWORK_TYPE=\"fix\"  # or feat/chore if --type specified\n```\n\nValidate:\n- Description must not be empty\n- If `--type` provided, must be one of: fix, feat, chore\n\n## Step 3: Determine Labels Based on Type\n\n```bash\n# Map work type to standard GitHub label\ncase \"$WORK_TYPE\" in\n  fix)\n    TYPE_LABEL=\"bug\"\n    BRANCH_PREFIX=\"fix\"\n    ;;\n  feat)\n    TYPE_LABEL=\"enhancement\"\n    BRANCH_PREFIX=\"feat\"\n    ;;\n  chore)\n    TYPE_LABEL=\"\"  # No automatic label for chores\n    BRANCH_PREFIX=\"chore\"\n    ;;\nesac\n\n# Build label list\nLABELS=\"\"\nif [ -n \"$TYPE_LABEL\" ]; then\n  LABELS=\"$TYPE_LABEL\"\nfi\n\n# Add any extra labels from --label flags\nfor label in \"${EXTRA_LABELS[@]}\"; do\n  if [ -n \"$LABELS\" ]; then\n    LABELS=\"$LABELS,$label\"\n  else\n    LABELS=\"$label\"\n  fi\ndone\n```\n\n## Step 4: Create GitHub Issue\n\n```bash\n# Build gh issue create command\nif [ -n \"$LABELS\" ]; then\n  ISSUE_URL=$(gh issue create \\\n    --repo \"$REPO\" \\\n    --title \"$DESCRIPTION\" \\\n    --label \"$LABELS\" \\\n    --body \"$(cat <<EOF\n$DESCRIPTION\n\n---\n*Created via \\`/ghpm:quick-issue\\`*\nEOF\n)\")\nelse\n  # No labels\n  ISSUE_URL=$(gh issue create \\\n    --repo \"$REPO\" \\\n    --title \"$DESCRIPTION\" \\\n    --body \"$(cat <<EOF\n$DESCRIPTION\n\n---\n*Created via \\`/ghpm:quick-issue\\`*\nEOF\n)\")\nfi\n\n# Extract issue number from URL\nISSUE_NUM=$(echo \"$ISSUE_URL\" | grep -oE '[0-9]+$')\n```\n\n## Step 5: Add to GitHub Project (if configured)\n\n```bash\nif [ -n \"$GHPM_PROJECT\" ]; then\n  gh project item-add \"$GHPM_PROJECT\" --owner \"$OWNER\" --url \"$ISSUE_URL\" 2>/dev/null && \\\n    echo \"✓ Added to project #$GHPM_PROJECT\" || \\\n    echo \"WARNING: Could not add to project #$GHPM_PROJECT\"\nfi\n```\n\n## Step 6: Create and Checkout Branch (unless --no-branch)\n\n```bash\nif [ \"$NO_BRANCH\" = false ]; then\n  # Generate branch name slug from description\n  # 1. Convert to lowercase\n  # 2. Replace spaces and special chars with hyphens\n  # 3. Remove consecutive hyphens\n  # 4. Truncate to 50 chars\n  # 5. Remove trailing hyphens\n  SLUG=$(echo \"$DESCRIPTION\" | \\\n    tr '[:upper:]' '[:lower:]' | \\\n    sed 's/[^a-z0-9]/-/g' | \\\n    sed 's/-\\+/-/g' | \\\n    cut -c1-50 | \\\n    sed 's/-$//')\n\n  BRANCH_NAME=\"$BRANCH_PREFIX/issue-$ISSUE_NUM-$SLUG\"\n\n  # Check for uncommitted changes\n  if ! git diff-index --quiet HEAD -- 2>/dev/null; then\n    echo \"WARNING: Uncommitted changes detected. Branch created but not checked out.\"\n    echo \"Run: git stash && git checkout $BRANCH_NAME\"\n  else\n    # Create and checkout branch\n    git checkout -b \"$BRANCH_NAME\" || {\n      echo \"ERROR: Failed to create branch. You may need to create it manually:\"\n      echo \"  git checkout -b $BRANCH_NAME\"\n    }\n  fi\n\n  # Update issue body with branch link\n  gh issue edit \"$ISSUE_NUM\" --repo \"$REPO\" --body \"$(cat <<EOF\n$DESCRIPTION\n\n**Branch:** \\`$BRANCH_NAME\\`\n\n---\n*Created via \\`/ghpm:quick-issue\\`*\nEOF\n)\"\nfi\n```\n\n## Step 7: Output Success Message\n\n```bash\necho \"\"\necho \"✓ Issue #$ISSUE_NUM created: \\\"$DESCRIPTION\\\"\"\necho \"  $ISSUE_URL\"\nif [ -n \"$LABELS\" ]; then\n  echo \"  Labels: $LABELS\"\nfi\n\nif [ \"$NO_BRANCH\" = false ]; then\n  echo \"✓ Branch created: $BRANCH_NAME\"\n  echo \"✓ Switched to branch $BRANCH_NAME\"\nfi\n\nif [ -n \"$GHPM_PROJECT\" ]; then\n  echo \"✓ Added to project #$GHPM_PROJECT\"\nfi\n\necho \"\"\necho \"Ready to work on issue #$ISSUE_NUM. What would you like me to do first?\"\n```\n\n</workflow>\n\n<error_handling>\n**If gh CLI not authenticated:**\n```\nERROR: Not authenticated. Run 'gh auth login'\n```\n\n**If not in git repository:**\n```\nERROR: Not in a git repository. Navigate to your project directory.\n```\n\n**If no GitHub remote:**\n```\nERROR: No GitHub remote found. Add one with: git remote add origin <url>\n```\n\n**If description is empty:**\n```\nERROR: Issue description required.\nUsage: /ghpm:quick-issue <description> [--type <fix|feat|chore>] [--label <name>] [--no-branch]\n```\n\n**If issue creation fails:**\n```\nERROR: Failed to create issue. Check:\n- gh auth status (authentication)\n- Repository permissions (write access to issues)\n- Rate limits: gh api rate_limit\n```\n\n**If branch creation fails:**\n```\nWARNING: Issue #N created, but branch creation failed.\nCreate branch manually: git checkout -b <branch-name>\n```\n\n**If uncommitted changes exist:**\n```\nWARNING: Uncommitted changes detected. Branch created but not checked out.\nRun: git stash && git checkout <branch-name>\n```\n</error_handling>\n\n<success_criteria>\nCommand completes successfully when:\n\n1. GitHub issue is created with appropriate label(s) based on type\n2. Issue body contains description and branch link (if branch created)\n3. Branch is created with correct naming convention (unless `--no-branch`)\n4. Branch is checked out (unless uncommitted changes or `--no-branch`)\n5. Issue is added to project (if `GHPM_PROJECT` set)\n6. Success message displays issue URL, labels, and branch name\n\n**Verification:**\n\n```bash\n# View the created issue\ngh issue view <issue_number>\n\n# Check current branch\ngit branch --show-current\n\n# Verify issue labels\ngh issue view <issue_number> --json labels -q '.labels[].name'\n```\n</success_criteria>\n\n<output>\nAfter completion, display:\n\n```\n✓ Issue #<number> created: \"<description>\"\n  <issue_url>\n  Labels: <label1>, <label2>\n✓ Branch created: <branch_prefix>/issue-<number>-<slug>\n✓ Switched to branch <branch_prefix>/issue-<number>-<slug>\n[✓ Added to project #<project_number>]  (if GHPM_PROJECT set)\n\nReady to work on issue #<number>. What would you like me to do first?\n```\n\nIf `--no-branch` was specified:\n\n```\n✓ Issue #<number> created: \"<description>\"\n  <issue_url>\n  Labels: <label1>, <label2>\n[✓ Added to project #<project_number>]  (if GHPM_PROJECT set)\n\nIssue created. Run `/ghpm:tdd-task task=#<number>` to start implementation.\n```\n</output>\n\n<related_commands>\n**After creating a quick issue:**\n- `/ghpm:tdd-task task=#N` - Implement the issue using TDD\n- `/ghpm:execute task=#N` - Execute the issue (auto-routes to TDD or non-TDD)\n\n**Full GHPM workflow (for larger features):**\n1. `/ghpm:create-prd` - Create PRD from user input\n2. `/ghpm:create-epics` - Break PRD into Epics\n3. `/ghpm:create-tasks` - Break Epics into Tasks\n4. `/ghpm:tdd-task` - Implement Tasks with TDD\n</related_commands>\n\nProceed now: parse $ARGUMENTS, validate environment, create issue and branch."
              },
              {
                "name": "/tdd-task",
                "description": "Execute a Task using a TDD loop; record decisions/progress on the issue; open a PR that closes the Task.",
                "path": "plugins/ghpm/commands/tdd-task.md",
                "frontmatter": {
                  "description": "Execute a Task using a TDD loop; record decisions/progress on the issue; open a PR that closes the Task.",
                  "allowed-tools": [
                    "Read",
                    "Edit",
                    "Write",
                    "Bash",
                    "Grep",
                    "Glob",
                    "Skill(ruby)",
                    "Skill(javascript)",
                    "Skill(rspec)",
                    "Skill(javascript-unit-testing)",
                    "Skill(rubycritic)",
                    "Skill(simplecov)"
                  ]
                },
                "content": "<objective>\nImplement a GitHub Task issue using disciplined TDD (Red -> Green -> Refactor), recording all decisions and progress on the GitHub issue, then opening a PR that closes the Task. All commits and PRs follow Conventional Commits format to enable automated changelog generation.\n</objective>\n\n<arguments>\n**Optional arguments:**\n- `task=#123` - Specific task issue number\n- `focus=unit|integration|e2e` - Best-effort hint for test focus\n\n**Resolution order if omitted:**\n\n1. If branch name matches `ghpm/task-<N>-*` or `task-<N>-*`, use N\n2. Most recent open issue labeled `Task` assigned to @me:\n   `gh issue list -l Task -a @me -s open --limit 1 --json number -q '.[0].number'`\n3. Most recent open Task:\n   `gh issue list -l Task -s open --limit 1 --json number -q '.[0].number'`\n</arguments>\n\n<usage_examples>\n**With task number:**\n\n```bash\n/ghpm:tdd-task task=#42\n```\n\n**With focus hint:**\n\n```bash\n/ghpm:tdd-task task=#42 focus=unit\n```\n\n**Auto-resolve from branch:**\n\n```bash\n# On branch: ghpm/task-42-add-auth\n/ghpm:tdd-task\n```\n\n**Auto-resolve from GitHub:**\n\n```bash\n# No arguments - uses most recent assigned Task\n/ghpm:tdd-task\n```\n\n</usage_examples>\n\n<operating_rules>\n\n- Always create a feature branch before making changes. Never commit directly to main/master.\n- No local markdown artifacts. Do not write local status files; only code changes + GitHub issue/PR updates.\n- Do NOT use the TodoWrite tool to track tasks during this session.\n- Do not silently expand scope. If you must, create a new follow-up Task issue and link it.\n- Always provide a runnable test command in the final notes.\n- Minimize noise: comment at meaningful milestones.\n- All commits and PR titles MUST follow Conventional Commits format for changelog generation.\n</operating_rules>\n\n<conventional_commits>\n\n## Conventional Commits Format\n\nAll commits and PR titles must follow the [Conventional Commits](https://www.conventionalcommits.org/) specification to enable automated changelog generation.\n\n### Format\n\n```\n<type>[optional scope]: <description> (#<issue>)\n\n[optional body]\n\n[optional footer(s)]\n```\n\n### Commit Types\n\n| Type | Description | Changelog Section |\n|------|-------------|-------------------|\n| `feat` | New feature or capability | Features |\n| `fix` | Bug fix | Bug Fixes |\n| `refactor` | Code restructuring without behavior change | Code Refactoring |\n| `perf` | Performance improvement | Performance |\n| `test` | Adding or updating tests | Testing |\n| `docs` | Documentation only changes | Documentation |\n| `style` | Formatting, whitespace (no code change) | (excluded) |\n| `chore` | Build, CI, dependencies, tooling | Maintenance |\n| `revert` | Revert a previous commit | Reverts |\n\n### Determining Commit Type\n\nInfer the type from the Task context:\n\n1. **Task labels**: `enhancement` → `feat`, `bug` → `fix`\n2. **Task title keywords**: \"add\", \"implement\", \"create\" → `feat`; \"fix\", \"resolve\", \"correct\" → `fix`\n3. **Epic context**: Feature epic → `feat`, Bug epic → `fix`, Tech debt epic → `refactor`\n4. **Scope of change**: If primarily tests → `test`, if primarily docs → `docs`\n\n### Breaking Changes\n\nFor breaking changes, add \\`!\\` after the type or include \\`BREAKING CHANGE:\\` in the footer:\n\n```\nfeat!: remove deprecated API endpoint (#123)\n\nBREAKING CHANGE: The /v1/users endpoint has been removed. Use /v2/users instead.\n```\n\n### Examples\n\n**Feature commit:**\n```\nfeat(auth): add OAuth2 login flow (#42)\n```\n\n**Bug fix commit:**\n```\nfix(payments): resolve null pointer in checkout (#103)\n```\n\n**Refactor commit:**\n```\nrefactor(users): extract email service into separate module (#87)\n```\n\n**Test commit:**\n```\ntest(api): add integration tests for user endpoints (#156)\n```\n\n### Commit Message During TDD Cycles\n\nDuring Red-Green-Refactor cycles, commit at each meaningful milestone:\n\n- **RED phase**: `test(<scope>): add failing test for <behavior> (#<task>)`\n- **GREEN phase**: `feat(<scope>): implement <behavior> (#<task>)` or `fix(<scope>): ...`\n- **REFACTOR phase**: `refactor(<scope>): <improvement description> (#<task>)`\n\n</conventional_commits>\n\n<workflow>\n\n## Step 0: Hydrate context\n\nResolve the task number and fetch context:\n\n```bash\n# Resolve task number from arguments, branch, or auto-select\nTASK={resolved_task_number}\n\n# Fetch issue details\ngh issue view \"$TASK\" --json title,body,url,labels,comments -q '.'\n```\n\n**Extract from issue:**\n\n- Acceptance criteria\n- Test plan (or infer if missing)\n- Epic/PRD links\n\n## Step 0.5: Validate Task Status\n\nBefore proceeding, check if the task is already closed or marked as done:\n\n```bash\n# Fetch issue state and labels\nISSUE_DATA=$(gh issue view \"$TASK\" --json state,labels,projectItems -q '.')\nSTATE=$(echo \"$ISSUE_DATA\" | jq -r '.state')\n\n# Check if issue is closed\nif [ \"$STATE\" = \"CLOSED\" ]; then\n  echo \"Task #$TASK is already CLOSED. Cannot proceed with TDD.\"\n  exit 0\nfi\n\n# Check for \"Done\" label\nDONE_LABEL=$(echo \"$ISSUE_DATA\" | jq -r '.labels[]?.name | select(. == \"Done\" or . == \"done\" or . == \"DONE\")')\nif [ -n \"$DONE_LABEL\" ]; then\n  echo \"Task #$TASK has 'Done' label. Cannot proceed with TDD.\"\n  exit 0\nfi\n\n# Check project status field (if linked to a project)\nPROJECT_STATUS=$(echo \"$ISSUE_DATA\" | jq -r '.projectItems[]?.status?.name // empty')\nif [ \"$PROJECT_STATUS\" = \"Done\" ] || [ \"$PROJECT_STATUS\" = \"Completed\" ]; then\n  echo \"Task #$TASK has project status '$PROJECT_STATUS'. Cannot proceed with TDD.\"\n  exit 0\nfi\n```\n\n**Behavior:**\n\n- If task is CLOSED → exit with message \"Task #N is already closed. Cannot proceed with TDD.\"\n- If task has \"Done\" label → exit with message \"Task #N is marked as done. Cannot proceed with TDD.\"\n- If task's project status is \"Done\" or \"Completed\" → exit with status message\n\n## Step 0.8: Claim Issue\n\nBefore starting any work, claim the issue to prevent duplicate work and enable progress tracking.\n\n```bash\n# Get current GitHub user\nCURRENT_USER=$(gh api user -q '.login')\nif [ -z \"$CURRENT_USER\" ]; then\n  echo \"ERROR: Could not determine current GitHub user. Run 'gh auth login'\"\n  exit 1\nfi\n\n# Check existing assignees\nASSIGNEES=$(gh issue view \"$TASK\" --json assignees -q '.assignees[].login')\n\n# Handle assignment scenarios\nif [ -z \"$ASSIGNEES\" ]; then\n  # No assignees - claim the issue\n  gh issue edit \"$TASK\" --add-assignee @me\n  echo \"✓ Assigned to @$CURRENT_USER\"\n\n  # Post audit comment\n  TIMESTAMP=$(date -u +\"%Y-%m-%d %H:%M:%S UTC\")\n  gh issue comment \"$TASK\" --body \"🏷️ Claimed by @$CURRENT_USER at $TIMESTAMP\"\n\nelif echo \"$ASSIGNEES\" | grep -qx \"$CURRENT_USER\"; then\n  # Already assigned to current user - proceed\n  echo \"✓ Already assigned to you (@$CURRENT_USER)\"\n\nelse\n  # Assigned to another user - abort\n  EXISTING_ASSIGNEE=$(echo \"$ASSIGNEES\" | head -1)\n  echo \"✗ Task #$TASK is already claimed by @$EXISTING_ASSIGNEE\"\n  exit 1\nfi\n\n# Update project status to \"In Progress\" (best-effort)\nif [ -n \"$GHPM_PROJECT\" ]; then\n  OWNER=$(gh repo view --json owner -q '.owner.login')\n  # Note: Project status update is best-effort and may require manual verification\n  echo \"Note: Project status update to 'In Progress' is best-effort\"\nfi\n\n# Warn on orphaned state (In Progress without assignee)\nif [ -z \"$ASSIGNEES\" ] && [ -n \"$GHPM_PROJECT\" ]; then\n  PROJECT_STATUS=$(gh issue view \"$TASK\" --json projectItems -q '.projectItems[0].status.name // empty' 2>/dev/null)\n  if [ \"$PROJECT_STATUS\" = \"In Progress\" ]; then\n    echo \"⚠ Warning: Task #$TASK had status 'In Progress' but no assignee\"\n  fi\nfi\n```\n\n**UX Output:**\n\n| Scenario | Output |\n|----------|--------|\n| Success (new claim) | `✓ Assigned to @username` |\n| Self-claim | `✓ Already assigned to you (@username)` |\n| Conflict | `✗ Task #N is already claimed by @another-user` |\n| Orphaned state | `⚠ Warning: Task #N had status 'In Progress' but no assignee` |\n\n**Behavior:**\n\n- Claiming occurs BEFORE any work begins (before TDD plan posting)\n- On conflict, command aborts cleanly with no partial work\n- On self-claim, command proceeds normally\n- All claiming operations complete within 3 seconds\n\n## Step 1: Post a TDD Plan comment\n\nComment on the Task with your implementation plan:\n\n```markdown\n## TDD Plan\n\n- **Objective:**\n- **Target behavior / acceptance criteria:**\n- **Test strategy (focus level + what to cover):**\n- **Proposed minimal design (non-binding):**\n- **Commands (build/test/lint) you will run:**\n- **Milestones (Red/Green/Refactor slices):**\n```\n\nExecute:\n\n```bash\ngh issue comment \"$TASK\" --body \"<markdown>\"\n```\n\n## Step 2: Create a working branch\n\n```bash\ngit checkout -b \"ghpm/task-$TASK-<short-slug>\"\n```\n\nComment branch name to the issue (same comment or a follow-up).\n\n## Step 3: TDD execution loop\n\nFor each slice:\n\n1. **RED:** Add failing test(s)\n   - Commit: `test(<scope>): add failing test for <behavior> (#$TASK)`\n2. **GREEN:** Implement minimum change to pass\n   - Commit: `<type>(<scope>): <description> (#$TASK)` (typically `feat` or `fix`)\n3. **REFACTOR:** Clean up while tests stay green\n   - Commit: `refactor(<scope>): <description> (#$TASK)`\n4. Run tests and capture command + result\n\n**Commit after each phase** using conventional commit format. Determine the type from Task context (see `<conventional_commits>` section).\n\nAfter each slice, comment on the Task with:\n\n- What changed\n- Tests added/updated\n- Test command executed + result\n- Commit hash(es) made\n- Any decision/rationale\n\n## Step 4: Update the Task body with a \"Task Report\" section\n\nEdit the issue body to append:\n\n```markdown\n## Task Report (auto)\n\n### Implementation summary\n\n### Files changed\n\n### How to validate locally\n\n### Test command(s) and results\n\n### Decision log\n\n### Follow-ups (if any)\n```\n\nExecute:\n\n```bash\ngh issue edit \"$TASK\" --body \"<updated markdown>\"\n```\n\n## Step 5: Open a PR that closes the Task\n\nPush branch and create PR using **Conventional Commits** format for the title:\n\n```bash\ngit push -u origin HEAD\n\n# Determine type from Task context (see <conventional_commits> section)\n# Format: <type>(<scope>): <description> (#$TASK)\n\ngh pr create --title \"<type>(<scope>): <description> (#$TASK)\" --body \"$(cat <<'EOF'\nCloses #$TASK\n\n## Summary\n\n- ...\n\n## Test Plan\n\n- `<test command>`\n\n## Commits\n\n<list of conventional commits made during TDD>\nEOF\n)\"\n```\n\n**PR Title Examples:**\n\n- `feat(auth): add OAuth2 login flow (#42)`\n- `fix(payments): resolve checkout null pointer (#103)`\n- `refactor(users): extract email service (#87)`\n\nComment the PR URL back onto the Task:\n\n```bash\ngh issue comment \"$TASK\" --body \"PR created: <PR_URL>\"\n```\n\n## Step 6: Final checkpoint\n\n- Ensure all tests pass\n- Ensure Task Report is updated in issue body\n- Ensure PR references and closes the Task\n\n</workflow>\n\n<success_criteria>\nCommand completes when:\n\n- All tests pass\n- Task Report section is updated in the issue body\n- PR is created with `Closes #$TASK` in the body\n- PR URL is commented back to the Task\n</success_criteria>\n\n<error_handling>\n**If tests fail during a cycle:**\n\n- Do not proceed to refactor\n- Comment on issue with failure details\n- Debug and fix before continuing\n\n**If PR creation fails:**\n\n- Ensure branch is pushed\n- Check repository permissions\n- Verify issue number exists\n- Comment failure details on Task issue\n</error_handling>\n\nProceed now."
              },
              {
                "name": "/auto-execute",
                "description": "Trigger the orchestrator-agent to autonomously execute a PRD from start to finish",
                "path": "plugins/ghpmplus/commands/auto-execute.md",
                "frontmatter": {
                  "description": "Trigger the orchestrator-agent to autonomously execute a PRD from start to finish",
                  "argument-hint": "prd=#<issue_number>",
                  "allowed-tools": [
                    "Read",
                    "Bash",
                    "Grep",
                    "Task"
                  ]
                },
                "content": "<objective>\nYou are the entry point for GHPMplus autonomous execution. Your job is to validate the PRD exists, confirm execution with the user, and then delegate to the orchestrator-agent via the Task tool to handle the complete workflow.\n</objective>\n\n<prerequisites>\n- `gh` CLI installed and authenticated (`gh auth status`)\n- Working directory is a git repository with GitHub remote\n- User has write access to repository issues\n- PRD issue must exist and be labeled \"PRD\"\n</prerequisites>\n\n<arguments>\n**Required:**\n- `prd=#N` - The PRD issue number to execute\n\n**Example:**\n```\n/ghpmplus:auto-execute prd=#42\n```\n</arguments>\n\n<usage_examples>\n\n**Standard usage:**\n\n```\n/ghpmplus:auto-execute prd=#42\n```\n\n→ Validates PRD #42 exists, shows summary, confirms with user, then triggers orchestrator\n\n**With existing Epics:**\n\n```\n/ghpmplus:auto-execute prd=#42\n```\n\n→ If PRD already has Epics, orchestrator will use existing breakdown instead of creating new\n\n</usage_examples>\n\n<operating_rules>\n\n- **Always validate** that the PRD issue exists and has the \"PRD\" label before proceeding\n- **Show PRD summary** to user before triggering execution\n- **Confirm execution** with user before delegating to orchestrator (this is a significant autonomous action)\n- **Do not create local artifacts** - all work happens via GitHub issues and the orchestrator\n- **Delegate fully** to the orchestrator-agent once confirmed - do not duplicate its workflow\n</operating_rules>\n\n<workflow>\n\n## Step 1: Parse Arguments\n\nExtract PRD number from arguments:\n\n```bash\n# Parse prd=#N from $ARGUMENTS\nPRD_NUMBER=$(echo \"$ARGUMENTS\" | grep -oE 'prd=#[0-9]+' | grep -oE '[0-9]+')\n\nif [ -z \"$PRD_NUMBER\" ]; then\n  echo \"ERROR: PRD number required\"\n  echo \"Usage: /ghpmplus:auto-execute prd=#<issue_number>\"\n  exit 1\nfi\n```\n\n## Step 2: Validate PRD Exists\n\n```bash\n# Verify PRD issue exists and has PRD label\nPRD_DATA=$(gh issue view \"$PRD_NUMBER\" --json title,body,labels,state,url 2>/dev/null)\n\nif [ -z \"$PRD_DATA\" ]; then\n  echo \"ERROR: Issue #$PRD_NUMBER not found\"\n  exit 1\nfi\n\n# Check for PRD label\nHAS_PRD_LABEL=$(echo \"$PRD_DATA\" | jq -r '.labels[].name' | grep -c \"^PRD$\" || echo \"0\")\n\nif [ \"$HAS_PRD_LABEL\" -eq 0 ]; then\n  echo \"WARNING: Issue #$PRD_NUMBER does not have 'PRD' label\"\n  echo \"This may not be a valid PRD. Proceeding anyway...\"\nfi\n\n# Check if PRD is open\nSTATE=$(echo \"$PRD_DATA\" | jq -r '.state')\nif [ \"$STATE\" = \"CLOSED\" ]; then\n  echo \"ERROR: PRD #$PRD_NUMBER is already closed\"\n  exit 1\nfi\n```\n\n## Step 3: Display PRD Summary\n\nExtract and display key information:\n\n```bash\nTITLE=$(echo \"$PRD_DATA\" | jq -r '.title')\nURL=$(echo \"$PRD_DATA\" | jq -r '.url')\n\necho \"## PRD Summary\"\necho \"\"\necho \"**Title:** $TITLE\"\necho \"**Issue:** #$PRD_NUMBER\"\necho \"**URL:** $URL\"\necho \"\"\n```\n\nAlso extract from body:\n- Summary section\n- Acceptance Criteria (high level)\n- Any existing Epics linked\n\n## Step 4: Check for Existing Work\n\n```bash\n# Get repository info\nOWNER=$(gh repo view --json owner -q '.owner.login')\nREPO=$(gh repo view --json name -q '.name')\n\n# Check for existing Epics linked to this PRD using GraphQL sub-issues API\ncat > /tmp/ghpmplus-subissues.graphql << 'GRAPHQL'\nquery($owner: String!, $repo: String!, $number: Int!) {\n  repository(owner: $owner, name: $repo) {\n    issue(number: $number) {\n      subIssues(first: 50) {\n        nodes {\n          number\n          title\n          state\n          labels(first: 10) {\n            nodes { name }\n          }\n        }\n      }\n    }\n  }\n}\nGRAPHQL\n\nEPICS=$(gh api graphql -F owner=\"$OWNER\" -F repo=\"$REPO\" -F number=$PRD_NUMBER \\\n  -f query=\"$(cat /tmp/ghpmplus-subissues.graphql)\" \\\n  --jq '.data.repository.issue.subIssues.nodes[] | select(.labels.nodes[].name == \"Epic\") | [.number, .title, .state] | @tsv' 2>/dev/null || echo \"\")\n\nif [ -n \"$EPICS\" ]; then\n  echo \"### Existing Epics Found\"\n  echo \"\"\n  echo \"$EPICS\" | while read line; do\n    NUM=$(echo \"$line\" | cut -f1)\n    TITLE=$(echo \"$line\" | cut -f2)\n    STATE=$(echo \"$line\" | cut -f3)\n    echo \"- #$NUM: $TITLE ($STATE)\"\n  done\n  echo \"\"\n  echo \"The orchestrator will use existing Epics instead of creating new ones.\"\nfi\n```\n\n## Step 5: Confirm Execution\n\nBefore delegating to orchestrator, confirm with user:\n\n```\nThis will trigger autonomous execution of PRD #$PRD_NUMBER.\n\nThe orchestrator will:\n1. Break down the PRD into Epics (if not already done)\n2. Break Epics into atomic Tasks\n3. Execute Tasks using TDD or Non-TDD workflows\n4. Create PRs for each Task\n5. Monitor CI and handle failures\n\nThis process may take significant time and will create multiple GitHub issues and PRs.\n\nProceed with autonomous execution?\n```\n\nUse `AskUserQuestion` tool if needed for confirmation.\n\n## Step 6: Delegate to Orchestrator\n\nOnce confirmed, delegate to the orchestrator-agent:\n\n```markdown\nUse the Task tool with subagent_type=\"ghpmplus:orchestrator\" to:\n\nExecute PRD #$PRD_NUMBER autonomously.\n\nContext:\n- PRD Title: $TITLE\n- PRD URL: $URL\n- Existing Epics: [list if any]\n\nThe orchestrator should:\n1. Fetch full PRD details\n2. Create or use existing Epics\n3. Create Tasks for each Epic\n4. Execute Tasks in appropriate order (respecting dependencies)\n5. Create PRs with conventional commits\n6. Monitor CI status\n7. Report completion status back to PRD issue\n```\n\n## Step 7: Report Initiation\n\nAfter delegation, report:\n\n```\nAutonomous Execution Initiated\n\nPRD: #$PRD_NUMBER - $TITLE\nOrchestrator: Delegated via Task tool\n\nThe orchestrator is now running. Progress will be posted to:\n- PRD issue: $URL\n- Individual Epic and Task issues as they are created\n\nYou can monitor progress by watching the PRD issue for updates.\n```\n\n</workflow>\n\n<error_handling>\n\n**If PRD not found:**\n- Report error with issue number\n- Suggest checking issue number or creating PRD first\n\n**If PRD is closed:**\n- Report that PRD is already closed\n- Suggest reopening if execution is still needed\n\n**If no PRD label:**\n- Warn but allow proceeding (user may have custom workflow)\n\n**If orchestrator delegation fails:**\n- Report the error\n- Suggest manual fallback using ghpm commands\n\n**If user declines confirmation:**\n- Exit gracefully\n- Suggest using manual ghpm commands for step-by-step control\n\n</error_handling>\n\n<success_criteria>\nCommand completes successfully when:\n\n1. PRD is validated and exists\n2. User confirms execution\n3. Orchestrator-agent is successfully delegated via Task tool\n4. Initiation message is displayed to user\n\nThe actual execution success is determined by the orchestrator-agent.\n</success_criteria>\n\n<output>\nAfter delegation, report:\n\n1. **PRD:** #<number> - <title>\n2. **Status:** Orchestrator delegated\n3. **Monitor:** Link to PRD issue for progress updates\n\n**Example Output:**\n\n```\nAutonomous Execution Initiated\n\nPRD: #42 - User Authentication System\nOrchestrator: Delegated via Task tool\nMonitor: https://github.com/owner/repo/issues/42\n\nProgress updates will be posted to the PRD issue.\n```\n\n</output>\n\n<related_commands>\n\n**GHPMplus Commands:**\n- `/ghpmplus:create-prd` - Create a new PRD (prerequisite for auto-execute)\n\n**Manual Workflow (if needed):**\n- `/ghpm:create-epics prd=#N` - Manually create Epics\n- `/ghpm:create-tasks epic=#N` - Manually create Tasks\n- `/ghpm:tdd-task task=#N` - Manually execute Tasks\n\n</related_commands>\n\nNow proceed:\n\n1. Parse arguments to extract PRD number\n2. Validate PRD exists and has appropriate label\n3. Display PRD summary to user\n4. Check for existing Epics\n5. Confirm execution with user\n6. Delegate to orchestrator-agent via Task tool\n7. Report initiation status"
              },
              {
                "name": "/create-prd",
                "description": "Create a PRD GitHub issue (labeled PRD) from user input and optionally add it to a GitHub Project",
                "path": "plugins/ghpmplus/commands/create-prd.md",
                "frontmatter": {
                  "description": "Create a PRD GitHub issue (labeled PRD) from user input and optionally add it to a GitHub Project",
                  "argument-hint": "<product idea or feature description>",
                  "allowed-tools": [
                    "Read",
                    "Bash",
                    "Grep",
                    "AskUserQuestion"
                  ]
                },
                "content": "<objective>\nYou are GHPMplus (GitHub Project Manager Plus). Convert user input into a high-quality Product Requirements Document (PRD) and publish it as a GitHub Issue. This is the first step in the GHPMplus autonomous workflow (PRD -> Epics -> Tasks -> Autonomous Execution).\n</objective>\n\n<prerequisites>\n- `gh` CLI installed and authenticated (`gh auth status`)\n- Working directory is a git repository with GitHub remote\n- User has write access to repository issues\n- Optional: `GHPM_PROJECT` environment variable pre-set (if not set, user will be prompted to select a project)\n- Optional: Repository has \"PRD\" label created\n</prerequisites>\n\n<arguments>\n**Required:**\n- Product idea, feature description, or problem statement (captured from user input via $ARGUMENTS)\n\n**Optional environment variables:**\n\n- `GHPM_PROJECT` - GitHub Project name to associate issue with. If not set, the command will query available projects for the repository owner and prompt for selection.\n</arguments>\n\n<usage_examples>\n\n**Detailed input (skips clarification):**\n\n```\n/ghpmplus:create-prd Build a user authentication system with email/password and OAuth support for enterprise customers who need SSO to reduce IT friction during onboarding\n```\n\n→ Detailed input (30+ words, has who/what/why) → Proceeds directly to PRD generation\n\n**Vague input (triggers clarification):**\n\n```\n/ghpmplus:create-prd Add a dashboard\n```\n\n→ Vague input (4 words, missing who/why/scope) → Presents clarifying questions:\n\n1. Who is the primary user? (Internal team, Customers, Admins, Developers)\n2. What problem does this solve? (Efficiency, Missing capability, UX, Compliance)\n3. What's the scope? (MVP, Feature complete, Production-ready, Enterprise-grade)\n\nAfter user responds → Generates PRD with enriched context\n\n**Complex feature (typically detailed enough):**\n\n```\n/ghpmplus:create-prd Add real-time collaboration features to the document editor, similar to Google Docs, so remote teams can co-edit documents without version conflicts\n```\n\n→ Detailed input → Proceeds directly to PRD generation\n\n**With project association (auto-prompt):**\n\n```\n/ghpmplus:create-prd Implement dark mode across the application for users with visual sensitivities to reduce eye strain\n```\n\n→ If `GHPM_PROJECT` not set, prompts: \"Which GitHub Project should this PRD be added to?\" with available projects\n\n**With project pre-set (skip prompt):**\n\n```bash\nexport GHPM_PROJECT=\"MyOrg/Q1 Roadmap\"\n/ghpmplus:create-prd Implement dark mode across the application for users with visual sensitivities to reduce eye strain\n```\n\n→ Skips project selection prompt and uses pre-set project\n\n</usage_examples>\n\n<operating_rules>\n\n- **For vague input:** Use `AskUserQuestion` tool to gather context before generating the PRD. See `<vagueness_detection>` for criteria.\n- **For detailed input:** Proceed directly to PRD generation. Make reasonable assumptions and explicitly record them under **Assumptions** and **Open Questions**.\n- Do not create or persist local markdown artifacts (no local PRD files). All artifacts must live in GitHub issue bodies/comments.\n- Use Markdown in the issue body. Make the PRD self-contained.\n- Keep scope crisp; if the request is broad, define a \"V1\" and park the rest in **Out of Scope** / **Future Ideas**.\n- Clarification should be quick (max 4 questions) - do not interrogate the user.\n</operating_rules>\n\n<prd_structure>\n\n## Required PRD Structure (Issue Body)\n\nUse this exact outline:\n\n```markdown\n# PRD: <Concise Name>\n\n## Summary\n## Problem / Opportunity\n## Goals (Success Metrics)\n## Non-Goals / Out of Scope\n## Users & Use Cases\n## Requirements\n- Functional Requirements\n- Non-Functional Requirements\n## UX / UI Notes (if relevant)\n## Data / Integrations (if relevant)\n## Risks / Edge Cases\n## Assumptions\n## Open Questions\n## Acceptance Criteria (high level)\n## Rollout / Release Notes (brief)\n## Implementation Notes (non-binding)\n(Keep this section minimal; do not over-prescribe.)\n```\n\n</prd_structure>\n\n<input_validation>\n\n## Validation Checks\n\nBefore proceeding, verify:\n\n```bash\n# 1. Verify gh CLI authentication\ngh auth status || { echo \"ERROR: Not authenticated. Run 'gh auth login'\"; exit 1; }\n\n# 2. Verify in git repository\ngit rev-parse --git-dir > /dev/null 2>&1 || { echo \"ERROR: Not in a git repository\"; exit 1; }\n\n# 3. Verify GitHub remote exists\ngh repo view --json nameWithOwner -q .nameWithOwner || { echo \"ERROR: No GitHub remote found\"; exit 1; }\n```\n\nIf $ARGUMENTS is empty or missing, report an error:\n\n```\nERROR: Product idea or feature description required\nUsage: /ghpmplus:create-prd <description>\n```\n\n</input_validation>\n\n<vagueness_detection>\n\n## Detecting Vague Input\n\nBefore generating the PRD, evaluate whether user input is sufficiently detailed. Input is considered **vague** if ANY of the following criteria are met:\n\n### Vagueness Criteria\n\n| Criterion           | Threshold                           | Example (Vague)           | Example (Detailed)                                                                                                                             |\n| ------------------- | ----------------------------------- | ------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------- |\n| **Too short**       | < 20 words                          | \"I want a dashboard\"      | \"Build an analytics dashboard for sales managers to track quarterly revenue, pipeline metrics, and team performance with drill-down by region\" |\n| **Missing 'who'**   | No target user/audience mentioned   | \"Add authentication\"      | \"Add OAuth2 authentication for enterprise customers who need SSO\"                                                                              |\n| **Missing 'what'**  | No specific functionality described | \"Improve performance\"     | \"Optimize database queries in the user search endpoint to reduce p95 latency below 200ms\"                                                      |\n| **Missing 'why'**   | No problem/goal articulated         | \"Add export feature\"      | \"Add CSV export for compliance reports so auditors can analyze data offline\"                                                                   |\n| **Ambiguous scope** | Could mean vastly different things  | \"Make it mobile-friendly\" | \"Create responsive layouts for the checkout flow that work on screens 320px to 768px wide\"                                                     |\n\n### Evaluation Process\n\n1. Count words in input (excluding common stop words for accuracy assessment)\n2. Scan for user/audience indicators: \"users\", \"customers\", \"admins\", \"managers\", \"developers\", etc.\n3. Scan for problem/goal indicators: \"so that\", \"in order to\", \"because\", \"to enable\", \"to reduce\", etc.\n4. Assess specificity: Does the input contain concrete details (numbers, specific features, constraints)?\n\n**If 2+ criteria are triggered:** Proceed to clarification step\n**If 0-1 criteria triggered:** Skip clarification, proceed directly to PRD generation\n\n</vagueness_detection>\n\n<clarification_questions>\n\n## Clarifying Questions\n\nWhen vague input is detected, use the `AskUserQuestion` tool to gather context. Select 2-4 questions based on what's missing from the input.\n\n### Question Templates\n\n**Q1: Target Users** (use when 'who' is missing)\n\n```json\n{\n  \"question\": \"Who is the primary user of this feature?\",\n  \"header\": \"Users\",\n  \"multiSelect\": false,\n  \"options\": [\n    {\"label\": \"End users/customers\", \"description\": \"People using the product directly\"},\n    {\"label\": \"Internal team members\", \"description\": \"Employees within the organization\"},\n    {\"label\": \"Administrators\", \"description\": \"Users who configure or manage the system\"},\n    {\"label\": \"Developers/API consumers\", \"description\": \"Technical users integrating with the system\"}\n  ]\n}\n```\n\n**Q2: Problem Being Solved** (use when 'why' is missing)\n\n```json\n{\n  \"question\": \"What problem does this solve for users?\",\n  \"header\": \"Problem\",\n  \"multiSelect\": false,\n  \"options\": [\n    {\"label\": \"Efficiency/speed\", \"description\": \"Reduce time or effort to complete tasks\"},\n    {\"label\": \"Missing capability\", \"description\": \"Enable something users currently cannot do\"},\n    {\"label\": \"User experience\", \"description\": \"Improve usability, accessibility, or satisfaction\"},\n    {\"label\": \"Compliance/security\", \"description\": \"Meet regulatory or security requirements\"}\n  ]\n}\n```\n\n**Q3: Core Capabilities** (use when 'what' is vague)\n\n```json\n{\n  \"question\": \"Which capabilities are most important?\",\n  \"header\": \"Features\",\n  \"multiSelect\": true,\n  \"options\": [\n    {\"label\": \"View/display data\", \"description\": \"Read-only access to information\"},\n    {\"label\": \"Create/edit content\", \"description\": \"CRUD operations on data\"},\n    {\"label\": \"Automation/workflows\", \"description\": \"Automated processes or triggers\"},\n    {\"label\": \"Reporting/analytics\", \"description\": \"Insights, charts, or exports\"}\n  ]\n}\n```\n\n**Q4: Technical Constraints** (use when scope is ambiguous)\n\n```json\n{\n  \"question\": \"Are there specific technical constraints?\",\n  \"header\": \"Constraints\",\n  \"multiSelect\": true,\n  \"options\": [\n    {\"label\": \"Must integrate with existing system\", \"description\": \"Needs to work with current infrastructure\"},\n    {\"label\": \"Performance-critical\", \"description\": \"High throughput or low latency required\"},\n    {\"label\": \"Mobile support required\", \"description\": \"Must work on mobile devices\"},\n    {\"label\": \"No constraints\", \"description\": \"Greenfield implementation\"}\n  ]\n}\n```\n\n**Q5: Scope/Priority** (use when input could mean many things)\n\n```json\n{\n  \"question\": \"What's the scope for the initial version?\",\n  \"header\": \"Scope\",\n  \"multiSelect\": false,\n  \"options\": [\n    {\"label\": \"MVP/proof of concept\", \"description\": \"Minimal viable version to validate the idea\"},\n    {\"label\": \"Feature complete for core use case\", \"description\": \"Fully functional for primary scenario\"},\n    {\"label\": \"Production-ready with edge cases\", \"description\": \"Robust handling of all scenarios\"},\n    {\"label\": \"Enterprise-grade\", \"description\": \"Scalability, security, and compliance built-in\"}\n  ]\n}\n```\n\n### Selecting Questions\n\nBased on vagueness detection results, select appropriate questions:\n\n| Missing Element  | Questions to Ask                                |\n| ---------------- | ----------------------------------------------- |\n| Who (users)      | Q1 (Target Users)                               |\n| Why (problem)    | Q2 (Problem Being Solved)                       |\n| What (features)  | Q3 (Core Capabilities)                          |\n| Scope unclear    | Q4 (Technical Constraints), Q5 (Scope/Priority) |\n| Multiple missing | Combine up to 4 questions maximum               |\n\n### Incorporating Responses\n\nAfter receiving user responses, append them to the original input before generating the PRD:\n\n```\nOriginal input: \"I want a dashboard\"\n\nEnriched context from clarification:\n- Target users: Internal team members\n- Problem: Efficiency/speed - reduce time to complete tasks\n- Capabilities: Reporting/analytics, View/display data\n- Scope: Feature complete for core use case\n\nGenerate PRD using both original input AND enriched context.\n```\n\n</clarification_questions>\n\n<workflow>\n## Step 1: Validate Environment\n\nRun input validation checks from previous section.\n\n## Step 2: Determine Repository and Owner\n\n```bash\nREPO=$(gh repo view --json nameWithOwner -q .nameWithOwner)\nOWNER=$(gh repo view --json owner -q .owner.login)\n```\n\n## Step 3: Select GitHub Project (if not pre-set)\n\nIf `GHPM_PROJECT` environment variable is already set, skip to Step 4.\n\nOtherwise, query available projects for the repository owner and prompt the user to select one:\n\n```bash\n# Get list of projects for the repo owner\nPROJECTS=$(gh project list --owner \"$OWNER\" --format json --limit 20)\n```\n\n**If projects exist:** Use `AskUserQuestion` to let the user select a project.\n\nBuild the question dynamically based on available projects:\n\n```json\n{\n  \"question\": \"Which GitHub Project should this PRD be added to?\",\n  \"header\": \"Project\",\n  \"multiSelect\": false,\n  \"options\": [\n    {\"label\": \"<Project Title 1>\", \"description\": \"Project #<number>\"},\n    {\"label\": \"<Project Title 2>\", \"description\": \"Project #<number>\"},\n    ...\n    {\"label\": \"None\", \"description\": \"Do not add to any project\"}\n  ]\n}\n```\n\n- Include up to 4 projects (the most recently updated, or first 4 returned)\n- Always include \"None\" as the last option\n- If user selects a project, set `GHPM_PROJECT` to the selected project title\n- If user selects \"None\", leave `GHPM_PROJECT` unset\n\n**If no projects exist:** Skip project selection and inform the user:\n\n```\nNo GitHub Projects found for owner '$OWNER'. Skipping project association.\nTo create a project, visit: https://github.com/<owner>?tab=projects\n```\n\n## Step 4: Evaluate Input & Clarify (if needed)\n\nEvaluate user input against the vagueness criteria in `<vagueness_detection>`.\n\n**If input is sufficiently detailed (0-1 criteria triggered):**\n\n- Skip to Step 5 (Draft PRD Content)\n\n**If input is vague (2+ criteria triggered):**\n\n1. Identify which elements are missing (who, what, why, scope)\n2. Select appropriate questions from `<clarification_questions>` (max 4)\n3. Use `AskUserQuestion` tool to present questions:\n\n```\nUse the AskUserQuestion tool with the selected question templates.\nWait for user responses before proceeding.\n```\n\n1. Combine original input with user responses to form enriched context\n2. Proceed to Step 5 with enriched context\n\n**Example clarification flow:**\n\nInput: \"I want a dashboard\"\n\nVagueness analysis:\n\n- ✗ Too short (4 words < 20)\n- ✗ Missing 'who' (no user mentioned)\n- ✗ Missing 'why' (no problem stated)\n- ✓ Has 'what' (dashboard is a feature)\n- ✗ Ambiguous scope (dashboard could mean many things)\n\n→ 4 criteria triggered → Ask Q1 (Users), Q2 (Problem), Q5 (Scope)\n\n## Step 5: Draft PRD Content\n\nBased on user input ($ARGUMENTS) and any enriched context from clarification, generate comprehensive PRD following the structure template.\n\n## Step 6: Create GitHub Issue\n\n```bash\n# Use heredoc to safely handle multiline content\ngh issue create \\\n  --repo \"$REPO\" \\\n  --title \"PRD: <Concise Name>\" \\\n  --label \"PRD\" \\\n  --body \"$(cat <<'EOF'\n<Generated PRD Content>\nEOF\n)\"\n```\n\n## Step 7: Add to GitHub Project\n\nUse the new GitHub Projects API (`gh project item-add`) instead of the deprecated `--add-project` flag.\n\n```bash\nif [ -n \"$GHPM_PROJECT\" ]; then\n  # Get the issue URL (needed for gh project item-add)\n  ISSUE_URL=$(gh issue list --repo \"$REPO\" -l PRD --limit 1 --json url -q '.[0].url')\n\n  # Get project number from the project list\n  # GHPM_PROJECT can be either the project title or number\n  if [[ \"$GHPM_PROJECT\" =~ ^[0-9]+$ ]]; then\n    PROJECT_NUMBER=\"$GHPM_PROJECT\"\n  else\n    # Look up project number by title\n    PROJECT_NUMBER=$(gh project list --owner \"$OWNER\" --format json | \\\n      jq -r --arg title \"$GHPM_PROJECT\" '.projects[] | select(.title == $title) | .number')\n  fi\n\n  if [ -n \"$PROJECT_NUMBER\" ]; then\n    gh project item-add \"$PROJECT_NUMBER\" --owner \"$OWNER\" --url \"$ISSUE_URL\" 2>/dev/null || {\n      echo \"WARNING: Failed to add issue to project '$GHPM_PROJECT'\"\n      ISSUE_NUMBER=$(echo \"$ISSUE_URL\" | grep -oE '[0-9]+$')\n      gh issue comment \"$ISSUE_NUMBER\" --body \"Note: Could not automatically add to project '$GHPM_PROJECT'. Please add manually if needed.\"\n    }\n  else\n    echo \"WARNING: Could not find project '$GHPM_PROJECT'\"\n  fi\nfi\n```\n\n**Note:** The `gh project item-add` command requires:\n- Project number (not title) - we look this up from the project list\n- Owner (user or organization)\n- Issue URL (not issue number)\n\n</workflow>\n\n<error_handling>\n**If gh CLI not authenticated:**\n\n- Check: `gh auth status`\n- Fix: `gh auth login`\n\n**If not in git repository:**\n\n- Navigate to repository directory\n- Verify with: `git status`\n\n**If no GitHub remote:**\n\n- Check remote: `git remote -v`\n- Add remote if needed: `git remote add origin <url>`\n\n**If label \"PRD\" doesn't exist:**\n\n- Create it: `gh label create PRD --description \"Product Requirements Document\" --color 0E8A16`\n- Or omit `--label \"PRD\"` from issue creation and continue\n\n**If issue creation fails:**\n\n- Check rate limits: `gh api rate_limit`\n- Verify write permissions: `gh repo view --json viewerPermission -q .viewerPermission`\n- Check repository exists and is accessible\n\n**If project association fails:**\n\n- Verify `GHPM_PROJECT` is either the project number or exact title\n- Check project exists: `gh project list --owner <OWNER>`\n- Ensure the new Projects API is used (`gh project item-add`), not the deprecated `--add-project` flag\n- Common error: \"Projects (classic) is being deprecated\" means you're using the old API\n- Command will continue and add warning comment to issue\n</error_handling>\n\n<success_criteria>\nCommand completes successfully when:\n\n1. PRD issue is created with \"PRD\" label\n2. Issue body contains all required sections from PRD structure\n3. Issue number and URL are captured\n4. If `GHPM_PROJECT` set, issue is added to project (or warning issued)\n\n**Verification:**\n\n```bash\n# View the created PRD\ngh issue view <issue_number>\n\n# List all PRD issues\ngh issue list -l PRD --json number,title,url\n```\n\n</success_criteria>\n\n<output>\nAfter completion, report:\n\n1. **PRD Issue:** #<number> - <URL>\n2. **Repository:** <owner>/<repo>\n3. **Project Association:**\n   - Success: \"Added to project '<GHPM_PROJECT>'\"\n   - Failure: \"WARNING: Could not add to project (see issue comment)\"\n   - N/A: \"No project specified\"\n4. **Next Step:** \"Run `/ghpmplus:auto-execute prd=#<number>` to autonomously execute this PRD\"\n\n**Example Output:**\n\n```\nPRD Created Successfully\n\nPRD Issue: #42 - https://github.com/owner/repo/issues/42\nRepository: owner/repo\nProject Association: Added to project 'Q1 Roadmap'\n\nNext Step: Run `/ghpmplus:auto-execute prd=#42` to autonomously execute this PRD\n```\n\n</output>\n\n<related_commands>\n**GHPMplus Workflow:**\n\n1. **Current:** `/ghpmplus:create-prd` - Create PRD from user input\n2. **Next:** `/ghpmplus:auto-execute prd=#N` - Trigger orchestrator for autonomous execution\n\nThe orchestrator agent will automatically:\n- Break PRD into Epics\n- Break Epics into Tasks\n- Execute Tasks via TDD or Non-TDD workflows (depending on commit type)\n- Create PRs and manage CI verification\n\n**Manual workflow (if needed):**\n\n- Use original ghpm commands for step-by-step control:\n  - `/ghpm:create-epics prd=#N`\n  - `/ghpm:create-tasks epic=#N`\n  - `/ghpm:tdd-task task=#N`\n</related_commands>\n\nNow proceed:\n\n1. Validate environment prerequisites.\n2. Determine repository and owner.\n3. If `GHPM_PROJECT` not set: Query projects for owner and prompt user to select one.\n4. Evaluate input against vagueness criteria.\n5. If vague (2+ criteria triggered): Use AskUserQuestion to gather context.\n6. Draft the PRD from $ARGUMENTS (and enriched context if clarified).\n7. Create the issue via `gh issue create`.\n8. Add it to the GitHub project if `GHPM_PROJECT` is set."
              }
            ],
            "skills": []
          },
          {
            "name": "js-ts",
            "description": "JavaScript and TypeScript development toolkit with ESLint, Vitest, and unit testing best practices",
            "source": "./plugins/js-ts",
            "category": null,
            "version": "0.1.0",
            "author": {
              "name": "Jeb Coleman"
            },
            "install_commands": [
              "/plugin marketplace add el-feo/ai-context",
              "/plugin install js-ts@jebs-dev-tools"
            ],
            "signals": {
              "stars": 0,
              "forks": 0,
              "pushed_at": "2026-01-12T05:23:19Z",
              "created_at": "2025-03-11T20:00:10Z",
              "license": "MIT"
            },
            "commands": [
              {
                "name": "/vitest",
                "description": "Migrate from Jest to Vitest or set up Vitest testing framework",
                "path": "plugins/js-ts/commands/vitest.md",
                "frontmatter": {
                  "description": "Migrate from Jest to Vitest or set up Vitest testing framework",
                  "argument-hint": [
                    "task or question about Vitest/Jest migration"
                  ],
                  "allowed-tools": "Skill(vitest)"
                },
                "content": "<objective>\nDelegate Vitest testing and Jest migration tasks to the vitest skill for: $ARGUMENTS\n\nThis routes to specialized skill containing migration tools, configuration patterns, and troubleshooting guides.\n</objective>\n\n<process>\n1. Use Skill tool to invoke vitest skill\n2. Pass user's request: $ARGUMENTS\n3. Let skill handle workflow\n</process>\n\n<success_criteria>\n- Skill successfully invoked\n- Arguments passed correctly to skill\n</success_criteria>"
              }
            ],
            "skills": [
              {
                "name": "eslint",
                "description": "Comprehensive ESLint agent for JavaScript/TypeScript code quality. Use when setting up ESLint, configuring linting rules, analyzing code for issues, fixing violations, or integrating ESLint into development workflows. Triggers on requests involving code quality, linting, static analysis, or ESLint configuration for JavaScript, TypeScript, React, or Node.js projects.",
                "path": "plugins/js-ts/skills/eslint/SKILL.md",
                "frontmatter": {
                  "name": "eslint",
                  "description": "Comprehensive ESLint agent for JavaScript/TypeScript code quality. Use when setting up ESLint, configuring linting rules, analyzing code for issues, fixing violations, or integrating ESLint into development workflows. Triggers on requests involving code quality, linting, static analysis, or ESLint configuration for JavaScript, TypeScript, React, or Node.js projects."
                },
                "content": "# ESLint Agent\n\n## Overview\n\nESLint is a pluggable and configurable linter tool for identifying and reporting on patterns in JavaScript and TypeScript code. This skill enables Claude to help you set up, configure, and effectively use ESLint to maintain code quality across your projects.\n\n## Quick Start\n\n### Prerequisites\n\n- Node.js (^18.18.0, ^20.9.0, or >=21.1.0) with SSL support\n- Existing `package.json` file (run `npm init` if needed)\n\n### Installation & Setup\n\n**Automated Setup (Recommended):**\n\n```bash\nnpm init @eslint/config@latest\n```\n\nThis interactive setup will ask about your project and create an `eslint.config.js` file.\n\n**Manual Setup:**\n\n```bash\n# Install ESLint packages\nnpm install --save-dev eslint@latest @eslint/js@latest\n\n# Create configuration file\ntouch eslint.config.js\n```\n\n### Basic Configuration\n\nThe new flat config format (ESLint 9.0+) uses `eslint.config.js`:\n\n```javascript\nimport { defineConfig } from \"eslint/config\";\nimport js from \"@eslint/js\";\n\nexport default defineConfig([\n  {\n    files: [\"**/*.js\"],\n    plugins: { js },\n    extends: [\"js/recommended\"],\n    rules: {\n      \"no-unused-vars\": \"warn\",\n      \"no-undef\": \"warn\"\n    }\n  }\n]);\n```\n\n### Running ESLint\n\n```bash\n# Lint a single file\nnpx eslint yourfile.js\n\n# Lint a directory\nnpx eslint src/\n\n# Lint with auto-fix\nnpx eslint src/ --fix\n```\n\n## Core ESLint Tasks\n\n### 1. Setting Up ESLint\n\n#### For JavaScript Projects\n\n```bash\nnpm init @eslint/config@latest\n```\n\nSelect options:\n\n- How would you like to use ESLint? → **To check syntax, find problems, and enforce code style**\n- What type of modules? → **JavaScript modules (import/export)**\n- Which framework? → **None/React/Vue** (as applicable)\n- Does your project use TypeScript? → **No**\n- Where does your code run? → **Browser** and/or **Node**\n- Config file format → **JavaScript/JSON/YAML** (JavaScript recommended)\n\n#### For TypeScript Projects\n\n```bash\nnpm install --save-dev eslint@latest @typescript-eslint/parser @typescript-eslint/eslint-plugin typescript-eslint\n```\n\nConfiguration for TypeScript:\n\n```javascript\nimport { defineConfig } from 'eslint/config';\nimport eslint from '@eslint/js';\nimport tseslint from 'typescript-eslint';\n\nexport default defineConfig(\n  eslint.configs.recommended,\n  ...tseslint.configs.recommended\n);\n```\n\n#### For React + TypeScript\n\n```bash\nnpm install --save-dev \\\n  eslint \\\n  @typescript-eslint/parser \\\n  @typescript-eslint/eslint-plugin \\\n  eslint-plugin-react \\\n  eslint-plugin-react-hooks \\\n  eslint-plugin-jsx-a11y \\\n  typescript-eslint\n```\n\n### 2. Configuring Rules\n\n#### Rule Severity Levels\n\n- `\"off\"` or `0` - Disable the rule\n- `\"warn\"` or `1` - Warning (doesn't affect exit code)\n- `\"error\"` or `2` - Error (exit code will be 1)\n\n#### Common Rule Configurations\n\n**Basic Rules:**\n\n```javascript\nexport default defineConfig([\n  {\n    rules: {\n      // Enforce semicolons\n      \"semi\": [\"error\", \"always\"],\n\n      // Enforce const where possible\n      \"prefer-const\": \"error\",\n\n      // Warn on unused variables\n      \"no-unused-vars\": \"warn\",\n\n      // No console.log in production\n      \"no-console\": [\"error\", { allow: [\"warn\", \"error\"] }],\n\n      // Enforce consistent quotes\n      \"quotes\": [\"error\", \"single\"],\n\n      // Require === instead of ==\n      \"eqeqeq\": [\"error\", \"always\"]\n    }\n  }\n]);\n```\n\n**TypeScript-Specific Rules:**\n\n```javascript\nexport default defineConfig([\n  {\n    files: [\"**/*.ts\", \"**/*.tsx\"],\n    rules: {\n      \"@typescript-eslint/no-explicit-any\": \"warn\",\n      \"@typescript-eslint/explicit-function-return-type\": [\"error\", {\n        allowExpressions: true\n      }],\n      \"@typescript-eslint/naming-convention\": [\"error\", {\n        selector: \"interface\",\n        format: [\"PascalCase\"],\n        custom: {\n          regex: \"^I[A-Z]\",\n          match: false\n        }\n      }]\n    }\n  }\n]);\n```\n\n#### Configuration Comments\n\nDisable rules inline:\n\n```javascript\n/* eslint-disable no-console */\nconsole.log('This is allowed');\n/* eslint-enable no-console */\n\n// Disable for single line\nconsole.log('Debug'); // eslint-disable-line no-console\n\n// Disable next line\n// eslint-disable-next-line no-console\nconsole.log('Debug');\n\n// Disable specific rules\nalert('foo'); // eslint-disable-line no-alert, no-undef\n```\n\n**Best Practices for Inline Disables:**\n\n1. Use sparingly with clear justification\n2. Document the reason:\n\n   ```javascript\n   // eslint-disable-next-line no-console -- Debugging production issue #1234\n   console.log('User data:', userData);\n   ```\n\n3. Prefer configuration file changes over inline disables\n4. Create follow-up tasks for temporary disables\n\n### 3. File Patterns and Ignores\n\n#### Specifying Files to Lint\n\n```javascript\nexport default defineConfig([\n  {\n    // Only lint TypeScript files in src/\n    files: [\"src/**/*.ts\", \"src/**/*.tsx\"],\n\n    // Ignore test files for certain rules\n    ignores: [\"**/*.test.ts\", \"**/*.spec.ts\"]\n  }\n]);\n```\n\n#### Global Ignores\n\n```javascript\nexport default defineConfig([\n  {\n    ignores: [\n      \"**/node_modules/**\",\n      \"**/dist/**\",\n      \"**/build/**\",\n      \"**/.next/**\",\n      \"**/coverage/**\"\n    ]\n  },\n  // ... rest of config\n]);\n```\n\n### 4. Using Shared Configurations\n\nESLint supports extending from popular configurations:\n\n```javascript\nimport { defineConfig } from \"eslint/config\";\nimport js from \"@eslint/js\";\nimport globals from \"globals\";\n\nexport default defineConfig([\n  js.configs.recommended, // ESLint recommended rules\n  {\n    languageOptions: {\n      globals: {\n        ...globals.browser,\n        ...globals.node\n      }\n    }\n  }\n]);\n```\n\n**Popular Shared Configs:**\n\n- `eslint:recommended` - ESLint's recommended rules\n- `@typescript-eslint/recommended` - TypeScript recommended\n- `@typescript-eslint/strict` - Stricter TypeScript rules\n- `plugin:react/recommended` - React best practices\n- `plugin:react-hooks/recommended` - React Hooks rules\n\n### 5. Auto-Fixing Issues\n\nESLint can automatically fix many issues:\n\n```bash\n# Fix all auto-fixable issues\nnpx eslint src/ --fix\n\n# Show what would be fixed (dry run)\nnpx eslint src/ --fix-dry-run\n```\n\n**Auto-fixable rules include:**\n\n- Formatting issues (spacing, semicolons, quotes)\n- Simple code transformations (prefer-const, arrow functions)\n- Import sorting\n\n**Non-fixable issues** require manual intervention:\n\n- Logic errors (no-unused-vars with actual usage)\n- Complex refactoring needs\n\n## Common Project Scenarios\n\n### React + TypeScript Project\n\n**Complete Configuration:**\n\n```javascript\nimport { defineConfig } from 'eslint/config';\nimport js from '@eslint/js';\nimport globals from 'globals';\nimport reactHooks from 'eslint-plugin-react-hooks';\nimport reactRefresh from 'eslint-plugin-react-refresh';\nimport tseslint from 'typescript-eslint';\n\nexport default defineConfig([\n  { ignores: ['dist'] },\n  js.configs.recommended,\n  ...tseslint.configs.recommended,\n  {\n    files: ['**/*.{ts,tsx}'],\n    languageOptions: {\n      ecmaVersion: 2020,\n      globals: globals.browser,\n      parserOptions: {\n        project: './tsconfig.json'\n      }\n    },\n    plugins: {\n      'react-hooks': reactHooks,\n      'react-refresh': reactRefresh\n    },\n    rules: {\n      ...reactHooks.configs.recommended.rules,\n      'react-refresh/only-export-components': [\n        'warn',\n        { allowConstantExport: true }\n      ],\n      '@typescript-eslint/no-unused-vars': ['error', {\n        argsIgnorePattern: '^_',\n        varsIgnorePattern: '^_'\n      }]\n    }\n  }\n]);\n```\n\n### Node.js + TypeScript Project\n\n```javascript\nimport { defineConfig } from 'eslint/config';\nimport eslint from '@eslint/js';\nimport tseslint from 'typescript-eslint';\nimport globals from 'globals';\n\nexport default defineConfig([\n  eslint.configs.recommended,\n  ...tseslint.configs.recommended,\n  {\n    files: ['**/*.ts'],\n    languageOptions: {\n      globals: globals.node\n    },\n    rules: {\n      '@typescript-eslint/no-explicit-any': 'warn',\n      'no-console': 'off' // Console is fine in Node.js\n    }\n  }\n]);\n```\n\n### Monorepo Configuration\n\n```javascript\nexport default defineConfig([\n  // Global ignores\n  { ignores: ['**/dist/**', '**/build/**'] },\n\n  // Frontend package\n  {\n    files: ['packages/frontend/**/*.{ts,tsx}'],\n    languageOptions: {\n      globals: globals.browser\n    },\n    // Frontend-specific rules\n  },\n\n  // Backend package\n  {\n    files: ['packages/backend/**/*.ts'],\n    languageOptions: {\n      globals: globals.node\n    },\n    // Backend-specific rules\n  }\n]);\n```\n\n## Integration with Development Tools\n\n### VS Code Integration\n\n**Install Extension:**\n\n- ESLint extension by Microsoft (dbaeumer.vscode-eslint)\n\n**Workspace Settings (`.vscode/settings.json`):**\n\n```json\n{\n  \"editor.defaultFormatter\": \"dbaeumer.vscode-eslint\",\n  \"editor.formatOnSave\": true,\n  \"editor.codeActionsOnSave\": {\n    \"source.fixAll.eslint\": \"explicit\"\n  },\n  \"eslint.validate\": [\n    \"javascript\",\n    \"javascriptreact\",\n    \"typescript\",\n    \"typescriptreact\"\n  ]\n}\n```\n\n### CI/CD Integration\n\n**GitHub Actions:**\n\n```yaml\nname: ESLint\n\non: [push, pull_request]\n\njobs:\n  lint:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n      - uses: actions/setup-node@v3\n        with:\n          node-version: '20'\n      - run: npm ci\n      - run: npx eslint .\n```\n\n**Pre-commit Hook (with Husky):**\n\n```bash\nnpm install --save-dev husky lint-staged\n\n# Add to package.json\n{\n  \"lint-staged\": {\n    \"*.{js,jsx,ts,tsx}\": [\"eslint --fix\", \"git add\"]\n  }\n}\n```\n\n### Package.json Scripts\n\n```json\n{\n  \"scripts\": {\n    \"lint\": \"eslint .\",\n    \"lint:fix\": \"eslint . --fix\",\n    \"lint:staged\": \"lint-staged\"\n  }\n}\n```\n\n## Troubleshooting\n\n### Common Issues\n\n**\"Cannot find module 'eslint/config'\"**\n\n- Update to ESLint 9.0+: `npm install eslint@latest`\n\n**\"Parsing error: Cannot find module '@typescript-eslint/parser'\"**\n\n- Install parser: `npm install --save-dev @typescript-eslint/parser`\n\n**Rules not being applied**\n\n- Check file patterns match your source files\n- Verify config file is named correctly (`eslint.config.js`)\n- Ensure config is in project root\n\n**Slow linting in large projects**\n\n- Add appropriate ignores for node_modules, dist, build folders\n- Use `--cache` flag: `npx eslint --cache .`\n- Consider using `--max-warnings 0` to fail on warnings in CI\n\n## Advanced Topics\n\n### Creating Custom Rules\n\nFor project-specific patterns, see `references/custom_rules.md`.\n\n### TypeScript Type-Aware Linting\n\nFor advanced TypeScript checks requiring type information, see `references/type_aware_linting.md`.\n\n### Migration from ESLint 8.x\n\nFor projects using the legacy `.eslintrc.*` format, see `references/migration_guide.md`.\n\n## Resources\n\n### references/\n\n- `custom_rules.md` - Guide to creating custom ESLint rules\n- `type_aware_linting.md` - TypeScript type-aware linting configuration\n- `migration_guide.md` - Migrating from ESLint 8.x to 9.x flat config\n- `rule_reference.md` - Comprehensive rule reference with examples\n\n### assets/\n\n- `eslint.config.js` - Complete example configuration for various project types\n- `.eslintignore` - Example ignore file patterns"
              },
              {
                "name": "javascript-unit-testing",
                "description": "Writing high-quality unit tests for JavaScript and TypeScript using Jest. Covers test structure (AAA pattern, USE naming), breaking dependencies (stubs, mocks, dependency injection), testing async code (promises, callbacks, timers), avoiding flaky tests, and test-driven development. Use when writing tests, debugging test failures, refactoring tests for maintainability, or questions about Jest, TDD, mocks, stubs, or test best practices.",
                "path": "plugins/js-ts/skills/javascript-unit-testing/SKILL.md",
                "frontmatter": {
                  "name": "javascript-unit-testing",
                  "description": "Writing high-quality unit tests for JavaScript and TypeScript using Jest. Covers test structure (AAA pattern, USE naming), breaking dependencies (stubs, mocks, dependency injection), testing async code (promises, callbacks, timers), avoiding flaky tests, and test-driven development. Use when writing tests, debugging test failures, refactoring tests for maintainability, or questions about Jest, TDD, mocks, stubs, or test best practices."
                },
                "content": "# JavaScript Unit Testing\n\nExpert guidance for writing maintainable, trustworthy unit tests in JavaScript and TypeScript using Jest. Based on \"The Art of Unit Testing, Third Edition\" by Roy Osherove with Vladimir Khorikov (Manning, 2024).\n\n## Instructions\n\nWhen helping users with unit testing:\n\n1. **Understand the context**: Identify if they're writing new tests, fixing existing ones, or learning concepts\n2. **Apply core principles**: Focus on readability, maintainability, and trust in tests\n3. **Use appropriate patterns**: Select the right testing pattern based on exit point type (return value, state change, or third-party call)\n4. **Provide examples**: Show concrete code examples following best practices\n5. **Reference supporting documentation**: Point to [REFERENCE.md](REFERENCE.md) for detailed concepts and [EXAMPLES.md](EXAMPLES.md) for more code samples\n\n## Core Concepts\n\n### Unit of Work\n\nA **unit of work** is all actions between an **entry point** (function/method we trigger) and one or more **exit points** (observable results).\n\n**Three types of exit points:**\n\n1. **Return value** - Function returns a useful value\n2. **State change** - Observable change in system state\n3. **Third-party call** - Calling external dependency (logger, database, API)\n\n### Good Unit Test Properties\n\n**Must have:**\n\n- Fast execution (milliseconds)\n- Fully isolated from other tests\n- Consistent results (no flakiness)\n- Runs in memory (no filesystem, network, database)\n- Clear intent and easy to read\n\n**Avoid:**\n\n- Logic in tests (if/else, loops, try/catch)\n- Multiple concerns per test\n- Shared state between tests\n- Testing implementation details vs behavior\n\n## Quick Start: Writing Your First Test\n\n### Basic Test Structure (AAA Pattern)\n\n```javascript\ntest('sum with two numbers returns their sum', () => {\n  // Arrange - set up test data\n  const input = '1,2';\n\n  // Act - call the unit of work\n  const result = sum(input);\n\n  // Assert - verify the outcome\n  expect(result).toBe(3);\n});\n```\n\n### Test Naming (USE Pattern)\n\nFormat: **[U]**nit, **[S]**cenario, **[E]**xpectation\n\n```javascript\n// Good examples\ntest('sum, with two valid numbers, returns their sum', () => { ... });\ntest('verify, with no uppercase letter, returns false', () => { ... });\ntest('save, during maintenance window, throws exception', () => { ... });\n```\n\n### Organizing Tests\n\n```javascript\ndescribe('Password Verifier', () => {\n  describe('one uppercase rule', () => {\n    test('given no uppercase, returns false', () => {\n      const verifier = makeVerifier([oneUpperCaseRule]);\n      expect(verifier.verify('abc')).toBe(false);\n    });\n\n    test('given one uppercase, returns true', () => {\n      const verifier = makeVerifier([oneUpperCaseRule]);\n      expect(verifier.verify('Abc')).toBe(true);\n    });\n  });\n});\n```\n\n**Use factory methods instead of beforeEach()** to avoid scroll fatigue and keep tests self-contained.\n\n## Testing Different Exit Points\n\n### Return Value Testing (Easiest)\n\n```javascript\ntest('processes input and returns result', () => {\n  const result = calculateTotal([10, 20, 30]);\n  expect(result).toBe(60);\n});\n```\n\n### State-Based Testing\n\n```javascript\ntest('adds item to cart and updates count', () => {\n  const cart = new ShoppingCart();\n\n  cart.addItem('apple');\n\n  expect(cart.itemCount()).toBe(1);\n  expect(cart.contains('apple')).toBe(true);\n});\n```\n\n### Interaction Testing (Use Sparingly)\n\nOnly for testing third-party calls (exit points):\n\n```javascript\ntest('save calls logger with correct message', () => {\n  const mockLogger = { info: jest.fn() };\n  const repository = new Repository(mockLogger);\n\n  repository.save({ id: 1, name: 'test' });\n\n  expect(mockLogger.info).toHaveBeenCalledWith('Saved item 1');\n});\n```\n\n**Important**: Use mocks only for exit points. Have **one mock per test maximum**. Most tests (95%+) should be return-value or state-based.\n\n## Breaking Dependencies\n\n### When to Break Dependencies\n\nBreak dependencies when code relies on:\n\n- Time (Date.now(), moment())\n- Random values (Math.random())\n- Network calls (fetch, axios)\n- Filesystem (fs.readFile)\n- Databases\n- External services\n\n### Dependency Injection Patterns\n\n**1. Parameter Injection (Simplest)**\n\n```javascript\n// Before - time dependency baked in\nconst verify = (input) => {\n  const day = moment().day(); // Hard to test!\n  if (day === 0 || day === 6) throw Error(\"Weekend!\");\n};\n\n// After - time injected\nconst verify = (input, currentDay) => {\n  if (currentDay === 0 || currentDay === 6) throw Error(\"Weekend!\");\n};\n\n// Test with full control\ntest('on weekends, throws exception', () => {\n  expect(() => verify('input', 0)).toThrow(\"Weekend!\");\n});\n```\n\n**2. Functional Injection**\n\n```javascript\nconst verify = (logger) => (input) => {\n  logger.info('Verifying');\n  return input.length > 5;\n};\n\n// Test\ntest('verify logs attempt', () => {\n  const stubLogger = { info: jest.fn() };\n  const verifyFn = verify(stubLogger);\n  verifyFn('password');\n});\n```\n\n**3. Constructor Injection (OOP)**\n\n```typescript\nclass Verifier {\n  constructor(private logger: ILogger) {}\n\n  verify(input: string): boolean {\n    this.logger.info('Verifying');\n    return true;\n  }\n}\n\n// Test\ntest('verify calls logger', () => {\n  const mockLogger = { info: jest.fn() };\n  const verifier = new Verifier(mockLogger);\n  verifier.verify('input');\n  expect(mockLogger.info).toHaveBeenCalled();\n});\n```\n\n### Stubs vs Mocks\n\n**Stubs** (incoming dependencies):\n\n- Provide fake data/behavior INTO the unit\n- Do NOT assert against them\n- Can have many per test\n\n**Mocks** (outgoing dependencies):\n\n- Represent exit points\n- DO assert they were called correctly\n- Should have ONE per test\n\n```javascript\n// Stub - provides data IN\nconst stubDatabase = {\n  getUser: () => ({ id: 1, name: 'John' })\n};\n\n// Mock - verifies calls OUT\nconst mockLogger = {\n  info: jest.fn()\n};\n\ntest('getUserName retrieves name from database and logs', () => {\n  const service = new UserService(stubDatabase, mockLogger);\n\n  const name = service.getUserName(1);\n\n  expect(name).toBe('John'); // Return value assertion\n  expect(mockLogger.info).toHaveBeenCalledWith('Retrieved user 1'); // Mock assertion\n});\n```\n\n## Testing Asynchronous Code\n\n### Extract Entry Point Pattern\n\nExtract pure logic from async operations:\n\n```javascript\n// Before - everything mixed\nconst isWebsiteAlive = async () => {\n  const resp = await fetch('http://example.com');\n  if (!resp.ok) throw resp.statusText;\n  const text = await resp.text();\n  return text.includes('illustrative')\n    ? { success: true }\n    : { success: false, status: 'missing text' };\n};\n\n// After - extract testable logic\nconst processFetchContent = (text) => {\n  return text.includes('illustrative')\n    ? { success: true }\n    : { success: false, status: 'missing text' };\n};\n\n// Fast, synchronous unit test\ntest('with good content, returns success', () => {\n  const result = processFetchContent('illustrative');\n  expect(result.success).toBe(true);\n});\n```\n\n### Extract Adapter Pattern\n\nWrap async dependencies behind testable interfaces:\n\n```javascript\n// network-adapter.js - wrapper for fetch\nconst fetchUrlText = async (url) => {\n  const resp = await fetch(url);\n  return resp.ok\n    ? { ok: true, text: await resp.text() }\n    : { ok: false, text: resp.statusText };\n};\n\n// website-verifier.js - inject adapter\nconst isWebsiteAlive = async (network) => {\n  const result = await network.fetchUrlText('http://example.com');\n  if (!result.ok) throw result.text;\n  return result.text.includes('illustrative');\n};\n\n// Test with fake adapter (synchronous!)\ntest('with good content, returns true', async () => {\n  const fakeNetwork = {\n    fetchUrlText: () => ({ ok: true, text: 'illustrative' })\n  };\n  const result = await isWebsiteAlive(fakeNetwork);\n  expect(result).toBe(true);\n});\n```\n\n### Testing Timers\n\n```javascript\ntest('calls callback after delay', () => {\n  jest.useFakeTimers();\n  const callback = jest.fn();\n\n  delayedGreeting(callback);\n\n  expect(callback).not.toHaveBeenCalled();\n  jest.advanceTimersByTime(1000);\n  expect(callback).toHaveBeenCalledWith('hello');\n\n  jest.useRealTimers();\n});\n```\n\n## Common Antipatterns to Avoid\n\n1. **Logic in tests** - No if/else, loops, or try/catch\n2. **Multiple mocks per test** - One exit point per test\n3. **Asserting against stubs** - Only assert against mocks\n4. **beforeEach() overuse** - Use factory methods instead\n5. **Testing private methods** - Test through public API\n6. **Overspecification** - Don't test implementation details\n7. **Flaky tests** - Inject all dependencies for consistency\n8. **Shared state** - Keep tests fully isolated\n9. **Integration tests as unit tests** - Use real dependencies sparingly\n10. **No test naming convention** - Follow USE pattern\n\n## Test Quality Checklist\n\nCan you answer YES to all these?\n\n- ✓ Tests run in under a few minutes (ideally seconds)?\n- ✓ Any team member can run tests on any machine?\n- ✓ Tests give same results every time (no flakiness)?\n- ✓ Tests work without network, database, or filesystem?\n- ✓ One test failure doesn't affect other tests?\n- ✓ Test names clearly explain what they verify?\n- ✓ Tests are easy to read and understand?\n- ✓ When tests fail, you know exactly what broke?\n\nIf NO to any → Review the corresponding section in [REFERENCE.md](REFERENCE.md)\n\n## Examples\n\nFor comprehensive code examples covering all patterns and scenarios, see [EXAMPLES.md](EXAMPLES.md).\n\n## Best Practices\n\n**Test Structure:**\n\n- Use AAA pattern (Arrange-Act-Assert)\n- Follow USE naming (Unit-Scenario-Expectation)\n- One assertion per test (or multiple for same concern)\n- Factory methods over beforeEach()\n\n**Dependencies:**\n\n- Inject all dependencies\n- Use stubs for incoming data\n- Use mocks only for exit points (one per test)\n- Prefer return-value and state-based tests (95%+ of tests)\n\n**Async Code:**\n\n- Extract pure logic into separate functions\n- Wrap async dependencies behind adapters\n- Use fake timers for time-dependent code\n- Keep most tests synchronous\n\n**Maintainability:**\n\n- No logic in tests\n- Test behavior, not implementation\n- Keep tests independent\n- Refactor tests like production code\n- Trust your tests - if they fail, there's a bug\n\n## Resources\n\n- Full reference documentation: [REFERENCE.md](REFERENCE.md)\n- Code examples: [EXAMPLES.md](EXAMPLES.md)\n- Book: \"The Art of Unit Testing, Third Edition\" by Roy Osherove (Manning, 2024)\n- Code samples: <https://github.com/royosherove/aout3-samples>\n- Jest documentation: <https://jestjs.io/>"
              },
              {
                "name": "vitest",
                "description": "Comprehensive Vitest testing framework guide with strong emphasis on Jest-to-Vitest migration. Covers automated migration using codemods, configuration setup, API differences, best practices, and troubleshooting. Use when migrating from Jest, setting up Vitest, writing tests, configuring test environments, or resolving migration issues. Primary focus is seamless Jest migration with minimal code changes.",
                "path": "plugins/js-ts/skills/vitest/SKILL.md",
                "frontmatter": {
                  "name": "vitest",
                  "description": "Comprehensive Vitest testing framework guide with strong emphasis on Jest-to-Vitest migration. Covers automated migration using codemods, configuration setup, API differences, best practices, and troubleshooting. Use when migrating from Jest, setting up Vitest, writing tests, configuring test environments, or resolving migration issues. Primary focus is seamless Jest migration with minimal code changes."
                },
                "content": "<objective>\nExpert guidance for migrating from Jest to Vitest and working with the Vitest testing framework. This skill focuses primarily on **automated migration from Jest** while covering setup, configuration, and best practices.\n\n**Key benefits of Vitest over Jest:**\n\n- 2-10x faster test startup (built on Vite and esbuild)\n- Native TypeScript support without ts-jest\n- Hot Module Replacement for instant re-runs\n- Jest-compatible API requiring minimal code changes\n- Modern ESM-first architecture\n</objective>\n\n<quick_start>\n<automated_migration>\n**RECOMMENDED APPROACH**: Use automated codemods for fastest migration.\n\n**Option 1: vitest-codemod** (recommended)\n\n```bash\n# Install globally\nnpm install -g @vitest-codemod/jest\n\n# Run migration on test files\nvitest-codemod jest path/to/tests/**/*.test.js\n\n# Or use npx (no installation)\nnpx @vitest-codemod/jest path/to/tests\n```\n\n**Option 2: Codemod.com Platform**\n\n```bash\n# Using VS Code extension\n# Install \"Codemod\" extension from marketplace\n# Right-click project → \"Run Codemod\" → \"Jest to Vitest\"\n\n# Using CLI\nnpx codemod jest/vitest\n```\n\n**What codemods handle automatically:**\n\n- ✓ Convert `jest.mock()` → `vi.mock()`\n- ✓ Convert `jest.fn()` → `vi.fn()`\n- ✓ Convert `jest.spyOn()` → `vi.spyOn()`\n- ✓ Convert `jest.setTimeout()` → `vi.setConfig({ testTimeout })`\n- ✓ Update global matchers and timer mocks\n- ✓ Transform `jest.requireActual()` → `vi.importActual()`\n- ✓ Update mock resets/clears/restores\n</automated_migration>\n\n<manual_migration>\n**For users who need manual control or want to understand changes:**\n\n**1. Install Vitest**\n\n```bash\n# Remove Jest\nnpm uninstall jest @types/jest ts-jest jest-environment-jsdom\n\n# Install Vitest\nnpm install -D vitest @vitest/ui happy-dom\n```\n\n**2. Create vitest.config.ts**\n\n```typescript\nimport { defineConfig } from 'vitest/config'\n\nexport default defineConfig({\n  test: {\n    globals: true,              // Enable globals for Jest compatibility\n    environment: 'happy-dom',   // Faster than jsdom\n    setupFiles: ['./vitest.setup.ts'],\n    clearMocks: true,\n    restoreMocks: true,\n  },\n})\n```\n\n**3. Update package.json**\n\n```json\n{\n  \"scripts\": {\n    \"test\": \"vitest\",\n    \"test:ui\": \"vitest --ui\",\n    \"test:run\": \"vitest run\",\n    \"test:coverage\": \"vitest run --coverage\"\n  }\n}\n```\n\n**4. Update TypeScript config**\n\n```json\n{\n  \"compilerOptions\": {\n    \"types\": [\"vitest/globals\"]\n  }\n}\n```\n\n**5. Update mock syntax**\n\n```typescript\n// Replace in all test files:\njest.fn → vi.fn\njest.spyOn → vi.spyOn\njest.mock → vi.mock\njest.useFakeTimers → vi.useFakeTimers\njest.clearAllMocks → vi.clearAllMocks\n```\n\n</manual_migration>\n\n<automated_scripts>\n**For comprehensive migrations with validation and rollback:**\n\nReady-to-run migration scripts available in `scripts/` directory:\n\n- `quick-migrate.sh` - Fast 30-second migration for simple projects\n- `comprehensive-migrate.sh` - Full-featured migration with project detection, backups, and validation\n\nSee [references/MIGRATION_SCRIPT.md](references/MIGRATION_SCRIPT.md) for usage instructions.\n</automated_scripts>\n</quick_start>\n\n<critical_differences>\n<module_mocking>\n**Jest**: Auto-returns default export\n\n```typescript\njest.mock('./module', () => 'hello')\n```\n\n**Vitest**: Must specify exports explicitly\n\n```typescript\nvi.mock('./module', () => ({\n  default: 'hello'  // Explicit default export required\n}))\n```\n\n</module_mocking>\n\n<mock_reset_behavior>\n**Jest**: `mockReset()` replaces with empty function returning `undefined`\n\n**Vitest**: `mockReset()` resets to original implementation\n\nTo match Jest behavior in Vitest:\n\n```typescript\nmockFn.mockReset()\nmockFn.mockImplementation(() => undefined)\n```\n\n</mock_reset_behavior>\n\n<globals_configuration>\n**Jest**: Globals enabled by default\n\n**Vitest**: Must explicitly enable:\n\n```typescript\nexport default defineConfig({\n  test: {\n    globals: true  // Enable for Jest compatibility\n  }\n})\n```\n\nThen add to `tsconfig.json`:\n\n```json\n{\n  \"compilerOptions\": {\n    \"types\": [\"vitest/globals\"]\n  }\n}\n```\n\n</globals_configuration>\n\n<auto_mocking>\n**Jest**: Files in `__mocks__/` auto-load\n\n**Vitest**: Must call `vi.mock()` explicitly, or add to `setupFiles`:\n\n```typescript\n// vitest.setup.ts\nvi.mock('./path/to/module')\n```\n\n</auto_mocking>\n\n<async_tests>\n**Jest**: Supports callback style with `done()`\n\n**Vitest**: Use async/await or Promises\n\n```typescript\n// Before (Jest)\ntest('async test', (done) => {\n  setTimeout(() => {\n    expect(true).toBe(true)\n    done()\n  }, 100)\n})\n\n// After (Vitest)\ntest('async test', async () => {\n  await new Promise(resolve => {\n    setTimeout(() => {\n      expect(true).toBe(true)\n      resolve()\n    }, 100)\n  })\n})\n```\n\n</async_tests>\n</critical_differences>\n\n<common_issues>\n<testing_library_cleanup>\n**Problem**: Auto-cleanup doesn't run when `globals: false`\n\n**Solution**: Manually import cleanup in setup file\n\n```typescript\n// vitest.setup.ts\nimport { cleanup } from '@testing-library/react'\nimport { afterEach } from 'vitest'\n\nafterEach(() => {\n  cleanup()\n})\n```\n\n</testing_library_cleanup>\n\n<path_aliases>\n**Problem**: Jest's `moduleNameMapper` not working\n\n**Solution**: Configure in `vitest.config.ts`\n\n```typescript\nimport { defineConfig } from 'vitest/config'\nimport path from 'path'\n\nexport default defineConfig({\n  resolve: {\n    alias: {\n      '@': path.resolve(__dirname, './src'),\n      '@components': path.resolve(__dirname, './src/components'),\n    }\n  }\n})\n```\n\n</path_aliases>\n\n<coverage_differences>\n**Problem**: Coverage numbers don't match Jest\n\n**Solution**: Vitest uses V8 by default. For Istanbul (Jest's provider):\n\n```bash\nnpm install -D @vitest/coverage-istanbul\n```\n\n```typescript\nexport default defineConfig({\n  test: {\n    coverage: {\n      provider: 'istanbul'\n    }\n  }\n})\n```\n\n</coverage_differences>\n\n<snapshot_names>\n**Problem**: Test names in snapshots use `>` separator instead of spaces\n\n```\nJest:  \"describe title test title\"\nVitest: \"describe title > test title\"\n```\n\n**Solution**: Regenerate snapshots with `npm run test -u`\n</snapshot_names>\n</common_issues>\n\n<best_practices>\n\n1. **Use `happy-dom` over `jsdom`** - 2-3x faster for most use cases\n2. **Enable globals for easier migration** - Set `globals: true` in config\n3. **Use watch mode during development** - `npm run test` (default behavior)\n4. **Leverage UI mode for debugging** - `npm run test:ui` opens browser interface\n5. **Configure auto-cleanup** - Set `clearMocks: true` and `restoreMocks: true`\n6. **Use workspace configuration for monorepos** - See [CONFIG.md](references/CONFIG.md)\n</best_practices>\n\n<performance_optimization>\n\n```typescript\nexport default defineConfig({\n  test: {\n    environment: 'node', // or 'happy-dom' instead of 'jsdom'\n    maxWorkers: 4,       // Increase for parallel execution\n    fileParallelism: true,\n    testTimeout: 5000,\n    isolate: false,      // Faster but use with caution\n    pool: 'threads',     // or 'forks' for better isolation\n  }\n})\n```\n\n**Pool options:**\n\n- `threads` (default) - Fast, CPU-intensive tests\n- `forks` - Better isolation, more memory\n- `vmThreads` - Best for TypeScript performance\n</performance_optimization>\n\n<migration_workflow>\n**Recommended migration process:**\n\n1. **Prepare**\n   - Ensure all Jest tests passing\n   - Commit working state\n   - Create migration branch\n\n2. **Install dependencies**\n\n   ```bash\n   npm install -D vitest @vitest/ui happy-dom\n   ```\n\n3. **Run automated codemod**\n\n   ```bash\n   npx @vitest-codemod/jest src/**/*.test.ts\n   ```\n\n4. **Create configuration**\n   - Add `vitest.config.ts` with `globals: true`\n   - Update `package.json` scripts\n   - Update `tsconfig.json` types\n\n5. **Run tests and fix issues**\n\n   ```bash\n   npm run test\n   ```\n\n   - Address failures one by one\n   - Check [MIGRATION.md](references/MIGRATION.md) for solutions\n\n6. **Update CI/CD**\n   - Replace Jest commands with Vitest\n   - Update coverage paths if needed\n\n7. **Cleanup**\n\n   ```bash\n   npm uninstall jest @types/jest ts-jest\n   rm jest.config.js\n   ```\n\n</migration_workflow>\n\n<common_commands>\n\n```bash\nnpm run test                    # Watch mode\nnpm run test:run                # Run once (CI mode)\nnpm run test:coverage           # With coverage\nnpm run test:ui                 # Visual UI\nnpm run test path/to/file.test.ts  # Specific file\nnpm run test -t \"pattern\"       # Matching pattern\nnpm run test --environment jsdom   # Specific environment\nnpm run test -u                 # Update snapshots\n```\n\n</common_commands>\n\n<detailed_references>\nFor comprehensive information:\n\n- **[MIGRATION.md](references/MIGRATION.md)** - Complete Jest→Vitest API mapping, troubleshooting, framework-specific guides\n- **[CONFIG.md](references/CONFIG.md)** - Full configuration reference with examples for React, Vue, TypeScript, Node.js, monorepos\n- **[MIGRATION_SCRIPT.md](references/MIGRATION_SCRIPT.md)** - Automated migration script usage and customization\n- **Official Vitest docs**: <https://vitest.dev>\n- **Vitest migration guide**: <https://vitest.dev/guide/migration>\n- **vitest-codemod tool**: <https://github.com/trivikr/vitest-codemod>\n- **Codemod platform**: <https://codemod.com/migrations/jest-to-vitest>\n</detailed_references>\n\n<success_criteria>\nMigration is successful when:\n\n- All tests passing with `npm run test:run`\n- Coverage reports generate correctly\n- CI/CD pipeline runs tests successfully\n- No `jest` references remain in codebase\n- TypeScript types resolve without errors\n- Test execution is noticeably faster (2-10x improvement)\n</success_criteria>\n\n<when_successful>\nAfter successful migration, you should observe:\n\n- **5x faster cold start** - Initial test run (10s → 2s typical)\n- **5x faster watch mode** - Hot reload (5s → <1s typical)\n- **2x faster execution** - Overall test suite runtime\n- **10x faster TypeScript tests** - No ts-jest compilation overhead\n- **Better DX** - Instant feedback, visual UI, better error messages\n</when_successful>"
              }
            ]
          },
          {
            "name": "devops",
            "description": "DevOps and infrastructure toolkit with GitHub Actions, Kamal deployment, and Tailscale VPN configuration",
            "source": "./plugins/devops",
            "category": null,
            "version": "0.1.0",
            "author": {
              "name": "Jeb Coleman"
            },
            "install_commands": [
              "/plugin marketplace add el-feo/ai-context",
              "/plugin install devops@jebs-dev-tools"
            ],
            "signals": {
              "stars": 0,
              "forks": 0,
              "pushed_at": "2026-01-12T05:23:19Z",
              "created_at": "2025-03-11T20:00:10Z",
              "license": "MIT"
            },
            "commands": [
              {
                "name": "/github-actions",
                "description": "Create, evaluate, and optimize GitHub Actions workflows and custom actions",
                "path": "plugins/devops/commands/github-actions.md",
                "frontmatter": {
                  "description": "Create, evaluate, and optimize GitHub Actions workflows and custom actions",
                  "argument-hint": [
                    "task description or workflow to evaluate"
                  ],
                  "allowed-tools": "Skill(github-actions)"
                },
                "content": "<objective>\nDelegate GitHub Actions tasks to the github-actions skill for: $ARGUMENTS\n\nThis routes to specialized skill containing workflows, security patterns, performance optimization, and deployment strategies for Ruby/Rails and TypeScript projects.\n</objective>\n\n<process>\n1. Use Skill tool to invoke github-actions skill\n2. Pass user's request: $ARGUMENTS\n3. Let skill handle workflow creation, evaluation, or optimization\n</process>\n\n<success_criteria>\n- Skill successfully invoked\n- Arguments passed correctly to skill\n- User receives comprehensive GitHub Actions guidance\n</success_criteria>"
              }
            ],
            "skills": [
              {
                "name": "github-actions",
                "description": "Create, evaluate, and optimize GitHub Actions workflows and custom actions. Use when building CI/CD pipelines, creating workflow files, developing custom actions, troubleshooting workflow failures, performing security analysis, optimizing performance, or reviewing GitHub Actions best practices. Covers Ruby/Rails, TypeScript/Node.js, Heroku and Fly.io deployments.",
                "path": "plugins/devops/skills/github-actions/SKILL.md",
                "frontmatter": {
                  "name": "github-actions",
                  "description": "Create, evaluate, and optimize GitHub Actions workflows and custom actions. Use when building CI/CD pipelines, creating workflow files, developing custom actions, troubleshooting workflow failures, performing security analysis, optimizing performance, or reviewing GitHub Actions best practices. Covers Ruby/Rails, TypeScript/Node.js, Heroku and Fly.io deployments."
                },
                "content": "<objective>\nEnable creation, evaluation, and optimization of GitHub Actions workflows and custom actions with comprehensive coverage of CI/CD patterns, security best practices, performance optimization, and deployment strategies for Ruby/Rails and TypeScript projects to Heroku and Fly.io.\n</objective>\n\n<context>\nGitHub Actions automates software workflows with event-driven CI/CD pipelines. Workflows are YAML files in `.github/workflows/` that define jobs, steps, and actions triggered by repository events.\n\n**Latest Updates (2024-2025):**\n- **November 2025**: Nested reusable workflows increased to 10 levels (was 4), total workflows to 50 (was 20)\n- **November 2025**: M2-powered macOS runners with GPU acceleration (macos-latest-xlarge, macos-15-xlarge)\n- **December 2024 - January 2025**: ubuntu-latest migrating from Ubuntu 22 to Ubuntu 24\n- **February-March 2025**: Cache storage v1-v2 retirement - must use actions/cache@v4.0.0+\n\n**Action Types:**\n- **Workflow files**: CI/CD pipelines using existing actions (.github/workflows/*.yml)\n- **Custom JavaScript actions**: Fast, cross-platform, use @actions/toolkit\n- **Custom Docker actions**: Full environment control, specific tooling, slower startup\n- **Composite actions**: Combine multiple steps into reusable units\n</context>\n\n<quick_start>\n**Create a basic workflow:**\n\n```yaml\n# .github/workflows/ci.yml\nname: CI\n\non:\n  push:\n    branches: [main]\n  pull_request:\n    branches: [main]\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Run tests\n        run: npm test\n```\n\n**Ruby/Rails with RSpec:**\n\n```yaml\n- uses: ruby/setup-ruby@v1\n  with:\n    ruby-version: .ruby-version\n    bundler-cache: true\n\n- name: Setup database\n  env:\n    RAILS_ENV: test\n  run: bin/rails db:setup\n\n- name: Run tests\n  run: bundle exec rspec\n```\n\n**TypeScript/Node.js:**\n\n```yaml\n- uses: actions/setup-node@v4\n  with:\n    node-version: '20'\n    cache: 'npm'\n\n- run: npm ci\n- run: npm run build --if-present\n- run: npm test\n```\n\n**Deploy to Fly.io:**\n\n```yaml\n- uses: superfly/flyctl-actions/setup-flyctl@master\n- run: flyctl deploy --remote-only\n  env:\n    FLY_API_TOKEN: ${{ secrets.FLY_API_TOKEN }}\n```\n</quick_start>\n\n<workflow>\n**Creating Workflows:**\n\n1. **Identify triggers**: push, pull_request, workflow_dispatch, schedule, etc.\n2. **Define jobs**: Specify runner OS, steps, and dependencies\n3. **Add security**: Set GITHUB_TOKEN permissions to read-only, pin actions to SHA\n4. **Optimize performance**: Enable caching, use matrix builds for parallelization\n5. **Test locally**: Use act or GitHub CLI to test before pushing\n\n**Evaluating Workflows:**\n\n1. **Security scan**: Check permissions, secrets exposure, action pinning, pull_request_target usage\n2. **Performance analysis**: Identify slow steps, missing caches, parallelization opportunities\n3. **Best practices review**: Validate naming, structure, error handling, documentation\n4. **Troubleshooting**: Review logs, check dependencies, verify secrets/environment variables\n</workflow>\n\n<validation>\n**Pre-deployment checks:**\n\n- YAML syntax valid (use yamllint or GitHub's workflow validator)\n- Required secrets configured in repository settings\n- GITHUB_TOKEN permissions explicitly set to minimum required\n- Actions pinned to specific SHA or trusted tags\n- Caching configured for dependencies (bundler, npm, etc.)\n- Matrix builds used for multiple versions/platforms\n- Workflow triggers appropriate for use case\n\n**Post-deployment monitoring:**\n\n- First run completes successfully\n- Execution time acceptable (check for optimization opportunities if >5 minutes)\n- No secrets or credentials in logs\n- Cache hit rate >80% after first run\n</validation>\n\n<security_checklist>\n**Critical Security Patterns:**\n\n1. **GITHUB_TOKEN permissions**: Always set to read-only by default\n   ```yaml\n   permissions:\n     contents: read\n   ```\n\n2. **Pin actions to commit SHA** (most secure):\n   ```yaml\n   - uses: actions/checkout@b4ffde65f46336ab88eb53be808477a3936bae11 # v4.1.1\n   ```\n\n3. **Use OIDC for cloud deployments** (credential-less authentication):\n   ```yaml\n   permissions:\n     id-token: write\n     contents: read\n   ```\n\n4. **Avoid pull_request_target with untrusted code**:\n   - Runs in base repository context with access to secrets\n   - Never checkout PR code without approval workflow\n\n5. **Environment secrets with required reviewers**:\n   ```yaml\n   jobs:\n     deploy:\n       environment: production\n   ```\n\n6. **Never log secrets**:\n   - Use `::add-mask::` for dynamic values\n   - Avoid `echo` or `print` statements with secret variables\n\n7. **Audit action sources**:\n   - Prefer verified creators (GitHub, major organizations)\n   - Review action source code before using\n   - Check for recent maintenance and security issues\n\nSee [references/security-checklist.md](references/security-checklist.md) for complete security guidelines.\n</security_checklist>\n\n<common_patterns>\n**Conditional execution:**\n\n```yaml\n- name: Deploy to production\n  if: github.ref == 'refs/heads/main' && github.event_name == 'push'\n  run: ./deploy.sh\n```\n\n**Matrix builds:**\n\n```yaml\nstrategy:\n  matrix:\n    ruby-version: ['3.1', '3.2', '3.3']\n    os: [ubuntu-latest, macos-latest]\njobs:\n  test:\n    runs-on: ${{ matrix.os }}\n```\n\n**Reusable workflows:**\n\n```yaml\n# .github/workflows/reusable.yml\non:\n  workflow_call:\n    inputs:\n      environment:\n        required: true\n        type: string\n\njobs:\n  deploy:\n    runs-on: ubuntu-latest\n    steps:\n      - run: echo \"Deploying to ${{ inputs.environment }}\"\n```\n\n```yaml\n# .github/workflows/main.yml\njobs:\n  call-reusable:\n    uses: ./.github/workflows/reusable.yml\n    with:\n      environment: production\n```\n\n**Secrets in composite actions:**\n\n```yaml\n# Pass secrets explicitly - they're not inherited\n- uses: ./.github/actions/my-action\n  with:\n    api-key: ${{ secrets.API_KEY }}\n```\n\nSee [references/common-workflows.md](references/common-workflows.md) for Ruby/Rails, TypeScript, Heroku, and Fly.io patterns.\n</common_patterns>\n\n<anti_patterns>\n**Avoid these mistakes:**\n\n- **Running as root in Docker actions**: Use non-root user for security\n- **Hardcoded secrets**: Always use GitHub Secrets\n- **Overly broad permissions**: Set minimal required permissions\n- **No caching**: Wastes time and resources on every run\n- **Sequential jobs that could be parallel**: Use dependencies only when needed\n- **Using `master` branch references**: Pin to tags or SHAs\n- **Ignoring security alerts**: Review and address Dependabot alerts\n- **No timeout-minutes**: Jobs can run for 6 hours by default\n- **Checkout without depth control**: Use `fetch-depth: 0` only when needed\n- **Manual apt-get installs**: Use setup actions when available\n</anti_patterns>\n\n<examples>\n**Complete Rails CI/CD workflow:**\n\n```yaml\nname: Rails CI\n\non:\n  push:\n    branches: [main]\n  pull_request:\n    branches: [main]\n\npermissions:\n  contents: read\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n\n    services:\n      postgres:\n        image: postgres:16\n        env:\n          POSTGRES_PASSWORD: postgres\n        options: >-\n          --health-cmd pg_isready\n          --health-interval 10s\n          --health-timeout 5s\n          --health-retries 5\n        ports:\n          - 5432:5432\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - uses: ruby/setup-ruby@v1\n        with:\n          ruby-version: .ruby-version\n          bundler-cache: true\n\n      - name: Setup database\n        env:\n          RAILS_ENV: test\n          DATABASE_URL: postgres://postgres:postgres@localhost:5432/test\n        run: |\n          bin/rails db:create\n          bin/rails db:schema:load\n\n      - name: Run tests\n        env:\n          RAILS_ENV: test\n          DATABASE_URL: postgres://postgres:postgres@localhost:5432/test\n        run: bundle exec rspec\n\n      - name: Run RuboCop\n        run: bundle exec rubocop\n\n  deploy:\n    needs: test\n    if: github.ref == 'refs/heads/main' && github.event_name == 'push'\n    runs-on: ubuntu-latest\n    environment: production\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - uses: superfly/flyctl-actions/setup-flyctl@master\n\n      - run: flyctl deploy --remote-only\n        env:\n          FLY_API_TOKEN: ${{ secrets.FLY_API_TOKEN }}\n```\n\nSee [references/common-workflows.md](references/common-workflows.md) for more complete examples.\n</examples>\n\n<troubleshooting>\n**Common issues and solutions:**\n\n1. **\"Resource not accessible by integration\"**\n   - Add required permissions to GITHUB_TOKEN\n   - Check if job needs `contents: write` or `pull-requests: write`\n\n2. **Cache not restoring**\n   - Verify cache key matches between save and restore\n   - Check if cache size exceeds 10GB limit\n   - Ensure actions/cache@v4+ for new cache backend\n\n3. **Secrets not available**\n   - Verify secret is defined in repository/organization/environment settings\n   - Check if job requires `environment` for environment secrets\n   - Ensure secret name matches exactly (case-sensitive)\n\n4. **Action fails to find command**\n   - Ensure setup action runs before command usage\n   - Check PATH modifications in previous steps\n   - Verify runner OS matches requirements\n\n5. **Timeout after 6 hours**\n   - Add `timeout-minutes: 30` to jobs or steps\n   - Investigate why job runs so long (missing cache, inefficient scripts)\n\nSee [references/troubleshooting.md](references/troubleshooting.md) for detailed debugging strategies.\n</troubleshooting>\n\n<performance_optimization>\n**Key optimization strategies:**\n\n1. **Dependency caching** (can reduce build times by 80%):\n   - Ruby: Use `ruby/setup-ruby` with `bundler-cache: true`\n   - Node.js: Use `actions/setup-node` with `cache: 'npm'`\n   - Custom: Use `actions/cache@v4` with hash keys from lock files\n\n2. **Parallelization**:\n   - Use matrix builds for multiple versions/platforms\n   - Split independent jobs to run concurrently\n   - Avoid job dependencies unless actually required\n\n3. **Selective triggers**:\n   ```yaml\n   on:\n     push:\n       paths:\n         - 'src/**'\n         - 'package.json'\n   ```\n\n4. **Concurrency control** (cancel outdated runs):\n   ```yaml\n   concurrency:\n     group: ${{ github.workflow }}-${{ github.ref }}\n     cancel-in-progress: true\n   ```\n\n5. **Self-hosted runners** for heavy workloads:\n   - Persistent caching across runs\n   - Faster than GitHub-hosted for large builds\n   - More control over environment\n\nSee [references/performance-optimization.md](references/performance-optimization.md) for advanced techniques.\n</performance_optimization>\n\n<reference_guides>\nFor detailed information on specific topics:\n\n- **[Workflow Syntax](references/workflow-syntax.md)**: Complete YAML reference, triggers, jobs, steps, expressions\n- **[Custom Actions](references/custom-actions.md)**: Building JavaScript, Docker, and composite actions\n- **[Security Checklist](references/security-checklist.md)**: Comprehensive security patterns and OIDC setup\n- **[Performance Optimization](references/performance-optimization.md)**: Caching strategies, parallelization, profiling\n- **[Common Workflows](references/common-workflows.md)**: Ruby/Rails, TypeScript, Heroku/Fly.io deployment templates\n- **[Troubleshooting](references/troubleshooting.md)**: Debugging workflows, common errors, log analysis\n- **[Evaluation Guide](references/evaluation-guide.md)**: Security analysis, performance review, best practices audit\n</reference_guides>\n\n<success_criteria>\n**For workflow creation:**\n- Workflow file is valid YAML with correct syntax\n- Triggers appropriate for use case\n- Jobs execute successfully with expected outputs\n- Security best practices applied (permissions, pinned actions, no secrets in logs)\n- Performance optimized (caching, parallelization where appropriate)\n- Documentation included (comments explaining non-obvious steps)\n\n**For workflow evaluation:**\n- Security issues identified and prioritized\n- Performance bottlenecks documented with recommendations\n- Best practice violations noted with fixes\n- Overall assessment: PASS/FAIL/NEEDS_IMPROVEMENT with specific action items\n</success_criteria>"
              },
              {
                "name": "kamal",
                "description": "Deploy containerized web applications to any Linux server using Kamal. Use when users need to deploy, configure, debug, or manage Kamal deployments including initial setup, configuration of deploy.yml, deployment workflows, rollbacks, managing accessories (databases, Redis), troubleshooting deployment issues, or understanding Kamal commands and best practices.",
                "path": "plugins/devops/skills/kamal/SKILL.md",
                "frontmatter": {
                  "name": "kamal",
                  "description": "Deploy containerized web applications to any Linux server using Kamal. Use when users need to deploy, configure, debug, or manage Kamal deployments including initial setup, configuration of deploy.yml, deployment workflows, rollbacks, managing accessories (databases, Redis), troubleshooting deployment issues, or understanding Kamal commands and best practices."
                },
                "content": "# Kamal Deployment\n\nKamal is a zero-downtime deployment tool for containerized applications, originally built by 37signals for deploying Rails apps but works with any containerized web application.\n\n## Core Concepts\n\n**Philosophy**: Kamal uses an imperative \"push\" model where you explicitly tell servers what to do, unlike declarative tools like Kubernetes. It combines SSH, Docker, and Kamal Proxy to achieve zero-downtime deployments.\n\n**Components**:\n- **SSH/SSHKit**: Remote command execution\n- **Docker**: Container runtime and image management\n- **Kamal Proxy**: Reverse proxy for zero-downtime deployments (routes traffic between container versions)\n- **Accessories**: Supporting services (PostgreSQL, MySQL, Redis, etc.)\n\n## When to Use This Skill\n\nUse this skill when you need to:\n- Set up Kamal for a new project\n- Configure `config/deploy.yml` or understand configuration options\n- Deploy applications or troubleshoot deployment failures\n- Manage multiple environments (staging, production)\n- Configure accessories (databases, Redis, etc.)\n- Debug deployment issues or container problems\n- Perform rollbacks or maintenance mode\n- Understand Kamal commands and workflows\n- Set up CI/CD pipelines with Kamal\n\n## Quick Start Workflow\n\n### Initial Setup\n```bash\n# 1. Install Kamal\ngem install kamal\n\n# 2. Initialize configuration\ncd your-app\nkamal init\n\n# 3. Edit config/deploy.yml\n# - Set service name and image\n# - Add server IP addresses\n# - Configure registry credentials\n# - Set environment variables\n\n# 4. Configure secrets in .kamal/secrets\nKAMAL_REGISTRY_PASSWORD=your-token\nRAILS_MASTER_KEY=your-key\n\n# 5. Run initial setup (installs Docker, deploys everything)\nkamal setup\n```\n\n### Standard Deploy\n```bash\nkamal deploy              # Build, push, deploy with zero downtime\nkamal deploy -d staging   # Deploy to staging environment\nkamal app logs -f         # Follow application logs\n```\n\n### Common Operations\n```bash\nkamal app exec -i --reuse \"bin/rails console\"  # Rails console\nkamal app logs -g \"error\"                       # Search logs\nkamal rollback <version>                        # Rollback\nkamal app maintenance                           # Maintenance mode\nkamal app live                                  # Exit maintenance\n```\n\n## Configuration Patterns\n\n### Basic deploy.yml Structure\n```yaml\nservice: myapp\nimage: username/myapp\n\nservers:\n  web:\n    - 192.168.1.10\n\nregistry:\n  server: ghcr.io\n  username: myuser\n  password:\n    - KAMAL_REGISTRY_PASSWORD\n\nenv:\n  secret:\n    - RAILS_MASTER_KEY\n  clear:\n    RAILS_ENV: production\n\nproxy:\n  ssl: true\n  host: example.com\n```\n\n### Multi-Server with Roles\n```yaml\nservers:\n  web:\n    hosts:\n      - 192.168.1.10\n      - 192.168.1.11\n  worker:\n    hosts:\n      - 192.168.1.12\n    cmd: bundle exec sidekiq\n```\n\n### Accessories (Supporting Services)\n```yaml\naccessories:\n  postgres:\n    image: postgres:15\n    host: 192.168.1.20\n    port: 5432\n    env:\n      secret:\n        - POSTGRES_PASSWORD\n      clear:\n        POSTGRES_DB: myapp_production\n    directories:\n      - data:/var/lib/postgresql/data\n  \n  redis:\n    image: redis:7\n    host: 192.168.1.21\n    directories:\n      - data:/data\n```\n\nFor comprehensive configuration options, see **references/configuration.md**.\n\n## Essential Commands\n\n### Deployment\n- `kamal init` - Initialize configuration files\n- `kamal setup` - First-time setup (installs Docker, deploys everything)\n- `kamal deploy` - Standard deploy with zero downtime\n- `kamal redeploy` - Fast redeploy (skips proxy setup)\n- `kamal rollback VERSION` - Rollback to previous version\n\n### Application Management\n- `kamal app logs [-f]` - View logs (follow with -f)\n- `kamal app exec \"COMMAND\"` - Run command in container\n- `kamal app exec -i --reuse \"bash\"` - Interactive shell\n- `kamal app maintenance` - Enable maintenance mode\n- `kamal app live` - Disable maintenance mode\n- `kamal app containers` - List all containers (for rollback)\n- `kamal app version` - Show deployed version\n\n### Accessories\n- `kamal accessory boot NAME` - Start accessory\n- `kamal accessory logs NAME [-f]` - View accessory logs\n- `kamal accessory exec NAME \"CMD\"` - Run command in accessory\n\n### Troubleshooting\n- `kamal config` - Show parsed configuration\n- `kamal lock status` - Check deployment lock\n- `kamal lock release` - Release stuck lock\n- `kamal server exec \"CMD\"` - Run command on host\n\n### Multiple Environments\n- `kamal deploy -d staging` - Deploy to staging\n- `kamal deploy -h 192.168.1.10` - Deploy to specific host\n- `kamal deploy -r web` - Deploy to specific role\n\nFor complete command reference, see **references/commands.md**.\n\n## Common Workflows\n\n### Deploy with Database Migration\n\n**Using pre-deploy hook** (recommended):\n\nCreate `.kamal/hooks/pre-deploy`:\n```bash\n#!/bin/bash\nkamal app exec -p -q \"bin/rails db:migrate\"\n```\n\n```bash\nchmod +x .kamal/hooks/pre-deploy\nkamal deploy\n```\n\n### Rollback Workflow\n```bash\n# Check what went wrong\nkamal app logs\n\n# List available versions\nkamal app containers\n\n# Rollback to previous version\nkamal rollback abc123def\n```\n\n### Debugging Failed Deployments\n\n1. **Check logs**: `kamal app logs -n 500`\n2. **Check container status**: `kamal server exec \"docker ps -a\"`\n3. **Test health endpoint**: `kamal app exec \"curl localhost:3000/up\"`\n4. **Check configuration**: `kamal config`\n5. **Release stuck locks**: `kamal lock release`\n\n### Multiple Environments Pattern\n\nCreate environment-specific configs:\n- `config/deploy.yml` (production)\n- `config/deploy.staging.yml`\n\n```bash\nkamal setup -d staging\nkamal deploy -d staging\nkamal deploy  # production\n```\n\nFor detailed workflows, troubleshooting guides, and best practices, see **references/workflows.md**.\n\n## Database and Accessory Management\n\n### Running Commands in Accessories\n```bash\n# PostgreSQL\nkamal accessory exec postgres \"psql -U myapp\"\nkamal accessory exec postgres \"pg_dump -U myapp myapp_production\" > backup.sql\n\n# Redis\nkamal accessory exec redis \"redis-cli\"\n\n# MySQL\nkamal accessory exec mysql \"mysql -u root -p myapp_production\"\n```\n\n### Litestream (SQLite Replication)\n```bash\nkamal accessory exec litestream \"litestream generations /data/production.sqlite3\"\nkamal accessory exec litestream \"litestream restore /data/production.sqlite3\"\n```\n\n## Configuration for Common Scenarios\n\n### Custom SSH User/Port\n```yaml\nssh:\n  user: deploy\n  port: 2222\n```\n\n### Custom Build Context\n```yaml\nbuilder:\n  context: .\n  dockerfile: Dockerfile.production\n  args:\n    RUBY_VERSION: 3.2.0\n```\n\n### Health Check Configuration\n```yaml\nhealthcheck:\n  path: /up\n  port: 3000\n  interval: 10\n  max_attempts: 7\n```\n\n### Aliases for Common Commands\n```yaml\naliases:\n  console: app exec --interactive --reuse \"bin/rails console\"\n  shell: app exec --interactive --reuse \"bash\"\n  logs: app logs -f\n```\n\nUse: `kamal console` instead of full command.\n\n## CI/CD Integration\n\n### GitHub Actions Example\n```yaml\n- name: Deploy\n  env:\n    KAMAL_REGISTRY_PASSWORD: ${{ secrets.REGISTRY_TOKEN }}\n    RAILS_MASTER_KEY: ${{ secrets.RAILS_MASTER_KEY }}\n  run: |\n    gem install kamal\n    kamal deploy\n```\n\n## Key Limitations\n\n1. **No automatic state reconciliation** - Kamal won't automatically decommission containers if you remove them from config\n2. **No dynamic provisioning** - Cannot auto-scale or provision servers on demand\n3. **Single-server load balancing only** - Kamal Proxy balances containers on each server, not across servers (use external load balancer for that)\n\n## References\n\nThis skill includes comprehensive reference documentation:\n\n- **configuration.md** - Complete `config/deploy.yml` reference with all options, registry configurations, accessory setups, and example configurations\n- **commands.md** - Detailed command reference for all Kamal CLI commands with options and examples\n- **workflows.md** - Common deployment workflows, troubleshooting patterns, CI/CD integration, security best practices, and production guidelines\n\nRead these references when you need detailed information about specific configuration options, commands, or deployment patterns."
              },
              {
                "name": "tailscale",
                "description": "Comprehensive Tailscale VPN setup, configuration, and management for mesh networking, secure access, and zero-trust infrastructure. Covers installation, CLI commands, subnet routers, exit nodes, Tailscale SSH, ACL/grants configuration, MagicDNS, Tailscale Serve/Funnel, API automation, and production deployment best practices.",
                "path": "plugins/devops/skills/tailscale/SKILL.md",
                "frontmatter": {
                  "name": "tailscale",
                  "description": "Comprehensive Tailscale VPN setup, configuration, and management for mesh networking, secure access, and zero-trust infrastructure. Covers installation, CLI commands, subnet routers, exit nodes, Tailscale SSH, ACL/grants configuration, MagicDNS, Tailscale Serve/Funnel, API automation, and production deployment best practices."
                },
                "content": "# Tailscale Network Management\n\n> **Trigger Keywords**: tailscale, tailnet, wireguard vpn, mesh vpn, tailscale ssh, exit node, subnet router, tailscale acl, magicDNS, tailscale serve, tailscale funnel\n\n**What is Tailscale?** A mesh VPN service built on WireGuard that creates secure, encrypted peer-to-peer connections between devices without complex configuration. Unlike traditional VPNs with central gateways, Tailscale creates direct connections between devices (or uses relay servers when needed).\n\n**Key Benefits:**\n- **Zero-config networking**: Works seamlessly across NAT and firewalls\n- **Direct connections**: Peer-to-peer mesh reduces latency vs traditional hub-and-spoke VPNs\n- **WireGuard encryption**: State-of-the-art cryptographic security\n- **Identity-based access**: Integrates with SSO providers (Google, Okta, GitHub, etc.)\n- **Cross-platform**: Works on Linux, macOS, Windows, iOS, Android, and more\n\n## Quick Start\n\n### Installation\n\n**Linux (one-liner):**\n```bash\ncurl -fsSL https://tailscale.com/install.sh | sh\n```\n\n**macOS:**\n```bash\nbrew install tailscale\n```\n\n**Windows/Other platforms:**\nDownload from https://tailscale.com/download\n\n### Initial Setup\n\n```bash\n# Start Tailscale and authenticate\nsudo tailscale up\n\n# Check status\ntailscale status\n\n# Get your Tailscale IP\ntailscale ip -4\n\n# Connect via MagicDNS hostname\nssh user@machine-name\n```\n\n## Common Operations\n\n### Basic Connection Management\n\n```bash\n# Connect to your tailnet\ntailscale up\n\n# Disconnect but keep daemon running\ntailscale down\n\n# Check connection status and peers\ntailscale status\n\n# View detailed network map\ntailscale status --json | jq\n\n# Ping another tailnet device (TSMP ping)\ntailscale ping machine-name\n\n# Test connectivity including ACLs (ICMP ping)\ntailscale ping --icmp machine-name\n```\n\n### Subnet Router Setup\n\n**What it does**: Allows devices without Tailscale to be accessible via a gateway device that does have Tailscale installed.\n\n**On the router device:**\n```bash\n# Enable IP forwarding (Linux)\necho 'net.ipv4.ip_forward = 1' | sudo tee -a /etc/sysctl.d/99-tailscale.conf\necho 'net.ipv6.conf.all.forwarding = 1' | sudo tee -a /etc/sysctl.d/99-tailscale.conf\nsudo sysctl -p /etc/sysctl.d/99-tailscale.conf\n\n# Advertise routes to your local network\nsudo tailscale up --advertise-routes=192.168.1.0/24,10.0.0.0/24\n```\n\n**In the admin console:**\n1. Go to Machines → find your subnet router\n2. Click menu → \"Edit route settings\"\n3. Enable the advertised routes\n\n**On client devices:**\n```bash\n# Linux needs explicit flag to accept routes\nsudo tailscale up --accept-routes\n\n# Other platforms accept routes automatically\n```\n\n### Exit Node Configuration\n\n**What it does**: Routes ALL internet traffic through a specific device on your tailnet (like a traditional VPN).\n\n**Setup exit node:**\n```bash\n# Enable IP forwarding (same as subnet router)\necho 'net.ipv4.ip_forward = 1' | sudo tee -a /etc/sysctl.d/99-tailscale.conf\necho 'net.ipv6.conf.all.forwarding = 1' | sudo tee -a /etc/sysctl.d/99-tailscale.conf\nsudo sysctl -p /etc/sysctl.d/99-tailscale.conf\n\n# Advertise as exit node\nsudo tailscale up --advertise-exit-node\n```\n\n**In admin console:**\n1. Go to Machines → find exit node\n2. Click menu → \"Edit route settings\"  \n3. Enable \"Use as exit node\"\n\n**Use exit node from another device:**\n```bash\n# Use specific exit node\ntailscale set --exit-node=exit-node-name\n\n# Use suggested exit node (auto-selects best)\ntailscale set --exit-node=auto:any\n\n# Allow LAN access while using exit node\ntailscale set --exit-node=exit-node-name --exit-node-allow-lan-access\n\n# Stop using exit node\ntailscale set --exit-node=\n```\n\n### Tailscale SSH Setup\n\n**What it does**: SSH without managing keys, using your Tailscale identity for authentication.\n\n**Enable SSH on server:**\n```bash\n# Enable Tailscale SSH server\nsudo tailscale set --ssh\n```\n\n**Configure access in admin console:**\nGo to Access Controls and add to the policy file:\n\n```json\n{\n  \"grants\": [\n    {\n      \"src\": [\"user@example.com\"],\n      \"dst\": [\"tag:servers\"],\n      \"ip\": [\"22\"]\n    }\n  ],\n  \"ssh\": [\n    {\n      \"action\": \"accept\",\n      \"src\": [\"user@example.com\"],\n      \"dst\": [\"tag:servers\"],\n      \"users\": [\"root\", \"ubuntu\", \"autogroup:nonroot\"]\n    }\n  ]\n}\n```\n\n**Connect from client:**\n```bash\n# No special setup needed on client!\nssh machine-name\n\n# Or use specific user\nssh ubuntu@machine-name\n\n# Works with SCP and SFTP too\nscp file.txt machine-name:/tmp/\n```\n\n**Check mode** (for high-security connections):\n```json\n{\n  \"ssh\": [\n    {\n      \"action\": \"check\",  // Requires recent SSO re-auth\n      \"src\": [\"user@example.com\"],\n      \"dst\": [\"tag:servers\"],\n      \"users\": [\"root\"]\n    }\n  ]\n}\n```\n\n### Serve and Funnel\n\n**Tailscale Serve** (share within your tailnet):\n```bash\n# Serve local web server to tailnet\ntailscale serve 3000\n\n# Serve specific path\ntailscale serve --https=443 --set-path=/app 8080\n\n# Serve static files\ntailscale serve --https=443 /var/www/html\n\n# Serve with TLS-terminated TCP\ntailscale serve --tls-terminated-tcp=5432 localhost:5432\n\n# Check status\ntailscale serve status\n\n# Turn off\ntailscale serve off\n```\n\n**Tailscale Funnel** (expose to public internet):\n```bash\n# Share to entire internet (must be on ports 443, 8443, or 10000)\ntailscale funnel 3000\n\n# Turn off\ntailscale funnel off\n```\n\n## Access Control Lists (ACLs)\n\n**Default policy** (allows all):\n```json\n{\n  \"acls\": [\n    {\n      \"action\": \"accept\",\n      \"src\": [\"*\"],\n      \"dst\": [\"*:*\"]\n    }\n  ]\n}\n```\n\n**Role-based access example:**\n```json\n{\n  \"groups\": {\n    \"group:engineering\": [\"user1@example.com\", \"user2@example.com\"],\n    \"group:ops\": [\"ops@example.com\"]\n  },\n  \"tagOwners\": {\n    \"tag:dev\": [\"group:engineering\"],\n    \"tag:prod\": [\"group:ops\"]\n  },\n  \"acls\": [\n    {\n      \"action\": \"accept\",\n      \"src\": [\"group:engineering\"],\n      \"dst\": [\"tag:dev:*\"]\n    },\n    {\n      \"action\": \"accept\",\n      \"src\": [\"group:ops\"],\n      \"dst\": [\"tag:prod:*\"]\n    }\n  ]\n}\n```\n\n**Modern Grants syntax** (recommended):\n```json\n{\n  \"grants\": [\n    {\n      \"src\": [\"group:engineering\"],\n      \"dst\": [\"tag:dev\"],\n      \"ip\": [\"*\"]\n    },\n    {\n      \"src\": [\"group:ops\"],\n      \"dst\": [\"tag:prod\"],\n      \"ip\": [\"22\", \"443\", \"80\"]\n    }\n  ]\n}\n```\n\n## Common Scenarios\n\n### Home Lab Access\n```bash\n# On home server\nsudo tailscale up --advertise-routes=192.168.1.0/24\n\n# From anywhere\nssh homeserver\n# Access 192.168.1.* devices through homeserver\n```\n\n### Secure Travel\n```bash\n# Set home device as exit node before trip\ntailscale set --exit-node=home-server\n\n# All traffic now routes through home\n```\n\n### Multi-Site Connectivity\n```bash\n# Site A router\nsudo tailscale up --advertise-routes=10.0.0.0/24\n\n# Site B router  \nsudo tailscale up --advertise-routes=10.1.0.0/24 --accept-routes\n\n# Now Site B can reach Site A's 10.0.0.0/24 network\n```\n\n## Troubleshooting\n\n### Connection Issues\n\n```bash\n# Check if devices can establish connection (ignores ACLs)\ntailscale ping --tsmp peer-name\n\n# Check end-to-end including ACLs\ntailscale ping --icmp peer-name\n\n# View network map and connection details\ntailscale netcheck\n\n# Debug daemon logs\ntailscale debug daemon-logs\n\n# Check DERP relay status\ntailscale netcheck\n```\n\n**If TSMP succeeds but ICMP fails**: ACL policy is blocking the connection.\n\n**If both fail**: Network connectivity issue (firewall, NAT, routing problem).\n\n### ACL Testing\n\n```bash\n# Preview rules for specific user (in admin console)\n# Access Controls → Preview rules → select user\n\n# Test ACL in policy file\n# Add to policy:\n\"tests\": [\n  {\n    \"src\": \"user@example.com\",\n    \"accept\": [\"tag:server:22\"],\n    \"deny\": [\"tag:prod:*\"]\n  }\n]\n```\n\n### Subnet Router Not Working\n\n```bash\n# Verify IP forwarding enabled\ncat /proc/sys/net/ipv4/ip_forward  # Should be 1\n\n# Check firewall isn't blocking\nsudo iptables -L -v -n\nsudo iptables -t nat -L -v -n\n\n# Verify routes advertised\ntailscale status | grep \"subnet router\"\n\n# On client, ensure routes accepted\ntailscale status | grep \"routes accepted\"\n```\n\n### MagicDNS Not Resolving\n\n```bash\n# Check MagicDNS enabled\ntailscale status | grep MagicDNS\n\n# In admin console: DNS → Enable MagicDNS\n\n# Flush DNS cache\n# macOS\nsudo dscacheutil -flushcache\n\n# Linux (systemd-resolved)\nsudo systemd-resolve --flush-caches\n```\n\n## Best Practices\n\n### Security\n\n✅ **Use tags for servers**: Never share with personal accounts\n```bash\nsudo tailscale up --advertise-tags=tag:server\n```\n\n✅ **Disable key expiry for servers**:\n- Admin console → Machines → menu → \"Disable key expiry\"\n- Or use `--auth-key` with reusable key\n\n✅ **Use check mode for root access**: Requires recent SSO re-authentication\n\n✅ **Principle of least privilege**: Grant only necessary ports in ACLs\n```json\n{\n  \"grants\": [{\n    \"src\": [\"group:devs\"],\n    \"dst\": [\"tag:dev\"],\n    \"ip\": [\"22\", \"80\", \"443\"]  // Only SSH and HTTP(S)\n  }]\n}\n```\n\n✅ **Enable Tailnet Lock** (enterprise): Cryptographically prevent unauthorized device additions\n\n### Operations\n\n✅ **Use auth keys for automation**:\n```bash\n# Generate in admin console → Settings → Keys\nsudo tailscale up --auth-key=tskey-auth-...\n```\n\n✅ **Tag infrastructure servers**: Enables service accounts instead of personal ownership\n\n✅ **Set up high-availability**:\n```bash\n# Multiple subnet routers with same routes = automatic failover\n# Router 1\nsudo tailscale up --advertise-routes=10.0.0.0/24\n\n# Router 2  \nsudo tailscale up --advertise-routes=10.0.0.0/24\n```\n\n✅ **Use GitOps for ACLs**: Version control your policy file with GitHub/GitLab\n\n✅ **Monitor with logging**: Enable network flow logs (Enterprise feature)\n\n### Performance\n\n✅ **Enable UDP GRO forwarding** (Linux subnet routers):\n```bash\nNETDEV=$(ip -o route get 8.8.8.8 | cut -f 5 -d \" \")\nsudo ethtool -K $NETDEV rx-udp-gro-forwarding on rx-gro-list off\n```\n\n✅ **Prefer direct connections**: Check with `tailscale status` - look for \"direct\"\n\n✅ **Use appropriate MTU**: Usually auto-detected correctly, but can tune if needed\n\n## Reference Files\n\n- `references/cli-reference.md` - Complete CLI command reference with all flags\n- `references/acl-examples.md` - Detailed ACL and grants configuration examples\n- `references/api-usage.md` - Tailscale API integration and automation\n- `references/troubleshooting.md` - Comprehensive troubleshooting guide\n- `references/production-setup.md` - Best practices for production deployments\n- `scripts/setup_subnet_router.sh` - Automated subnet router setup script\n- `scripts/setup_exit_node.sh` - Automated exit node setup script"
              }
            ]
          },
          {
            "name": "general",
            "description": "General development utilities including Mermaid diagram creation for software documentation",
            "source": "./plugins/general",
            "category": null,
            "version": "0.1.0",
            "author": {
              "name": "Jeb Coleman"
            },
            "install_commands": [
              "/plugin marketplace add el-feo/ai-context",
              "/plugin install general@jebs-dev-tools"
            ],
            "signals": {
              "stars": 0,
              "forks": 0,
              "pushed_at": "2026-01-12T05:23:19Z",
              "created_at": "2025-03-11T20:00:10Z",
              "license": "MIT"
            },
            "commands": [],
            "skills": [
              {
                "name": "mermaid-diagrams",
                "description": "Comprehensive guide for creating software diagrams using Mermaid syntax. Use when users need to create, visualize, or document software through diagrams including class diagrams (domain modeling, object-oriented design), sequence diagrams (application flows, API interactions, code execution), flowcharts (processes, algorithms, user journeys), entity relationship diagrams (database schemas), C4 architecture diagrams (system context, containers, components), state diagrams, git graphs, pie charts, gantt charts, or any other diagram type. Triggers include requests to \"diagram\", \"visualize\", \"model\", \"map out\", \"show the flow\", or when explaining system architecture, database design, code structure, or user/application flows.",
                "path": "plugins/general/skills/mermaid-diagrams/SKILL.md",
                "frontmatter": {
                  "name": "mermaid-diagrams",
                  "description": "Comprehensive guide for creating software diagrams using Mermaid syntax. Use when users need to create, visualize, or document software through diagrams including class diagrams (domain modeling, object-oriented design), sequence diagrams (application flows, API interactions, code execution), flowcharts (processes, algorithms, user journeys), entity relationship diagrams (database schemas), C4 architecture diagrams (system context, containers, components), state diagrams, git graphs, pie charts, gantt charts, or any other diagram type. Triggers include requests to \"diagram\", \"visualize\", \"model\", \"map out\", \"show the flow\", or when explaining system architecture, database design, code structure, or user/application flows."
                },
                "content": "# Mermaid Diagramming\n\nCreate professional software diagrams using Mermaid's text-based syntax. Mermaid renders diagrams from simple text definitions, making diagrams version-controllable, easy to update, and maintainable alongside code.\n\n## Core Syntax Structure\n\nAll Mermaid diagrams follow this pattern:\n\n```mermaid\ndiagramType\n  definition content\n```\n\n**Key principles:**\n- First line declares diagram type (e.g., `classDiagram`, `sequenceDiagram`, `flowchart`)\n- Use `%%` for comments\n- Line breaks and indentation improve readability but aren't required\n- Unknown words break diagrams; parameters fail silently\n\n## Diagram Type Selection Guide\n\n**Choose the right diagram type:**\n\n1. **Class Diagrams** - Domain modeling, OOP design, entity relationships\n   - Domain-driven design documentation\n   - Object-oriented class structures\n   - Entity relationships and dependencies\n\n2. **Sequence Diagrams** - Temporal interactions, message flows\n   - API request/response flows\n   - User authentication flows\n   - System component interactions\n   - Method call sequences\n\n3. **Flowcharts** - Processes, algorithms, decision trees\n   - User journeys and workflows\n   - Business processes\n   - Algorithm logic\n   - Deployment pipelines\n\n4. **Entity Relationship Diagrams (ERD)** - Database schemas\n   - Table relationships\n   - Data modeling\n   - Schema design\n\n5. **C4 Diagrams** - Software architecture at multiple levels\n   - System Context (systems and users)\n   - Container (applications, databases, services)\n   - Component (internal structure)\n   - Code (class/interface level)\n\n6. **State Diagrams** - State machines, lifecycle states\n7. **Git Graphs** - Version control branching strategies\n8. **Gantt Charts** - Project timelines, scheduling\n9. **Pie/Bar Charts** - Data visualization\n\n## Quick Start Examples\n\n### Class Diagram (Domain Model)\n```mermaid\nclassDiagram\n    Title -- Genre\n    Title *-- Season\n    Title *-- Review\n    User --> Review : creates\n    \n    class Title {\n        +string name\n        +int releaseYear\n        +play()\n    }\n    \n    class Genre {\n        +string name\n        +getTopTitles()\n    }\n```\n\n### Sequence Diagram (API Flow)\n```mermaid\nsequenceDiagram\n    participant User\n    participant API\n    participant Database\n    \n    User->>API: POST /login\n    API->>Database: Query credentials\n    Database-->>API: Return user data\n    alt Valid credentials\n        API-->>User: 200 OK + JWT token\n    else Invalid credentials\n        API-->>User: 401 Unauthorized\n    end\n```\n\n### Flowchart (User Journey)\n```mermaid\nflowchart TD\n    Start([User visits site]) --> Auth{Authenticated?}\n    Auth -->|No| Login[Show login page]\n    Auth -->|Yes| Dashboard[Show dashboard]\n    Login --> Creds[Enter credentials]\n    Creds --> Validate{Valid?}\n    Validate -->|Yes| Dashboard\n    Validate -->|No| Error[Show error]\n    Error --> Login\n```\n\n### ERD (Database Schema)\n```mermaid\nerDiagram\n    USER ||--o{ ORDER : places\n    ORDER ||--|{ LINE_ITEM : contains\n    PRODUCT ||--o{ LINE_ITEM : includes\n    \n    USER {\n        int id PK\n        string email UK\n        string name\n        datetime created_at\n    }\n    \n    ORDER {\n        int id PK\n        int user_id FK\n        decimal total\n        datetime created_at\n    }\n```\n\n## Detailed References\n\nFor in-depth guidance on specific diagram types, see:\n\n- **[references/class-diagrams.md](references/class-diagrams.md)** - Domain modeling, relationships (association, composition, aggregation, inheritance), multiplicity, methods/properties\n- **[references/sequence-diagrams.md](references/sequence-diagrams.md)** - Actors, participants, messages (sync/async), activations, loops, alt/opt/par blocks, notes\n- **[references/flowcharts.md](references/flowcharts.md)** - Node shapes, connections, decision logic, subgraphs, styling\n- **[references/erd-diagrams.md](references/erd-diagrams.md)** - Entities, relationships, cardinality, keys, attributes\n- **[references/c4-diagrams.md](references/c4-diagrams.md)** - System context, container, component diagrams, boundaries\n- **[references/advanced-features.md](references/advanced-features.md)** - Themes, styling, configuration, layout options\n\n## Best Practices\n\n1. **Start Simple** - Begin with core entities/components, add details incrementally\n2. **Use Meaningful Names** - Clear labels make diagrams self-documenting\n3. **Comment Extensively** - Use `%%` comments to explain complex relationships\n4. **Keep Focused** - One diagram per concept; split large diagrams into multiple focused views\n5. **Version Control** - Store `.mmd` files alongside code for easy updates\n6. **Add Context** - Include titles and notes to explain diagram purpose\n7. **Iterate** - Refine diagrams as understanding evolves\n\n## Configuration and Theming\n\nConfigure diagrams using frontmatter:\n\n```mermaid\n---\nconfig:\n  theme: base\n  themeVariables:\n    primaryColor: \"#ff6b6b\"\n---\nflowchart LR\n    A --> B\n```\n\n**Available themes:** default, forest, dark, neutral, base\n\n**Layout options:**\n- `layout: dagre` (default) - Classic balanced layout\n- `layout: elk` - Advanced layout for complex diagrams (requires integration)\n\n**Look options:**\n- `look: classic` - Traditional Mermaid style\n- `look: handDrawn` - Sketch-like appearance\n\n## Exporting and Rendering\n\n**Native support in:**\n- GitHub/GitLab - Automatically renders in Markdown\n- VS Code - With Markdown Mermaid extension\n- Notion, Obsidian, Confluence - Built-in support\n\n**Export options:**\n- [Mermaid Live Editor](https://mermaid.live) - Online editor with PNG/SVG export\n- Mermaid CLI - `npm install -g @mermaid-js/mermaid-cli` then `mmdc -i input.mmd -o output.png`\n- Docker - `docker run --rm -v $(pwd):/data minlag/mermaid-cli -i /data/input.mmd -o /data/output.png`\n\n## Common Pitfalls\n\n- **Breaking characters** - Avoid `{}` in comments, use proper escape sequences for special characters\n- **Syntax errors** - Misspellings break diagrams; validate syntax in Mermaid Live\n- **Overcomplexity** - Split complex diagrams into multiple focused views\n- **Missing relationships** - Document all important connections between entities\n\n## When to Create Diagrams\n\n**Always diagram when:**\n- Starting new projects or features\n- Documenting complex systems\n- Explaining architecture decisions\n- Designing database schemas\n- Planning refactoring efforts\n- Onboarding new team members\n\n**Use diagrams to:**\n- Align stakeholders on technical decisions\n- Document domain models collaboratively\n- Visualize data flows and system interactions\n- Plan before coding\n- Create living documentation that evolves with code"
              }
            ]
          },
          {
            "name": "ghpmplus",
            "description": "Autonomous GitHub Project Management with orchestrator-agent coordination, parallel task execution via git worktrees, state reconstruction, and failure recovery",
            "source": "./plugins/ghpmplus",
            "category": null,
            "version": "0.2.1",
            "author": {
              "name": "Jeb Coleman"
            },
            "install_commands": [
              "/plugin marketplace add el-feo/ai-context",
              "/plugin install ghpmplus@jebs-dev-tools"
            ],
            "signals": {
              "stars": 0,
              "forks": 0,
              "pushed_at": "2026-01-12T05:23:19Z",
              "created_at": "2025-03-11T20:00:10Z",
              "license": "MIT"
            },
            "commands": [
              {
                "name": "/auto-execute",
                "description": "Trigger the orchestrator-agent to autonomously execute a PRD from start to finish",
                "path": "plugins/ghpmplus/commands/auto-execute.md",
                "frontmatter": {
                  "description": "Trigger the orchestrator-agent to autonomously execute a PRD from start to finish",
                  "argument-hint": "prd=#<issue_number>",
                  "allowed-tools": [
                    "Read",
                    "Bash",
                    "Grep",
                    "Task"
                  ]
                },
                "content": "<objective>\nYou are the entry point for GHPMplus autonomous execution. Your job is to validate the PRD exists, confirm execution with the user, and then delegate to the orchestrator-agent via the Task tool to handle the complete workflow.\n</objective>\n\n<prerequisites>\n- `gh` CLI installed and authenticated (`gh auth status`)\n- Working directory is a git repository with GitHub remote\n- User has write access to repository issues\n- PRD issue must exist and be labeled \"PRD\"\n</prerequisites>\n\n<arguments>\n**Required:**\n- `prd=#N` - The PRD issue number to execute\n\n**Example:**\n```\n/ghpmplus:auto-execute prd=#42\n```\n</arguments>\n\n<usage_examples>\n\n**Standard usage:**\n\n```\n/ghpmplus:auto-execute prd=#42\n```\n\n→ Validates PRD #42 exists, shows summary, confirms with user, then triggers orchestrator\n\n**With existing Epics:**\n\n```\n/ghpmplus:auto-execute prd=#42\n```\n\n→ If PRD already has Epics, orchestrator will use existing breakdown instead of creating new\n\n</usage_examples>\n\n<operating_rules>\n\n- **Always validate** that the PRD issue exists and has the \"PRD\" label before proceeding\n- **Show PRD summary** to user before triggering execution\n- **Confirm execution** with user before delegating to orchestrator (this is a significant autonomous action)\n- **Do not create local artifacts** - all work happens via GitHub issues and the orchestrator\n- **Delegate fully** to the orchestrator-agent once confirmed - do not duplicate its workflow\n</operating_rules>\n\n<workflow>\n\n## Step 1: Parse Arguments\n\nExtract PRD number from arguments:\n\n```bash\n# Parse prd=#N from $ARGUMENTS\nPRD_NUMBER=$(echo \"$ARGUMENTS\" | grep -oE 'prd=#[0-9]+' | grep -oE '[0-9]+')\n\nif [ -z \"$PRD_NUMBER\" ]; then\n  echo \"ERROR: PRD number required\"\n  echo \"Usage: /ghpmplus:auto-execute prd=#<issue_number>\"\n  exit 1\nfi\n```\n\n## Step 2: Validate PRD Exists\n\n```bash\n# Verify PRD issue exists and has PRD label\nPRD_DATA=$(gh issue view \"$PRD_NUMBER\" --json title,body,labels,state,url 2>/dev/null)\n\nif [ -z \"$PRD_DATA\" ]; then\n  echo \"ERROR: Issue #$PRD_NUMBER not found\"\n  exit 1\nfi\n\n# Check for PRD label\nHAS_PRD_LABEL=$(echo \"$PRD_DATA\" | jq -r '.labels[].name' | grep -c \"^PRD$\" || echo \"0\")\n\nif [ \"$HAS_PRD_LABEL\" -eq 0 ]; then\n  echo \"WARNING: Issue #$PRD_NUMBER does not have 'PRD' label\"\n  echo \"This may not be a valid PRD. Proceeding anyway...\"\nfi\n\n# Check if PRD is open\nSTATE=$(echo \"$PRD_DATA\" | jq -r '.state')\nif [ \"$STATE\" = \"CLOSED\" ]; then\n  echo \"ERROR: PRD #$PRD_NUMBER is already closed\"\n  exit 1\nfi\n```\n\n## Step 3: Display PRD Summary\n\nExtract and display key information:\n\n```bash\nTITLE=$(echo \"$PRD_DATA\" | jq -r '.title')\nURL=$(echo \"$PRD_DATA\" | jq -r '.url')\n\necho \"## PRD Summary\"\necho \"\"\necho \"**Title:** $TITLE\"\necho \"**Issue:** #$PRD_NUMBER\"\necho \"**URL:** $URL\"\necho \"\"\n```\n\nAlso extract from body:\n- Summary section\n- Acceptance Criteria (high level)\n- Any existing Epics linked\n\n## Step 4: Check for Existing Work\n\n```bash\n# Get repository info\nOWNER=$(gh repo view --json owner -q '.owner.login')\nREPO=$(gh repo view --json name -q '.name')\n\n# Check for existing Epics linked to this PRD using GraphQL sub-issues API\ncat > /tmp/ghpmplus-subissues.graphql << 'GRAPHQL'\nquery($owner: String!, $repo: String!, $number: Int!) {\n  repository(owner: $owner, name: $repo) {\n    issue(number: $number) {\n      subIssues(first: 50) {\n        nodes {\n          number\n          title\n          state\n          labels(first: 10) {\n            nodes { name }\n          }\n        }\n      }\n    }\n  }\n}\nGRAPHQL\n\nEPICS=$(gh api graphql -F owner=\"$OWNER\" -F repo=\"$REPO\" -F number=$PRD_NUMBER \\\n  -f query=\"$(cat /tmp/ghpmplus-subissues.graphql)\" \\\n  --jq '.data.repository.issue.subIssues.nodes[] | select(.labels.nodes[].name == \"Epic\") | [.number, .title, .state] | @tsv' 2>/dev/null || echo \"\")\n\nif [ -n \"$EPICS\" ]; then\n  echo \"### Existing Epics Found\"\n  echo \"\"\n  echo \"$EPICS\" | while read line; do\n    NUM=$(echo \"$line\" | cut -f1)\n    TITLE=$(echo \"$line\" | cut -f2)\n    STATE=$(echo \"$line\" | cut -f3)\n    echo \"- #$NUM: $TITLE ($STATE)\"\n  done\n  echo \"\"\n  echo \"The orchestrator will use existing Epics instead of creating new ones.\"\nfi\n```\n\n## Step 5: Confirm Execution\n\nBefore delegating to orchestrator, confirm with user:\n\n```\nThis will trigger autonomous execution of PRD #$PRD_NUMBER.\n\nThe orchestrator will:\n1. Break down the PRD into Epics (if not already done)\n2. Break Epics into atomic Tasks\n3. Execute Tasks using TDD or Non-TDD workflows\n4. Create PRs for each Task\n5. Monitor CI and handle failures\n\nThis process may take significant time and will create multiple GitHub issues and PRs.\n\nProceed with autonomous execution?\n```\n\nUse `AskUserQuestion` tool if needed for confirmation.\n\n## Step 6: Delegate to Orchestrator\n\nOnce confirmed, delegate to the orchestrator-agent:\n\n```markdown\nUse the Task tool with subagent_type=\"ghpmplus:orchestrator\" to:\n\nExecute PRD #$PRD_NUMBER autonomously.\n\nContext:\n- PRD Title: $TITLE\n- PRD URL: $URL\n- Existing Epics: [list if any]\n\nThe orchestrator should:\n1. Fetch full PRD details\n2. Create or use existing Epics\n3. Create Tasks for each Epic\n4. Execute Tasks in appropriate order (respecting dependencies)\n5. Create PRs with conventional commits\n6. Monitor CI status\n7. Report completion status back to PRD issue\n```\n\n## Step 7: Report Initiation\n\nAfter delegation, report:\n\n```\nAutonomous Execution Initiated\n\nPRD: #$PRD_NUMBER - $TITLE\nOrchestrator: Delegated via Task tool\n\nThe orchestrator is now running. Progress will be posted to:\n- PRD issue: $URL\n- Individual Epic and Task issues as they are created\n\nYou can monitor progress by watching the PRD issue for updates.\n```\n\n</workflow>\n\n<error_handling>\n\n**If PRD not found:**\n- Report error with issue number\n- Suggest checking issue number or creating PRD first\n\n**If PRD is closed:**\n- Report that PRD is already closed\n- Suggest reopening if execution is still needed\n\n**If no PRD label:**\n- Warn but allow proceeding (user may have custom workflow)\n\n**If orchestrator delegation fails:**\n- Report the error\n- Suggest manual fallback using ghpm commands\n\n**If user declines confirmation:**\n- Exit gracefully\n- Suggest using manual ghpm commands for step-by-step control\n\n</error_handling>\n\n<success_criteria>\nCommand completes successfully when:\n\n1. PRD is validated and exists\n2. User confirms execution\n3. Orchestrator-agent is successfully delegated via Task tool\n4. Initiation message is displayed to user\n\nThe actual execution success is determined by the orchestrator-agent.\n</success_criteria>\n\n<output>\nAfter delegation, report:\n\n1. **PRD:** #<number> - <title>\n2. **Status:** Orchestrator delegated\n3. **Monitor:** Link to PRD issue for progress updates\n\n**Example Output:**\n\n```\nAutonomous Execution Initiated\n\nPRD: #42 - User Authentication System\nOrchestrator: Delegated via Task tool\nMonitor: https://github.com/owner/repo/issues/42\n\nProgress updates will be posted to the PRD issue.\n```\n\n</output>\n\n<related_commands>\n\n**GHPMplus Commands:**\n- `/ghpmplus:create-prd` - Create a new PRD (prerequisite for auto-execute)\n\n**Manual Workflow (if needed):**\n- `/ghpm:create-epics prd=#N` - Manually create Epics\n- `/ghpm:create-tasks epic=#N` - Manually create Tasks\n- `/ghpm:tdd-task task=#N` - Manually execute Tasks\n\n</related_commands>\n\nNow proceed:\n\n1. Parse arguments to extract PRD number\n2. Validate PRD exists and has appropriate label\n3. Display PRD summary to user\n4. Check for existing Epics\n5. Confirm execution with user\n6. Delegate to orchestrator-agent via Task tool\n7. Report initiation status"
              },
              {
                "name": "/create-prd",
                "description": "Create a PRD GitHub issue (labeled PRD) from user input and optionally add it to a GitHub Project",
                "path": "plugins/ghpmplus/commands/create-prd.md",
                "frontmatter": {
                  "description": "Create a PRD GitHub issue (labeled PRD) from user input and optionally add it to a GitHub Project",
                  "argument-hint": "<product idea or feature description>",
                  "allowed-tools": [
                    "Read",
                    "Bash",
                    "Grep",
                    "AskUserQuestion"
                  ]
                },
                "content": "<objective>\nYou are GHPMplus (GitHub Project Manager Plus). Convert user input into a high-quality Product Requirements Document (PRD) and publish it as a GitHub Issue. This is the first step in the GHPMplus autonomous workflow (PRD -> Epics -> Tasks -> Autonomous Execution).\n</objective>\n\n<prerequisites>\n- `gh` CLI installed and authenticated (`gh auth status`)\n- Working directory is a git repository with GitHub remote\n- User has write access to repository issues\n- Optional: `GHPM_PROJECT` environment variable pre-set (if not set, user will be prompted to select a project)\n- Optional: Repository has \"PRD\" label created\n</prerequisites>\n\n<arguments>\n**Required:**\n- Product idea, feature description, or problem statement (captured from user input via $ARGUMENTS)\n\n**Optional environment variables:**\n\n- `GHPM_PROJECT` - GitHub Project name to associate issue with. If not set, the command will query available projects for the repository owner and prompt for selection.\n</arguments>\n\n<usage_examples>\n\n**Detailed input (skips clarification):**\n\n```\n/ghpmplus:create-prd Build a user authentication system with email/password and OAuth support for enterprise customers who need SSO to reduce IT friction during onboarding\n```\n\n→ Detailed input (30+ words, has who/what/why) → Proceeds directly to PRD generation\n\n**Vague input (triggers clarification):**\n\n```\n/ghpmplus:create-prd Add a dashboard\n```\n\n→ Vague input (4 words, missing who/why/scope) → Presents clarifying questions:\n\n1. Who is the primary user? (Internal team, Customers, Admins, Developers)\n2. What problem does this solve? (Efficiency, Missing capability, UX, Compliance)\n3. What's the scope? (MVP, Feature complete, Production-ready, Enterprise-grade)\n\nAfter user responds → Generates PRD with enriched context\n\n**Complex feature (typically detailed enough):**\n\n```\n/ghpmplus:create-prd Add real-time collaboration features to the document editor, similar to Google Docs, so remote teams can co-edit documents without version conflicts\n```\n\n→ Detailed input → Proceeds directly to PRD generation\n\n**With project association (auto-prompt):**\n\n```\n/ghpmplus:create-prd Implement dark mode across the application for users with visual sensitivities to reduce eye strain\n```\n\n→ If `GHPM_PROJECT` not set, prompts: \"Which GitHub Project should this PRD be added to?\" with available projects\n\n**With project pre-set (skip prompt):**\n\n```bash\nexport GHPM_PROJECT=\"MyOrg/Q1 Roadmap\"\n/ghpmplus:create-prd Implement dark mode across the application for users with visual sensitivities to reduce eye strain\n```\n\n→ Skips project selection prompt and uses pre-set project\n\n</usage_examples>\n\n<operating_rules>\n\n- **For vague input:** Use `AskUserQuestion` tool to gather context before generating the PRD. See `<vagueness_detection>` for criteria.\n- **For detailed input:** Proceed directly to PRD generation. Make reasonable assumptions and explicitly record them under **Assumptions** and **Open Questions**.\n- Do not create or persist local markdown artifacts (no local PRD files). All artifacts must live in GitHub issue bodies/comments.\n- Use Markdown in the issue body. Make the PRD self-contained.\n- Keep scope crisp; if the request is broad, define a \"V1\" and park the rest in **Out of Scope** / **Future Ideas**.\n- Clarification should be quick (max 4 questions) - do not interrogate the user.\n</operating_rules>\n\n<prd_structure>\n\n## Required PRD Structure (Issue Body)\n\nUse this exact outline:\n\n```markdown\n# PRD: <Concise Name>\n\n## Summary\n## Problem / Opportunity\n## Goals (Success Metrics)\n## Non-Goals / Out of Scope\n## Users & Use Cases\n## Requirements\n- Functional Requirements\n- Non-Functional Requirements\n## UX / UI Notes (if relevant)\n## Data / Integrations (if relevant)\n## Risks / Edge Cases\n## Assumptions\n## Open Questions\n## Acceptance Criteria (high level)\n## Rollout / Release Notes (brief)\n## Implementation Notes (non-binding)\n(Keep this section minimal; do not over-prescribe.)\n```\n\n</prd_structure>\n\n<input_validation>\n\n## Validation Checks\n\nBefore proceeding, verify:\n\n```bash\n# 1. Verify gh CLI authentication\ngh auth status || { echo \"ERROR: Not authenticated. Run 'gh auth login'\"; exit 1; }\n\n# 2. Verify in git repository\ngit rev-parse --git-dir > /dev/null 2>&1 || { echo \"ERROR: Not in a git repository\"; exit 1; }\n\n# 3. Verify GitHub remote exists\ngh repo view --json nameWithOwner -q .nameWithOwner || { echo \"ERROR: No GitHub remote found\"; exit 1; }\n```\n\nIf $ARGUMENTS is empty or missing, report an error:\n\n```\nERROR: Product idea or feature description required\nUsage: /ghpmplus:create-prd <description>\n```\n\n</input_validation>\n\n<vagueness_detection>\n\n## Detecting Vague Input\n\nBefore generating the PRD, evaluate whether user input is sufficiently detailed. Input is considered **vague** if ANY of the following criteria are met:\n\n### Vagueness Criteria\n\n| Criterion           | Threshold                           | Example (Vague)           | Example (Detailed)                                                                                                                             |\n| ------------------- | ----------------------------------- | ------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------- |\n| **Too short**       | < 20 words                          | \"I want a dashboard\"      | \"Build an analytics dashboard for sales managers to track quarterly revenue, pipeline metrics, and team performance with drill-down by region\" |\n| **Missing 'who'**   | No target user/audience mentioned   | \"Add authentication\"      | \"Add OAuth2 authentication for enterprise customers who need SSO\"                                                                              |\n| **Missing 'what'**  | No specific functionality described | \"Improve performance\"     | \"Optimize database queries in the user search endpoint to reduce p95 latency below 200ms\"                                                      |\n| **Missing 'why'**   | No problem/goal articulated         | \"Add export feature\"      | \"Add CSV export for compliance reports so auditors can analyze data offline\"                                                                   |\n| **Ambiguous scope** | Could mean vastly different things  | \"Make it mobile-friendly\" | \"Create responsive layouts for the checkout flow that work on screens 320px to 768px wide\"                                                     |\n\n### Evaluation Process\n\n1. Count words in input (excluding common stop words for accuracy assessment)\n2. Scan for user/audience indicators: \"users\", \"customers\", \"admins\", \"managers\", \"developers\", etc.\n3. Scan for problem/goal indicators: \"so that\", \"in order to\", \"because\", \"to enable\", \"to reduce\", etc.\n4. Assess specificity: Does the input contain concrete details (numbers, specific features, constraints)?\n\n**If 2+ criteria are triggered:** Proceed to clarification step\n**If 0-1 criteria triggered:** Skip clarification, proceed directly to PRD generation\n\n</vagueness_detection>\n\n<clarification_questions>\n\n## Clarifying Questions\n\nWhen vague input is detected, use the `AskUserQuestion` tool to gather context. Select 2-4 questions based on what's missing from the input.\n\n### Question Templates\n\n**Q1: Target Users** (use when 'who' is missing)\n\n```json\n{\n  \"question\": \"Who is the primary user of this feature?\",\n  \"header\": \"Users\",\n  \"multiSelect\": false,\n  \"options\": [\n    {\"label\": \"End users/customers\", \"description\": \"People using the product directly\"},\n    {\"label\": \"Internal team members\", \"description\": \"Employees within the organization\"},\n    {\"label\": \"Administrators\", \"description\": \"Users who configure or manage the system\"},\n    {\"label\": \"Developers/API consumers\", \"description\": \"Technical users integrating with the system\"}\n  ]\n}\n```\n\n**Q2: Problem Being Solved** (use when 'why' is missing)\n\n```json\n{\n  \"question\": \"What problem does this solve for users?\",\n  \"header\": \"Problem\",\n  \"multiSelect\": false,\n  \"options\": [\n    {\"label\": \"Efficiency/speed\", \"description\": \"Reduce time or effort to complete tasks\"},\n    {\"label\": \"Missing capability\", \"description\": \"Enable something users currently cannot do\"},\n    {\"label\": \"User experience\", \"description\": \"Improve usability, accessibility, or satisfaction\"},\n    {\"label\": \"Compliance/security\", \"description\": \"Meet regulatory or security requirements\"}\n  ]\n}\n```\n\n**Q3: Core Capabilities** (use when 'what' is vague)\n\n```json\n{\n  \"question\": \"Which capabilities are most important?\",\n  \"header\": \"Features\",\n  \"multiSelect\": true,\n  \"options\": [\n    {\"label\": \"View/display data\", \"description\": \"Read-only access to information\"},\n    {\"label\": \"Create/edit content\", \"description\": \"CRUD operations on data\"},\n    {\"label\": \"Automation/workflows\", \"description\": \"Automated processes or triggers\"},\n    {\"label\": \"Reporting/analytics\", \"description\": \"Insights, charts, or exports\"}\n  ]\n}\n```\n\n**Q4: Technical Constraints** (use when scope is ambiguous)\n\n```json\n{\n  \"question\": \"Are there specific technical constraints?\",\n  \"header\": \"Constraints\",\n  \"multiSelect\": true,\n  \"options\": [\n    {\"label\": \"Must integrate with existing system\", \"description\": \"Needs to work with current infrastructure\"},\n    {\"label\": \"Performance-critical\", \"description\": \"High throughput or low latency required\"},\n    {\"label\": \"Mobile support required\", \"description\": \"Must work on mobile devices\"},\n    {\"label\": \"No constraints\", \"description\": \"Greenfield implementation\"}\n  ]\n}\n```\n\n**Q5: Scope/Priority** (use when input could mean many things)\n\n```json\n{\n  \"question\": \"What's the scope for the initial version?\",\n  \"header\": \"Scope\",\n  \"multiSelect\": false,\n  \"options\": [\n    {\"label\": \"MVP/proof of concept\", \"description\": \"Minimal viable version to validate the idea\"},\n    {\"label\": \"Feature complete for core use case\", \"description\": \"Fully functional for primary scenario\"},\n    {\"label\": \"Production-ready with edge cases\", \"description\": \"Robust handling of all scenarios\"},\n    {\"label\": \"Enterprise-grade\", \"description\": \"Scalability, security, and compliance built-in\"}\n  ]\n}\n```\n\n### Selecting Questions\n\nBased on vagueness detection results, select appropriate questions:\n\n| Missing Element  | Questions to Ask                                |\n| ---------------- | ----------------------------------------------- |\n| Who (users)      | Q1 (Target Users)                               |\n| Why (problem)    | Q2 (Problem Being Solved)                       |\n| What (features)  | Q3 (Core Capabilities)                          |\n| Scope unclear    | Q4 (Technical Constraints), Q5 (Scope/Priority) |\n| Multiple missing | Combine up to 4 questions maximum               |\n\n### Incorporating Responses\n\nAfter receiving user responses, append them to the original input before generating the PRD:\n\n```\nOriginal input: \"I want a dashboard\"\n\nEnriched context from clarification:\n- Target users: Internal team members\n- Problem: Efficiency/speed - reduce time to complete tasks\n- Capabilities: Reporting/analytics, View/display data\n- Scope: Feature complete for core use case\n\nGenerate PRD using both original input AND enriched context.\n```\n\n</clarification_questions>\n\n<workflow>\n## Step 1: Validate Environment\n\nRun input validation checks from previous section.\n\n## Step 2: Determine Repository and Owner\n\n```bash\nREPO=$(gh repo view --json nameWithOwner -q .nameWithOwner)\nOWNER=$(gh repo view --json owner -q .owner.login)\n```\n\n## Step 3: Select GitHub Project (if not pre-set)\n\nIf `GHPM_PROJECT` environment variable is already set, skip to Step 4.\n\nOtherwise, query available projects for the repository owner and prompt the user to select one:\n\n```bash\n# Get list of projects for the repo owner\nPROJECTS=$(gh project list --owner \"$OWNER\" --format json --limit 20)\n```\n\n**If projects exist:** Use `AskUserQuestion` to let the user select a project.\n\nBuild the question dynamically based on available projects:\n\n```json\n{\n  \"question\": \"Which GitHub Project should this PRD be added to?\",\n  \"header\": \"Project\",\n  \"multiSelect\": false,\n  \"options\": [\n    {\"label\": \"<Project Title 1>\", \"description\": \"Project #<number>\"},\n    {\"label\": \"<Project Title 2>\", \"description\": \"Project #<number>\"},\n    ...\n    {\"label\": \"None\", \"description\": \"Do not add to any project\"}\n  ]\n}\n```\n\n- Include up to 4 projects (the most recently updated, or first 4 returned)\n- Always include \"None\" as the last option\n- If user selects a project, set `GHPM_PROJECT` to the selected project title\n- If user selects \"None\", leave `GHPM_PROJECT` unset\n\n**If no projects exist:** Skip project selection and inform the user:\n\n```\nNo GitHub Projects found for owner '$OWNER'. Skipping project association.\nTo create a project, visit: https://github.com/<owner>?tab=projects\n```\n\n## Step 4: Evaluate Input & Clarify (if needed)\n\nEvaluate user input against the vagueness criteria in `<vagueness_detection>`.\n\n**If input is sufficiently detailed (0-1 criteria triggered):**\n\n- Skip to Step 5 (Draft PRD Content)\n\n**If input is vague (2+ criteria triggered):**\n\n1. Identify which elements are missing (who, what, why, scope)\n2. Select appropriate questions from `<clarification_questions>` (max 4)\n3. Use `AskUserQuestion` tool to present questions:\n\n```\nUse the AskUserQuestion tool with the selected question templates.\nWait for user responses before proceeding.\n```\n\n1. Combine original input with user responses to form enriched context\n2. Proceed to Step 5 with enriched context\n\n**Example clarification flow:**\n\nInput: \"I want a dashboard\"\n\nVagueness analysis:\n\n- ✗ Too short (4 words < 20)\n- ✗ Missing 'who' (no user mentioned)\n- ✗ Missing 'why' (no problem stated)\n- ✓ Has 'what' (dashboard is a feature)\n- ✗ Ambiguous scope (dashboard could mean many things)\n\n→ 4 criteria triggered → Ask Q1 (Users), Q2 (Problem), Q5 (Scope)\n\n## Step 5: Draft PRD Content\n\nBased on user input ($ARGUMENTS) and any enriched context from clarification, generate comprehensive PRD following the structure template.\n\n## Step 6: Create GitHub Issue\n\n```bash\n# Use heredoc to safely handle multiline content\ngh issue create \\\n  --repo \"$REPO\" \\\n  --title \"PRD: <Concise Name>\" \\\n  --label \"PRD\" \\\n  --body \"$(cat <<'EOF'\n<Generated PRD Content>\nEOF\n)\"\n```\n\n## Step 7: Add to GitHub Project\n\nUse the new GitHub Projects API (`gh project item-add`) instead of the deprecated `--add-project` flag.\n\n```bash\nif [ -n \"$GHPM_PROJECT\" ]; then\n  # Get the issue URL (needed for gh project item-add)\n  ISSUE_URL=$(gh issue list --repo \"$REPO\" -l PRD --limit 1 --json url -q '.[0].url')\n\n  # Get project number from the project list\n  # GHPM_PROJECT can be either the project title or number\n  if [[ \"$GHPM_PROJECT\" =~ ^[0-9]+$ ]]; then\n    PROJECT_NUMBER=\"$GHPM_PROJECT\"\n  else\n    # Look up project number by title\n    PROJECT_NUMBER=$(gh project list --owner \"$OWNER\" --format json | \\\n      jq -r --arg title \"$GHPM_PROJECT\" '.projects[] | select(.title == $title) | .number')\n  fi\n\n  if [ -n \"$PROJECT_NUMBER\" ]; then\n    gh project item-add \"$PROJECT_NUMBER\" --owner \"$OWNER\" --url \"$ISSUE_URL\" 2>/dev/null || {\n      echo \"WARNING: Failed to add issue to project '$GHPM_PROJECT'\"\n      ISSUE_NUMBER=$(echo \"$ISSUE_URL\" | grep -oE '[0-9]+$')\n      gh issue comment \"$ISSUE_NUMBER\" --body \"Note: Could not automatically add to project '$GHPM_PROJECT'. Please add manually if needed.\"\n    }\n  else\n    echo \"WARNING: Could not find project '$GHPM_PROJECT'\"\n  fi\nfi\n```\n\n**Note:** The `gh project item-add` command requires:\n- Project number (not title) - we look this up from the project list\n- Owner (user or organization)\n- Issue URL (not issue number)\n\n</workflow>\n\n<error_handling>\n**If gh CLI not authenticated:**\n\n- Check: `gh auth status`\n- Fix: `gh auth login`\n\n**If not in git repository:**\n\n- Navigate to repository directory\n- Verify with: `git status`\n\n**If no GitHub remote:**\n\n- Check remote: `git remote -v`\n- Add remote if needed: `git remote add origin <url>`\n\n**If label \"PRD\" doesn't exist:**\n\n- Create it: `gh label create PRD --description \"Product Requirements Document\" --color 0E8A16`\n- Or omit `--label \"PRD\"` from issue creation and continue\n\n**If issue creation fails:**\n\n- Check rate limits: `gh api rate_limit`\n- Verify write permissions: `gh repo view --json viewerPermission -q .viewerPermission`\n- Check repository exists and is accessible\n\n**If project association fails:**\n\n- Verify `GHPM_PROJECT` is either the project number or exact title\n- Check project exists: `gh project list --owner <OWNER>`\n- Ensure the new Projects API is used (`gh project item-add`), not the deprecated `--add-project` flag\n- Common error: \"Projects (classic) is being deprecated\" means you're using the old API\n- Command will continue and add warning comment to issue\n</error_handling>\n\n<success_criteria>\nCommand completes successfully when:\n\n1. PRD issue is created with \"PRD\" label\n2. Issue body contains all required sections from PRD structure\n3. Issue number and URL are captured\n4. If `GHPM_PROJECT` set, issue is added to project (or warning issued)\n\n**Verification:**\n\n```bash\n# View the created PRD\ngh issue view <issue_number>\n\n# List all PRD issues\ngh issue list -l PRD --json number,title,url\n```\n\n</success_criteria>\n\n<output>\nAfter completion, report:\n\n1. **PRD Issue:** #<number> - <URL>\n2. **Repository:** <owner>/<repo>\n3. **Project Association:**\n   - Success: \"Added to project '<GHPM_PROJECT>'\"\n   - Failure: \"WARNING: Could not add to project (see issue comment)\"\n   - N/A: \"No project specified\"\n4. **Next Step:** \"Run `/ghpmplus:auto-execute prd=#<number>` to autonomously execute this PRD\"\n\n**Example Output:**\n\n```\nPRD Created Successfully\n\nPRD Issue: #42 - https://github.com/owner/repo/issues/42\nRepository: owner/repo\nProject Association: Added to project 'Q1 Roadmap'\n\nNext Step: Run `/ghpmplus:auto-execute prd=#42` to autonomously execute this PRD\n```\n\n</output>\n\n<related_commands>\n**GHPMplus Workflow:**\n\n1. **Current:** `/ghpmplus:create-prd` - Create PRD from user input\n2. **Next:** `/ghpmplus:auto-execute prd=#N` - Trigger orchestrator for autonomous execution\n\nThe orchestrator agent will automatically:\n- Break PRD into Epics\n- Break Epics into Tasks\n- Execute Tasks via TDD or Non-TDD workflows (depending on commit type)\n- Create PRs and manage CI verification\n\n**Manual workflow (if needed):**\n\n- Use original ghpm commands for step-by-step control:\n  - `/ghpm:create-epics prd=#N`\n  - `/ghpm:create-tasks epic=#N`\n  - `/ghpm:tdd-task task=#N`\n</related_commands>\n\nNow proceed:\n\n1. Validate environment prerequisites.\n2. Determine repository and owner.\n3. If `GHPM_PROJECT` not set: Query projects for owner and prompt user to select one.\n4. Evaluate input against vagueness criteria.\n5. If vague (2+ criteria triggered): Use AskUserQuestion to gather context.\n6. Draft the PRD from $ARGUMENTS (and enriched context if clarified).\n7. Create the issue via `gh issue create`.\n8. Add it to the GitHub project if `GHPM_PROJECT` is set."
              }
            ],
            "skills": []
          }
        ]
      }
    }
  ]
}