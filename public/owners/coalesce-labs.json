{
  "owner": {
    "id": "coalesce-labs",
    "display_name": "coalesce-labs",
    "type": "Organization",
    "avatar_url": "https://avatars.githubusercontent.com/u/216886590?v=4",
    "url": "https://github.com/coalesce-labs",
    "bio": null,
    "stats": {
      "total_repos": 1,
      "total_plugins": 5,
      "total_commands": 36,
      "total_skills": 1,
      "total_stars": 6,
      "total_forks": 0
    }
  },
  "repos": [
    {
      "full_name": "coalesce-labs/catalyst",
      "url": "https://github.com/coalesce-labs/catalyst",
      "description": "Token-efficient Claude Code workspace with parallel agents and persistent memory. Research ‚Üí Plan ‚Üí Implement ‚Üí   Validate workflow.",
      "homepage": "",
      "signals": {
        "stars": 6,
        "forks": 0,
        "pushed_at": "2026-01-12T04:14:24Z",
        "created_at": "2025-10-04T11:10:26Z",
        "license": null
      },
      "file_tree": [
        {
          "path": ".claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude-plugin/marketplace.json",
          "type": "blob",
          "size": 4025
        },
        {
          "path": ".claude",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude/.gitignore",
          "type": "blob",
          "size": 174
        },
        {
          "path": ".claude/.personal",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude/.personal/.gitkeep",
          "type": "blob",
          "size": 152
        },
        {
          "path": ".claude/.personal/README.md",
          "type": "blob",
          "size": 5857
        },
        {
          "path": ".claude/config.example.json",
          "type": "blob",
          "size": 180
        },
        {
          "path": ".claude/config.json",
          "type": "blob",
          "size": 197
        },
        {
          "path": ".claude/config.template.json",
          "type": "blob",
          "size": 737
        },
        {
          "path": ".claude/plugins",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude/plugins/dev",
          "type": "blob",
          "size": 17
        },
        {
          "path": ".claude/plugins/meta",
          "type": "blob",
          "size": 18
        },
        {
          "path": ".claude/prompts",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude/prompts/README.md",
          "type": "blob",
          "size": 3501
        },
        {
          "path": ".claude/prompts/classify-issue.md.example",
          "type": "blob",
          "size": 2081
        },
        {
          "path": ".claude/prompts/custom-validation.md.example",
          "type": "blob",
          "size": 2618
        },
        {
          "path": ".gitignore",
          "type": "blob",
          "size": 939
        },
        {
          "path": ".markdownlintrc",
          "type": "blob",
          "size": 274
        },
        {
          "path": ".mcp.json.template",
          "type": "blob",
          "size": 1170
        },
        {
          "path": ".prettierrc",
          "type": "blob",
          "size": 210
        },
        {
          "path": ".trunk",
          "type": "tree",
          "size": null
        },
        {
          "path": ".trunk/actions",
          "type": "blob",
          "size": 71
        },
        {
          "path": ".trunk/logs",
          "type": "blob",
          "size": 68
        },
        {
          "path": ".trunk/notifications",
          "type": "blob",
          "size": 77
        },
        {
          "path": ".trunk/out",
          "type": "blob",
          "size": 67
        },
        {
          "path": ".trunk/plugins",
          "type": "tree",
          "size": null
        },
        {
          "path": ".trunk/plugins/trunk",
          "type": "blob",
          "size": 92
        },
        {
          "path": ".trunk/tools",
          "type": "blob",
          "size": 69
        },
        {
          "path": ".trunk/trunk.yaml",
          "type": "blob",
          "size": 1174
        },
        {
          "path": "CLAUDE.md",
          "type": "blob",
          "size": 29756
        },
        {
          "path": "COMMANDS_ANALYSIS.md",
          "type": "blob",
          "size": 4516
        },
        {
          "path": "CONTRIBUTING.md",
          "type": "blob",
          "size": 5916
        },
        {
          "path": "IMPLEMENTATION_STATUS.md",
          "type": "blob",
          "size": 11576
        },
        {
          "path": "Makefile",
          "type": "blob",
          "size": 2188
        },
        {
          "path": "PLUGIN_MIGRATION.md",
          "type": "blob",
          "size": 8688
        },
        {
          "path": "PM_ATTRIBUTION_AND_IMPROVEMENTS.md",
          "type": "blob",
          "size": 13399
        },
        {
          "path": "PM_PLUGIN_IMPLEMENTATION_GUIDE.md",
          "type": "blob",
          "size": 16792
        },
        {
          "path": "PM_REPORTING_COMPLETE_GUIDE.md",
          "type": "blob",
          "size": 15367
        },
        {
          "path": "POSTHOG_MCP_SETUP.md",
          "type": "blob",
          "size": 4217
        },
        {
          "path": "QUICKSTART.md",
          "type": "blob",
          "size": 14217
        },
        {
          "path": "README.md",
          "type": "blob",
          "size": 13066
        },
        {
          "path": "VALIDATION_SUMMARY.md",
          "type": "blob",
          "size": 6726
        },
        {
          "path": "artifacts",
          "type": "tree",
          "size": null
        },
        {
          "path": "artifacts/CLAUDE.md.workspace",
          "type": "blob",
          "size": 4181
        },
        {
          "path": "artifacts/README.md",
          "type": "blob",
          "size": 725
        },
        {
          "path": "docs",
          "type": "tree",
          "size": null
        },
        {
          "path": "docs/AGENTIC_WORKFLOW_GUIDE.md",
          "type": "blob",
          "size": 20606
        },
        {
          "path": "docs/BEST_PRACTICES.md",
          "type": "blob",
          "size": 26923
        },
        {
          "path": "docs/CONTEXT_ENGINEERING.md",
          "type": "blob",
          "size": 32097
        },
        {
          "path": "docs/DEEPWIKI_INTEGRATION.md",
          "type": "blob",
          "size": 15760
        },
        {
          "path": "docs/FRONTMATTER_STANDARD.md",
          "type": "blob",
          "size": 11072
        },
        {
          "path": "docs/HUMANLAYER_COMMANDS_ANALYSIS.md",
          "type": "blob",
          "size": 12269
        },
        {
          "path": "docs/LINEAR_WORKFLOW_AUTOMATION.md",
          "type": "blob",
          "size": 11392
        },
        {
          "path": "docs/MCP_MANAGEMENT_STRATEGY.md",
          "type": "blob",
          "size": 11622
        },
        {
          "path": "docs/MCP_SESSION_WORKFLOW.md",
          "type": "blob",
          "size": 6287
        },
        {
          "path": "docs/MULTI_CONFIG_GUIDE.md",
          "type": "blob",
          "size": 5744
        },
        {
          "path": "docs/MULTI_PROJECT_SENTRY.md",
          "type": "blob",
          "size": 7873
        },
        {
          "path": "docs/PATTERNS.md",
          "type": "blob",
          "size": 31304
        },
        {
          "path": "docs/PLUGIN_ARCHITECTURE_PROPOSAL.md",
          "type": "blob",
          "size": 10803
        },
        {
          "path": "docs/PLUGIN_MCP_VALIDATION.md",
          "type": "blob",
          "size": 11623
        },
        {
          "path": "docs/PLUGIN_USAGE_GUIDE.md",
          "type": "blob",
          "size": 8449
        },
        {
          "path": "docs/PLUGIN_VERSIONING.md",
          "type": "blob",
          "size": 6539
        },
        {
          "path": "docs/PR_LIFECYCLE.md",
          "type": "blob",
          "size": 13958
        },
        {
          "path": "docs/README.md",
          "type": "blob",
          "size": 6319
        },
        {
          "path": "docs/SMART_SETUP.md",
          "type": "blob",
          "size": 5290
        },
        {
          "path": "docs/SMART_SETUP_SUMMARY.md",
          "type": "blob",
          "size": 9093
        },
        {
          "path": "docs/THOUGHTS_SETUP.md",
          "type": "blob",
          "size": 5852
        },
        {
          "path": "docs/USAGE.md",
          "type": "blob",
          "size": 27937
        },
        {
          "path": "docs/WORKFLOW_DISCOVERY_SYSTEM.md",
          "type": "blob",
          "size": 18710
        },
        {
          "path": "linearis-research-2025-10-27.md",
          "type": "blob",
          "size": 16260
        },
        {
          "path": "plugins",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/analytics",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/analytics/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/analytics/.claude-plugin/.mcp.json",
          "type": "blob",
          "size": 326
        },
        {
          "path": "plugins/analytics/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 635
        },
        {
          "path": "plugins/analytics/README.md",
          "type": "blob",
          "size": 4056
        },
        {
          "path": "plugins/analytics/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/analytics/commands/analyze_user_behavior.md",
          "type": "blob",
          "size": 2643
        },
        {
          "path": "plugins/analytics/commands/product_metrics.md",
          "type": "blob",
          "size": 2402
        },
        {
          "path": "plugins/analytics/commands/segment_analysis.md",
          "type": "blob",
          "size": 3260
        },
        {
          "path": "plugins/debugging",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/debugging/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/debugging/.claude-plugin/.mcp.json",
          "type": "blob",
          "size": 294
        },
        {
          "path": "plugins/debugging/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 662
        },
        {
          "path": "plugins/debugging/README.md",
          "type": "blob",
          "size": 5430
        },
        {
          "path": "plugins/debugging/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/debugging/commands/debug_production_error.md",
          "type": "blob",
          "size": 4155
        },
        {
          "path": "plugins/debugging/commands/error_impact_analysis.md",
          "type": "blob",
          "size": 3508
        },
        {
          "path": "plugins/debugging/commands/trace_analysis.md",
          "type": "blob",
          "size": 4132
        },
        {
          "path": "plugins/dev",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/dev/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/dev/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 664
        },
        {
          "path": "plugins/dev/HOOKS.md",
          "type": "blob",
          "size": 6551
        },
        {
          "path": "plugins/dev/README.md",
          "type": "blob",
          "size": 4714
        },
        {
          "path": "plugins/dev/WORKFLOW_CONTEXT.md",
          "type": "blob",
          "size": 10398
        },
        {
          "path": "plugins/dev/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/dev/agents/.linearis-syntax-reference.md",
          "type": "blob",
          "size": 5430
        },
        {
          "path": "plugins/dev/agents/README.md",
          "type": "blob",
          "size": 10202
        },
        {
          "path": "plugins/dev/agents/codebase-analyzer.md",
          "type": "blob",
          "size": 6459
        },
        {
          "path": "plugins/dev/agents/codebase-locator.md",
          "type": "blob",
          "size": 4855
        },
        {
          "path": "plugins/dev/agents/codebase-pattern-finder.md",
          "type": "blob",
          "size": 8803
        },
        {
          "path": "plugins/dev/agents/external-research.md",
          "type": "blob",
          "size": 9682
        },
        {
          "path": "plugins/dev/agents/github-research.md",
          "type": "blob",
          "size": 2821
        },
        {
          "path": "plugins/dev/agents/linear-research.md",
          "type": "blob",
          "size": 4758
        },
        {
          "path": "plugins/dev/agents/railway-research.md",
          "type": "blob",
          "size": 2896
        },
        {
          "path": "plugins/dev/agents/sentry-research.md",
          "type": "blob",
          "size": 3529
        },
        {
          "path": "plugins/dev/agents/thoughts-analyzer.md",
          "type": "blob",
          "size": 5234
        },
        {
          "path": "plugins/dev/agents/thoughts-locator.md",
          "type": "blob",
          "size": 5083
        },
        {
          "path": "plugins/dev/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/dev/commands/.auto-discover-pattern.md",
          "type": "blob",
          "size": 5599
        },
        {
          "path": "plugins/dev/commands/README.md",
          "type": "blob",
          "size": 1430
        },
        {
          "path": "plugins/dev/commands/commit.md",
          "type": "blob",
          "size": 5325
        },
        {
          "path": "plugins/dev/commands/create_handoff.md",
          "type": "blob",
          "size": 6609
        },
        {
          "path": "plugins/dev/commands/create_plan.md",
          "type": "blob",
          "size": 18851
        },
        {
          "path": "plugins/dev/commands/create_pr.md",
          "type": "blob",
          "size": 8281
        },
        {
          "path": "plugins/dev/commands/create_worktree.md",
          "type": "blob",
          "size": 3303
        },
        {
          "path": "plugins/dev/commands/cycle_plan.md",
          "type": "blob",
          "size": 3768
        },
        {
          "path": "plugins/dev/commands/cycle_review.md",
          "type": "blob",
          "size": 4948
        },
        {
          "path": "plugins/dev/commands/debug.md",
          "type": "blob",
          "size": 5937
        },
        {
          "path": "plugins/dev/commands/describe_pr.md",
          "type": "blob",
          "size": 12405
        },
        {
          "path": "plugins/dev/commands/implement_plan.md",
          "type": "blob",
          "size": 5912
        },
        {
          "path": "plugins/dev/commands/linear.md",
          "type": "blob",
          "size": 14294
        },
        {
          "path": "plugins/dev/commands/merge_pr.md",
          "type": "blob",
          "size": 12864
        },
        {
          "path": "plugins/dev/commands/research_codebase.md",
          "type": "blob",
          "size": 22522
        },
        {
          "path": "plugins/dev/commands/resume_handoff.md",
          "type": "blob",
          "size": 9020
        },
        {
          "path": "plugins/dev/commands/roadmap_review.md",
          "type": "blob",
          "size": 3293
        },
        {
          "path": "plugins/dev/commands/validate_plan.md",
          "type": "blob",
          "size": 6179
        },
        {
          "path": "plugins/dev/commands/workflow_help.md",
          "type": "blob",
          "size": 14863
        },
        {
          "path": "plugins/dev/hooks.toml",
          "type": "blob",
          "size": 2928
        },
        {
          "path": "plugins/dev/hooks",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/dev/hooks/update-workflow-context.sh",
          "type": "blob",
          "size": 2385
        },
        {
          "path": "plugins/dev/scripts",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/dev/scripts/check-prerequisites.sh",
          "type": "blob",
          "size": 1662
        },
        {
          "path": "plugins/dev/scripts/create-worktree.sh",
          "type": "blob",
          "size": 5035
        },
        {
          "path": "plugins/dev/scripts/frontmatter-utils.sh",
          "type": "blob",
          "size": 1410
        },
        {
          "path": "plugins/dev/scripts/workflow-context.sh",
          "type": "blob",
          "size": 2063
        },
        {
          "path": "plugins/dev/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/dev/skills/linearis",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/dev/skills/linearis/SKILL.md",
          "type": "blob",
          "size": 7006
        },
        {
          "path": "plugins/dev/templates",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/dev/templates/config.template.json",
          "type": "blob",
          "size": 845
        },
        {
          "path": "plugins/meta",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/meta/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/meta/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 575
        },
        {
          "path": "plugins/meta/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/meta/commands/create_workflow.md",
          "type": "blob",
          "size": 12305
        },
        {
          "path": "plugins/meta/commands/discover_workflows.md",
          "type": "blob",
          "size": 8570
        },
        {
          "path": "plugins/meta/commands/import_workflow.md",
          "type": "blob",
          "size": 7614
        },
        {
          "path": "plugins/meta/commands/validate_frontmatter.md",
          "type": "blob",
          "size": 15392
        },
        {
          "path": "plugins/meta/commands/workflow_help.md",
          "type": "blob",
          "size": 14863
        },
        {
          "path": "plugins/meta/scripts",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/meta/scripts/check-prerequisites.sh",
          "type": "blob",
          "size": 1662
        },
        {
          "path": "plugins/pm",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/pm/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/pm/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 994
        },
        {
          "path": "plugins/pm/README.md",
          "type": "blob",
          "size": 13513
        },
        {
          "path": "plugins/pm/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/pm/agents/backlog-analyzer.md",
          "type": "blob",
          "size": 4523
        },
        {
          "path": "plugins/pm/agents/calendar-analyzer.md",
          "type": "blob",
          "size": 10165
        },
        {
          "path": "plugins/pm/agents/code-classifier.md",
          "type": "blob",
          "size": 12104
        },
        {
          "path": "plugins/pm/agents/context-analyzer.md",
          "type": "blob",
          "size": 8979
        },
        {
          "path": "plugins/pm/agents/cycle-analyzer.md",
          "type": "blob",
          "size": 6587
        },
        {
          "path": "plugins/pm/agents/github-linear-analyzer.md",
          "type": "blob",
          "size": 5622
        },
        {
          "path": "plugins/pm/agents/github-metrics.md",
          "type": "blob",
          "size": 8437
        },
        {
          "path": "plugins/pm/agents/health-scorer.md",
          "type": "blob",
          "size": 14850
        },
        {
          "path": "plugins/pm/agents/linear-metrics.md",
          "type": "blob",
          "size": 9950
        },
        {
          "path": "plugins/pm/agents/linear-research.md",
          "type": "blob",
          "size": 5299
        },
        {
          "path": "plugins/pm/agents/milestone-analyzer.md",
          "type": "blob",
          "size": 5493
        },
        {
          "path": "plugins/pm/agents/thoughts-metrics.md",
          "type": "blob",
          "size": 11294
        },
        {
          "path": "plugins/pm/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/pm/commands/analyze_cycle.md",
          "type": "blob",
          "size": 8025
        },
        {
          "path": "plugins/pm/commands/analyze_milestone.md",
          "type": "blob",
          "size": 5086
        },
        {
          "path": "plugins/pm/commands/context_daily.md",
          "type": "blob",
          "size": 11829
        },
        {
          "path": "plugins/pm/commands/groom_backlog.md",
          "type": "blob",
          "size": 5890
        },
        {
          "path": "plugins/pm/commands/report_daily.md",
          "type": "blob",
          "size": 5671
        },
        {
          "path": "plugins/pm/commands/sync_prs.md",
          "type": "blob",
          "size": 5987
        },
        {
          "path": "plugins/pm/plugin.json",
          "type": "blob",
          "size": 4204
        },
        {
          "path": "plugins/pm/scripts",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/pm/scripts/check-prerequisites.sh",
          "type": "blob",
          "size": 1837
        },
        {
          "path": "plugins/pm/scripts/pm-utils.sh",
          "type": "blob",
          "size": 1116
        },
        {
          "path": "plugins/pm/scripts/test-script-resolution.sh",
          "type": "blob",
          "size": 1287
        },
        {
          "path": "plugins/pm/scripts/workflow-context.sh",
          "type": "blob",
          "size": 2063
        },
        {
          "path": "plugins/pm/templates",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/pm/templates/README.md",
          "type": "blob",
          "size": 10359
        },
        {
          "path": "plugins/pm/templates/config.yml.example",
          "type": "blob",
          "size": 3700
        },
        {
          "path": "plugins/pm/templates/github-actions",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/pm/templates/github-actions/SETUP.md",
          "type": "blob",
          "size": 9185
        },
        {
          "path": "plugins/pm/templates/github-actions/context-daily.yml.template",
          "type": "blob",
          "size": 12339
        },
        {
          "path": "plugins/pm/templates/github-actions/setup.sh",
          "type": "blob",
          "size": 5009
        },
        {
          "path": "plugins/pm/templates/reports",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/pm/templates/reports/CONTEXT_ENGINEERING_DAILY.md",
          "type": "blob",
          "size": 8893
        },
        {
          "path": "plugins/pm/templates/reports/CYCLE_EXAMPLE.md",
          "type": "blob",
          "size": 10609
        },
        {
          "path": "plugins/pm/templates/reports/DAILY_EXAMPLE.md",
          "type": "blob",
          "size": 3128
        },
        {
          "path": "plugins/pm/templates/reports/DASHBOARD_EXAMPLE.md",
          "type": "blob",
          "size": 8035
        },
        {
          "path": "plugins/pm/templates/reports/MARKDOWN_TABLES_FIX.md",
          "type": "blob",
          "size": 2183
        },
        {
          "path": "plugins/pm/templates/reports/MONTHLY_EXAMPLE.md",
          "type": "blob",
          "size": 12463
        },
        {
          "path": "plugins/pm/templates/reports/WEEKLY_EXAMPLE.md",
          "type": "blob",
          "size": 9094
        },
        {
          "path": "pm-plugin-review-2025-10-27.md",
          "type": "blob",
          "size": 14812
        },
        {
          "path": "research",
          "type": "tree",
          "size": null
        },
        {
          "path": "research/2025-10-25-agent-tool-matrix.md",
          "type": "blob",
          "size": 3941
        },
        {
          "path": "research/2025-10-25-catalyst-2-plugin-structure.md",
          "type": "blob",
          "size": 7648
        },
        {
          "path": "research/2025-10-25-catalyst-final-aligned-structure.md",
          "type": "blob",
          "size": 19558
        },
        {
          "path": "research/2025-10-25-catalyst-final-plugin-structure.md",
          "type": "blob",
          "size": 20719
        },
        {
          "path": "research/2025-10-25-catalyst-migration-plan.md",
          "type": "blob",
          "size": 18842
        },
        {
          "path": "research/2025-10-25-catalyst-plugin-organization-proposal.md",
          "type": "blob",
          "size": 17992
        },
        {
          "path": "research/2025-10-25-catalyst-tooling-integration-plan.md",
          "type": "blob",
          "size": 11544
        },
        {
          "path": "research/2025-10-25-claude-code-plugin-packaging-strategy.md",
          "type": "blob",
          "size": 35067
        },
        {
          "path": "research/2025-10-25-config-file-strategy.md",
          "type": "blob",
          "size": 6732
        },
        {
          "path": "research/2025-10-25-plugin-cleanup-research.md",
          "type": "blob",
          "size": 8527
        },
        {
          "path": "research/2025-10-25-script-packaging-strategy.md",
          "type": "blob",
          "size": 20097
        },
        {
          "path": "research/2025-10-26-documentation-audit.md",
          "type": "blob",
          "size": 21086
        },
        {
          "path": "research/2025-10-26-remaining-documentation-work-plan.md",
          "type": "blob",
          "size": 12461
        },
        {
          "path": "scripts",
          "type": "tree",
          "size": null
        },
        {
          "path": "scripts/INTEGRATION_GUIDE.md",
          "type": "blob",
          "size": 7552
        },
        {
          "path": "scripts/README.md",
          "type": "blob",
          "size": 8188
        },
        {
          "path": "scripts/bump-version.sh",
          "type": "blob",
          "size": 3636
        },
        {
          "path": "scripts/catalyst-integration-helpers.sh",
          "type": "blob",
          "size": 6989
        },
        {
          "path": "scripts/check-plugin-version.sh",
          "type": "blob",
          "size": 2450
        },
        {
          "path": "scripts/humanlayer",
          "type": "tree",
          "size": null
        },
        {
          "path": "scripts/humanlayer/add-client-config",
          "type": "blob",
          "size": 1078
        },
        {
          "path": "scripts/humanlayer/init-project.sh",
          "type": "blob",
          "size": 2096
        },
        {
          "path": "scripts/humanlayer/setup-personal-thoughts.sh",
          "type": "blob",
          "size": 4527
        },
        {
          "path": "scripts/humanlayer/setup-thoughts.sh",
          "type": "blob",
          "size": 3837
        },
        {
          "path": "scripts/linear",
          "type": "tree",
          "size": null
        },
        {
          "path": "scripts/linear/setup-linear-workflow",
          "type": "blob",
          "size": 8548
        },
        {
          "path": "scripts/load-catalyst-config.sh",
          "type": "blob",
          "size": 980
        },
        {
          "path": "scripts/sentry-project-helper.sh",
          "type": "blob",
          "size": 5138
        },
        {
          "path": "scripts/setup-catalyst-config.sh",
          "type": "blob",
          "size": 2293
        },
        {
          "path": "scripts/smart-linear-config.sh",
          "type": "blob",
          "size": 6949
        },
        {
          "path": "scripts/smart-sentry-config.sh",
          "type": "blob",
          "size": 9730
        },
        {
          "path": "scripts/validate-thoughts-setup.sh",
          "type": "blob",
          "size": 1964
        },
        {
          "path": "setup-catalyst.sh",
          "type": "blob",
          "size": 52721
        }
      ],
      "marketplace": {
        "name": "catalyst",
        "version": "1.0.0",
        "description": "Research-driven development workflow with Linear integration, PM tools, and infrastructure research agents",
        "owner_info": {
          "name": "Coalesce Labs",
          "email": "hello@coalesce.dev"
        },
        "keywords": [],
        "plugins": [
          {
            "name": "catalyst-dev",
            "description": "Core development workflow: research ‚Üí plan ‚Üí implement ‚Üí validate ‚Üí ship. Includes 10 research agents, workflow commands, Linear integration, handoff system. Always enabled. ~3.5k context (lightweight MCPs: DeepWiki, Context7).",
            "source": "./plugins/dev",
            "category": "development",
            "version": "3.0.1",
            "author": {
              "name": "Coalesce Labs",
              "email": "hello@coalesce.dev"
            },
            "install_commands": [
              "/plugin marketplace add coalesce-labs/catalyst",
              "/plugin install catalyst-dev@catalyst"
            ],
            "signals": {
              "stars": 6,
              "forks": 0,
              "pushed_at": "2026-01-12T04:14:24Z",
              "created_at": "2025-10-04T11:10:26Z",
              "license": null
            },
            "commands": [
              {
                "name": "/.auto-discover-pattern",
                "description": null,
                "path": "plugins/dev/commands/.auto-discover-pattern.md",
                "frontmatter": null,
                "content": "# Auto-Discovery Pattern for Workflow Commands\n\nThis document defines the standard pattern for commands that should automatically discover recent documents from workflow context.\n\n## The Problem\n\nCommands have bash scripts to check workflow context, but they're **suggestions** for Claude - not guaranteed to execute. Users shouldn't have to paste file paths when we just created the file.\n\n## The Solution\n\n**Explicit, mandatory auto-discovery at the start of every workflow command.**\n\n## Standard Pattern\n\n### 1. Initial Response (REQUIRED)\n\nEvery workflow command must start with this EXACT pattern:\n\n```markdown\n## Initial Response\n\nWhen this command is invoked, IMMEDIATELY run this bash script BEFORE responding to the user:\n\n```bash\n# Auto-discover recent document from workflow context\nif [[ -f \"${CLAUDE_PLUGIN_ROOT}/scripts/workflow-context.sh\" ]]; then\n  RECENT_DOC=$(\"${CLAUDE_PLUGIN_ROOT}/scripts/workflow-context.sh\" recent <TYPE>)\n  if [[ -n \"$RECENT_DOC\" ]]; then\n    echo \"üìã Auto-discovered recent <TYPE>: $RECENT_DOC\"\n    echo \"\"\n  fi\nfi\n```\n\n**Replace `<TYPE>` with:** `handoffs`, `plans`, `research`, or `prs`\n\n**CRITICAL**: This bash script MUST be executed FIRST, before any other response.\n```\n\n### 2. Logic Flow (REQUIRED)\n\nAfter running the auto-discovery script:\n\n```markdown\n1. **If user provided a file path as parameter**:\n   - Use that path (user override)\n   - Proceed with the command\n\n2. **If no parameter provided but RECENT_DOC found**:\n   - Show the user: \"Found recent <TYPE>: $RECENT_DOC\"\n   - Ask: \"Proceed with this document? [Y/n]\"\n   - If yes: proceed with RECENT_DOC\n   - If no: ask for document path\n\n3. **If no parameter and no RECENT_DOC found**:\n   - List available documents (if applicable)\n   - Ask user for document path\n```\n\n### 3. Command-Specific Examples\n\n#### `/resume-handoff`\n\n```markdown\n## Initial Response\n\nIMMEDIATELY run this bash script BEFORE responding:\n\n```bash\n# Auto-discover recent handoff\nif [[ -f \"${CLAUDE_PLUGIN_ROOT}/scripts/workflow-context.sh\" ]]; then\n  RECENT_HANDOFF=$(\"${CLAUDE_PLUGIN_ROOT}/scripts/workflow-context.sh\" recent handoffs)\n  if [[ -n \"$RECENT_HANDOFF\" ]]; then\n    echo \"üìã Auto-discovered recent handoff: $RECENT_HANDOFF\"\n    echo \"\"\n  fi\nfi\n```\n\nThen apply logic:\n1. User provided path? ‚Üí Use it\n2. RECENT_HANDOFF found? ‚Üí Ask to proceed with it\n3. Nothing found? ‚Üí Show available handoffs and ask\n```\n\n#### `/implement-plan`\n\n```markdown\n## Initial Response\n\nIMMEDIATELY run this bash script BEFORE responding:\n\n```bash\n# Auto-discover recent plan\nif [[ -f \"${CLAUDE_PLUGIN_ROOT}/scripts/workflow-context.sh\" ]]; then\n  RECENT_PLAN=$(\"${CLAUDE_PLUGIN_ROOT}/scripts/workflow-context.sh\" recent plans)\n  if [[ -n \"$RECENT_PLAN\" ]]; then\n    echo \"üìã Auto-discovered recent plan: $RECENT_PLAN\"\n    echo \"\"\n  fi\nfi\n```\n\nThen apply logic:\n1. User provided path? ‚Üí Use it\n2. RECENT_PLAN found? ‚Üí Ask to proceed with it\n3. Nothing found? ‚Üí Ask for plan path\n```\n\n#### `/create-plan`\n\nNote: This command doesn't auto-discover (it creates new), but should reference recent research:\n\n```markdown\n## Context Gathering\n\nAfter understanding the task, suggest recent research:\n\n```bash\n# Find recent research that might be relevant\nif [[ -f \"${CLAUDE_PLUGIN_ROOT}/scripts/workflow-context.sh\" ]]; then\n  RECENT_RESEARCH=$(\"${CLAUDE_PLUGIN_ROOT}/scripts/workflow-context.sh\" recent research)\n  if [[ -n \"$RECENT_RESEARCH\" ]]; then\n    echo \"üí° Found recent research: $RECENT_RESEARCH\"\n    echo \"Would you like me to reference this research in the plan?\"\n  fi\nfi\n```\n```\n\n## Key Principles\n\n1. **Execute First, Ask Later**: Run auto-discovery BEFORE any user interaction\n2. **Make it Visible**: Always show what was found with emoji indicator\n3. **Allow Override**: User-provided paths always take precedence\n4. **Graceful Fallback**: If nothing found, proceed with normal flow\n5. **Confirm Before Proceeding**: Ask user to confirm auto-discovered document\n\n## Commands That Need Auto-Discovery\n\n### High Priority (Must Have)\n- `/resume-handoff` ‚Üí auto-find recent handoff ‚úÖ (partially implemented)\n- `/implement-plan` ‚Üí auto-find recent plan ‚úÖ (partially implemented)\n- `/validate-plan` ‚Üí auto-find plan being validated ‚ùå (missing)\n\n### Medium Priority (Should Have)\n- `/create-plan` ‚Üí suggest recent research ‚ùå (missing)\n- `/describe-pr` ‚Üí find related plan/research ‚ùå (missing)\n\n### Low Priority (Nice to Have)\n- `/merge-pr` ‚Üí reference PR description ‚ùå (missing)\n\n## Testing Checklist\n\nFor each command with auto-discovery:\n\n- [ ] Run bash script is FIRST thing command does\n- [ ] Script output is visible to user\n- [ ] User can override with explicit path\n- [ ] User is asked to confirm auto-discovered doc\n- [ ] Graceful fallback if nothing found\n- [ ] Works with workflow context from hooks\n\n## Implementation Status\n\n| Command | Auto-Discovery | Status | Notes |\n|---------|---------------|--------|-------|\n| `/resume-handoff` | handoffs | üü° Partial | Has script but not explicit enough |\n| `/implement-plan` | plans | üü° Partial | Has script but not explicit enough |\n| `/validate-plan` | plans | ‚ùå Missing | Needs implementation |\n| `/create-plan` | research (suggest) | ‚ùå Missing | Should offer to reference |\n| `/describe-pr` | plans | ‚ùå Missing | Could auto-reference plan |\n\n## Next Steps\n\n1. Update `/resume-handoff` with explicit pattern\n2. Update `/implement-plan` with explicit pattern\n3. Add auto-discovery to `/validate-plan`\n4. Add research suggestion to `/create-plan`\n5. Test full workflow: research ‚Üí plan ‚Üí implement ‚Üí validate\n"
              },
              {
                "name": "/README",
                "description": null,
                "path": "plugins/dev/commands/README.md",
                "frontmatter": null,
                "content": "# Thoughts Commands\n\nContext handoff and collaboration tools using the thoughts system.\n\n## Commands\n\n### `/create-handoff`\n\nCreate handoff document for passing work to another developer or session.\n\n**Usage:**\n\n```\n/create-handoff\n> What work are you handing off?\n```\n\n**Creates:**\n\n- Handoff document in `thoughts/shared/handoffs/YYYY-MM-DD-description.md`\n- Includes: Current state, work completed, next steps, blockers, context\n\n**Content:**\n\n- Current ticket/task\n- Work completed (with file:line references)\n- Files modified\n- Next steps (prioritized)\n- Known blockers\n- Important context\n\n### `/resume-handoff`\n\nResume work from handoff document.\n\n**Usage:**\n\n```\n/resume-handoff thoughts/shared/handoffs/YYYY-MM-DD-file.md\n```\n\n**Process:**\n\n- Reads full handoff document\n- Loads context (ticket, files, blockers)\n- Presents next steps\n- Asks how to proceed\n\n**Benefits:**\n\n- Quick context restoration\n- No lost work\n- Clear continuation path\n\n## Use Cases\n\n**Handoffs:**\n\n- End of day ‚Üí Resume next morning\n- Developer ‚Üí Developer\n- Blocked work ‚Üí When unblocked\n\n**Collaboration:**\n\n- Pair programming context\n- Code review preparation\n- Onboarding new team members\n\n## Thoughts System\n\nCommands use the HumanLayer thoughts system:\n\n- `thoughts/personal/` - Your private notes\n- `thoughts/shared/` - Team-shared documents\n- `thoughts/global/` - Cross-project knowledge\n\nInitialize with: `humanlayer thoughts init`\n"
              },
              {
                "name": "/commit",
                "description": "Create conventional commits for session changes",
                "path": "plugins/dev/commands/commit.md",
                "frontmatter": {
                  "description": "Create conventional commits for session changes",
                  "category": "version-control-git",
                  "tools": "Bash, Read",
                  "model": "inherit",
                  "version": "2.0.0"
                },
                "content": "# Commit Changes\n\nYou are tasked with creating git commits using conventional commit format for the changes made\nduring this session.\n\n## Process:\n\n1. **Analyze what changed:**\n   - Review the conversation history and understand what was accomplished\n   - Run `git status` to see current changes\n   - Run `git diff --cached` to see staged changes (if any)\n   - Run `git diff` to see unstaged changes\n   - Get changed file list: `git diff --name-only` and `git diff --cached --name-only`\n\n2. **Auto-detect conventional commit components:**\n\n   **Type detection (suggest to user):**\n   - If only `*.md` files in `docs/`: suggest `docs`\n   - If only test files (`*test*`, `*spec*`): suggest `test`\n   - If `package.json`, `*.lock` files: suggest `build`\n   - If `.github/workflows/`: suggest `ci`\n   - If mix of changes: suggest `feat` or `fix` based on context\n   - Otherwise: ask user to choose from: `feat`, `fix`, `refactor`, `chore`, `docs`, `style`,\n     `perf`, `test`, `build`, `ci`\n\n   **Scope detection (suggest to user):**\n   - Parse changed file paths\n   - Map to scopes:\n     - `agents/*.md` ‚Üí `agents`\n     - `commands/*.md` ‚Üí `commands`\n     - `hack/*` ‚Üí `hack`\n     - `docs/*.md` ‚Üí `docs`\n     - `.claude/` ‚Üí `claude`\n     - Multiple dirs or root files ‚Üí empty scope (cross-cutting)\n\n   **Extract ticket reference:**\n   - Get current branch: `git branch --show-current`\n   - Extract ticket pattern: `{PREFIX}-{NUMBER}` (e.g., RCW-13, ENG-123)\n   - Will be added to commit footer\n\n3. **Generate conventional commit message:**\n\n   **Format:**\n\n   ```\n   <type>(<scope>): <short summary>\n\n   <body - optional but recommended>\n\n   <footer - ticket reference>\n   ```\n\n   **Rules:**\n   - Header max 100 characters\n   - Type: lowercase\n   - Subject: imperative mood, no period, no capital first letter\n   - Body: explain WHY, not what (optional for simple changes)\n   - Footer: `Refs: TICKET-123` if ticket in branch name\n\n   **Example:**\n\n   ```\n   feat(commands): add conventional commit support to /catalyst-dev:commit\n\n   Updates the commit command to automatically detect commit type\n   and scope from changed files, following conventional commits spec.\n   Extracts ticket references from branch names for traceability.\n\n   Refs: RCW-13\n   ```\n\n4. **Present plan to user:**\n   - Show detected type and scope with confidence\n   - Show generated commit message\n   - Explain: \"Detected changes suggest: `<type>(<scope>): <summary>`\"\n   - List files to be committed\n   - Ask: \"Proceed with this commit? [Y/n/e(dit)]\"\n     - Y: execute as-is\n     - n: abort\n     - e: allow user to edit message\n\n5. **Execute commit:**\n   - Stage files: `git add <specific-files>` (NEVER use `-A` or `.`)\n   - Create commit with message\n   - Show result: `git log --oneline -n 1`\n   - Show summary: `git show --stat HEAD`\n\n## Configuration\n\nReads from `.claude/config.json`:\n\n```json\n{\n  \"catalyst\": {\n    \"commit\": {\n      \"useConventional\": true,\n      \"scopes\": [\"agents\", \"commands\", \"hack\", \"docs\", \"claude\", \"config\"],\n      \"autoDetectType\": true,\n      \"autoDetectScope\": true,\n      \"requireBody\": false\n    },\n    \"project\": {\n      \"ticketPrefix\": \"RCW\"\n    }\n  }\n}\n```\n\n## Type Reference\n\n**Types that appear in CHANGELOG:**\n\n- `feat` - New feature\n- `fix` - Bug fix\n- `perf` - Performance improvement\n- `revert` - Revert previous commit\n\n**Internal types:**\n\n- `docs` - Documentation only\n- `style` - Formatting, no code change\n- `refactor` - Code restructuring, no behavior change\n- `test` - Adding/updating tests\n- `build` - Build system or dependencies\n- `ci` - CI/CD configuration\n- `chore` - Maintenance tasks\n\n## Examples\n\n**Feature:**\n\n```\nfeat(agents): add codebase-pattern-finder agent\n\nImplements new agent for finding similar code patterns across\nthe codebase with concrete examples and file references.\n\nRefs: RCW-45\n```\n\n**Fix:**\n\n```\nfix(commands): handle missing PR template gracefully\n\nPreviously crashed when thoughts/shared/pr_description.md was\nmissing. Now provides clear error with setup instructions.\n\nRefs: RCW-78\n```\n\n**Documentation:**\n\n```\ndocs(hack): add README for installation scripts\n\nDocuments all scripts in hack/ directory with usage examples\nand explains when to use each installation method.\n\nRefs: RCW-12\n```\n\n**Chore (no ticket):**\n\n```\nchore(config): update conventional commit scopes\n\nAdds new scopes for agents and commands directories.\n```\n\n## Important:\n\n- **NEVER add co-author information or Claude attribution**\n- Commits should be authored solely by the user\n- Do not include any \"Generated with Claude\" messages\n- Do not add \"Co-Authored-By\" lines\n- Write commit messages as if the user wrote them\n- Use conventional format for consistency and changelog generation\n- Keep header under 100 characters\n- Use imperative mood: \"add feature\" not \"added feature\"\n\n## Remember:\n\n- You have the full context of what was done in this session\n- Group related changes together logically\n- Keep commits focused and atomic when possible\n- The user trusts your judgment - they asked you to commit\n- Suggest type and scope based on file analysis\n- Extract ticket from branch name automatically\n- Allow user to override suggestions"
              },
              {
                "name": "/create_handoff",
                "description": "Create handoff document for passing work to another session",
                "path": "plugins/dev/commands/create_handoff.md",
                "frontmatter": {
                  "description": "Create handoff document for passing work to another session",
                  "category": "workflow",
                  "tools": "Write, Bash, Read",
                  "model": "inherit",
                  "version": "1.0.0"
                },
                "content": "# Create Handoff\n\n## Prerequisites\n\nBefore executing, verify all required tools and systems:\n\n```bash\n# 1. Validate thoughts system (REQUIRED)\nif [[ -f \"scripts/validate-thoughts-setup.sh\" ]]; then\n  ./scripts/validate-thoughts-setup.sh || exit 1\nelse\n  # Inline validation if script not found\n  if [[ ! -d \"thoughts/shared\" ]]; then\n    echo \"‚ùå ERROR: Thoughts system not configured\"\n    echo \"Run: ./scripts/humanlayer/init-project.sh . {project-name}\"\n    exit 1\n  fi\nfi\n\n# 2. Validate plugin scripts\nif [[ -f \"${CLAUDE_PLUGIN_ROOT}/scripts/check-prerequisites.sh\" ]]; then\n  \"${CLAUDE_PLUGIN_ROOT}/scripts/check-prerequisites.sh\" || exit 1\nfi\n```\n\n## Configuration Note\n\nThis command uses ticket references like `PROJ-123`. Replace `PROJ` with your Linear team's ticket\nprefix:\n\n- Read from `.claude/config.json` if available\n- Otherwise use a generic format like `TICKET-XXX`\n- Examples: `ENG-123`, `FEAT-456`, `BUG-789`\n\nYou are tasked with writing a handoff document to hand off your work to another agent in a new\nsession. You will create a handoff document that is thorough, but also **concise**. The goal is to\ncompact and summarize your context without losing any of the key details of what you're working on.\n\n## Process\n\n### 1. Filepath & Metadata\n\nUse the following information to understand how to create your document: - create your file under\n`thoughts/shared/handoffs/PROJ-XXX/YYYY-MM-DD_HH-MM-SS_description.md`, where: - YYYY-MM-DD is\ntoday's date - HH-MM-SS is the hours, minutes and seconds based on the current time, in 24-hour\nformat (i.e. use `13:00` for `1:00 pm`) - PROJ-XXX is the ticket number directory (replace with\n`general` if no ticket) - description is a brief kebab-case description (optionally including ticket\nnumber) - Get current git information for metadata (branch, commit, repository name) using git\ncommands - Examples: - With ticket:\n`thoughts/shared/handoffs/PROJ-123/2025-01-08_13-55-22_PROJ-123_auth-feature.md` - Without ticket:\n`thoughts/shared/handoffs/general/2025-01-08_13-55-22_refactor-api.md`\n\n### 2. Handoff writing.\n\nusing the above conventions, write your document. use the defined filepath, and the following YAML\nfrontmatter pattern. Use the metadata gathered in step 1, Structure the document with YAML\nfrontmatter followed by content:\n\nUse the following template structure:\n\n```markdown\n---\ndate: [Current date and time with timezone in ISO format]\nresearcher: [Researcher name from thoughts status]\ngit_commit: [Current commit hash]\nbranch: [Current branch name]\nrepository: [Repository name]\ntopic: \"[Feature/Task Name] Implementation Strategy\"\ntags: [implementation, strategy, relevant-component-names]\nstatus: complete\nlast_updated: [Current date in YYYY-MM-DD format]\nlast_updated_by: [Researcher name]\ntype: implementation_strategy\n---\n\n# Handoff: {TICKET or General} - {very concise description}\n\n## Task(s)\n\n{description of the task(s) that you were working on, along with the status of each (completed, work\nin progress, planned/discussed). If you are working on an implementation plan, make sure to call out\nwhich phase you are on. Make sure to reference the plan document and/or research document(s) you are\nworking from that were provided to you at the beginning of the session, if applicable.}\n\n## Critical References\n\n{List any critical specification documents, architectural decisions, or design docs that must be\nfollowed. Include only 2-3 most important file paths. Leave blank if none.}\n\n## Recent changes\n\n{describe recent changes made to the codebase that you made in line:file syntax}\n\n## Learnings\n\n{describe important things that you learned - e.g. patterns, root causes of bugs, or other important\npieces of information someone that is picking up your work after you should know. consider listing\nexplicit file paths.}\n\n## Artifacts\n\n{ an exhaustive list of artifacts you produced or updated as filepaths and/or file:line references -\ne.g. paths to feature documents, implementation plans, etc that should be read in order to resume\nyour work.}\n\n## Action Items & Next Steps\n\n{ a list of action items and next steps for the next agent to accomplish based on your tasks and\ntheir statuses}\n\n## Other Notes\n\n{ other notes, references, or useful information - e.g. where relevant sections of the codebase are,\nwhere relevant documents are, or other important things you leanrned that you want to pass on but\nthat don't fall into the above categories}\n```\n\n---\n\n### 3. Approve and Sync\n\nAsk the user to review and approve the document. if they request any changes, you should make them\nand ask for approval again. Once the user approves the documents, you should run\n`humanlayer thoughts sync` to save the document.\n\n### Track in Workflow Context\n\nAfter saving the handoff document, add it to workflow context:\n\n```bash\nif [[ -f \"${CLAUDE_PLUGIN_ROOT}/scripts/workflow-context.sh\" ]]; then\n  \"${CLAUDE_PLUGIN_ROOT}/scripts/workflow-context.sh\" add handoffs \"$HANDOFF_FILE\" \"${TICKET_ID:-null}\"\nfi\n```\n\nOnce this is completed, you should respond to the user with the template between\n<template_response></template_response> XML tags. do NOT include the tags in your response.\n\n<template_response> Handoff created and synced! You can resume from this handoff in a new session\nwith the following command:\n\n```bash\n/catalyst-dev:resume_handoff path/to/handoff.md\n```\n\n</template_response>\n\nfor example (between <example_response></example_response> XML tags - do NOT include these tags in\nyour actual response to the user)\n\n<example_response> Handoff created and synced! You can resume from this handoff in a new session\nwith the following command:\n\n```bash\n/catalyst-dev:resume_handoff thoughts/shared/handoffs/PROJ-123/2025-01-08_13-44-55_PROJ-123_create-context-compaction.md\n```\n\n</example_response>\n\n---\n\n##. Additional Notes & Instructions\n\n- **more information, not less**. This is a guideline that defines the minimum of what a handoff\n  should be. Always feel free to include more information if necessary.\n- **be thorough and precise**. include both top-level objectives, and lower-level details as\n  necessary.\n- **avoid excessive code snippets**. While a brief snippet to describe some key change is important,\n  avoid large code blocks or diffs; do not include one unless it's absolutely necessary. Prefer\n  using `/path/to/file.ext:line` references that an agent can follow later when it's ready, e.g.\n  `packages/dashboard/src/app/dashboard/page.tsx:12-24`"
              },
              {
                "name": "/create_plan",
                "description": "Create detailed implementation plans through an interactive process",
                "path": "plugins/dev/commands/create_plan.md",
                "frontmatter": {
                  "description": "Create detailed implementation plans through an interactive process",
                  "category": "workflow",
                  "tools": "Read, Write, Grep, Glob, Task, TodoWrite, Bash",
                  "model": "inherit",
                  "version": "1.0.0"
                },
                "content": "# Implementation Plan\n\n## Configuration Note\n\nThis command uses ticket references like `PROJ-123`. Replace `PROJ` with your Linear team's ticket\nprefix:\n\n- Read from `.claude/config.json` if available\n- Otherwise use a generic format like `TICKET-XXX`\n- Examples: `ENG-123`, `FEAT-456`, `BUG-789`\n\nYou are tasked with creating detailed implementation plans through an interactive, iterative\nprocess. You should be skeptical, thorough, and work collaboratively with the user to produce\nhigh-quality technical specifications.\n\n## Prerequisites\n\nBefore executing, verify all required tools and systems:\n\n```bash\n# 1. Validate thoughts system (REQUIRED)\nif [[ -f \"scripts/validate-thoughts-setup.sh\" ]]; then\n  ./scripts/validate-thoughts-setup.sh || exit 1\nelse\n  # Inline validation if script not found\n  if [[ ! -d \"thoughts/shared\" ]]; then\n    echo \"‚ùå ERROR: Thoughts system not configured\"\n    echo \"Run: ./scripts/humanlayer/init-project.sh . {project-name}\"\n    exit 1\n  fi\nfi\n\n# 2. Validate plugin scripts\nif [[ -f \"${CLAUDE_PLUGIN_ROOT}/scripts/check-prerequisites.sh\" ]]; then\n  \"${CLAUDE_PLUGIN_ROOT}/scripts/check-prerequisites.sh\" || exit 1\nfi\n```\n\n## Initial Response\n\n**STEP 1: Check for recent research (OPTIONAL)**\n\nIMMEDIATELY run this bash script to find recent research that might be relevant:\n\n```bash\n# Find recent research that might inform this plan\nif [[ -f \"${CLAUDE_PLUGIN_ROOT}/scripts/workflow-context.sh\" ]]; then\n  RECENT_RESEARCH=$(\"${CLAUDE_PLUGIN_ROOT}/scripts/workflow-context.sh\" recent research)\n  if [[ -n \"$RECENT_RESEARCH\" ]]; then\n    echo \"üí° Found recent research: $RECENT_RESEARCH\"\n    echo \"\"\n  fi\nfi\n```\n\n**STEP 2: Gather initial input**\n\nAfter checking for research, follow this logic:\n\n1. **If user provided parameters** (file path or ticket reference):\n   - Immediately read any provided files FULLY\n   - If RECENT_RESEARCH was found, ask: \"Should I reference the recent research document in this plan?\"\n   - Begin the research process\n\n2. **If no parameters provided**:\n   - Show any RECENT_RESEARCH that was found\n   - Respond with:\n\n```\nI'll help you create a detailed implementation plan. Let me start by understanding what we're building.\n\nPlease provide:\n1. The task/ticket description (or reference to a ticket file)\n2. Any relevant context, constraints, or specific requirements\n3. Links to related research or previous implementations\n```\n\nIf RECENT_RESEARCH exists, add:\n```\nüí° I found recent research: $RECENT_RESEARCH\n   Would you like me to use this as context for the plan?\n```\n\nContinue with:\n```\nI'll analyze this information and work with you to create a comprehensive plan.\n\nTip: You can also invoke this command with a ticket file directly: `/create_plan thoughts/allison/tickets/proj_123.md`\nFor deeper analysis, try: `/create_plan think deeply about thoughts/allison/tickets/proj_123.md`\n```\n\nThen wait for the user's input.\n\n## Process Steps\n\n### Step 1: Context Gathering & Initial Analysis\n\n1. **Read all mentioned files immediately and FULLY**:\n   - Ticket files (e.g., `thoughts/allison/tickets/proj_123.md`)\n   - Research documents\n   - Related implementation plans\n   - Any JSON/data files mentioned\n   - **IMPORTANT**: Use the Read tool WITHOUT limit/offset parameters to read entire files\n   - **CRITICAL**: DO NOT spawn sub-tasks before reading these files yourself in the main context\n   - **NEVER** read files partially - if a file is mentioned, read it completely\n\n2. **Spawn initial research tasks to gather context**: Before asking the user any questions, use\n   specialized agents to research in parallel:\n   - Use the **codebase-locator** agent to find all files related to the ticket/task\n   - Use the **codebase-analyzer** agent to understand how the current implementation works\n   - If relevant, use the **thoughts-locator** agent to find any existing thoughts documents about\n     this feature\n   - If a Linear ticket is mentioned, use the **linear-ticket-reader** agent to get full details\n\n   These agents will:\n   - Find relevant source files, configs, and tests\n   - Identify the specific directories to focus on (e.g., if WUI is mentioned, they'll focus on\n     humanlayer-wui/)\n   - Trace data flow and key functions\n   - Return detailed explanations with file:line references\n\n3. **Read all files identified by research tasks**:\n   - After research tasks complete, read ALL files they identified as relevant\n   - Read them FULLY into the main context\n   - This ensures you have complete understanding before proceeding\n\n4. **Analyze and verify understanding**:\n   - Cross-reference the ticket requirements with actual code\n   - Identify any discrepancies or misunderstandings\n   - Note assumptions that need verification\n   - Determine true scope based on codebase reality\n\n5. **Present informed understanding and focused questions**:\n\n   ```\n   Based on the ticket and my research of the codebase, I understand we need to [accurate summary].\n\n   I've found that:\n   - [Current implementation detail with file:line reference]\n   - [Relevant pattern or constraint discovered]\n   - [Potential complexity or edge case identified]\n\n   Questions that my research couldn't answer:\n   - [Specific technical question that requires human judgment]\n   - [Business logic clarification]\n   - [Design preference that affects implementation]\n   ```\n\n   Only ask questions that you genuinely cannot answer through code investigation.\n\n### Step 2: Research & Discovery\n\nAfter getting initial clarifications:\n\n1. **If the user corrects any misunderstanding**:\n   - DO NOT just accept the correction\n   - Spawn new research tasks to verify the correct information\n   - Read the specific files/directories they mention\n   - Only proceed once you've verified the facts yourself\n\n2. **Create a research todo list** using TodoWrite to track exploration tasks\n\n3. **Spawn parallel sub-tasks for comprehensive research**:\n   - Create multiple Task agents to research different aspects concurrently\n   - Use the right agent for each type of research:\n\n   **For local codebase:**\n   - **codebase-locator** - To find more specific files (e.g., \"find all files that handle [specific\n     component]\")\n   - **codebase-analyzer** - To understand implementation details (e.g., \"analyze how [system]\n     works\")\n   - **codebase-pattern-finder** - To find similar features we can model after\n\n   **For external research:**\n   - **external-research** - To research framework patterns and best practices from popular repos\n   - Ask: \"How does [framework] recommend implementing [feature]?\"\n   - Ask: \"What's the standard approach for [pattern] in [library]?\"\n   - Examples: React patterns, Express middleware, Next.js routing, Prisma schemas\n\n   **For historical context:**\n   - **thoughts-locator** - To find any research, plans, or decisions about this area\n   - **thoughts-analyzer** - To extract key insights from the most relevant documents\n\n   **For related tickets:**\n   - **linear-searcher** - To find similar issues or past implementations\n\n   Each agent knows how to:\n   - Find the right files and code patterns\n   - Identify conventions and patterns to follow\n   - Look for integration points and dependencies\n   - Return specific file:line references\n   - Find tests and examples\n\n4. **Wait for ALL sub-tasks to complete** before proceeding\n\n5. **Present findings and design options**:\n\n   ```\n   Based on my research, here's what I found:\n\n   **Current State:**\n   - [Key discovery about existing code]\n   - [Pattern or convention to follow]\n\n   **Design Options:**\n   1. [Option A] - [pros/cons]\n   2. [Option B] - [pros/cons]\n\n   **Open Questions:**\n   - [Technical uncertainty]\n   - [Design decision needed]\n\n   Which approach aligns best with your vision?\n   ```\n\n### Step 3: Plan Structure Development\n\nOnce aligned on approach:\n\n1. **Create initial plan outline**:\n\n   ```\n   Here's my proposed plan structure:\n\n   ## Overview\n   [1-2 sentence summary]\n\n   ## Implementation Phases:\n   1. [Phase name] - [what it accomplishes]\n   2. [Phase name] - [what it accomplishes]\n   3. [Phase name] - [what it accomplishes]\n\n   Does this phasing make sense? Should I adjust the order or granularity?\n   ```\n\n2. **Get feedback on structure** before writing details\n\n### Step 4: Detailed Plan Writing\n\nAfter structure approval:\n\n1. **Gather metadata for the plan document**:\n\n   Before writing the plan, collect git and temporal metadata:\n\n   ```bash\n   # Get current date/time in ISO 8601 format with timezone\n   CURRENT_ISO_DATETIME=$(date -Iseconds)  # e.g., 2025-01-11T14:30:00-06:00\n   CURRENT_DATE=$(date +%Y-%m-%d)          # e.g., 2025-01-11\n\n   # Get git information\n   GIT_COMMIT_SHORT=$(git rev-parse --short HEAD)\n   GIT_BRANCH=$(git branch --show-current)\n   REPO_NAME=$(basename \"$(git rev-parse --show-toplevel)\")\n   ```\n\n2. **Write the plan** to `thoughts/shared/plans/YYYY-MM-DD-PROJ-XXXX-description.md`\n   - Format: `YYYY-MM-DD-PROJ-XXXX-description.md` where:\n     - YYYY-MM-DD is today's date\n     - PROJ-XXXX is the ticket number (omit if no ticket)\n     - description is a brief kebab-case description\n   - Examples:\n     - With ticket: `2025-01-08-PROJ-123-parent-child-tracking.md`\n     - Without ticket: `2025-01-08-improve-error-handling.md`\n\n3. **Use this template structure** (note: frontmatter comes BEFORE the heading):\n\n````markdown\n---\ndate: {CURRENT_ISO_DATETIME}\nresearcher: claude\ngit_commit: {GIT_COMMIT_SHORT}\nbranch: {GIT_BRANCH}\nrepository: {REPO_NAME}\ntopic: \"{PLAN_TITLE}\"\ntags: [plan, implementation, {RELEVANT_COMPONENT_TAGS}]\nstatus: ready_for_implementation\nlast_updated: {CURRENT_DATE}\nlast_updated_by: claude\ntype: implementation_plan\n---\n\n# [Feature/Task Name] Implementation Plan\n\n## Overview\n\n[Brief description of what we're implementing and why]\n\n## Current State Analysis\n\n[What exists now, what's missing, key constraints discovered]\n\n## Desired End State\n\n[A Specification of the desired end state after this plan is complete, and how to verify it]\n\n### Key Discoveries:\n\n- [Important finding with file:line reference]\n- [Pattern to follow]\n- [Constraint to work within]\n\n## What We're NOT Doing\n\n[Explicitly list out-of-scope items to prevent scope creep]\n\n## Implementation Approach\n\n[High-level strategy and reasoning]\n\n## Phase 1: [Descriptive Name]\n\n### Overview\n\n[What this phase accomplishes]\n\n### Changes Required:\n\n#### 1. [Component/File Group]\n\n**File**: `path/to/file.ext` **Changes**: [Summary of changes]\n\n```[language]\n// Specific code to add/modify\n```\n\n### Success Criteria:\n\n#### Automated Verification:\n\n- [ ] Migration applies cleanly: `make migrate`\n- [ ] Unit tests pass: `make test-component`\n- [ ] Type checking passes: `npm run typecheck`\n- [ ] Linting passes: `make lint`\n- [ ] Integration tests pass: `make test-integration`\n\n#### Manual Verification:\n\n- [ ] Feature works as expected when tested via UI\n- [ ] Performance is acceptable under load\n- [ ] Edge case handling verified manually\n- [ ] No regressions in related features\n\n---\n\n## Phase 2: [Descriptive Name]\n\n[Similar structure with both automated and manual success criteria...]\n\n---\n\n## Testing Strategy\n\n### Unit Tests:\n\n- [What to test]\n- [Key edge cases]\n\n### Integration Tests:\n\n- [End-to-end scenarios]\n\n### Manual Testing Steps:\n\n1. [Specific step to verify feature]\n2. [Another verification step]\n3. [Edge case to test manually]\n\n## Performance Considerations\n\n[Any performance implications or optimizations needed]\n\n## Migration Notes\n\n[If applicable, how to handle existing data/systems]\n\n## References\n\n- Original ticket: `thoughts/allison/tickets/proj_XXXX.md`\n- Related research: `thoughts/shared/research/[relevant].md`\n- Similar implementation: `[file:line]`\n````\n\n### Step 5: Sync and Review\n\n1. **Sync the thoughts directory**:\n   - Run `humanlayer thoughts sync` to sync the newly created plan\n   - This ensures the plan is properly indexed and available\n\n2. **Track in Workflow Context**:\n\n   After saving the plan document, add it to workflow context:\n\n   ```bash\n   if [[ -f \"${CLAUDE_PLUGIN_ROOT}/scripts/workflow-context.sh\" ]]; then\n     \"${CLAUDE_PLUGIN_ROOT}/scripts/workflow-context.sh\" add plans \"$PLAN_FILE\" \"${TICKET_ID}\"\n   fi\n   ```\n\n3. **Check context usage and present plan**:\n\n   **Monitor your context** and present:\n\n   ```\n   ‚úÖ Implementation plan created!\n\n   **Plan location**: `thoughts/shared/plans/YYYY-MM-DD-PROJ-XXXX-description.md`\n\n   ## üìä Context Status\n\n   Current usage: {X}% ({Y}K/{Z}K tokens)\n\n   {If >60%}:\n   ‚ö†Ô∏è **Context Alert**: We're at {X}% context usage.\n\n   **Recommendation**: Clear context before implementation phase.\n\n   **Why?** The implementation phase will:\n   - Load the complete plan file\n   - Read multiple source files\n   - Track progress with TodoWrite\n   - Benefit from fresh context for optimal performance\n\n   **What to do**:\n   1. ‚úÖ Review the plan (read the file above)\n   2. ‚úÖ Close this session (clear context)\n   3. ‚úÖ Start fresh session in worktree\n   4. ‚úÖ Run `/implement-plan {plan-path}`\n\n   This is normal! Context is meant to be cleared between phases.\n\n   {If <60%}:\n   ‚úÖ Context healthy ({X}%).\n\n   ---\n\n   Please review the plan and let me know:\n   - Are the phases properly scoped?\n   - Are the success criteria specific enough?\n   - Any technical details that need adjustment?\n   - Missing edge cases or considerations?\n   ```\n\n4. **Iterate based on feedback** - be ready to:\n   - Add missing phases\n   - Adjust technical approach\n   - Clarify success criteria (both automated and manual)\n   - Add/remove scope items\n   - After making changes, run `humanlayer thoughts sync` again\n   - **Monitor context** - if >70% during iterations, warn user to review file offline\n\n5. **Continue refining** until the user is satisfied\n\n6. **Final context check** after approval:\n   - If context >50%, remind user to clear before implementation\n   - Provide clear instructions on next steps with fresh context\n\n## Important Guidelines\n\n1. **Be Skeptical**:\n   - Question vague requirements\n   - Identify potential issues early\n   - Ask \"why\" and \"what about\"\n   - Don't assume - verify with code\n\n2. **Be Interactive**:\n   - Don't write the full plan in one shot\n   - Get buy-in at each major step\n   - Allow course corrections\n   - Work collaboratively\n\n3. **Be Thorough**:\n   - Read all context files COMPLETELY before planning\n   - Research actual code patterns using parallel sub-tasks\n   - Include specific file paths and line numbers\n   - Write measurable success criteria with clear automated vs manual distinction\n   - automated steps should use `make` whenever possible - for example\n     `make -C humanlayer-wui check` instead of `cd humanlayer-wui && bun run fmt`\n\n4. **Be Practical**:\n   - Focus on incremental, testable changes\n   - Consider migration and rollback\n   - Think about edge cases\n   - Include \"what we're NOT doing\"\n\n5. **Track Progress**:\n   - Use TodoWrite to track planning tasks\n   - Update todos as you complete research\n   - Mark planning tasks complete when done\n\n6. **No Open Questions in Final Plan**:\n   - If you encounter open questions during planning, STOP\n   - Research or ask for clarification immediately\n   - Do NOT write the plan with unresolved questions\n   - The implementation plan must be complete and actionable\n   - Every decision must be made before finalizing the plan\n\n## Success Criteria Guidelines\n\n**Always separate success criteria into two categories:**\n\n1. **Automated Verification** (can be run by execution agents):\n   - Commands that can be run: `make test`, `npm run lint`, etc.\n   - Specific files that should exist\n   - Code compilation/type checking\n   - Automated test suites\n\n2. **Manual Verification** (requires human testing):\n   - UI/UX functionality\n   - Performance under real conditions\n   - Edge cases that are hard to automate\n   - User acceptance criteria\n\n**Format example:**\n\n```markdown\n### Success Criteria:\n\n#### Automated Verification:\n\n- [ ] Database migration runs successfully: `make migrate`\n- [ ] All unit tests pass: `go test ./...`\n- [ ] No linting errors: `golangci-lint run`\n- [ ] API endpoint returns 200: `curl localhost:8080/api/new-endpoint`\n\n#### Manual Verification:\n\n- [ ] New feature appears correctly in the UI\n- [ ] Performance is acceptable with 1000+ items\n- [ ] Error messages are user-friendly\n- [ ] Feature works correctly on mobile devices\n```\n\n## Common Patterns\n\n### For Database Changes:\n\n- Start with schema/migration\n- Add store methods\n- Update business logic\n- Expose via API\n- Update clients\n\n### For New Features:\n\n- Research existing patterns first\n- Start with data model\n- Build backend logic\n- Add API endpoints\n- Implement UI last\n\n### For Refactoring:\n\n- Document current behavior\n- Plan incremental changes\n- Maintain backwards compatibility\n- Include migration strategy\n\n## Sub-task Spawning Best Practices\n\nWhen spawning research sub-tasks:\n\n1. **Spawn multiple tasks in parallel** for efficiency\n2. **Each task should be focused** on a specific area\n3. **Provide detailed instructions** including:\n   - Exactly what to search for\n   - Which directories to focus on\n   - What information to extract\n   - Expected output format\n4. **Be EXTREMELY specific about directories**:\n   - If the ticket mentions \"WUI\", specify `humanlayer-wui/` directory\n   - If it mentions \"daemon\", specify `hld/` directory\n   - Never use generic terms like \"UI\" when you mean \"WUI\"\n   - Include the full path context in your prompts\n5. **Specify read-only tools** to use\n6. **Request specific file:line references** in responses\n7. **Wait for all tasks to complete** before synthesizing\n8. **Verify sub-task results**:\n   - If a sub-task returns unexpected results, spawn follow-up tasks\n   - Cross-check findings against the actual codebase\n   - Don't accept results that seem incorrect\n\nExample of spawning multiple tasks:\n\n```python\n# Spawn these tasks concurrently:\ntasks = [\n    Task(\"Research database schema\", db_research_prompt),\n    Task(\"Find API patterns\", api_research_prompt),\n    Task(\"Investigate UI components\", ui_research_prompt),\n    Task(\"Check test patterns\", test_research_prompt)\n]\n```\n\n## Example Interaction Flow\n\n```\nUser: /implementation_plan\nAssistant: I'll help you create a detailed implementation plan...\n\nUser: We need to add parent-child tracking for Claude sub-tasks. See thoughts/allison/tickets/proj_456.md\nAssistant: Let me read that ticket file completely first...\n\n[Reads file fully]\n\nBased on the ticket, I understand we need to track parent-child relationships for Claude sub-task events in the hld daemon. Before I start planning, I have some questions...\n\n[Interactive process continues...]\n```"
              },
              {
                "name": "/create_pr",
                "description": "Create pull request with automatic Linear integration",
                "path": "plugins/dev/commands/create_pr.md",
                "frontmatter": {
                  "description": "Create pull request with automatic Linear integration",
                  "category": "version-control-git",
                  "tools": "Bash(linearis *), Bash(git *), Bash(gh *), Read, Task",
                  "model": "inherit",
                  "version": "1.0.0"
                },
                "content": "# Create Pull Request\n\nOrchestrates the complete PR creation flow: commit ‚Üí rebase ‚Üí push ‚Üí create ‚Üí describe ‚Üí link Linear\nticket.\n\n## Prerequisites\n\nBefore executing, verify required tools are installed:\n\n```bash\nif [[ -f \"${CLAUDE_PLUGIN_ROOT}/scripts/check-prerequisites.sh\" ]]; then\n  \"${CLAUDE_PLUGIN_ROOT}/scripts/check-prerequisites.sh\" || exit 1\nfi\n```\n\n## Configuration\n\nRead team configuration from `.claude/config.json`:\n\n```bash\nCONFIG_FILE=\".claude/config.json\"\nTEAM_KEY=$(jq -r '.catalyst.linear.teamKey // \"PROJ\"' \"$CONFIG_FILE\")\n```\n\n## Process:\n\n### 1. Check for uncommitted changes\n\n```bash\ngit status --porcelain\n```\n\nIf there are uncommitted changes:\n\n- Offer to commit: \"You have uncommitted changes. Create commits now? [Y/n]\"\n- If yes: internally call `/catalyst-dev:commit` workflow\n- If no: proceed (user may want to commit manually later)\n\n### 2. Verify not on main/master branch\n\n```bash\nbranch=$(git branch --show-current)\n```\n\nIf on `main` or `master`:\n\n- Error: \"Cannot create PR from main branch. Create a feature branch first.\"\n- Exit\n\n### 3. Detect base branch\n\n```bash\n# Check which exists\nif git show-ref --verify --quiet refs/heads/main; then\n    base=\"main\"\nelif git show-ref --verify --quiet refs/heads/master; then\n    base=\"master\"\nelse\n    base=$(git symbolic-ref refs/remotes/origin/HEAD | sed 's@^refs/remotes/origin/@@')\nfi\n```\n\n### 4. Check if branch is up-to-date with base\n\n```bash\n# Fetch latest\ngit fetch origin $base\n\n# Check if behind\nif git log HEAD..origin/$base --oneline | grep -q .; then\n    echo \"Branch is behind $base\"\nfi\n```\n\nIf behind:\n\n- Auto-rebase: `git rebase origin/$base`\n- If conflicts:\n  - Show conflicting files\n  - Error: \"Rebase conflicts detected. Resolve conflicts and run /catalyst-dev:create_pr again.\"\n  - Exit\n\n### 5. Check for existing PR\n\n```bash\ngh pr view --json number,url,title,state 2>/dev/null\n```\n\nIf PR exists:\n\n- Show: \"PR #{number} already exists: {title}\\n{url}\"\n- Ask: \"What would you like to do?\\n [D] Describe/update this PR\\n [S] Skip (do nothing)\\n [A]\n  Abort\"\n- If D: call `/catalyst-dev:describe_pr` and exit\n- If S: exit with success message\n- If A: exit\n- **This is the ONLY interactive prompt in the happy path**\n\n### 6. Extract ticket from branch name\n\n```bash\nbranch=$(git branch --show-current)\n\n# Extract pattern: PREFIX-NUMBER using configured team key\nif [[ \"$branch\" =~ ($TEAM_KEY-[0-9]+) ]]; then\n    ticket=\"${BASH_REMATCH[1]}\"  # e.g., RCW-13\nfi\n```\n\n### 7. Generate PR title from branch and ticket\n\n```bash\n# Branch format examples:\n# - RCW-13-implement-pr-lifecycle ‚Üí \"RCW-13: implement pr lifecycle\"\n# - feature-add-validation ‚Üí \"add validation\"\n\n# Extract description from branch name\nif [[ \"$ticket\" ]]; then\n    # Remove ticket prefix from branch\n    desc=$(echo \"$branch\" | sed \"s/^$ticket-//\")\n    # Convert kebab-case to spaces\n    desc=$(echo \"$desc\" | tr '-' ' ')\n    # Capitalize first word\n    desc=\"$(tr '[:lower:]' '[:upper:]' <<< ${desc:0:1})${desc:1}\"\n\n    title=\"$ticket: $desc\"\nelse\n    # No ticket in branch\n    desc=$(echo \"$branch\" | tr '-' ' ')\n    desc=\"$(tr '[:lower:]' '[:upper:]' <<< ${desc:0:1})${desc:1}\"\n    title=\"$desc\"\nfi\n```\n\n### 8. Push branch\n\n```bash\n# Check if branch has upstream\nif ! git rev-parse --abbrev-ref --symbolic-full-name @{u} 2>/dev/null; then\n    # No upstream, push with -u\n    git push -u origin HEAD\nelse\n    # Has upstream, check if up-to-date\n    git push\nfi\n```\n\n### 9. Create PR\n\n**CRITICAL: NO CLAUDE ATTRIBUTION**\n\nDO NOT add any of the following to the PR:\n- ‚ùå \"Generated with Claude Code\" or similar messages\n- ‚ùå \"Co-Authored-By: Claude\" lines\n- ‚ùå Any reference to AI assistance\n- ‚ùå Links to Claude Code or Anthropic\n\nThe PR should be authored solely by the user (git author). Keep the description clean and professional.\n\n```bash\n# Minimal initial body (NO CLAUDE ATTRIBUTION)\nbody=\"Automated PR creation. Comprehensive description generating...\"\n\n# If ticket exists, add reference\nif [[ \"$ticket\" ]]; then\n    body=\"$body\\n\\nRefs: $ticket\"\nfi\n\n# Create PR (author will be the git user)\ngh pr create --title \"$title\" --body \"$body\" --base \"$base\"\n```\n\nCapture PR number and URL from output.\n\n### Track in Workflow Context\n\nAfter creating the PR, add it to workflow context:\n\n```bash\nif [[ -f \"${CLAUDE_PLUGIN_ROOT}/scripts/workflow-context.sh\" ]]; then\n  \"${CLAUDE_PLUGIN_ROOT}/scripts/workflow-context.sh\" add prs \"$PR_URL\" \"${TICKET_ID:-null}\"\nfi\n```\n\n### 10. Auto-call /catalyst-dev:describe_pr\n\nImmediately call `/catalyst-dev:describe_pr` with the PR number to:\n\n- Generate comprehensive description\n- Run verification checks\n- Update PR title (refined from code analysis)\n- Save to thoughts/\n- Update Linear ticket\n\n### 11. Update Linear ticket (if ticket found)\n\nIf ticket was extracted from branch:\n\n```bash\n# Verify linearis is available\nif ! command -v linearis &> /dev/null; then\n    echo \"‚ö†Ô∏è  Linearis CLI not found - skipping Linear ticket update\"\n    echo \"Install: npm install -g --install-links ryanrozich/linearis#feat/cycles-cli\"\nelse\n    # Update ticket state to \"In Review\"\n    linearis issues update \"$ticket\" --state \"In Review\" --assignee \"@me\"\n\n    # Add comment with PR link\n    linearis comments create \"$ticket\" \\\n        --body \"PR created and ready for review!\\n\\n**PR**: $prUrl\\n\\nDescription has been auto-generated with verification checks.\"\nfi\n```\n\n### 12. Report success\n\n```\n‚úÖ Pull request created successfully!\n\n**PR**: #{number} - {title}\n**URL**: {url}\n**Base**: {base_branch}\n**Ticket**: {ticket} (moved to \"In Review\")\n\nDescription has been generated and verification checks have been run.\nReview the PR on GitHub!\n```\n\n## Error Handling\n\n**On main/master branch:**\n\n```\n‚ùå Cannot create PR from main branch.\n\nCreate a feature branch first:\n  git checkout -b TICKET-123-feature-name\n```\n\n**Rebase conflicts:**\n\n```\n‚ùå Rebase conflicts detected\n\nConflicting files:\n  - src/file1.ts\n  - src/file2.ts\n\nResolve conflicts and run:\n  git add <resolved-files>\n  git rebase --continue\n  /catalyst-dev:create_pr\n```\n\n**GitHub CLI not configured:**\n\n```\n‚ùå GitHub CLI not configured\n\nRun: gh auth login\nThen: gh repo set-default\n```\n\n**Linearis CLI not found:**\n\n```\n‚ö†Ô∏è  Linearis CLI not found\n\nPR created successfully, but Linear ticket not updated.\n\nInstall Linearis:\n  npm install -g --install-links ryanrozich/linearis#feat/cycles-cli\n\nConfigure:\n  export LINEAR_API_TOKEN=your_token\n```\n\n**Linear ticket not found:**\n\n```\n‚ö†Ô∏è  Could not find Linear ticket for {ticket}\n\nPR created successfully, but ticket not updated.\nUpdate manually or check ticket ID.\n```\n\n## Configuration\n\nUses `.claude/config.json`:\n\n```json\n{\n  \"catalyst\": {\n    \"project\": {\n      \"ticketPrefix\": \"RCW\"\n    },\n    \"linear\": {\n      \"teamKey\": \"RCW\",\n      \"inReviewStatusName\": \"In Review\"\n    }\n  }\n}\n```\n\n## Examples\n\n**Branch: `RCW-13-implement-pr-lifecycle`**\n\n```\nExtracting ticket: RCW-13\nGenerated title: \"RCW-13: Implement pr lifecycle\"\nCreating PR...\n‚úÖ PR #2 created\nCalling /catalyst-dev:describe_pr to generate description...\nUpdating Linear ticket RCW-13 ‚Üí In Review\n‚úÖ Complete!\n```\n\n**Branch: `feature-add-validation` (no ticket)**\n\n```\nNo ticket found in branch name\nGenerated title: \"Feature add validation\"\nCreating PR...\n‚úÖ PR #3 created\nCalling /catalyst-dev:describe_pr...\n‚ö†Ô∏è  No Linear ticket to update\n‚úÖ Complete!\n```\n\n## Integration with Other Commands\n\n- **Calls `/catalyst-dev:commit`** - if uncommitted changes (optional)\n- **Calls `/catalyst-dev:describe_pr`** - always, to generate comprehensive description\n- **Sets up for `/catalyst-dev:merge_pr`** - PR is now ready for review and eventual merge\n\n## Remember:\n\n- **Minimize prompts** - only ask when PR already exists\n- **Auto-rebase** - keep branch up-to-date with base\n- **Auto-link Linear** - extract ticket from branch, update status with Linearis CLI\n- **Auto-describe** - comprehensive description generated immediately\n- **Fail fast** - stop on conflicts or errors with clear messages\n- **Graceful degradation** - If Linearis not installed, warn but continue"
              },
              {
                "name": "/create_worktree",
                "description": "Create a git worktree for parallel work and optionally launch implementation session",
                "path": "plugins/dev/commands/create_worktree.md",
                "frontmatter": {
                  "description": "Create a git worktree for parallel work and optionally launch implementation session",
                  "category": "version-control-git",
                  "tools": "Bash, Read",
                  "model": "inherit",
                  "version": "1.0.0"
                },
                "content": "## Configuration Note\n\nThis command uses ticket references like `PROJ-123`. Replace `PROJ` with your Linear team's ticket\nprefix:\n\n- Read from `.claude/config.json` if available\n- Otherwise use a generic format like `TICKET-XXX`\n- Examples: `ENG-123`, `FEAT-456`, `BUG-789`\n\nYou are tasked with creating a git worktree for parallel development work.\n\n## Process\n\nWhen this command is invoked:\n\n1. **Gather required information**:\n   - Worktree name (e.g., PROJ-123, feature-name)\n   - Base branch (default: current branch)\n   - Optional: Path to implementation plan\n\n2. **Confirm with user**: Present the worktree details and get confirmation before creating.\n\n3. **Create the worktree**: Use the create-worktree.sh script:\n\n   ```bash\n   \"${CLAUDE_PLUGIN_ROOT}/scripts/create-worktree.sh\" <worktree_name> [base_branch]\n   ```\n\n   The script automatically:\n   - Detects GitHub org/repo from git remote\n   - Uses `GITHUB_SOURCE_ROOT` environment variable if set\n   - Creates worktrees in a clean, organized structure\n\n4. **Initialize thoughts** (REQUIRED - handled automatically by script):\n\n   The create-worktree.sh script automatically initializes thoughts and syncs with the shared\n   repository, giving the worktree access to:\n   - Shared research documents\n   - Implementation plans\n   - Handoff documents\n   - Team knowledge base\n\n5. **Optional: Launch implementation session**: If a plan file path was provided, ask if the user\n   wants to launch Claude in the worktree:\n   ```bash\n   humanlayer launch --model opus -w <worktree_path> \\\n     \"/implement_plan <plan_path> and when done: create commit, create PR, update Linear ticket\"\n   ```\n\n## Worktree Location Convention\n\n**Recommended Setup**: Set `GITHUB_SOURCE_ROOT` environment variable for clean organization:\n\n```bash\n# In ~/.zshrc or ~/.bashrc\nexport GITHUB_SOURCE_ROOT=\"$HOME/code-repos/github\"\n```\n\n**Convention**:\n\n- **Main repository**: `${GITHUB_SOURCE_ROOT}/<org>/<repo>`\n  - Example: `~/code-repos/github/coalesce-labs/catalyst`\n- **Worktrees**: `${GITHUB_SOURCE_ROOT}/<org>/<repo>-worktrees/<feature>`\n  - Example: `~/code-repos/github/coalesce-labs/catalyst-worktrees/PROJ-123`\n\n**Fallback behavior** (if `GITHUB_SOURCE_ROOT` not set):\n\n- Defaults to `~/wt/<repo_name>/<worktree_name>`\n\n**Why this convention?**\n\n- ‚úÖ Main branches and worktrees are organized together by org/repo\n- ‚úÖ Easy to find: all worktrees for a project in one place\n- ‚úÖ Clean separation: `<repo>` vs `<repo>-worktrees`\n- ‚úÖ Configurable per-developer via environment variable\n- ‚úÖ No hardcoded paths in scripts or documentation\n\n**Example with GITHUB_SOURCE_ROOT**:\n\n```\n~/code-repos/github/\n‚îú‚îÄ‚îÄ coalesce-labs/\n‚îÇ   ‚îú‚îÄ‚îÄ catalyst/                    # Main branch\n‚îÇ   ‚îî‚îÄ‚îÄ catalyst-worktrees/          # All worktrees\n‚îÇ       ‚îú‚îÄ‚îÄ PROJ-123-feature/\n‚îÇ       ‚îî‚îÄ‚îÄ PROJ-456-bugfix/\n‚îî‚îÄ‚îÄ acme/\n    ‚îú‚îÄ‚îÄ api/                          # Main branch\n    ‚îî‚îÄ‚îÄ api-worktrees/                # All worktrees\n        ‚îî‚îÄ‚îÄ ENG-789-oauth/\n```\n\n## Example Interaction\n\n```\nUser: /catalyst-dev:create_worktree PROJ-123\n```"
              },
              {
                "name": "/cycle_plan",
                "description": "Plan work for current or next cycle using Linearis and GitHub",
                "path": "plugins/dev/commands/cycle_plan.md",
                "frontmatter": {
                  "description": "Plan work for current or next cycle using Linearis and GitHub",
                  "category": "project-task-management",
                  "tools": "Bash(linearis *), Bash(gh *), Read, Write, TodoWrite",
                  "model": "inherit",
                  "version": "1.0.0",
                  "status": "placeholder"
                },
                "content": "# Cycle Planning\n\n**Status**: Placeholder for v1.0 - Full implementation coming in future release\n\n## Planned Functionality\n\nThis command will help you plan work for the current or upcoming cycle by:\n\n1. Fetching current and next cycle information\n2. Listing backlog tickets ready for planning\n3. Interactively assigning tickets to cycles\n4. Setting milestones and priorities\n5. Generating cycle plan summary\n\n## Current Workaround\n\nUse Linearis CLI directly:\n\n```bash\n# Get active cycle\nlinearis cycles list --team TEAM --active\n\n# List backlog tickets (filter with jq - issues list only supports --limit)\nlinearis issues list --limit 100 | jq '.[] | select(.state.name == \"Backlog\")'\n\n# Assign ticket to cycle\nlinearis issues update TICKET-123 --cycle \"Sprint 2025-11\"\n\n# Set priority\nlinearis issues update TICKET-123 --priority 2\n```\n\n### Example Workflow\n\n```bash\n# 1. View active cycle\nlinearis cycles list --team ENG --active | jq '.[] | {name, startsAt, endsAt, progress}'\n\n# 2. View next cycle\nlinearis cycles list --team ENG --limit 5 | jq '.[1]'\n\n# 3. List backlog tickets ready for planning (filter with jq)\nlinearis issues list --limit 100 | \\\n  jq '.[] | select(.state.name == \"Backlog\") | {id, title, priority}'\n\n# 4. Review recent PRs to understand current work\n# This helps identify work done but not captured in Linear tickets\ngh pr list --state merged --limit 20 --json number,title,author,mergedAt,closedAt\n\n# Filter by date range (e.g., last 2 weeks for planning context)\ngh pr list --state merged --search \"merged:>=$(date -v-14d +%Y-%m-%d)\" \\\n  --json number,title,author,mergedAt --jq '.[] | \"\\(.author.login): \\(.title)\"'\n\n# 5. Identify who is working on what\ngh pr list --state open --json number,title,author,createdAt | \\\n  jq 'group_by(.author.login) | map({author: .[0].author.login, prs: map({number, title})})'\n\n# 6. Assign high-priority tickets to next cycle\nlinearis issues update ENG-123 --cycle \"Sprint 2025-11\" --priority 2\nlinearis issues update ENG-124 --cycle \"Sprint 2025-11\" --priority 2\n\n# 7. Generate summary (manual)\n# Count tickets by cycle and priority\n```\n\n## Future Implementation\n\nWhen fully implemented, this command will:\n\n- **Interactive cycle selection** - Choose current or next cycle\n- **Smart backlog filtering** - Show tickets by priority and readiness\n- **Batch assignment** - Select multiple tickets to assign at once\n- **Capacity planning** - Estimate points/hours per ticket\n- **Milestone tracking** - Group tickets by project milestones\n- **PR-based work tracking** - Auto-detect work from merged/open PRs to identify:\n  - Work completed but not tracked in Linear\n  - Who is actively working on what\n  - Team velocity based on PR activity\n- **Team activity report** - Show contribution breakdown by team member\n- **Summary generation** - Create cycle plan document in thoughts/\n\nTrack progress at: https://github.com/coalesce-labs/catalyst/issues\n\n## Configuration\n\nUses `.claude/config.json`:\n\n```json\n{\n  \"linear\": {\n    \"teamKey\": \"ENG\",\n    \"defaultTeam\": \"Backend\"\n  }\n}\n```\n\n## Tips\n\n- Plan cycles **before they start** - gives team time to review\n- Prioritize by **user impact** and **dependencies**\n- Leave **buffer capacity** for bugs and urgent tasks\n- Use **milestones** to group related work\n- Review cycle plans in team meetings for alignment\n- **Check PR activity** before planning to understand:\n  - What work has been completed recently\n  - Who is actively contributing\n  - Untracked work that should be captured in Linear\n  - Team velocity and capacity trends"
              },
              {
                "name": "/cycle_review",
                "description": "Review cycle progress and identify blockers using Linearis and GitHub",
                "path": "plugins/dev/commands/cycle_review.md",
                "frontmatter": {
                  "description": "Review cycle progress and identify blockers using Linearis and GitHub",
                  "category": "project-task-management",
                  "tools": "Bash(linearis *), Bash(gh *), Read, Write, TodoWrite",
                  "model": "inherit",
                  "version": "1.0.0",
                  "status": "placeholder"
                },
                "content": "# Cycle Review\n\n**Status**: Placeholder for v1.0 - Full implementation coming in future release\n\n## Planned Functionality\n\nThis command will help you review cycle progress by:\n\n1. Fetching active cycle details\n2. Calculating completion percentage by status\n3. Identifying blocked tickets\n4. Generating velocity metrics\n5. Creating cycle summary report\n\n## Current Workaround\n\nUse Linearis CLI directly:\n\n```bash\n# Get active cycle with tickets\nlinearis cycles read \"Sprint 2025-10\" --team TEAM\n\n# List tickets by status (use cycles read to get all issues, then filter)\nlinearis cycles read \"Sprint 2025-10\" --team TEAM | \\\n  jq '.issues[] | select(.state.name == \"In Progress\")'\nlinearis cycles read \"Sprint 2025-10\" --team TEAM | \\\n  jq '.issues[] | select(.state.name == \"Done\")'\n\n# Calculate completion manually (count tickets)\n```\n\n### Example Workflow\n\n```bash\n# 1. Get active cycle info\nCYCLE=$(linearis cycles list --team ENG --active | jq -r '.[0].name')\necho \"Active cycle: $CYCLE\"\n\n# 2. Get all tickets in cycle\nlinearis issues list --team ENG | \\\n  jq --arg cycle \"$CYCLE\" '.[] | select(.cycle.name == $cycle)'\n\n# 3. Count by status (use cycles read to get issues)\nCYCLE_DATA=$(linearis cycles read \"$CYCLE\" --team ENG)\n\necho \"Backlog:\"\necho \"$CYCLE_DATA\" | jq '[.issues[] | select(.state.name == \"Backlog\")] | length'\n\necho \"In Progress:\"\necho \"$CYCLE_DATA\" | jq '[.issues[] | select(.state.name == \"In Progress\")] | length'\n\necho \"Done:\"\necho \"$CYCLE_DATA\" | jq '[.issues[] | select(.state.name == \"Done\")] | length'\n\n# 4. Calculate completion percentage\n# total_tickets = backlog + in_progress + done\n# completion = (done / total_tickets) * 100\n\n# 5. Find blocked tickets (use cycles read)\nlinearis cycles read \"$CYCLE\" --team ENG | \\\n  jq '.issues[] | select(.state.name == \"Blocked\") | {id, title, blockedReason}'\n\n# 6. Review PRs merged during cycle\n# Get cycle start date (example: 2 weeks ago)\nCYCLE_START=$(date -v-14d +%Y-%m-%d)\n\n# List all PRs merged during cycle\ngh pr list --state merged --search \"merged:>=$CYCLE_START\" \\\n  --json number,title,author,mergedAt --jq \\\n  '.[] | \"\\(.mergedAt | split(\"T\")[0]) - \\(.author.login): \\(.title)\"'\n\n# 7. Identify active contributors\ngh pr list --state merged --search \"merged:>=$CYCLE_START\" \\\n  --json author --jq '[.[].author.login] | group_by(.) | map({author: .[0], count: length}) | sort_by(-.count)'\n\n# 8. Check open PRs (work in progress)\ngh pr list --state open --json number,title,author,createdAt,isDraft | \\\n  jq '.[] | {author: .author.login, title, days_open: ((now - (.createdAt | fromdateiso8601)) / 86400 | floor), draft: .isDraft}'\n\n# 9. Find work without Linear tickets\n# Compare PR titles with Linear ticket IDs (TEAM-XXX pattern)\ngh pr list --state merged --search \"merged:>=$CYCLE_START\" \\\n  --json number,title --jq '.[] | select(.title | test(\"TEAM-[0-9]+\") | not) | {number, title}'\n```\n\n## Future Implementation\n\nWhen fully implemented, this command will:\n\n- **Automated metrics** - Calculate completion, velocity, cycle time\n- **Status breakdown** - Show tickets grouped by status with percentages\n- **Blocker identification** - Highlight blocked tickets with reasons\n- **Trend analysis** - Compare to previous cycles\n- **Risk assessment** - Identify at-risk tickets (large, old, no progress)\n- **PR-based activity tracking** - Analyze GitHub PR data to:\n  - Identify who completed what work during the cycle\n  - Find work done without Linear tickets (untracked work)\n  - Calculate actual velocity based on merged PRs\n  - Show contributor activity breakdown\n  - Flag stale PRs that need attention\n- **Work reconciliation** - Match PRs to Linear tickets, flag mismatches\n- **Team contribution report** - Show per-person breakdown of PRs and tickets\n- **Summary generation** - Create review document in thoughts/\n- **Burndown visualization** - Show progress over time (text-based chart)\n\nTrack progress at: https://github.com/coalesce-labs/catalyst/issues\n\n## Configuration\n\nUses `.claude/config.json`:\n\n```json\n{\n  \"linear\": {\n    \"teamKey\": \"ENG\",\n    \"defaultTeam\": \"Backend\"\n  }\n}\n```\n\n## Tips\n\n- Review **mid-cycle** to course-correct\n- Review **end-of-cycle** for retrospectives\n- Track **blockers daily** - don't wait for review\n- Compare velocity across cycles for **capacity planning**\n- Document **lessons learned** for process improvement\n- Celebrate **wins** - acknowledge team progress\n- **Use PR data to understand actual work**:\n  - Merged PRs show completed work (even if not in Linear)\n  - Open PRs show current work in progress\n  - PR activity reveals team contribution patterns\n  - Missing ticket references indicate process gaps\n- **Reconcile Linear and GitHub regularly** to ensure all work is tracked"
              },
              {
                "name": "/debug",
                "description": "Debug issues by investigating logs, database state, and git history",
                "path": "plugins/dev/commands/debug.md",
                "frontmatter": {
                  "description": "Debug issues by investigating logs, database state, and git history",
                  "category": "dev",
                  "tools": "Read, Bash, Task, Grep",
                  "model": "inherit",
                  "version": "1.0.0"
                },
                "content": "# Debug\n\nYou are tasked with helping debug issues during manual testing or implementation. This command\nallows you to investigate problems by examining logs, database state, and git history without\nediting files. Think of this as a way to bootstrap a debugging session without using the primary\nwindow's context.\n\n## Initial Response\n\nWhen invoked WITH a plan/ticket file:\n\n```\nI'll help debug issues with [file name]. Let me understand the current state.\n\nWhat specific problem are you encountering?\n- What were you trying to test/implement?\n- What went wrong?\n- Any error messages?\n\nI'll investigate the logs, database, and git state to help figure out what's happening.\n```\n\nWhen invoked WITHOUT parameters:\n\n```\nI'll help debug your current issue.\n\nPlease describe what's going wrong:\n- What are you working on?\n- What specific problem occurred?\n- When did it last work?\n\nI can investigate logs, database state, and recent changes to help identify the issue.\n```\n\n## Environment Information\n\nYou have access to these key locations and tools:\n\n**Logs** (automatically created by `make daemon` and `make wui`):\n\n- MCP logs: `~/.humanlayer/logs/mcp-claude-approvals-*.log`\n- Combined WUI/Daemon logs: `~/.humanlayer/logs/wui-${BRANCH_NAME}/codelayer.log`\n- First line shows: `[timestamp] starting [service] in [directory]`\n\n**Database**:\n\n- Location: `~/.humanlayer/daemon-{BRANCH_NAME}.db`\n- SQLite database with sessions, events, approvals, etc.\n- Can query directly with `sqlite3`\n\n**Git State**:\n\n- Check current branch, recent commits, uncommitted changes\n- Similar to how `commit` and `describe_pr` commands work\n\n**Service Status**:\n\n- Check if daemon is running: `ps aux | grep hld`\n- Check if WUI is running: `ps aux | grep wui`\n- Socket exists: `~/.humanlayer/daemon.sock`\n\n## Process Steps\n\n### Step 1: Understand the Problem\n\nAfter the user describes the issue:\n\n1. **Read any provided context** (plan or ticket file):\n   - Understand what they're implementing/testing\n   - Note which phase or step they're on\n   - Identify expected vs actual behavior\n\n2. **Quick state check**:\n   - Current git branch and recent commits\n   - Any uncommitted changes\n   - When the issue started occurring\n\n### Step 2: Investigate the Issue\n\nSpawn parallel Task agents for efficient investigation:\n\n```\nTask 1 - Check Recent Logs:\nFind and analyze the most recent logs for errors:\n1. Find latest daemon log: ls -t ~/.humanlayer/logs/daemon-*.log | head -1\n2. Find latest WUI log: ls -t ~/.humanlayer/logs/wui-*.log | head -1\n3. Search for errors, warnings, or issues around the problem timeframe\n4. Note the working directory (first line of log)\n5. Look for stack traces or repeated errors\nReturn: Key errors/warnings with timestamps\n```\n\n```\nTask 2 - Database State:\nCheck the current database state:\n1. Connect to database: sqlite3 ~/.humanlayer/daemon.db\n2. Check schema: .tables and .schema for relevant tables\n3. Query recent data:\n   - SELECT * FROM sessions ORDER BY created_at DESC LIMIT 5;\n   - SELECT * FROM conversation_events WHERE created_at > datetime('now', '-1 hour');\n   - Other queries based on the issue\n4. Look for stuck states or anomalies\nReturn: Relevant database findings\n```\n\n```\nTask 3 - Git and File State:\nUnderstand what changed recently:\n1. Check git status and current branch\n2. Look at recent commits: git log --oneline -10\n3. Check uncommitted changes: git diff\n4. Verify expected files exist\n5. Look for any file permission issues\nReturn: Git state and any file issues\n```\n\n### Step 3: Present Findings\n\nBased on the investigation, present a focused debug report:\n\n````markdown\n## Debug Report\n\n### What's Wrong\n\n[Clear statement of the issue based on evidence]\n\n### Evidence Found\n\n**From Logs** (`~/.humanlayer/logs/`):\n\n- [Error/warning with timestamp]\n- [Pattern or repeated issue]\n\n**From Database**:\n\n```sql\n-- Relevant query and result\n[Finding from database]\n```\n````\n\n**From Git/Files**:\n\n- [Recent changes that might be related]\n- [File state issues]\n\n### Root Cause\n\n[Most likely explanation based on evidence]\n\n### Next Steps\n\n1. **Try This First**:\n\n   ```bash\n   [Specific command or action]\n   ```\n\n2. **If That Doesn't Work**:\n   - Restart services: `make daemon` and `make wui`\n   - Check browser console for WUI errors\n   - Run with debug: `HUMANLAYER_DEBUG=true make daemon`\n\n### Can't Access?\n\nSome issues might be outside my reach:\n\n- Browser console errors (F12 in browser)\n- MCP server internal state\n- System-level issues\n\nWould you like me to investigate something specific further?\n\n````\n\n## Important Notes\n\n- **Focus on manual testing scenarios** - This is for debugging during implementation\n- **Always require problem description** - Can't debug without knowing what's wrong\n- **Read files completely** - No limit/offset when reading context\n- **Think like `commit` or `describe_pr`** - Understand git state and changes\n- **Guide back to user** - Some issues (browser console, MCP internals) are outside reach\n- **No file editing** - Pure investigation only\n\n## Quick Reference\n\n**Find Latest Logs**:\n```bash\nls -t ~/.humanlayer/logs/daemon-*.log | head -1\nls -t ~/.humanlayer/logs/wui-*.log | head -1\n````\n\n**Database Queries**:\n\n```bash\nsqlite3 ~/.humanlayer/daemon.db \".tables\"\nsqlite3 ~/.humanlayer/daemon.db \".schema sessions\"\nsqlite3 ~/.humanlayer/daemon.db \"SELECT * FROM sessions ORDER BY created_at DESC LIMIT 5;\"\n```\n\n**Service Check**:\n\n```bash\nps aux | grep hld     # Is daemon running?\nps aux | grep wui     # Is WUI running?\n```\n\n**Git State**:\n\n```bash\ngit status\ngit log --oneline -10\ngit diff\n```\n\nRemember: This command helps you investigate without burning the primary window's context. Perfect\nfor when you hit an issue during manual testing and need to dig into logs, database, or git state."
              },
              {
                "name": "/describe_pr",
                "description": "Generate or update PR description with incremental changes",
                "path": "plugins/dev/commands/describe_pr.md",
                "frontmatter": {
                  "description": "Generate or update PR description with incremental changes",
                  "category": "version-control-git",
                  "tools": "Bash, Read, Write",
                  "model": "inherit",
                  "version": "2.0.0"
                },
                "content": "# Generate/Update PR Description\n\nGenerates or updates PR description with incremental information, auto-updates title, and links\nLinear tickets.\n\n## Prerequisites\n\nBefore executing, verify all required tools and systems:\n\n```bash\n# 1. Validate thoughts system (REQUIRED)\nif [[ -f \"scripts/validate-thoughts-setup.sh\" ]]; then\n  ./scripts/validate-thoughts-setup.sh || exit 1\nelse\n  # Inline validation if script not found\n  if [[ ! -d \"thoughts/shared\" ]]; then\n    echo \"‚ùå ERROR: Thoughts system not configured\"\n    echo \"Run: ./scripts/humanlayer/init-project.sh . {project-name}\"\n    exit 1\n  fi\nfi\n\n# 2. Validate plugin scripts\nif [[ -f \"${CLAUDE_PLUGIN_ROOT}/scripts/check-prerequisites.sh\" ]]; then\n  \"${CLAUDE_PLUGIN_ROOT}/scripts/check-prerequisites.sh\" || exit 1\nfi\n```\n\n## Process:\n\n### 1. Read PR description template\n\n```bash\n# Check if template exists\nif [ ! -f \"thoughts/shared/pr_description.md\" ]; then\n    echo \"‚ùå PR description template not found\"\nfi\n```\n\nIf missing:\n\n```\n‚ùå PR description template missing\n\nYour humanlayer thoughts setup is incomplete. Create a template at:\n  thoughts/shared/pr_description.md\n\nSee the PR description template you created earlier for reference.\n```\n\nRead template fully to understand all sections.\n\n### 2. Identify target PR\n\n**If argument provided:**\n\n- Use that PR number: `/describe_pr 123`\n\n**If no argument:**\n\n```bash\n# Try current branch\ngh pr view --json number,url,title,state,body,headRefName,baseRefName 2>/dev/null\n```\n\nIf no PR on current branch OR on main/master:\n\n```bash\n# List recent PRs\ngh pr list --limit 10 --json number,title,headRefName,state\n```\n\nAsk user: \"Which PR would you like to describe? (enter number)\"\n\n### 3. Extract ticket reference\n\n**From multiple sources:**\n\n```bash\n# 1. From branch name\nbranch=$(gh pr view $pr_number --json headRefName -q .headRefName)\nif [[ \"$branch\" =~ ([A-Z]+)-([0-9]+) ]]; then\n    ticket=\"${BASH_REMATCH[0]}\"\nfi\n\n# 2. From PR title\ntitle=$(gh pr view $pr_number --json title -q .title)\nif [[ \"$title\" =~ ([A-Z]+)-([0-9]+) ]]; then\n    ticket=\"${BASH_REMATCH[0]}\"\nfi\n\n# 3. From existing PR body\nbody=$(gh pr view $pr_number --json body -q .body)\nif [[ \"$body\" =~ Refs:\\ ([A-Z]+-[0-9]+) ]]; then\n    ticket=\"${BASH_REMATCH[1]}\"\nfi\n```\n\n### 4. Read existing descriptions\n\n**Read current PR body from GitHub:**\n\n```bash\ncurrent_body=$(gh pr view $pr_number --json body -q .body)\n```\n\n**Read saved description (if exists):**\n\n```bash\nsaved_desc=\"thoughts/shared/prs/${pr_number}_description.md\"\nif [ -f \"$saved_desc\" ]; then\n    # Read fully\n    # Note what sections exist vs what's new\nfi\n```\n\n**Check for metadata header:**\n\n```markdown\n<!-- Auto-generated: 2025-10-06T10:30:00Z -->\n<!-- Last updated: 2025-10-06T14:45:00Z -->\n<!-- PR: #123 -->\n<!-- Previous commits: abc123,def456 -->\n```\n\n### 5. Gather comprehensive PR information\n\n```bash\n# Full diff\ngh pr diff $pr_number\n\n# Commit history with messages\ngh pr view $pr_number --json commits\n\n# Changed files\ngh pr view $pr_number --json files\n\n# PR metadata\ngh pr view $pr_number --json url,title,number,state,baseRefName,headRefName,author\n\n# CI/CD status\ngh pr checks $pr_number\n```\n\n### 6. Analyze changes incrementally\n\n**If this is an UPDATE (saved description exists):**\n\n```bash\n# Extract previous commit list from metadata\nprev_commits=$(grep \"Previous commits:\" $saved_desc | sed 's/.*: //')\n\n# Get current commits\ncurrent_commits=$(gh pr view $pr_number --json commits -q '.commits[].oid' | tr '\\n' ',' | sed 's/,$//')\n\n# Compare\nnew_commits=$(comm -13 <(echo \"$prev_commits\" | tr ',' '\\n' | sort) <(echo \"$current_commits\" | tr ',' '\\n' | sort))\n```\n\n**Analysis:**\n\n- Identify what's NEW since last description\n- Deep analysis of:\n  - Code changes and architectural impact\n  - Breaking changes\n  - User-facing vs internal changes\n  - Migration requirements\n  - Security implications\n\n### 7. Merge descriptions intelligently\n\n**Auto-generated sections (always update):**\n\n- **Summary** - regenerate based on ALL changes\n- **Changes Made** - append new changes, preserve old\n- **How to Verify It** - update checklist, rerun checks\n- **Changelog Entry** - update to reflect all changes\n\n**Preserve manual edits in:**\n\n- **Reviewer Notes** - keep existing unless explicitly empty\n- **Screenshots/Videos** - never overwrite\n- **Manually checked boxes** - preserve [x] marks for manual steps\n- **Post-Merge Tasks** - append new, keep existing\n\n**Merging strategy:**\n\n```markdown\n## Changes Made\n\n### Backend Changes\n\n[Existing changes from previous description]\n\n**New changes** (since last update):\n\n- [New change 1]\n- [New change 2]\n\n### Frontend Changes\n\n[Existing + new merged together]\n```\n\n**Add change summary at top:**\n\n```markdown\n<!-- Auto-generated: 2025-10-06T15:00:00Z -->\n<!-- Last updated: 2025-10-06T15:00:00Z -->\n<!-- PR: #123 -->\n<!-- Previous commits: abc123,def456,ghi789 -->\n\n---\n\n**Update History:**\n\n- 2025-10-06 15:00: Added validation logic, updated tests (3 new commits)\n- 2025-10-06 10:30: Initial implementation (5 commits)\n\n---\n```\n\n### 8. Add Linear reference\n\nIf ticket found:\n\n```markdown\n## Related Issues/PRs\n\n- Fixes https://linear.app/{workspace}/issue/{ticket}\n- Related to [any other linked issues]\n```\n\nGet Linear ticket details:\n\n```bash\n# Use Linearis CLI to get ticket details\nlinearis issues read \"$ticket\"\n\n# Extract title and description with jq\nticket_title=$(linearis issues read \"$ticket\" | jq -r '.title')\nticket_description=$(linearis issues read \"$ticket\" | jq -r '.description')\n```\n\nUse ticket title and description for context.\n\n### 9. Generate updated title\n\n**Title generation rules:**\n\n```bash\n# If ticket exists\nif [[ \"$ticket\" ]]; then\n    # Get ticket title from Linear\n    ticket_title=$(linear API or fallback to branch)\n\n    # Format: TICKET: Descriptive title (max 72 chars)\n    title=\"$ticket: ${ticket_title:0:60}\"\nelse\n    # Generate from primary change\n    # Analyze commits and code changes\n    title=\"Brief summary of main change\"\nfi\n```\n\n**Auto-update without prompt** - title is auto-generated section.\n\n### 10. Run verification checks\n\n**For each checklist item in \"How to Verify It\":**\n\n```bash\n# Example: \"- [ ] Build passes: `make build`\"\n# Extract command: make build\n\n# Try to run\nif command -v make >/dev/null 2>&1; then\n    if make build 2>&1; then\n        # Mark as checked\n        checkbox=\"- [x] Build passes: \\`make build\\` ‚úÖ\"\n    else\n        # Mark unchecked with error\n        checkbox=\"- [ ] Build passes: \\`make build\\` ‚ùå (failed: $error)\"\n    fi\nelse\n    # Can't run\n    checkbox=\"- [ ] Build passes: \\`make build\\` (manual verification required)\"\nfi\n```\n\n**Common checks to attempt:**\n\n- `make test` / `npm test` / `pytest`\n- `make lint` / `npm run lint`\n- `npm run typecheck` / `tsc --noEmit`\n- `make build` / `npm run build`\n\n**Document results:**\n\n- ‚úÖ if passed\n- ‚ùå if failed (with error)\n- Manual required if can't automate\n\n### 11. Save and sync\n\n**Save description:**\n\n```bash\n# Add metadata header\ncat > \"thoughts/shared/prs/${pr_number}_description.md\" <<EOF\n<!-- Auto-generated: $(date -u +%Y-%m-%dT%H:%M:%SZ) -->\n<!-- Last updated: $(date -u +%Y-%m-%dT%H:%M:%SZ) -->\n<!-- PR: #$pr_number -->\n<!-- Previous commits: $commit_list -->\n\n[Full description content]\nEOF\n```\n\n**Sync thoughts:**\n\n```bash\nhumanlayer thoughts sync\n```\n\n### 12. Update PR on GitHub\n\n**CRITICAL: NO CLAUDE ATTRIBUTION**\n\nBefore updating the PR, ensure the description contains NO Claude attribution:\n\n‚ùå **Remove these if present**:\n- \"Generated with Claude Code\" or similar messages\n- \"Co-Authored-By: Claude\" lines\n- Any reference to AI assistance or Anthropic\n- Links to Claude Code documentation\n\n‚úÖ **Keep descriptions professional and human-authored**:\n- Focus on code changes and their purpose\n- Attribute work to the git author (the human developer)\n- Write in first-person if needed (\"I added...\", \"We implemented...\")\n\n**Update title:**\n\n```bash\ngh pr edit $pr_number --title \"$new_title\"\n```\n\n**Update body:**\n\n```bash\n# Ensure no Claude attribution in the description file\ngh pr edit $pr_number --body-file \"thoughts/shared/prs/${pr_number}_description.md\"\n```\n\n### 13. Update Linear ticket\n\nIf ticket found:\n\n```bash\n# Verify linearis is available\nif ! command -v linearis &> /dev/null; then\n    echo \"‚ö†Ô∏è  Linearis CLI not found - skipping Linear ticket update\"\nelse\n    # If not already in \"In Review\", move it and assign to self\n    linearis issues update \"$ticket\" --state \"In Review\" --assignee \"@me\"\n\n    # Add comment about update with PR link\n    linearis comments create \"$ticket\" \\\n        --body \"PR description updated!\\n\\n**Changes**: ${updateSummary}\\n**Verification**: ${checksPassedCount}/${totalChecks} automated checks passed\\n\\nView PR: ${prUrl}\"\nfi\n```\n\n### 14. Report results\n\n**If first-time generation:**\n\n```\n‚úÖ PR description generated!\n\n**PR**: #123 - {title}\n**URL**: {url}\n**Verification**: {X}/{Y} automated checks passed\n**Linear**: {ticket} updated\n\nManual verification steps remaining:\n- [ ] Test feature in staging\n- [ ] Verify UI on mobile\n\nReview PR on GitHub!\n```\n\n**If incremental update:**\n\n```\n‚úÖ PR description updated!\n\n**Changes since last update**:\n- 3 new commits\n- Added validation logic\n- Updated tests\n\n**Verification**: {X}/{Y} automated checks passed\n**Sections updated**: Summary, Changes Made, How to Verify It\n**Sections preserved**: Reviewer Notes, Screenshots\n\n**What changed**:\n  Updated: Summary, Backend Changes, Automated Checks\n  Preserved: Manual verification steps, Reviewer notes\n  Added: New validation section\n\nReview updated PR: {url}\n```\n\n## Metadata Management\n\n**First generation:**\n\n```markdown\n<!-- Auto-generated: 2025-10-06T10:00:00Z -->\n<!-- Last updated: 2025-10-06T10:00:00Z -->\n<!-- PR: #123 -->\n<!-- Previous commits: abc123,def456 -->\n```\n\n**Subsequent updates:**\n\n```markdown\n<!-- Auto-generated: 2025-10-06T10:00:00Z -->\n<!-- Last updated: 2025-10-06T15:30:00Z -->\n<!-- PR: #123 -->\n<!-- Previous commits: abc123,def456,ghi789,jkl012 -->\n\n---\n\n**Update History:**\n\n- 2025-10-06 15:30: Added error handling, fixed tests (2 commits)\n- 2025-10-06 10:00: Initial implementation (2 commits)\n\n---\n```\n\n## Incremental Update Examples\n\n**Example 1: Code review changes**\n\n```\nUser pushes 2 commits after code review feedback\n\n/catalyst-dev:describe_pr detects:\n- 2 new commits\n- Changes in validation logic\n- New tests added\n\nUpdates:\n- Appends to \"Backend Changes\"\n- Updates \"How to Verify It\" (reruns test check)\n- Updates Summary to mention review changes\n- Preserves reviewer notes and screenshots\n- Adds to update history\n```\n\n**Example 2: Multiple updates**\n\n```\nUpdate 1 (initial): 5 commits\nUpdate 2 (review): 3 commits\nUpdate 3 (fixes): 2 commits\n\nDescription shows:\n- Complete history in update log\n- All changes accumulated\n- Latest verification status\n- All manual notes preserved\n```\n\n## Error Handling\n\n**No PR found:**\n\n```\n‚ùå No PR found for current branch\n\nOpen PRs:\n  #120 - Feature A (feature-a branch)\n  #121 - Fix B (fix-b branch)\n\nWhich PR? (enter number)\n```\n\n**Template missing:**\n\n```\n‚ùå PR description template required\n\nCreate: thoughts/shared/pr_description.md\nSee earlier in conversation for template structure.\n```\n\n**Verification command fails:**\n\n```\n‚ö†Ô∏è  Some automated checks failed\n\nFailed:\n- make test (exit code 1)\n  Error: 2 tests failed in validation.test.ts\n\nPassed:\n- make lint ‚úÖ\n- make build ‚úÖ\n\nFix failing tests before merge or document as known issues.\n```\n\n## Configuration\n\nUses `.claude/config.json`:\n\n```json\n{\n  \"catalyst\": {\n    \"project\": {\n      \"ticketPrefix\": \"RCW\"\n    },\n    \"linear\": {\n      \"teamId\": \"team-id\",\n      \"inReviewStatusName\": \"In Review\"\n    },\n    \"pr\": {\n      \"testCommand\": \"make test\",\n      \"lintCommand\": \"make lint\",\n      \"buildCommand\": \"make build\"\n    }\n  }\n}\n```\n\n## Remember:\n\n- **No interactive prompts** - fully automated\n- **Incremental updates** - preserve manual edits, append new\n- **Auto-update title** - based on analysis\n- **Run verification** - attempt all automated checks\n- **Link Linear** - extract ticket, update status\n- **Show what changed** - clear summary of updates\n- **Full context** - read entire existing description\n- **Metadata tracking** - commit history, timestamps"
              },
              {
                "name": "/implement_plan",
                "description": "Implement approved technical plans from thoughts/shared/plans/",
                "path": "plugins/dev/commands/implement_plan.md",
                "frontmatter": {
                  "description": "Implement approved technical plans from thoughts/shared/plans/",
                  "category": "workflow",
                  "tools": "Read, Write, Edit, Grep, Glob, Task, TodoWrite, Bash",
                  "model": "inherit",
                  "version": "1.0.0"
                },
                "content": "# Implement Plan\n\nYou are tasked with implementing an approved technical plan from `thoughts/shared/plans/`. These\nplans contain phases with specific changes and success criteria.\n\n## Prerequisites\n\nBefore executing, verify required tools are installed:\n\n```bash\nif [[ -f \"${CLAUDE_PLUGIN_ROOT}/scripts/check-prerequisites.sh\" ]]; then\n  \"${CLAUDE_PLUGIN_ROOT}/scripts/check-prerequisites.sh\" || exit 1\nfi\n```\n\n## Initial Response\n\n**STEP 1: Auto-discover recent plan (REQUIRED)**\n\nIMMEDIATELY run this bash script BEFORE any other response:\n\n```bash\n# Auto-discover most recent plan from workflow context\nif [[ -f \"${CLAUDE_PLUGIN_ROOT}/scripts/workflow-context.sh\" ]]; then\n  RECENT_PLAN=$(\"${CLAUDE_PLUGIN_ROOT}/scripts/workflow-context.sh\" recent plans)\n  if [[ -n \"$RECENT_PLAN\" ]]; then\n    echo \"üìã Auto-discovered recent plan: $RECENT_PLAN\"\n    echo \"\"\n  fi\nfi\n```\n\n**STEP 2: Determine which plan to implement**\n\nAfter running the auto-discovery script, follow this logic:\n\n1. **If user provided a plan path as parameter**:\n   - Use the provided path (user override)\n   - Skip to Step 3\n\n2. **If no parameter provided AND RECENT_PLAN was found**:\n   - Show user: \"üìã Found recent plan: $RECENT_PLAN\"\n   - Ask: \"**Proceed with this plan?** [Y/n]\"\n   - If yes: use RECENT_PLAN and skip to Step 3\n   - If no: proceed to option 3\n\n3. **If no parameter AND no RECENT_PLAN found**:\n   - List available plans from `thoughts/shared/plans/`\n   - Show most recent 5 plans with dates and ticket numbers\n   - Ask user which plan to implement\n   - Wait for user input with plan path\n\n**STEP 3: Read and prepare**\n\nOnce you have a plan path:\n- Read the plan completely (no limit/offset)\n- Check for any existing checkmarks (- [x]) to see what's done\n- Read the original ticket and all files mentioned in the plan\n- Think deeply about how the pieces fit together\n- Create a todo list to track your progress\n- Start implementing if you understand what needs to be done\n\n## Implementation Philosophy\n\nPlans are carefully designed, but reality can be messy. Your job is to:\n\n- Follow the plan's intent while adapting to what you find\n- Implement each phase fully before moving to the next\n- Verify your work makes sense in the broader codebase context\n- Update checkboxes in the plan as you complete sections\n\nWhen things don't match the plan exactly, think about why and communicate clearly. The plan is your\nguide, but your judgment matters too.\n\nIf you encounter a mismatch:\n\n- STOP and think deeply about why the plan can't be followed\n- Present the issue clearly:\n\n  ```\n  Issue in Phase [N]:\n  Expected: [what the plan says]\n  Found: [actual situation]\n  Why this matters: [explanation]\n\n  How should I proceed?\n  ```\n\n## Verification Approach\n\nAfter implementing a phase:\n\n- Run the success criteria checks (usually `make check test` covers everything)\n- Fix any issues before proceeding\n- Update your progress in both the plan and your todos\n- Check off completed items in the plan file itself using Edit\n- **Check context usage** - monitor token consumption\n\nDon't let verification interrupt your flow - batch it at natural stopping points.\n\n## Context Management During Implementation\n\n**Monitor context proactively throughout implementation**:\n\n**After Each Phase**:\n\n```\n‚úÖ Phase {N} complete!\n\n## üìä Context Status\nCurrent usage: {X}% ({Y}K/{Z}K tokens)\n\n{If >60%}:\n‚ö†Ô∏è **Context Alert**: We're at {X}% usage.\n\n**Recommendation**: Create a handoff before continuing to Phase {N+1}.\n\n**Why?** Implementation accumulates context:\n- File reads\n- Code changes\n- Test outputs\n- Error messages\n- Context clears ensure continued high performance\n\n**Options**:\n1. ‚úÖ Create handoff and clear context (recommended)\n   - Use `/create-handoff` to generate properly formatted handoff\n   - Format: `thoughts/shared/handoffs/{ticket}/YYYY-MM-DD_HH-MM-SS_description.md`\n   - Includes timestamp for lexical sorting by recency\n2. Continue to next phase (if close to completion)\n\n**To resume**: Start fresh session, run `/implement-plan {plan-path}`\n(The plan file tracks progress with checkboxes - you'll resume automatically)\n\n{If <60%}:\n‚úÖ Context healthy. Ready for Phase {N+1}.\n```\n\n**When to Warn**:\n\n- After any phase if context >60%\n- If context >70%, strongly recommend handoff\n- If context >80%, STOP and require handoff\n- If user is spinning on errors (3+ attempts), suggest context clear\n\n**Educate About Phase-Based Context**:\n\n- Explain that implementation is designed to work in chunks\n- Each phase completion is a natural handoff point\n- Plan file preserves progress across sessions\n- Fresh context = fresh perspective on next phase\n\n**Creating a Handoff**:\n\nWhen recommending a handoff, guide the user:\n\n1. Offer to create the handoff using `/create-handoff`\n2. Or create a manual handoff following the timestamp convention\n3. Handoff filename format: `thoughts/shared/handoffs/{ticket}/YYYY-MM-DD_HH-MM-SS_description.md`\n4. Include: completed phases, next steps, key learnings, file references\n5. Update plan file with checkboxes for completed work\n\n## If You Get Stuck\n\nWhen something isn't working as expected:\n\n- First, make sure you've read and understood all the relevant code\n- Consider if the codebase has evolved since the plan was written\n- Present the mismatch clearly and ask for guidance\n\nUse sub-tasks sparingly - mainly for targeted debugging or exploring unfamiliar territory.\n\n## Resuming Work\n\nIf the plan has existing checkmarks:\n\n- Trust that completed work is done\n- Pick up from the first unchecked item\n- Verify previous work only if something seems off\n\nRemember: You're implementing a solution, not just checking boxes. Keep the end goal in mind and\nmaintain forward momentum."
              },
              {
                "name": "/linear",
                "description": "Manage Linear tickets with workflow automation",
                "path": "plugins/dev/commands/linear.md",
                "frontmatter": {
                  "description": "Manage Linear tickets with workflow automation",
                  "category": "project-task-management",
                  "tools": "Bash(linearis *), Read, Write, Edit, Grep",
                  "model": "inherit",
                  "version": "1.0.0"
                },
                "content": "# Linear - Ticket Management\n\nYou are tasked with managing Linear tickets, including creating tickets from thoughts documents,\nupdating existing tickets, and following a structured workflow using the Linearis CLI.\n\n## Prerequisites Check\n\nFirst, verify that Linearis CLI is installed and configured:\n\n```bash\nif ! command -v linearis &> /dev/null; then\n    echo \"‚ùå Linearis CLI not found\"\n    echo \"\"\n    echo \"Install with:\"\n    echo \"  npm install -g --install-links ryanrozich/linearis#feat/cycles-cli\"\n    echo \"\"\n    echo \"Configure with:\"\n    echo \"  export LINEAR_API_TOKEN=your_token\"\n    echo \"  # or create ~/.linear_api_token file\"\n    exit 1\nfi\n```\n\n## Configuration\n\nRead team configuration from `.claude/config.json`:\n\n```bash\nCONFIG_FILE=\".claude/config.json\"\n\n# Read team key (e.g., \"ENG\", \"PROJ\")\nTEAM_KEY=$(jq -r '.catalyst.linear.teamKey // \"PROJ\"' \"$CONFIG_FILE\")\n\n# Read default team name (optional)\nDEFAULT_TEAM=$(jq -r '.catalyst.linear.defaultTeam // null' \"$CONFIG_FILE\")\n\n# Read thoughts repo URL\nTHOUGHTS_URL=$(jq -r '.catalyst.linear.thoughtsRepoUrl // \"https://github.com/org/thoughts/blob/main\"' \"$CONFIG_FILE\")\n```\n\n**Configuration in `.claude/config.json`**:\n\n```json\n{\n  \"linear\": {\n    \"teamKey\": \"ENG\",\n    \"defaultTeam\": \"Backend\",\n    \"thoughtsRepoUrl\": \"https://github.com/coalesce-labs/thoughts/blob/main\"\n  }\n}\n```\n\n## Initial Response\n\nIf tools are available, respond based on the user's request:\n\n### For general requests:\n\n```\nI can help you with Linear tickets. What would you like to do?\n1. Create a new ticket from a thoughts document\n2. Add a comment to a ticket (I'll use our conversation context)\n3. Search for tickets\n4. Update ticket status or details\n5. Move ticket through workflow\n```\n\nThen wait for the user's input.\n\n---\n\n## Workflow & Status Progression\n\nThis workflow ensures alignment through planning before implementation:\n\n### Workflow Statuses\n\n1. **Backlog** ‚Üí New ideas and feature requests\n2. **Triage** ‚Üí Initial review and prioritization\n3. **Spec Needed** ‚Üí Needs problem statement and solution outline\n4. **Research Needed** ‚Üí Requires investigation\n5. **Research in Progress** ‚Üí Active research underway\n6. **Ready for Plan** ‚Üí Research complete, needs implementation plan\n7. **Plan in Progress** ‚Üí Writing implementation plan\n8. **Plan in Review** ‚Üí Plan under discussion\n9. **Ready for Dev** ‚Üí Plan approved, ready to implement\n10. **In Dev** ‚Üí Active development\n11. **In Review** ‚Üí PR submitted\n12. **Done** ‚Üí Completed\n\n**Note**: These statuses must be configured in your Linear workspace settings. The Linearis CLI will\nread and use whatever states exist in your workspace.\n\n### Key Principle\n\n**Review and alignment happen at the plan stage (not PR stage)** to move faster and avoid rework.\n\n### Workflow Commands Integration\n\nThese commands automatically update ticket status:\n\n- `/catalyst-dev:create_plan` ‚Üí Moves ticket to \"Plan in Progress\"\n- Plan completed ‚Üí Moves to \"Plan in Review\"\n- `/catalyst-dev:implement_plan` ‚Üí Moves to \"In Dev\"\n- `/catalyst-dev:create_pr` ‚Üí Moves to \"In Review\"\n- `/catalyst-dev:merge_pr` ‚Üí Moves to \"Done\"\n\n---\n\n## Important Conventions\n\n### URL Mapping for Thoughts Documents\n\nWhen referencing thoughts documents, always provide GitHub links:\n\n- `thoughts/shared/...` ‚Üí `{thoughtsRepoUrl}/repos/{project}/shared/...`\n- `thoughts/{user}/...` ‚Üí `{thoughtsRepoUrl}/repos/{project}/{user}/...`\n- `thoughts/global/...` ‚Üí `{thoughtsRepoUrl}/global/...`\n\n### Default Values\n\n- **Status**: Create new tickets in \"Backlog\" status\n- **Priority**: Default to Medium (3) for most tasks\n  - Urgent (1): Critical blockers, security issues\n  - High (2): Important features with deadlines, major bugs\n  - Medium (3): Standard implementation tasks (default)\n  - Low (4): Nice-to-haves, minor improvements\n\n---\n\n## Action-Specific Instructions\n\n### 1. Creating Tickets from Thoughts\n\n#### Steps to follow:\n\n1. **Locate and read the thoughts document:**\n   - If given a path, read the document directly\n   - If given a topic/keyword, search thoughts/ directory using Grep\n   - If multiple matches found, show list and ask user to select\n   - Create a TodoWrite list to track: Read document ‚Üí Analyze ‚Üí Draft ‚Üí Create\n\n2. **Analyze the document content:**\n   - Identify the core problem or feature being discussed\n   - Extract key implementation details or technical decisions\n   - Note any specific code files or areas mentioned\n   - Look for action items or next steps\n   - Identify what stage the idea is at (early ideation vs ready to implement)\n\n3. **Check for related context (if mentioned in doc):**\n   - If the document references specific code files, read relevant sections\n   - If it mentions other thoughts documents, quickly check them\n   - Look for any existing Linear tickets mentioned\n\n4. **Draft the ticket summary:** Present a draft to the user:\n\n   ```\n   ## Draft Linear Ticket\n\n   **Title**: [Clear, action-oriented title]\n\n   **Description**:\n   [2-3 sentence summary of the problem/goal]\n\n   ## Key Details\n   - [Bullet points of important details from thoughts]\n   - [Technical decisions or constraints]\n   - [Any specific requirements]\n\n   ## Implementation Notes (if applicable)\n   [Any specific technical approach or steps outlined]\n\n   ## References\n   - Source: `thoughts/[path]` ([View on GitHub](converted URL))\n   - Related code: [any file:line references]\n\n   ---\n   Based on the document, this seems to be at the stage of: [ideation/planning/ready to implement]\n   ```\n\n5. **Interactive refinement:** Ask the user:\n   - Does this summary capture the ticket accurately?\n   - What priority? (Default: Medium/3)\n   - Any additional context to add?\n   - Should we include more/less implementation detail?\n   - Do you want to assign it to yourself?\n\n   Note: Ticket will be created in \"Backlog\" status by default.\n\n6. **Create the Linear ticket using Linearis CLI:**\n\n   ```bash\n   # Create issue with linearis\n   linearis issues create \\\n     --team \"$TEAM_KEY\" \\\n     --title \"[refined title]\" \\\n     --description \"[final description in markdown]\" \\\n     --priority [1-4] \\\n     --status \"Backlog\"\n\n   # Capture the created issue ID from output\n   ISSUE_ID=$(linearis issues create ... | jq -r '.id')\n   ```\n\n   **Note**: Linearis creates issues in the team's default backlog state. To set specific status or\n   assignee, create first then update:\n\n   ```bash\n   # Assign to self\n   linearis issues update \"$ISSUE_ID\" --assignee \"@me\"\n   ```\n\n7. **Post-creation actions:**\n   - Show the created ticket URL\n   - Ask if user wants to:\n     - Add a comment with additional implementation details\n     - Update the original thoughts document with the ticket reference\n   - If yes to updating thoughts doc:\n     ```\n     Add at the top of the document:\n     ---\n     linear_ticket: [TEAM-123]\n     created: [date]\n     ---\n     ```\n\n### 2. Adding Comments to Existing Tickets\n\nWhen user wants to add a comment to a ticket:\n\n1. **Determine which ticket:**\n   - Use context from the current conversation to identify the relevant ticket\n   - If uncertain, use `linearis issues read TEAM-123` to show ticket details and confirm\n\n2. **Format comments for clarity:**\n   - Keep concise (~10 lines) unless more detail needed\n   - Focus on key insights or most useful information\n   - Include relevant file references with backticks and GitHub links\n\n3. **File reference formatting:**\n   - Wrap paths in backticks: `thoughts/user/example.md`\n   - Add GitHub link after: `([View](url))`\n   - Do this for both thoughts/ and code files\n\n4. **Comment structure example:**\n\n   ```markdown\n   Implemented retry logic in webhook handler to address rate limit issues.\n\n   Key insight: The 429 responses were clustered during batch operations, so exponential backoff\n   alone wasn't sufficient - added request queuing.\n\n   Files updated:\n\n   - `src/webhooks/handler.ts` ([GitHub](link))\n   - `thoughts/shared/rate_limit_analysis.md` ([GitHub](link))\n   ```\n\n5. **Add comment with Linearis:**\n\n   ```bash\n   linearis comments create TEAM-123 --body \"Your comment text here\"\n   ```\n\n### 3. Moving Tickets Through Workflow\n\nWhen moving tickets to a new status:\n\n1. **Get current status:**\n\n   ```bash\n   linearis issues read TEAM-123 | jq -r '.state.name'\n   ```\n\n2. **Suggest next status based on workflow:**\n\n   ```\n   Backlog ‚Üí Triage (for initial review)\n   Triage ‚Üí Spec Needed (needs more detail) OR Research Needed (needs investigation)\n   Spec Needed ‚Üí Research Needed (once problem outlined)\n   Research Needed ‚Üí Research in Progress (starting research)\n   Research in Progress ‚Üí Ready for Plan (research complete)\n   Ready for Plan ‚Üí Plan in Progress (starting plan with /catalyst-dev:create_plan)\n   Plan in Progress ‚Üí Plan in Review (plan complete)\n   Plan in Review ‚Üí Ready for Dev (plan approved)\n   Ready for Dev ‚Üí In Dev (starting work with /catalyst-dev:implement_plan)\n   In Dev ‚Üí In Review (PR created)\n   In Review ‚Üí Done (PR merged)\n   ```\n\n3. **Automatic status updates:** When certain commands are run, automatically update ticket status:\n   - `/catalyst-dev:create_plan` with ticket ‚Üí Move to \"Plan in Progress\"\n   - Plan synced and linked ‚Üí Move to \"Plan in Review\"\n   - `/catalyst-dev:implement_plan` with ticket ‚Üí Move to \"In Dev\"\n   - `/catalyst-dev:create_pr` with ticket ‚Üí Move to \"In Review\"\n   - `/catalyst-dev:merge_pr` with ticket ‚Üí Move to \"Done\"\n\n4. **Manual status updates:**\n\n   ```bash\n   linearis issues update TEAM-123 --state \"In Progress\"\n   ```\n\n5. **Add comment explaining the transition:**\n   ```bash\n   linearis comments create TEAM-123 --body \"Moving to In Progress: Starting implementation\"\n   ```\n\n### 4. Searching for Tickets\n\nWhen user wants to find tickets:\n\n1. **Gather search criteria:**\n   - Query text\n   - Status filters\n   - Assignee filters\n\n2. **Execute search:**\n\n   ```bash\n   # List all issues (linearis issues list only supports --limit, not --team)\n   linearis issues list --limit 100\n\n   # Filter by team using jq\n   linearis issues list --limit 100 | jq '.[] | select(.team.key == \"TEAM\")'\n\n   # Filter by status using jq\n   linearis issues list --limit 100 | jq '.[] | select(.state.name == \"In Progress\")'\n\n   # Filter by assignee using jq\n   linearis issues list --limit 100 | jq '.[] | select(.assignee.email == \"user@example.com\")'\n\n   # Search by text (filter JSON output with jq)\n   linearis issues list --limit 100 | \\\n     jq '.[] | select(.title | contains(\"search term\"))'\n   ```\n\n3. **Present results:**\n   - Show ticket ID, title, status, assignee\n   - Include direct links to Linear\n   - Parse JSON output for display\n\n---\n\n## Integration with Other Commands\n\n### Automatic Ticket Updates\n\nWhen these commands are run, check if there's a related Linear ticket and update it:\n\n**During `/catalyst-dev:create_plan`:**\n\n1. If ticket mentioned, move to \"Plan in Progress\"\n2. When plan complete, add comment with plan link\n3. Move to \"Plan in Review\"\n\n**During `/catalyst-dev:implement_plan`:**\n\n1. If ticket in plan metadata, move to \"In Dev\"\n2. Add comment: \"Started implementation from plan: [link]\"\n\n**During `/catalyst-dev:create_pr`:**\n\n1. If ticket mentioned in PR or plan, move to \"In Review\"\n2. Add comment with PR link\n\n**During `/catalyst-dev:merge_pr`:**\n\n1. Move ticket to \"Done\"\n2. Add comment with merge details\n\n---\n\n## Example Workflows\n\n### Workflow 1: Thought ‚Üí Ticket ‚Üí Plan ‚Üí Implement\n\n```bash\n# 1. Research and document\n/catalyst-dev:research_codebase \"authentication patterns\"\n# Saves to thoughts/shared/research/auth-patterns.md\n\n# 2. Create ticket from research\n/catalyst-dev:linear create thoughts/shared/research/auth-patterns.md\n# Creates ticket in Backlog\n\n# 3. Create plan\n/catalyst-dev:create_plan\n# Reads research, creates plan\n# Ticket moves to \"Plan in Progress\" ‚Üí \"Plan in Review\"\n\n# 4. Implement\n/catalyst-dev:implement_plan thoughts/shared/plans/2025-01-08-auth-feature.md\n# Ticket moves to \"In Dev\"\n\n# 5. Create PR\n/catalyst-dev:create_pr\n# Ticket moves to \"In Review\"\n\n# 6. Merge PR\n/catalyst-dev:merge_pr\n# Ticket moves to \"Done\"\n```\n\n### Workflow 2: Quick Ticket Updates\n\n```bash\n# Add progress comment\nlinearis comments create PROJ-123 --body \"Completed phase 1, moving to phase 2\"\n\n# Move ticket forward\nlinearis issues update PROJ-123 --state \"In Dev\"\n\n# Search for related tickets\nlinearis issues list --team PROJ | jq '.[] | select(.title | contains(\"authentication\"))'\n```\n\n---\n\n## Linearis CLI Reference\n\n### Common Commands\n\n```bash\n# List issues (only --limit supported, use jq for filtering)\nlinearis issues list --limit 50\n\n# Filter by status using jq\nlinearis issues list --limit 100 | jq '.[] | select(.state.name == \"In Progress\")'\n\n# Read specific issue\nlinearis issues read TICKET-123\n\n# Create issue\nlinearis issues create \"Title\" --description \"Description\" --state \"Todo\"\n\n# Update issue state\nlinearis issues update TICKET-123 --state \"In Progress\"\n\n# Update assignee\nlinearis issues update TICKET-123 --assignee <user-id>\n\n# Add comment\nlinearis comments create TICKET-123 --body \"Comment text\"\n\n# List cycles\nlinearis cycles list --team TEAM [--active]\n\n# Read cycle\nlinearis cycles read \"Sprint 2025-10\" --team TEAM\n```\n\n### JSON Output Parsing\n\nLinearis returns JSON, parse with jq:\n\n```bash\n# Get ticket status\nlinearis issues read TEAM-123 | jq -r '.state.name'\n\n# Get ticket title\nlinearis issues read TEAM-123 | jq -r '.title'\n\n# Get assignee\nlinearis issues read TEAM-123 | jq -r '.assignee.name'\n\n# Filter list by keyword\nlinearis issues list --team TEAM | jq '.[] | select(.title | contains(\"bug\"))'\n```\n\n---\n\n## Notes\n\n- **Configuration**: Use `.claude/config.json` for team settings\n- **Status mapping**: Use status names that exist in your Linear workspace\n- **Automation**: Workflow commands auto-update tickets when ticket IDs are referenced\n- **CLI required**: Linearis CLI must be installed and configured with LINEAR_API_TOKEN\n\nThis command integrates seamlessly with the create_plan ‚Üí implement_plan ‚Üí validate_plan workflow\nwhile keeping Linear tickets in sync!"
              },
              {
                "name": "/merge_pr",
                "description": "Safely merge PR with verification and Linear integration",
                "path": "plugins/dev/commands/merge_pr.md",
                "frontmatter": {
                  "description": "Safely merge PR with verification and Linear integration",
                  "category": "version-control-git",
                  "tools": "Bash(linearis *), Bash(git *), Bash(gh *), Read",
                  "model": "inherit",
                  "version": "1.0.0"
                },
                "content": "# Merge Pull Request\n\nSafely merges a PR after comprehensive verification, with Linear integration and automated cleanup.\n\n## Configuration\n\nRead team configuration from `.claude/config.json`:\n\n```bash\nCONFIG_FILE=\".claude/config.json\"\nTEAM_KEY=$(jq -r '.catalyst.linear.teamKey // \"PROJ\"' \"$CONFIG_FILE\")\nTEST_CMD=$(jq -r '.catalyst.pr.testCommand // \"make test\"' \"$CONFIG_FILE\")\n```\n\n## Process:\n\n### 1. Identify PR to merge\n\n**If argument provided:**\n\n- Use that PR number: `/merge_pr 123`\n\n**If no argument:**\n\n```bash\n# Try current branch\ngh pr view --json number,url,title,state,mergeable 2>/dev/null\n```\n\nIf no PR on current branch:\n\n```bash\ngh pr list --limit 10 --json number,title,headRefName,state\n```\n\nAsk: \"Which PR would you like to merge? (enter number)\"\n\n### 2. Get PR details\n\n```bash\ngh pr view $pr_number --json \\\n  number,url,title,state,mergeable,mergeStateStatus,\\\n  baseRefName,headRefName,reviewDecision\n```\n\n**Extract:**\n\n- PR number, URL, title\n- Mergeable status\n- Base branch (usually main)\n- Head branch (feature branch)\n- Review decision (APPROVED, REVIEW_REQUIRED, etc.)\n\n### 3. Verify PR is open and mergeable\n\n```bash\nstate=$(gh pr view $pr_number --json state -q .state)\nmergeable=$(gh pr view $pr_number --json mergeable -q .mergeable)\n```\n\n**If PR not OPEN:**\n\n```\n‚ùå PR #$pr_number is $state\n\nOnly open PRs can be merged.\n```\n\n**If not mergeable (CONFLICTING):**\n\n```\n‚ùå PR has merge conflicts\n\nResolve conflicts first:\n  gh pr checkout $pr_number\n  git fetch origin $base_branch\n  git merge origin/$base_branch\n  # ... resolve conflicts ...\n  git push\n```\n\nExit with error.\n\n### 4. Check if head branch is up-to-date with base\n\n```bash\n# Checkout PR branch\ngh pr checkout $pr_number\n\n# Fetch latest base\nbase_branch=$(gh pr view $pr_number --json baseRefName -q .baseRefName)\ngit fetch origin $base_branch\n\n# Check if behind\nif git log HEAD..origin/$base_branch --oneline | grep -q .; then\n    echo \"Branch is behind $base_branch\"\nfi\n```\n\n**If behind:**\n\n```bash\n# Auto-rebase\ngit rebase origin/$base_branch\n\n# Check for conflicts\nif [ $? -ne 0 ]; then\n    echo \"‚ùå Rebase conflicts\"\n    git rebase --abort\n    exit 1\nfi\n\n# Push rebased branch\ngit push --force-with-lease\n```\n\n**If conflicts during rebase:**\n\n```\n‚ùå Rebase conflicts detected\n\nConflicting files:\n  $(git diff --name-only --diff-filter=U)\n\nResolve manually:\n  1. Fix conflicts in listed files\n  2. git add <resolved-files>\n  3. git rebase --continue\n  4. git push --force-with-lease\n  5. Run /catalyst-dev:merge_pr again\n```\n\nExit with error.\n\n### 5. Run local tests\n\n**Read test command from config:**\n\n```bash\ntest_cmd=$(jq -r '.catalyst.pr.testCommand // \"make test\"' .claude/config.json)\n```\n\n**Execute tests:**\n\n```bash\necho \"Running tests: $test_cmd\"\nif ! $test_cmd; then\n    echo \"‚ùå Tests failed\"\n    exit 1\nfi\n```\n\n**If tests fail:**\n\n```\n‚ùå Local tests failed\n\nFix failing tests before merge:\n  $test_cmd\n\nOr skip tests (not recommended):\n  /catalyst-dev:merge_pr $pr_number --skip-tests\n```\n\nExit with error (unless `--skip-tests` flag provided).\n\n### 6. Check CI/CD status\n\n```bash\ngh pr checks $pr_number\n```\n\n**Parse output for failures:**\n\n- If all checks pass: continue\n- If required checks fail: prompt user\n- If optional checks fail: warn but allow\n\n**If required checks failing:**\n\n```\n‚ö†Ô∏è  Some required CI checks are failing\n\nFailed checks:\n  - build (required)\n  - lint (required)\n\nPassed checks:\n  - test ‚úÖ\n  - security ‚úÖ\n\nContinue merge anyway? [y/N]:\n```\n\nIf user says no: exit. If user says yes: continue (user override).\n\n### 7. Check approval status\n\n```bash\nreview_decision=$(gh pr view $pr_number --json reviewDecision -q .reviewDecision)\n```\n\n**Review decisions:**\n\n- `APPROVED` - proceed\n- `CHANGES_REQUESTED` - prompt user\n- `REVIEW_REQUIRED` - prompt user\n- `null` / empty - no reviews, prompt user\n\n**If not approved:**\n\n```\n‚ö†Ô∏è  PR has not been approved\n\nReview status: $review_decision\n\nContinue merge anyway? [y/N]:\n```\n\nIf user says no: exit. If user says yes: continue (user override).\n\n**Skip these prompts if** `requireApproval: false` in config.\n\n### 8. Extract ticket reference\n\n```bash\nbranch=$(gh pr view $pr_number --json headRefName -q .headRefName)\ntitle=$(gh pr view $pr_number --json title -q .title)\n\n# From branch using configured team key\nif [[ \"$branch\" =~ ($TEAM_KEY-[0-9]+) ]]; then\n    ticket=\"${BASH_REMATCH[1]}\"\nfi\n\n# From title if not in branch\nif [[ -z \"$ticket\" ]] && [[ \"$title\" =~ ($TEAM_KEY-[0-9]+) ]]; then\n    ticket=\"${BASH_REMATCH[1]}\"\nfi\n```\n\n### 9. Show merge summary\n\n```\nAbout to merge:\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n PR:      #$pr_number - $title\n From:    $head_branch\n To:      $base_branch\n Commits: $commit_count\n Files:   $file_count changed\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n Reviews: $review_status\n CI:      $ci_status\n Tests:   ‚úÖ Passed locally\n Ticket:  $ticket (will move to Done)\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n\nMerge strategy: Squash and merge\n\nProceed? [Y/n]:\n```\n\n### 10. Execute squash merge\n\n```bash\ngh pr merge $pr_number --squash --delete-branch\n```\n\n**Always:**\n\n- Squash merge (combines all commits into one)\n- Delete remote branch automatically\n\n**Capture merge commit SHA:**\n\n```bash\nmerge_sha=$(git rev-parse HEAD)\n```\n\n### 11. Update Linear ticket\n\nIf ticket found and not using `--no-update`:\n\n```bash\n# Verify linearis is available\nif ! command -v linearis &> /dev/null; then\n    echo \"‚ö†Ô∏è  Linearis CLI not found - skipping Linear ticket update\"\n    echo \"Install: npm install -g --install-links ryanrozich/linearis#feat/cycles-cli\"\nelse\n    # Move to \"Done\"\n    linearis issues update \"$ticket\" --state \"Done\"\n\n    # Add merge comment\n    linearis comments create \"$ticket\" \\\n        --body \"‚úÖ PR merged!\\n\\n**PR**: #${prNumber} - ${prTitle}\\n**Merge commit**: ${mergeSha}\\n**Merged into**: ${baseBranch}\\n\\nView PR: ${prUrl}\"\nfi\n```\n\n### 12. Delete local branch and update base\n\n```bash\n# Switch to base branch\ngit checkout $base_branch\n\n# Pull latest (includes merge commit)\ngit pull origin $base_branch\n\n# Delete local feature branch\ngit branch -d $head_branch\n\n# Confirm deletion\necho \"‚úÖ Deleted local branch: $head_branch\"\n```\n\n**Always delete local branch** - no prompt (remote already deleted).\n\n### 13. Extract post-merge tasks\n\n**Read PR description:**\n\n```bash\ndesc_file=\"thoughts/shared/prs/${pr_number}_description.md\"\nif [ -f \"$desc_file\" ]; then\n    # Extract \"Post-Merge Tasks\" section\n    tasks=$(sed -n '/## Post-Merge Tasks/,/^##/p' \"$desc_file\" | grep -E '^\\- \\[')\nfi\n```\n\n**If tasks exist:**\n\n```\nüìã Post-merge tasks from PR description:\n- [ ] Update documentation\n- [ ] Monitor error rates in production\n- [ ] Notify stakeholders\n\nSave these tasks? [Y/n]:\n```\n\nIf yes:\n\n```bash\n# Save to thoughts\ncat > \"thoughts/shared/post_merge_tasks/${ticket}_tasks.md\" <<EOF\n# Post-Merge Tasks: $ticket\n\nMerged: $(date)\nPR: #$pr_number\n\n$tasks\nEOF\n\nhumanlayer thoughts sync\n```\n\n### 14. Report success summary\n\n```\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n‚úÖ PR #$pr_number merged successfully!\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n\nMerge details:\n  Strategy:     Squash and merge\n  Commit:       $merge_sha\n  Base branch:  $base_branch (updated)\n  Merged by:    @$user\n\nCleanup:\n  Remote branch: $head_branch (deleted)\n  Local branch:  $head_branch (deleted)\n\nLinear:\n  Ticket:  $ticket ‚Üí Done ‚úÖ\n  Comment: Added with merge details\n\nPost-merge tasks: $task_count saved to thoughts/\n\nNext steps:\n  - Monitor deployment\n  - Check CI/CD pipeline\n  - Verify in production\n\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n```\n\n## Flags\n\n**`--skip-tests`** - Skip local test execution\n\n```bash\n/catalyst-dev:merge_pr 123 --skip-tests\n```\n\n**`--no-update`** - Don't update Linear ticket\n\n```bash\n/catalyst-dev:merge_pr 123 --no-update\n```\n\n**`--keep-branch`** - Don't delete local branch\n\n```bash\n/catalyst-dev:merge_pr 123 --keep-branch\n```\n\n**Combined:**\n\n```bash\n/catalyst-dev:merge_pr 123 --skip-tests --no-update\n```\n\n## Error Handling\n\n**Rebase conflicts:**\n\n```\n‚ùå Rebase conflicts detected\n\nConflicting files:\n  - src/app.ts\n  - tests/app.test.ts\n\nResolve manually:\n  gh pr checkout $pr_number\n  git fetch origin $base_branch\n  git rebase origin/$base_branch\n  # Fix conflicts\n  git add <files>\n  git rebase --continue\n  git push --force-with-lease\n  /catalyst-dev:merge_pr $pr_number\n```\n\n**Tests failing:**\n\n```\n‚ùå Tests failed (exit code 1)\n\nFailed tests:\n  - validation.test.ts:45 - Expected true but got false\n  - auth.test.ts:12 - Timeout exceeded\n\nFix tests or skip (not recommended):\n  /catalyst-dev:merge_pr $pr_number --skip-tests\n```\n\n**CI checks failing:**\n\n```\n‚ö†Ô∏è  Required CI checks failing\n\nFailed:\n  - build: Compilation error in src/types.ts\n  - security: Dependency vulnerability found\n\nYou can:\n  1. Fix issues and try again\n  2. Override and merge anyway (not recommended)\n\nOverride? [y/N]:\n```\n\n**Linearis CLI not found:**\n\n```\n‚ö†Ô∏è  Linearis CLI not found\n\nPR merged successfully, but Linear ticket not updated.\n\nInstall Linearis:\n  npm install -g --install-links ryanrozich/linearis#feat/cycles-cli\n\nConfigure:\n  export LINEAR_API_TOKEN=your_token\n\nThen update ticket manually:\n  linearis issues update $ticket --state \"Done\"\n```\n\n**Linear API error:**\n\n```\n‚ö†Ô∏è  Could not update Linear ticket $ticket\n\nError: Ticket not found or API unavailable\n\nPR merged successfully, but ticket status not updated.\nUpdate manually in Linear.\n```\n\n**Branch deletion error:**\n\n```\n‚ö†Ô∏è  Could not delete local branch $head_branch\n\nError: Branch has unpushed commits\n\nThis won't affect the merge (already complete).\nDelete manually: git branch -D $head_branch\n```\n\n## Configuration\n\nUses `.claude/config.json`:\n\n```json\n{\n  \"catalyst\": {\n    \"project\": {\n      \"ticketPrefix\": \"RCW\"\n    },\n    \"linear\": {\n      \"teamKey\": \"RCW\",\n      \"doneStatusName\": \"Done\"\n    },\n    \"pr\": {\n      \"defaultMergeStrategy\": \"squash\",\n      \"deleteRemoteBranch\": true,\n      \"deleteLocalBranch\": true,\n      \"updateLinearOnMerge\": true,\n      \"requireApproval\": false,\n      \"requireCI\": false,\n      \"testCommand\": \"make test\"\n    }\n  }\n}\n```\n\n## Examples\n\n**Happy path (all checks pass):**\n\n```bash\n/catalyst-dev:merge_pr 123\n\nRunning tests: make test\n‚úÖ All tests passed\n‚úÖ CI checks passed\n‚úÖ PR approved\n\nAbout to merge PR #123...\n[shows summary]\nProceed? Y\n\n‚úÖ Merged!\n‚úÖ Linear ticket RCW-13 ‚Üí Done\n‚úÖ Branches deleted\n```\n\n**With failing CI (user override):**\n\n```bash\n/catalyst-dev:merge_pr 124\n\n‚ö†Ô∏è  Some CI checks failing\nContinue anyway? y\n\n‚úÖ Merged (with overrides)\n```\n\n**Skip tests:**\n\n```bash\n/catalyst-dev:merge_pr 125 --skip-tests\n\n‚ö†Ô∏è  Skipping tests (not recommended)\n‚úÖ Merged!\n```\n\n**Linearis not installed:**\n\n```bash\n/catalyst-dev:merge_pr 126\n\n‚úÖ PR merged successfully!\n‚ö†Ô∏è  Linearis CLI not found - Linear ticket not updated\n\nInstall Linearis to enable automatic ticket updates.\n```\n\n## Safety Features\n\n**Fail fast on:**\n\n- Merge conflicts (can't auto-resolve)\n- Test failures (unless --skip-tests)\n- Rebase conflicts\n- PR not in mergeable state\n\n**Prompt for confirmation on:**\n\n- Missing required approvals\n- Failing CI checks\n- Any exceptional circumstance\n\n**Always automated:**\n\n- Rebase if behind (no conflicts)\n- Squash merge\n- Delete remote branch\n- Delete local branch\n- Update Linear to Done (if Linearis available)\n- Pull latest base branch\n\n**Graceful degradation:**\n\n- If Linearis not installed, warn but continue\n- Merge succeeds regardless of Linear integration\n\n## Post-Merge Workflow\n\n```\nPR merged\n    ‚Üì\nLinear ticket ‚Üí Done (if Linearis available)\n    ‚Üì\nBranches deleted\n    ‚Üì\nBase branch updated locally\n    ‚Üì\nPost-merge tasks extracted\n    ‚Üì\nMonitor deployment\n```\n\n## Remember:\n\n- **Always squash merge** - clean history\n- **Always delete branches** - no orphan branches\n- **Always run tests** - unless explicitly skipped\n- **Auto-rebase** - keep up-to-date with base\n- **Fail fast** - stop on conflicts or test failures\n- **Update Linear** - move ticket to Done automatically (if Linearis available)\n- **Extract tasks** - save post-merge checklist\n- **Clear summary** - show what happened\n- **Only prompt for exceptions** - approvals missing, CI failing\n- **Graceful degradation** - Work without Linearis if needed"
              },
              {
                "name": "/research_codebase",
                "description": "Conduct comprehensive codebase research using parallel sub-agents",
                "path": "plugins/dev/commands/research_codebase.md",
                "frontmatter": {
                  "description": "Conduct comprehensive codebase research using parallel sub-agents",
                  "category": "workflow",
                  "tools": "Read, Write, Grep, Glob, Task, TodoWrite, Bash",
                  "model": "inherit",
                  "version": "1.0.0"
                },
                "content": "# Research Codebase\n\nYou are tasked with conducting comprehensive research across the codebase to answer user questions\nby spawning parallel sub-agents and synthesizing their findings.\n\n## CRITICAL: YOUR ONLY JOB IS TO DOCUMENT AND EXPLAIN THE CODEBASE AS IT EXISTS TODAY\n\n- DO NOT suggest improvements or changes unless the user explicitly asks for them\n- DO NOT perform root cause analysis unless the user explicitly asks for them\n- DO NOT propose future enhancements unless the user explicitly asks for them\n- DO NOT critique the implementation or identify problems\n- DO NOT recommend refactoring, optimization, or architectural changes\n- ONLY describe what exists, where it exists, how it works, and how components interact\n- You are creating a technical map/documentation of the existing system\n\n## Prerequisites\n\nBefore executing, verify all required tools and systems:\n\n```bash\n# 1. Validate thoughts system (REQUIRED)\nif [[ -f \"scripts/validate-thoughts-setup.sh\" ]]; then\n  ./scripts/validate-thoughts-setup.sh || exit 1\nelse\n  # Inline validation if script not found\n  if [[ ! -d \"thoughts/shared\" ]]; then\n    echo \"‚ùå ERROR: Thoughts system not configured\"\n    echo \"Run: ./scripts/humanlayer/init-project.sh . {project-name}\"\n    exit 1\n  fi\nfi\n\n# 2. Validate plugin scripts\nif [[ -f \"${CLAUDE_PLUGIN_ROOT}/scripts/check-prerequisites.sh\" ]]; then\n  \"${CLAUDE_PLUGIN_ROOT}/scripts/check-prerequisites.sh\" || exit 1\nfi\n```\n\n## Initial Setup\n\nWhen this command is invoked, respond with:\n\n```\nI'm ready to research the codebase. Please provide your research question or area of interest, and I'll analyze it thoroughly by exploring relevant components and connections.\n```\n\nThen wait for the user's research query.\n\n## Steps to Follow After Receiving the Research Query\n\n### Step 1: Read Any Directly Mentioned Files First\n\n- If the user mentions specific files (tickets, docs, JSON), read them FULLY first\n- **IMPORTANT**: Use the Read tool WITHOUT limit/offset parameters to read entire files\n- **CRITICAL**: Read these files yourself in the main context before spawning any sub-tasks\n- This ensures you have full context before decomposing the research\n\n### Step 2: Analyze and Decompose the Research Question\n\n- Break down the user's query into composable research areas\n- Take time to think deeply about the underlying patterns, connections, and architectural\n  implications the user might be seeking\n- Identify specific components, patterns, or concepts to investigate\n- Create a research plan using TodoWrite to track all subtasks\n- Consider which directories, files, or architectural patterns are relevant\n\n### Step 3: Spawn Parallel Sub-Agent Tasks for Comprehensive Research\n\nCreate multiple Task agents to research different aspects concurrently.\n\nWe have specialized agents that know how to do specific research tasks:\n\n**For codebase research:**\n\n- Use the **codebase-locator** agent to find WHERE files and components live\n- Use the **codebase-analyzer** agent to understand HOW specific code works (without critiquing it)\n- Use the **codebase-pattern-finder** agent to find examples of existing patterns (without\n  evaluating them)\n\n**IMPORTANT**: All agents are documentarians, not critics. They will describe what exists without\nsuggesting improvements or identifying issues.\n\n**For thoughts directory (if using thoughts system):**\n\n- Use the **thoughts-locator** agent to discover what documents exist about the topic\n- Use the **thoughts-analyzer** agent to extract key insights from specific documents (only the most\n  relevant ones)\n\n**For external research (only if user explicitly asks):**\n\n- Use the **external-research** agent for external documentation and resources\n- IF you use external research agents, instruct them to return LINKS with their findings, and\n  INCLUDE those links in your final report\n\n**For Linear tickets (if relevant):**\n\n- Use the **linear-ticket-reader** agent to get full details of a specific ticket (if Linear MCP\n  available)\n- Use the **linear-searcher** agent to find related tickets or historical context\n\nThe key is to use these agents intelligently:\n\n- Start with locator agents to find what exists\n- Then use analyzer agents on the most promising findings to document how they work\n- Run multiple agents in parallel when they're searching for different things\n- Each agent knows its job - just tell it what you're looking for\n- Don't write detailed prompts about HOW to search - the agents already know\n- Remind agents they are documenting, not evaluating or improving\n\n**Example of spawning parallel research tasks:**\n\n```\nI'm going to spawn 3 parallel research tasks:\n\nTask 1 - Find WHERE components live:\n\"Use codebase-locator to find all files related to [topic]. Focus on [specific directories if known].\"\n\nTask 2 - Understand HOW it works:\n\"Use codebase-analyzer to analyze [specific component] and document how it currently works. Include data flow and key integration points.\"\n\nTask 3 - Find existing patterns:\n\"Use codebase-pattern-finder to find similar implementations of [pattern] in the codebase. Show concrete examples.\"\n```\n\n### Step 4: Wait for All Sub-Agents to Complete and Synthesize Findings\n\n- **IMPORTANT**: Wait for ALL sub-agent tasks to complete before proceeding\n- Compile all sub-agent results (both codebase and thoughts findings if applicable)\n- Prioritize live codebase findings as primary source of truth\n- Use thoughts/ findings as supplementary historical context (if thoughts system is used)\n- Connect findings across different components\n- Document specific file paths and line numbers (format: `file.ext:line`)\n- Explain how components interact with each other\n- Include temporal context where relevant (e.g., \"This was added in commit abc123\")\n- Mark all research tasks as complete in TodoWrite\n\n### Step 5: Gather Metadata for the Research Document\n\nCollect metadata for the research document:\n\n**If using thoughts system with metadata script:**\n\n- Run `hack/spec_metadata.sh` or equivalent to generate metadata\n- Metadata includes: date, researcher, git commit, branch, repository\n\n**If using simple approach:**\n\n- Get current date/time\n- Get git commit hash: `git rev-parse HEAD`\n- Get current branch: `git branch --show-current`\n- Get repository name from `.git/config` or working directory\n\n**Document Storage:**\n\nAll research documents are stored in the **thoughts system** for persistence:\n\n**Required location:** `thoughts/shared/research/YYYY-MM-DD-{ticket}-{description}.md`\n\n**Why thoughts/shared/**:\n- ‚úÖ Persisted across sessions (git-backed via HumanLayer)\n- ‚úÖ Shared across worktrees\n- ‚úÖ Synced via `humanlayer thoughts sync`\n- ‚úÖ Team collaboration ready\n\n**Filename format:**\n- With ticket: `thoughts/shared/research/YYYY-MM-DD-PROJ-XXXX-description.md`\n- Without ticket: `thoughts/shared/research/YYYY-MM-DD-description.md`\n\nReplace `PROJ` with your ticket prefix from `.claude/config.json`.\n\n**Examples:**\n- `thoughts/shared/research/2025-01-08-PROJ-1478-parent-child-tracking.md`\n- `thoughts/shared/research/2025-01-08-authentication-flow.md` (no ticket)\n\n### Step 6: Generate Research Document\n\nCreate a structured research document with the following format:\n\n```markdown\n---\ndate: YYYY-MM-DDTHH:MM:SS+TZ\nresearcher: { your-name }\ngit_commit: { commit-hash }\nbranch: { branch-name }\nrepository: { repo-name }\ntopic: \"{User's Research Question}\"\ntags: [research, codebase, { component-names }]\nstatus: complete\nlast_updated: YYYY-MM-DD\nlast_updated_by: { your-name }\n---\n\n# Research: {User's Research Question}\n\n**Date**: {date/time with timezone} **Researcher**: {your-name} **Git Commit**: {commit-hash}\n**Branch**: {branch-name} **Repository**: {repo-name}\n\n## Research Question\n\n{Original user query, verbatim}\n\n## Summary\n\n{High-level documentation of what you found. 2-3 paragraphs explaining the current state of the\nsystem in this area. Focus on WHAT EXISTS, not what should exist.}\n\n## Detailed Findings\n\n### {Component/Area 1}\n\n**What exists**: {Describe the current implementation}\n\n- File location: `path/to/file.ext:123`\n- Current behavior: {what it does}\n- Key functions/classes: {list with file:line references}\n\n**Connections**: {How this component integrates with others}\n\n- Calls: `other-component.ts:45` - {description}\n- Used by: `consumer.ts:67` - {description}\n\n**Implementation details**: {Technical specifics without evaluation}\n\n### {Component/Area 2}\n\n{Same structure as above}\n\n### {Component/Area N}\n\n{Continue for all major findings}\n\n## Code References\n\nQuick reference of key files and their roles:\n\n- `path/to/file1.ext:123-145` - {What this code does}\n- `path/to/file2.ext:67` - {What this code does}\n- `path/to/file3.ext:200-250` - {What this code does}\n\n## Architecture Documentation\n\n{Document the current architectural patterns, conventions, and design decisions observed in the\ncode. This is descriptive, not prescriptive.}\n\n### Current Patterns\n\n- **Pattern 1**: {How it's implemented in the codebase}\n- **Pattern 2**: {How it's implemented in the codebase}\n\n### Data Flow\n\n{Document how data moves through the system in this area}\n```\n\nComponent A ‚Üí Component B ‚Üí Component C {Describe what happens at each step}\n\n```\n\n### Key Integrations\n\n{Document how different parts of the system connect}\n\n## Historical Context (from thoughts/)\n\n{ONLY if using thoughts system}\n\n{Include insights from thoughts/ documents that provide context}\n\n- `thoughts/shared/research/previous-doc.md` - {Key decision or insight}\n- `thoughts/shared/plans/plan-123.md` - {Related implementation detail}\n\n## Related Research\n\n{Links to other research documents that touch on related topics}\n\n- `research/YYYY-MM-DD-related-topic.md` - {How it relates}\n\n## Open Questions\n\n{Areas that would benefit from further investigation - NOT problems to fix, just areas where understanding could be deepened}\n\n- {Question 1}\n- {Question 2}\n```\n\n### Step 7: Add GitHub Permalinks (If Applicable)\n\n**If you're on the main/master branch OR if the commit is pushed:**\n\nGenerate GitHub permalinks and replace file references:\n\n```\nhttps://github.com/{owner}/{repo}/blob/{commit-hash}/{file-path}#L{line}\n```\n\nFor line ranges:\n\n```\nhttps://github.com/{owner}/{repo}/blob/{commit-hash}/{file-path}#L{start}-L{end}\n```\n\n**If working on a feature branch that's not pushed yet:**\n\n- Keep local file references: `path/to/file.ext:line`\n- Add note: \"GitHub permalinks will be added once this branch is pushed\"\n\n### Step 8: Sync and Present Findings\n\n**If using thoughts system:**\n\n- Run `humanlayer thoughts sync` to sync the thoughts directory\n- This updates symlinks, creates searchable index, and commits to thoughts repo\n\n**If using simple approach:**\n\n- Just save the file to your research directory\n- Optionally commit to git\n\n**Present to user:**\n\n```markdown\n‚úÖ Research complete!\n\n**Research document**: {file-path}\n\n## Summary\n\n{2-3 sentence summary of key findings}\n\n## Key Files\n\n{Top 3-5 most important file references}\n\n## What I Found\n\n{Brief overview - save details for the document}\n\n---\n\n## üìä Context Status\n\nCurrent usage: {X}% ({Y}K/{Z}K tokens)\n\n{If >60%}: ‚ö†Ô∏è **Recommendation**: Context is getting full. For best results in the planning phase, I\nrecommend clearing context now.\n\n**Options**:\n\n1. ‚úÖ Clear context now (recommended) - Close this session and start fresh for planning\n2. Create handoff to pause work\n3. Continue anyway (may impact performance)\n\n**Why clear?** Fresh context ensures optimal AI performance for the planning phase, which will load\nadditional files and research.\n\n{If <60%}: ‚úÖ Context healthy. Ready to proceed to planning phase if needed.\n\n---\n\nWould you like me to:\n\n1. Dive deeper into any specific area?\n2. Create an implementation plan based on this research?\n3. Explore related topics?\n```\n\n### Step 9: Handle Follow-Up Questions\n\nIf the user has follow-up questions:\n\n1. **DO NOT create a new research document** - append to the same one\n2. **Update frontmatter fields:**\n   - `last_updated`: {new date}\n   - `last_updated_by`: {your name}\n   - Add `last_updated_note`: \"{Brief note about what was added}\"\n\n3. **Add new section to existing document:**\n\n```markdown\n---\n\n## Follow-up Research: {Follow-up Question}\n\n**Date**: {date} **Updated by**: {your-name}\n\n### Additional Findings\n\n{New research results using same structure as above}\n```\n\n4. **Spawn new sub-agents as needed** for the follow-up research\n5. **Re-sync** (if using thoughts system)\n\n## Important Notes\n\n### Proactive Context Management\n\n**Monitor Your Context Throughout Research**:\n\n- Check token usage after spawning parallel agents\n- After synthesis phase, check context again\n- **If context >60%**: Warn user and recommend handoff\n\n**Example Warning**:\n\n```\n‚ö†Ô∏è Context Usage Alert: Currently at 65% (130K/200K tokens)\n\nResearch is complete, but context is getting full. Before continuing to\nplanning phase, I recommend creating a handoff to preserve this work\nand start fresh.\n\nWould you like me to:\n1. Create a handoff now (recommended)\n2. Continue and clear context manually\n3. Proceed anyway (not recommended - may impact planning quality)\n\n**Why this matters**: The planning phase will load additional context.\nStarting fresh ensures optimal AI performance.\n```\n\n**When to Warn**:\n\n- After Step 7 (document generated) if context >60%\n- After Step 9 (follow-up complete) if context >70%\n- Anytime during research if context >80%\n\n**Educate the User**:\n\n- Explain WHY clearing context matters (performance, token efficiency)\n- Explain WHEN to clear (between phases)\n- Offer to create handoff yourself if `/create-handoff` command exists\n\n### Parallel Execution\n\n- ALWAYS use parallel Task agents for efficiency\n- Don't wait for one agent to finish before spawning the next\n- Spawn all research tasks at once, then wait for all to complete\n\n### Research Philosophy\n\n- Always perform fresh codebase research - never rely solely on existing docs\n- The `thoughts/` directory (if used) provides historical context, not primary source\n- Focus on concrete file paths and line numbers - make it easy to navigate\n- Research documents should be self-contained and understandable months later\n\n### Sub-Agent Prompts\n\n- Be specific about what to search for\n- Specify directories to focus on when known\n- Make prompts focused on read-only documentation\n- Remind agents they are documentarians, not critics\n\n### Cross-Component Understanding\n\n- Document how components interact, not just what they do individually\n- Trace data flow across boundaries\n- Note integration points and dependencies\n\n### Temporal Context\n\n- Include when things were added/changed if relevant\n- Note deprecated patterns still in the codebase\n- Don't judge - just document the timeline\n\n### GitHub Links\n\n- Use permalinks for permanent references\n- Include line numbers for precision\n- Link to specific commits, not branches (branches move)\n\n### Main Agent Role\n\n- Your role is synthesis, not deep file reading\n- Let sub-agents do the detailed reading\n- You orchestrate, compile, and connect their findings\n- Focus on the big picture and cross-component connections\n\n### Documentation Style\n\n- Sub-agents document examples and usage patterns as they exist\n- Main agent synthesizes into coherent narrative\n- Both levels: documentarian, not evaluator\n- Never recommend changes or improvements unless explicitly asked\n\n### File Reading Rules\n\n- ALWAYS read mentioned files fully before spawning sub-tasks\n- Use Read tool WITHOUT limit/offset for complete files\n- This is critical for proper decomposition\n\n### Follow the Steps\n\n- These numbered steps are not suggestions - follow them exactly\n- Don't skip steps or reorder them\n- Each step builds on the previous ones\n\n### Thoughts Directory Handling\n\n**If using thoughts system:**\n\n- `thoughts/searchable/` is a special directory - paths found there should be documented as their\n  actual location\n- Example: `thoughts/searchable/allison/notes.md` ‚Üí document as `thoughts/allison/notes.md`\n- Don't change directory names (keep `allison/`, don't change to `shared/`)\n\n**If NOT using thoughts system:**\n\n- Skip thoughts-related agents\n- Skip thoughts sync commands\n- Save research docs to `research/` directory in workspace root\n\n### Frontmatter Consistency\n\n- Always include complete frontmatter as shown in template\n- Use ISO 8601 dates with timezone\n- Keep tags consistent across research documents\n- Update `last_updated` fields when appending follow-ups\n\n## Linear Integration\n\nIf a Linear ticket is associated with the research, the command can automatically update the ticket\nstatus.\n\n### How It Works\n\n**Ticket detection** (same as other commands):\n\n1. User provides ticket ID explicitly: `/research_codebase PROJ-123`\n2. Ticket mentioned in research query\n3. Auto-detected from current context\n\n**Status updates:**\n\n- When research starts ‚Üí Move ticket to **\"Research\"**\n- When research document is saved ‚Üí Add comment with link to research doc\n\n### Implementation Pattern\n\n**At research start** (Step 2 - after reading mentioned files):\n\n```bash\n# If ticket is detected or provided\nif [[ -n \"$ticketId\" ]]; then\n  # Check if Linearis CLI is available\n  if command -v linearis &> /dev/null; then\n    # Update ticket state to \"Research\" (use --state NOT --status!)\n    linearis issues update \"$ticketId\" --state \"Research\"\n\n    # Add comment (use 'comments create' NOT 'issues comment'!)\n    linearis comments create \"$ticketId\" --body \"Starting research: [user's research question]\"\n  else\n    echo \"‚ö†Ô∏è  Linearis CLI not found - skipping Linear ticket update\"\n  fi\nfi\n```\n\n**After research document is saved** (Step 6 - after generating document):\n\n```bash\n# Attach research document to ticket\nif [[ -n \"$ticketId\" ]] && [[ -n \"$githubPermalink\" ]]; then\n  # Check if Linearis CLI is available\n  if command -v linearis &> /dev/null; then\n    # Add completion comment with research doc link\n    linearis comments create \"$ticketId\" \\\n        --body \"Research complete! See findings: $githubPermalink\"\n  else\n    echo \"‚ö†Ô∏è  Linearis CLI not found - skipping Linear ticket update\"\n  fi\nfi\n```\n\n### User Experience\n\n**With ticket:**\n\n```bash\n/catalyst-dev:research_codebase PROJ-123\n> \"How does authentication work?\"\n```\n\n**What happens:**\n\n1. Command detects ticket PROJ-123\n2. Moves ticket from Backlog ‚Üí Research\n3. Adds comment: \"Starting research: How does authentication work?\"\n4. Conducts research with parallel agents\n5. Saves document to thoughts/shared/research/\n6. Attaches document to Linear ticket\n7. Adds comment: \"Research complete! See findings: [link]\"\n\n**Without ticket:**\n\n```bash\n/catalyst-dev:research_codebase\n> \"How does authentication work?\"\n```\n\n**What happens:**\n\n- Same research process, but no Linear updates\n- User can manually attach research to ticket later\n\n### Configuration\n\nUses the same Linear configuration as other commands from `.claude/config.json`:\n\n- `linear.teamId`\n- `linear.thoughtsRepoUrl` (for GitHub permalinks)\n\n### Error Handling\n\n**If Linear MCP not available:**\n\n- Skip Linear integration silently\n- Continue with research as normal\n- Note in output: \"Research complete (Linear not configured)\"\n\n**If ticket not found:**\n\n- Show warning: \"Ticket PROJ-123 not found in Linear\"\n- Ask user: \"Continue research without Linear integration? (Y/n)\"\n\n**If status update fails:**\n\n- Log error but continue research\n- Include note in final output: \"‚ö†Ô∏è Could not update Linear ticket status\"\n\n## Integration with Other Commands\n\nThis command integrates with the complete development workflow:\n\n```\n/research-codebase ‚Üí research document (+ Linear: Research)\n                  ‚Üì\n           /create-plan ‚Üí implementation plan (+ Linear: Planning)\n                  ‚Üì\n          /implement-plan ‚Üí code changes (+ Linear: In Progress)\n                  ‚Üì\n              /describe-pr ‚Üí PR created (+ Linear: In Review)\n```\n\n**How it connects:**\n\n- **research_codebase ‚Üí Linear**: Moves ticket to \"Research\" status and attaches research document\n\n- **research_codebase ‚Üí create_plan**: Research findings provide foundation for planning. The\n  create_plan command can reference research documents in its \"References\" section.\n\n- **Research before planning**: Always research the codebase first to understand what exists before\n  planning changes.\n\n- **Shared agents**: Both research_codebase and create_plan use the same specialized agents\n  (codebase-locator, codebase-analyzer, codebase-pattern-finder).\n\n- **Documentation persistence**: Research documents serve as permanent reference for future work.\n\n## Example Workflow\n\n```bash\n# User starts research\n/research-codebase\n\n# You respond with initial prompt\n# User asks: \"How does authentication work in the API?\"\n\n# You execute:\n# 1. Read any mentioned files fully\n# 2. Decompose into research areas (auth middleware, token validation, session management)\n# 3. Spawn parallel agents:\n#    - codebase-locator: Find auth-related files\n#    - codebase-analyzer: Understand auth middleware implementation\n#    - codebase-pattern-finder: Find auth usage patterns\n#    - thoughts-locator: Find previous auth discussions (if using thoughts)\n# 4. Wait for all agents\n# 5. Synthesize findings\n# 6. Generate research document at research/2025-01-08-authentication-system.md\n# 7. Present summary to user\n\n# User follows up: \"How does it integrate with the database?\"\n# You append to same document with new findings\n```\n\n### Track in Workflow Context\n\nAfter saving the research document, add it to workflow context:\n\n```bash\nif [[ -f \"${CLAUDE_PLUGIN_ROOT}/scripts/workflow-context.sh\" ]]; then\n  \"${CLAUDE_PLUGIN_ROOT}/scripts/workflow-context.sh\" add research \"$DOC_PATH\" \"${TICKET_ID:-null}\"\nfi\n```\n\n## Adaptation Notes\n\nThis command is adapted from HumanLayer's research_codebase command. Key differences for\nportability:\n\n- **Thoughts system**: Made optional - can use simple `research/` directory\n- **Metadata script**: Made optional - can generate metadata inline\n- **Ticket prefixes**: Read from `.claude/config.json` or use PROJ- placeholder\n- **Linear integration**: Made optional - only used if Linear MCP available\n- **Web research**: Uses `external-research` agent instead of `web-search-researcher`\n\nThe core workflow and philosophy remain the same: parallel sub-agents, documentarian mindset, and\nstructured output."
              },
              {
                "name": "/resume_handoff",
                "description": "Resume work from a handoff document",
                "path": "plugins/dev/commands/resume_handoff.md",
                "frontmatter": {
                  "description": "Resume work from a handoff document",
                  "category": "workflow",
                  "tools": "Read, Bash, TodoWrite",
                  "model": "inherit",
                  "version": "1.0.0"
                },
                "content": "# Resume work from a handoff document\n\n## Prerequisites\n\nBefore executing, verify required tools are installed:\n\n```bash\nif [[ -f \"${CLAUDE_PLUGIN_ROOT}/scripts/check-prerequisites.sh\" ]]; then\n  \"${CLAUDE_PLUGIN_ROOT}/scripts/check-prerequisites.sh\" || exit 1\nfi\n```\n\n## Configuration Note\n\nThis command uses ticket references like `PROJ-123`. Replace `PROJ` with your Linear team's ticket\nprefix:\n\n- Read from `.claude/config.json` if available\n- Otherwise use a generic format like `TICKET-XXX`\n- Examples: `ENG-123`, `FEAT-456`, `BUG-789`\n\nYou are tasked with resuming work from a handoff document through an interactive process. These\nhandoffs contain critical context, learnings, and next steps from previous work sessions that need\nto be understood and continued.\n\n## Initial Response\n\n**STEP 1: Auto-discover recent handoff (REQUIRED)**\n\nIMMEDIATELY run this bash script BEFORE any other response:\n\n```bash\n# Auto-discover most recent handoff from workflow context\nif [[ -f \"${CLAUDE_PLUGIN_ROOT}/scripts/workflow-context.sh\" ]]; then\n  RECENT_HANDOFF=$(\"${CLAUDE_PLUGIN_ROOT}/scripts/workflow-context.sh\" recent handoffs)\n  if [[ -n \"$RECENT_HANDOFF\" ]]; then\n    echo \"üìã Auto-discovered recent handoff: $RECENT_HANDOFF\"\n    echo \"\"\n  fi\nfi\n```\n\n**STEP 2: Determine which handoff to use**\n\nAfter running the auto-discovery script, follow this logic:\n\n1. **If user provided a file path as parameter**:\n   - Use the provided path (user override)\n   - Skip to Step 3\n\n2. **If user provided a ticket number (like PROJ-123)**:\n   - Run `humanlayer thoughts sync` to ensure `thoughts/` is up to date\n   - Look in `thoughts/shared/handoffs/PROJ-123/` directory\n   - List all handoffs for that ticket\n   - If multiple exist, use the most recent (by timestamp in filename `YYYY-MM-DD_HH-MM-SS`)\n   - If none exist, tell user and wait for input\n   - Skip to Step 3\n\n3. **If no parameters provided AND RECENT_HANDOFF was found**:\n   - Show user: \"üìã Found recent handoff: $RECENT_HANDOFF\"\n   - Ask: \"**Proceed with this handoff?** [Y/n]\"\n   - If yes: use RECENT_HANDOFF and skip to Step 3\n   - If no: proceed to option 4\n\n4. **If no parameters AND no RECENT_HANDOFF found**:\n   - List available handoffs from `thoughts/shared/handoffs/`\n   - Show most recent 5 handoffs with dates\n   - Ask user which one to use\n   - Wait for user input with path or ticket number\n\n**STEP 3: Analyze the handoff**\n\nOnce you have a handoff path:\n- Read the handoff document FULLY (no limit/offset)\n- Immediately read any research or plan documents it references\n- Do NOT use sub-agents to read these critical files\n- Ingest all context from the handoff\n- Propose course of action to user\n- Get confirmation before proceeding\n\n## Process Steps\n\n### Step 1: Read and Analyze Handoff\n\n1. **Read handoff document completely**:\n   - Use the Read tool WITHOUT limit/offset parameters\n   - Extract all sections:\n     - Task(s) and their statuses\n     - Recent changes\n     - Learnings\n     - Artifacts\n     - Action items and next steps\n     - Other notes\n\n2. **Spawn focused research tasks**: Based on the handoff content, spawn parallel research tasks to\n   verify current state:\n\n   ```\n   Task 1 - Verify recent changes:\n   Check if the recent changes mentioned in the handoff still exist.\n   1. Verify files mentioned in \"Recent changes\" section\n   2. Check if the described changes are still present\n   3. Look for any subsequent modifications\n   4. Identify any conflicts or regressions\n   Use tools: Read, Grep, Glob\n   Return: Current state of recent changes with file:line references\n   ```\n\n   ```\n   Task 2 - Validate current codebase state:\n   Verify the current state against what's described in the handoff.\n   1. Check files mentioned in \"Learnings\" section\n   2. Verify patterns and implementations still exist\n   3. Look for any breaking changes since handoff\n   4. Identify new related code added since handoff\n   Use tools: Read, Grep, Glob\n   Return: Validation results and any discrepancies found\n   ```\n\n   ```\n   Task 3 - Gather artifact context:\n   Read all artifacts mentioned in the handoff.\n   1. Read feature documents listed in \"Artifacts\"\n   2. Read implementation plans referenced\n   3. Read any research documents mentioned\n   4. Extract key requirements and decisions\n   Use tools: Read\n   Return: Summary of artifact contents and key decisions\n   ```\n\n3. **Wait for ALL sub-tasks to complete** before proceeding\n\n4. **Read critical files identified**:\n   - Read files from \"Learnings\" section completely\n   - Read files from \"Recent changes\" to understand modifications\n   - Read any new related files discovered during research\n\n### Step 2: Synthesize and Present Analysis\n\n1. **Present comprehensive analysis**:\n\n   ```\n   I've analyzed the handoff from [date] by [researcher]. Here's the current situation:\n\n   **Original Tasks:**\n   - [Task 1]: [Status from handoff] ‚Üí [Current verification]\n   - [Task 2]: [Status from handoff] ‚Üí [Current verification]\n\n   **Key Learnings Validated:**\n   - [Learning with file:line reference] - [Still valid/Changed]\n   - [Pattern discovered] - [Still applicable/Modified]\n\n   **Recent Changes Status:**\n   - [Change 1] - [Verified present/Missing/Modified]\n   - [Change 2] - [Verified present/Missing/Modified]\n\n   **Artifacts Reviewed:**\n   - [Document 1]: [Key takeaway]\n   - [Document 2]: [Key takeaway]\n\n   **Recommended Next Actions:**\n   Based on the handoff's action items and current state:\n   1. [Most logical next step based on handoff]\n   2. [Second priority action]\n   3. [Additional tasks discovered]\n\n   **Potential Issues Identified:**\n   - [Any conflicts or regressions found]\n   - [Missing dependencies or broken code]\n\n   Shall I proceed with [recommended action 1], or would you like to adjust the approach?\n   ```\n\n2. **Get confirmation** before proceeding\n\n### Step 3: Create Action Plan\n\n1. **Use TodoWrite to create task list**:\n   - Convert action items from handoff into todos\n   - Add any new tasks discovered during analysis\n   - Prioritize based on dependencies and handoff guidance\n\n2. **Present the plan**:\n\n   ```\n   I've created a task list based on the handoff and current analysis:\n\n   [Show todo list]\n\n   Ready to begin with the first task: [task description]?\n   ```\n\n### Step 4: Begin Implementation\n\n1. **Start with the first approved task**\n2. **Reference learnings from handoff** throughout implementation\n3. **Apply patterns and approaches documented** in the handoff\n4. **Update progress** as tasks are completed\n\n## Guidelines\n\n1. **Be Thorough in Analysis**:\n   - Read the entire handoff document first\n   - Verify ALL mentioned changes still exist\n   - Check for any regressions or conflicts\n   - Read all referenced artifacts\n\n2. **Be Interactive**:\n   - Present findings before starting work\n   - Get buy-in on the approach\n   - Allow for course corrections\n   - Adapt based on current state vs handoff state\n\n3. **Leverage Handoff Wisdom**:\n   - Pay special attention to \"Learnings\" section\n   - Apply documented patterns and approaches\n   - Avoid repeating mistakes mentioned\n   - Build on discovered solutions\n\n4. **Track Continuity**:\n   - Use TodoWrite to maintain task continuity\n   - Reference the handoff document in commits\n   - Document any deviations from original plan\n   - Consider creating a new handoff when done\n\n5. **Validate Before Acting**:\n   - Never assume handoff state matches current state\n   - Verify all file references still exist\n   - Check for breaking changes since handoff\n   - Confirm patterns are still valid\n\n## Common Scenarios\n\n### Scenario 1: Clean Continuation\n\n- All changes from handoff are present\n- No conflicts or regressions\n- Clear next steps in action items\n- Proceed with recommended actions\n\n### Scenario 2: Diverged Codebase\n\n- Some changes missing or modified\n- New related code added since handoff\n- Need to reconcile differences\n- Adapt plan based on current state\n\n### Scenario 3: Incomplete Handoff Work\n\n- Tasks marked as \"in_progress\" in handoff\n- Need to complete unfinished work first\n- May need to re-understand partial implementations\n- Focus on completing before new work\n\n### Scenario 4: Stale Handoff\n\n- Significant time has passed\n- Major refactoring has occurred\n- Original approach may no longer apply\n- Need to re-evaluate strategy\n\n## Example Interaction Flow\n\n```\nUser: /catalyst-dev:resume_handoff specification/feature/handoffs/handoff-0.md\nAssistant: Let me read and analyze that handoff document...\n\n[Reads handoff completely]\n[Spawns research tasks]\n[Waits for completion]\n[Reads identified files]\n\nI've analyzed the handoff from [date]. Here's the current situation...\n\n[Presents analysis]\n\nShall I proceed with implementing the webhook validation fix, or would you like to adjust the approach?\n\nUser: Yes, proceed with the webhook validation\nAssistant: [Creates todo list and begins implementation]\n```"
              },
              {
                "name": "/roadmap_review",
                "description": "Review project roadmap and milestone progress",
                "path": "plugins/dev/commands/roadmap_review.md",
                "frontmatter": {
                  "description": "Review project roadmap and milestone progress",
                  "category": "project-task-management",
                  "tools": "Bash(linearis *), Read, Write, TodoWrite",
                  "model": "inherit",
                  "version": "1.0.0",
                  "status": "placeholder"
                },
                "content": "# Roadmap Review\n\n**Status**: Placeholder for v1.0 - Full implementation coming in future release\n\n## Planned Functionality\n\nThis command will help you review your roadmap by:\n\n1. Listing all active projects\n2. Showing milestone progress for each project\n3. Identifying project dependencies\n4. Calculating project completion\n5. Generating roadmap summary\n\n## Current Workaround\n\nUse Linearis CLI directly:\n\n```bash\n# List projects\nlinearis projects list --team TEAM\n\n# Parse project status from JSON\nlinearis projects list --team TEAM | jq '.[] | {name, status, progress}'\n\n# List tickets for specific project\nlinearis issues list --team TEAM | jq '.[] | select(.project.name == \"Project Name\")'\n```\n\n### Example Workflow\n\n```bash\n# 1. List all active projects\nlinearis projects list --team ENG | \\\n  jq '.[] | select(.state != \"completed\") | {name, lead, targetDate}'\n\n# 2. Get project details with ticket counts\nfor project in $(linearis projects list --team ENG | jq -r '.[].name'); do\n  echo \"Project: $project\"\n\n  # Count tickets by status\n  linearis issues list --team ENG | \\\n    jq --arg proj \"$project\" '\n      [.[] | select(.project.name == $proj)] |\n      group_by(.state.name) |\n      map({status: .[0].state.name, count: length})\n    '\ndone\n\n# 3. Identify project dependencies\n# (Manual - look at project descriptions or ticket relationships)\n\n# 4. Calculate overall progress\n# total_tickets in project\n# completed_tickets in project\n# progress = (completed / total) * 100\n\n# 5. Identify at-risk projects\n# - No tickets completed in last 2 weeks\n# - Target date approaching with <50% completion\n# - Blocked tickets preventing progress\n```\n\n## Future Implementation\n\nWhen fully implemented, this command will:\n\n- **Project overview** - Show all projects with key metrics\n- **Milestone tracking** - Group tickets by milestone with progress\n- **Dependency visualization** - Show project relationships and blockers\n- **Risk analysis** - Identify at-risk projects (delayed, under-resourced)\n- **Timeline view** - Show project timelines and conflicts\n- **Resource allocation** - Show team members assigned to projects\n- **Summary generation** - Create roadmap document in thoughts/\n- **Trend analysis** - Compare progress month-over-month\n\nTrack progress at: https://github.com/coalesce-labs/catalyst/issues\n\n## Configuration\n\nUses `.claude/config.json`:\n\n```json\n{\n  \"linear\": {\n    \"teamKey\": \"ENG\",\n    \"defaultTeam\": \"Backend\"\n  }\n}\n```\n\n## Tips\n\n- Review roadmap **monthly** or **quarterly**\n- Update **target dates** based on actual velocity\n- Document **dependencies** explicitly in project descriptions\n- Identify **resource constraints** early\n- Communicate **delays** proactively to stakeholders\n- Use **milestones** to track major deliverables\n- Archive **completed projects** to reduce noise\n- Link projects to **company OKRs** for alignment\n\n## Related Commands\n\n- `/cycle-plan` - Plan work within cycles for a project\n- `/cycle-review` - Review cycle progress\n- `/catalyst-dev:linear` - Manage individual tickets\n- `/create-plan` - Create implementation plans for tickets"
              },
              {
                "name": "/validate_plan",
                "description": "Validate that implementation plans were correctly executed",
                "path": "plugins/dev/commands/validate_plan.md",
                "frontmatter": {
                  "description": "Validate that implementation plans were correctly executed",
                  "category": "workflow"
                },
                "content": "# Validate Plan\n\nYou are tasked with validating that an implementation plan was correctly executed, verifying all\nsuccess criteria and identifying any deviations or issues.\n\n## Initial Setup\n\nWhen invoked:\n\n1. **Determine context** - Are you in an existing conversation or starting fresh?\n   - If existing: Review what was implemented in this session\n   - If fresh: Need to discover what was done through git and codebase analysis\n\n2. **Locate the plan**:\n   - If plan path provided, use it\n   - Otherwise, search recent commits for plan references or ask user\n\n3. **Gather implementation evidence**:\n\n   ```bash\n   # Check recent commits\n   git log --oneline -n 20\n   git diff HEAD~N..HEAD  # Where N covers implementation commits\n\n   # Run comprehensive checks\n   cd $(git rev-parse --show-toplevel) && make check test\n   ```\n\n## Validation Process\n\n### Step 1: Context Discovery\n\nIf starting fresh or need more context:\n\n1. **Read the implementation plan** completely\n2. **Identify what should have changed**:\n   - List all files that should be modified\n   - Note all success criteria (automated and manual)\n   - Identify key functionality to verify\n\n3. **Spawn parallel research tasks** to discover implementation:\n\n   ```\n   Task 1 - Verify database changes:\n   Research if migration [N] was added and schema changes match plan.\n   Check: migration files, schema version, table structure\n   Return: What was implemented vs what plan specified\n\n   Task 2 - Verify code changes:\n   Find all modified files related to [feature].\n   Compare actual changes to plan specifications.\n   Return: File-by-file comparison of planned vs actual\n\n   Task 3 - Verify test coverage:\n   Check if tests were added/modified as specified.\n   Run test commands and capture results.\n   Return: Test status and any missing coverage\n   ```\n\n### Step 2: Systematic Validation\n\nFor each phase in the plan:\n\n1. **Check completion status**:\n   - Look for checkmarks in the plan (- [x])\n   - Verify the actual code matches claimed completion\n\n2. **Run automated verification**:\n   - Execute each command from \"Automated Verification\"\n   - Document pass/fail status\n   - If failures, investigate root cause\n\n3. **Assess manual criteria**:\n   - List what needs manual testing\n   - Provide clear steps for user verification\n\n4. **Think deeply about edge cases**:\n   - Were error conditions handled?\n   - Are there missing validations?\n   - Could the implementation break existing functionality?\n\n### Step 3: Generate Validation Report\n\n**Before generating report, check context usage**:\n\nCreate comprehensive validation summary:\n\n```\n# Validation Report: {Feature Name}\n\n**Plan**: `thoughts/shared/plans/YYYY-MM-DD-PROJ-XXXX-feature.md`\n**Validated**: {date}\n**Validation Status**: {PASS/FAIL/PARTIAL}\n\n## üìä Context Status\nCurrent usage: {X}% ({Y}K/{Z}K tokens)\n\n{If >60%}:\n‚ö†Ô∏è **Context Alert**: Validation consumed {X}% of context.\n\n**Recommendation**: After reviewing this report, clear context before PR creation.\n\n**Why?** PR description generation benefits from fresh context to:\n- Synthesize changes clearly\n- Write concise summaries\n- Avoid accumulated error context\n\n**Next steps**:\n1. Review this validation report\n2. Address any failures\n3. Close this session (clear context)\n4. Start fresh for: `/catalyst-dev:commit` and `/describe-pr`\n\n{If <60%}:\n‚úÖ Context healthy. Ready for PR creation.\n\n---\n\n{Continue with rest of validation report...}\n```\n\n```markdown\n## Validation Report: [Plan Name]\n\n### Implementation Status\n\n‚úì Phase 1: [Name] - Fully implemented ‚úì Phase 2: [Name] - Fully implemented ‚ö†Ô∏è Phase 3: [Name] -\nPartially implemented (see issues)\n\n### Automated Verification Results\n\n‚úì Build passes: `make build` ‚úì Tests pass: `make test` ‚úó Linting issues: `make lint` (3 warnings)\n\n### Code Review Findings\n\n#### Matches Plan:\n\n- Database migration correctly adds [table]\n- API endpoints implement specified methods\n- Error handling follows plan\n\n#### Deviations from Plan:\n\n- Used different variable names in [file:line]\n- Added extra validation in [file:line] (improvement)\n\n#### Potential Issues:\n\n- Missing index on foreign key could impact performance\n- No rollback handling in migration\n\n### Manual Testing Required:\n\n1. UI functionality:\n   - [ ] Verify [feature] appears correctly\n   - [ ] Test error states with invalid input\n\n2. Integration:\n   - [ ] Confirm works with existing [component]\n   - [ ] Check performance with large datasets\n\n### Recommendations:\n\n- Address linting warnings before merge\n- Consider adding integration test for [scenario]\n- Document new API endpoints\n```\n\n## Working with Existing Context\n\nIf you were part of the implementation:\n\n- Review the conversation history\n- Check your todo list for what was completed\n- Focus validation on work done in this session\n- Be honest about any shortcuts or incomplete items\n\n## Important Guidelines\n\n1. **Be thorough but practical** - Focus on what matters\n2. **Run all automated checks** - Don't skip verification commands\n3. **Document everything** - Both successes and issues\n4. **Think critically** - Question if the implementation truly solves the problem\n5. **Consider maintenance** - Will this be maintainable long-term?\n\n## Validation Checklist\n\nAlways verify:\n\n- [ ] All phases marked complete are actually done\n- [ ] Automated tests pass\n- [ ] Code follows existing patterns\n- [ ] No regressions introduced\n- [ ] Error handling is robust\n- [ ] Documentation updated if needed\n- [ ] Manual test steps are clear\n\n## Relationship to Other Commands\n\nRecommended workflow:\n\n1. `/catalyst-dev:implement_plan` - Execute the implementation\n2. `/catalyst-dev:commit` - Create atomic commits for changes\n3. `/catalyst-dev:validate_plan` - Verify implementation correctness\n4. `/catalyst-dev:describe_pr` - Generate PR description\n\nThe validation works best after commits are made, as it can analyze the git history to understand\nwhat was implemented.\n\nRemember: Good validation catches issues before they reach production. Be constructive but thorough\nin identifying gaps or improvements."
              },
              {
                "name": "/workflow_help",
                "description": "Interactive guide to supported workflows with context-aware assistance",
                "path": "plugins/dev/commands/workflow_help.md",
                "frontmatter": {
                  "description": "Interactive guide to supported workflows with context-aware assistance",
                  "category": "workflow",
                  "tools": "Read, Grep, Glob, Task",
                  "model": "inherit",
                  "version": "1.0.0"
                },
                "content": "# Workflow Help\n\nYou are an interactive workflow guide that helps users navigate the supported workflows in this\nrepository using parallel sub-agents for research and context-aware guidance.\n\n## Initial Response\n\nWhen this command is invoked WITHOUT parameters:\n\n```\n# üéØ Workflow Guide\n\nI can help you navigate the supported workflows in this workspace.\n\n## Available Workflows\n\n**1. Development Workflow** (research ‚Üí plan ‚Üí implement ‚Üí validate ‚Üí PR)\n   - `/research-codebase` ‚Üí Document existing system\n   - `/create-plan` ‚Üí Create implementation plan\n   - `/implement-plan` ‚Üí Execute approved plan\n   - `/validate-plan` ‚Üí Verify implementation\n   - Handoffs & worktrees for context management\n\n**2. Workflow Discovery** (discover ‚Üí import ‚Üí create ‚Üí validate)\n   - `/discover-workflows` ‚Üí Research external repositories\n   - `/import-workflow` ‚Üí Adapt external workflows\n   - `/create-workflow` ‚Üí Build new agents/commands\n   - `/validate-frontmatter` ‚Üí Ensure consistency\n\n**3. Utilities**\n   - `/catalyst-dev:commit` ‚Üí Create structured commits\n   - `/describe-pr` ‚Üí Generate PR descriptions\n   - `/catalyst-dev:debug` ‚Üí Investigate issues\n   - `/catalyst-dev:linear` ‚Üí Linear ticket integration\n\n---\n\n**Which workflow would you like to learn about?**\n\nType the number (1-3) or workflow name, or ask a question like:\n- \"I have a ticket to implement - what should I do?\"\n- \"How do I pause work and resume later?\"\n- \"What's the complete development workflow?\"\n```\n\nThen wait for user input.\n\n## Processing User Input\n\n### Step 1: Detect Context\n\nCheck if the user is already in a workflow by spawning parallel detection tasks:\n\n**Task 1 - Check for Active Work**:\n\n```\nUse codebase-locator agent:\n\"Search for recent uncommitted changes, work-in-progress files, or partial implementations. Look for:\n- Git status (uncommitted files)\n- WIP branches\n- Partial plan files with unchecked boxes\n- Draft handoffs\nReturn: Evidence of active work with file paths\"\n\nTools: Bash (git status), Grep, Glob\n```\n\n**Task 2 - Find Recent Documents**:\n\n```\nUse thoughts-locator agent (or Glob if no thoughts):\n\"Find the most recent research, plan, or handoff documents. Look in:\n- thoughts/shared/research/ (or research/)\n- thoughts/shared/plans/ (or plans/)\n- thoughts/shared/handoffs/ (or handoffs/)\nReturn: 3 most recent documents with dates and topics\"\n\nTools: Bash (ls -t), Grep, Glob\n```\n\n**Task 3 - Detect Worktree**:\n\n```\n\"Check if currently in a git worktree (not main repo).\nRun: pwd and git worktree list\nReturn: Whether in worktree, worktree name if applicable\"\n\nTools: Bash\n```\n\nWAIT for all tasks to complete.\n\n### Step 2: Analyze Context\n\nBased on detection results, determine user's current state:\n\n- **In Worktree with Plan** ‚Üí Likely in Implementation phase\n- **Recent Research Doc** ‚Üí May be ready for Planning\n- **Recent Plan Doc** ‚Üí May be ready for Implementation\n- **Recent Handoff** ‚Üí May want to resume\n- **No Active Work** ‚Üí Starting fresh\n\n### Step 3: Provide Context-Aware Guidance\n\n**If User is in Active Workflow:**\n\n```\nüéØ **I see you're currently working on {detected-context}**\n\n**Current State:**\n- {What I detected - be specific with file paths}\n- {Where you likely are in workflow}\n\n**Suggested Next Steps:**\n1. {Most likely next action}\n2. {Alternative action}\n3. {How to pause/handoff if needed}\n\n**Context Management:**\n‚ö†Ô∏è Remember to CLEAR CONTEXT between workflow phases!\n- Current phase: {detected-phase}\n- Clear context after: {when to clear}\n\n**Note**: I can monitor my own context usage and will proactively warn you if it gets high. You can also check anytime with `/context`.\n\nWould you like me to:\n1. Continue with next step\n2. Explain the complete workflow\n3. Help you pause/create handoff\n4. Something else\n```\n\n**If User is Starting Fresh:**\n\nProceed to workflow selection (Step 4).\n\n### Step 4: Workflow Selection\n\nBased on user's choice, spawn parallel research to provide comprehensive guidance:\n\n#### For Development Workflow (Option 1):\n\nSpawn 3 parallel research tasks:\n\n**Task 1 - Read Workflow Guide**:\n\n```\n\"Read docs/AGENTIC_WORKFLOW_GUIDE.md and extract:\n- Complete workflow phases\n- Context clearing guidelines\n- When to use each command\nReturn: Concise summary of complete workflow\"\n\nTools: Read\n```\n\n**Task 2 - Find Command Examples**:\n\n```\n\"Search for examples in:\n- commands/research_codebase.md\n- commands/create_plan.md\n- commands/implement_plan.md\nExtract example usage and common patterns\nReturn: Concrete examples users can follow\"\n\nTools: Read, Grep\n```\n\n**Task 3 - Check for User Files**:\n\n```\n\"Check if user has any existing research, plans, or handoffs.\nLook in thoughts/ or research/, plans/, handoffs/ directories.\nReturn: What files exist, suggesting next steps based on what's there\"\n\nTools: Glob, Bash\n```\n\nWAIT for all tasks.\n\n**Present Comprehensive Guide:**\n\n```\n# üîÑ Development Workflow: Research ‚Üí Plan ‚Üí Implement ‚Üí Validate ‚Üí PR\n\n{Synthesize findings from 3 parallel tasks}\n\n## Complete Process\n\n### Phase 1: Research üîç\n**When**: Need to understand existing codebase before planning\n**Command**: `/research-codebase`\n\n{Include example from Task 2}\n{Note any existing research docs from Task 3}\n\n**Output**: `thoughts/shared/research/YYYY-MM-DD-PROJ-XXXX-description.md`\n**After**: ‚úÖ **CLEAR CONTEXT**\n\n---\n\n### Phase 2: Planning üìã\n**When**: Ready to create implementation plan\n**Command**: `/create-plan`\n\n{Include example}\n\n**Output**: `thoughts/shared/plans/YYYY-MM-DD-PROJ-XXXX-description.md`\n**After**: ‚úÖ **CLEAR CONTEXT**\n\n---\n\n### Phase 3: Worktree Creation üå≤\n**When**: Plan approved, ready to implement\n**How**:\n\n\\`\\`\\`bash\n\"${CLAUDE_PLUGIN_ROOT}/scripts/create-worktree.sh\" PROJ-123 feature-name\ncd ~/wt/{project}/PROJ-123-feature\n\\`\\`\\`\n\n**After**: ‚úÖ **CLEAR CONTEXT** (fresh session in worktree)\n\n---\n\n### Phase 4: Implementation ‚öôÔ∏è\n**When**: In worktree with approved plan\n**Command**: `/implement-plan thoughts/shared/plans/YYYY-MM-DD-PROJ-XXXX-feature.md`\n\n{Include example}\n\n**Checkpoints**: After EACH phase in plan\n**After**: ‚úÖ **CLEAR CONTEXT**\n\n---\n\n### Phase 5: Validation ‚úÖ\n**When**: All implementation phases complete\n**Command**: `/validate-plan`\n\n**After**: ‚úÖ **CLEAR CONTEXT**\n\n---\n\n### Phase 6: PR Creation üöÄ\n**Commands**:\n\\`\\`\\`bash\n/catalyst-dev:commit\ngh pr create --fill\n/describe-pr\n\\`\\`\\`\n\n**Output**: `thoughts/shared/prs/pr_{number}_{description}.md`\n**After**: ‚úÖ **CLEAR CONTEXT** - workflow complete!\n\n---\n\n## üîÑ Handoff System (Pause/Resume)\n\n**Create Handoff** (to pause work):\n\\`\\`\\`bash\n/create-handoff\n\\`\\`\\`\n**Output**: `thoughts/shared/handoffs/PROJ-XXXX/YYYY-MM-DD_HH-MM-SS_description.md`\n\n**Resume Handoff**:\n\\`\\`\\`bash\n/resume-handoff {path-or-ticket}\n\\`\\`\\`\n\n---\n\n## ‚ö†Ô∏è Context Management\n\n**CLEAR CONTEXT between EVERY phase**\n- After research document created\n- After plan approved\n- After creating handoff\n- Before implementation in worktree\n- After implementation complete\n- Before validation\n- After PR created\n\n**Why?** Keeps AI performance optimal (40-60% context utilization)\n\n**How to check**: I monitor my context automatically and will warn you.\nYou can also check anytime with `/context` command.\n\n**When I warn you**:\n- I'll show current usage: e.g., \"65% (130K/200K tokens)\"\n- I'll explain why clearing helps\n- I'll offer to create a handoff if needed\n- I'll tell you exactly what to do next\n\n**Context clearing is NORMAL and EXPECTED** - it's how we maintain quality!\n\n---\n\n{Based on Task 3 - suggest next step}\n\n**Your Next Step:**\n{If existing files found:} You have {file} - ready to {next-action}?\n{If no files:} Start with: `/research-codebase` or `/create-plan`\n\n**Need more details on any phase?** Just ask!\n```\n\n#### For Workflow Discovery (Option 2):\n\nSpawn parallel research:\n\n**Task 1**: Read `docs/WORKFLOW_DISCOVERY_SYSTEM.md` **Task 2**: Read command files\n(discover_workflows, import_workflow, etc.) **Task 3**: Check if user has any workflow catalog\n\nWAIT and synthesize similar to above.\n\n#### For Utilities (Option 3):\n\nRead relevant command files and provide quick reference.\n\n### Step 5: Answer Follow-Up Questions\n\n**If user asks specific questions:**\n\nSpawn focused research tasks to answer:\n\n**Example**: \"How do I pause work and resume later?\"\n\n```\nTask 1: \"Read docs/AGENTIC_WORKFLOW_GUIDE.md section on Handoff System\"\nTask 2: \"Find examples in commands/create_handoff.md and commands/resume_handoff.md\"\nTask 3: \"Check if user has existing handoffs\"\n```\n\nPresent targeted answer with examples.\n\n### Step 6: Provide Quick Actions\n\n**Always end with actionable next steps:**\n\n```\n---\n\n## Ready to Get Started?\n\n**Quick Actions:**\n1. üìù Start research: `/research-codebase`\n2. üìã Create plan: `/create-plan`\n3. üîÑ Resume work: `/resume-handoff {ticket}`\n4. üîç Discover workflows: `/discover-workflows`\n5. ‚ùì Ask me anything else!\n\n**Pro Tips:**\n- Clear context between phases for best performance\n- Read outputs completely before next phase\n- Use handoffs liberally - context is precious\n- Worktrees isolate your changes safely\n\nType a command or ask another question!\n```\n\n## Important Guidelines\n\n### Context-Aware Assistance\n\n1. **Always detect current state first** using parallel agents\n2. **Don't assume** - verify with actual file checks\n3. **Be specific** with file paths and next actions\n4. **Remind about context clearing** at appropriate points\n\n### Compression & Conciseness\n\n1. **Parallel agents research details** - keep main context clean\n2. **Synthesize findings** - don't dump raw agent outputs\n3. **Provide examples** - concrete > abstract\n4. **Quick reference** - users can dive deeper if needed\n\n### Link to Documentation\n\n**Always provide links** to detailed documentation:\n\n- Full workflow: `docs/AGENTIC_WORKFLOW_GUIDE.md`\n- Workflow discovery: `docs/WORKFLOW_DISCOVERY_SYSTEM.md`\n- Frontmatter: `docs/FRONTMATTER_STANDARD.md`\n- Main README: `README.md`\n\n### Web Research (If Needed)\n\nIf user asks about external concepts:\n\n**Use external-research agent**:\n\n```\n\"Research {topic} from HumanLayer or Anthropic documentation.\nReturn: Summary with links to sources\"\n\nTools: WebSearch, WebFetch, mcp__deepwiki__ask_question\n```\n\nInclude links in response.\n\n## Example Interactions\n\n### Example 1: User in Middle of Workflow\n\n```\nUser: /workflow-help\n\n[Agent spawns 3 parallel detection tasks]\n\nAgent: üéØ **I see you're currently working on PROJ-123 OAuth implementation**\n\n**Current State:**\n- Worktree: `~/wt/my-project/PROJ-123-oauth`\n- Plan: `thoughts/shared/plans/2025-01-08-PROJ-123-oauth.md`\n- Status: Phase 2/4 complete (checkboxes updated)\n\n**You're in Implementation Phase**\n\n**Suggested Next Steps:**\n1. ‚úÖ Continue implementing Phase 3: `/implement-plan` (will resume from checkboxes)\n2. üîÑ Need to pause? `/create-handoff` before stopping\n3. üìñ Review plan: Check `thoughts/shared/plans/2025-01-08-PROJ-123-oauth.md`\n\n**Context Management:**\n‚ö†Ô∏è If context feels full (>60%), clear and resume with plan file\n\nWould you like me to:\n1. Continue with Phase 3\n2. Show complete workflow overview\n3. Help create handoff to pause work\n```\n\n### Example 2: User Starting Fresh\n\n```\nUser: I have a ticket to implement OAuth support\n\n[Agent spawns detection tasks - finds no active work]\n\nAgent: üéØ **Great! Let's start the Development Workflow for OAuth support**\n\nI don't see any existing research or plans for this, so let's start from the beginning.\n\n## Recommended Approach\n\n### Step 1: Research Phase üîç\nFirst, understand how authentication currently works:\n\n\\`\\`\\`\n/research-codebase\n\\`\\`\\`\n\nWhen prompted, ask: \"How does authentication currently work? What patterns exist?\"\n\n**Output**: `thoughts/shared/research/YYYY-MM-DD-PROJ-XXX-auth-system.md`\n\n**After research**: ‚úÖ **CLEAR CONTEXT** (close this conversation, start fresh)\n\n---\n\n### Step 2: Planning Phase üìã\nCreate implementation plan:\n\n\\`\\`\\`\n/create-plan\n\\`\\`\\`\n\nReference your research doc when planning.\n\n**Output**: `thoughts/shared/plans/YYYY-MM-DD-PROJ-XXX-oauth-support.md`\n\n**After plan approved**: ‚úÖ **CLEAR CONTEXT**\n\n---\n\n{Continue with remaining phases...}\n\n**Ready to start research?** Type `/research-codebase` or ask more questions!\n```\n\n### Example 3: Quick Question\n\n```\nUser: How do I pause work and resume later?\n\n[Agent reads handoff documentation]\n\nAgent: üîÑ **Pausing and Resuming Work**\n\nUse the **Handoff System** to pause/resume:\n\n### To Pause:\n\\`\\`\\`bash\n/create-handoff\n\\`\\`\\`\n\nCreates: `thoughts/shared/handoffs/PROJ-XXXX/YYYY-MM-DD_HH-MM-SS_description.md`\n\nThe handoff captures:\n- Current progress\n- Critical file references\n- Next action items\n- Blockers/questions\n\n**After creating handoff**: ‚úÖ **CLEAR CONTEXT** - you can safely stop\n\n---\n\n### To Resume:\n\\`\\`\\`bash\n/resume-handoff thoughts/shared/handoffs/PROJ-123/2025-01-08_14-30-45_oauth.md\n\\`\\`\\`\n\nOr if command supports:\n\\`\\`\\`bash\n/resume-handoff PROJ-123  # Finds latest handoff\n\\`\\`\\`\n\n**The resume process:**\n1. Reads handoff + linked docs\n2. Verifies current state\n3. Proposes next actions\n4. Continues where you left off\n\n---\n\n**Pro Tip**: Create handoffs liberally! Any time:\n- End of day\n- Context fills up (>60%)\n- Need to switch tasks\n- Blocked and need input\n\nSee full guide: `docs/AGENTIC_WORKFLOW_GUIDE.md` (Handoff System section)\n\n**Anything else?**\n```\n\n## Advanced Features\n\n### Workflow State Detection\n\nThe parallel agents can detect:\n\n- Current git branch\n- Worktree vs main repo\n- Recent files modified\n- Plan files with checkboxes\n- Research documents\n- Handoff documents\n- PR status\n\n### Personalized Guidance\n\nBased on detected state, provide:\n\n- Specific file paths to reference\n- Exact commands to run next\n- Progress indicators (Phase X of Y)\n- Context clearing reminders at right moments\n\n### Link to External Resources\n\nWhen relevant, include links:\n\n```\n**Further Reading:**\n- [HumanLayer Advanced Context Engineering](https://github.com/humanlayer/advanced-context-engineering-for-coding-agents)\n- [12 Factor Agents](https://github.com/humanlayer/12-factor-agents)\n- [Anthropic Best Practices](https://www.anthropic.com/engineering/claude-code-best-practices)\n```\n\n## Important Notes\n\n- **Use parallel agents** to research docs - keeps main context clean\n- **Be context-aware** - detect where user is in workflow\n- **Provide concrete examples** - not just theory\n- **Remind about context clearing** - critical for performance\n- **Link to detailed docs** - comprehensive info available\n- **Quick actionable steps** - users can start immediately\n- **Follow-up friendly** - can answer deeper questions\n\nThis command serves as an interactive, intelligent guide to the entire workflow system!"
              }
            ],
            "skills": [
              {
                "name": "linearis-cli",
                "description": "Reference for Linearis CLI commands to interact with Linear project management. Use when working with Linear tickets, cycles, projects, milestones, or when the user mentions ticket IDs like TEAM-123, BRAVO-456, ENG-789.",
                "path": "plugins/dev/skills/linearis/SKILL.md",
                "frontmatter": {
                  "name": "linearis-cli",
                  "description": "Reference for Linearis CLI commands to interact with Linear project management. Use when working with Linear tickets, cycles, projects, milestones, or when the user mentions ticket IDs like TEAM-123, BRAVO-456, ENG-789."
                },
                "content": "# Linearis CLI Reference\n\n**CRITICAL: Always use these exact patterns. Do NOT guess or improvise syntax.**\n\n## Issue Operations\n\n### Read a Ticket\n```bash\nlinearis issues read TEAM-123                    # ‚úÖ By identifier\nlinearis issues read 7690e05c-32fb-4cf2-b709-f9adb12e73e7  # ‚úÖ By UUID\n```\n\n**Common mistakes:**\n```bash\nlinearis issues get TEAM-123      # ‚ùå WRONG - no 'get' command\nlinearis issue view TEAM-123      # ‚ùå WRONG - no 'view', use 'read'\nlinearis issue TEAM-123           # ‚ùå WRONG - missing subcommand\n```\n\n### List Tickets\n```bash\nlinearis issues list                      # Basic list (25 tickets)\nlinearis issues list --limit 50           # With limit\nlinearis issues list --team BRAVO         # Filter by team\nlinearis issues list --team BRAVO --limit 100\n```\n\n**NOTE:** `--limit` and `--team` are the ONLY supported filters. For other filtering, use jq:\n```bash\n# Filter by status - use jq, NOT --status or --filter\nlinearis issues list --limit 100 | jq '.[] | select(.state.name == \"In Progress\")'\n\n# Search by title\nlinearis issues list --limit 100 | jq '.[] | select(.title | contains(\"auth\"))'\n```\n\n**Common mistakes:**\n```bash\nlinearis issues list --status \"In Progress\"  # ‚ùå WRONG - no --status flag\nlinearis issues list --filter \"keyword\"      # ‚ùå WRONG - no --filter flag\nlinearis issues --filter \"keyword\"           # ‚ùå WRONG - no --filter flag\n```\n\n### Search Tickets\n```bash\nlinearis issues search \"keyword\" --team BRAVO    # ‚úÖ Correct\nlinearis issues search \"auth\" --team ENG         # ‚úÖ Correct\n```\n\n### Update a Ticket\n```bash\n# Update state - use --state NOT --status!\nlinearis issues update TEAM-123 --state \"In Progress\"\nlinearis issues update TEAM-123 --state \"Research\"\nlinearis issues update TEAM-123 --state \"Done\"\n\n# Other updates\nlinearis issues update TEAM-123 --title \"New title\"\nlinearis issues update TEAM-123 --description \"New description\"\nlinearis issues update TEAM-123 --priority 1              # 1=Urgent, 2=High, 3=Medium, 4=Low\nlinearis issues update TEAM-123 --assignee <user-id>\nlinearis issues update TEAM-123 --project \"Project Name\"\nlinearis issues update TEAM-123 --cycle \"Cycle Name\"\nlinearis issues update TEAM-123 --project-milestone \"Milestone Name\"\nlinearis issues update TEAM-123 --labels \"bug,urgent\"\nlinearis issues update TEAM-123 --clear-cycle\nlinearis issues update TEAM-123 --clear-project-milestone\n```\n\n**Common mistakes:**\n```bash\nlinearis issues update TEAM-123 --status \"Done\"   # ‚ùå WRONG - use --state\n```\n\n### Create a Ticket\n```bash\nlinearis issues create \"Title of ticket\"\nlinearis issues create \"Title\" --description \"Description\" --state \"Todo\" --priority 2\nlinearis issues create \"Title\" --team BRAVO --project \"Project Name\"\n```\n\n## Comment Operations\n\n### Add a Comment\n```bash\nlinearis comments create TEAM-123 --body \"Starting research\"\n\n# Multi-line comment\nlinearis comments create TEAM-123 --body \"Research complete!\n\nSee findings: https://github.com/...\"\n```\n\n**Common mistakes:**\n```bash\nlinearis issues comment TEAM-123 \"Comment\"        # ‚ùå WRONG\nlinearis issues add-comment TEAM-123 \"Comment\"    # ‚ùå WRONG\nlinearis comment TEAM-123 --body \"Comment\"        # ‚ùå WRONG\n```\n\n**Correct pattern:** `linearis comments create` (plural \"comments\", then \"create\")\n\n## Cycle Operations\n\n### List Cycles\n```bash\nlinearis cycles list --team BRAVO              # All cycles\nlinearis cycles list --team BRAVO --active     # Only active cycle\nlinearis cycles list --team BRAVO --limit 5    # Recent cycles\n```\n\n### Read Cycle Details\n```bash\nlinearis cycles read \"Sprint 2025-11\" --team BRAVO   # By name\nlinearis cycles read <cycle-uuid>                     # By UUID\n```\n\nReturns all issues in the cycle - useful for cycle analysis.\n\n### Get Active Cycle Pattern\n```bash\nCYCLE=$(linearis cycles list --team BRAVO --active | jq -r '.[0].name')\nlinearis cycles read \"$CYCLE\" --team BRAVO | jq '.issues[] | {identifier, title, state: .state.name}'\n```\n\n## Project Operations\n\n### List Projects\n```bash\nlinearis projects list --team BRAVO\nlinearis projects list --team BRAVO | jq '.[] | select(.name == \"Auth System\")'\n```\n\n## Milestone Operations\n\n### List Milestones\n```bash\nlinearis project-milestones list --project \"Project Name\"\nlinearis project-milestones list --project <project-uuid>\n```\n\n### Read Milestone\n```bash\nlinearis project-milestones read \"Beta Launch\" --project \"Auth System\"\nlinearis project-milestones read <milestone-uuid>\n```\n\n### Update Milestone\n```bash\nlinearis project-milestones update \"Milestone\" --project \"Project\" --name \"New Name\"\nlinearis project-milestones update \"Milestone\" --project \"Project\" --target-date \"2025-12-31\"\n```\n\n## Label Operations\n\n```bash\nlinearis labels list --team BRAVO\n```\n\n## Common Workflow Patterns\n\n### Read ticket, update state, add comment\n```bash\n# 1. Read ticket\nlinearis issues read TEAM-123\n\n# 2. Update state\nlinearis issues update TEAM-123 --state \"In Progress\"\n\n# 3. Add comment\nlinearis comments create TEAM-123 --body \"Starting work on this\"\n```\n\n### Find tickets in current cycle\n```bash\nCYCLE=$(linearis cycles list --team BRAVO --active | jq -r '.[0].name')\nlinearis cycles read \"$CYCLE\" --team BRAVO | jq '.issues[] | {identifier, title, state: .state.name}'\n```\n\n### Get tickets by project\n```bash\nlinearis issues list --team BRAVO --limit 100 | jq '.[] | select(.project.name == \"Auth System\")'\n```\n\n### Mark ticket as done with PR link\n```bash\nlinearis issues update TEAM-123 --state \"Done\"\nlinearis comments create TEAM-123 --body \"Merged: PR #456 https://github.com/org/repo/pull/456\"\n```\n\n## Quick Reference Card\n\n| Action | Command |\n|--------|---------|\n| Read ticket | `linearis issues read TEAM-123` |\n| Update state | `linearis issues update TEAM-123 --state \"State\"` |\n| Add comment | `linearis comments create TEAM-123 --body \"text\"` |\n| Search | `linearis issues search \"keyword\" --team TEAM` |\n| List issues | `linearis issues list --team TEAM --limit N` |\n| Active cycle | `linearis cycles list --team TEAM --active` |\n| Cycle details | `linearis cycles read \"Name\" --team TEAM` |\n\n## Important Rules\n\n1. **--state NOT --status**: Always use `--state` for issue state updates\n2. **comments create**: Use `linearis comments create`, not `issues comment`\n3. **issues read**: Use `read`, not `get` or `view`\n4. **Filtering via jq**: No `--filter` or `--status` flags - pipe to jq instead\n5. **Team parameter**: Most commands need `--team TEAM-KEY`\n6. **Quotes for spaces**: `--cycle \"Sprint 2025-11\"` not `--cycle Sprint 2025-11`\n7. **JSON output**: All commands return JSON - use jq for parsing\n\n## Getting Help\n\n```bash\nlinearis --help\nlinearis issues --help\nlinearis issues update --help\nlinearis comments --help\nlinearis cycles --help\n```"
              }
            ]
          },
          {
            "name": "catalyst-pm",
            "description": "Linear-focused project management: cycle tracking, milestone planning, backlog grooming, daily standups, GitHub-Linear sync. Enable when managing Linear projects. ~5k context when enabled.",
            "source": "./plugins/pm",
            "category": "productivity",
            "version": "3.0.1",
            "author": {
              "name": "Coalesce Labs",
              "email": "hello@coalesce.dev"
            },
            "install_commands": [
              "/plugin marketplace add coalesce-labs/catalyst",
              "/plugin install catalyst-pm@catalyst"
            ],
            "signals": {
              "stars": 6,
              "forks": 0,
              "pushed_at": "2026-01-12T04:14:24Z",
              "created_at": "2025-10-04T11:10:26Z",
              "license": null
            },
            "commands": [
              {
                "name": "/analyze_cycle",
                "description": "Analyze cycle health and generate comprehensive report with actionable insights, risk analysis, capacity assessment, and specific recommendations",
                "path": "plugins/pm/commands/analyze_cycle.md",
                "frontmatter": {
                  "description": "Analyze cycle health and generate comprehensive report with actionable insights, risk analysis, capacity assessment, and specific recommendations",
                  "category": "pm",
                  "tools": "Task, Read, Write, TodoWrite",
                  "model": "inherit",
                  "version": "1.0.0"
                },
                "content": "# Analyze Cycle Command\n\nGenerates a comprehensive **health report** (not just data) for the current Linear cycle.\n\n**Reports Include**:\n- üü¢üü°üî¥ Health assessment with overall status\n- üìä Progress metrics with data backing\n- üéØ Actionable takeaways (what needs attention NOW)\n- üë• Team capacity analysis (who can work on what)\n- ‚ö†Ô∏è Risk identification (overweight, blocked, at-risk issues)\n- üí° Specific recommendations (what to do about it)\n\n**Philosophy**: Provide insights and recommendations, not just data dumps. PMs should know exactly what action to take after reading the report.\n\n## Prerequisites Check\n\nFirst, verify all required tools and systems:\n\n```bash\n# 1. Validate thoughts system (REQUIRED)\nif [[ -f \"scripts/validate-thoughts-setup.sh\" ]]; then\n  ./scripts/validate-thoughts-setup.sh || exit 1\nelse\n  # Inline validation if script not found\n  if [[ ! -d \"thoughts/shared\" ]]; then\n    echo \"‚ùå ERROR: Thoughts system not configured\"\n    echo \"Run: ./scripts/humanlayer/init-project.sh . {project-name}\"\n    exit 1\n  fi\nfi\n\n# 2. Determine script directory with fallback\nif [[ -n \"${CLAUDE_PLUGIN_ROOT}\" ]]; then\n  SCRIPT_DIR=\"${CLAUDE_PLUGIN_ROOT}/scripts\"\nelse\n  # Fallback: resolve relative to this command file\n  SCRIPT_DIR=\"$(cd \"$(dirname \"${BASH_SOURCE[0]}\")/..\" && pwd)/scripts\"\nfi\n\n# 3. Check PM plugin prerequisites\nif [[ -f \"${SCRIPT_DIR}/check-prerequisites.sh\" ]]; then\n  \"${SCRIPT_DIR}/check-prerequisites.sh\" || exit 1\nelse\n  echo \"‚ö†Ô∏è Prerequisites check skipped (script not found at: ${SCRIPT_DIR})\"\nfi\n```\n\n## Process\n\n### Step 1: Gather Configuration\n\n```bash\n# Determine script directory with fallback (if not already set)\nif [[ -z \"${SCRIPT_DIR}\" ]]; then\n  if [[ -n \"${CLAUDE_PLUGIN_ROOT}\" ]]; then\n    SCRIPT_DIR=\"${CLAUDE_PLUGIN_ROOT}/scripts\"\n  else\n    SCRIPT_DIR=\"$(cd \"$(dirname \"${BASH_SOURCE[0]}\")/..\" && pwd)/scripts\"\n  fi\nfi\n\nsource \"${SCRIPT_DIR}/pm-utils.sh\"\n\nTEAM_KEY=$(get_team_key)\nCONFIG_FILE=\".claude/config.json\"\n```\n\n### Step 2: Spawn Research Tasks (Parallel)\n\nSpawn multiple research agents in parallel to gather data:\n\n**Task 1 - Get Active Cycle**:\n\nUse Task tool with `catalyst-dev:linear-research` agent:\n\n```\nPrompt: \"Get the active cycle for team ${TEAM_KEY} with all issues\"\nModel: haiku (fast data gathering)\n```\n\n**Task 2 - Get Team Workload**:\n\nUse Task tool with `catalyst-dev:linear-research` agent:\n\n```\nPrompt: \"List all in-progress issues for team ${TEAM_KEY}\"\nModel: haiku (fast data gathering)\n```\n\n**Wait for both tasks to complete**\n\n### Step 3: Spawn Analysis Agent\n\nUse Task tool with `cycle-analyzer` agent:\n\n**Input**:\n- Cycle data JSON from Task 1\n- In-progress issues from Task 2\n- Current date: $(date +%Y-%m-%d)\n\n**Agent returns**:\nStructured markdown with health assessment, risks, capacity, recommendations\n\n### Step 4: Generate Health Report\n\nFormat the agent's analysis into a user-facing health report:\n\n**Report Structure**:\n\n```markdown\n# Cycle Health Report: [Cycle Name]\n\n## üü¢/üü°/üî¥ Health Assessment\n\n**Takeaway**: [One-sentence summary of cycle health and key concern]\n\n**Current State**: [Concise statement with specific numbers]\n- Progress: X% complete (Y/Z issues done)\n- Time: N days remaining of M total\n- Projected completion: X% (based on current velocity)\n- Risk level: [Explanation]\n\n---\n\n## üìä Progress Data\n\n**Cycle**: Sprint 2025-W04 (Jan 20-26)\n**Progress**: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë 45% (18/40 issues)\n\n| Status | Count | Percentage |\n|--------|-------|------------|\n| ‚úÖ Done | 18 | 45% |\n| üîÑ In Progress | 12 | 30% |\n| üìã Todo | 10 | 25% |\n\n**By Assignee**:\n- Alice: 15 issues (8 done, 5 in progress, 2 todo)\n- Bob: 12 issues (6 done, 4 in progress, 2 todo)\n- Charlie: 8 issues (4 done, 2 in progress, 2 todo)\n- Unassigned: 5 issues\n\n---\n\n## üë• Team Capacity Analysis\n\n**Available for Work**:\n- Bob: 2 active issues, can take 1-2 more\n- Charlie: 2 active issues, can take 1 more\n\n**At Capacity**:\n- Alice: 5 active issues (near max capacity)\n\n**Needs Attention**:\n- Dave: No active issues (assign work)\n\n---\n\n## ‚ö†Ô∏è Risks & Blockers\n\n**üö® Blockers** (2 issues):\n- TEAM-461: External API approval (blocked 6 days)\n  - Owner: Alice\n  - Blocker: Waiting on partner team response\n- TEAM-462: Dependency conflict (blocked 4 days)\n  - Owner: Bob\n  - Blocker: Upstream library bug\n\n**‚ö†Ô∏è At Risk** (3 issues, >5 days in progress):\n- TEAM-463: Complex refactor (7 days, Alice)\n  - Risk: No commits in 3 days\n- TEAM-464: Database migration (6 days, Bob)\n  - Risk: Scope increased mid-work\n- TEAM-465: API redesign (5 days, Charlie)\n  - Risk: Waiting on code review\n\n---\n\n## üí° Recommendations\n\n**Priority Actions** (do these today):\n1. **Escalate TEAM-461** - Partner team blocking for 6 days, needs PM intervention\n2. **Pair Bob with senior dev** on TEAM-462 - Dependency issue may need architectural change\n3. **Check in with Alice** on TEAM-463 - 3 days no activity, may need help\n\n**Capacity Optimization**:\n1. **Assign 2 issues to Dave** from backlog (currently no active work)\n2. **Assign 1 issue to Bob** once TEAM-462 unblocked (has capacity)\n\n**Review Needed**:\n1. **TEAM-464**: Scope changed mid-cycle, consider moving to next cycle\n2. **TEAM-465**: Waiting on review for 2 days, expedite review process\n\n---\n\n## üìà Velocity Projection\n\n**Current Velocity**: 2.25 issues/day (18 done in 8 days)\n**Remaining Work**: 22 issues\n**Days Left**: 3\n\n**Projection**: At current pace, will complete ~7 more issues = 63% total completion\n\n**To Hit 80%**: Need to complete 14 more issues in 3 days (4.7/day) - requires addressing blockers immediately\n```\n\n### Step 5: Save Report\n\nWrite report to `thoughts/shared/reports/cycles/YYYY-MM-DD-cycle-N-status.md`\n\n```bash\nREPORT_DIR=\"thoughts/shared/reports/cycles\"\nmkdir -p \"$REPORT_DIR\"\n\nREPORT_FILE=\"$REPORT_DIR/$(date +%Y-%m-%d)-cycle-${cycle_number}-status.md\"\n\n# Write formatted report to file\ncat > \"$REPORT_FILE\" << EOF\n# Cycle Status Report - ${cycle_name}\n\n**Generated**: $(date +\"%Y-%m-%d %H:%M\")\n**Cycle**: ${cycle_number} (${cycle_starts} ‚Üí ${cycle_ends})\n\n[... formatted report content ...]\nEOF\n\necho \"‚úÖ Report saved: $REPORT_FILE\"\n\n# Update workflow context\nif [[ -f \"${SCRIPT_DIR}/workflow-context.sh\" ]]; then\n  \"${SCRIPT_DIR}/workflow-context.sh\" add reports \"$REPORT_FILE\" \"${TICKET_ID:-null}\"\nfi\n```\n\n### Step 6: Display Summary\n\nPresent concise summary to user with health assessment:\n\n```\nüü° Cycle Health: Sprint 2025-W04 - At Risk\n\nTakeaway: Cycle is 45% complete with 3 days remaining. We're tracking\nslightly behind (projected 63% completion). Main risks: 2 blocked issues\nand Dave has no assigned work.\n\nProgress: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë 45% (18/40 issues)\nDays Remaining: 3 of 10\n\nPriority Actions:\n  1. Escalate TEAM-461 blocker (external dependency, 6 days)\n  2. Pair Bob with senior dev on TEAM-462 (dependency conflict)\n  3. Assign 2 backlog issues to Dave (no active work)\n\nStatus:\n  ‚úÖ Done: 18  |  üîÑ In Progress: 12  |  üìã Todo: 10\n  üö® Blocked: 2  |  ‚ö†Ô∏è  At Risk: 3 (>5 days)\n\nFull health report: thoughts/shared/reports/cycles/2025-01-27-cycle-4-health.md\n```\n\n## Success Criteria\n\n### Automated Verification:\n- [ ] Prerequisites script passes: `./scripts/check-prerequisites.sh`\n- [ ] Command executes without errors\n- [ ] Report file created in expected location\n- [ ] JSON parsing succeeds for all linearis output\n- [ ] TodoWrite tracking works correctly\n- [ ] Health assessment is data-backed\n\n### Manual Verification:\n- [ ] Health score accurately reflects cycle state\n- [ ] Takeaway is clear and actionable\n- [ ] Capacity analysis identifies available team members\n- [ ] Recommendations are specific and prioritized\n- [ ] Risk identification is meaningful\n- [ ] Report guides PM to take specific action"
              },
              {
                "name": "/analyze_milestone",
                "description": "Analyze project milestone health with actionable insights, target date assessment, risk analysis, and specific recommendations",
                "path": "plugins/pm/commands/analyze_milestone.md",
                "frontmatter": {
                  "description": "Analyze project milestone health with actionable insights, target date assessment, risk analysis, and specific recommendations",
                  "category": "pm",
                  "tools": "Task, Read, Write, TodoWrite",
                  "model": "inherit",
                  "version": "1.0.0"
                },
                "content": "# Analyze Milestone Command\n\nGenerates a comprehensive **health report** for a project milestone.\n\n**Reports Include**:\n- üü¢üü°üî¥ Health assessment with target date feasibility\n- üìä Progress metrics toward target date\n- üéØ Actionable takeaways (what needs attention NOW)\n- ‚ö†Ô∏è Risk identification (behind schedule, blocked, at-risk)\n- üí° Specific recommendations (adjust timeline, reduce scope, etc.)\n\n**Philosophy**: Provide insights and recommendations for milestone planning, not just data dumps.\n\n## Prerequisites Check\n\n```bash\n# 1. Validate thoughts system (REQUIRED)\nif [[ -f \"scripts/validate-thoughts-setup.sh\" ]]; then\n  ./scripts/validate-thoughts-setup.sh || exit 1\nelse\n  # Inline validation if script not found\n  if [[ ! -d \"thoughts/shared\" ]]; then\n    echo \"‚ùå ERROR: Thoughts system not configured\"\n    echo \"Run: ./scripts/humanlayer/init-project.sh . {project-name}\"\n    exit 1\n  fi\nfi\n\n# 2. Determine script directory with fallback\nif [[ -n \"${CLAUDE_PLUGIN_ROOT}\" ]]; then\n  SCRIPT_DIR=\"${CLAUDE_PLUGIN_ROOT}/scripts\"\nelse\n  # Fallback: resolve relative to this command file\n  SCRIPT_DIR=\"$(cd \"$(dirname \"${BASH_SOURCE[0]}\")/..\" && pwd)/scripts\"\nfi\n\n# 3. Check PM plugin prerequisites\nif [[ -f \"${SCRIPT_DIR}/check-prerequisites.sh\" ]]; then\n  \"${SCRIPT_DIR}/check-prerequisites.sh\" || exit 1\nelse\n  echo \"‚ö†Ô∏è Prerequisites check skipped (script not found at: ${SCRIPT_DIR})\"\nfi\n```\n\n## Process\n\n### Step 1: Gather Configuration and Milestone Identifier\n\n**Option A: User provides milestone name**\n```bash\nMILESTONE_NAME=\"Q1 Launch\"\nPROJECT_NAME=\"Mobile App\"\n```\n\n**Option B: Interactive prompt**\n```\nWhich milestone would you like to analyze?\n- Milestone name: [user input]\n- Project name (optional, helps scope lookup): [user input]\n```\n\n### Step 2: Spawn Research Agent\n\nUse Task tool with `catalyst-dev:linear-research` agent:\n\n```\nPrompt: \"Get milestone '${MILESTONE_NAME}' details for project '${PROJECT_NAME}' with all issues (limit 100)\"\nModel: haiku (fast data gathering)\n```\n\nIf milestone not found or ambiguous, report error and ask user to clarify.\n\n### Step 3: Spawn Analysis Agent\n\nUse Task tool with `milestone-analyzer` agent:\n\n**Input**:\n- Milestone data JSON from research task\n- Current date: $(date +%Y-%m-%d)\n- Project configuration (if available)\n\n**Agent returns**:\nStructured markdown with:\n- Health score and target date feasibility\n- Progress tracking (actual vs expected)\n- Risk factors (target date, blockers, at-risk)\n- Issue distribution\n- Specific recommendations\n\n### Step 4: Format Report\n\nFormat the analyzer output into final report:\n\n```markdown\n# Milestone Health Report: [Milestone Name]\n\n**Project**: [Project Name]\n**Target Date**: [YYYY-MM-DD] ([X] days remaining)\n**Generated**: [YYYY-MM-DD HH:MM]\n\n---\n\n## üü¢/üü°/üî¥ Health Assessment\n\n**Takeaway**: [One-sentence summary with target date assessment]\n\n**Current State**:\n- Progress: X% complete (Y/Z issues done)\n- Target: [YYYY-MM-DD] ([N] days remaining)\n- Projected completion: [YYYY-MM-DD] (based on current velocity)\n- Risk level: [On track / Behind by N days / Critical]\n\n---\n\n## üìä Progress Tracking\n\n[Progress bars, velocity, time remaining]\n\n---\n\n## ‚ö†Ô∏è Risks & Blockers\n\n[Target date risks, blockers, at-risk issues]\n\n---\n\n## üí° Recommendations\n\n[Priority-ordered actions]\n\n---\n\n**Next Review**: [Suggested date based on target date proximity]\n```\n\n### Step 5: Save Report\n\n```bash\nREPORT_DIR=\"thoughts/shared/reports/milestones\"\nmkdir -p \"$REPORT_DIR\"\n\n# Sanitize milestone name for filename\nMILESTONE_SLUG=$(echo \"$MILESTONE_NAME\" | tr '[:upper:]' '[:lower:]' | tr ' ' '-')\nREPORT_FILE=\"$REPORT_DIR/$(date +%Y-%m-%d)-${MILESTONE_SLUG}.md\"\n\n# Write formatted report\n# ...\n\necho \"‚úÖ Report saved: $REPORT_FILE\"\n\n# Update workflow context\nif [[ -f \"${SCRIPT_DIR}/workflow-context.sh\" ]]; then\n  \"${SCRIPT_DIR}/workflow-context.sh\" add reports \"$REPORT_FILE\" \"${TICKET_ID:-null}\"\nfi\n```\n\n### Step 6: Display Summary\n\n```\nüéØ Milestone Health: [Milestone Name] - [üü¢/üü°/üî¥]\n\nTarget Date: [YYYY-MM-DD] ([X] days remaining)\nProgress: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë [X]% ([Y]/[Z] issues)\nStatus: [On track / Behind by N days]\n\nPriority Actions:\n  1. [Action 1]\n  2. [Action 2]\n  3. [Action 3]\n\nFull report: thoughts/shared/reports/milestones/YYYY-MM-DD-milestone.md\n```\n\n## Success Criteria\n\n### Automated Verification:\n- [ ] Research agent fetches milestone data successfully\n- [ ] Analyzer agent produces structured output\n- [ ] Report file created in expected location\n- [ ] No errors when milestone exists\n\n### Manual Verification:\n- [ ] Health score accurately reflects milestone state\n- [ ] Target date feasibility is realistic\n- [ ] Recommendations are specific and actionable\n- [ ] Report guides PM to adjust timeline or scope if needed\n- [ ] Works with different projects and milestone names"
              },
              {
                "name": "/context_daily",
                "description": "Generate daily context engineering adoption dashboard",
                "path": "plugins/pm/commands/context_daily.md",
                "frontmatter": {
                  "description": "Generate daily context engineering adoption dashboard",
                  "category": "reporting",
                  "tools": "Read, Write, Task, TodoWrite, Bash",
                  "model": "inherit",
                  "version": "1.0.0"
                },
                "content": "# Generate Context Engineering Daily Dashboard\n\nYou are tasked with generating a daily dashboard that tracks context engineering adoption across the team by cross-referencing code repository activity with thoughts repository activity.\n\n## Purpose\n\nThis command identifies developers who have code activity but NO thoughts activity (not using context engineering) and provides actionable insights for improving adoption.\n\n## Prerequisites\n\nBefore executing, verify required tools are installed:\n\n```bash\nif [[ -f \"/Users/ryan/.claude/plugins/marketplaces/catalyst/plugins/dev/scripts/check-prerequisites.sh\" ]]; then\n  \"/Users/ryan/.claude/plugins/marketplaces/catalyst/plugins/dev/scripts/check-prerequisites.sh\" || exit 1\nfi\n```\n\n## Configuration\n\nRead project configuration from `.claude/config.json`:\n\n```bash\nCONFIG_FILE=\".claude/config.json\"\n\n# Required configuration - detect from HumanLayer or fallback to config\nif command -v humanlayer &> /dev/null; then\n  THOUGHTS_REPO=$(humanlayer thoughts status --format json 2>/dev/null | jq -r '.repository_path // empty')\nfi\nif [ -z \"$THOUGHTS_REPO\" ]; then\n  THOUGHTS_REPO=$(jq -r '.thoughts.repo // \"~/thoughts\"' \"$CONFIG_FILE\")\nfi\nPROJECT_KEY=$(jq -r '.projectKey // \"unknown\"' \"$CONFIG_FILE\")\n\n# Code repositories to analyze (comma-separated)\nCODE_REPOS=$(jq -r '.contextEngineering.codeRepos // [] | join(\",\")' \"$CONFIG_FILE\")\n\n# If no code repos configured, try to detect from git remote\nif [[ -z \"$CODE_REPOS\" || \"$CODE_REPOS\" == \"\" ]]; then\n  REMOTE_URL=$(git config --get remote.origin.url 2>/dev/null || echo \"\")\n  if [[ -n \"$REMOTE_URL\" ]]; then\n    # Extract org/repo from GitHub URL\n    CODE_REPOS=$(echo \"$REMOTE_URL\" | sed -E 's#.*github\\.com[:/]([^/]+/[^/]+)(\\.git)?#\\1#')\n    echo \"‚ö†Ô∏è  No code repos configured in .claude/config.json\"\n    echo \"üìç Auto-detected from git remote: $CODE_REPOS\"\n  else\n    echo \"‚ùå ERROR: No code repos configured and could not detect from git remote\"\n    echo \"Add to .claude/config.json:\"\n    echo '  \"contextEngineering\": {'\n    echo '    \"codeRepos\": [\"org/repo-1\", \"org/repo-2\"]'\n    echo '  }'\n    exit 1\n  fi\nfi\n```\n\n## Process Steps\n\n### Step 1: Initialize Task Tracking\n\n```\nUse TodoWrite to create task list:\n1. Collect code repository metrics (7-day and 28-day windows)\n2. Collect thoughts repository metrics (7-day and 28-day windows)\n3. Cross-reference and synthesize adoption insights\n4. Generate context engineering dashboard\n5. Save report to thoughts repository root\n```\n\n### Step 2: Spawn Parallel Data Collection Agents\n\n**CRITICAL**: Spawn BOTH agents in the SAME response for maximum efficiency.\n\n**Agent 1: github-metrics** (Haiku model for speed):\n```\nTask prompt:\nCollect GitHub metrics for the following repositories: {CODE_REPOS}\n\nAnalysis windows:\n- 7-day window (last 7 calendar days)\n- 28-day window (last 28 calendar days)\n\nFor each developer, collect:\n1. Number of PRs created/merged\n2. Number of commits authored\n3. Last activity date\n\nUse GitHub API or gh CLI:\ngh api \"/repos/{org}/{repo}/commits?since={7-days-ago}\" --jq '.[].author.login' | sort -u\n\nReturn data in this format:\n```json\n{\n  \"period\": \"7-day\",\n  \"developers\": [\n    {\n      \"name\": \"Alice\",\n      \"prs\": 4,\n      \"commits\": 12,\n      \"lastActivity\": \"2025-01-17\"\n    }\n  ]\n}\n```\n\nIMPORTANT:\n- Use Git author metadata ONLY (%an, author.login)\n- Filter out \"Claude\" from all lists\n- Error if \"Claude\" appears in results\n```\n\n**Agent 2: thoughts-metrics** (Haiku model for speed):\n```\nTask prompt:\nCollect thoughts repository metrics from: {THOUGHTS_REPO}\n\nAnalysis windows:\n- Yesterday (last 24 hours)\n- 7-day window (last 7 calendar days)\n- 28-day window (last 28 calendar days)\n\nFor each developer, collect:\n1. Number of files created (by type: research, plans, handoffs, prs)\n2. Number of commits\n3. Last activity date\n\nUse git log in thoughts repository:\ncd {THOUGHTS_REPO}\ngit log --since=\"7 days ago\" --author=\"Alice\" --name-only --diff-filter=A \\\n  | grep \"^shared/\" | wc -l\n\nClassify files by directory:\n- shared/research/ ‚Üí Research\n- shared/plans/ ‚Üí Plans\n- shared/handoffs/ ‚Üí Handoffs\n- shared/prs/ ‚Üí PR Descriptions\n\nReturn data in this format:\n```json\n{\n  \"period\": \"7-day\",\n  \"developers\": [\n    {\n      \"name\": \"Alice\",\n      \"files\": 22,\n      \"commits\": 24,\n      \"filesByType\": {\n        \"research\": 18,\n        \"plans\": 3,\n        \"handoffs\": 1,\n        \"prs\": 0\n      },\n      \"lastActivity\": \"2025-01-17\"\n    }\n  ]\n}\n```\n\nIMPORTANT:\n- Use Git author metadata ONLY (%an)\n- Filter out \"Claude\" from all lists\n- Error if \"Claude\" appears in results\n- Use --diff-filter=A to count only files CREATED (not modified)\n```\n\n**Tool use**:\n```\nTask(subagent_type=catalyst-pm:github-metrics, description=\"Collect code repo metrics\", prompt=[github-metrics prompt], model=haiku)\nTask(subagent_type=catalyst-pm:thoughts-metrics, description=\"Collect thoughts repo metrics\", prompt=[thoughts-metrics prompt], model=haiku)\n```\n\n### Step 3: Wait for Both Agents to Complete\n\n**CRITICAL**: Do NOT proceed until BOTH agents return their results.\n\n- Mark task 1 as completed when github-metrics returns\n- Mark task 2 as completed when thoughts-metrics returns\n- Verify both data sets are valid JSON\n- Check for errors or warnings from agents\n\n### Step 4: Spawn Context Analyzer Agent\n\n**Agent 3: context-analyzer** (Sonnet model for synthesis):\n\n```\nTask prompt:\nAnalyze context engineering adoption by cross-referencing code and thoughts repository activity.\n\nYou will receive two data sets:\n\n**Code Repository Metrics**:\n[Paste github-metrics agent output here]\n\n**Thoughts Repository Metrics**:\n[Paste thoughts-metrics agent output here]\n\nGenerate a comprehensive context engineering dashboard following the template at:\nplugins/pm/templates/reports/CONTEXT_ENGINEERING_DAILY.md\n\nCRITICAL REQUIREMENTS:\n1. Identify developers with code activity but NO thoughts activity (not using context engineering)\n2. Calculate individual adoption scores (Excellent, Good, Growing, Light, Minimal, Not using)\n3. Analyze file type breakdown (Research, Plans, Handoffs, PRs)\n4. Calculate trends over 28-day period with week-over-week growth\n5. Generate prioritized action items (P1: Immediate, P2: Celebrate, P3: Growth)\n6. Ensure NO \"Claude\" attribution anywhere in the report\n\nReturn the complete dashboard report in Markdown format.\n```\n\n**Tool use**:\n```\nTask(subagent_type=catalyst-pm:context-analyzer, description=\"Synthesize adoption dashboard\", prompt=[context-analyzer prompt], model=inherit)\n```\n\n**Wait for completion** and mark task 3 as completed.\n\n### Step 5: Save Report to Thoughts Repository Root\n\n```bash\n# Get thoughts repo path - detect from HumanLayer or fallback to config\nif command -v humanlayer &> /dev/null; then\n  THOUGHTS_REPO=$(humanlayer thoughts status --format json 2>/dev/null | jq -r '.repository_path // empty')\nfi\nif [ -z \"$THOUGHTS_REPO\" ]; then\n  THOUGHTS_REPO=$(jq -r '.thoughts.repo // \"~/thoughts\"' .claude/config.json)\n  THOUGHTS_REPO=\"${THOUGHTS_REPO/#\\~/$HOME}\"  # Expand ~ to home directory\nfi\n\n# Create report filename with timestamp\nTIMESTAMP=$(TZ=\"America/Chicago\" date \"+%Y-%m-%d_%H-%M-%S\")\nREPORT_FILE=\"${THOUGHTS_REPO}/context-engineering-daily.md\"\n\n# Save the report (agent output will be in memory)\n# Use Write tool to save to $REPORT_FILE\n\n# Verify file was created\nif [[ -f \"$REPORT_FILE\" ]]; then\n  echo \"‚úÖ Report saved: $REPORT_FILE\"\n\n  # Create symlink to latest report\n  ln -sf \"context-engineering-daily.md\" \"${THOUGHTS_REPO}/context-engineering-latest.md\"\n\n  # Optional: Commit to thoughts repo if it's a git repo\n  cd \"$THOUGHTS_REPO\"\n  if [[ -d .git ]]; then\n    git add context-engineering-daily.md context-engineering-latest.md\n    git commit -m \"docs: update context engineering dashboard - $TIMESTAMP\" --no-verify\n    echo \"üìù Committed to thoughts repository\"\n  fi\nelse\n  echo \"‚ùå ERROR: Failed to save report to $REPORT_FILE\"\n  exit 1\nfi\n```\n\nMark task 5 as completed.\n\n### Step 6: Present Summary to User\n\nShow the user:\n\n1. **Report location**: Full path to saved report\n2. **Key findings**:\n   - Number of developers NOT using context engineering\n   - Overall adoption rate (X/Y developers active)\n   - Top 3 action items from report\n3. **Quick stats**: Yesterday, 7-day avg, 28-day avg\n4. **Next steps**: How to view full report and suggested actions\n\n## Example Interaction Flow\n\n```\nUser: /catalyst-pm:context-daily\nAssistant: [Runs prerequisites check]\n\n[Creates task list with TodoWrite]\n\n[Spawns github-metrics and thoughts-metrics agents in parallel]\n\nWaiting for both agents to complete...\n\n[Agents return with data]\n\n[Spawns context-analyzer agent with both data sets]\n\nAnalyzing context engineering adoption...\n\n[context-analyzer returns dashboard report]\n\n[Saves report to thoughts repo root]\n\n‚úÖ Context Engineering Dashboard generated\\!\n\n**Report location**: ~/thoughts/repos/myproject/context-engineering-daily.md\n\n**Key Findings**:\n- üö® **2/7 developers** NOT using context engineering (Frank, Grace)\n- üìä **71% adoption rate** (5/7 developers active in last 7 days)\n- ‚Üë **+51% growth** month-over-month\n\n**Top 3 Action Items**:\n1. **P1: Onboard Frank & Grace** - No thoughts activity despite code commits\n2. **P2: Celebrate Alice's consistency** - 22 research docs in 7 days\n3. **P3: Support Emily's growth** - Building habit, needs guidance\n\n**Quick Stats**:\n- Yesterday: 12 files, 18 commits\n- 7-day avg: 8.6 files/day, 15.3 commits/day\n- 28-day avg: 6.2 files/day, 12.1 commits/day\n\n**Next Steps**:\n- View full report: `cat ~/thoughts/repos/myproject/context-engineering-daily.md`\n- Schedule onboarding sessions with Frank and Grace\n- Share adoption wins in team meeting\n```\n\n## Important Notes\n\n### Configuration Required\n\nThe command requires configuration in `.claude/config.json`:\n\n```json\n{\n  \"projectKey\": \"myproject\",\n  \"thoughts\": {\n    \"repo\": \"~/thoughts/repos/myproject\"\n  },\n  \"contextEngineering\": {\n    \"codeRepos\": [\n      \"org/repo-1\",\n      \"org/repo-2\"\n    ]\n  }\n}\n```\n\n### Data Collection Windows\n\n- **Yesterday**: Last 24 hours (since yesterday 9 AM CST)\n- **7-day**: Last 7 calendar days\n- **28-day**: Last 28 calendar days (4 weeks)\n\n### Attribution Rules\n\n**CRITICAL**: All agents must use Git author metadata only:\n- **Code repos**: `git log --format=\\\"%an\\\"` or `gh api ... author.login`\n- **Thoughts repo**: `git log --format=\\\"%an\\\"`\n- **Filter**: Remove any \"Claude\" from all author lists\n- **Validate**: Error if \"Claude\" appears in results\n\n### Report Location\n\n**Dashboard saves to ROOT of thoughts repository**:\n- Path: `{THOUGHTS_REPO}/context-engineering-daily.md`\n- Latest symlink: `{THOUGHTS_REPO}/context-engineering-latest.md`\n- Rationale: Report is ABOUT the thoughts repo, not project docs\n\n### Parallel Agent Execution\n\n**CRITICAL**: github-metrics and thoughts-metrics agents MUST be spawned in the SAME response for maximum efficiency. Do NOT spawn them sequentially.\n\n### Error Handling\n\nIf agents fail:\n1. **github-metrics fails**: Cannot identify \"Not Using\" developers - abort\n2. **thoughts-metrics fails**: Dashboard will be empty - abort\n3. **context-analyzer fails**: Check data format, retry once\n4. **Save fails**: Check thoughts repo path, permissions\n\n## Success Criteria\n\n‚úÖ Both data collection agents return valid data\n‚úÖ Context analyzer identifies developers NOT using context engineering\n‚úÖ Report follows CONTEXT_ENGINEERING_DAILY.md template structure\n‚úÖ No \"Claude\" attribution anywhere in report\n‚úÖ Report saved to thoughts repo root\n‚úÖ User sees actionable summary with top 3 action items\n\n---\n\n*This command is part of the Catalyst PM Plugin for tracking context engineering adoption.*"
              },
              {
                "name": "/groom_backlog",
                "description": "Groom Linear backlog to identify orphaned issues, incorrect project assignments, and health issues",
                "path": "plugins/pm/commands/groom_backlog.md",
                "frontmatter": {
                  "description": "Groom Linear backlog to identify orphaned issues, incorrect project assignments, and health issues",
                  "category": "pm",
                  "tools": "Task, Read, Write",
                  "model": "inherit",
                  "version": "1.0.0"
                },
                "content": "# Groom Backlog Command\n\nComprehensive backlog health analysis that identifies:\n- Issues without projects (orphaned)\n- Issues in wrong projects (misclassified)\n- Issues without estimates\n- Stale issues (no activity >30 days)\n- Duplicate issues (similar titles)\n\n## Prerequisites Check\n\n```bash\n# 1. Validate thoughts system (REQUIRED)\nif [[ -f \"scripts/validate-thoughts-setup.sh\" ]]; then\n  ./scripts/validate-thoughts-setup.sh || exit 1\nelse\n  # Inline validation if script not found\n  if [[ ! -d \"thoughts/shared\" ]]; then\n    echo \"‚ùå ERROR: Thoughts system not configured\"\n    echo \"Run: ./scripts/humanlayer/init-project.sh . {project-name}\"\n    exit 1\n  fi\nfi\n\n# 2. Determine script directory with fallback\nif [[ -n \"${CLAUDE_PLUGIN_ROOT}\" ]]; then\n  SCRIPT_DIR=\"${CLAUDE_PLUGIN_ROOT}/scripts\"\nelse\n  # Fallback: resolve relative to this command file\n  SCRIPT_DIR=\"$(cd \"$(dirname \"${BASH_SOURCE[0]}\")/..\" && pwd)/scripts\"\nfi\n\n# 3. Check PM plugin prerequisites\nif [[ -f \"${SCRIPT_DIR}/check-prerequisites.sh\" ]]; then\n  \"${SCRIPT_DIR}/check-prerequisites.sh\" || exit 1\nelse\n  echo \"‚ö†Ô∏è Prerequisites check skipped (script not found at: ${SCRIPT_DIR})\"\nfi\n```\n\n## Process\n\n### Step 1: Spawn Research Agent\n\n```bash\n# Determine script directory with fallback\nif [[ -n \"${CLAUDE_PLUGIN_ROOT}\" ]]; then\n  SCRIPT_DIR=\"${CLAUDE_PLUGIN_ROOT}/scripts\"\nelse\n  # Fallback: resolve relative to this command file\n  SCRIPT_DIR=\"$(cd \"$(dirname \"${BASH_SOURCE[0]}\")/..\" && pwd)/scripts\"\nfi\n\nsource \"${SCRIPT_DIR}/pm-utils.sh\"\nTEAM_KEY=$(get_team_key)\n```\n\nUse Task tool with `catalyst-dev:linear-research` agent:\n\n```\nPrompt: \"Get all backlog issues for team ${TEAM_KEY} including issues with no cycle assignment\"\nModel: haiku\n```\n\n### Step 2: Spawn Analysis Agent\n\nUse Task tool with `backlog-analyzer` agent:\n\n**Input**: Backlog issues JSON from research\n\n**Output**: Structured recommendations with:\n- Orphaned issues (no project)\n- Misplaced issues (wrong project)\n- Stale issues (>30 days)\n- Potential duplicates\n- Missing estimates\n\n### Step 3: Generate Grooming Report\n\nCreate markdown report with sections:\n\n**Orphaned Issues** (no project):\n```markdown\n## üè∑Ô∏è Orphaned Issues (No Project Assignment)\n\n### High Priority\n- **TEAM-456**: \"Add OAuth support\"\n  - **Suggested Project**: Auth & Security\n  - **Reasoning**: Mentions authentication, OAuth, security tokens\n  - **Action**: Move to Auth project\n\n[... more issues ...]\n\n### Medium Priority\n[... issues ...]\n```\n\n**Misplaced Issues** (wrong project):\n```markdown\n## üîÑ Misplaced Issues (Wrong Project)\n\n- **TEAM-123**: \"Fix dashboard bug\" (currently in: API)\n  - **Should be in**: Frontend\n  - **Reasoning**: UI bug, no backend changes mentioned\n  - **Action**: Move to Frontend project\n```\n\n**Stale Issues** (>30 days inactive):\n```markdown\n## üóìÔ∏è Stale Issues (No Activity >30 Days)\n\n- **TEAM-789**: \"Investigate caching\" (last updated: 45 days ago)\n  - **Action**: Review and close, or assign to current cycle\n```\n\n**Duplicates** (similar titles):\n```markdown\n## üîÅ Potential Duplicates\n\n- **TEAM-111**: \"User authentication bug\"\n- **TEAM-222**: \"Authentication not working\"\n  - **Similarity**: 85%\n  - **Action**: Review and merge\n```\n\n**Missing Estimates**:\n```markdown\n## üìä Issues Without Estimates\n\n- TEAM-444: \"Implement new feature\"\n- TEAM-555: \"Refactor old code\"\n  - **Action**: Add story point estimates\n```\n\n### Step 4: Interactive Review\n\nPresent recommendations and ask user:\n\n```\nüìã Backlog Grooming Report Generated\n\nSummary:\n  üè∑Ô∏è Orphaned: 12 issues\n  üîÑ Misplaced: 5 issues\n  üóìÔ∏è Stale: 8 issues\n  üîÅ Duplicates: 3 pairs\n  üìä No Estimates: 15 issues\n\nWould you like to:\n1. Review detailed report (opens in editor)\n2. Apply high-confidence recommendations automatically\n3. Generate Linear update commands for manual execution\n4. Skip (report saved for later)\n```\n\n### Step 5: Generate Update Commands\n\nIf user chooses option 3, generate batch update script:\n\n```bash\n#!/usr/bin/env bash\n# Backlog grooming updates - Generated 2025-01-27\n\n# Move TEAM-456 to Auth project\nlinearis issues update TEAM-456 --project \"Auth & Security\"\n\n# Move TEAM-123 to Frontend project\nlinearis issues update TEAM-123 --project \"Frontend\"\n\n# Close stale issue TEAM-789\nlinearis issues update TEAM-789 --state \"Canceled\"\nlinearis comments create TEAM-789 --body \"Closing stale issue (>30 days inactive)\"\n\n# [... more commands ...]\n\necho \"‚úÖ Backlog grooming updates applied\"\n```\n\n```bash\n# Save update script\nUPDATE_SCRIPT=\"thoughts/shared/reports/backlog/$(date +%Y-%m-%d)-grooming-updates.sh\"\nmkdir -p \"$(dirname \"$UPDATE_SCRIPT\")\"\n# [script contents saved here]\nchmod +x \"$UPDATE_SCRIPT\"\n```\n\n### Step 6: Save Report\n\n```bash\nREPORT_DIR=\"thoughts/shared/reports/backlog\"\nmkdir -p \"$REPORT_DIR\"\n\nREPORT_FILE=\"$REPORT_DIR/$(date +%Y-%m-%d)-backlog-grooming.md\"\n\n# Write formatted report to file\ncat > \"$REPORT_FILE\" << EOF\n# Backlog Grooming Report - $(date +%Y-%m-%d)\n\n[... formatted report content ...]\nEOF\n\necho \"‚úÖ Report saved: $REPORT_FILE\"\n\n# Update workflow context\nif [[ -f \"${SCRIPT_DIR}/workflow-context.sh\" ]]; then\n  \"${SCRIPT_DIR}/workflow-context.sh\" add reports \"$REPORT_FILE\" null\nfi\n```\n\n## Success Criteria\n\n### Automated Verification:\n- [ ] All backlog issues fetched successfully\n- [ ] Agent analysis completes without errors\n- [ ] Report generated with all sections\n- [ ] Update script is valid bash syntax\n- [ ] Files saved to correct locations\n\n### Manual Verification:\n- [ ] Orphaned issues correctly identified\n- [ ] Project recommendations make sense\n- [ ] Stale issues are actually inactive\n- [ ] Duplicate detection has few false positives\n- [ ] Report is actionable and clear"
              },
              {
                "name": "/report_daily",
                "description": "Generate daily status report showing yesterday's deliveries, current work, and team members needing assignments",
                "path": "plugins/pm/commands/report_daily.md",
                "frontmatter": {
                  "description": "Generate daily status report showing yesterday's deliveries, current work, and team members needing assignments",
                  "category": "pm",
                  "tools": "Task, Read, Write",
                  "model": "inherit",
                  "version": "1.0.0"
                },
                "content": "# Report Daily Command\n\nLightweight daily standup report for quick team status checks.\n\n**Focus Areas**:\n- ‚úÖ What was delivered yesterday (completed issues/PRs)\n- üîÑ What is the team working on RIGHT NOW (active issues)\n- üë• Who needs work assigned (no open PRs or active issues)\n- ‚ö†Ô∏è Quick blockers/risks (issues blocked or stalled)\n\n**Philosophy**: Fast, focused report for daily standups. Takes <30 seconds to read. No deep analysis - save that for weekly reports.\n\n## Prerequisites Check\n\n```bash\n# 1. Validate thoughts system (REQUIRED)\nif [[ -f \"scripts/validate-thoughts-setup.sh\" ]]; then\n  ./scripts/validate-thoughts-setup.sh || exit 1\nelse\n  # Inline validation if script not found\n  if [[ ! -d \"thoughts/shared\" ]]; then\n    echo \"‚ùå ERROR: Thoughts system not configured\"\n    echo \"Run: ./scripts/humanlayer/init-project.sh . {project-name}\"\n    exit 1\n  fi\nfi\n\n# 2. Determine script directory with fallback\nif [[ -n \"${CLAUDE_PLUGIN_ROOT}\" ]]; then\n  SCRIPT_DIR=\"${CLAUDE_PLUGIN_ROOT}/scripts\"\nelse\n  # Fallback: resolve relative to this command file\n  SCRIPT_DIR=\"$(cd \"$(dirname \"${BASH_SOURCE[0]}\")/..\" && pwd)/scripts\"\nfi\n\n# 3. Check PM plugin prerequisites\nif [[ -f \"${SCRIPT_DIR}/check-prerequisites.sh\" ]]; then\n  \"${SCRIPT_DIR}/check-prerequisites.sh\" || exit 1\nelse\n  echo \"‚ö†Ô∏è Prerequisites check skipped (script not found at: ${SCRIPT_DIR})\"\nfi\n```\n\n## Process\n\n### Step 1: Gather Configuration\n\n```bash\n# Determine script directory with fallback\nif [[ -n \"${CLAUDE_PLUGIN_ROOT}\" ]]; then\n  SCRIPT_DIR=\"${CLAUDE_PLUGIN_ROOT}/scripts\"\nelse\n  # Fallback: resolve relative to this command file\n  SCRIPT_DIR=\"$(cd \"$(dirname \"${BASH_SOURCE[0]}\")/..\" && pwd)/scripts\"\nfi\n\nsource \"${SCRIPT_DIR}/pm-utils.sh\"\n\nTEAM_KEY=$(get_team_key)\nTODAY=$(date +%Y-%m-%d)\nYESTERDAY=$(date -v-1d +%Y-%m-%d)\n```\n\n### Step 2: Spawn Research Tasks (Parallel)\n\nSpawn 4 research agents in parallel:\n\n**Task 1 - Yesterday's Completions**:\n```\nUse Task tool with catalyst-dev:linear-research agent:\nPrompt: \"Get issues completed yesterday for team ${TEAM_KEY} (completed after ${YESTERDAY} and before ${TODAY})\"\nModel: haiku\n```\n\n**Task 2 - Current In Progress**:\n```\nUse Task tool with catalyst-dev:linear-research agent:\nPrompt: \"List all in-progress issues for team ${TEAM_KEY}\"\nModel: haiku\n```\n\n**Task 3 - Blocked Issues**:\n```\nUse Task tool with catalyst-dev:linear-research agent:\nPrompt: \"Get all blocked issues for team ${TEAM_KEY}\"\nModel: haiku\n```\n\n**Task 4 - Team Members**:\n```\nUse Task tool with catalyst-dev:linear-research agent:\nPrompt: \"List all issues by assignee for team ${TEAM_KEY}\"\nModel: haiku\n```\n\n**Wait for all 4 research tasks to complete**\n\n### Step 3: Analyze Results\n\nCombine research results to identify:\n- Team members with no active work\n- Stalled issues (in progress >5 days, no recent updates)\n- Blocker count and duration\n\n### Step 4: Format Daily Report\n\n```markdown\n# Team Daily - [Date]\n\n## ‚úÖ Delivered Yesterday (${YESTERDAY})\n\n**Issues Completed** (N):\n- TEAM-456: OAuth integration (Alice)\n- TEAM-457: Bug fix for login (Bob)\n- TEAM-458: Update docs (Charlie)\n\n**PRs Merged** (N):\n- #123: OAuth integration ‚Üí prod (Alice)\n- #124: Login bug fix ‚Üí prod (Bob)\n\n---\n\n## üîÑ Currently Working On\n\n**Alice**:\n- TEAM-461: Payment processing (in progress 3 days)\n- PR #130: API refactor (in review)\n\n**Bob**:\n- TEAM-462: Database migration (in progress 1 day)\n- TEAM-463: Performance optimization (in progress 2 days)\n\n**Charlie**:\n- TEAM-465: UI redesign (in progress 4 days)\n\n---\n\n## üë• Available for Work\n\n**Dave**: No active issues or PRs\n**Emily**: No active issues or PRs\n\n**Recommendation**: Assign 1-2 backlog issues to Dave and Emily\n\n---\n\n## ‚ö†Ô∏è Blockers & Quick Risks\n\n**Blocked** (1):\n- TEAM-461: Waiting on external API approval (Alice, 3 days)\n\n**Stalled** (1):\n- TEAM-465: No commits in 2 days (Charlie)\n\n---\n\n**Next Actions**:\n1. Check in with Alice on TEAM-461 blocker status\n2. Sync with Charlie on TEAM-465 progress\n3. Assign work to Dave and Emily from backlog\n```\n\n### Step 5: Save Report\n\n```bash\nREPORT_DIR=\"thoughts/shared/reports/daily\"\nmkdir -p \"$REPORT_DIR\"\n\nREPORT_FILE=\"$REPORT_DIR/$(date +%Y-%m-%d)-team-daily.md\"\n\n# Write formatted report to file\ncat > \"$REPORT_FILE\" << EOF\n# Team Daily - $(date +%Y-%m-%d)\n\n[... formatted report content ...]\nEOF\n\necho \"‚úÖ Report saved: $REPORT_FILE\"\n\n# Update workflow context\nif [[ -f \"${SCRIPT_DIR}/workflow-context.sh\" ]]; then\n  \"${SCRIPT_DIR}/workflow-context.sh\" add reports \"$REPORT_FILE\" null\nfi\n```\n\n### Step 6: Display Summary\n\n```\nüìÖ Team Daily - 2025-01-27\n\n‚úÖ Delivered yesterday: 3 issues, 2 PRs merged\nüîÑ In progress: 5 issues, 3 PRs open\nüë• Need work: Dave, Emily (2 team members)\n‚ö†Ô∏è  Blockers: 1 issue (TEAM-461)\n\nQuick Actions:\n  ‚Ä¢ Follow up on TEAM-461 blocker (Alice)\n  ‚Ä¢ Assign backlog work to Dave and Emily\n  ‚Ä¢ Check TEAM-465 status with Charlie\n\nFull report: thoughts/shared/reports/daily/2025-01-27-team-daily.md\n```\n\n## Success Criteria\n\n### Automated Verification:\n- [ ] Data fetched from Linear and GitHub successfully\n- [ ] Team member workload calculated correctly\n- [ ] Report generated in under 10 seconds\n- [ ] File saved to expected location\n\n### Manual Verification:\n- [ ] Yesterday's completions are accurate\n- [ ] Current work assignments match reality\n- [ ] Team members needing work are correctly identified\n- [ ] Report is scannable in <30 seconds\n- [ ] Actionable next steps are clear"
              },
              {
                "name": "/sync_prs",
                "description": "Sync GitHub PRs with Linear issues and identify correlation gaps",
                "path": "plugins/pm/commands/sync_prs.md",
                "frontmatter": {
                  "description": "Sync GitHub PRs with Linear issues and identify correlation gaps",
                  "category": "pm",
                  "tools": "Task, Read, Write",
                  "model": "inherit",
                  "version": "1.0.0"
                },
                "content": "# Sync PRs Command\n\nAnalyzes the relationship between GitHub pull requests and Linear issues to identify:\n- PRs without linked Linear issues\n- Linear issues without associated PRs\n- Merged PRs with open Linear issues (candidates for closure)\n- Open PRs for completed Linear issues (stale PRs)\n\n## Prerequisites Check\n\n```bash\n# 1. Validate thoughts system (REQUIRED)\nif [[ -f \"scripts/validate-thoughts-setup.sh\" ]]; then\n  ./scripts/validate-thoughts-setup.sh || exit 1\nelse\n  # Inline validation if script not found\n  if [[ ! -d \"thoughts/shared\" ]]; then\n    echo \"‚ùå ERROR: Thoughts system not configured\"\n    echo \"Run: ./scripts/humanlayer/init-project.sh . {project-name}\"\n    exit 1\n  fi\nfi\n\n# 2. Determine script directory with fallback\nif [[ -n \"${CLAUDE_PLUGIN_ROOT}\" ]]; then\n  SCRIPT_DIR=\"${CLAUDE_PLUGIN_ROOT}/scripts\"\nelse\n  # Fallback: resolve relative to this command file\n  SCRIPT_DIR=\"$(cd \"$(dirname \"${BASH_SOURCE[0]}\")/..\" && pwd)/scripts\"\nfi\n\n# 3. Check PM plugin prerequisites\nif [[ -f \"${SCRIPT_DIR}/check-prerequisites.sh\" ]]; then\n  \"${SCRIPT_DIR}/check-prerequisites.sh\" || exit 1\nelse\n  echo \"‚ö†Ô∏è Prerequisites check skipped (script not found at: ${SCRIPT_DIR})\"\nfi\n```\n\n## Process\n\n### Step 1: Spawn Research Tasks (Parallel)\n\n```bash\n# Determine script directory with fallback\nif [[ -n \"${CLAUDE_PLUGIN_ROOT}\" ]]; then\n  SCRIPT_DIR=\"${CLAUDE_PLUGIN_ROOT}/scripts\"\nelse\n  # Fallback: resolve relative to this command file\n  SCRIPT_DIR=\"$(cd \"$(dirname \"${BASH_SOURCE[0]}\")/..\" && pwd)/scripts\"\nfi\n\nsource \"${SCRIPT_DIR}/pm-utils.sh\"\nTEAM_KEY=$(get_team_key)\n```\n\n**Task 1 - Get GitHub PRs**:\nUse `catalyst-dev:github-research` agent (if exists) or inline `gh` commands:\n```\nGet open and recently merged PRs (last 7 days)\n```\n\n**Task 2 - Get Linear Issues**:\nUse Task tool with `catalyst-dev:linear-research` agent:\n```\nPrompt: \"Get all in-review and in-progress issues for team ${TEAM_KEY}\"\nModel: haiku\n```\n\n**Wait for both tasks to complete**\n\n### Step 2: Spawn Analysis Agent\n\nUse Task tool with `github-linear-analyzer` agent:\n\n**Input**:\n- GitHub PRs from Task 1\n- Linear issues from Task 2\n\n**Output**:\n- Linked PRs (healthy)\n- Orphaned PRs (no Linear issue)\n- Orphaned issues (no PR)\n- Ready to close (PR merged, issue open)\n- Stale PRs (>14 days)\n\n### Step 3: Generate Sync Report\n\n```markdown\n# PR-Linear Sync Report\n\n**Generated**: 2025-01-27\n**Repository**: user/repo\n**Linear Team**: TEAM\n\n## üìä Summary\n\n- Open PRs: 12 (8 linked, 4 orphaned)\n- Merged PRs (7d): 15 (13 linked, 2 orphaned)\n- Linear issues in review: 10 (8 with PRs, 2 without)\n\n## üîó Linked PRs (Healthy)\n\n| PR | Linear Issue | Status | Author |\n|----|--------------|--------|--------|\n| #123 | TEAM-456 | Open | Alice |\n| #124 | TEAM-457 | Merged | Bob |\n\n## ‚ö†Ô∏è Orphaned PRs (No Linear Issue)\n\n| PR | Title | Branch | Author | Action |\n|----|-------|--------|--------|--------|\n| #125 | \"Fix bug\" | fix-bug | Alice | Create Linear issue or link existing |\n| #126 | \"Update docs\" | docs-update | Bob | Create Linear issue or link existing |\n\n**Recommended Actions**:\n```bash\n# Create Linear issue for PR #125\nlinearis issues create \\\n  --team TEAM \\\n  --title \"Fix bug (from PR #125)\" \\\n  --description \"Imported from PR: https://github.com/user/repo/pull/125\"\n\n# Or manually link in Linear UI\n```\n\n## üè∑Ô∏è Orphaned Issues (No PR)\n\n| Issue | Title | Status | Assignee | Action |\n|-------|-------|--------|----------|--------|\n| TEAM-789 | \"Implement feature\" | In Progress | Alice | Create PR or update status |\n| TEAM-790 | \"Refactor code\" | In Review | Bob | PR might exist with different branch name |\n\n## ‚úÖ Ready to Close (PR merged, issue open)\n\n| Issue | PR | Merged | Action |\n|-------|----|--------|--------|\n| TEAM-456 | #123 | 2025-01-25 | Close issue |\n| TEAM-457 | #124 | 2025-01-26 | Close issue |\n\n**Auto-close commands**:\n```bash\n# Update state\nlinearis issues update TEAM-456 --state \"Done\"\n# Add comment\nlinearis comments create TEAM-456 --body \"PR #123 merged: https://github.com/user/repo/pull/123\"\n\n# Update state\nlinearis issues update TEAM-457 --state \"Done\"\n# Add comment\nlinearis comments create TEAM-457 --body \"PR #124 merged: https://github.com/user/repo/pull/124\"\n```\n\n## üïê Stale PRs (Open >14 days)\n\n| PR | Issue | Days Open | Author | Action |\n|----|-------|-----------|--------|--------|\n| #120 | TEAM-450 | 18 days | Alice | Review and merge or close |\n```\n\n### Step 4: Save Report\n\n```bash\nREPORT_DIR=\"thoughts/shared/reports/pr-sync\"\nmkdir -p \"$REPORT_DIR\"\n\nREPORT_FILE=\"$REPORT_DIR/$(date +%Y-%m-%d)-pr-sync.md\"\n\n# Write formatted report to file\ncat > \"$REPORT_FILE\" << EOF\n# PR-Linear Sync Report - $(date +%Y-%m-%d)\n\n[... formatted report content ...]\nEOF\n\necho \"‚úÖ Report saved: $REPORT_FILE\"\n\n# Update workflow context\nif [[ -f \"${SCRIPT_DIR}/workflow-context.sh\" ]]; then\n  \"${SCRIPT_DIR}/workflow-context.sh\" add reports \"$REPORT_FILE\" null\nfi\n```\n\n### Step 5: Display Summary\n\n```\nüîó PR-Linear Sync Report\n\nHealth Score: 75/100\n  ‚úÖ 8 properly linked PRs\n  ‚ö†Ô∏è 4 orphaned PRs need Linear issues\n  ‚ö†Ô∏è 2 orphaned issues need PRs\n  ‚úÖ 2 ready to close\n\nActions available:\n  1. Auto-close merged issues (generates commands)\n  2. Create Linear issues for orphaned PRs\n  3. View full report\n\nFull report: thoughts/shared/reports/pr-sync/2025-01-27-pr-sync.md\n```\n\n## Success Criteria\n\n### Automated Verification:\n- [ ] GitHub PR data fetched successfully\n- [ ] Linear issue data fetched successfully\n- [ ] PR-ticket correlation logic executes\n- [ ] Report generated with all sections\n- [ ] Auto-close commands are valid\n\n### Manual Verification:\n- [ ] PR-issue matches are accurate\n- [ ] Orphaned detection has minimal false positives\n- [ ] Branch name extraction works correctly\n- [ ] Recommendations are actionable\n- [ ] Report provides clear next steps"
              }
            ],
            "skills": []
          },
          {
            "name": "catalyst-analytics",
            "description": "Product analytics with PostHog MCP integration. Enable when analyzing user behavior, conversion funnels, and product metrics. ~40k context when enabled.",
            "source": "./plugins/analytics",
            "category": "analytics",
            "version": "1.0.1",
            "author": {
              "name": "Coalesce Labs",
              "email": "hello@coalesce.dev"
            },
            "install_commands": [
              "/plugin marketplace add coalesce-labs/catalyst",
              "/plugin install catalyst-analytics@catalyst"
            ],
            "signals": {
              "stars": 6,
              "forks": 0,
              "pushed_at": "2026-01-12T04:14:24Z",
              "created_at": "2025-10-04T11:10:26Z",
              "license": null
            },
            "commands": [
              {
                "name": "/analyze_user_behavior",
                "description": "Analyze user behavior patterns and cohorts using PostHog",
                "path": "plugins/analytics/commands/analyze_user_behavior.md",
                "frontmatter": {
                  "description": "Analyze user behavior patterns and cohorts using PostHog",
                  "category": "analytics",
                  "tools": "Task, TodoWrite",
                  "model": "inherit",
                  "version": "1.0.0"
                },
                "content": "# Analyze User Behavior\n\nQuery PostHog to understand user behavior patterns, cohorts, and product usage.\n\n## Prerequisites\n\n- PostHog MCP must be enabled (this plugin should be enabled)\n- `POSTHOG_AUTH_HEADER` environment variable configured\n- Access to PostHog project\n\n## Usage\n\n```bash\n/analyze-user-behavior <query>\n\nExamples:\n  /analyze-user-behavior \"checkout abandonment last 30 days\"\n  /analyze-user-behavior \"feature adoption for new dashboard\"\n  /analyze-user-behavior \"user retention cohorts by signup month\"\n```\n\n## What This Command Does\n\nUses PostHog MCP tools to:\n\n1. Query user events and properties\n2. Analyze cohorts and segments\n3. Calculate conversion metrics\n4. Identify behavior patterns\n5. Generate insights with charts/data\n\n## Available PostHog Capabilities\n\nWhen this plugin is enabled, you have access to ~43 PostHog tools:\n\n**User Analysis**:\n\n- Query user properties and events\n- Segment users by behavior\n- Track user journeys\n- Analyze cohort retention\n\n**Product Metrics**:\n\n- Feature usage tracking\n- Conversion funnel analysis\n- A/B test results\n- Session replay analysis\n\n**Trends & Insights**:\n\n- Event trends over time\n- User engagement metrics\n- Feature adoption rates\n- Custom dashboard queries\n\n## Example Queries\n\n### Conversion Analysis\n\n```bash\n/analyze-user-behavior \"Show conversion rate from signup to first purchase, broken down by traffic source\"\n```\n\n### Feature Adoption\n\n```bash\n/analyze-user-behavior \"How many users adopted the new search feature in the last week?\"\n```\n\n### Retention Cohorts\n\n```bash\n/analyze-user-behavior \"Show weekly retention for users who signed up in December 2024\"\n```\n\n### User Journey\n\n```bash\n/analyze-user-behavior \"What's the typical path users take before upgrading to paid plan?\"\n```\n\n## Output Format\n\nThe command will:\n\n1. Translate your natural language query to PostHog API calls\n2. Fetch relevant data\n3. Present findings with:\n   - Key metrics and numbers\n   - Trends and patterns\n   - Visualizations (when possible)\n   - Actionable insights\n\n## Tips\n\n- Be specific about time ranges (\"last 30 days\", \"this quarter\")\n- Mention specific events or features by name\n- Ask for comparisons (\"vs last month\", \"broken down by...\")\n- Request segmentation (\"by country\", \"by plan type\")\n\n## Context Cost\n\n**This plugin adds ~40,645 tokens** to your context window. Disable when not analyzing metrics:\n\n```bash\n/plugin disable catalyst-analytics\n```\n\n---\n\n**See also**: `/product-metrics`, `/segment-analysis`"
              },
              {
                "name": "/product_metrics",
                "description": "View key product metrics, KPIs, and conversion rates from PostHog",
                "path": "plugins/analytics/commands/product_metrics.md",
                "frontmatter": {
                  "description": "View key product metrics, KPIs, and conversion rates from PostHog",
                  "category": "analytics",
                  "tools": "Task, TodoWrite",
                  "model": "inherit",
                  "version": "1.0.0"
                },
                "content": "# Product Metrics Dashboard\n\nQuery PostHog for key product metrics, KPIs, and performance indicators.\n\n## Usage\n\n```bash\n/product-metrics [metric-type] [time-range]\n\nExamples:\n  /product-metrics \"overall KPIs last 30 days\"\n  /product-metrics \"conversion rates this quarter\"\n  /product-metrics \"feature usage breakdown this week\"\n```\n\n## Available Metrics\n\n### Conversion Metrics\n\n- Signup conversion rate\n- Trial to paid conversion\n- Checkout completion rate\n- Feature activation rate\n\n### Engagement Metrics\n\n- Daily/Weekly/Monthly Active Users (DAU/WAU/MAU)\n- Session duration\n- Feature usage frequency\n- User retention rates\n\n### Business Metrics\n\n- Revenue per user\n- Customer acquisition cost\n- Lifetime value\n- Churn rate\n\n### Feature Metrics\n\n- Feature adoption rate\n- Time to first use\n- Feature retention\n- Power user identification\n\n## Example Queries\n\n### Overall Dashboard\n\n```bash\n/product-metrics \"Show me our key metrics for last month: MAU, conversion rates, and top features\"\n```\n\n### Conversion Funnel\n\n```bash\n/product-metrics \"Breakdown of our signup to paid funnel with drop-off rates at each step\"\n```\n\n### Feature Performance\n\n```bash\n/product-metrics \"Compare usage of our top 5 features over the last quarter\"\n```\n\n### Cohort Performance\n\n```bash\n/product-metrics \"How do our December signups compare to November in terms of activation and retention?\"\n```\n\n## Output Format\n\nResults typically include:\n\n- **Metric values** with trend indicators (‚Üë‚Üì)\n- **Comparisons** to previous periods\n- **Breakdowns** by segment when relevant\n- **Top performers** and bottom performers\n- **Recommendations** based on data\n\n## Time Range Options\n\n- `today`, `yesterday`\n- `last 7 days`, `last 30 days`, `last 90 days`\n- `this week`, `last week`\n- `this month`, `last month`, `this quarter`\n- Custom: `2024-01-01 to 2024-03-31`\n\n## Segmentation\n\nAdd segmentation to any query:\n\n```bash\n/product-metrics \"MAU by country\"\n/product-metrics \"conversion rates by traffic source\"\n/product-metrics \"feature usage by plan type\"\n```\n\n## Context Management\n\nThis plugin consumes ~40k tokens. Disable after viewing metrics:\n\n```bash\n/plugin disable catalyst-analytics\n```\n\n---\n\n**See also**: `/analyze-user-behavior`, `/segment-analysis`"
              },
              {
                "name": "/segment_analysis",
                "description": "Analyze user segments and cohorts for targeted insights",
                "path": "plugins/analytics/commands/segment_analysis.md",
                "frontmatter": {
                  "description": "Analyze user segments and cohorts for targeted insights",
                  "category": "analytics",
                  "tools": "Task, TodoWrite",
                  "model": "inherit",
                  "version": "1.0.0"
                },
                "content": "# Segment Analysis\n\nDeep-dive into specific user segments, cohorts, or customer groups using PostHog data.\n\n## Usage\n\n```bash\n/segment-analysis <segment-description>\n\nExamples:\n  /segment-analysis \"users from paid plans vs free plans\"\n  /segment-analysis \"power users who use feature X daily\"\n  /segment-analysis \"users who churned in last 30 days\"\n  /segment-analysis \"cohort: signed up in Q4 2024\"\n```\n\n## What This Analyzes\n\n### User Segments\n\n- By plan type (free, pro, enterprise)\n- By geography (country, region)\n- By acquisition source (organic, paid, referral)\n- By behavior (power users, casual users, at-risk)\n\n### Cohort Analysis\n\n- By signup date (monthly, weekly cohorts)\n- By first feature used\n- By activation milestone reached\n- By engagement level\n\n### Comparison Analysis\n\n- Segment A vs Segment B\n- Before/after feature launch\n- Treatment vs control (A/B tests)\n- Time period comparisons\n\n## Example Analyses\n\n### Plan Comparison\n\n```bash\n/segment-analysis \"Compare engagement patterns between free and paid users: session frequency, feature usage, retention\"\n```\n\n### Power User Identification\n\n```bash\n/segment-analysis \"Identify our power users: who are they, what features do they use, what's their profile?\"\n```\n\n### Churn Analysis\n\n```bash\n/segment-analysis \"Analyze users who churned: what were their last actions, which features didn't they use?\"\n```\n\n### Geographic Performance\n\n```bash\n/segment-analysis \"Compare conversion rates and engagement across our top 5 countries\"\n```\n\n### Cohort Retention\n\n```bash\n/segment-analysis \"Show retention curves for each monthly signup cohort in 2024\"\n```\n\n## Output Format\n\nAnalysis typically includes:\n\n- **Segment characteristics** (size, demographics, behavior)\n- **Key metrics** for each segment\n- **Comparative insights** between segments\n- **Behavior patterns** unique to segment\n- **Recommendations** for targeting or improvement\n\n## Segmentation Criteria\n\nYou can segment by:\n\n- **Demographics**: Country, language, device type\n- **Behavior**: Feature usage, session frequency, engagement score\n- **Business**: Plan type, payment history, LTV\n- **Temporal**: Signup date, last active, tenure\n- **Custom**: Any event or property in PostHog\n\n## Advanced Analysis\n\n### Multi-dimensional Segmentation\n\n```bash\n/segment-analysis \"Power users (5+ sessions/week) from enterprise plans who use feature X\"\n```\n\n### Funnel by Segment\n\n```bash\n/segment-analysis \"Compare signup to activation funnel for organic vs paid traffic\"\n```\n\n### Retention by Segment\n\n```bash\n/segment-analysis \"30-day retention by initial feature used\"\n```\n\n## Tips for Better Analysis\n\n1. **Be specific** - Define your segment clearly\n2. **Ask for comparisons** - \"vs\" between segments reveals insights\n3. **Look for patterns** - What makes segments different?\n4. **Consider time** - Trends over time matter\n5. **Combine criteria** - Multi-dimensional segments can be revealing\n\n## Context Cost\n\nPlugin uses ~40k tokens. Disable when analysis is complete:\n\n```bash\n/plugin disable catalyst-analytics\n```\n\n---\n\n**See also**: `/analyze-user-behavior`, `/product-metrics`"
              }
            ],
            "skills": []
          },
          {
            "name": "catalyst-debugging",
            "description": "Production error monitoring with Sentry MCP integration. Enable when debugging errors, analyzing stack traces, and investigating incidents. ~20k context when enabled.",
            "source": "./plugins/debugging",
            "category": "debugging",
            "version": "1.0.2",
            "author": {
              "name": "Coalesce Labs",
              "email": "hello@coalesce.dev"
            },
            "install_commands": [
              "/plugin marketplace add coalesce-labs/catalyst",
              "/plugin install catalyst-debugging@catalyst"
            ],
            "signals": {
              "stars": 6,
              "forks": 0,
              "pushed_at": "2026-01-12T04:14:24Z",
              "created_at": "2025-10-04T11:10:26Z",
              "license": null
            },
            "commands": [
              {
                "name": "/debug_production_error",
                "description": "Debug production errors using Sentry error tracking and analysis",
                "path": "plugins/debugging/commands/debug_production_error.md",
                "frontmatter": {
                  "description": "Debug production errors using Sentry error tracking and analysis",
                  "category": "debugging",
                  "tools": "Task, TodoWrite",
                  "model": "inherit",
                  "version": "1.0.0"
                },
                "content": "# Debug Production Error\n\nInvestigate production errors using Sentry's error tracking, stack traces, and context.\n\n## Prerequisites\n\n- Sentry MCP must be enabled (this plugin should be enabled)\n- Environment variables configured:\n  - `SENTRY_AUTH_TOKEN`\n  - `SENTRY_ORG`\n  - `SENTRY_PROJECT`\n\n## Usage\n\n```bash\n/catalyst-dev:debug-production-error <error-description-or-id>\n\nExamples:\n  /catalyst-dev:debug-production-error \"TypeError in checkout flow\"\n  /catalyst-dev:debug-production-error \"ISSUE-123\"\n  /catalyst-dev:debug-production-error \"errors from last deployment\"\n  /catalyst-dev:debug-production-error \"unhandled exceptions this week\"\n```\n\n## What This Command Does\n\nUses Sentry MCP tools to:\n\n1. Search for relevant errors\n2. Retrieve stack traces and context\n3. Analyze error patterns and frequency\n4. Identify affected users and environments\n5. Suggest root causes and fixes\n\n## Available Sentry Capabilities\n\nWhen this plugin is enabled, you have access to ~19 Sentry tools:\n\n**Error Search & Analysis**:\n\n- Search issues by query\n- Filter by status, assignment, date\n- View error trends and patterns\n- Identify new vs recurring errors\n\n**Stack Trace Analysis**:\n\n- Full stack traces with source context\n- Source map resolution\n- Frame-by-frame analysis\n- Variable inspection\n\n**Context & Metadata**:\n\n- User context (who was affected)\n- Environment details\n- Release/deployment information\n- Breadcrumb trail (user actions leading to error)\n\n**Issue Management**:\n\n- Update issue status\n- Assign to team members\n- Link to tickets/PRs\n- Add comments and notes\n\n**Root Cause Analysis** (Seer AI):\n\n- AI-powered root cause identification\n- Code-level explanations\n- Specific fix recommendations\n- Related error patterns\n\n## Example Debugging Sessions\n\n### Investigate Specific Error\n\n```bash\n/catalyst-dev:debug-production-error \"Show me details for MYAPP-456 including stack trace and user context\"\n```\n\n### Search by Error Type\n\n```bash\n/catalyst-dev:debug-production-error \"Find all TypeError exceptions in the last 24 hours\"\n```\n\n### Deployment Issues\n\n```bash\n/catalyst-dev:debug-production-error \"What new errors appeared after release v2.3.0?\"\n```\n\n### High-Impact Errors\n\n```bash\n/catalyst-dev:debug-production-error \"Show unresolved errors affecting more than 100 users\"\n```\n\n## Output Format\n\nAnalysis typically includes:\n\n**Error Overview**:\n\n- Error message and type\n- Frequency and trend\n- First seen / last seen\n- Number of users affected\n\n**Stack Trace**:\n\n- Full call stack\n- Source code context\n- File paths and line numbers\n- Variable values (if available)\n\n**User Context**:\n\n- User ID and properties\n- Browser/device information\n- URL and user actions (breadcrumbs)\n\n**Root Cause** (when Seer analysis available):\n\n- Likely cause explanation\n- Relevant code snippets\n- Specific fix recommendations\n- Related issues\n\n## Advanced Queries\n\n### Filter by Environment\n\n```bash\n/catalyst-dev:debug-production-error \"production errors in payment service\"\n```\n\n### Time-Based Analysis\n\n```bash\n/catalyst-dev:debug-production-error \"spike in errors between 2pm-3pm today\"\n```\n\n### User-Specific\n\n```bash\n/catalyst-dev:debug-production-error \"errors for user@example.com\"\n```\n\n### Integration with Analytics\n\nIf you have both plugins enabled:\n\n```bash\n# Enable both\n/plugin enable catalyst-debugging\n/plugin enable catalyst-analytics\n\n# Combined analysis\n> \"Show me errors in checkout AND how many users abandoned checkout today\"\n```\n\n## Workflow Integration\n\n### With Issue Tracking\n\nAfter identifying root cause:\n\n```bash\n> \"Create a GitHub issue for this error with the stack trace and fix recommendations\"\n```\n\n### With Code Changes\n\nAfter finding the bug:\n\n```bash\n/create-plan \"Fix the TypeError in checkout.ts based on Sentry analysis\"\n```\n\n## Context Cost\n\n**This plugin adds ~20,670 tokens** to your context window. Disable when debugging is complete:\n\n```bash\n/plugin disable catalyst-debugging\n```\n\n---\n\n**See also**: `/error-impact-analysis`, `/trace-analysis`"
              },
              {
                "name": "/error_impact_analysis",
                "description": "Analyze the impact and scope of production errors",
                "path": "plugins/debugging/commands/error_impact_analysis.md",
                "frontmatter": {
                  "description": "Analyze the impact and scope of production errors",
                  "category": "debugging",
                  "tools": "Task, TodoWrite",
                  "model": "inherit",
                  "version": "1.0.0"
                },
                "content": "# Error Impact Analysis\n\nAssess the severity, reach, and business impact of production errors.\n\n## Usage\n\n```bash\n/error-impact-analysis <error-or-timeframe>\n\nExamples:\n  /error-impact-analysis \"ISSUE-789\"\n  /error-impact-analysis \"checkout errors last 7 days\"\n  /error-impact-analysis \"critical errors this week\"\n  /error-impact-analysis \"impact of recent deployment\"\n```\n\n## What This Analyzes\n\n### Quantitative Impact\n\n- Number of occurrences\n- Number of users affected\n- Error rate over time\n- Affected environments/releases\n\n### Qualitative Impact\n\n- Error severity (critical, high, medium, low)\n- Affected user workflows\n- Business function impact (checkout, signup, etc.)\n- User experience degradation\n\n### Trend Analysis\n\n- Is it increasing or decreasing?\n- When did it start?\n- Related to specific release?\n- Correlation with traffic/usage\n\n## Example Analyses\n\n### Single Issue Impact\n\n```bash\n/error-impact-analysis \"What's the impact of MYAPP-123? How many users, revenue impact?\"\n```\n\n### Category Impact\n\n```bash\n/error-impact-analysis \"Overall impact of all payment-related errors this month\"\n```\n\n### Release Health\n\n```bash\n/error-impact-analysis \"Error impact comparison: current release vs previous release\"\n```\n\n### Critical Errors\n\n```bash\n/error-impact-analysis \"Show all critical errors and their combined user impact\"\n```\n\n## Output Format\n\nAnalysis includes:\n\n**Scope**:\n\n- Total occurrences\n- Unique users affected\n- Affected countries/regions\n- Browser/device breakdown\n\n**Severity Assessment**:\n\n- Error frequency\n- User impact score\n- Business criticality\n- Blocking vs non-blocking\n\n**Trends**:\n\n- Occurrence over time (chart/data)\n- Peak times\n- Growth rate\n- Comparison to baseline\n\n**Business Impact**:\n\n- Affected revenue-generating flows\n- Customer support tickets related\n- SLA implications\n- Reputation risk\n\n**Prioritization**:\n\n- Recommendation on urgency\n- Comparison with other errors\n- ROI of fixing\n\n## Integration with Analytics\n\nEnable both plugins for deeper impact analysis:\n\n```bash\n/plugin enable catalyst-debugging\n/plugin enable catalyst-analytics\n\n/error-impact-analysis \"How many users who hit error X churned vs users who didn't?\"\n```\n\nThis combines:\n\n- Sentry error data (who hit the error)\n- PostHog behavior data (did they churn)\n\n## Incident Response Workflow\n\n### 1. Assess Impact\n\n```bash\n/error-impact-analysis \"new spike in errors at 3pm\"\n```\n\n### 2. Determine Severity\n\nBased on output:\n\n- **Critical**: >1000 users, blocking checkout/signup\n- **High**: >100 users, degraded experience\n- **Medium**: <100 users, minor inconvenience\n- **Low**: <10 users, edge case\n\n### 3. Prioritize Response\n\n```bash\n> \"Based on this impact, should we rollback or hotfix?\"\n```\n\n### 4. Track Resolution\n\n```bash\n> \"After fix, compare error rates before and after\"\n```\n\n## Tips for Impact Analysis\n\n1. **Consider timeframe** - \"last hour\" for incidents, \"last week\" for trends\n2. **Segment users** - Impact on paid vs free users may differ\n3. **Check related errors** - One root cause may affect multiple error types\n4. **Compare releases** - Pinpoint when impact started\n5. **Business context** - Impact during peak hours is more severe\n\n## Context Cost\n\nPlugin uses ~20k tokens. Disable after analysis:\n\n```bash\n/plugin disable catalyst-debugging\n```\n\n---\n\n**See also**: `/debug-production-error`, `/trace-analysis`"
              },
              {
                "name": "/trace_analysis",
                "description": "Analyze distributed traces and performance issues with Sentry",
                "path": "plugins/debugging/commands/trace_analysis.md",
                "frontmatter": {
                  "description": "Analyze distributed traces and performance issues with Sentry",
                  "category": "debugging",
                  "tools": "Task, TodoWrite",
                  "model": "inherit",
                  "version": "1.0.0"
                },
                "content": "# Trace Analysis\n\nInvestigate distributed traces, transaction performance, and slow requests using Sentry.\n\n## Usage\n\n```bash\n/trace-analysis <trace-id-or-query>\n\nExamples:\n  /trace-analysis \"a4d1aae7216b47ff8117cf4e09ce9d0a\"\n  /trace-analysis \"slow API requests to /checkout\"\n  /trace-analysis \"traces with >5 second response time\"\n  /trace-analysis \"performance issues in payment service\"\n```\n\n## What This Analyzes\n\n### Trace Components\n\n- Transaction spans (API calls, DB queries, external services)\n- Timing breakdown per span\n- Parent-child span relationships\n- Span operations and descriptions\n\n### Performance Metrics\n\n- Total transaction duration\n- Time spent in each service\n- Database query performance\n- External API latency\n- Network overhead\n\n### Bottleneck Identification\n\n- Slowest spans in trace\n- Sequential vs parallel operations\n- N+1 query detection\n- Inefficient operations\n\n## Example Analyses\n\n### Specific Trace Investigation\n\n```bash\n/trace-analysis \"Analyze trace abc123def456: where's the bottleneck?\"\n```\n\n### Performance Pattern\n\n```bash\n/trace-analysis \"Why are checkout API requests slow today?\"\n```\n\n### Service Comparison\n\n```bash\n/trace-analysis \"Compare performance of payment service vs order service\"\n```\n\n### Database Performance\n\n```bash\n/trace-analysis \"Find traces with slow database queries in user service\"\n```\n\n## Output Format\n\nAnalysis includes:\n\n**Trace Overview**:\n\n- Transaction name and operation\n- Total duration\n- Timestamp\n- Environment and release\n\n**Span Breakdown**:\n\n```\nTransaction: POST /api/checkout (2.4s)\n‚îú‚îÄ Authentication (45ms)\n‚îú‚îÄ Database Query: SELECT users (120ms)\n‚îú‚îÄ External API: Payment Gateway (1.8s) ‚ö†Ô∏è SLOW\n‚îú‚îÄ Database Query: INSERT orders (230ms)\n‚îî‚îÄ Email Service (180ms)\n```\n\n**Performance Insights**:\n\n- Slowest operations\n- Time distribution (pie chart/percentages)\n- Parallel vs sequential execution\n- Optimization opportunities\n\n**Recommendations**:\n\n- Cache frequently accessed data\n- Optimize specific queries\n- Implement async processing\n- Add timeouts for external calls\n\n## Advanced Analysis\n\n### Multi-Trace Patterns\n\n```bash\n/trace-analysis \"Find common bottlenecks across all slow checkout traces today\"\n```\n\n### Service Dependencies\n\n```bash\n/trace-analysis \"Map service call chain for failed transactions\"\n```\n\n### Error Correlation\n\n```bash\n/trace-analysis \"Traces that resulted in errors: what went wrong before?\"\n```\n\n## Integration Opportunities\n\n### With Error Debugging\n\n```bash\n# Enable debugging plugin (if not already)\n/plugin enable catalyst-debugging\n\n# Combine trace and error analysis\n> \"Show me the trace for the transaction that caused error ISSUE-456\"\n```\n\n### With Code Changes\n\nAfter identifying bottleneck:\n\n```bash\n/create-plan \"Optimize the slow payment gateway call identified in trace analysis\"\n```\n\n## Performance Optimization Workflow\n\n### 1. Identify Slow Transactions\n\n```bash\n/trace-analysis \"transactions with >2s response time in last hour\"\n```\n\n### 2. Analyze Bottlenecks\n\n```bash\n> \"Drill into the slowest trace: which span is the problem?\"\n```\n\n### 3. Root Cause\n\n```bash\n> \"Why is the database query taking 800ms?\"\n```\n\n### 4. Implement Fix\n\n```bash\n/create-plan \"Add database index for user lookups based on trace analysis\"\n```\n\n### 5. Verify Improvement\n\n```bash\n> \"After deploy, compare trace durations before and after\"\n```\n\n## Tips\n\n1. **Start with aggregates** - \"slow checkouts\" before diving into specific traces\n2. **Look for patterns** - One slow trace might be an outlier, many indicate systemic issue\n3. **Check external dependencies** - Third-party APIs often cause slowdowns\n4. **Consider concurrency** - Sequential operations that could be parallel\n5. **Database queries** - N+1 queries, missing indexes, inefficient queries\n\n## Context Cost\n\nPlugin uses ~20k tokens. Disable after analysis:\n\n```bash\n/plugin disable catalyst-debugging\n```\n\n---\n\n**See also**: `/debug-production-error`, `/error-impact-analysis`"
              }
            ],
            "skills": []
          },
          {
            "name": "catalyst-meta",
            "description": "Workflow discovery and creation: learn from community patterns and extend Catalyst. Optional plugin for advanced users.",
            "source": "./plugins/meta",
            "category": "development",
            "version": "2.0.1",
            "author": {
              "name": "Coalesce Labs",
              "email": "hello@coalesce.dev"
            },
            "install_commands": [
              "/plugin marketplace add coalesce-labs/catalyst",
              "/plugin install catalyst-meta@catalyst"
            ],
            "signals": {
              "stars": 6,
              "forks": 0,
              "pushed_at": "2026-01-12T04:14:24Z",
              "created_at": "2025-10-04T11:10:26Z",
              "license": null
            },
            "commands": [
              {
                "name": "/create_workflow",
                "description": "Create new agents or commands using discovered patterns and templates",
                "path": "plugins/meta/commands/create_workflow.md",
                "frontmatter": {
                  "description": "Create new agents or commands using discovered patterns and templates",
                  "category": "workflow-discovery",
                  "tools": "Read, Write, Edit, Grep, Glob",
                  "model": "inherit",
                  "version": "1.0.0",
                  "workspace_only": true
                },
                "content": "# Create Workflow\n\nYou are tasked with helping users create new agents or commands by leveraging discovered patterns,\ntemplates, and examples from the workflow catalog.\n\n## Purpose\n\nThis command guides users through creating well-structured, standardized workflows by showing\nrelevant examples and enforcing frontmatter consistency.\n\n## Initial Response\n\nWhen invoked:\n\n```\nI'll help you create a new agent or command.\n\nWhat would you like to create?\n1. Agent (for Task tool sub-agents)\n2. Command (for slash commands)\n\nOr provide details:\n- Name: (e.g., code-reviewer, test-generator)\n- Purpose: (brief description)\n- Similar to: (optional - name of existing workflow to model after)\n```\n\n## Process\n\n### Step 1: Gather Requirements\n\nAsk the user:\n\n1. **Type**: Agent or Command?\n2. **Name**: What should it be called? (suggest kebab-case)\n3. **Purpose**: What does it do?\n4. **Tools needed**: Which Claude Code tools will it use?\n5. **Category**: Which category does it belong to?\n6. **Similar workflows**: Any existing workflows to model after?\n\n### Step 2: Parallel Example Research\n\n**IMPORTANT**: Spawn 3 parallel tasks to gather comprehensive examples.\n\nUse TodoWrite to track parallel research.\n\n**Task 1 - Local Examples**:\n\n```\nUse codebase-pattern-finder agent:\n\"Find all {agents/commands} in our workspace that are similar to {user-description}. Focus on {category} workflows. Return file paths and brief descriptions.\"\n\nTools: Glob, Grep, Read\nPath: /Users/ryan/code-repos/ryan-claude-workspace\nReturn: List of similar local workflows with their frontmatter and key patterns\n```\n\n**Task 2 - Catalog Examples**:\n\n```\nUse thoughts-analyzer agent:\n\"Search the workflow catalog at thoughts/shared/workflows/ for workflows similar to {user-description}. Find examples from external repositories that match the {category} category.\"\n\nTools: Grep, Read\nPath: thoughts/shared/workflows/\nReturn: External workflow examples with their implementations\n```\n\n**Task 3 - Frontmatter Standards**:\n\n```\nUse codebase-analyzer agent:\n\"Analyze all existing {agents/commands} in the workspace to extract the frontmatter standard. What fields are required? What patterns are used? What categories exist?\"\n\nTools: Glob, Grep, Read\nPath: /Users/ryan/code-repos/ryan-claude-workspace/{agents,commands}/\nReturn: Frontmatter standard with field definitions and examples\n```\n\n**WAIT for all 3 tasks to complete.**\n\n### Step 3: Aggregate Examples\n\nCombine results from parallel tasks:\n\n- Local examples (Task 1)\n- Catalog examples (Task 2)\n- Frontmatter standards (Task 3)\n\nMark all tasks complete in TodoWrite.\n\nAnalyze:\n\n1. **Common patterns**: What do similar workflows do?\n2. **Tool usage**: Which tools are typically used?\n3. **Structure**: How are they organized?\n4. **Frontmatter**: What's the standard format?\n\n### Step 4: Present Options to User\n\nShow analysis and options:\n\n````markdown\n# Create {workflow-type}: {name}\n\n## Similar Workflows Found\n\n### From Our Workspace\n\n1. **{local-workflow-1}**\n   - Purpose: {description}\n   - Tools: {tools}\n   - File: {path}\n\n2. **{local-workflow-2}** [....]\n\n### From Catalog\n\n1. **{external-workflow-1}** (from {repo})\n   - Purpose: {description}\n   - Tools: {tools}\n\n## Frontmatter Standard\n\nBased on existing workflows, here's the standard format:\n\n```yaml\n---\n{ required-fields }\n---\n```\n````\n\n## Recommended Approach\n\nBased on similar workflows, I recommend:\n\n- **Model after**: {most-similar-workflow}\n- **Tools to use**: {suggested-tools}\n- **Key patterns**: {patterns-to-follow}\n\nWould you like me to:\n\n1. Generate a workflow based on {specific-example}\n2. Create a custom workflow from scratch\n3. Show me more examples first\n\n````\n\n### Step 5: Generate Workflow Template\n\nBased on user selection, generate the appropriate template:\n\n#### 5a. For Agents\n\n```markdown\n---\nname: {workflow-name}\ndescription: |\n  {Clear description from user input}\n\n  Use this agent when:\n  - {use case 1}\n  - {use case 2}\n\n  This agent will:\n  - {action 1}\n  - {action 2}\ntools: {validated-tool-list}\nmodel: inherit\ncategory: {selected-category}\nversion: 1.0.0\n---\n\n# {Agent Name}\n\nYou are a specialized agent for {purpose}.\n\n## Your Role\n\n{Detailed role description}\n\n## Process\n\n### Step 1: {First Step}\n\n{Instructions for first step}\n\n### Step 2: {Second Step}\n\n{Instructions for second step}\n\n[Continue with all steps...]\n\n## Output Format\n\nReturn your findings in this format:\n\n````\n\n{Expected output structure}\n\n```\n\n## Important Notes\n\n- {Guideline 1}\n- {Guideline 2}\n- {Guideline 3}\n\n## Examples\n\n### Example 1: {Scenario}\n\n**Input**: {example input}\n**Expected output**: {example output}\n\n[More examples...]\n```\n\n#### 5b. For Commands\n\n````markdown\n---\ndescription: { One-line summary }\ncategory: { category }\nargument-hint: { if applicable }\ntools: { tool-list }\nmodel: inherit\nversion: 1.0.0\n---\n\n# {Command Name}\n\nYou are tasked with {command purpose}.\n\n## Purpose\n\n{Detailed explanation of what this command does and why it exists}\n\n## Initial Response\n\nWhen invoked:\n\n\\`\\`\\` {Default message to show user} \\`\\`\\`\n\n## Process\n\n### Step 1: {First Step Name}\n\n{Instructions for first step}\n\n### Step 2: {Second Step Name}\n\n{Instructions for second step}\n\n[Continue with all steps...]\n\n## Configuration\n\nThis command uses configuration from `.claude/config.json`:\n\n```json\n{\n  \"catalyst\": {\n    \"project\": {\n      \"ticketPrefix\": \"PROJ\"\n    }\n  }\n}\n```\n````\n\n## Advanced Usage\n\n### {Advanced Feature 1}\n\n```\n{Example usage}\n```\n\n### {Advanced Feature 2}\n\n```\n{Example usage}\n```\n\n## Important Notes\n\n- {Guideline 1}\n- {Guideline 2}\n\n## Integration with Other Commands\n\n- **{Related command 1}**: {How they work together}\n- **{Related command 2}**: {How they work together}\n\n## Error Handling\n\n### {Common Error 1}\n\n- {How to handle it}\n\n### {Common Error 2}\n\n- {How to handle it}\n\n````\n\n### Step 6: Validate Template\n\nBefore showing to user, validate:\n\n1. **Frontmatter**:\n   - All required fields present?\n   - Tools list valid?\n   - Category matches existing categories?\n   - Name in kebab-case?\n   - Version starts at 1.0.0?\n\n2. **Structure**:\n   - Clear purpose statement?\n   - Step-by-step process?\n   - Output format specified (for agents)?\n   - Error handling included?\n\n3. **Consistency**:\n   - Matches patterns from similar workflows?\n   - Uses workspace conventions?\n   - References config.json for project-specific values?\n\nIf validation fails, fix issues before proceeding.\n\n### Step 7: Present Draft\n\nShow the user the generated template:\n\n```markdown\n# Generated Workflow: {name}\n\nI've created a draft based on {source-pattern}.\n\n**Type**: {Agent/Command}\n**File**: {target-path}\n\n## Frontmatter\n```yaml\n{frontmatter}\n````\n\n## Key Features\n\n- {Feature 1}\n- {Feature 2}\n- {Feature 3}\n\n## Modeled After\n\n- Local: {local-example if any}\n- External: {catalog-example if any}\n\nWould you like me to:\n\n1. Save this workflow as-is\n2. Make adjustments (specify what to change)\n3. Show me alternative approaches\n\n````\n\n### Step 8: Iterate on Feedback\n\nBe ready to adjust:\n- Add/remove steps\n- Change tools\n- Adjust frontmatter\n- Modify structure\n- Add examples\n- Update descriptions\n\nContinue iterating until user is satisfied.\n\n### Step 9: Save Workflow\n\nDetermine save location:\n\n**If Agent**:\n- Save to: `agents/{workflow-name}.md`\n\n**If Command**:\n- Save to: `commands/{workflow-name}.md`\n\n### Step 10: Create Creation Record\n\nSave creation details to `thoughts/shared/workflows/created.md`:\n\n```markdown\n## {workflow-name}\n\n- **Created**: {date}\n- **Type**: {agent/command}\n- **Location**: {file-path}\n- **Modeled After**:\n  - {local-example if any}\n  - {catalog-example if any}\n- **Purpose**: {brief-description}\n- **Tools**: {tool-list}\n- **Category**: {category}\n\n**Creation Notes**: {any special notes about decisions made}\n````\n\n### Step 11: Confirmation\n\nPresent success summary:\n\n```markdown\n‚úÖ Workflow created successfully!\n\n**Saved to**: {file-path}\n\n**What's included**:\n\n- Standardized frontmatter\n- Clear step-by-step process\n- {Type-specific features}\n- Error handling guidelines\n\n**Next steps**:\n\n1. Review: `{file-path}`\n2. Test: Try using the workflow\n3. Customize: Adjust for your specific needs\n4. Commit: `git add {file-path} && git commit -m \"Add {workflow-name} {type}\"`\n\nCreation recorded in: thoughts/shared/workflows/created.md\n```\n\n## Advanced Usage\n\n### Create from Catalog Entry\n\n```\n/create-workflow from catalog wshobson/commands/code-review\n```\n\nCreates a new workflow based on a specific catalog entry.\n\n### Create with Custom Template\n\n```\n/create-workflow agent data-analyzer --template minimal\n```\n\nUses predefined templates:\n\n- `minimal`: Basic structure only\n- `standard`: Full featured (default)\n- `advanced`: Includes sub-agent patterns\n\n### Quick Create\n\n```\n/create-workflow command quick-commit \"Create conventional commits\"\n```\n\nSkips interactive steps, uses defaults.\n\n## Templates\n\n### Minimal Agent Template\n\n```yaml\n---\nname: {name}\ndescription: {description}\ntools: Read, Grep\nmodel: inherit\ncategory: general\nversion: 1.0.0\n---\n\n# {Name}\n\nYou are a specialized agent for {purpose}.\n\n## Process\n\n[Your implementation]\n\n## Output\n\nReturn: {what you return}\n```\n\n### Minimal Command Template\n\n```yaml\n---\ndescription: {description}\ncategory: general\ntools: Read, Write\nmodel: inherit\nversion: 1.0.0\n---\n\n# {Name}\n\nYou are tasked with {purpose}.\n\n## Process\n\n[Your implementation]\n```\n\n## Categories\n\nStandard categories found in workspace:\n\n**For Agents**:\n\n- `research` - Finding and analyzing information\n- `analysis` - Deep code/data analysis\n- `search` - Locating files/patterns\n- `execution` - Running commands/operations\n- `validation` - Checking and verifying\n- `general` - Multi-purpose agents\n\n**For Commands**:\n\n- `workflow` - Development workflows\n- `planning` - Planning and design\n- `implementation` - Code changes\n- `validation` - Testing and verification\n- `linear` - Linear integration\n- `git` - Version control\n- `workflow-discovery` - Meta-workflows\n- `general` - Miscellaneous\n\n## Frontmatter Field Reference\n\n### Required for All\n\n- `description`: One-line summary (commands) or longer explanation (agents)\n- `tools`: Array of Claude Code tools used\n- `model`: Usually \"inherit\"\n- `version`: Start with \"1.0.0\"\n\n### Agent-Specific\n\n- `name`: Agent identifier in kebab-case\n- `category`: Agent category from list above\n\n### Command-Specific\n\n- `category`: Command category from list above\n- `argument-hint`: (optional) Hint for command arguments\n\n### Optional for Both\n\n- `source`: URL of origin if imported/adapted\n- `adapted`: Date if modified from external source\n- `original-author`: Credit for original creator\n\n## Important Notes\n\n- **Follow standards**: Always use workspace frontmatter format\n- **Validate tools**: Only reference tools that exist in Claude Code\n- **Check categories**: Use existing categories when possible\n- **Kebab-case names**: All workflow names should be kebab-case\n- **Clear descriptions**: Make purpose immediately obvious\n- **Include examples**: Show expected inputs/outputs for agents\n- **Error handling**: Always include error scenarios\n- **Configuration**: Use .claude/config.json for project values\n\n## Integration with Other Commands\n\n- **Discover**: `/discover-workflows` ‚Üí find examples to model after\n- **Import**: `/import-workflow` ‚Üí import external workflow as starting point\n- **Create**: `/create-workflow` (this command) ‚Üí create new workflow\n- **Validate**: `/validate-frontmatter` ‚Üí ensure consistency\n\n## Error Handling\n\n### No Similar Workflows Found\n\n- Show general templates\n- Ask for more details about desired functionality\n- Suggest browsing catalog manually\n\n### Invalid Tool References\n\n- List available tools\n- Suggest alternatives\n- Ask if should proceed without unavailable tools\n\n### Category Mismatch\n\n- Show list of existing categories\n- Suggest closest match\n- Allow creating new category if justified\n\n### Name Collision\n\n- Detect existing workflow with same name\n- Suggest alternative names\n- Ask: Rename / Replace / Cancel?\n\nThis command helps you create high-quality workflows following workspace standards!"
              },
              {
                "name": "/discover_workflows",
                "description": "Research and catalog workflows from external Claude Code repositories",
                "path": "plugins/meta/commands/discover_workflows.md",
                "frontmatter": {
                  "description": "Research and catalog workflows from external Claude Code repositories",
                  "category": "workflow-discovery",
                  "tools": "mcp__deepwiki__ask_question, mcp__deepwiki__read_wiki_structure, Read, Write",
                  "model": "inherit",
                  "version": "1.0.0",
                  "workspace_only": true
                },
                "content": "# Discover Workflows\n\nYou are tasked with researching external Claude Code repositories to discover, analyze, and catalog\ntheir agents, commands, and workflow patterns.\n\n## Purpose\n\nThis command helps you learn from the Claude Code community by analyzing workflow repositories and\nextracting reusable patterns.\n\n## Supported Repositories\n\nDefault repositories to research:\n\n- `catlog22/Claude-Code-Workflow` - Multi-agent automation\n- `automazeio/ccpm` - Project management system\n- `wshobson/commands` - Production slash commands\n- `wshobson/agents` - Production subagents\n- `qdhenry/Claude-Command-Suite` - 148+ commands, 54 agents\n- `VoltAgent/awesome-claude-code-subagents` - 100+ subagents\n- `hesreallyhim/awesome-claude-code` - Curated commands/agents\n- `feiskyer/claude-code-settings` - Workflow improvements\n- `OneRedOak/claude-code-workflows` - Code review workflows\n- `anthropics/claude-code` - Official Claude Code repo\n- `winfunc/opcode` - GUI toolkit for agents/commands\n\n## Initial Response\n\nWhen invoked:\n\n```\nI'll research Claude Code workflows from external repositories.\n\nWhich repository would you like to explore?\n1. wshobson/commands - Production slash commands\n2. wshobson/agents - Production subagents\n3. qdhenry/Claude-Command-Suite - 148+ commands\n4. VoltAgent/awesome-claude-code-subagents - 100+ subagents\n5. Custom repository (provide org/repo)\n\nOr type 'all' to catalog all supported repos (this may take a while).\n```\n\n## Process\n\n### Step 1: Select Repository\n\nGet user selection or use provided parameter.\n\n### Step 2: Research Repository (Parallel Sub-Agents)\n\n**IMPORTANT**: Spawn 3 parallel research tasks for efficiency and context isolation.\n\nUse TodoWrite to track the 3 parallel research tasks.\n\n**Task 1 - Workflow Discovery**:\n\n```\nUse external-research agent:\n\"Research {repo-name}. What commands and agents are available? List all workflows with brief descriptions of what each does.\"\n\nTools: mcp__deepwiki__read_wiki_structure, mcp__deepwiki__ask_question\nReturn: Complete list of all workflows found\n```\n\n**Task 2 - Frontmatter Analysis**:\n\n```\nUse external-research agent:\n\"Research {repo-name}. What frontmatter format is used for agents and commands? Provide specific examples showing all frontmatter fields used.\"\n\nTools: mcp__deepwiki__ask_question\nReturn: Frontmatter patterns with concrete examples\n```\n\n**Task 3 - Implementation Patterns**:\n\n```\nUse external-research agent:\n\"Research {repo-name}. What are the common implementation patterns, structures, and conventions used across workflows? Include naming conventions, file organization, and any templates.\"\n\nTools: mcp__deepwiki__ask_question\nReturn: Patterns, templates, conventions observed\n```\n\n**WAIT for all 3 tasks to complete before proceeding.**\n\n**Why parallel**:\n\n- 3x faster than sequential\n- Each agent has isolated context\n- No context contamination between research areas\n- Better token efficiency per agent\n\n### Step 3: Aggregate Parallel Results\n\nCombine findings from the 3 parallel research tasks:\n\n- Workflows list from Task 1\n- Frontmatter patterns from Task 2\n- Implementation patterns from Task 3\n\nMark all 3 tasks complete in TodoWrite.\n\n### Step 4: Analyze and Extract\n\nFrom the aggregated results, extract:\n\n1. **Available Workflows**\n   - List all agents and commands\n   - What each one does\n   - When to use them\n\n2. **Frontmatter Patterns**\n   - What fields are used\n   - Naming conventions\n   - Tool specifications\n   - Categories/tags\n\n3. **Implementation Patterns**\n   - Common structures\n   - Reusable templates\n   - Integration patterns\n\n4. **Unique Features**\n   - Novel approaches\n   - Interesting combinations\n   - Advanced techniques\n\n### Step 5: Create Catalog Entry\n\nSave research to `thoughts/shared/workflows/{repo-name}/analysis.md`:\n\n````markdown\n# Workflow Analysis: {Repo Name}\n\n**Repository**: {org/repo} **Analyzed**: {date} **Focus**: {agents/commands/both}\n\n## Summary\n\n[1-2 sentence overview of what this repo offers]\n\n## Available Workflows\n\n### Commands\n\n1. **{command-name}**\n   - **Purpose**: [what it does]\n   - **Use when**: [scenario]\n   - **Frontmatter**:\n     ```yaml\n     [actual frontmatter from repo]\n     ```\n\n2. **{command-name}** [...]\n\n### Agents\n\n1. **{agent-name}**\n   - **Purpose**: [what it does]\n   - **Tools**: [tools it uses]\n   - **Frontmatter**:\n     ```yaml\n     [actual frontmatter from repo]\n     ```\n\n## Frontmatter Patterns\n\n### Standard Fields\n\n- name: [how they define it]\n- description: [format they use]\n- tools: [how specified]\n- [other fields observed]\n\n### Naming Conventions\n\n- [pattern 1]\n- [pattern 2]\n\n## Implementation Patterns\n\n### Common Structures\n\n[Patterns you notice across workflows]\n\n### Reusable Templates\n\n[Templates that could be adapted]\n\n## Unique Features\n\n[Novel or interesting approaches]\n\n## Integration Notes\n\n[How these could integrate with your workspace]\n\n## Recommendations\n\n### High-Value Imports\n\n1. **{workflow-name}** - [why it's valuable]\n2. **{workflow-name}** - [why it's valuable]\n\n### Patterns to Adopt\n\n- [Pattern 1]: [how to use it]\n- [Pattern 2]: [how to use it]\n\n## References\n\n- DeepWiki searches: [links]\n- Repository: {URL}\n- Analyzed on: {date}\n````\n\n### Step 6: Update Master Catalog\n\nUpdate `thoughts/shared/workflows/catalog.md`:\n\n```markdown\n# Workflow Catalog\n\nDiscovered workflows from the Claude Code community.\n\n## Repositories Analyzed\n\n### wshobson/commands\n\n- **Analyzed**: 2025-01-08\n- **Workflows**: 15 commands\n- **Focus**: Production-ready automation\n- **Details**: [See analysis](wshobson-commands/analysis.md)\n- **Top Picks**:\n  - code-review: Automated code review workflow\n  - refactor: Safe refactoring patterns\n\n[... more repos]\n\n## By Category\n\n### Code Review\n\n- wshobson/commands: code-review\n- OneRedOak/claude-code-workflows: review-pr\n\n### Documentation\n\n- qdhenry/Claude-Command-Suite: doc-generator\n- hesreallyhim/awesome-claude-code: readme-generator\n\n[... more categories]\n\n## By Use Case\n\n### \"I want to automate code reviews\"\n\n1. wshobson/commands/code-review\n2. OneRedOak/claude-code-workflows/review-pr\n3. [Details in respective analyses]\n\n### \"I need project management workflows\"\n\n1. automazeio/ccpm - Full PM system\n2. [...]\n```\n\n### Step 7: Present Summary\n\nShow user what was found:\n\n```markdown\n# Discovery Results: {Repo Name}\n\n## Summary\n\nDiscovered {N} workflows ({X} commands, {Y} agents)\n\n## Highlights\n\n### Top Workflows\n\n1. **{name}** - {brief description}\n2. **{name}** - {brief description}\n3. **{name}** - {brief description}\n\n### Interesting Patterns\n\n- {Pattern 1}\n- {Pattern 2}\n\n### Recommended for Import\n\n- **{workflow-name}**: {why}\n\n## Next Steps\n\n1. **Review the analysis**: `thoughts/shared/workflows/{repo}/analysis.md`\n2. **Import a workflow**: `/import-workflow {repo} {workflow-name}`\n3. **Discover another repo**: `/discover-workflows`\n\nCatalog updated at: `thoughts/shared/workflows/catalog.md`\n```\n\n## Advanced Usage\n\n### Discover All Repos (Maximum Parallelism)\n\n```\n/discover-workflows all\n```\n\nThis will:\n\n1. Spawn parallel research for ALL supported repos simultaneously\n2. Each repo gets 3 sub-agents (structure, frontmatter, patterns)\n3. Total: 11 repos √ó 3 agents = 33 parallel tasks\n4. Aggregate all results\n5. Create analysis for each repo\n6. Update master catalog\n7. Present summary comparison\n\n**Performance**: ~10-15x faster than sequential research\n\n**Context efficiency**: Each agent loads only its research area\n\n### Discover Custom Repo\n\n```\n/discover-workflows org/repo\n```\n\nWorks with any public GitHub repo with Claude Code workflows.\n\n### Focus on Specific Type\n\n```\n/discover-workflows wshobson/agents --focus agents\n```\n\nOnly analyzes agents, skips commands.\n\n## Important Notes\n\n- **Read-only**: This command only researches, doesn't import\n- **Catalog persistence**: Saved in thoughts/ for future reference\n- **Reusable**: Run anytime to update catalog\n- **Combinable**: Use with `/import-workflow` to actually import\n\n## Integration with Other Commands\n\n- **Discover** ‚Üí `/discover-workflows` (this command)\n- **Import** ‚Üí `/import-workflow` (imports discovered workflows)\n- **Create** ‚Üí `/create-workflow` (creates new using discovered patterns)\n- **Validate** ‚Üí `/validate-frontmatter` (ensures consistency)\n\nThis command is the first step in workflow discovery and reuse!"
              },
              {
                "name": "/import_workflow",
                "description": "Import and adapt a workflow from external repositories",
                "path": "plugins/meta/commands/import_workflow.md",
                "frontmatter": {
                  "description": "Import and adapt a workflow from external repositories",
                  "category": "workflow-discovery",
                  "tools": "Read, Write, Edit, mcp__deepwiki__ask_question",
                  "model": "inherit",
                  "version": "1.0.0",
                  "workspace_only": true
                },
                "content": "# Import Workflow\n\nYou are tasked with importing and adapting workflows from external Claude Code repositories into\nthis workspace.\n\n## Purpose\n\nThis command helps you import discovered workflows, adapt them to your workspace standards, validate\nfrontmatter consistency, and integrate with your configuration.\n\n## Initial Response\n\nWhen invoked:\n\n```\nI'll help you import a workflow from an external repository.\n\nPlease provide:\n1. Repository name (e.g., wshobson/commands)\n2. Workflow name (e.g., code-review)\n\nOr, if you've already run /discover-workflows:\n- Check the catalog: thoughts/shared/workflows/catalog.md\n- Pick from discovered workflows\n```\n\n## Process\n\n### Step 1: Identify Workflow\n\nGet the repository and workflow name from user or parameters.\n\n### Step 2: Parallel Research & Validation\n\n**IMPORTANT**: Spawn 3 parallel tasks for comprehensive analysis.\n\nUse TodoWrite to track parallel research.\n\n**Task 1 - External Research**:\n\n```\nUse external-research agent:\n\"Research {repo}/{workflow}. Explain what this workflow does, how it works, what tools it uses, and provide the complete implementation including frontmatter.\"\n\nTools: mcp__deepwiki__ask_question\nReturn: Full workflow understanding and implementation\n```\n\n**Task 2 - Local Pattern Check**:\n\n```\nUse codebase-pattern-finder agent:\n\"Find similar workflows in our workspace (agents/ and commands/ directories). Look for workflows that serve similar purposes or use similar patterns.\"\n\nTools: Grep, Glob, Read\nPath: /Users/ryan/code-repos/ryan-claude-workspace\nReturn: Similar local workflows for comparison\n```\n\n**Task 3 - Historical Context**:\n\n```\nUse thoughts-locator agent:\n\"Search for any previous research, notes, or attempts related to this type of workflow. Search for keywords: {workflow-name}, {workflow-purpose}.\"\n\nTools: Grep, Glob\nPath: thoughts/\nReturn: Any historical context or previous attempts\n```\n\n**WAIT for all 3 tasks to complete.**\n\n### Step 3: Aggregate and Analyze\n\nCombine results from parallel tasks:\n\n- External workflow details (Task 1)\n- Similar local patterns (Task 2)\n- Historical context (Task 3)\n\nMark all tasks complete in TodoWrite.\n\nAnalyze:\n\n1. **Purpose alignment**: Does this fit our needs?\n2. **Duplication check**: Do we already have something similar?\n3. **Adaptation needs**: What needs to change?\n\n### Step 4: Present Analysis to User\n\nShow comprehensive analysis:\n\n````markdown\n# Import Analysis: {workflow-name}\n\n## What It Does\n\n[Summary from external research]\n\n## External Implementation\n\n- **Repository**: {repo}\n- **Tools used**: [list]\n- **Frontmatter**:\n  ```yaml\n  [original frontmatter]\n  ```\n````\n\n## Comparison with Our Workspace\n\n### Similar Local Workflows\n\n[From Task 2 - what we already have]\n\n### Differences\n\n- [Key differences from our patterns]\n\n### Historical Context\n\n[From Task 3 - any previous attempts or notes]\n\n## Required Adaptations\n\n1. **Frontmatter**: [what needs to change]\n2. **Configuration**: [ticket prefix, Linear IDs, etc.]\n3. **Tool references**: [any tool updates needed]\n4. **Naming**: [follow our conventions]\n\n## Recommendation\n\n[Import as-is / Import with modifications / Skip (we have similar)]\n\nProceed with import? (Y/n)\n\n````\n\n### Step 5: Adapt to Workspace Standards\n\nIf user approves, adapt the workflow:\n\n#### 5a. Standardize Frontmatter\n\nApply consistent frontmatter based on type:\n\n**For Agents**:\n```yaml\n---\nname: {workflow-name}\ndescription: |\n  {Clear description from research}\n  {When to invoke}\ntools: {validated tool list}\nmodel: inherit\ncategory: {appropriate category}\nversion: 1.0.0\nsource: {repo-url}  # Track origin\n---\n````\n\n**For Commands**:\n\n```yaml\n---\ndescription: { One-line summary }\ncategory: { appropriate category }\nargument-hint: { if applicable }\ntools: { tool list }\nmodel: inherit\nversion: 1.0.0\nsource: { repo-url } # Track origin\n---\n```\n\n#### 5b. Replace Repository-Specific Values\n\nCheck for and replace:\n\n- Ticket prefixes (ENG-XXX ‚Üí read from `.claude/config.json`)\n- Repository paths (their paths ‚Üí local paths)\n- Team/project IDs (their IDs ‚Üí prompt or use config)\n- User names (their names ‚Üí generic or config)\n- Tool names (check compatibility)\n\n#### 5c. Add Attribution\n\nAdd source attribution in frontmatter and as comment:\n\n```markdown\n---\nsource: https://github.com/{repo}\nadapted: { date }\noriginal-author: { if known }\n---\n\n<!--\nAdapted from: {repo}/{workflow-name}\nOriginal: {URL}\nModifications:\n- {change 1}\n- {change 2}\n-->\n```\n\n### Step 6: Validate Frontmatter\n\nBefore saving, validate against standard:\n\n- Required fields present?\n- Tools list valid?\n- Category appropriate?\n- Description clear?\n- Name follows kebab-case?\n\nIf validation fails, show issues and fix.\n\n### Step 7: Save Workflow\n\nDetermine type and save location:\n\n**If Agent**:\n\n- Save to: `agents/{workflow-name}.md`\n\n**If Command**:\n\n- Save to: `commands/{workflow-name}.md`\n\n### Step 8: Create Import Record\n\nSave import details to `thoughts/shared/workflows/imports.md`:\n\n```markdown\n## {workflow-name}\n\n- **Imported**: {date}\n- **Source**: {repo}/{workflow}\n- **Type**: {agent/command}\n- **Location**: {file-path}\n- **Adaptations**:\n  - {adaptation 1}\n  - {adaptation 2}\n- **Status**: Active\n\n**Why imported**: {reason}\n```\n\n### Step 9: Confirmation\n\nPresent success summary:\n\n```markdown\n‚úÖ Workflow imported successfully!\n\n**Saved to**: {file-path}\n\n**Adaptations made**:\n\n- Standardized frontmatter\n- Updated ticket prefix: ENG ‚Üí PROJ\n- Added source attribution\n- Validated tools list\n\n**Next steps**:\n\n1. Review: `{file-path}`\n2. Test: Try using the workflow\n3. Customize: Adjust for your specific needs\n4. Commit: `git add {file-path} && git commit -m \"Import {workflow-name} from {repo}\"`\n\nImport recorded in: thoughts/shared/workflows/imports.md\n```\n\n## Advanced Usage\n\n### Import with Custom Adaptations\n\n```\n/import-workflow wshobson/commands code-review --adapt \"Use our custom linting rules\"\n```\n\n### Import Multiple Workflows\n\n```\n/import-workflow wshobson/commands code-review refactor test-gen\n```\n\nImports all 3 in sequence (with parallel validation for each).\n\n### Dry Run Mode\n\n```\n/import-workflow wshobson/commands code-review --dry-run\n```\n\nShows what would be imported without actually saving files.\n\n## Important Notes\n\n- **Always validate**: Never blindly import without checking compatibility\n- **Track provenance**: Always attribute source\n- **Respect licenses**: Check repo license before importing\n- **Test imported workflows**: Verify they work in your environment\n- **Keep imports.md updated**: Track what you've imported\n\n## Integration with Other Commands\n\n- **Discover first**: `/discover-workflows` ‚Üí catalog workflows\n- **Then import**: `/import-workflow` (this command)\n- **Validate**: `/validate-frontmatter` ensures consistency\n- **Create custom**: `/create-workflow` for new workflows\n\n## Error Handling\n\n### Workflow Not Found\n\n- Suggest running `/discover-workflows {repo}` first\n- Check catalog for available workflows\n\n### Incompatible Tools\n\n- List tools that don't exist in your environment\n- Suggest alternatives\n- Ask if should proceed with modifications\n\n### Duplicate Workflow\n\n- Show existing similar workflow\n- Ask: Replace / Rename / Skip?\n\n### Validation Failures\n\n- Show specific issues\n- Offer to auto-fix\n- Request manual review if complex\n\nThis command bridges external workflows into your workspace with proper adaptation and validation!"
              },
              {
                "name": "/validate_frontmatter",
                "description": "Validate and fix frontmatter consistency across all workflows",
                "path": "plugins/meta/commands/validate_frontmatter.md",
                "frontmatter": {
                  "description": "Validate and fix frontmatter consistency across all workflows",
                  "category": "workflow-discovery",
                  "tools": "Read, Edit, Glob, Grep",
                  "model": "inherit",
                  "version": "1.0.0",
                  "workspace_only": true
                },
                "content": "# Validate Frontmatter\n\nYou are tasked with validating frontmatter consistency across all agents and commands in the\nworkspace, and fixing any issues found.\n\n## Purpose\n\nThis command ensures all workflows follow the workspace frontmatter standard, making them easier to\nmaintain, discover, and integrate.\n\n## Initial Response\n\nWhen invoked:\n\n```\nI'll validate frontmatter across all workflows.\n\nChecking:\n- agents/ directory\n- commands/ directory\n\nWhat would you like to do?\n1. Validate all workflows (report issues only)\n2. Validate and auto-fix issues\n3. Validate specific workflow\n4. Generate frontmatter standard document\n```\n\n## Process\n\n### Step 1: Determine Scope\n\nGet user selection:\n\n- **All workflows**: Check everything\n- **Auto-fix**: Fix issues automatically\n- **Specific workflow**: Validate one file\n- **Generate standard**: Create reference document\n\n### Step 2: Parallel Validation\n\n**IMPORTANT**: Spawn parallel validation tasks for efficiency.\n\nUse TodoWrite to track parallel validation tasks.\n\n**For \"Validate All\" mode**:\n\n**Task 1 - Validate Agents**:\n\n```\nUse codebase-analyzer agent:\n\"Validate frontmatter in all files matching agents/*.md. For each file, check:\n1. Required fields present (name, description, tools, model, version)\n2. Name field matches filename (kebab-case)\n3. Tools list contains valid Claude Code tools\n4. Category is one of: research, analysis, search, execution, validation, general\n5. Version follows semver (e.g., 1.0.0)\n6. Description is clear and informative\nReturn: List of all validation issues found with file:line references\"\n\nTools: Glob, Grep, Read\nPath: /Users/ryan/code-repos/ryan-claude-workspace/agents/\nReturn: Validation report for all agents\n```\n\n**Task 2 - Validate Commands**:\n\n```\nUse codebase-analyzer agent:\n\"Validate frontmatter in all files matching commands/*.md. For each file, check:\n1. Required fields present (description, category, tools, model, version)\n2. No 'name' field (commands use filename)\n3. Tools list contains valid Claude Code tools\n4. Category is one of: workflow, planning, implementation, validation, linear, git, workflow-discovery, general\n5. Version follows semver (e.g., 1.0.0)\n6. Description is clear and concise\n7. argument-hint present if command takes arguments\nReturn: List of all validation issues found with file:line references\"\n\nTools: Glob, Grep, Read\nPath: /Users/ryan/code-repos/ryan-claude-workspace/commands/\nReturn: Validation report for all commands\n```\n\n**Task 3 - Extract Tool References**:\n\n```\nUse codebase-pattern-finder agent:\n\"Extract all unique tool names referenced in frontmatter across agents/*.md and commands/*.md. Return a sorted list of all tools used.\"\n\nTools: Glob, Grep\nPath: /Users/ryan/code-repos/ryan-claude-workspace/\nReturn: Complete list of tools referenced\n```\n\n**WAIT for all 3 tasks to complete.**\n\n### Step 3: Aggregate Validation Results\n\nCombine results from parallel tasks:\n\n- Agent issues (Task 1)\n- Command issues (Task 2)\n- Tool inventory (Task 3)\n\nMark all tasks complete in TodoWrite.\n\nAnalyze:\n\n1. **Critical issues**: Missing required fields, invalid formats\n2. **Warnings**: Unusual patterns, potential improvements\n3. **Tool usage**: Are all tools valid?\n4. **Category distribution**: Are categories being used correctly?\n\n### Step 4: Present Validation Report\n\nShow comprehensive report:\n\n```markdown\n# Frontmatter Validation Report\n\n**Validated**: {date} **Scope**: {agents-count} agents, {commands-count} commands **Status**:\n{PASS/FAIL}\n\n## Summary\n\n- ‚úÖ **Passed**: {pass-count} workflows\n- ‚ö†Ô∏è **Warnings**: {warning-count} workflows\n- ‚ùå **Failed**: {fail-count} workflows\n\n## Critical Issues\n\n### {workflow-name}.md\n\n- ‚ùå Missing required field: `version`\n- ‚ùå Invalid category: \"misc\" (should be one of: general, research, analysis...)\n\n### {workflow-name}.md\n\n- ‚ùå Name field \"{name}\" doesn't match filename \"{filename}\"\n- ‚ùå Invalid tool reference: \"SearchFiles\" (not a valid Claude Code tool)\n\n## Warnings\n\n### {workflow-name}.md\n\n- ‚ö†Ô∏è Description is very short (< 20 chars)\n- ‚ö†Ô∏è No category specified (defaulting to \"general\")\n\n### {workflow-name}.md\n\n- ‚ö†Ô∏è Using old version format: \"v1.0\" (should be \"1.0.0\")\n\n## Tool Inventory\n\n**Total unique tools**: {tool-count} **Valid tools**: {valid-count} **Invalid references**:\n{invalid-count}\n\n### Used Tools:\n\n- Read ({usage-count} workflows)\n- Write ({usage-count} workflows)\n- Edit ({usage-count} workflows)\n- Grep ({usage-count} workflows)\n- Glob ({usage-count} workflows) [... more tools ...]\n\n### Invalid References:\n\n- SearchFiles (used in {workflow-name}.md) ‚Üí Should be: Grep or Glob\n- FindFile (used in {workflow-name}.md) ‚Üí Should be: Glob\n\n## Category Distribution\n\n### Agents:\n\n- research: {count}\n- analysis: {count}\n- search: {count}\n- execution: {count}\n- validation: {count}\n- general: {count}\n\n### Commands:\n\n- workflow: {count}\n- planning: {count}\n- implementation: {count}\n- validation: {count}\n- linear: {count}\n- git: {count}\n- workflow-discovery: {count}\n- general: {count}\n\n## Recommendations\n\n1. **Fix critical issues first**: {count} workflows need immediate attention\n2. **Standardize versions**: {count} workflows use non-semver format\n3. **Update tool references**: {count} invalid tool names found\n4. **Add descriptions**: {count} workflows have minimal descriptions\n\n---\n\nNext steps:\n\n- Run with `--fix` to auto-correct issues\n- Review and approve fixes before applying\n- Re-validate after fixes\n```\n\n### Step 5: Auto-Fix Mode (if requested)\n\nIf user chose auto-fix:\n\n1. **Create fix plan**:\n   - List all fixable issues\n   - Show what will be changed\n   - Ask for confirmation\n\n2. **Present fix plan**:\n\n   ```markdown\n   # Auto-Fix Plan\n\n   I can automatically fix {fixable-count} issues:\n\n   ## {workflow-name}.md\n\n   - Add missing `version: 1.0.0`\n   - Fix category: \"misc\" ‚Üí \"general\"\n   - Standardize tool name: \"SearchFiles\" ‚Üí \"Grep\"\n\n   ## {workflow-name}.md\n\n   - Fix version format: \"v1.0\" ‚Üí \"1.0.0\"\n   - Add missing `model: inherit`\n\n   **Cannot auto-fix** ({manual-count} issues):\n\n   - {workflow-name}.md: Description too short (needs human review)\n   - {workflow-name}.md: Unclear category (analysis vs research?)\n\n   Proceed with auto-fix? (Y/n)\n   ```\n\n3. **Apply fixes** (after confirmation):\n   - Use Edit tool to fix each issue\n   - Track all changes made\n   - Preserve original formatting and comments\n\n4. **Report results**:\n\n   ```markdown\n   ‚úÖ Auto-fix complete!\n\n   **Fixed**: {fixed-count} issues across {file-count} files\n\n   ### Changes Made:\n\n   #### agents/codebase-locator.md\n\n   - Added `version: 1.0.0`\n   - Standardized category: \"search\"\n\n   #### commands/create_plan.md\n\n   - Fixed version: \"v1.0\" ‚Üí \"1.0.0\"\n   - Updated tool reference: \"SearchFiles\" ‚Üí \"Grep\"\n\n   [... more changes ...]\n\n   **Still needs manual review**:\n\n   - {workflow-name}.md: {issue description}\n\n   Re-run validation to verify: `/validate-frontmatter`\n   ```\n\n### Step 6: Generate Standard Document (if requested)\n\nIf user chose to generate standard:\n\nCreate `docs/FRONTMATTER_STANDARD.md`:\n\n````markdown\n# Frontmatter Standard\n\nThis document defines the frontmatter standard for all agents and commands in this workspace.\n\n## Agent Frontmatter\n\n### Required Fields\n\n```yaml\n---\nname: { agent-name } # Agent identifier (kebab-case, must match filename)\ndescription: | # Multi-line description\n  {What this agent does}\n\n  Use this agent when:\n  - {Use case 1}\n  - {Use case 2}\ntools: { tool-list } # Array of Claude Code tools\nmodel: inherit # Always \"inherit\"\ncategory: { category } # One of: research, analysis, search, execution, validation, general\nversion: 1.0.0 # Semantic version\n---\n```\n````\n\n### Optional Fields\n\n```yaml\nsource: { repo-url } # If imported/adapted\nadapted: { date } # Date of adaptation\noriginal-author: { name } # Original creator\n```\n\n### Valid Categories\n\n- **research**: Finding and gathering information\n- **analysis**: Deep code/data analysis\n- **search**: Locating files/patterns/content\n- **execution**: Running commands/operations\n- **validation**: Checking and verifying\n- **general**: Multi-purpose or uncategorized\n\n### Example\n\n```yaml\n---\nname: codebase-analyzer\ndescription: |\n  Analyzes codebases to understand implementation details and patterns.\n\n  Use this agent when:\n  - You need to understand how a feature is implemented\n  - You want to trace data flow through the system\n  - You need to find patterns and conventions\ntools: Read, Grep, Glob\nmodel: inherit\ncategory: analysis\nversion: 1.0.0\n---\n```\n\n## Command Frontmatter\n\n### Required Fields\n\n```yaml\n---\ndescription: { one-line-summary } # Brief description (no name field!)\ncategory: { category } # Command category\ntools: { tool-list } # Array of Claude Code tools\nmodel: inherit # Always \"inherit\"\nversion: 1.0.0 # Semantic version\n---\n```\n\n### Optional Fields\n\n```yaml\nargument-hint: { hint } # Hint for command arguments\nsource: { repo-url } # If imported/adapted\nadapted: { date } # Date of adaptation\noriginal-author: { name } # Original creator\n```\n\n### Valid Categories\n\n- **workflow**: Development workflows\n- **planning**: Planning and design\n- **implementation**: Code changes\n- **validation**: Testing and verification\n- **linear**: Linear integration\n- **git**: Version control\n- **workflow-discovery**: Meta-workflows\n- **general**: Miscellaneous\n\n### Example\n\n```yaml\n---\ndescription: Create detailed implementation plans through interactive process\ncategory: planning\nargument-hint: [ticket-file | ticket-reference]\ntools: Read, Write, Edit, Grep, Glob, Task, TodoWrite\nmodel: inherit\nversion: 1.0.0\n---\n```\n\n## Valid Tools\n\nClaude Code provides these tools:\n\n### File Operations\n\n- `Read` - Read file contents\n- `Write` - Write files\n- `Edit` - Edit existing files\n\n### Search\n\n- `Grep` - Search file contents (regex)\n- `Glob` - Find files by pattern\n\n### Execution\n\n- `Bash` - Run shell commands\n- `Task` - Spawn sub-agents\n\n### Management\n\n- `TodoWrite` - Manage todo lists\n\n### External\n\n- `WebFetch` - Fetch web content\n- `WebSearch` - Search the web\n- `mcp__deepwiki__ask_question` - Query external repos\n- `mcp__deepwiki__read_wiki_structure` - Get repo structure\n- `mcp__deepwiki__read_wiki_contents` - Read repo docs\n\n### Linear Integration\n\n- `linear_get_ticket` - Get Linear ticket details\n- `linear_create_ticket` - Create Linear tickets\n- `linear_update_ticket` - Update Linear tickets\n\n(Check official Claude Code docs for complete list)\n\n## Validation Rules\n\n### All Workflows\n\n1. **Required fields must be present**\n2. **Version must follow semver**: `X.Y.Z` (not `vX.Y`)\n3. **Model must be \"inherit\"** (unless specific reason)\n4. **Tools must be valid Claude Code tools**\n5. **Category must be from valid list**\n\n### Agents Specifically\n\n1. **Must have `name` field** matching filename\n2. **Name must be kebab-case**\n3. **Description should be multi-line with use cases**\n\n### Commands Specifically\n\n1. **Must NOT have `name` field** (use filename)\n2. **Description should be one-line summary**\n3. **Use `argument-hint` if command takes arguments**\n\n## Common Mistakes\n\n### ‚ùå Wrong: Command with name field\n\n```yaml\n---\nname: create-plan # Commands don't have name field\ndescription: Create plans\n---\n```\n\n### ‚úÖ Correct: Command without name\n\n```yaml\n---\ndescription: Create detailed implementation plans\ncategory: planning\n---\n```\n\n### ‚ùå Wrong: Invalid tool reference\n\n```yaml\ntools: SearchFiles, FindFile # These aren't real tools\n```\n\n### ‚úÖ Correct: Valid tools\n\n```yaml\ntools: Grep, Glob # Correct tool names\n```\n\n### ‚ùå Wrong: Version format\n\n```yaml\nversion: v1.0 # Should be semver\n```\n\n### ‚úÖ Correct: Semver version\n\n```yaml\nversion: 1.0.0 # Proper semver\n```\n\n## Updating the Standard\n\nWhen adding new categories or patterns:\n\n1. Update this document\n2. Validate all existing workflows\n3. Fix any inconsistencies\n4. Document the change in git commit\n\n## See Also\n\n- `/validate-frontmatter` - Validate workflows against this standard\n- `/create-workflow` - Create new workflows with correct frontmatter\n- `/import-workflow` - Import external workflows and adapt frontmatter\n\n```\n\nSave and report:\n```\n\n‚úÖ Frontmatter standard documented!\n\n**Saved to**: docs/FRONTMATTER_STANDARD.md\n\nThis document now serves as the canonical reference for all frontmatter in this workspace.\n\nNext steps:\n\n1. Review the standard\n2. Share with team\n3. Use `/validate-frontmatter` to check compliance\n4. Reference when creating new workflows\n\n```\n\n## Advanced Usage\n\n### Validate Specific Workflow\n\n```\n\n/validate-frontmatter agents/codebase-analyzer.md\n\n```\n\nValidates just one file.\n\n### Auto-Fix Everything\n\n```\n\n/validate-frontmatter --fix\n\n```\n\nAutomatically fixes all issues without prompting.\n\n### Generate Report Only\n\n```\n\n/validate-frontmatter --report-only > frontmatter-report.md\n\n```\n\nSaves report to file for review.\n\n### Validate by Category\n\n```\n\n/validate-frontmatter --category research\n\n```\n\nOnly validates workflows in \"research\" category.\n\n## Validation Categories\n\n### Critical Issues (Must Fix)\n\n- Missing required fields\n- Invalid field values\n- Name/filename mismatch (agents)\n- Invalid tool references\n- Malformed YAML\n\n### Warnings (Should Fix)\n\n- Short descriptions (< 20 chars)\n- Missing optional but recommended fields\n- Unusual category choices\n- Non-standard patterns\n\n### Info (Nice to Have)\n\n- Could add more detail\n- Could specify argument-hint\n- Could add source attribution\n- Could improve formatting\n\n## Auto-Fix Capabilities\n\n### What Can Be Auto-Fixed\n\n‚úÖ Missing version field ‚Üí Add `version: 1.0.0`\n‚úÖ Wrong version format ‚Üí Convert to semver\n‚úÖ Missing model field ‚Üí Add `model: inherit`\n‚úÖ Common tool typos ‚Üí Fix to correct names\n‚úÖ Category typos ‚Üí Fix to valid category\n‚úÖ YAML formatting ‚Üí Standardize indentation\n\n### What Requires Manual Review\n\n‚ùå Ambiguous categories ‚Üí Needs human judgment\n‚ùå Short descriptions ‚Üí Needs content creation\n‚ùå Complex tool issues ‚Üí May need workflow redesign\n‚ùå Missing description ‚Üí Needs understanding of purpose\n\n## Important Notes\n\n- **Non-destructive**: Auto-fix preserves content, only fixes frontmatter\n- **Safe**: Always shows plan before applying fixes\n- **Trackable**: Reports all changes made\n- **Reversible**: Changes are standard edits, can be reverted via git\n- **Standard-based**: Uses workspace-specific conventions\n\n## Integration with Other Commands\n\n- **Discover**: `/discover-workflows` ‚Üí uses this for validation\n- **Import**: `/import-workflow` ‚Üí validates imported workflows\n- **Create**: `/create-workflow` ‚Üí ensures new workflows are valid\n- **Validate**: `/validate-frontmatter` (this command) ‚Üí checks everything\n\n## Error Handling\n\n### Malformed YAML\n- Report syntax errors\n- Show line number\n- Suggest fixes\n- Cannot auto-fix (manual correction needed)\n\n### Unknown Fields\n- Report unexpected fields\n- Ask: Keep / Remove?\n- Could be custom extensions\n\n### Missing Files\n- Skip files that don't exist\n- Report which files were skipped\n- Continue validation\n\n### Permission Errors\n- Report read/write issues\n- Skip files that can't be accessed\n- Provide error details\n\nThis command ensures workspace consistency and quality!\n```"
              },
              {
                "name": "/workflow_help",
                "description": "Interactive guide to supported workflows with context-aware assistance",
                "path": "plugins/meta/commands/workflow_help.md",
                "frontmatter": {
                  "description": "Interactive guide to supported workflows with context-aware assistance",
                  "category": "workflow",
                  "tools": "Read, Grep, Glob, Task",
                  "model": "inherit",
                  "version": "1.0.0"
                },
                "content": "# Workflow Help\n\nYou are an interactive workflow guide that helps users navigate the supported workflows in this\nrepository using parallel sub-agents for research and context-aware guidance.\n\n## Initial Response\n\nWhen this command is invoked WITHOUT parameters:\n\n```\n# üéØ Workflow Guide\n\nI can help you navigate the supported workflows in this workspace.\n\n## Available Workflows\n\n**1. Development Workflow** (research ‚Üí plan ‚Üí implement ‚Üí validate ‚Üí PR)\n   - `/research-codebase` ‚Üí Document existing system\n   - `/create-plan` ‚Üí Create implementation plan\n   - `/implement-plan` ‚Üí Execute approved plan\n   - `/validate-plan` ‚Üí Verify implementation\n   - Handoffs & worktrees for context management\n\n**2. Workflow Discovery** (discover ‚Üí import ‚Üí create ‚Üí validate)\n   - `/discover-workflows` ‚Üí Research external repositories\n   - `/import-workflow` ‚Üí Adapt external workflows\n   - `/create-workflow` ‚Üí Build new agents/commands\n   - `/validate-frontmatter` ‚Üí Ensure consistency\n\n**3. Utilities**\n   - `/catalyst-dev:commit` ‚Üí Create structured commits\n   - `/describe-pr` ‚Üí Generate PR descriptions\n   - `/catalyst-dev:debug` ‚Üí Investigate issues\n   - `/catalyst-dev:linear` ‚Üí Linear ticket integration\n\n---\n\n**Which workflow would you like to learn about?**\n\nType the number (1-3) or workflow name, or ask a question like:\n- \"I have a ticket to implement - what should I do?\"\n- \"How do I pause work and resume later?\"\n- \"What's the complete development workflow?\"\n```\n\nThen wait for user input.\n\n## Processing User Input\n\n### Step 1: Detect Context\n\nCheck if the user is already in a workflow by spawning parallel detection tasks:\n\n**Task 1 - Check for Active Work**:\n\n```\nUse codebase-locator agent:\n\"Search for recent uncommitted changes, work-in-progress files, or partial implementations. Look for:\n- Git status (uncommitted files)\n- WIP branches\n- Partial plan files with unchecked boxes\n- Draft handoffs\nReturn: Evidence of active work with file paths\"\n\nTools: Bash (git status), Grep, Glob\n```\n\n**Task 2 - Find Recent Documents**:\n\n```\nUse thoughts-locator agent (or Glob if no thoughts):\n\"Find the most recent research, plan, or handoff documents. Look in:\n- thoughts/shared/research/ (or research/)\n- thoughts/shared/plans/ (or plans/)\n- thoughts/shared/handoffs/ (or handoffs/)\nReturn: 3 most recent documents with dates and topics\"\n\nTools: Bash (ls -t), Grep, Glob\n```\n\n**Task 3 - Detect Worktree**:\n\n```\n\"Check if currently in a git worktree (not main repo).\nRun: pwd and git worktree list\nReturn: Whether in worktree, worktree name if applicable\"\n\nTools: Bash\n```\n\nWAIT for all tasks to complete.\n\n### Step 2: Analyze Context\n\nBased on detection results, determine user's current state:\n\n- **In Worktree with Plan** ‚Üí Likely in Implementation phase\n- **Recent Research Doc** ‚Üí May be ready for Planning\n- **Recent Plan Doc** ‚Üí May be ready for Implementation\n- **Recent Handoff** ‚Üí May want to resume\n- **No Active Work** ‚Üí Starting fresh\n\n### Step 3: Provide Context-Aware Guidance\n\n**If User is in Active Workflow:**\n\n```\nüéØ **I see you're currently working on {detected-context}**\n\n**Current State:**\n- {What I detected - be specific with file paths}\n- {Where you likely are in workflow}\n\n**Suggested Next Steps:**\n1. {Most likely next action}\n2. {Alternative action}\n3. {How to pause/handoff if needed}\n\n**Context Management:**\n‚ö†Ô∏è Remember to CLEAR CONTEXT between workflow phases!\n- Current phase: {detected-phase}\n- Clear context after: {when to clear}\n\n**Note**: I can monitor my own context usage and will proactively warn you if it gets high. You can also check anytime with `/context`.\n\nWould you like me to:\n1. Continue with next step\n2. Explain the complete workflow\n3. Help you pause/create handoff\n4. Something else\n```\n\n**If User is Starting Fresh:**\n\nProceed to workflow selection (Step 4).\n\n### Step 4: Workflow Selection\n\nBased on user's choice, spawn parallel research to provide comprehensive guidance:\n\n#### For Development Workflow (Option 1):\n\nSpawn 3 parallel research tasks:\n\n**Task 1 - Read Workflow Guide**:\n\n```\n\"Read docs/AGENTIC_WORKFLOW_GUIDE.md and extract:\n- Complete workflow phases\n- Context clearing guidelines\n- When to use each command\nReturn: Concise summary of complete workflow\"\n\nTools: Read\n```\n\n**Task 2 - Find Command Examples**:\n\n```\n\"Search for examples in:\n- commands/research_codebase.md\n- commands/create_plan.md\n- commands/implement_plan.md\nExtract example usage and common patterns\nReturn: Concrete examples users can follow\"\n\nTools: Read, Grep\n```\n\n**Task 3 - Check for User Files**:\n\n```\n\"Check if user has any existing research, plans, or handoffs.\nLook in thoughts/ or research/, plans/, handoffs/ directories.\nReturn: What files exist, suggesting next steps based on what's there\"\n\nTools: Glob, Bash\n```\n\nWAIT for all tasks.\n\n**Present Comprehensive Guide:**\n\n```\n# üîÑ Development Workflow: Research ‚Üí Plan ‚Üí Implement ‚Üí Validate ‚Üí PR\n\n{Synthesize findings from 3 parallel tasks}\n\n## Complete Process\n\n### Phase 1: Research üîç\n**When**: Need to understand existing codebase before planning\n**Command**: `/research-codebase`\n\n{Include example from Task 2}\n{Note any existing research docs from Task 3}\n\n**Output**: `thoughts/shared/research/YYYY-MM-DD-PROJ-XXXX-description.md`\n**After**: ‚úÖ **CLEAR CONTEXT**\n\n---\n\n### Phase 2: Planning üìã\n**When**: Ready to create implementation plan\n**Command**: `/create-plan`\n\n{Include example}\n\n**Output**: `thoughts/shared/plans/YYYY-MM-DD-PROJ-XXXX-description.md`\n**After**: ‚úÖ **CLEAR CONTEXT**\n\n---\n\n### Phase 3: Worktree Creation üå≤\n**When**: Plan approved, ready to implement\n**How**:\n\n\\`\\`\\`bash\n\"${CLAUDE_PLUGIN_ROOT}/scripts/create-worktree.sh\" PROJ-123 feature-name\ncd ~/wt/{project}/PROJ-123-feature\n\\`\\`\\`\n\n**After**: ‚úÖ **CLEAR CONTEXT** (fresh session in worktree)\n\n---\n\n### Phase 4: Implementation ‚öôÔ∏è\n**When**: In worktree with approved plan\n**Command**: `/implement-plan thoughts/shared/plans/YYYY-MM-DD-PROJ-XXXX-feature.md`\n\n{Include example}\n\n**Checkpoints**: After EACH phase in plan\n**After**: ‚úÖ **CLEAR CONTEXT**\n\n---\n\n### Phase 5: Validation ‚úÖ\n**When**: All implementation phases complete\n**Command**: `/validate-plan`\n\n**After**: ‚úÖ **CLEAR CONTEXT**\n\n---\n\n### Phase 6: PR Creation üöÄ\n**Commands**:\n\\`\\`\\`bash\n/catalyst-dev:commit\ngh pr create --fill\n/describe-pr\n\\`\\`\\`\n\n**Output**: `thoughts/shared/prs/pr_{number}_{description}.md`\n**After**: ‚úÖ **CLEAR CONTEXT** - workflow complete!\n\n---\n\n## üîÑ Handoff System (Pause/Resume)\n\n**Create Handoff** (to pause work):\n\\`\\`\\`bash\n/create-handoff\n\\`\\`\\`\n**Output**: `thoughts/shared/handoffs/PROJ-XXXX/YYYY-MM-DD_HH-MM-SS_description.md`\n\n**Resume Handoff**:\n\\`\\`\\`bash\n/resume-handoff {path-or-ticket}\n\\`\\`\\`\n\n---\n\n## ‚ö†Ô∏è Context Management\n\n**CLEAR CONTEXT between EVERY phase**\n- After research document created\n- After plan approved\n- After creating handoff\n- Before implementation in worktree\n- After implementation complete\n- Before validation\n- After PR created\n\n**Why?** Keeps AI performance optimal (40-60% context utilization)\n\n**How to check**: I monitor my context automatically and will warn you.\nYou can also check anytime with `/context` command.\n\n**When I warn you**:\n- I'll show current usage: e.g., \"65% (130K/200K tokens)\"\n- I'll explain why clearing helps\n- I'll offer to create a handoff if needed\n- I'll tell you exactly what to do next\n\n**Context clearing is NORMAL and EXPECTED** - it's how we maintain quality!\n\n---\n\n{Based on Task 3 - suggest next step}\n\n**Your Next Step:**\n{If existing files found:} You have {file} - ready to {next-action}?\n{If no files:} Start with: `/research-codebase` or `/create-plan`\n\n**Need more details on any phase?** Just ask!\n```\n\n#### For Workflow Discovery (Option 2):\n\nSpawn parallel research:\n\n**Task 1**: Read `docs/WORKFLOW_DISCOVERY_SYSTEM.md` **Task 2**: Read command files\n(discover_workflows, import_workflow, etc.) **Task 3**: Check if user has any workflow catalog\n\nWAIT and synthesize similar to above.\n\n#### For Utilities (Option 3):\n\nRead relevant command files and provide quick reference.\n\n### Step 5: Answer Follow-Up Questions\n\n**If user asks specific questions:**\n\nSpawn focused research tasks to answer:\n\n**Example**: \"How do I pause work and resume later?\"\n\n```\nTask 1: \"Read docs/AGENTIC_WORKFLOW_GUIDE.md section on Handoff System\"\nTask 2: \"Find examples in commands/create_handoff.md and commands/resume_handoff.md\"\nTask 3: \"Check if user has existing handoffs\"\n```\n\nPresent targeted answer with examples.\n\n### Step 6: Provide Quick Actions\n\n**Always end with actionable next steps:**\n\n```\n---\n\n## Ready to Get Started?\n\n**Quick Actions:**\n1. üìù Start research: `/research-codebase`\n2. üìã Create plan: `/create-plan`\n3. üîÑ Resume work: `/resume-handoff {ticket}`\n4. üîç Discover workflows: `/discover-workflows`\n5. ‚ùì Ask me anything else!\n\n**Pro Tips:**\n- Clear context between phases for best performance\n- Read outputs completely before next phase\n- Use handoffs liberally - context is precious\n- Worktrees isolate your changes safely\n\nType a command or ask another question!\n```\n\n## Important Guidelines\n\n### Context-Aware Assistance\n\n1. **Always detect current state first** using parallel agents\n2. **Don't assume** - verify with actual file checks\n3. **Be specific** with file paths and next actions\n4. **Remind about context clearing** at appropriate points\n\n### Compression & Conciseness\n\n1. **Parallel agents research details** - keep main context clean\n2. **Synthesize findings** - don't dump raw agent outputs\n3. **Provide examples** - concrete > abstract\n4. **Quick reference** - users can dive deeper if needed\n\n### Link to Documentation\n\n**Always provide links** to detailed documentation:\n\n- Full workflow: `docs/AGENTIC_WORKFLOW_GUIDE.md`\n- Workflow discovery: `docs/WORKFLOW_DISCOVERY_SYSTEM.md`\n- Frontmatter: `docs/FRONTMATTER_STANDARD.md`\n- Main README: `README.md`\n\n### Web Research (If Needed)\n\nIf user asks about external concepts:\n\n**Use external-research agent**:\n\n```\n\"Research {topic} from HumanLayer or Anthropic documentation.\nReturn: Summary with links to sources\"\n\nTools: WebSearch, WebFetch, mcp__deepwiki__ask_question\n```\n\nInclude links in response.\n\n## Example Interactions\n\n### Example 1: User in Middle of Workflow\n\n```\nUser: /workflow-help\n\n[Agent spawns 3 parallel detection tasks]\n\nAgent: üéØ **I see you're currently working on PROJ-123 OAuth implementation**\n\n**Current State:**\n- Worktree: `~/wt/my-project/PROJ-123-oauth`\n- Plan: `thoughts/shared/plans/2025-01-08-PROJ-123-oauth.md`\n- Status: Phase 2/4 complete (checkboxes updated)\n\n**You're in Implementation Phase**\n\n**Suggested Next Steps:**\n1. ‚úÖ Continue implementing Phase 3: `/implement-plan` (will resume from checkboxes)\n2. üîÑ Need to pause? `/create-handoff` before stopping\n3. üìñ Review plan: Check `thoughts/shared/plans/2025-01-08-PROJ-123-oauth.md`\n\n**Context Management:**\n‚ö†Ô∏è If context feels full (>60%), clear and resume with plan file\n\nWould you like me to:\n1. Continue with Phase 3\n2. Show complete workflow overview\n3. Help create handoff to pause work\n```\n\n### Example 2: User Starting Fresh\n\n```\nUser: I have a ticket to implement OAuth support\n\n[Agent spawns detection tasks - finds no active work]\n\nAgent: üéØ **Great! Let's start the Development Workflow for OAuth support**\n\nI don't see any existing research or plans for this, so let's start from the beginning.\n\n## Recommended Approach\n\n### Step 1: Research Phase üîç\nFirst, understand how authentication currently works:\n\n\\`\\`\\`\n/research-codebase\n\\`\\`\\`\n\nWhen prompted, ask: \"How does authentication currently work? What patterns exist?\"\n\n**Output**: `thoughts/shared/research/YYYY-MM-DD-PROJ-XXX-auth-system.md`\n\n**After research**: ‚úÖ **CLEAR CONTEXT** (close this conversation, start fresh)\n\n---\n\n### Step 2: Planning Phase üìã\nCreate implementation plan:\n\n\\`\\`\\`\n/create-plan\n\\`\\`\\`\n\nReference your research doc when planning.\n\n**Output**: `thoughts/shared/plans/YYYY-MM-DD-PROJ-XXX-oauth-support.md`\n\n**After plan approved**: ‚úÖ **CLEAR CONTEXT**\n\n---\n\n{Continue with remaining phases...}\n\n**Ready to start research?** Type `/research-codebase` or ask more questions!\n```\n\n### Example 3: Quick Question\n\n```\nUser: How do I pause work and resume later?\n\n[Agent reads handoff documentation]\n\nAgent: üîÑ **Pausing and Resuming Work**\n\nUse the **Handoff System** to pause/resume:\n\n### To Pause:\n\\`\\`\\`bash\n/create-handoff\n\\`\\`\\`\n\nCreates: `thoughts/shared/handoffs/PROJ-XXXX/YYYY-MM-DD_HH-MM-SS_description.md`\n\nThe handoff captures:\n- Current progress\n- Critical file references\n- Next action items\n- Blockers/questions\n\n**After creating handoff**: ‚úÖ **CLEAR CONTEXT** - you can safely stop\n\n---\n\n### To Resume:\n\\`\\`\\`bash\n/resume-handoff thoughts/shared/handoffs/PROJ-123/2025-01-08_14-30-45_oauth.md\n\\`\\`\\`\n\nOr if command supports:\n\\`\\`\\`bash\n/resume-handoff PROJ-123  # Finds latest handoff\n\\`\\`\\`\n\n**The resume process:**\n1. Reads handoff + linked docs\n2. Verifies current state\n3. Proposes next actions\n4. Continues where you left off\n\n---\n\n**Pro Tip**: Create handoffs liberally! Any time:\n- End of day\n- Context fills up (>60%)\n- Need to switch tasks\n- Blocked and need input\n\nSee full guide: `docs/AGENTIC_WORKFLOW_GUIDE.md` (Handoff System section)\n\n**Anything else?**\n```\n\n## Advanced Features\n\n### Workflow State Detection\n\nThe parallel agents can detect:\n\n- Current git branch\n- Worktree vs main repo\n- Recent files modified\n- Plan files with checkboxes\n- Research documents\n- Handoff documents\n- PR status\n\n### Personalized Guidance\n\nBased on detected state, provide:\n\n- Specific file paths to reference\n- Exact commands to run next\n- Progress indicators (Phase X of Y)\n- Context clearing reminders at right moments\n\n### Link to External Resources\n\nWhen relevant, include links:\n\n```\n**Further Reading:**\n- [HumanLayer Advanced Context Engineering](https://github.com/humanlayer/advanced-context-engineering-for-coding-agents)\n- [12 Factor Agents](https://github.com/humanlayer/12-factor-agents)\n- [Anthropic Best Practices](https://www.anthropic.com/engineering/claude-code-best-practices)\n```\n\n## Important Notes\n\n- **Use parallel agents** to research docs - keeps main context clean\n- **Be context-aware** - detect where user is in workflow\n- **Provide concrete examples** - not just theory\n- **Remind about context clearing** - critical for performance\n- **Link to detailed docs** - comprehensive info available\n- **Quick actionable steps** - users can start immediately\n- **Follow-up friendly** - can answer deeper questions\n\nThis command serves as an interactive, intelligent guide to the entire workflow system!"
              }
            ],
            "skills": []
          }
        ]
      }
    }
  ]
}