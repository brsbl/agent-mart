{
  "owner": {
    "id": "nprbst",
    "display_name": "Nathan Probst",
    "type": "User",
    "avatar_url": "https://avatars.githubusercontent.com/u/1227125?u=79256a357debcd21efc17bbdaf41837d9a266f8d&v=4",
    "url": "https://github.com/nprbst",
    "bio": null,
    "stats": {
      "total_repos": 1,
      "total_plugins": 2,
      "total_commands": 18,
      "total_skills": 3,
      "total_stars": 0,
      "total_forks": 0
    }
  },
  "repos": [
    {
      "full_name": "nprbst/speck-market",
      "url": "https://github.com/nprbst/speck-market",
      "description": "Speck Marketplace",
      "homepage": null,
      "signals": {
        "stars": 0,
        "forks": 0,
        "pushed_at": "2025-12-07T19:58:52Z",
        "created_at": "2025-11-16T17:13:07Z",
        "license": null
      },
      "file_tree": [
        {
          "path": ".claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude-plugin/marketplace.json",
          "type": "blob",
          "size": 1387
        },
        {
          "path": "CHANGELOG.md",
          "type": "blob",
          "size": 19275
        },
        {
          "path": "README.md",
          "type": "blob",
          "size": 1456
        },
        {
          "path": "speck-reviewer",
          "type": "tree",
          "size": null
        },
        {
          "path": "speck-reviewer/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "speck-reviewer/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 458
        },
        {
          "path": "speck-reviewer/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "speck-reviewer/commands/init.md",
          "type": "blob",
          "size": 2747
        },
        {
          "path": "speck-reviewer/commands/review.md",
          "type": "blob",
          "size": 3351
        },
        {
          "path": "speck-reviewer/dist",
          "type": "tree",
          "size": null
        },
        {
          "path": "speck-reviewer/dist/speck-review.js",
          "type": "blob",
          "size": 49692
        },
        {
          "path": "speck-reviewer/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "speck-reviewer/skills/pr-review",
          "type": "tree",
          "size": null
        },
        {
          "path": "speck-reviewer/skills/pr-review/SKILL.md",
          "type": "blob",
          "size": 31439
        },
        {
          "path": "speck-reviewer/src",
          "type": "tree",
          "size": null
        },
        {
          "path": "speck-reviewer/src/cli",
          "type": "tree",
          "size": null
        },
        {
          "path": "speck-reviewer/src/cli/bootstrap.sh",
          "type": "blob",
          "size": 1903
        },
        {
          "path": "speck",
          "type": "tree",
          "size": null
        },
        {
          "path": "speck/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "speck/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 710
        },
        {
          "path": "speck/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "speck/commands/analyze.md",
          "type": "blob",
          "size": 7670
        },
        {
          "path": "speck/commands/checklist.md",
          "type": "blob",
          "size": 17257
        },
        {
          "path": "speck/commands/clarify.md",
          "type": "blob",
          "size": 11705
        },
        {
          "path": "speck/commands/constitution.md",
          "type": "blob",
          "size": 5522
        },
        {
          "path": "speck/commands/env.md",
          "type": "blob",
          "size": 1000
        },
        {
          "path": "speck/commands/help.md",
          "type": "blob",
          "size": 2205
        },
        {
          "path": "speck/commands/implement.md",
          "type": "blob",
          "size": 7846
        },
        {
          "path": "speck/commands/init.md",
          "type": "blob",
          "size": 3515
        },
        {
          "path": "speck/commands/inquiries.md",
          "type": "blob",
          "size": 6844
        },
        {
          "path": "speck/commands/link.md",
          "type": "blob",
          "size": 1505
        },
        {
          "path": "speck/commands/plan.md",
          "type": "blob",
          "size": 7041
        },
        {
          "path": "speck/commands/specify.md",
          "type": "blob",
          "size": 14589
        },
        {
          "path": "speck/commands/tasks.md",
          "type": "blob",
          "size": 10012
        },
        {
          "path": "speck/commands/taskstoissues.md",
          "type": "blob",
          "size": 1381
        },
        {
          "path": "speck/dist",
          "type": "tree",
          "size": null
        },
        {
          "path": "speck/dist/branch-command-9d1ws535.js",
          "type": "blob",
          "size": 19132
        },
        {
          "path": "speck/dist/branch-command-e4v7vp7f.js",
          "type": "blob",
          "size": 19339
        },
        {
          "path": "speck/dist/branch-command-xmqtg052.js",
          "type": "blob",
          "size": 19605
        },
        {
          "path": "speck/dist/create-new-feature-ge2f0p7p.js",
          "type": "blob",
          "size": 6797
        },
        {
          "path": "speck/dist/create-new-feature-na4fe1gk.js",
          "type": "blob",
          "size": 6751
        },
        {
          "path": "speck/dist/env-command-29yhkjew.js",
          "type": "blob",
          "size": 5709
        },
        {
          "path": "speck/dist/env-command-d62v6w5f.js",
          "type": "blob",
          "size": 5291
        },
        {
          "path": "speck/dist/env-command-mnga9796.js",
          "type": "blob",
          "size": 5490
        },
        {
          "path": "speck/dist/link-repo-4j4x71db.js",
          "type": "blob",
          "size": 3258
        },
        {
          "path": "speck/dist/link-repo-sm3nten3.js",
          "type": "blob",
          "size": 3274
        },
        {
          "path": "speck/dist/paths-qqmkr5wb.js",
          "type": "blob",
          "size": 10500
        },
        {
          "path": "speck/dist/paths-x5kskk5z.js",
          "type": "blob",
          "size": 10386
        },
        {
          "path": "speck/dist/pre-prompt-submit-hook.js",
          "type": "blob",
          "size": 37517
        },
        {
          "path": "speck/dist/setup-plan-dgdja63m.js",
          "type": "blob",
          "size": 2330
        },
        {
          "path": "speck/dist/setup-plan-dgms79yg.js",
          "type": "blob",
          "size": 2346
        },
        {
          "path": "speck/dist/speck-7546wgqm.js",
          "type": "blob",
          "size": 69536
        },
        {
          "path": "speck/dist/speck-ac2ebaf8.js",
          "type": "blob",
          "size": 8
        },
        {
          "path": "speck/dist/speck-cli.js",
          "type": "blob",
          "size": 347844
        },
        {
          "path": "speck/dist/speck-hook.js",
          "type": "blob",
          "size": 184172
        },
        {
          "path": "speck/dist/speck-v4perbmj.js",
          "type": "blob",
          "size": 69607
        },
        {
          "path": "speck/dist/test-bundle.js",
          "type": "blob",
          "size": 167693
        },
        {
          "path": "speck/dist/update-agent-context-8hxmk24f.js",
          "type": "blob",
          "size": 7059
        },
        {
          "path": "speck/dist/update-agent-context-j5xabq9h.js",
          "type": "blob",
          "size": 7012
        },
        {
          "path": "speck/hooks",
          "type": "tree",
          "size": null
        },
        {
          "path": "speck/hooks/hooks.json",
          "type": "blob",
          "size": 244
        },
        {
          "path": "speck/hooks/setup-env.sh",
          "type": "blob",
          "size": 1089
        },
        {
          "path": "speck/memory",
          "type": "tree",
          "size": null
        },
        {
          "path": "speck/memory/constitution.md",
          "type": "blob",
          "size": 2346
        },
        {
          "path": "speck/scripts",
          "type": "tree",
          "size": null
        },
        {
          "path": "speck/scripts/check-prerequisites.ts",
          "type": "blob",
          "size": 22016
        },
        {
          "path": "speck/scripts/common",
          "type": "tree",
          "size": null
        },
        {
          "path": "speck/scripts/common/branch-mapper.ts",
          "type": "blob",
          "size": 13560
        },
        {
          "path": "speck/scripts/common/errors.ts",
          "type": "blob",
          "size": 666
        },
        {
          "path": "speck/scripts/common/file-ops.ts",
          "type": "blob",
          "size": 5638
        },
        {
          "path": "speck/scripts/common/git-operations.ts",
          "type": "blob",
          "size": 8436
        },
        {
          "path": "speck/scripts/common/github-api.ts",
          "type": "blob",
          "size": 4988
        },
        {
          "path": "speck/scripts/common/json-tracker.ts",
          "type": "blob",
          "size": 4918
        },
        {
          "path": "speck/scripts/common/paths.ts",
          "type": "blob",
          "size": 35816
        },
        {
          "path": "speck/scripts/common/staging-manager.ts",
          "type": "blob",
          "size": 18239
        },
        {
          "path": "speck/scripts/common/staging-types.ts",
          "type": "blob",
          "size": 8103
        },
        {
          "path": "speck/scripts/common/symlink-manager.ts",
          "type": "blob",
          "size": 5576
        },
        {
          "path": "speck/scripts/common/transformation-history.ts",
          "type": "blob",
          "size": 9634
        },
        {
          "path": "speck/scripts/contracts",
          "type": "tree",
          "size": null
        },
        {
          "path": "speck/scripts/contracts/cli-interface.ts",
          "type": "blob",
          "size": 5079
        },
        {
          "path": "speck/scripts/contracts/github-api.ts",
          "type": "blob",
          "size": 3648
        },
        {
          "path": "speck/scripts/contracts/release-registry.ts",
          "type": "blob",
          "size": 7010
        },
        {
          "path": "speck/scripts/contracts/test-utilities.ts",
          "type": "blob",
          "size": 7427
        },
        {
          "path": "speck/scripts/create-new-feature.ts",
          "type": "blob",
          "size": 29433
        },
        {
          "path": "speck/scripts/lib",
          "type": "tree",
          "size": null
        },
        {
          "path": "speck/scripts/lib/arg-parser.ts",
          "type": "blob",
          "size": 3065
        },
        {
          "path": "speck/scripts/lib/error-handler.ts",
          "type": "blob",
          "size": 3630
        },
        {
          "path": "speck/scripts/lib/logger.ts",
          "type": "blob",
          "size": 5100
        },
        {
          "path": "speck/scripts/lib/output-formatter.ts",
          "type": "blob",
          "size": 11662
        },
        {
          "path": "speck/scripts/lib/prereq-cache.ts",
          "type": "blob",
          "size": 1972
        },
        {
          "path": "speck/scripts/lib/prereq-runner.ts",
          "type": "blob",
          "size": 6875
        },
        {
          "path": "speck/scripts/lib/shell-escape.ts",
          "type": "blob",
          "size": 1549
        },
        {
          "path": "speck/scripts/lib/types.ts",
          "type": "blob",
          "size": 2461
        },
        {
          "path": "speck/scripts/setup-plan.ts",
          "type": "blob",
          "size": 6889
        },
        {
          "path": "speck/scripts/update-agent-context.ts",
          "type": "blob",
          "size": 11921
        },
        {
          "path": "speck/scripts/worktree",
          "type": "tree",
          "size": null
        },
        {
          "path": "speck/scripts/worktree/cli-create.ts",
          "type": "blob",
          "size": 3305
        },
        {
          "path": "speck/scripts/worktree/cli-init.ts",
          "type": "blob",
          "size": 10048
        },
        {
          "path": "speck/scripts/worktree/cli-launch-ide.ts",
          "type": "blob",
          "size": 3161
        },
        {
          "path": "speck/scripts/worktree/cli-list.ts",
          "type": "blob",
          "size": 2161
        },
        {
          "path": "speck/scripts/worktree/cli-prune.ts",
          "type": "blob",
          "size": 1965
        },
        {
          "path": "speck/scripts/worktree/cli-remove.ts",
          "type": "blob",
          "size": 1618
        },
        {
          "path": "speck/scripts/worktree/cli.ts",
          "type": "blob",
          "size": 6983
        },
        {
          "path": "speck/scripts/worktree/config-schema.ts",
          "type": "blob",
          "size": 8438
        },
        {
          "path": "speck/scripts/worktree/config.ts",
          "type": "blob",
          "size": 3654
        },
        {
          "path": "speck/scripts/worktree/create.ts",
          "type": "blob",
          "size": 7888
        },
        {
          "path": "speck/scripts/worktree/deps-install.ts",
          "type": "blob",
          "size": 7069
        },
        {
          "path": "speck/scripts/worktree/errors.ts",
          "type": "blob",
          "size": 2161
        },
        {
          "path": "speck/scripts/worktree/file-ops.ts",
          "type": "blob",
          "size": 9341
        },
        {
          "path": "speck/scripts/worktree/git.ts",
          "type": "blob",
          "size": 6274
        },
        {
          "path": "speck/scripts/worktree/handoff.ts",
          "type": "blob",
          "size": 19218
        },
        {
          "path": "speck/scripts/worktree/ide-launch.ts",
          "type": "blob",
          "size": 4850
        },
        {
          "path": "speck/scripts/worktree/naming.ts",
          "type": "blob",
          "size": 5190
        },
        {
          "path": "speck/scripts/worktree/remove.ts",
          "type": "blob",
          "size": 2738
        },
        {
          "path": "speck/scripts/worktree/types.ts",
          "type": "blob",
          "size": 7250
        },
        {
          "path": "speck/scripts/worktree/validation.ts",
          "type": "blob",
          "size": 4299
        },
        {
          "path": "speck/scripts/worktree/workflows.ts",
          "type": "blob",
          "size": 3754
        },
        {
          "path": "speck/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "speck/skills/speck-help",
          "type": "tree",
          "size": null
        },
        {
          "path": "speck/skills/speck-help/SKILL.md",
          "type": "blob",
          "size": 15126
        },
        {
          "path": "speck/skills/speck-help/examples.md",
          "type": "blob",
          "size": 7368
        },
        {
          "path": "speck/skills/speck-help/reference.md",
          "type": "blob",
          "size": 23944
        },
        {
          "path": "speck/skills/speck-help/workflows.md",
          "type": "blob",
          "size": 10588
        },
        {
          "path": "speck/src",
          "type": "tree",
          "size": null
        },
        {
          "path": "speck/src/cli",
          "type": "tree",
          "size": null
        },
        {
          "path": "speck/src/cli/bootstrap.sh",
          "type": "blob",
          "size": 5411
        },
        {
          "path": "speck/templates",
          "type": "tree",
          "size": null
        },
        {
          "path": "speck/templates/agent-file-template.md",
          "type": "blob",
          "size": 464
        },
        {
          "path": "speck/templates/checklist-template.md",
          "type": "blob",
          "size": 1312
        },
        {
          "path": "speck/templates/constitution-template.md",
          "type": "blob",
          "size": 2346
        },
        {
          "path": "speck/templates/plan-template.md",
          "type": "blob",
          "size": 3671
        },
        {
          "path": "speck/templates/spec-template.md",
          "type": "blob",
          "size": 3960
        },
        {
          "path": "speck/templates/tasks-template.md",
          "type": "blob",
          "size": 9177
        }
      ],
      "marketplace": {
        "name": "speck-market",
        "version": null,
        "description": null,
        "owner_info": {
          "name": "Nathan Prabst",
          "email": "nathan@example.com"
        },
        "keywords": [],
        "plugins": [
          {
            "name": "speck",
            "description": "Specification and planning workflow framework for Claude Code",
            "source": "./speck",
            "category": "development-tools",
            "version": "1.10.2",
            "author": {
              "name": "Nathan Prabst"
            },
            "install_commands": [
              "/plugin marketplace add nprbst/speck-market",
              "/plugin install speck@speck-market"
            ],
            "signals": {
              "stars": 0,
              "forks": 0,
              "pushed_at": "2025-12-07T19:58:52Z",
              "created_at": "2025-11-16T17:13:07Z",
              "license": null
            },
            "commands": [
              {
                "name": "/init",
                "description": "Install speck-review CLI globally and configure auto-allow permissions",
                "path": "speck-reviewer/commands/init.md",
                "frontmatter": {
                  "description": "Install speck-review CLI globally and configure auto-allow permissions"
                },
                "content": "## Speck-Reviewer Initialization\n\nThis command installs the `speck-review` CLI globally and configures auto-allow permissions for seamless PR reviews.\n\n### What This Does\n\n1. Creates `~/.local/bin` directory if it doesn't exist\n2. Creates symlink at `~/.local/bin/speck-review` pointing to the bootstrap script\n3. Configures auto-allow permissions for GitHub CLI and speck-review commands\n4. Adds `review-state.json` to `.speck/.gitignore`\n5. Verifies the installation\n\n### Prerequisites\n\n- Bun runtime installed (https://bun.sh)\n- GitHub CLI installed and authenticated (`gh auth login`)\n\n### Installation Steps\n\nRun these commands in order:\n\n```bash\n# 1. Verify plugin is built (dist/ should exist)\nls \"${CLAUDE_PLUGIN_ROOT}/dist/speck-review.js\" || echo \"Warning: Plugin not built yet\"\n\n# 2. Create ~/.local/bin if it doesn't exist\nmkdir -p ~/.local/bin\n\n# 3. Create symlink to bootstrap.sh\nln -sf \"${CLAUDE_PLUGIN_ROOT}/src/cli/bootstrap.sh\" ~/.local/bin/speck-review\n\n# 4. Verify installation\nspeck-review version\n```\n\n### Auto-Allow Permissions\n\nAfter CLI installation succeeds, configure auto-allow permissions by adding these entries to `.claude/settings.local.json` in the repository root. Create the file if it doesn't exist.\n\n**Required permissions:**\n```json\n{\n  \"permissions\": {\n    \"allow\": [\n      \"Read(~/.claude/plugins/marketplaces/speck-market/speck-reviewer/skills/**)\",\n      \"Bash(gh pr list:*)\",\n      \"Bash(gh pr view:*)\",\n      \"Bash(gh pr diff:*)\",\n      \"Bash(gh api:*)\",\n      \"Bash(gh auth status:*)\",\n      \"Bash(speck-review:*)\"\n    ]\n  }\n}\n```\n\nIf `.claude/settings.local.json` already exists, merge these permissions into the existing `allow` array. Do not remove existing permissions.\n\n### Configure .gitignore\n\nAdd `review-state.json` to `.speck/.gitignore` to prevent committing machine-specific review state.\n\n**If `.speck/.gitignore` exists:** Read it, and if `review-state.json` is not already present, add it to the file using the Edit tool.\n\n**If `.speck/.gitignore` does not exist:** Create it with:\n```\n# Machine-specific files\nreview-state.json\n```\n\n### PATH Configuration\n\nIf `speck-review version` fails with \"command not found\", add `~/.local/bin` to your PATH.\n\n**For zsh** (`~/.zshrc`):\n```bash\nexport PATH=\"$HOME/.local/bin:$PATH\"\n```\n\n**For bash** (`~/.bashrc`):\n```bash\nexport PATH=\"$HOME/.local/bin:$PATH\"\n```\n\nThen reload your shell: `source ~/.zshrc` or `source ~/.bashrc`\n\n### Verification\n\nAfter installation, verify the CLI is working:\n\n```bash\nwhich speck-review\nspeck-review help\ngh auth status\n```\n\nIf `which speck-review` returns `~/.local/bin/speck-review`, the installation was successful."
              },
              {
                "name": "/review",
                "description": "Review a GitHub pull request with Speck-aware context",
                "path": "speck-reviewer/commands/review.md",
                "frontmatter": {
                  "description": "Review a GitHub pull request with Speck-aware context",
                  "argument-hint": [
                    "pr-number"
                  ]
                },
                "content": "# PR Review Command\n\nFirst, use the Read tool to load the skill instructions from\n`${CLAUDE_PLUGIN_ROOT}/skills/pr-review/SKILL.md`, then follow those\ninstructions to review the specified PR.\n\n## Arguments\n\n- `$ARGUMENTS`: Optional PR number. If not provided, detects the current PR from\n  the checked-out branch or finds PRs where user is assigned/requested.\n\n## Prerequisites\n\n- `gh` CLI installed and authenticated (`gh auth login`)\n- Git repository with PR access\n\n## Planning Phase\n\nExecute these steps in order:\n\n### 1. Identify PR\n\nIf PR number provided: `$ARGUMENTS` If no PR number: Find open PRs where user is\nassigned or requested as reviewer using the method in the skill.\n\n### 2. Load Existing State\n\nCheck for existing review state:\n\n```bash\nspeck-review state show\n```\n\n**If exit code 127 (command not found):** Stop and tell the user:\n\n> The `speck-review` CLI is not installed. Please run `/speck-reviewer:init` to install it globally, then try this command again.\n\nIf state exists for this PR:\n\n- Show progress summary (reviewed clusters, pending comments)\n- Offer to resume or start fresh\n- If resuming, skip to walkthrough with current progress\n\nIf state is for a different PR or branch:\n\n- Warn about stale state\n- Offer to clear and start fresh\n\n### 3. Fetch PR Metadata\n\n```bash\ngh pr view <PR_NUMBER> --json title,body,state,author,baseRefName,headRefName,additions,deletions,changedFiles,url\n```\n\n### 4. Run Clustering Analysis\n\n```bash\nspeck-review analyze <PR_NUMBER>\n```\n\nThis returns heuristic clusters. Refine them using LLM augmentation as described\nin the skill.\n\n### 5. Check Self-Review Mode\n\n```bash\nspeck-review check-self-review <PR_AUTHOR>\n```\n\n### 6. Load Speck Context (if available)\n\n```bash\nspeck-review spec-context\n```\n\nIf spec exists for the branch, include requirements in review context. If no\nspec, proceed with standard review (graceful degradation).\n\n### 7. Generate PR Narrative\n\nUsing the PR body, commit history, and cluster analysis, generate a narrative\nthat:\n\n- References what the author said in the PR description\n- Explains the story of changes\n- Highlights cross-cutting concerns (config, deps, migrations)\n\n### 8. Present Cluster Overview\n\nShow the refined clusters with:\n\n- Semantic names (not just directory paths)\n- Why each cluster matters\n- Dependencies between clusters\n- Priority order for review\n\n### 9. Initialize State\n\nUse the Write tool to save the initial review state to\n`.speck/review-state.json` with:\n\n- PR metadata (number, title, author, branches)\n- Generated narrative\n- Refined clusters\n- Review mode (normal or self-review)\n\nSee the state schema in SKILL.md for the exact JSON structure.\n\n### 10. Begin Guided Walkthrough\n\nStart the cluster-by-cluster review as described in the skill.\n\n## Quick Commands\n\nDuring review, users can say:\n\n- \"next\" - advance to next cluster\n- \"back\" - return to previous cluster\n- \"where am I?\" - show current progress\n- \"show clusters\" - list all clusters with status\n- \"skip 2\" - skip comment #2\n- \"restore 2\" - bring back skipped comment\n- \"reword 1 to be friendlier\" - modify comment #1\n- \"post 1, 3\" - post specific comments\n- \"post all\" - post all staged comments\n- \"post all then approve\" - post staged comments and approve PR"
              },
              {
                "name": "/analyze",
                "description": "Perform a non-destructive cross-artifact consistency and quality analysis across spec.md, plan.md, and tasks.md after task generation.",
                "path": "speck/commands/analyze.md",
                "frontmatter": {
                  "description": "Perform a non-destructive cross-artifact consistency and quality analysis across spec.md, plan.md, and tasks.md after task generation."
                },
                "content": "## User Input\n\n```text\n$ARGUMENTS\n```\n\nYou **MUST** consider the user input before proceeding (if not empty).\n\n## Goal\n\nIdentify inconsistencies, duplications, ambiguities, and underspecified items across the three core artifacts (`spec.md`, `plan.md`, `tasks.md`) before implementation. This command MUST run only after `/speck:tasks` has successfully produced a complete `tasks.md`.\n\n## Operating Constraints\n\n**STRICTLY READ-ONLY**: Do **not** modify any files. Output a structured analysis report. Offer an optional remediation plan (user must explicitly approve before any follow-up editing commands would be invoked manually).\n\n**Constitution Authority**: The project constitution (`.speck/memory/constitution.md`) is **non-negotiable** within this analysis scope. Constitution conflicts are automatically CRITICAL and require adjustment of the spec, plan, or tasks‚Äînot dilution, reinterpretation, or silent ignoring of the principle. If a principle itself needs to change, that must occur in a separate, explicit constitution update outside `/speck:analyze`.\n\n## Execution Steps\n\n### 1. Initialize Analysis Context\n\nExtract prerequisite context from the auto-injected comment in the prompt:\n```\n<!-- SPECK_PREREQ_CONTEXT\n{\"MODE\":\"single-repo\",\"FEATURE_DIR\":\"/path/to/specs/010-feature\",\"AVAILABLE_DOCS\":[\"specs/010-feature/spec.md\",\"specs/010-feature/plan.md\",\"specs/010-feature/tasks.md\",\".speck/memory/constitution.md\"]}\n-->\n```\nUse FEATURE_DIR and AVAILABLE_DOCS from this JSON.\n\n**Fallback**: If the comment is not present (VSCode hook bug), run:\n```bash\nspeck check-prerequisites --json --require-tasks --include-tasks\n```\n\nParse JSON output to extract FEATURE_DIR and AVAILABLE_DOCS.\n\n**IMPORTANT**: Do NOT invent or guess CLI paths. Use ONLY the path above.\n\nAbort with an error message if any required file is missing (instruct the user to run missing prerequisite command).\n\n### 2. Load Artifacts (Progressive Disclosure)\n\nUse Read tool to load files from paths in AVAILABLE_DOCS. Load only the minimal necessary context from each artifact:\n\n**From spec.md:**\n\n- Overview/Context\n- Functional Requirements\n- Non-Functional Requirements\n- User Stories\n- Edge Cases (if present)\n\n**From plan.md:**\n\n- Architecture/stack choices\n- Data Model references\n- Phases\n- Technical constraints\n\n**From tasks.md:**\n\n- Task IDs\n- Descriptions\n- Phase grouping\n- Parallel markers [P]\n- Referenced file paths\n\n**From constitution.md:**\n\n- Principle validation rules\n\n### 3. Build Semantic Models\n\nCreate internal representations (do not include raw artifacts in output):\n\n- **Requirements inventory**: Each functional + non-functional requirement with a stable key (derive slug based on imperative phrase; e.g., \"User can upload file\" ‚Üí `user-can-upload-file`)\n- **User story/action inventory**: Discrete user actions with acceptance criteria\n- **Task coverage mapping**: Map each task to one or more requirements or stories (inference by keyword / explicit reference patterns like IDs or key phrases)\n- **Constitution rule set**: Extract principle names and MUST/SHOULD normative statements\n\n### 4. Detection Passes (Token-Efficient Analysis)\n\nFocus on high-signal findings. Limit to 50 findings total; aggregate remainder in overflow summary.\n\n#### A. Duplication Detection\n\n- Identify near-duplicate requirements\n- Mark lower-quality phrasing for consolidation\n\n#### B. Ambiguity Detection\n\n- Flag vague adjectives (fast, scalable, secure, intuitive, robust) lacking measurable criteria\n- Flag unresolved placeholders (TODO, TKTK, ???, `<placeholder>`, etc.)\n\n#### C. Underspecification\n\n- Requirements with verbs but missing object or measurable outcome\n- User stories missing acceptance criteria alignment\n- Tasks referencing files or components not defined in spec/plan\n\n#### D. Constitution Alignment\n\n- Any requirement or plan element conflicting with a MUST principle\n- Missing mandated sections or quality gates from constitution\n\n#### E. Coverage Gaps\n\n- Requirements with zero associated tasks\n- Tasks with no mapped requirement/story\n- Non-functional requirements not reflected in tasks (e.g., performance, security)\n\n#### F. Inconsistency\n\n- Terminology drift (same concept named differently across files)\n- Data entities referenced in plan but absent in spec (or vice versa)\n- Task ordering contradictions (e.g., integration tasks before foundational setup tasks without dependency note)\n- Conflicting requirements (e.g., one requires Next.js while other specifies Vue)\n\n### 5. Severity Assignment\n\nUse this heuristic to prioritize findings:\n\n- **CRITICAL**: Violates constitution MUST, missing core spec artifact, or requirement with zero coverage that blocks baseline functionality\n- **HIGH**: Duplicate or conflicting requirement, ambiguous security/performance attribute, untestable acceptance criterion\n- **MEDIUM**: Terminology drift, missing non-functional task coverage, underspecified edge case\n- **LOW**: Style/wording improvements, minor redundancy not affecting execution order\n\n### 6. Produce Compact Analysis Report\n\nOutput a Markdown report (no file writes) with the following structure:\n\n## Specification Analysis Report\n\n| ID | Category | Severity | Location(s) | Summary | Recommendation |\n|----|----------|----------|-------------|---------|----------------|\n| A1 | Duplication | HIGH | spec.md:L120-134 | Two similar requirements ... | Merge phrasing; keep clearer version |\n\n(Add one row per finding; generate stable IDs prefixed by category initial.)\n\n**Coverage Summary Table:**\n\n| Requirement Key | Has Task? | Task IDs | Notes |\n|-----------------|-----------|----------|-------|\n\n**Constitution Alignment Issues:** (if any)\n\n**Unmapped Tasks:** (if any)\n\n**Metrics:**\n\n- Total Requirements\n- Total Tasks\n- Coverage % (requirements with >=1 task)\n- Ambiguity Count\n- Duplication Count\n- Critical Issues Count\n\n### 7. Provide Next Actions\n\nAt end of report, output a concise Next Actions block:\n\n- If CRITICAL issues exist: Recommend resolving before `/speck:implement`\n- If only LOW/MEDIUM: User may proceed, but provide improvement suggestions\n- Provide explicit command suggestions: e.g., \"Run /speck:specify with refinement\", \"Run /speck:plan to adjust architecture\", \"Manually edit tasks.md to add coverage for 'performance-metrics'\"\n\n### 8. Offer Remediation\n\nAsk the user: \"Would you like me to suggest concrete remediation edits for the top N issues?\" (Do NOT apply them automatically.)\n\n**CRITICAL**: If remediation edits are approved and applied, any tasks that are modified with new requirements MUST be unchecked (changed from `[X]` to `[ ]`) in tasks.md so they will be re-implemented with the updated requirements.\n\n## Operating Principles\n\n### Context Efficiency\n\n- **Minimal high-signal tokens**: Focus on actionable findings, not exhaustive documentation\n- **Progressive disclosure**: Load artifacts incrementally; don't dump all content into analysis\n- **Token-efficient output**: Limit findings table to 50 rows; summarize overflow\n- **Deterministic results**: Rerunning without changes should produce consistent IDs and counts\n\n### Analysis Guidelines\n\n- **NEVER modify files** (this is read-only analysis)\n- **NEVER hallucinate missing sections** (if absent, report them accurately)\n- **Prioritize constitution violations** (these are always CRITICAL)\n- **Use examples over exhaustive rules** (cite specific instances, not generic patterns)\n- **Report zero issues gracefully** (emit success report with coverage statistics)\n\n## Context\n\n$ARGUMENTS"
              },
              {
                "name": "/checklist",
                "description": "Generate a custom checklist for the current feature based on user requirements.",
                "path": "speck/commands/checklist.md",
                "frontmatter": {
                  "description": "Generate a custom checklist for the current feature based on user requirements."
                },
                "content": "## Checklist Purpose: \"Unit Tests for English\"\n\n**CRITICAL CONCEPT**: Checklists are **UNIT TESTS FOR REQUIREMENTS WRITING** - they validate the quality, clarity, and completeness of requirements in a given domain.\n\n**NOT for verification/testing**:\n\n- ‚ùå NOT \"Verify the button clicks correctly\"\n- ‚ùå NOT \"Test error handling works\"\n- ‚ùå NOT \"Confirm the API returns 200\"\n- ‚ùå NOT checking if code/implementation matches the spec\n\n**FOR requirements quality validation**:\n\n- ‚úÖ \"Are visual hierarchy requirements defined for all card types?\" (completeness)\n- ‚úÖ \"Is 'prominent display' quantified with specific sizing/positioning?\" (clarity)\n- ‚úÖ \"Are hover state requirements consistent across all interactive elements?\" (consistency)\n- ‚úÖ \"Are accessibility requirements defined for keyboard navigation?\" (coverage)\n- ‚úÖ \"Does the spec define what happens when logo image fails to load?\" (edge cases)\n\n**Metaphor**: If your spec is code written in English, the checklist is its unit test suite. You're testing whether the requirements are well-written, complete, unambiguous, and ready for implementation - NOT whether the implementation works.\n\n## User Input\n\n```text\n$ARGUMENTS\n```\n\nYou **MUST** consider the user input before proceeding (if not empty).\n\n## Execution Steps\n\n1. **Setup**: Extract prerequisite context from the auto-injected comment in the prompt:\n   ```\n   <!-- SPECK_PREREQ_CONTEXT\n   {\"MODE\":\"single-repo\",\"FEATURE_DIR\":\"/path/to/specs/010-feature\",\"TEMPLATE_DIR\":\"/path/to/plugin/templates\",\"AVAILABLE_DOCS\":[\"specs/010-feature/spec.md\",\"specs/010-feature/plan.md\",\"specs/010-feature/tasks.md\"]}\n   -->\n   ```\n   Use the FEATURE_DIR, TEMPLATE_DIR, and AVAILABLE_DOCS values from this JSON.\n\n   **Fallback**: If the comment is not present (VSCode hook bug), run:\n   ```bash\n   speck check-prerequisites --json\n   ```\n\n   Parse JSON output to extract FEATURE_DIR and AVAILABLE_DOCS.\n\n   **IMPORTANT**: Do NOT invent or guess CLI paths. Use ONLY the path above.\n\n2. **Clarify intent (dynamic)**: Derive up to THREE initial contextual clarifying questions (no pre-baked catalog). They MUST:\n   - Be generated from the user's phrasing + extracted signals from spec/plan/tasks\n   - Only ask about information that materially changes checklist content\n   - Be skipped individually if already unambiguous in `$ARGUMENTS`\n   - Prefer precision over breadth\n\n   Generation algorithm:\n   1. Extract signals: feature domain keywords (e.g., auth, latency, UX, API), risk indicators (\"critical\", \"must\", \"compliance\"), stakeholder hints (\"QA\", \"review\", \"security team\"), and explicit deliverables (\"a11y\", \"rollback\", \"contracts\").\n   2. Cluster signals into candidate focus areas (max 4) ranked by relevance.\n   3. Identify probable audience & timing (author, reviewer, QA, release) if not explicit.\n   4. Detect missing dimensions: scope breadth, depth/rigor, risk emphasis, exclusion boundaries, measurable acceptance criteria.\n   5. Formulate questions chosen from these archetypes:\n      - Scope refinement (e.g., \"Should this include integration touchpoints with X and Y or stay limited to local module correctness?\")\n      - Risk prioritization (e.g., \"Which of these potential risk areas should receive mandatory gating checks?\")\n      - Depth calibration (e.g., \"Is this a lightweight pre-commit sanity list or a formal release gate?\")\n      - Audience framing (e.g., \"Will this be used by the author only or peers during PR review?\")\n      - Boundary exclusion (e.g., \"Should we explicitly exclude performance tuning items this round?\")\n      - Scenario class gap (e.g., \"No recovery flows detected‚Äîare rollback / partial failure paths in scope?\")\n\n   Question formatting rules:\n   - If presenting options, generate a compact table with columns: Option | Candidate | Why It Matters\n   - Limit to A‚ÄìE options maximum; omit table if a free-form answer is clearer\n   - Never ask the user to restate what they already said\n   - Avoid speculative categories (no hallucination). If uncertain, ask explicitly: \"Confirm whether X belongs in scope.\"\n\n   Defaults when interaction impossible:\n   - Depth: Standard\n   - Audience: Reviewer (PR) if code-related; Author otherwise\n   - Focus: Top 2 relevance clusters\n\n   Output the questions (label Q1/Q2/Q3). After answers: if ‚â•2 scenario classes (Alternate / Exception / Recovery / Non-Functional domain) remain unclear, you MAY ask up to TWO more targeted follow‚Äëups (Q4/Q5) with a one-line justification each (e.g., \"Unresolved recovery path risk\"). Do not exceed five total questions. Skip escalation if user explicitly declines more.\n\n3. **Understand user request**: Combine `$ARGUMENTS` + clarifying answers:\n   - Derive checklist theme (e.g., security, review, deploy, ux)\n   - Consolidate explicit must-have items mentioned by user\n   - Map focus selections to category scaffolding\n   - Infer any missing context from spec/plan/tasks (do NOT hallucinate)\n\n4. **Load feature context**: Use Read tool to load files from paths in AVAILABLE_DOCS:\n   Files to load:\n   - spec.md: Feature requirements and scope\n   - plan.md (if exists): Technical details, dependencies\n   - tasks.md (if exists): Implementation tasks\n\n   **Context Loading Strategy**:\n   - Load only necessary portions relevant to active focus areas (avoid full-file dumping)\n   - Prefer summarizing long sections into concise scenario/requirement bullets\n   - Use progressive disclosure: add follow-on retrieval only if gaps detected\n   - If source docs are large, generate interim summary items instead of embedding raw text\n\n5. **Generate checklist** - Create \"Unit Tests for Requirements\":\n   - Create `FEATURE_DIR/checklists/` directory if it doesn't exist\n   - Generate unique checklist filename:\n     - Use short, descriptive name based on domain (e.g., `ux.md`, `api.md`, `security.md`)\n     - Format: `[domain].md`\n     - If file exists, append to existing file\n   - Number items sequentially starting from CHK001\n   - Each `/speck:checklist` run creates a NEW file (never overwrites existing checklists)\n\n   **CORE PRINCIPLE - Test the Requirements, Not the Implementation**:\n   Every checklist item MUST evaluate the REQUIREMENTS THEMSELVES for:\n   - **Completeness**: Are all necessary requirements present?\n   - **Clarity**: Are requirements unambiguous and specific?\n   - **Consistency**: Do requirements align with each other?\n   - **Measurability**: Can requirements be objectively verified?\n   - **Coverage**: Are all scenarios/edge cases addressed?\n\n   **Category Structure** - Group items by requirement quality dimensions:\n   - **Requirement Completeness** (Are all necessary requirements documented?)\n   - **Requirement Clarity** (Are requirements specific and unambiguous?)\n   - **Requirement Consistency** (Do requirements align without conflicts?)\n   - **Acceptance Criteria Quality** (Are success criteria measurable?)\n   - **Scenario Coverage** (Are all flows/cases addressed?)\n   - **Edge Case Coverage** (Are boundary conditions defined?)\n   - **Non-Functional Requirements** (Performance, Security, Accessibility, etc. - are they specified?)\n   - **Dependencies & Assumptions** (Are they documented and validated?)\n   - **Ambiguities & Conflicts** (What needs clarification?)\n\n   **HOW TO WRITE CHECKLIST ITEMS - \"Unit Tests for English\"**:\n\n   ‚ùå **WRONG** (Testing implementation):\n   - \"Verify landing page displays 3 episode cards\"\n   - \"Test hover states work on desktop\"\n   - \"Confirm logo click navigates home\"\n\n   ‚úÖ **CORRECT** (Testing requirements quality):\n   - \"Are the exact number and layout of featured episodes specified?\" [Completeness]\n   - \"Is 'prominent display' quantified with specific sizing/positioning?\" [Clarity]\n   - \"Are hover state requirements consistent across all interactive elements?\" [Consistency]\n   - \"Are keyboard navigation requirements defined for all interactive UI?\" [Coverage]\n   - \"Is the fallback behavior specified when logo image fails to load?\" [Edge Cases]\n   - \"Are loading states defined for asynchronous episode data?\" [Completeness]\n   - \"Does the spec define visual hierarchy for competing UI elements?\" [Clarity]\n\n   **ITEM STRUCTURE**:\n   Each item should follow this pattern:\n   - Question format asking about requirement quality\n   - Focus on what's WRITTEN (or not written) in the spec/plan\n   - Include quality dimension in brackets [Completeness/Clarity/Consistency/etc.]\n   - Reference spec section `[Spec ¬ßX.Y]` when checking existing requirements\n   - Use `[Gap]` marker when checking for missing requirements\n\n   **EXAMPLES BY QUALITY DIMENSION**:\n\n   Completeness:\n   - \"Are error handling requirements defined for all API failure modes? [Gap]\"\n   - \"Are accessibility requirements specified for all interactive elements? [Completeness]\"\n   - \"Are mobile breakpoint requirements defined for responsive layouts? [Gap]\"\n\n   Clarity:\n   - \"Is 'fast loading' quantified with specific timing thresholds? [Clarity, Spec ¬ßNFR-2]\"\n   - \"Are 'related episodes' selection criteria explicitly defined? [Clarity, Spec ¬ßFR-5]\"\n   - \"Is 'prominent' defined with measurable visual properties? [Ambiguity, Spec ¬ßFR-4]\"\n\n   Consistency:\n   - \"Do navigation requirements align across all pages? [Consistency, Spec ¬ßFR-10]\"\n   - \"Are card component requirements consistent between landing and detail pages? [Consistency]\"\n\n   Coverage:\n   - \"Are requirements defined for zero-state scenarios (no episodes)? [Coverage, Edge Case]\"\n   - \"Are concurrent user interaction scenarios addressed? [Coverage, Gap]\"\n   - \"Are requirements specified for partial data loading failures? [Coverage, Exception Flow]\"\n\n   Measurability:\n   - \"Are visual hierarchy requirements measurable/testable? [Acceptance Criteria, Spec ¬ßFR-1]\"\n   - \"Can 'balanced visual weight' be objectively verified? [Measurability, Spec ¬ßFR-2]\"\n\n   **Scenario Classification & Coverage** (Requirements Quality Focus):\n   - Check if requirements exist for: Primary, Alternate, Exception/Error, Recovery, Non-Functional scenarios\n   - For each scenario class, ask: \"Are [scenario type] requirements complete, clear, and consistent?\"\n   - If scenario class missing: \"Are [scenario type] requirements intentionally excluded or missing? [Gap]\"\n   - Include resilience/rollback when state mutation occurs: \"Are rollback requirements defined for migration failures? [Gap]\"\n\n   **Traceability Requirements**:\n   - MINIMUM: ‚â•80% of items MUST include at least one traceability reference\n   - Each item should reference: spec section `[Spec ¬ßX.Y]`, or use markers: `[Gap]`, `[Ambiguity]`, `[Conflict]`, `[Assumption]`\n   - If no ID system exists: \"Is a requirement & acceptance criteria ID scheme established? [Traceability]\"\n\n   **Surface & Resolve Issues** (Requirements Quality Problems):\n   Ask questions about the requirements themselves:\n   - Ambiguities: \"Is the term 'fast' quantified with specific metrics? [Ambiguity, Spec ¬ßNFR-1]\"\n   - Conflicts: \"Do navigation requirements conflict between ¬ßFR-10 and ¬ßFR-10a? [Conflict]\"\n   - Assumptions: \"Is the assumption of 'always available podcast API' validated? [Assumption]\"\n   - Dependencies: \"Are external podcast API requirements documented? [Dependency, Gap]\"\n   - Missing definitions: \"Is 'visual hierarchy' defined with measurable criteria? [Gap]\"\n\n   **Content Consolidation**:\n   - Soft cap: If raw candidate items > 40, prioritize by risk/impact\n   - Merge near-duplicates checking the same requirement aspect\n   - If >5 low-impact edge cases, create one item: \"Are edge cases X, Y, Z addressed in requirements? [Coverage]\"\n\n   **üö´ ABSOLUTELY PROHIBITED** - These make it an implementation test, not a requirements test:\n   - ‚ùå Any item starting with \"Verify\", \"Test\", \"Confirm\", \"Check\" + implementation behavior\n   - ‚ùå References to code execution, user actions, system behavior\n   - ‚ùå \"Displays correctly\", \"works properly\", \"functions as expected\"\n   - ‚ùå \"Click\", \"navigate\", \"render\", \"load\", \"execute\"\n   - ‚ùå Test cases, test plans, QA procedures\n   - ‚ùå Implementation details (frameworks, APIs, algorithms)\n\n   **‚úÖ REQUIRED PATTERNS** - These test requirements quality:\n   - ‚úÖ \"Are [requirement type] defined/specified/documented for [scenario]?\"\n   - ‚úÖ \"Is [vague term] quantified/clarified with specific criteria?\"\n   - ‚úÖ \"Are requirements consistent between [section A] and [section B]?\"\n   - ‚úÖ \"Can [requirement] be objectively measured/verified?\"\n   - ‚úÖ \"Are [edge cases/scenarios] addressed in requirements?\"\n   - ‚úÖ \"Does the spec define [missing aspect]?\"\n\n6. **Structure Reference**: **Read** checklist template from `{TEMPLATE_DIR}/checklist-template.md` using Read tool. Follow the template for title, meta section, category headings, and ID formatting. If template is unavailable, use: H1 title, purpose/created meta lines, `##` category sections containing `- [ ] CHK### <requirement item>` lines with globally incrementing IDs starting at CHK001.\n\n7. **Report**: Output full path to created checklist, item count, and remind user that each run creates a new file. Summarize:\n   - Focus areas selected\n   - Depth level\n   - Actor/timing\n   - Any explicit user-specified must-have items incorporated\n\n**Important**: Each `/speck:checklist` command invocation creates a checklist file using short, descriptive names unless file already exists. This allows:\n\n- Multiple checklists of different types (e.g., `ux.md`, `test.md`, `security.md`)\n- Simple, memorable filenames that indicate checklist purpose\n- Easy identification and navigation in the `checklists/` folder\n\nTo avoid clutter, use descriptive types and clean up obsolete checklists when done.\n\n## Example Checklist Types & Sample Items\n\n**UX Requirements Quality:** `ux.md`\n\nSample items (testing the requirements, NOT the implementation):\n\n- \"Are visual hierarchy requirements defined with measurable criteria? [Clarity, Spec ¬ßFR-1]\"\n- \"Is the number and positioning of UI elements explicitly specified? [Completeness, Spec ¬ßFR-1]\"\n- \"Are interaction state requirements (hover, focus, active) consistently defined? [Consistency]\"\n- \"Are accessibility requirements specified for all interactive elements? [Coverage, Gap]\"\n- \"Is fallback behavior defined when images fail to load? [Edge Case, Gap]\"\n- \"Can 'prominent display' be objectively measured? [Measurability, Spec ¬ßFR-4]\"\n\n**API Requirements Quality:** `api.md`\n\nSample items:\n\n- \"Are error response formats specified for all failure scenarios? [Completeness]\"\n- \"Are rate limiting requirements quantified with specific thresholds? [Clarity]\"\n- \"Are authentication requirements consistent across all endpoints? [Consistency]\"\n- \"Are retry/timeout requirements defined for external dependencies? [Coverage, Gap]\"\n- \"Is versioning strategy documented in requirements? [Gap]\"\n\n**Performance Requirements Quality:** `performance.md`\n\nSample items:\n\n- \"Are performance requirements quantified with specific metrics? [Clarity]\"\n- \"Are performance targets defined for all critical user journeys? [Coverage]\"\n- \"Are performance requirements under different load conditions specified? [Completeness]\"\n- \"Can performance requirements be objectively measured? [Measurability]\"\n- \"Are degradation requirements defined for high-load scenarios? [Edge Case, Gap]\"\n\n**Security Requirements Quality:** `security.md`\n\nSample items:\n\n- \"Are authentication requirements specified for all protected resources? [Coverage]\"\n- \"Are data protection requirements defined for sensitive information? [Completeness]\"\n- \"Is the threat model documented and requirements aligned to it? [Traceability]\"\n- \"Are security requirements consistent with compliance obligations? [Consistency]\"\n- \"Are security failure/breach response requirements defined? [Gap, Exception Flow]\"\n\n## Anti-Examples: What NOT To Do\n\n**‚ùå WRONG - These test implementation, not requirements:**\n\n```markdown\n- [ ] CHK001 - Verify landing page displays 3 episode cards [Spec ¬ßFR-001]\n- [ ] CHK002 - Test hover states work correctly on desktop [Spec ¬ßFR-003]\n- [ ] CHK003 - Confirm logo click navigates to home page [Spec ¬ßFR-010]\n- [ ] CHK004 - Check that related episodes section shows 3-5 items [Spec ¬ßFR-005]\n```\n\n**‚úÖ CORRECT - These test requirements quality:**\n\n```markdown\n- [ ] CHK001 - Are the number and layout of featured episodes explicitly specified? [Completeness, Spec ¬ßFR-001]\n- [ ] CHK002 - Are hover state requirements consistently defined for all interactive elements? [Consistency, Spec ¬ßFR-003]\n- [ ] CHK003 - Are navigation requirements clear for all clickable brand elements? [Clarity, Spec ¬ßFR-010]\n- [ ] CHK004 - Is the selection criteria for related episodes documented? [Gap, Spec ¬ßFR-005]\n- [ ] CHK005 - Are loading state requirements defined for asynchronous episode data? [Gap]\n- [ ] CHK006 - Can \"visual hierarchy\" requirements be objectively measured? [Measurability, Spec ¬ßFR-001]\n```\n\n**Key Differences:**\n\n- Wrong: Tests if the system works correctly\n- Correct: Tests if the requirements are written correctly\n- Wrong: Verification of behavior\n- Correct: Validation of requirement quality\n- Wrong: \"Does it do X?\"\n- Correct: \"Is X clearly specified?\""
              },
              {
                "name": "/clarify",
                "description": "Identify underspecified areas in the current feature spec by asking up to 5 highly targeted clarification questions and encoding answers back into the spec.",
                "path": "speck/commands/clarify.md",
                "frontmatter": {
                  "description": "Identify underspecified areas in the current feature spec by asking up to 5 highly targeted clarification questions and encoding answers back into the spec.",
                  "handoffs": [
                    {
                      "label": "Build Technical Plan",
                      "agent": "speck.plan",
                      "prompt": "Create a plan for the spec. I am building with..."
                    }
                  ]
                },
                "content": "## User Input\n\n```text\n$ARGUMENTS\n```\n\nYou **MUST** consider the user input before proceeding (if not empty).\n\n## Outline\n\nGoal: Detect and reduce ambiguity or missing decision points in the active feature specification and record the clarifications directly in the spec file.\n\nNote: This clarification workflow is expected to run (and be completed) BEFORE invoking `/speck:plan`. If the user explicitly states they are skipping clarification (e.g., exploratory spike), you may proceed, but must warn that downstream rework risk increases.\n\nExecution steps:\n\n1. Extract prerequisite context from the auto-injected comment in the prompt:\n   ```\n   <!-- SPECK_PREREQ_CONTEXT\n   {\"MODE\":\"single-repo\",\"FEATURE_DIR\":\"/path/to/specs/010-feature\",\"AVAILABLE_DOCS\":[\"specs/010-feature/spec.md\"]}\n   -->\n   ```\n   Use FEATURE_DIR and AVAILABLE_DOCS from this JSON.\n\n   **Fallback**: If the comment is not present (VSCode hook bug), run:\n   ```bash\n   speck check-prerequisites --json --paths-only\n   ```\n   Parse minimal JSON payload fields: FEATURE_DIR, FEATURE_SPEC.\n   If JSON parsing fails, abort and instruct user to re-run `/speck:specify` or verify feature branch environment.\n\n   Parse JSON output to extract FEATURE_DIR and FEATURE_SPEC.\n\n   **IMPORTANT**: Do NOT invent or guess CLI paths. Use ONLY the path above.\n\n2. Load the current spec file:\n   - Use Read tool to load spec.md from path in AVAILABLE_DOCS\n\n   Perform a structured ambiguity & coverage scan using this taxonomy. For each category, mark status: Clear / Partial / Missing. Produce an internal coverage map used for prioritization (do not output raw map unless no questions will be asked).\n\n   Functional Scope & Behavior:\n   - Core user goals & success criteria\n   - Explicit out-of-scope declarations\n   - User roles / personas differentiation\n\n   Domain & Data Model:\n   - Entities, attributes, relationships\n   - Identity & uniqueness rules\n   - Lifecycle/state transitions\n   - Data volume / scale assumptions\n\n   Interaction & UX Flow:\n   - Critical user journeys / sequences\n   - Error/empty/loading states\n   - Accessibility or localization notes\n\n   Non-Functional Quality Attributes:\n   - Performance (latency, throughput targets)\n   - Scalability (horizontal/vertical, limits)\n   - Reliability & availability (uptime, recovery expectations)\n   - Observability (logging, metrics, tracing signals)\n   - Security & privacy (authN/Z, data protection, threat assumptions)\n   - Compliance / regulatory constraints (if any)\n\n   Integration & External Dependencies:\n   - External services/APIs and failure modes\n   - Data import/export formats\n   - Protocol/versioning assumptions\n\n   Edge Cases & Failure Handling:\n   - Negative scenarios\n   - Rate limiting / throttling\n   - Conflict resolution (e.g., concurrent edits)\n\n   Constraints & Tradeoffs:\n   - Technical constraints (language, storage, hosting)\n   - Explicit tradeoffs or rejected alternatives\n\n   Terminology & Consistency:\n   - Canonical glossary terms\n   - Avoided synonyms / deprecated terms\n\n   Completion Signals:\n   - Acceptance criteria testability\n   - Measurable Definition of Done style indicators\n\n   Misc / Placeholders:\n   - TODO markers / unresolved decisions\n   - Ambiguous adjectives (\"robust\", \"intuitive\") lacking quantification\n\n   For each category with Partial or Missing status, add a candidate question opportunity unless:\n   - Clarification would not materially change implementation or validation strategy\n   - Information is better deferred to planning phase (note internally)\n\n3. Generate (internally) a prioritized queue of candidate clarification questions (maximum 5). Do NOT output them all at once. Apply these constraints:\n    - Maximum of 10 total questions across the whole session.\n    - Each question must be answerable with EITHER:\n       - A short multiple‚Äëchoice selection (2‚Äì5 distinct, mutually exclusive options), OR\n       - A one-word / short‚Äëphrase answer (explicitly constrain: \"Answer in <=5 words\").\n    - Only include questions whose answers materially impact architecture, data modeling, task decomposition, test design, UX behavior, operational readiness, or compliance validation.\n    - Ensure category coverage balance: attempt to cover the highest impact unresolved categories first; avoid asking two low-impact questions when a single high-impact area (e.g., security posture) is unresolved.\n    - Exclude questions already answered, trivial stylistic preferences, or plan-level execution details (unless blocking correctness).\n    - Favor clarifications that reduce downstream rework risk or prevent misaligned acceptance tests.\n    - If more than 5 categories remain unresolved, select the top 5 by (Impact * Uncertainty) heuristic.\n\n4. Sequential questioning loop (interactive):\n    - Present EXACTLY ONE question at a time.\n    - For multiple‚Äëchoice questions:\n       - **Analyze all options** and determine the **most suitable option** based on:\n          - Best practices for the project type\n          - Common patterns in similar implementations\n          - Risk reduction (security, performance, maintainability)\n          - Alignment with any explicit project goals or constraints visible in the spec\n       - Format the question output exactly as shown (preserve blank lines between sections):\n\n       ```\n       ## Question [N] of 5\n\n       **Question:** <The actual question text>\n\n       **Recommended:** Option [X] - <reasoning (1-2 sentences explaining why this is the best choice)>\n\n       | Option | Description |\n       |--------|-------------|\n       | A | <Option A description> |\n       | B | <Option B description> |\n       | C | <Option C description> (add D/E as needed up to 5) |\n       | Short | Provide a different short answer (<=5 words) (Include only if free-form alternative is appropriate) |\n\n       You can reply with the option letter (e.g., \"A\"), accept the recommendation by saying \"yes\" or \"recommended\", or provide your own short answer.\n       ```\n\n    - For short‚Äëanswer style (no meaningful discrete options):\n       - Format the question output exactly as shown (preserve blank lines between sections):\n\n       ```\n       ## Question [N] of 5\n\n       **Question:** <The actual question text>\n\n       **Suggested:** <your proposed answer> - <brief reasoning (1-2 sentences)>\n\n       Format: Short answer (<=5 words). You can accept the suggestion by saying \"yes\" or \"suggested\", or provide your own answer.\n       ```\n    - After the user answers:\n       - If the user replies with \"yes\", \"recommended\", or \"suggested\", use your previously stated recommendation/suggestion as the answer.\n       - Otherwise, validate the answer maps to one option or fits the <=5 word constraint.\n       - If ambiguous, ask for a quick disambiguation (count still belongs to same question; do not advance).\n       - Once satisfactory, record it in working memory (do not yet write to disk) and move to the next queued question.\n    - Stop asking further questions when:\n       - All critical ambiguities resolved early (remaining queued items become unnecessary), OR\n       - User signals completion (\"done\", \"good\", \"no more\"), OR\n       - You reach 5 asked questions.\n    - Never reveal future queued questions in advance.\n    - If no valid questions exist at start, immediately report no critical ambiguities.\n\n5. Integration after EACH accepted answer (incremental update approach):\n    - Maintain in-memory representation of the spec (loaded once at start) plus the raw file contents.\n    - For the first integrated answer in this session:\n       - Ensure a `## Clarifications` section exists (create it just after the highest-level contextual/overview section per the spec template if missing).\n       - Under it, create (if not present) a `### Session YYYY-MM-DD` subheading for today.\n    - Append a bullet line immediately after acceptance: `- Q: <question> ‚Üí A: <final answer>`.\n    - Then immediately apply the clarification to the most appropriate section(s):\n       - Functional ambiguity ‚Üí Update or add a bullet in Functional Requirements.\n       - User interaction / actor distinction ‚Üí Update User Stories or Actors subsection (if present) with clarified role, constraint, or scenario.\n       - Data shape / entities ‚Üí Update Data Model (add fields, types, relationships) preserving ordering; note added constraints succinctly.\n       - Non-functional constraint ‚Üí Add/modify measurable criteria in Non-Functional / Quality Attributes section (convert vague adjective to metric or explicit target).\n       - Edge case / negative flow ‚Üí Add a new bullet under Edge Cases / Error Handling (or create such subsection if template provides placeholder for it).\n       - Terminology conflict ‚Üí Normalize term across spec; retain original only if necessary by adding `(formerly referred to as \"X\")` once.\n    - If the clarification invalidates an earlier ambiguous statement, replace that statement instead of duplicating; leave no obsolete contradictory text.\n    - Save the spec file AFTER each integration to minimize risk of context loss (atomic overwrite).\n    - Preserve formatting: do not reorder unrelated sections; keep heading hierarchy intact.\n    - Keep each inserted clarification minimal and testable (avoid narrative drift).\n\n6. Validation (performed after EACH write plus final pass):\n   - Clarifications session contains exactly one bullet per accepted answer (no duplicates).\n   - Total asked (accepted) questions ‚â§ 5.\n   - Updated sections contain no lingering vague placeholders the new answer was meant to resolve.\n   - No contradictory earlier statement remains (scan for now-invalid alternative choices removed).\n   - Markdown structure valid; only allowed new headings: `## Clarifications`, `### Session YYYY-MM-DD`.\n   - Terminology consistency: same canonical term used across all updated sections.\n\n7. Write the updated spec back to `FEATURE_SPEC`.\n\n8. Report completion (after questioning loop ends or early termination):\n   - Number of questions asked & answered.\n   - Path to updated spec.\n   - Sections touched (list names).\n   - Coverage summary table listing each taxonomy category with Status: Resolved (was Partial/Missing and addressed), Deferred (exceeds question quota or better suited for planning), Clear (already sufficient), Outstanding (still Partial/Missing but low impact).\n   - If any Outstanding or Deferred remain, recommend whether to proceed to `/speck:plan` or run `/speck:clarify` again later post-plan.\n   - Suggested next command.\n\nBehavior rules:\n\n- If no meaningful ambiguities found (or all potential questions would be low-impact), respond: \"No critical ambiguities detected worth formal clarification.\" and suggest proceeding.\n- If spec file missing, instruct user to run `/speck:specify` first (do not create a new spec here).\n- Never exceed 5 total asked questions (clarification retries for a single question do not count as new questions).\n- Avoid speculative tech stack questions unless the absence blocks functional clarity.\n- Respect user early termination signals (\"stop\", \"done\", \"proceed\").\n- If no questions asked due to full coverage, output a compact coverage summary (all categories Clear) then suggest advancing.\n- If quota reached with unresolved high-impact categories remaining, explicitly flag them under Deferred with rationale.\n\nContext for prioritization: $ARGUMENTS"
              },
              {
                "name": "/constitution",
                "description": "Create or update the project constitution from interactive or provided principle inputs, ensuring all dependent templates stay in sync.",
                "path": "speck/commands/constitution.md",
                "frontmatter": {
                  "description": "Create or update the project constitution from interactive or provided principle inputs, ensuring all dependent templates stay in sync.",
                  "handoffs": [
                    {
                      "label": "Build Specification",
                      "agent": "speck.specify",
                      "prompt": "Implement the feature specification based on the updated constitution. I want to build..."
                    }
                  ]
                },
                "content": "## User Input\n\n```text\n$ARGUMENTS\n```\n\nYou **MUST** consider the user input before proceeding (if not empty).\n\n## Outline\n\nYou are updating the project-local constitution at `.speck/memory/constitution.md` (in the project root, NOT the plugin). If this file doesn't exist yet, copy it from the plugin template at `.speck/memory/constitution.md` first. This file is a TEMPLATE containing placeholder tokens in square brackets (e.g. `[PROJECT_NAME]`, `[PRINCIPLE_1_NAME]`). Your job is to (a) collect/derive concrete values, (b) fill the template precisely, and (c) propagate any amendments across dependent artifacts.\n\nFollow this execution flow:\n\n1. **Get template directory**: Run `speck check-prerequisites --json --skip-feature-check` and extract `TEMPLATE_DIR` from the JSON output.\n\n2. Check if `.speck/memory/constitution.md` exists in the project root:\n   - If it exists: **Read** it as the working copy using Read tool\n   - If it doesn't exist: **Read** `{TEMPLATE_DIR}/constitution-template.md` using Read tool, then **Write** to `.speck/memory/constitution.md`\n   - Identify every placeholder token of the form `[ALL_CAPS_IDENTIFIER]`\n   **IMPORTANT**: The user might require less or more principles than the ones used in the template. If a number is specified, respect that - follow the general template. You will update the doc accordingly.\n\n3. Collect/derive values for placeholders:\n   - If user input (conversation) supplies a value, use it.\n   - Otherwise infer from existing repo context (README, docs, prior constitution versions if embedded).\n   - For governance dates: `RATIFICATION_DATE` is the original adoption date (if unknown ask or mark TODO), `LAST_AMENDED_DATE` is today if changes are made, otherwise keep previous.\n   - `CONSTITUTION_VERSION` must increment according to semantic versioning rules:\n     - MAJOR: Backward incompatible governance/principle removals or redefinitions.\n     - MINOR: New principle/section added or materially expanded guidance.\n     - PATCH: Clarifications, wording, typo fixes, non-semantic refinements.\n   - If version bump type ambiguous, propose reasoning before finalizing.\n\n4. Draft the updated constitution content:\n   - Replace every placeholder with concrete text (no bracketed tokens left except intentionally retained template slots that the project has chosen not to define yet‚Äîexplicitly justify any left).\n   - Preserve heading hierarchy and comments can be removed once replaced unless they still add clarifying guidance.\n   - Ensure each Principle section: succinct name line, paragraph (or bullet list) capturing non‚Äënegotiable rules, explicit rationale if not obvious.\n   - Ensure Governance section lists amendment procedure, versioning policy, and compliance review expectations.\n\n5. Consistency propagation checklist (use Read tool for all template files):\n   - **Read** `{TEMPLATE_DIR}/plan-template.md` and ensure any \"Constitution Check\" or rules align with updated principles.\n   - **Read** `{TEMPLATE_DIR}/spec-template.md` for scope/requirements alignment‚Äîupdate if constitution adds/removes mandatory sections or constraints.\n   - **Read** `{TEMPLATE_DIR}/tasks-template.md` and ensure task categorization reflects new or removed principle-driven task types (e.g., observability, versioning, testing discipline).\n   - **Read** any runtime guidance docs (e.g., `README.md`, `docs/quickstart.md`, or agent-specific guidance files if present). Update references to principles changed.\n\n6. Produce a Sync Impact Report (prepend as an HTML comment at top of the constitution file after update):\n   - Version change: old ‚Üí new\n   - List of modified principles (old title ‚Üí new title if renamed)\n   - Added sections\n   - Removed sections\n   - Templates requiring updates (‚úÖ updated / ‚ö† pending) with file paths\n   - Follow-up TODOs if any placeholders intentionally deferred.\n\n7. Validation before final output:\n   - No remaining unexplained bracket tokens.\n   - Version line matches report.\n   - Dates ISO format YYYY-MM-DD.\n   - Principles are declarative, testable, and free of vague language (\"should\" ‚Üí replace with MUST/SHOULD rationale where appropriate).\n\n8. Write the completed constitution back to `.speck/memory/constitution.md` (overwrite).\n\n9. Output a final summary to the user with:\n   - New version and bump rationale.\n   - Any files flagged for manual follow-up.\n   - Suggested commit message (e.g., `docs: amend constitution to vX.Y.Z (principle additions + governance update)`).\n\nFormatting & Style Requirements:\n\n- Use Markdown headings exactly as in the template (do not demote/promote levels).\n- Wrap long rationale lines to keep readability (<100 chars ideally) but do not hard enforce with awkward breaks.\n- Keep a single blank line between sections.\n- Avoid trailing whitespace.\n\nIf the user supplies partial updates (e.g., only one principle revision), still perform validation and version decision steps.\n\nIf critical info missing (e.g., ratification date truly unknown), insert `TODO(<FIELD_NAME>): explanation` and include in the Sync Impact Report under deferred items.\n\nDo not create a new template; always operate on the existing `.speck/memory/constitution.md` file."
              },
              {
                "name": "/env",
                "description": "Check Speck plugin environment and configuration",
                "path": "speck/commands/env.md",
                "frontmatter": {
                  "description": "Check Speck plugin environment and configuration"
                },
                "content": "## User Input\n\n```text\n$ARGUMENTS\n```\n\n## Environment Check\n\nRun the Speck environment check command:\n\n```bash\nspeck env --json\n```\n\n## Present Results\n\nParse the JSON output and present a summary to the user.\n\n**Required sections:**\n1. **Mode**: Single-repo or Multi-repo (root/child)\n2. **Paths**: Repository root, specs directory, speck root (if multi-repo)\n3. **Current Branch**: The active git branch\n4. **Branch Mappings**: Any feature branch ‚Üí spec mappings\n5. **Warnings**: Any configuration issues detected\n\n**If errors occur**, explain the issue and suggest remediation steps.\n\n**Example output format:**\n\n| Setting | Value |\n|---------|-------|\n| Mode | Multi-repo (Child) |\n| Repo Root | /path/to/backend |\n| Speck Root | /path/to/multi-repo-root |\n| Current Branch | 002-cross-repo-auth |\n| Branch Mappings | 1 mapping(s) |\n\nIf the command fails or `ok: false` in JSON, display the error and recovery suggestions."
              },
              {
                "name": "/help",
                "description": "Load speck-help skill for answering questions about Speck features, specs, plans, and tasks",
                "path": "speck/commands/help.md",
                "frontmatter": {
                  "description": "Load speck-help skill for answering questions about Speck features, specs, plans, and tasks"
                },
                "content": "## User Input\n\n```text\n$ARGUMENTS\n```\n\nYou **MUST** consider the user input before proceeding (if not empty).\n\n## Speck Help Skill\n\nThis command activates the **speck-help** skill to answer natural language questions about Speck workflow artifacts.\n\n### What This Skill Does\n\nThe speck-help skill interprets Speck specification artifacts and answers questions without requiring you to manually read files:\n\n- **spec.md**: Requirements, user stories, success criteria\n- **plan.md**: Implementation approach, technical context, constitution check\n- **tasks.md**: Task breakdown, dependencies, progress\n\n### Skill Location\n\nLoad the skill from: `.claude/skills/speck-help/`\n\nThe skill includes these reference files:\n- `SKILL.md` - Core capabilities and activation patterns\n- `reference.md` - Detailed interpretation rules and error formats\n- `examples.md` - Usage examples\n- `workflows.md` - Multi-repo, worktrees, and session handoff\n\n### Example Questions\n\nYou can ask questions like:\n\n- \"What are the functional requirements for feature 015?\"\n- \"How many tasks are completed for this feature?\"\n- \"Does my spec follow the template?\"\n- \"What should go in the Success Criteria section?\"\n- \"Is this a multi-repo setup?\"\n- \"Did my session handoff work?\"\n- \"What's the worktree config?\"\n\n### How to Use\n\nAfter loading this skill, simply ask your question about Speck artifacts. The skill will:\n\n1. Identify the feature from your query (by number, name, or current context)\n2. Load the relevant artifact files (spec.md, plan.md, tasks.md)\n3. Parse and interpret the content\n4. Answer your question with specific information\n\n### Related Commands\n\nFor **modifying** Speck artifacts, use these commands instead:\n\n| Command | Purpose |\n|---------|---------|\n| `/speck:specify` | Create or update feature specification |\n| `/speck:clarify` | Resolve ambiguities in specs |\n| `/speck:plan` | Generate implementation plan |\n| `/speck:tasks` | Generate task breakdown |\n| `/speck:implement` | Execute implementation tasks |\n| `/speck:analyze` | Check cross-artifact consistency |\n\n## Context\n\n$ARGUMENTS"
              },
              {
                "name": "/implement",
                "description": "Execute the implementation plan by processing and executing all tasks defined in tasks.md",
                "path": "speck/commands/implement.md",
                "frontmatter": {
                  "description": "Execute the implementation plan by processing and executing all tasks defined in tasks.md"
                },
                "content": "## User Input\n\n```text\n$ARGUMENTS\n```\n\nYou **MUST** consider the user input before proceeding (if not empty).\n\n## Outline\n\n1. Extract prerequisite context from the auto-injected comment in the prompt:\n   ```\n   <!-- SPECK_PREREQ_CONTEXT\n   {\"MODE\":\"single-repo\",\"FEATURE_DIR\":\"/path/to/specs/010-feature\",\"AVAILABLE_DOCS\":[\"specs/010-feature/research.md\",\"specs/010-feature/tasks.md\",\"specs/010-feature/plan.md\",\".speck/memory/constitution.md\",\"../../../8-specs/specs/010-feature/checklists/requirements.md\"]}\n   -->\n   ```\n   Use the FEATURE_DIR and AVAILABLE_DOCS values from this JSON.\n\n   **Fallback**: If the comment is not present (VSCode hook bug), run:\n   ```bash\n   speck check-prerequisites --json --require-tasks --include-tasks\n   ```\n\n   Parse JSON output to extract MODE, FEATURE_DIR, and AVAILABLE_DOCS.\n\n   **IMPORTANT**: Do NOT invent or guess CLI paths. Use ONLY the path above.\n\n2. **Check checklists status** (if checklists exist):\n   - Find checklist files from AVAILABLE_DOCS (paths containing \"/checklists/\")\n   - Use Read tool to load each checklist file\n   - For each checklist, count:\n     - Total items: All lines matching `- [ ]` or `- [X]` or `- [x]`\n     - Completed items: Lines matching `- [X]` or `- [x]`\n     - Incomplete items: Lines matching `- [ ]`\n   - Create a status table:\n\n     ```text\n     | Checklist | Total | Completed | Incomplete | Status |\n     |-----------|-------|-----------|------------|--------|\n     | ux.md     | 12    | 12        | 0          | ‚úì PASS |\n     | test.md   | 8     | 5         | 3          | ‚úó FAIL |\n     | security.md | 6   | 6         | 0          | ‚úì PASS |\n     ```\n\n   - Calculate overall status:\n     - **PASS**: All checklists have 0 incomplete items\n     - **FAIL**: One or more checklists have incomplete items\n\n   - **If any checklist is incomplete**:\n     - Display the table with incomplete item counts\n     - **STOP** and ask: \"Some checklists are incomplete. Do you want to proceed with implementation anyway? (yes/no)\"\n     - Wait for user response before continuing\n     - If user says \"no\" or \"wait\" or \"stop\", halt execution\n     - If user says \"yes\" or \"proceed\" or \"continue\", proceed to step 3\n\n   - **If all checklists are complete**:\n     - Display the table showing all checklists passed\n     - Automatically proceed to step 3\n\n3. Load and analyze the implementation context:\n\n   Use Read tool to load files from paths in AVAILABLE_DOCS:\n\n   **Required files**:\n   - **REQUIRED**: tasks.md\n   - **REQUIRED**: plan.md\n\n   **Optional files** (only if they exist in AVAILABLE_DOCS):\n   - data-model.md\n   - contracts/ files\n   - research.md\n   - quickstart.md\n\n4. **Project Setup Verification**:\n   - **REQUIRED**: Create/verify ignore files based on actual project setup:\n\n   **Detection & Creation Logic**:\n   - Check if the following command succeeds to determine if the repository is a git repo (create/verify .gitignore if so):\n\n     ```sh\n     git rev-parse --git-dir 2>/dev/null\n     ```\n\n   - Check if Dockerfile* exists or Docker in plan.md ‚Üí create/verify .dockerignore\n   - Check if .eslintrc* exists ‚Üí create/verify .eslintignore\n   - Check if eslint.config.* exists ‚Üí ensure the config's `ignores` entries cover required patterns\n   - Check if .prettierrc* exists ‚Üí create/verify .prettierignore\n   - Check if .npmrc or package.json exists ‚Üí create/verify .npmignore (if publishing)\n   - Check if terraform files (*.tf) exist ‚Üí create/verify .terraformignore\n   - Check if .helmignore needed (helm charts present) ‚Üí create/verify .helmignore\n\n   **If ignore file already exists**: Verify it contains essential patterns, append missing critical patterns only\n   **If ignore file missing**: Create with full pattern set for detected technology\n\n   **Common Patterns by Technology** (from plan.md tech stack):\n   - **Node.js/JavaScript/TypeScript**: `node_modules/`, `dist/`, `build/`, `*.log`, `.env*`\n   - **Python**: `__pycache__/`, `*.pyc`, `.venv/`, `venv/`, `dist/`, `*.egg-info/`\n   - **Java**: `target/`, `*.class`, `*.jar`, `.gradle/`, `build/`\n   - **C#/.NET**: `bin/`, `obj/`, `*.user`, `*.suo`, `packages/`\n   - **Go**: `*.exe`, `*.test`, `vendor/`, `*.out`\n   - **Ruby**: `.bundle/`, `log/`, `tmp/`, `*.gem`, `vendor/bundle/`\n   - **PHP**: `vendor/`, `*.log`, `*.cache`, `*.env`\n   - **Rust**: `target/`, `debug/`, `release/`, `*.rs.bk`, `*.rlib`, `*.prof*`, `.idea/`, `*.log`, `.env*`\n   - **Kotlin**: `build/`, `out/`, `.gradle/`, `.idea/`, `*.class`, `*.jar`, `*.iml`, `*.log`, `.env*`\n   - **C++**: `build/`, `bin/`, `obj/`, `out/`, `*.o`, `*.so`, `*.a`, `*.exe`, `*.dll`, `.idea/`, `*.log`, `.env*`\n   - **C**: `build/`, `bin/`, `obj/`, `out/`, `*.o`, `*.a`, `*.so`, `*.exe`, `Makefile`, `config.log`, `.idea/`, `*.log`, `.env*`\n   - **Swift**: `.build/`, `DerivedData/`, `*.swiftpm/`, `Packages/`\n   - **R**: `.Rproj.user/`, `.Rhistory`, `.RData`, `.Ruserdata`, `*.Rproj`, `packrat/`, `renv/`\n   - **Universal**: `.DS_Store`, `Thumbs.db`, `*.tmp`, `*.swp`, `.vscode/`, `.idea/`\n\n   **Tool-Specific Patterns**:\n   - **Docker**: `node_modules/`, `.git/`, `Dockerfile*`, `.dockerignore`, `*.log*`, `.env*`, `coverage/`\n   - **ESLint**: `node_modules/`, `dist/`, `build/`, `coverage/`, `*.min.js`\n   - **Prettier**: `node_modules/`, `dist/`, `build/`, `coverage/`, `package-lock.json`, `yarn.lock`, `pnpm-lock.yaml`\n   - **Terraform**: `.terraform/`, `*.tfstate*`, `*.tfvars`, `.terraform.lock.hcl`\n   - **Kubernetes/k8s**: `*.secret.yaml`, `secrets/`, `.kube/`, `kubeconfig*`, `*.key`, `*.crt`\n\n5. Parse tasks.md structure and extract:\n   - **Task phases**: Setup, Tests, Core, Integration, Polish\n   - **Task dependencies**: Sequential vs parallel execution rules\n   - **Task details**: ID, description, file paths, parallel markers [P]\n   - **Execution flow**: Order and dependency requirements\n\n6. Execute implementation following the task plan:\n   - **Phase-by-phase execution**: Complete each phase before moving to the next\n   - **Respect dependencies**: Run sequential tasks in order, parallel tasks [P] can run together\n   - **Follow TDD approach**: Execute test tasks before their corresponding implementation tasks\n   - **File-based coordination**: Tasks affecting the same files must run sequentially\n   - **Validation checkpoints**: Verify each phase completion before proceeding\n\n7. Implementation execution rules:\n   - **Setup first**: Initialize project structure, dependencies, configuration\n   - **Tests before code**: If you need to write tests for contracts, entities, and integration scenarios\n   - **Core development**: Implement models, services, CLI commands, endpoints\n   - **Integration work**: Database connections, middleware, logging, external services\n   - **Polish and validation**: Unit tests, performance optimization, documentation\n\n8. Progress tracking and error handling:\n   - Report progress after each completed task\n   - Halt execution if any non-parallel task fails\n   - For parallel tasks [P], continue with successful tasks, report failed ones\n   - Provide clear error messages with context for debugging\n   - Suggest next steps if implementation cannot proceed\n   - **IMPORTANT** For completed tasks, make sure to mark the task off as [X] in the tasks file.\n\n9. Completion validation:\n   - Verify all required tasks are completed\n   - Check that implemented features match the original specification\n   - Validate that tests pass and coverage meets requirements\n   - Confirm the implementation follows the technical plan\n   - Report final status with summary of completed work\n\nNote: This command assumes a complete task breakdown exists in tasks.md. If tasks are incomplete or missing, suggest running `/speck:tasks` first to regenerate the task list."
              },
              {
                "name": "/init",
                "description": "Install Speck CLI globally via symlink to ~/.local/bin/speck",
                "path": "speck/commands/init.md",
                "frontmatter": {
                  "description": "Install Speck CLI globally via symlink to ~/.local/bin/speck"
                },
                "content": "## User Input\n\n```text\n$ARGUMENTS\n```\n\nYou **MUST** consider the user input before proceeding (if not empty).\n\n## Speck Initialization\n\nThis command initializes Speck in the current repository and optionally installs the CLI globally.\n\n### What This Does\n\n1. **Creates `.speck/` directory** in the current repository with:\n   - `memory/` - For constitution.md and other memory files\n   - `scripts/` - For custom scripts\n2. **Creates `.speck/config.json`** with user preferences for worktree mode and IDE settings\n3. **Configures plugin permissions** in `.claude/settings.local.json` to allow reading from Speck's template files without prompts (this file is gitignored)\n4. **Installs CLI symlink** at `~/.local/bin/speck`\n5. **Suggests next step** - prompts to run `/speck:constitution` if needed\n\n### Configuration Prompts\n\nBefore running `speck init`, ask the user about their preferences:\n\n1. **Worktree Mode** (default: enabled)\n   - Ask: \"Enable worktree mode? This creates isolated directories for each feature branch. (Y/n)\"\n   - If user says \"n\" or \"no\", set `--worktree-enabled false`\n   - If user says \"y\", \"yes\", or presses enter, set `--worktree-enabled true`\n\n2. **IDE Auto-Launch** (default: disabled)\n   - Ask: \"Auto-launch IDE when creating features? (y/N)\"\n   - If user says \"y\" or \"yes\", set `--ide-autolaunch true` and proceed to ask which IDE\n   - If user says \"n\", \"no\", or presses enter, skip IDE settings\n\n3. **IDE Editor** (only if auto-launch enabled)\n   - Ask: \"Which IDE? (vscode/cursor/webstorm/idea/pycharm) [vscode]\"\n   - Use the user's choice or \"vscode\" as default\n\n### Run Initialization\n\nAfter collecting user preferences, run:\n\n```bash\nspeck init [FLAGS]\n```\n\nIf the command fails (speck not found in PATH), fall back to running via bun in a **separate Bash call**:\n\n```bash\nbun $HOME/.claude/plugins/marketplaces/speck-market/speck/dist/speck-cli.js init [FLAGS]\n```\n\nReplace `[FLAGS]` with the appropriate flags based on user responses:\n- `--worktree-enabled true` or `--worktree-enabled false`\n- `--ide-autolaunch true` (if enabled)\n- `--ide-editor <choice>` (if IDE auto-launch is enabled)\n\nExample with all options:\n```bash\nspeck init --worktree-enabled true --ide-autolaunch true --ide-editor cursor\n```\n\nExample with defaults (worktree enabled, no IDE auto-launch):\n```bash\nspeck init --worktree-enabled true\n```\n\n### Options\n\n- `--force`: Force reinstall even if symlink already exists\n- `--json`: Output result as JSON\n- `--worktree-enabled <true|false>`: Enable or disable worktree mode\n- `--ide-autolaunch <true|false>`: Enable or disable IDE auto-launch\n- `--ide-editor <editor>`: IDE editor choice (vscode/cursor/webstorm/idea/pycharm)\n\n### PATH Configuration\n\nIf `~/.local/bin` is not in your PATH, add this to your shell config:\n\n**For bash** (`~/.bashrc`) or **zsh** (`~/.zshrc`):\n```bash\nexport PATH=\"$HOME/.local/bin:$PATH\"\n```\n\nThen reload: `source ~/.bashrc` or `source ~/.zshrc`\n\n### Next Steps\n\nAfter initialization completes successfully:\n\n1. **Restart Claude Code** - Exit this session and start a new one for permission changes to take effect\n2. **Set up your constitution** - Run `/speck:constitution` to define your project principles\n\n**Important**: The permission configuration in `.claude/settings.local.json` requires a Claude Code restart to take effect. Without restarting, you may still see permission prompts when reading template files.\n\n## Context\n\n$ARGUMENTS"
              },
              {
                "name": "/inquiries",
                "description": "Manage inquiries from the expert-help page stored in Cloudflare D1",
                "path": "speck/commands/inquiries.md",
                "frontmatter": {
                  "description": "Manage inquiries from the expert-help page stored in Cloudflare D1"
                },
                "content": "# /speck:inquiries\n\nManage interest inquiries submitted through the expert-help page contact form. This command queries and updates inquiries stored in Cloudflare D1.\n\n## IMPORTANT: Just Run the Commands\n\n**Do NOT explore the codebase or check wrangler configuration.** The management script at `.claude/scripts/inquiries/manage.ts` handles everything internally including directory navigation.\n\n**Start immediately with:**\n```bash\nbun run .claude/scripts/inquiries/manage.ts stats\nbun run .claude/scripts/inquiries/manage.ts list\n```\n\n**Key points:**\n- Always use `bun` (not npm/npx) - this is a Bun project\n- Run commands from the **project root** directory\n- The script internally navigates to `website/` for wrangler operations\n- Add `--remote` flag for production database\n\n## Quick Reference\n\n| Action | Command |\n|--------|---------|\n| List all new inquiries | `/speck:inquiries list` |\n| Filter by status | `/speck:inquiries list --status=contacted` |\n| View inquiry details | `/speck:inquiries view 123` |\n| Mark as contacted | `/speck:inquiries mark-contacted 123` |\n| Archive inquiry | `/speck:inquiries archive 123 --notes=\"Handled\"` |\n| View statistics | `/speck:inquiries stats` |\n| Draft email response | `/speck:inquiries respond 123` |\n| Send email response | `/speck:inquiries send 123 --subject=\"...\" --body=\"...\"` |\n\n## Usage\n\nRun the inquiry management script with the specified action:\n\n```bash\nbun run .claude/scripts/inquiries/manage.ts <action> [options]\n```\n\n### Actions\n\n**list** - Show recent inquiries (newest first)\n```bash\n# All inquiries\nbun run .claude/scripts/inquiries/manage.ts list\n\n# Filter by status\nbun run .claude/scripts/inquiries/manage.ts list --status=new\nbun run .claude/scripts/inquiries/manage.ts list --status=contacted\nbun run .claude/scripts/inquiries/manage.ts list --status=archived\n```\n\n**view** - Show full details of a specific inquiry\n```bash\nbun run .claude/scripts/inquiries/manage.ts view <id>\n```\n\n**mark-contacted** - Update inquiry status to \"contacted\" and set timestamp\n```bash\nbun run .claude/scripts/inquiries/manage.ts mark-contacted <id>\n```\n\n**archive** - Archive an inquiry with optional notes\n```bash\nbun run .claude/scripts/inquiries/manage.ts archive <id>\nbun run .claude/scripts/inquiries/manage.ts archive <id> --notes=\"Handled via email on 2025-01-15\"\n```\n\n**stats** - Show inquiry statistics by status\n```bash\nbun run .claude/scripts/inquiries/manage.ts stats\n```\n\n**respond** - Fetch inquiry details for drafting an email response\n```bash\nbun run .claude/scripts/inquiries/manage.ts respond <id>\n```\nThis outputs the inquiry details formatted for Claude to draft a response, including the original message and a template to fill in.\n\n**send** - Send an email response via Resend API and record in database\n```bash\n# Via --body flag\nbun run .claude/scripts/inquiries/manage.ts send <id> --subject=\"Re: Your Speck Inquiry\" --body=\"Your markdown response...\"\n\n# Via stdin (heredoc) - preferred for multi-line content\nbun run .claude/scripts/inquiries/manage.ts send <id> --subject=\"Re: Your Speck Inquiry\" <<'EOF'\nYour **markdown** response here.\n\n- Supports full markdown\n- Multi-line content\n- Code blocks, etc.\nEOF\n\n# Preview HTML without sending (no RESEND_API_KEY required)\nbun run .claude/scripts/inquiries/manage.ts send <id> --subject=\"...\" --preview <<'EOF'\nPreview content...\nEOF\n```\nThis command:\n- Converts the markdown body to HTML with styled email template\n- Sends the email via Resend API (unless `--preview`)\n- Records the response in the `responses` table\n- Updates the inquiry status to \"contacted\"\n\n## Database Location\n\nBy default, the script queries the **local** D1 database (development).\n\nTo query the **remote** (production) database, add the `--remote` flag:\n\n```bash\nbun run .claude/scripts/inquiries/manage.ts list --remote\nbun run .claude/scripts/inquiries/manage.ts view 123 --remote\n```\n\n## Inquiry Status Values\n\n| Status | Description | Emoji |\n|--------|-------------|-------|\n| `new` | Unread inquiry, needs attention | üÜï |\n| `contacted` | Admin has reached out to the inquirer | üìß |\n| `archived` | Handled or no longer active | üìÅ |\n\n## Example Workflow\n\n### Basic Status Management\n\n1. Check for new inquiries:\n   ```bash\n   bun run .claude/scripts/inquiries/manage.ts list --status=new --remote\n   ```\n\n2. Review an inquiry:\n   ```bash\n   bun run .claude/scripts/inquiries/manage.ts view 42 --remote\n   ```\n\n3. After responding via email, mark as contacted:\n   ```bash\n   bun run .claude/scripts/inquiries/manage.ts mark-contacted 42 --remote\n   ```\n\n4. If no follow-up needed, archive:\n   ```bash\n   bun run .claude/scripts/inquiries/manage.ts archive 42 --notes=\"Scheduled call for next week\" --remote\n   ```\n\n### Email Response Workflow\n\n1. Review a new inquiry and prepare to respond:\n   ```bash\n   bun run .claude/scripts/inquiries/manage.ts respond 42 --remote\n   ```\n\n2. Ask Claude to draft a response based on the inquiry content\n\n3. Send the email (Claude drafts the markdown body):\n   ```bash\n   bun run .claude/scripts/inquiries/manage.ts send 42 \\\n     --subject=\"Re: Your Speck Inquiry\" \\\n     --body=\"Thank you for your interest in Speck!\n\n   I'd be happy to discuss implementation support for your team.\n\n   **Next Steps:**\n   - Schedule a 30-minute discovery call\n   - Review your current development workflow\n\n   Best regards,\n   The Speck Team\" --remote\n   ```\n\n4. The email is sent, recorded in the database, and the inquiry is marked as contacted\n\n## Prerequisites\n\n- **Wrangler CLI**: Accessed via `bunx wrangler` (not npx). Authenticate with `bunx wrangler login`\n- **D1 Database**: The `speck-inquiries` database must exist (created via `bunx wrangler d1 create`)\n- **Migrations**: Run `cd website && bunx wrangler d1 migrations apply speck-inquiries --local` first\n- **RESEND_API_KEY**: Required for `send` command. Set via `export RESEND_API_KEY=re_xxxxx`\n\n## Troubleshooting\n\n**\"no such table: inquiries\"**\n- Run migrations: `cd website && bunx wrangler d1 migrations apply speck-inquiries --local`\n\n**\"no such table: responses\"**\n- Run migrations: `cd website && bunx wrangler d1 migrations apply speck-inquiries --local`\n- Ensure migration 002_create_responses.sql exists\n\n**\"authentication required\"**\n- Run `bunx wrangler login` to authenticate with Cloudflare\n\n**\"RESEND_API_KEY environment variable is not set\"**\n- Set the API key: `export RESEND_API_KEY=re_xxxxx`\n- Get your API key from https://resend.com/api-keys\n\n**Email send fails with \"domain not verified\"**\n- Verify your sending domain in Resend dashboard\n- Default from address is `hello@speck.codes`\n\n**Empty results**\n- Ensure you're querying the correct database (local vs remote)\n- Check that inquiries have been submitted via the form"
              },
              {
                "name": "/link",
                "description": "Link repository to multi-repo speck root",
                "path": "speck/commands/link.md",
                "frontmatter": {
                  "description": "Link repository to multi-repo speck root"
                },
                "content": "# Link Repository to Multi-Repo Speck Root\n\nCreates a `.speck/root` symlink to enable multi-repo mode and registers this repository in the Speck root's linked-repos.md file.\n\n## Usage\n\n```\n/speck:link <path-to-speck-root>\n```\n\n## Examples\n\n**From frontend repo in my-product/ directory:**\n```\n/speck:link ..\n```\n\n**From nested monorepo package (e.g., packages/ui/):**\n```\n/speck:link ../..\n```\n\n**Using absolute path:**\n```\n/speck:link /Users/dev/my-product\n```\n\n## What This Does\n\n1. Creates symlink: `.speck/root` ‚Üí `<path>`\n2. Enables multi-repo mode (automatic detection)\n3. Specs now read/written to `<path>/specs/`\n4. Plans/tasks/constitution remain local to this repo\n5. **Automatically updates** `<path>/.speck/linked-repos.md` to register this repository\n6. Creates reverse symlink: `<speck-root>/.speck/repos/<repo-name>` ‚Üí relative path back to this repo\n\n## Multi-Repo Workflow\n\nAfter linking, you can:\n\n- **Create shared spec**: `/speck:specify \"Feature description\"` (creates spec at speck root)\n- **Generate local plan**: `/speck:plan` (uses this repo's constitution)\n- **Check configuration**: `/speck:env` (shows multi-repo status)\n\n## Implementation\n\nRun the Speck CLI link command:\n\n```bash\nspeck link <path-to-speck-root>\n```\n\nThe CLI handles all the details:\n- Creates `.speck/` directory if needed\n- Creates the symlink with proper path adjustment\n- Sets up reverse symlink at speck root\n- Updates `linked-repos.md`"
              },
              {
                "name": "/plan",
                "description": "Execute the implementation planning workflow using the plan template to generate design artifacts.",
                "path": "speck/commands/plan.md",
                "frontmatter": {
                  "description": "Execute the implementation planning workflow using the plan template to generate design artifacts.",
                  "handoffs": [
                    {
                      "label": "Create Tasks",
                      "agent": "speck.tasks",
                      "prompt": "Break the plan into tasks",
                      "send": true
                    },
                    {
                      "label": "Create Checklist",
                      "agent": "speck.checklist",
                      "prompt": "Create a checklist for the following domain..."
                    }
                  ]
                },
                "content": "## User Input\n\n```text\n$ARGUMENTS\n```\n\nYou **MUST** consider the user input before proceeding (if not empty).\n\n## Workflow Mode Detection\n\nParse command-line flags from user input:\n- `--stacked`: Enable stacked PR workflow mode (write workflow metadata to plan.md)\n- If no flag provided: Default to single-branch mode (no workflow metadata written)\n\n## Outline\n\n1. **Setup**: Extract prerequisite context from the auto-injected comment in the prompt:\n   ```\n   <!-- SPECK_PREREQ_CONTEXT\n   {\"MODE\":\"multi-repo\",\"FEATURE_DIR\":\"/path/to/root-repo/specs/010-feature\",\"IMPL_PLAN\":\"/path/to/child-repo/specs/010-feature/plan.md\",\"TASKS\":\"/path/to/child-repo/specs/010-feature/tasks.md\",\"REPO_ROOT\":\"/path/to/child-repo\",\"TEMPLATE_DIR\":\"/path/to/plugin/templates\",\"AVAILABLE_DOCS\":[\"../../../8-specs/specs/010-feature/spec.md\",\".speck/memory/constitution.md\"]}\n   -->\n   ```\n\n   **Path Usage**:\n   - `FEATURE_DIR`: Directory containing shared artifacts (spec.md, research.md, data-model.md) - **READ ONLY**\n   - `IMPL_PLAN`: Full path where plan.md should be written - **WRITE HERE**\n   - `TASKS`: Full path where tasks.md should be written (used by /speck:tasks)\n   - `REPO_ROOT`: Root directory of current repository (for relative path calculations)\n   - `TEMPLATE_DIR`: Directory containing templates (plan-template.md, spec-template.md, etc.) - **USE FOR TEMPLATES**\n   - `MODE`: \"single-repo\" or \"multi-repo\" (child in multi-repo setup)\n\n   **Multi-repo behavior**:\n   - In single-repo mode: FEATURE_DIR, IMPL_PLAN, and TASKS all point to same directory\n   - In multi-repo mode: FEATURE_DIR points to root repo (shared), IMPL_PLAN/TASKS point to child repo (local)\n\n   **Fallback**: If the comment is not present (VSCode hook bug), run:\n   ```bash\n   speck setup-plan --json\n   ```\n   Parse JSON for FEATURE_SPEC, IMPL_PLAN, SPECS_DIR, BRANCH.\n\n   **IMPORTANT**: Do NOT invent or guess CLI paths. Use ONLY the path above.\n\n   Parse JSON output to extract FEATURE_SPEC, IMPL_PLAN, SPECS_DIR, and BRANCH.\n\n2. **Load context** (use Read tool for all files):\n   - **Read** spec.md and constitution.md from paths in AVAILABLE_DOCS\n   - **Read** plan template from `{TEMPLATE_DIR}/plan-template.md` (e.g., `/Users/.../.claude/plugins/.../templates/plan-template.md`)\n\n3. **Execute plan workflow**: Follow the structure in IMPL_PLAN template to:\n   - Fill Technical Context (mark unknowns as \"NEEDS CLARIFICATION\")\n   - **If --stacked flag provided**: Add workflow mode metadata to plan.md header\n     - After the \"Feature Branch:\", \"Spec:\", \"Status:\", \"Created:\" lines in plan.md header\n     - Insert line: `**Workflow Mode**: stacked-pr`\n     - Analyze user stories in spec.md to suggest groupings:\n       - Group related user stories that could be implemented in sequence\n       - Example: US1,US2 (database layer) ‚Üí US3,US4 (API layer) ‚Üí US5,US6 (UI layer)\n     - Add section to plan.md (after Executive Summary):\n       ```markdown\n       ## User Story Groupings\n\n       **Suggested Stacking Strategy**:\n       - Branch 1: US1, US2 (Database layer)\n       - Branch 2: US3, US4 (API endpoints)\n       - Branch 3: US5, US6 (UI components)\n\n       These groupings represent natural boundaries for stacked PRs. Each group can be implemented in a separate branch with its own pull request.\n       ```\n   - Fill Constitution Check section from constitution\n   - Evaluate gates (ERROR if violations unjustified)\n   - Phase 0: Generate research.md (resolve all NEEDS CLARIFICATION)\n   - Phase 1: Generate data-model.md, contracts/, quickstart.md\n   - Phase 1: Update agent context by running the agent script\n   - Re-evaluate Constitution Check post-design\n\n4. **Write plan.md**: Use the IMPL_PLAN path from prerequisite context to write plan.md file.\n   - **IMPORTANT**: Write to IMPL_PLAN path, NOT to FEATURE_DIR/plan.md\n   - In multi-repo mode, IMPL_PLAN points to child repo, FEATURE_DIR points to root repo\n\n5. **Stop and report**: Command ends after Phase 2 planning. Report branch, IMPL_PLAN path, and generated artifacts.\n\n## Phases\n\n### Phase 0: Outline & Research\n\n1. **Extract unknowns from Technical Context** above:\n   - For each NEEDS CLARIFICATION ‚Üí research task\n   - For each dependency ‚Üí best practices task\n   - For each integration ‚Üí patterns task\n\n2. **Generate and dispatch research agents**:\n\n   ```text\n   For each unknown in Technical Context:\n     Task: \"Research {unknown} for {feature context}\"\n   For each technology choice:\n     Task: \"Find best practices for {tech} in {domain}\"\n   ```\n\n3. **Consolidate findings** in `research.md` using format:\n   - Decision: [what was chosen]\n   - Rationale: [why chosen]\n   - Alternatives considered: [what else evaluated]\n   - **Write to**: `{REPO_ROOT}/specs/{feature}/research.md` (local to child repo - each repo does its own research)\n\n**Output**: research.md with all NEEDS CLARIFICATION resolved\n\n### Phase 1: Design & Contracts\n\n**Prerequisites:** `research.md` complete\n\n**Before generating contracts**: Check for existing shared contracts\n1. If `{FEATURE_DIR}/contracts/` exists and contains files:\n   - Read all contract files in that directory\n   - Use these as constraints for planning (the API is already defined)\n   - Do NOT regenerate contracts - skip to step 3\n2. If no contracts exist, proceed to generate them below\n\n1. **Extract entities from feature spec** ‚Üí `data-model.md`:\n   - Entity name, fields, relationships\n   - Validation rules from requirements\n   - State transitions if applicable\n   - **Write to**: `{REPO_ROOT}/specs/{feature}/data-model.md` (local to child repo - each repo has its own data model)\n\n2. **Generate API contracts** from functional requirements (only if no shared contracts exist):\n   - For each user action ‚Üí endpoint\n   - Use standard REST/GraphQL patterns\n   - **Write to**: `{FEATURE_DIR}/contracts/` (shared - goes to root repo, accessible to all child repos)\n\n3. **Generate quickstart.md** with developer setup instructions:\n   - Prerequisites (runtime versions, dependencies)\n   - Installation steps\n   - Development commands (start, test, build)\n   - Project structure overview\n   - Common tasks and workflows\n   - **Write to**: `{REPO_ROOT}/specs/{feature}/quickstart.md` (local to child repo)\n\n4. **Agent context update**:\n   - Run `speck update-agent-context`\n   - These scripts detect which AI agent is in use\n   - Update the appropriate agent-specific context file\n   - Add only new technology from current plan\n   - Preserve manual additions between markers\n\n**Output**: data-model.md (local), contracts/* (shared, if created), quickstart.md (local), agent-specific file\n\n## Key rules\n\n- Use absolute paths\n- ERROR on gate failures or unresolved clarifications"
              },
              {
                "name": "/specify",
                "description": "Create or update the feature specification from a natural language feature description.",
                "path": "speck/commands/specify.md",
                "frontmatter": {
                  "description": "Create or update the feature specification from a natural language feature description.",
                  "handoffs": [
                    {
                      "label": "Build Technical Plan",
                      "agent": "speck.plan",
                      "prompt": "Create a plan for the spec. I am building with..."
                    },
                    {
                      "label": "Clarify Spec Requirements",
                      "agent": "speck.clarify",
                      "prompt": "Clarify specification requirements",
                      "send": true
                    }
                  ]
                },
                "content": "## User Input\n\n```text\n$ARGUMENTS\n```\n\nYou **MUST** consider the user input before proceeding (if not empty).\n\n## Outline\n\nThe text the user typed after `/speck:specify` in the triggering message **is** the feature description. Assume you always have it available in this conversation even if `$ARGUMENTS` appears literally below. Do not ask the user to repeat it unless they provided an empty command.\n\nGiven that feature description, do this:\n\n1. **Generate a concise short name** (2-4 words) for the branch:\n   - Analyze the feature description and extract the most meaningful keywords\n   - Create a 2-4 word short name that captures the essence of the feature\n   - Use action-noun format when possible (e.g., \"add-user-auth\", \"fix-payment-bug\")\n   - Preserve technical terms and acronyms (OAuth2, API, JWT, etc.)\n   - Keep it concise but descriptive enough to understand the feature at a glance\n   - Examples:\n     - \"I want to add user authentication\" ‚Üí \"user-auth\"\n     - \"Implement OAuth2 integration for the API\" ‚Üí \"oauth2-api-integration\"\n     - \"Create a dashboard for analytics\" ‚Üí \"analytics-dashboard\"\n     - \"Fix payment processing timeout bug\" ‚Üí \"fix-payment-timeout\"\n\n2. **Get next feature number and detect mode**:\n\n   Run: `speck next-feature --json --short-name \"<short-name>\"`\n\n   This single command handles all git branch checking internally and returns:\n   - `NEXT_NUMBER`: The next available feature number\n   - `MODE`: \"single-repo\" or \"multi-repo\"\n   - `SPECS_DIR`: Path to the specs directory\n\n   **If `MODE` is \"multi-repo\"**:\n   - **Ask the user**: \"Create spec at parent (shared across repos) or local (this repo only)? (parent/local)\"\n   - **Wait for user response**\n   - Store the answer as `SPEC_LOCATION` (either \"parent\" or \"local\")\n\n   **If `MODE` is \"single-repo\"**:\n   - Set `SPEC_LOCATION = \"local\"` (no prompt needed)\n\n3. **Create the feature**:\n\n   Run the command `speck create-new-feature --json --no-ide \"$ARGUMENTS\"` with the number from step 2:\n   - Pass `--number NEXT_NUMBER` and `--short-name \"your-short-name\"` along with the feature description\n   - **ALWAYS include `--no-ide`** to defer IDE launch until after spec is fully written\n   - **If multi-repo mode and user chose \"parent\"**: Add `--shared-spec` flag\n   - **If multi-repo mode and user chose \"local\"**: Add `--local-spec` flag (or omit flag - local is default)\n   - Bash example: `speck create-new-feature --json --no-ide --number 5 --short-name \"user-auth\" --shared-spec \"Add user authentication\"`\n   - With custom branch: `speck create-new-feature --json --no-ide --number 5 --short-name \"user-auth\" --branch \"feature/user-auth\" \"Add user authentication\"`\n\n   **IMPORTANT**:\n   - You must only ever run the create-new-feature script once per feature\n   - The JSON is provided in the terminal as output - always refer to it to get the actual content you're looking for\n   - The JSON output will contain BRANCH_NAME, SPEC_FILE, and optionally WORKTREE_PATH\n   - **CRITICAL**: The SPEC_FILE path is an **absolute path** - use it exactly as returned. In worktree mode, SPEC_FILE points to the worktree's specs/ directory (NOT the main repo).\n   - For single quotes in args like \"I'm Groot\", use escape syntax: e.g 'I'\\''m Groot' (or double-quote if possible: \"I'm Groot\")\n   - **Worktree mode**: If worktree.enabled is true in config, create-new-feature will create the worktree and write handoff artifacts, but NOT launch IDE yet (deferred to step 9)\n   - **Flag support** (override config):\n     - If user passed `--branch <name>` flag: Also pass it to create-new-feature to use a custom branch name\n     - If user passed `--no-worktree` flag: Also pass it to create-new-feature to skip worktree creation\n     - If user passed `--worktree` flag: Also pass it to force worktree creation\n     - If user passed `--no-deps` flag: Also pass it to skip dependency installation\n\n4. **Read** spec template from `{TEMPLATE_DIR}/spec-template.md` using Read tool to understand required sections.\n\n5. Follow this execution flow:\n\n    1. Parse user description from Input\n       If empty: ERROR \"No feature description provided\"\n    2. Extract key concepts from description\n       Identify: actors, actions, data, constraints\n    3. For unclear aspects:\n       - Make informed guesses based on context and industry standards\n       - Only mark with [NEEDS CLARIFICATION: specific question] if:\n         - The choice significantly impacts feature scope or user experience\n         - Multiple reasonable interpretations exist with different implications\n         - No reasonable default exists\n       - **LIMIT: Maximum 3 [NEEDS CLARIFICATION] markers total**\n       - Prioritize clarifications by impact: scope > security/privacy > user experience > technical details\n    4. Fill User Scenarios & Testing section\n       If no clear user flow: ERROR \"Cannot determine user scenarios\"\n    5. Generate Functional Requirements\n       Each requirement must be testable\n       Use reasonable defaults for unspecified details (document assumptions in Assumptions section)\n    6. Define Success Criteria\n       Create measurable, technology-agnostic outcomes\n       Include both quantitative metrics (time, performance, volume) and qualitative measures (user satisfaction, task completion)\n       Each criterion must be verifiable without implementation details\n    7. Identify Key Entities (if data involved)\n    8. Return: SUCCESS (spec ready for planning)\n\n6. Write the specification to the **absolute SPEC_FILE path** from the JSON output using the template structure, replacing placeholders with concrete details derived from the feature description (arguments) while preserving section order and headings.\n\n   **IMPORTANT**: Always use the exact SPEC_FILE path returned by `create-new-feature`. Do NOT construct a relative path like `specs/NNN-name/spec.md` - the script may have created the spec in a worktree directory, and SPEC_FILE contains the correct absolute path.\n\n7. **Specification Quality Validation**: After writing the initial spec, validate it against quality criteria:\n\n   a. **Create Spec Quality Checklist**: Generate a checklist file at `FEATURE_DIR/checklists/requirements.md` using the checklist template structure with these validation items (FEATURE_DIR is the directory containing SPEC_FILE, e.g., if SPEC_FILE is `/path/to/specs/001-auth/spec.md`, then FEATURE_DIR is `/path/to/specs/001-auth/`):\n\n      ```markdown\n      # Specification Quality Checklist: [FEATURE NAME]\n\n      **Purpose**: Validate specification completeness and quality before proceeding to planning\n      **Created**: [DATE]\n      **Feature**: [Link to spec.md]\n\n      ## Content Quality\n\n      - [ ] No implementation details (languages, frameworks, APIs)\n      - [ ] Focused on user value and business needs\n      - [ ] Written for non-technical stakeholders\n      - [ ] All mandatory sections completed\n\n      ## Requirement Completeness\n\n      - [ ] No [NEEDS CLARIFICATION] markers remain\n      - [ ] Requirements are testable and unambiguous\n      - [ ] Success criteria are measurable\n      - [ ] Success criteria are technology-agnostic (no implementation details)\n      - [ ] All acceptance scenarios are defined\n      - [ ] Edge cases are identified\n      - [ ] Scope is clearly bounded\n      - [ ] Dependencies and assumptions identified\n\n      ## Feature Readiness\n\n      - [ ] All functional requirements have clear acceptance criteria\n      - [ ] User scenarios cover primary flows\n      - [ ] Feature meets measurable outcomes defined in Success Criteria\n      - [ ] No implementation details leak into specification\n\n      ## Notes\n\n      - Items marked incomplete require spec updates before `/speck:clarify` or `/speck:plan`\n      ```\n\n   b. **Run Validation Check**: Review the spec against each checklist item:\n      - For each item, determine if it passes or fails\n      - Document specific issues found (quote relevant spec sections)\n\n   c. **Handle Validation Results**:\n\n      - **If all items pass**: Mark checklist complete and proceed to step 6\n\n      - **If items fail (excluding [NEEDS CLARIFICATION])**:\n        1. List the failing items and specific issues\n        2. Update the spec to address each issue\n        3. Re-run validation until all items pass (max 3 iterations)\n        4. If still failing after 3 iterations, document remaining issues in checklist notes and warn user\n\n      - **If [NEEDS CLARIFICATION] markers remain**:\n        1. Extract all [NEEDS CLARIFICATION: ...] markers from the spec\n        2. **LIMIT CHECK**: If more than 3 markers exist, keep only the 3 most critical (by scope/security/UX impact) and make informed guesses for the rest\n        3. For each clarification needed (max 3), present options to user in this format:\n\n           ```markdown\n           ## Question [N]: [Topic]\n\n           **Context**: [Quote relevant spec section]\n\n           **What we need to know**: [Specific question from NEEDS CLARIFICATION marker]\n\n           **Suggested Answers**:\n\n           | Option | Answer | Implications |\n           |--------|--------|--------------|\n           | A      | [First suggested answer] | [What this means for the feature] |\n           | B      | [Second suggested answer] | [What this means for the feature] |\n           | C      | [Third suggested answer] | [What this means for the feature] |\n           | Custom | Provide your own answer | [Explain how to provide custom input] |\n\n           **Your choice**: _[Wait for user response]_\n           ```\n\n        4. **CRITICAL - Table Formatting**: Ensure markdown tables are properly formatted:\n           - Use consistent spacing with pipes aligned\n           - Each cell should have spaces around content: `| Content |` not `|Content|`\n           - Header separator must have at least 3 dashes: `|--------|`\n           - Test that the table renders correctly in markdown preview\n        5. Number questions sequentially (Q1, Q2, Q3 - max 3 total)\n        6. Present all questions together before waiting for responses\n        7. Wait for user to respond with their choices for all questions (e.g., \"Q1: A, Q2: Custom - [details], Q3: B\")\n        8. Update the spec by replacing each [NEEDS CLARIFICATION] marker with the user's selected or provided answer\n        9. Re-run validation after all clarifications are resolved\n\n   d. **Update Checklist**: After each validation iteration, update the checklist file with current pass/fail status\n\n8. Report completion with branch name, spec file path, checklist results, and readiness for the next phase (`/speck:clarify` or `/speck:plan`).\n\n9. **[SPECK-EXTENSION] Deferred IDE Launch** (Only if worktree was created in step 3):\n   - Check if WORKTREE_PATH was returned by create-new-feature (indicates worktree mode was used)\n   - If WORKTREE_PATH exists AND user did NOT pass `--no-ide` flag:\n     1. Run: `speck launch-ide --worktree-path \"$WORKTREE_PATH\"`\n     2. If launch succeeds: Report \"‚úì Launched IDE at [WORKTREE_PATH]\"\n     3. If launch fails (non-fatal): Report \"‚ö† IDE launch failed: [error]\"\n   - This ensures the IDE opens AFTER the spec and checklists are fully written, allowing the handoff to work correctly\n\n**NOTE:** The script creates and checks out the new branch and initializes the spec file before writing.\n\n## General Guidelines\n\n## Quick Guidelines\n\n- Focus on **WHAT** users need and **WHY**.\n- Avoid HOW to implement (no tech stack, APIs, code structure).\n- Written for business stakeholders, not developers.\n- DO NOT create any checklists that are embedded in the spec. That will be a separate command.\n\n### Section Requirements\n\n- **Mandatory sections**: Must be completed for every feature\n- **Optional sections**: Include only when relevant to the feature\n- When a section doesn't apply, remove it entirely (don't leave as \"N/A\")\n\n### For AI Generation\n\nWhen creating this spec from a user prompt:\n\n1. **Make informed guesses**: Use context, industry standards, and common patterns to fill gaps\n2. **Document assumptions**: Record reasonable defaults in the Assumptions section\n3. **Limit clarifications**: Maximum 3 [NEEDS CLARIFICATION] markers - use only for critical decisions that:\n   - Significantly impact feature scope or user experience\n   - Have multiple reasonable interpretations with different implications\n   - Lack any reasonable default\n4. **Prioritize clarifications**: scope > security/privacy > user experience > technical details\n5. **Think like a tester**: Every vague requirement should fail the \"testable and unambiguous\" checklist item\n6. **Common areas needing clarification** (only if no reasonable default exists):\n   - Feature scope and boundaries (include/exclude specific use cases)\n   - User types and permissions (if multiple conflicting interpretations possible)\n   - Security/compliance requirements (when legally/financially significant)\n\n**Examples of reasonable defaults** (don't ask about these):\n\n- Data retention: Industry-standard practices for the domain\n- Performance targets: Standard web/mobile app expectations unless specified\n- Error handling: User-friendly messages with appropriate fallbacks\n- Authentication method: Standard session-based or OAuth2 for web apps\n- Integration patterns: RESTful APIs unless specified otherwise\n\n### Success Criteria Guidelines\n\nSuccess criteria must be:\n\n1. **Measurable**: Include specific metrics (time, percentage, count, rate)\n2. **Technology-agnostic**: No mention of frameworks, languages, databases, or tools\n3. **User-focused**: Describe outcomes from user/business perspective, not system internals\n4. **Verifiable**: Can be tested/validated without knowing implementation details\n\n**Good examples**:\n\n- \"Users can complete checkout in under 3 minutes\"\n- \"System supports 10,000 concurrent users\"\n- \"95% of searches return results in under 1 second\"\n- \"Task completion rate improves by 40%\"\n\n**Bad examples** (implementation-focused):\n\n- \"API response time is under 200ms\" (too technical, use \"Users see results instantly\")\n- \"Database can handle 1000 TPS\" (implementation detail, use user-facing metric)\n- \"React components render efficiently\" (framework-specific)\n- \"Redis cache hit rate above 80%\" (technology-specific)"
              },
              {
                "name": "/tasks",
                "description": "Generate an actionable, dependency-ordered tasks.md for the feature based on available design artifacts.",
                "path": "speck/commands/tasks.md",
                "frontmatter": {
                  "description": "Generate an actionable, dependency-ordered tasks.md for the feature based on available design artifacts.",
                  "handoffs": [
                    {
                      "label": "Analyze For Consistency",
                      "agent": "speck.analyze",
                      "prompt": "Run a project analysis for consistency",
                      "send": true
                    },
                    {
                      "label": "Implement Project",
                      "agent": "speck.implement",
                      "prompt": "Start the implementation in phases",
                      "send": true
                    }
                  ]
                },
                "content": "## User Input\n\n```text\n$ARGUMENTS\n```\n\nYou **MUST** consider the user input before proceeding (if not empty).\n\n## Flag Support\n\nThis command supports the following flags for branch-aware task generation (US4):\n\n- `--branch <name>`: Generate tasks for specific branch (requires stacked PR mode)\n- `--stories <US1,US2>`: Filter to specific user stories (comma-separated)\n\n**Examples**:\n```bash\n/speck:tasks --branch username/db-layer --stories US1\n/speck:tasks --stories US1,US2\n/speck:tasks --branch username/api\n```\n\n## Outline\n\n1. **Parse flags from $ARGUMENTS** (T050-T054):\n   - Check for `--branch <name>` flag and extract branch name\n   - Check for `--stories <US1,US2>` flag and extract comma-separated story IDs\n   - If `--branch` provided: Load `.speck/branches.json` (T052) and validate branch exists (T053)\n   - If `--stories` provided: Store story IDs for filtering (will validate against spec.md later) (T054)\n\n2. **Setup**: Extract prerequisite context from the auto-injected comment in the prompt:\n   ```\n   <!-- SPECK_PREREQ_CONTEXT\n   {\"MODE\":\"multi-repo\",\"FEATURE_DIR\":\"/path/to/root-repo/specs/010-feature\",\"IMPL_PLAN\":\"/path/to/child-repo/specs/010-feature/plan.md\",\"TASKS\":\"/path/to/child-repo/specs/010-feature/tasks.md\",\"REPO_ROOT\":\"/path/to/child-repo\",\"TEMPLATE_DIR\":\"/path/to/plugin/templates\",\"AVAILABLE_DOCS\":[\"../../../8-specs/specs/010-feature/spec.md\",\"specs/010-feature/plan.md\",\"specs/010-feature/research.md\"]}\n   -->\n   ```\n\n   **Path Usage**:\n   - `FEATURE_DIR`: Directory containing shared artifacts (spec.md, research.md, data-model.md, plan.md in multi-repo mode) - **READ ONLY**\n   - `IMPL_PLAN`: Full path to plan.md (for reading in multi-repo mode)\n   - `TASKS`: Full path where tasks.md should be written - **WRITE HERE**\n   - `REPO_ROOT`: Root directory of current repository (for relative path calculations)\n   - `TEMPLATE_DIR`: Directory containing templates (tasks-template.md, spec-template.md, etc.) - **USE FOR TEMPLATES**\n   - `MODE`: \"single-repo\" or \"multi-repo\" (child in multi-repo setup)\n\n   **Multi-repo behavior**:\n   - In single-repo mode: FEATURE_DIR and TASKS point to same directory\n   - In multi-repo mode: FEATURE_DIR points to root repo (shared), TASKS points to child repo (local)\n\n   Use the FEATURE_DIR and AVAILABLE_DOCS values from this JSON.\n\n   **Fallback**: If the comment is not present (VSCode hook bug), run:\n   ```bash\n   speck check-prerequisites --json\n   ```\n\n   Parse JSON output to extract FEATURE_DIR, AVAILABLE_DOCS, MODE, and other fields.\n\n   **IMPORTANT**: Do NOT invent or guess CLI paths. Use ONLY the path above.\n\n3. **Load design documents**:\n   Use Read tool to load files from the paths in AVAILABLE_DOCS:\n   - Iterate through AVAILABLE_DOCS array and use Read tool for each file\n   - AVAILABLE_DOCS contains relative paths from REPO_ROOT (e.g., \"specs/010-feature/plan.md\" or \"../../../8-specs/specs/010-feature/spec.md\")\n   - Use Glob if you need to find additional files (e.g., contracts/*.json)\n\n   **Required files**: plan.md (tech stack, libraries, structure), spec.md (user stories with priorities)\n   **Optional files**: data-model.md (entities), contracts/ (API endpoints), research.md (decisions), quickstart.md (test scenarios)\n   Note: Not all projects have all documents. Generate tasks based on what's available.\n\n4. **Execute task generation workflow**:\n   - Load plan.md and extract tech stack, libraries, project structure\n   - Load spec.md and extract user stories with their priorities (P1, P2, P3, etc.)\n   - **If `--stories` flag provided** (T055-T056):\n     - Parse story IDs from flag (e.g., \"US1,US2\" ‚Üí [\"US1\", \"US2\"])\n     - Validate each story ID exists in spec.md (T055)\n     - Filter user stories to only include requested IDs (T056)\n   - **If `--stories` flag NOT provided**: Use all user stories from spec.md\n   - If data-model.md exists: Extract entities and map to user stories\n   - If contracts/ exists: Map endpoints to user stories\n   - If research.md exists: Extract decisions for setup tasks\n   - **Task generation strategy** (T057):\n     - If `--stories` flag used: Skip Setup/Foundational phases, generate only requested story tasks\n     - If `--stories` flag NOT used: Generate all phases (Setup, Foundational, all user stories, Polish)\n   - Generate tasks organized by user story (see Task Generation Rules below)\n   - Generate dependency graph showing user story completion order\n   - Create parallel execution examples per user story\n   - Validate task completeness (each user story has all needed tasks, independently testable)\n\n5. **Generate tasks.md** (T058): **Read** tasks template from `{TEMPLATE_DIR}/tasks-template.md` using Read tool, then fill with:\n   - **Output file path**:\n     - **IMPORTANT**: Use TASKS path from prerequisite context, NOT FEATURE_DIR\n     - If `--branch` flag provided: Replace `.md` extension in TASKS path with `-<branch-name>.md`\n     - If `--branch` flag NOT provided: Use TASKS path as-is (default)\n     - In multi-repo mode, TASKS points to child repo, FEATURE_DIR points to root repo\n   - Correct feature name from plan.md\n   - Phase 1: Setup tasks (project initialization)\n   - Phase 2: Foundational tasks (blocking prerequisites for all user stories)\n   - Phase 3+: One phase per user story (in priority order from spec.md)\n   - Each phase includes: story goal, independent test criteria, tests (if requested), implementation tasks\n   - Final Phase: Polish & cross-cutting concerns\n   - All tasks must follow the strict checklist format (see Task Generation Rules below)\n   - Clear file paths for each task\n   - Dependencies section showing story completion order\n   - Parallel execution examples per story\n   - Implementation strategy section (MVP first, incremental delivery)\n\n6. **Report** (T059): Output path to generated tasks.md and summary:\n   - File path (either `tasks.md` or `tasks-<branch-name>.md`)\n   - If `--branch` flag used: Display branch name and spec ID\n   - If `--stories` flag used: Display filtered story IDs\n   - Total task count\n   - Task count per user story\n   - Parallel opportunities identified\n   - Independent test criteria for each story\n   - Suggested MVP scope (typically just User Story 1)\n   - Format validation: Confirm ALL tasks follow the checklist format (checkbox, ID, labels, file paths)\n\nContext for task generation: $ARGUMENTS\n\nThe tasks.md should be immediately executable - each task must be specific enough that an LLM can complete it without additional context.\n\n## Task Generation Rules\n\n**CRITICAL**: Tasks MUST be organized by user story to enable independent implementation and testing.\n\n**Tests are OPTIONAL**: Only generate test tasks if explicitly requested in the feature specification or if user requests TDD approach.\n\n### Checklist Format (REQUIRED)\n\nEvery task MUST strictly follow this format:\n\n```text\n- [ ] [TaskID] [P?] [Story?] Description with file path\n```\n\n**Format Components**:\n\n1. **Checkbox**: ALWAYS start with `- [ ]` (markdown checkbox)\n2. **Task ID**: Sequential number (T001, T002, T003...) in execution order\n3. **[P] marker**: Include ONLY if task is parallelizable (different files, no dependencies on incomplete tasks)\n4. **[Story] label**: REQUIRED for user story phase tasks only\n   - Format: [US1], [US2], [US3], etc. (maps to user stories from spec.md)\n   - Setup phase: NO story label\n   - Foundational phase: NO story label\n   - User Story phases: MUST have story label\n   - Polish phase: NO story label\n5. **Description**: Clear action with exact file path\n\n**Examples**:\n\n- ‚úÖ CORRECT: `- [ ] T001 Create project structure per implementation plan`\n- ‚úÖ CORRECT: `- [ ] T005 [P] Implement authentication middleware in src/middleware/auth.py`\n- ‚úÖ CORRECT: `- [ ] T012 [P] [US1] Create User model in src/models/user.py`\n- ‚úÖ CORRECT: `- [ ] T014 [US1] Implement UserService in src/services/user_service.py`\n- ‚ùå WRONG: `- [ ] Create User model` (missing ID and Story label)\n- ‚ùå WRONG: `T001 [US1] Create model` (missing checkbox)\n- ‚ùå WRONG: `- [ ] [US1] Create User model` (missing Task ID)\n- ‚ùå WRONG: `- [ ] T001 [US1] Create model` (missing file path)\n\n### Task Organization\n\n1. **From User Stories (spec.md)** - PRIMARY ORGANIZATION:\n   - Each user story (P1, P2, P3...) gets its own phase\n   - Map all related components to their story:\n     - Models needed for that story\n     - Services needed for that story\n     - Endpoints/UI needed for that story\n     - If tests requested: Tests specific to that story\n   - Mark story dependencies (most stories should be independent)\n\n2. **From Contracts**:\n   - Map each contract/endpoint ‚Üí to the user story it serves\n   - If tests requested: Each contract ‚Üí contract test task [P] before implementation in that story's phase\n\n3. **From Data Model**:\n   - Map each entity to the user story(ies) that need it\n   - If entity serves multiple stories: Put in earliest story or Setup phase\n   - Relationships ‚Üí service layer tasks in appropriate story phase\n\n4. **From Setup/Infrastructure**:\n   - Shared infrastructure ‚Üí Setup phase (Phase 1)\n   - Foundational/blocking tasks ‚Üí Foundational phase (Phase 2)\n   - Story-specific setup ‚Üí within that story's phase\n\n### Phase Structure\n\n- **Phase 1**: Setup (project initialization)\n- **Phase 2**: Foundational (blocking prerequisites - MUST complete before user stories)\n- **Phase 3+**: User Stories in priority order (P1, P2, P3...)\n  - Within each story: Tests (if requested) ‚Üí Models ‚Üí Services ‚Üí Endpoints ‚Üí Integration\n  - Each phase should be a complete, independently testable increment\n- **Final Phase**: Polish & Cross-Cutting Concerns"
              },
              {
                "name": "/taskstoissues",
                "description": "Convert existing tasks into actionable, dependency-ordered GitHub issues for the feature based on available design artifacts.",
                "path": "speck/commands/taskstoissues.md",
                "frontmatter": {
                  "description": "Convert existing tasks into actionable, dependency-ordered GitHub issues for the feature based on available design artifacts.",
                  "tools": [
                    "github/github-mcp-server/issue_write"
                  ]
                },
                "content": "## User Input\n\n```text\n$ARGUMENTS\n```\n\nYou **MUST** consider the user input before proceeding (if not empty).\n\n## Outline\n\n1. Extract prerequisite context from the auto-injected comment in the prompt:\n   ```\n   <!-- SPECK_PREREQ_CONTEXT\n   {\"MODE\":\"single-repo\",\"FEATURE_DIR\":\"/path/to/specs/010-feature\",\"AVAILABLE_DOCS\":[\"tasks.md\"]}\n   -->\n   ```\n   Use FEATURE_DIR to locate tasks.md. All paths are absolute.\n\n   **Fallback**: If the comment is not present (VSCode hook bug), run:\n   ```bash\n   speck check-prerequisites --json --require-tasks --include-tasks\n   ```\n   Parse FEATURE_DIR and AVAILABLE_DOCS list.\n\n   Parse JSON output to extract FEATURE_DIR and AVAILABLE_DOCS.\n\n   **IMPORTANT**: Do NOT invent or guess CLI paths. Use ONLY the path above.\n\n1. From FEATURE_DIR, read the tasks.md file.\n1. Get the Git remote by running:\n\n```bash\ngit config --get remote.origin.url\n```\n\n**ONLY PROCEED TO NEXT STEPS IF THE REMOTE IS A GITHUB URL**\n\n1. For each task in the list, use the GitHub MCP server to create a new issue in the repository that is representative of the Git remote.\n\n**UNDER NO CIRCUMSTANCES EVER CREATE ISSUES IN REPOSITORIES THAT DO NOT MATCH THE REMOTE URL**"
              }
            ],
            "skills": [
              {
                "name": "pr-review",
                "description": "Review GitHub pull requests with VSCode integration. Use when the user asks to \"review a PR\", \"review PRs\", \"check pull requests\", or wants AI-assisted code review with clickable navigation and one-click comment posting via the speck-review CLI.",
                "path": "speck-reviewer/skills/pr-review/SKILL.md",
                "frontmatter": {
                  "name": "pr-review",
                  "description": "Review GitHub pull requests with VSCode integration. Use when the user asks to \"review a PR\", \"review PRs\", \"check pull requests\", or wants AI-assisted code review with clickable navigation and one-click comment posting via the speck-review CLI."
                },
                "content": "# PR Review Skill\n\nYou are a **code reviewer** helping review pull requests with VSCode\nintegration. This workflow combines systematic code review with clickable\nnavigation, guided walkthroughs for large PRs, and one-click comment posting.\n\n## Core Principles\n\n1. **Reviewer Role**: You are acting as a code reviewer, not a developer. Your\n   job is to provide feedback, not implement changes.\n\n2. **Read-Only Mode**: During PR review, you MUST NOT use Edit, Write, or any\n   file modification tools EXCEPT for writing to `.speck/review-state.json` for\n   session persistence. This constraint ensures review integrity.\n\n3. **Constructive Feedback**: Use friendly, suggestion-based tone. Only be\n   strongly opinionated on obvious bugs or security issues.\n\n---\n\n## Guided Review Mode (Large PRs)\n\nFor PRs with 5+ changed files, use guided review mode for a structured\nwalkthrough:\n\n### Planning Phase\n\n1. **Analyze PR with clustering**:\n   ```bash\n   speck-review analyze <PR_NUMBER>\n   ```\n\n2. **Check for self-review**:\n   ```bash\n   speck-review check-self-review <PR_AUTHOR>\n   ```\n   If self-review detected, announce clearly with this messaging:\n\n   > **Self-review detected!** Since you're reviewing your own PR, I'll use\n   > **self-review mode**:\n   >\n   > - Comments will be posted as **issue comments** (not formal review\n   >   comments)\n   > - **Approve/Request Changes** actions are hidden (you can't formally\n   >   approve your own PR)\n   > - I'll still provide the same thorough review with suggested improvements\n   >\n   > This is useful for self-checks before requesting review from teammates.\n\n   Do NOT imply that self-review mode means \"no review\" or \"fewer comments\" -\n   the review is just as thorough, only the posting mechanism differs.\n\n   **Action Restrictions in Self-Review Mode:** When in self-review mode, **hide\n   the Approve/Request Changes actions** from all output:\n   - Do NOT show \"(a) - approve\" or \"(b) - request changes\" options\n   - Only show \"(c) Comment only\" as the review submission option\n   - Replace \"post all then a\" examples with just \"post all\"\n   - The user cannot formally approve their own PR, so don't offer it\n\n3. **Present PR narrative** showing the story of changes and logical file\n   groupings\n\n### Generating the PR Narrative\n\nThe narrative should tell the **story** of changes, not just list files or\nstatistics.\n\n**Use the PR description!** The author wrote it to explain their changes - read\nthe `body` field from `gh pr view` and:\n\n- Quote or paraphrase key points the author made\n- Reference their stated motivation or context\n- Build on their explanation rather than ignoring it\n\nInclude in your narrative:\n\n1. **Purpose**: What problem does this PR solve? (quote/reference PR\n   description)\n2. **Approach**: How are the changes organized? (from cluster analysis)\n3. **Flow**: How do changes build on each other? (dependency order)\n4. **Key additions**: What's new or notable? (cross-cutting concerns like new\n   deps, migrations, config)\n\n**Example narrative** (assuming PR description mentioned \"adding JWT auth for\nthe API\"):\n\n> As the author notes, this PR implements **JWT-based authentication for the\n> API**. The changes build from database schema (migrations) ‚Üí core auth logic\n> (AuthService) ‚Üí API endpoints (routes) ‚Üí tests. Key additions include rate\n> limiting middleware and refresh token rotation.\n\nPresent this narrative BEFORE the file cluster table. The cluster table should\nbe labeled \"**Review Order**\" or \"**File Clusters**\", not \"PR Narrative\".\n\n### Cluster Semantic Refinement\n\nWhen the CLI returns heuristic clusters via `analyze`, **refine\nthem with semantic understanding**:\n\n1. **Meaningful Cluster Names**:\n   - Transform directory-based names into semantic names\n   - BAD: \"src/auth/*\", \"cli/src\", \"Components\"\n   - GOOD: \"Authentication Refactor\", \"CLI State Management\", \"User Profile\n     Components\"\n   - Names should describe _what the changes do_, not _where files are_\n\n2. **Cluster Descriptions**:\n   - Explain WHY these files are grouped together\n   - Explain WHY this cluster should be reviewed in this order (dependencies)\n   - Example: \"These files implement the JWT token flow. Review before API\n     routes since the routes depend on these auth utilities.\"\n\n3. **Cross-Cutting Concerns**:\n   - Identify changes that span multiple clusters (config changes, new\n     dependencies, migrations)\n   - Call these out prominently at the start of the review\n   - Example: \"**Cross-cutting:** This PR adds `bcrypt` dependency and updates\n     TypeScript config\"\n\n4. **Boundary Refinement**:\n   - The heuristic may group files by directory, but sometimes files should move\n     between clusters\n   - If a test file in `tests/` clearly tests a specific service in\n     `src/services/`, consider noting that relationship\n   - Use your understanding of the code to suggest better logical groupings\n\n**Example transformation:**\n\nHeuristic output:\n\n```\nCluster 1: cli/src (5 files)\nCluster 2: extension/src (3 files)\n```\n\nRefined output:\n\n```\nCluster 1: State Persistence Layer (3 files)\n  - state.ts, types.ts, storage.ts\n  - \"Core state management used by all other components. Review first.\"\n\nCluster 2: CLI Commands (2 files)\n  - index.ts, commands.ts\n  - \"Depends on state layer. These expose the state to users.\"\n\nCluster 3: VSCode Extension Bridge (3 files)\n  - extension.ts, bridge.ts, handlers.ts\n  - \"Connects CLI to VSCode. Review after understanding CLI commands.\"\n```\n\n### Walkthrough Flow\n\nFor each cluster, follow this flow:\n\n1. **Show Cluster** - Present the cluster card (see format below)\n2. **Explain Context** - Why this cluster matters, what it does, dependencies\n3. **Highlight Focus Areas** - What to look for in each file\n4. **Review Files** - Let user examine files, answer questions\n5. **Collect Comments** - Gather any review comments for this cluster\n6. **Prompt for Next Action** - Ask: \"Ready for next cluster?\" or offer\n   navigation options\n\n**Example interaction:**\n\n```\n## Cluster 2: Authentication Logic (Priority: 2)\n\n**Context:** This cluster implements the JWT token flow. It depends on Cluster 1 (Data Models) for the User type.\n\n**Files:**\n| File | Changes | Focus Areas |\n|------|---------|-------------|\n| [src/auth/token.ts](src/auth/token.ts) | +85/-0 | Token generation, expiry handling |\n| [src/auth/validate.ts](src/auth/validate.ts) | +42/-5 | Input validation, error messages |\n\n**What to look for:**\n- Token expiry configuration (hardcoded vs env var?)\n- Error messages (too verbose? security leak?)\n- Async error handling\n\n---\nWhen ready: \"next\" for Cluster 3, or ask questions about this cluster.\n```\n\n### Small PR Handling\n\nFor PRs with **1-2 changed files**, skip the clustering overhead:\n\n- Don't show cluster cards or priority ordering\n- Present files directly with focus notes\n- Use simplified format:\n  ```\n  ## Quick Review: PR #142\n\n  **Files Changed:**\n  - [src/utils/format.ts](src/utils/format.ts) (+12/-3) - Utility function update\n\n  **Focus Areas:** Edge case handling, input validation\n\n  **Summary:** Small change to date formatting utility.\n  ```\n\n### Cluster Card Format\n\nPresent each cluster as a review section:\n\n```markdown\n## Cluster 1: [Cluster Name] (Priority: 1)\n\n**Why review first:** [Explanation of dependencies]\n\n| File                            | Changes | Focus Areas    |\n| ------------------------------- | ------- | -------------- |\n| [path/to/file.ts](path/to/file.ts) | +45/-12 | [Review notes] |\n\n**What to look for:**\n\n- [Specific guidance for this cluster]\n```\n\n### Navigation Commands\n\nSupport natural language navigation:\n\n- \"next\" / \"continue\" ‚Üí Move to next cluster\n- \"back\" / \"previous\" ‚Üí Return to previous cluster\n- \"go to [cluster/file]\" ‚Üí Jump to specific location\n- \"show comments\" ‚Üí Display all staged comments\n- \"where was I?\" ‚Üí Show current progress\n\n### State Persistence\n\nTrack review progress in `.speck/review-state.json`:\n\n```bash\n# Show current state\nspeck-review state show\n\n# Clear state (start fresh)\nspeck-review state clear\n```\n\n**When initializing a new review:**\n\n1. After generating the PR narrative and refining clusters, **persist them to\n   state**\n2. Use the Write tool to save the ReviewSession to `.speck/review-state.json`\n3. The state file schema is:\n   ```json\n   {\n     \"$schema\": \"review-state-v1\",\n     \"prNumber\": 142,\n     \"branchName\": \"feature/xyz\",\n     \"repoFullName\": \"owner/repo\",\n     \"baseBranch\": \"main\",\n     \"reviewMode\": \"normal\",\n     \"title\": \"PR title here\",\n     \"author\": \"username\",\n     \"narrative\": \"Generated narrative here...\",\n     \"clusters\": [...],\n     \"comments\": [],\n     \"reviewedSections\": [],\n     \"questions\": [],\n     \"startedAt\": \"2025-12-06T10:00:00Z\",\n     \"lastUpdated\": \"2025-12-06T10:00:00Z\"\n   }\n   ```\n4. This allows resuming reviews across sessions\n\n### Progress Tracking\n\n**After each cluster reviewed:**\n\n- Mark the cluster as \"reviewed\" in state\n- Update `reviewedSections` array\n- Save state immediately\n\n**Resume Detection:**\n\nAt the start of any review:\n\n1. Check: `speck-review state show`\n2. If state exists:\n   - Validate PR# and branch match current checkout\n   - If match ‚Üí Offer to resume: \"Found existing review for PR #X. Resume where\n     you left off?\"\n   - If mismatch ‚Üí Warn: \"Found state for PR #Y but you're on PR #X. Clear and\n     start fresh?\"\n3. Options:\n   - \"resume\" ‚Üí Continue from last position\n   - \"start fresh\" ‚Üí Clear state and begin new review\n   - \"abort\" ‚Üí Cancel review\n\n**\"Where was I?\" Command:**\n\nDisplay progress summary:\n\n```markdown\n## Review Progress: PR #142\n\n**Status:** 2 of 4 clusters reviewed\n\n### Clusters:\n\n| # | Cluster        | Status     |\n| - | -------------- | ---------- |\n| 1 | Data Models    | ‚úì Reviewed |\n| 2 | Authentication | ‚úì Reviewed |\n| 3 | API Routes     | ‚è≥ Current |\n| 4 | Tests          | ‚óã Pending  |\n\n### Comments:\n\n- **Staged:** 3 (will post)\n- **Skipped:** 1\n- **Posted:** 0\n\n### Current Position:\n\nCluster 3: API Routes - [src/routes/auth.ts](src/routes/auth.ts)\n\n**Actions:** \"next\" to continue, \"post all\" to finish, \"show comments\" for\ndetails\n```\n\nDistinguish:\n\n- Posted comments: Already on GitHub\n- Staged comments: Will be posted on \"post all\"\n- Skipped comments: Excluded from posting\n\n**Review Completion:**\n\nDetect completion when:\n\n- All clusters reviewed AND\n- All staged comments posted (or none remaining)\n\nOn completion:\n\n1. Confirm: \"Review complete! All comments posted.\"\n2. Auto-clear state file\n3. Offer final actions: \"View PR on GitHub\" link\n\n---\n\n## Prerequisites\n\n- `gh` CLI installed and authenticated\n- Current directory is within a git repository with a PR\n\n---\n\n## Detecting Your Environment\n\nCheck your system prompt for context about where you're running:\n\n**VSCode Extension (Webview):**\n\n```\n# VSCode Extension Context\nYou are running inside a VSCode native extension environment.\n```\n\nWhen running in the VSCode extension webview:\n\n- ‚úÖ **Relative file links work**: `[file.ts:42](path/file.ts#L42)` - clickable!\n- ‚úÖ Use **numbered commands** for actions - user says \"post 1, 2\" and you\n  execute via Bash\n\n**Integrated Terminal (CLI):**\n\n- No \"VSCode Extension Context\" section in system prompt\n- ‚úÖ Use **numbered commands** for actions - same as webview\n\n---\n\n## Step 1: Find Relevant PRs\n\nFind open PRs where the user is assigned, requested as reviewer, or has already\nreviewed:\n\n```bash\ngh pr list \\\n  --search \"is:open (review-requested:@me OR reviewed-by:@me OR assignee:@me)\" \\\n  --limit 10 \\\n  --json number,title,author,reviewRequests,assignees,createdAt \\\n  --jq '.[] | {number, title, author: .author.login, reviewers: [.reviewRequests[]?.login], assignees: [.assignees[]?.login], created: .createdAt}'\n```\n\nIf multiple PRs, present as numbered list and ask which to review. If only one,\nconfirm before proceeding.\n\n---\n\n## Step 2: Check Out and Open PR\n\nOnce confirmed, check out the PR:\n\n```bash\n# Check out the PR locally\ngh pr checkout <PR_NUMBER>\n```\n\n---\n\n## Step 3: Examine the PR\n\n```bash\n# Get PR details (use --json to avoid Projects Classic deprecation error)\ngh pr view <PR_NUMBER> --json title,body,state,author,baseRefName,headRefName,additions,deletions,changedFiles,url\n\n# Get the full diff against base branch\ngh pr diff <PR_NUMBER>\n\n# Get changed files list\ngh pr diff <PR_NUMBER> --name-only\n\n# Check for existing review comments (shows resolved vs open)\nspeck-review list-comments\n\n# List changed files with clickable links (after checkout)\nspeck-review files\n```\n\n**Note on file-specific diffs:** `gh pr diff` doesn't support file path filtering.\nTo view a specific file's diff after checkout:\n```bash\ngit diff origin/<base-branch> -- <file-path>\n```\nOr simply use the Read tool for new files (the full content is the diff).\n\n**Note on existing comments:** The `list-comments` command shows comments\ngrouped by status:\n\n- **Open** comments need attention - these are unresolved discussions\n- **Resolved** comments have been addressed - don't repeat these in your review\n\nWhen presenting existing comments to the user, only highlight **open**\n(unresolved) comments as issues to address. Resolved comments can be mentioned\nfor context but shouldn't be treated as active concerns.\n\n### Existing Comments Integration\n\n**Group by file for lookup:**\n\n- When reviewing a file, check if it has existing comments\n- Present relevant open comments before suggesting new ones\n\n**Surface during file review:**\n\n```markdown\n### src/auth/token.ts\n\n**Existing discussions (2 open):**\n\n- Line 42: @alice: \"Should we add rate limiting here?\" (unresolved)\n- Line 67: @bob: \"Token format question\" (unresolved)\n\n**Your review notes:** [Your observations about this file...]\n```\n\n**Indicate resolved status:**\n\n- ‚úÖ Resolved: Show for context but don't re-raise\n- ‚ö†Ô∏è Open: Highlight, consider if your review relates\n- üí¨ Threads with replies: Show reply count, link to GitHub for full context\n\n### Edge Cases\n\n**Skip Walkthrough Option:** If user says \"skip walkthrough\" or \"just show\ncomments\":\n\n- Jump directly to suggested comments section\n- Skip cluster-by-cluster review\n- Still show narrative summary first\n\n**Merge Conflicts / Checkout Issues:** If PR has merge conflicts or checkout\nfails:\n\n```\n‚ö†Ô∏è This PR has merge conflicts or cannot be checked out locally.\n\n**Limited Review Mode:**\n- Showing diff via `gh pr diff` (no local checkout)\n- File navigation links may not work\n- Comments can still be posted via GitHub API\n\n[Continue with remote diff review]\n```\n\n**Long Comment Threads:** For threads with 5+ replies:\n\n```markdown\n**Thread at line 42:** 8 replies (latest: @alice, 2 hours ago) Summary:\nDiscussion about error handling approach - consensus moving toward Option B.\n[View full thread on GitHub](https://github.com/...)\n```\n\n---\n\n## Step 4: Analyze the Changes\n\nExamine the diff and provide:\n\n### High-Level Summary\n\n- Overall purpose of this PR\n- New APIs introduced (endpoints, functions, methods)\n- New or modified data structures (types, interfaces, schemas)\n- New dependencies or libraries added\n- Architectural or design pattern changes\n- Configuration changes\n- Database migrations or schema changes\n- Any breaking changes\n\n### Dependency Check\n\n- For new dependencies: check if actively maintained\n- Flag archived, deprecated, or unmaintained libraries\n- Look for existing libraries in codebase that could be used instead (check\n  imports across codebase)\n\n### Impact Assessment\n\n- How does this affect existing code?\n- What areas need to be aware of these changes?\n- Documentation implications?\n\n---\n\n## Step 5: Review Focus Areas\n\nProvide ordered list of files/directories to review (foundational changes first,\nthen core logic, then usages, then tests).\n\n**Output format** (use relative links):\n\n```markdown\n### Review Order\n\n1. **Database/Schema** - Foundational changes\n   - [migrations/001_add_users.sql](migrations/001_add_users.sql) - Check\n     migration safety, rollback plan\n\n2. **Core Types** - Data structures\n   - [src/types/user.ts](src/types/user.ts) - Interface design, optional vs\n     required\n\n3. **Business Logic** - Core implementation\n   - [src/services/auth.ts](src/services/auth.ts) - Security, error handling\n   - [src/services/user.ts](src/services/user.ts) - Validation logic\n\n4. **API Layer** - Endpoints\n   - [src/routes/auth.ts](src/routes/auth.ts) - Input validation, response\n     shapes\n\n5. **Tests** - Coverage\n   - [tests/auth.test.ts](tests/auth.test.ts) - Edge cases, mocking\n```\n\nFor each area, note:\n\n- API or DB schema design considerations\n- Complex logic needing careful examination\n- Potential edge cases or error handling gaps\n- Performance considerations\n- Security implications\n- Test coverage gaps\n- Code style or consistency issues\n\n---\n\n## Step 6: Suggested Comments\n\nPrepare review comments. For each:\n\n- Keep short and to the point\n- Use friendly, suggestion-based tone (\"Consider...\", \"Might be worth...\", \"Nit:\n  ...\")\n- Only be strongly opinionated if there's an obvious bug or security issue\n- **IMPORTANT: Verify line numbers** by reading actual file content before\n  suggesting\n- **IMPORTANT: Use actual file paths** in links - use the path from when you\n  read the file, not an assumed directory prefix\n\n**Output format with numbered commands:**\n\n```markdown\n### Suggested Comments\n\n| # | Location                                                | Comment                                                        |\n| - | ------------------------------------------------------- | -------------------------------------------------------------- |\n| 1 | [src/services/auth.ts:42](src/services/auth.ts#L42)     | Consider adding rate limiting to prevent brute force attempts  |\n| 2 | [src/services/auth.ts:67](src/services/auth.ts#L67)     | Nit: token expiry should be configurable via env var           |\n| 3 | [src/middleware/auth.ts:15](src/middleware/auth.ts#L15) | Might want to log failed auth attempts for security monitoring |\n\n**To post:** \"post 1, 3\" or \"post all\" **To skip:** \"skip 2\"\n```\n\n---\n\n## Step 6.5: Comment Refinement\n\nBefore posting, allow the user to refine comments. **Save state immediately\nafter any modification**.\n\n### Refinement Commands\n\nSupport these natural language commands:\n\n**Rewording:**\n\n- \"reword #1\" ‚Üí Ask what they want instead, or suggest alternatives\n- \"change #2 to say...\" ‚Üí Replace with their text\n- \"make #1 friendlier\" / \"be more direct on #3\" ‚Üí Adjust tone\n\n**Combining:**\n\n- \"combine #1 and #2\" ‚Üí Merge into a single comment\n- \"merge #2 into #1\" ‚Üí Add #2's content to #1, remove #2\n\n**Skip/Restore:**\n\n- \"skip #2\" ‚Üí Mark as skipped (won't be posted)\n- \"restore #2\" ‚Üí Bring back a skipped comment\n- \"only post 1, 3\" ‚Üí Skip all others\n\n**Tone Adjustment:**\n\n- \"soften #1\" ‚Üí Make more tentative/polite\n- \"strengthen #1\" ‚Üí Make more assertive/direct\n- \"make #1 a nit\" ‚Üí Add \"Nit:\" prefix, soften\n\n### Comment List Display\n\n**\"show comments\"** or **\"show final list\"** displays:\n\n```markdown\n### Comment Status\n\n**Staged (will post):**\n\n| # | Location             | Comment                          |\n| - | -------------------- | -------------------------------- |\n| 1 | src/auth.ts:42       | Consider adding rate limiting... |\n| 3 | src/middleware.ts:15 | Might want to log failed...      |\n\n**Skipped:**\n\n| # | Location       | Comment                  |\n| - | -------------- | ------------------------ |\n| 2 | src/auth.ts:67 | ~~Nit: token expiry...~~ |\n\n**Posted:** (none yet)\n```\n\n**\"show history for #1\"** displays edit history:\n\n```markdown\n### Comment #1 History\n\n- Original: \"You should add rate limiting\"\n- Softened: \"Consider adding rate limiting\"\n- Ready to post ‚úì\n```\n\n### Comment Posting\n\n**Individual posting:**\n\n- Each staged comment retains its own post link/action\n- \"post 1\" ‚Üí Posts just that comment\n\n**Batch posting:**\n\n- \"post all\" ‚Üí Post all staged comments sequentially\n- For each comment: `speck-review comment <file> <line> \"<body>\"`\n\n**After posting:**\n\n- Update comment state to \"posted\"\n- Record the GitHub comment ID for reference\n- Save state immediately\n\n### State Persistence\n\nAfter ANY comment modification:\n\n1. Update the in-memory comment list\n2. Write to `.speck/review-state.json` immediately\n3. Confirm the change to the user\n\nThis ensures no refinements are lost if the session ends.\n\n---\n\n## Contextual Q&A\n\nDuring review, users may ask questions about the changes. Answer these\ncontextually:\n\n### Answering \"Why\" Questions\n\nWhen the user asks questions like:\n\n- \"Why did they change this?\"\n- \"What's the purpose of this file?\"\n- \"Why is this approach used?\"\n\n**How to respond:**\n\n1. Check the PR description for author's stated rationale\n2. Look at commit messages for context\n3. Analyze the code changes for implicit reasons\n4. If unclear, say \"Based on the changes, it appears...\" rather than guessing\n\n### Contextual Analysis\n\nWhen answering questions:\n\n1. Reference specific lines/files from the PR\n2. Quote relevant code snippets\n3. Explain the relationship between changes\n4. Connect to broader patterns in the codebase\n\n**Example:**\n\n```\nUser: \"Why is the token validation moved here?\"\n\nClaude: Looking at the PR, the token validation was moved from\n`middleware/auth.ts:45` to `services/AuthService.ts:78`.\n\nBased on the commit message \"centralize auth logic\", this appears to\nconsolidate validation into the service layer. The middleware now\ncalls `AuthService.validateToken()` rather than having its own logic.\n\nThis follows the pattern used elsewhere - see `UserService.validateUser()`\nat `services/UserService.ts:32` which uses the same approach.\n```\n\n### Distinguishing PR Changes vs Existing Code\n\nAlways be clear about what's new vs. existing:\n\n- **New in this PR:** Code added or modified in the current diff\n- **Existing code:** Code that was already in the codebase before this PR\n\nUse phrases like:\n\n- \"This PR introduces...\" for new changes\n- \"The existing code at X does...\" for context\n- \"This changes the previous behavior from X to Y...\"\n\n### Referencing Related Code\n\nWhen explaining patterns or decisions:\n\n1. Search for similar patterns in the codebase (use Grep/Glob)\n2. Reference existing implementations: \"Similar to how `UserService` handles\n   this at line X\"\n3. Point out deviations: \"Note this differs from the pattern at Y\"\n4. Link to relevant files for context\n\n### Recording Q&A\n\nAfter answering a substantive question:\n\n1. Record it in the review state for reference\n2. The Q&A history helps maintain context across sessions\n3. Previous Q&A can inform future answers\n\n---\n\n## Step 7: Human Approval Gate\n\n**‚ö†Ô∏è IMPORTANT: Do NOT post any comments until explicitly approved.**\n\nPresent findings and wait for feedback:\n\n```markdown\n---\n\n## Ready to Submit?\n\n**Summary:** Solid implementation! Left suggestions around rate limiting and\nconfigurability.\n\n**Proposed comments:** 3 **Recommendation:** Approve\n\n---\n\nYou can:\n\n- Modify wording: \"change #1 to say...\"\n- Skip comments: \"skip 2\" or \"only post 1, 3\"\n- Change review type: \"request changes instead\"\n\n**Actions:**\n\n- \"post 1, 3\" - post specific comments\n- \"post all\" - post all comments\n- \"a\" - approve | \"b\" - request changes | \"c\" - comment only\n- \"post all then a\" - post comments and approve\n\nWhen ready, just say what you want (e.g., \"post all then a\").\n```\n\n---\n\n## Step 8: Execute Review\n\nOnly after approval, execute:\n\n### Post Comments\n\nFor each approved comment:\n\n```bash\nspeck-review comment <file> <line> \"<message>\"\n```\n\n### Submit Review\n\n```bash\n# Keep review body SHORT - detailed feedback is in line comments\nspeck-review review approve \"Short summary here.\"\n\n# Or for changes requested:\nspeck-review review request-changes \"Please address the comments above.\"\n```\n\n### Reply to Existing Comments (if needed)\n\n```bash\nspeck-review comment-reply <comment_id> \"<reply>\"\n```\n\n---\n\n## CLI Reference\n\n```bash\n# Navigation\nspeck-review files                         # List changed files with links\n\n# Guided Review\nspeck-review analyze [pr]                  # Analyze PR with clustering, output JSON\nspeck-review state [show|clear]            # Show or clear review session state\nspeck-review check-self-review <author>    # Check if reviewing own PR\nspeck-review spec-context                  # Load Speck spec for current branch\n\n# Comments\nspeck-review comment <file> <line> <body>  # Add line comment\nspeck-review comment-reply <id> <body>     # Reply to existing comment\nspeck-review comment-delete <id>           # Delete a comment\nspeck-review list-comments                 # List all PR comments\n\n# Review\nspeck-review review approve [body]         # Approve PR\nspeck-review review request-changes <body> # Request changes\nspeck-review review comment [body]         # Comment without approval\n\n# Utility (FR-027)\nspeck-review link <file> [line]            # Generate navigation link\nspeck-review actions                       # Display navigation action menu\nspeck-review run-actions                   # Display review action menu\nspeck-review review-table [--example]      # Generate formatted comment table\nspeck-review submit-actions [body]         # Display submit review menu\nspeck-review logs                          # Display log file locations\n```\n\n---\n\n## Speck-Aware Context\n\nWhen a Speck specification exists for the branch:\n\n1. The `spec-context` command returns parsed requirements and user stories\n2. Reference spec requirements in comments: \"This implements FR-003\"\n3. Note alignment or misalignment with spec acceptance criteria\n4. Suggest spec updates if implementation differs\n\nIf no spec exists, proceed with standard review (graceful degradation per FR-022).\n\n---\n\n## Fork PR Limitations\n\nWhen reviewing PRs from forks:\n\n- Line comments may fail due to GitHub permissions\n- Use issue comments instead: `gh pr comment <PR_NUMBER> --body \"<message>\"`\n- The CLI handles this automatically in self-review mode\n- Inform the user if fork limitations are encountered\n\n---\n\n## Output Formats by Context\n\n### Webview Format (VSCode Extension)\n\nUse **relative file links** for navigation and **numbered commands** for\nactions:\n\n```markdown\n### Suggested Comments\n\n| # | Location                                                              | Comment                                              |\n| - | --------------------------------------------------------------------- | ---------------------------------------------------- |\n| 1 | [src/services/auth.ts:42](src/services/auth.ts#L42)                   | Consider adding rate limiting to prevent brute force |\n| 2 | [src/services/auth.ts:78](src/services/auth.ts#L78)                   | Nit: JWT_EXPIRY should be configurable via env var   |\n| 3 | [src/middleware/requireAuth.ts:23](src/middleware/requireAuth.ts#L23) | Might be worth logging failed auth attempts          |\n\n**To post comments:** Tell me which ones (e.g., \"post 1, 3\" or \"post all\") **To\nskip comments:** \"skip 2\" or \"only post 1\"\n```\n\nAfter user says \"post 1, 3\":\n\n```bash\nspeck-review comment src/services/auth.ts 42 \"Consider adding rate limiting to prevent brute force\"\nspeck-review comment src/middleware/requireAuth.ts 23 \"Might be worth logging failed auth attempts\"\n```\n\n### Terminal Format (CLI)\n\nSame numbered format works:\n\n```markdown\n### Suggested Comments\n\n| # | File:Line                        | Comment                                              |\n| - | -------------------------------- | ---------------------------------------------------- |\n| 1 | src/services/auth.ts:42          | Consider adding rate limiting to prevent brute force |\n| 2 | src/services/auth.ts:78          | Nit: JWT_EXPIRY should be configurable via env var   |\n| 3 | src/middleware/requireAuth.ts:23 | Might be worth logging failed auth attempts          |\n\n**To post:** \"post 1, 3\" or \"post all\"\n```\n\n### Quick Actions (Both Contexts)\n\nUse numbered/lettered shortcuts for common actions:\n\n```markdown\n### Actions\n\n(a) Approve PR (b) Request changes (c) Comment only (no approval)\n\nSay \"a\" to approve, or \"post 1, 2 then a\" to post comments and approve.\n```\n\n---\n\n## Complete Example Session\n\nThis example shows a typical review workflow.\n\n**User:** Review PRs\n\n**Claude:**\n\n```markdown\nFound 2 PRs requiring your review:\n\n1. **#142** \"Add user authentication\" by @alice (requested 2 days ago)\n2. **#138** \"Fix payment processing bug\" by @bob (requested 5 days ago)\n\nWhich PR would you like to review?\n```\n\n**User:** 1\n\n**Claude:** _checks out PR, runs analyze, examines diff_\n\n```markdown\n## PR #142: Add user authentication\n\n### Summary\n\nThis PR adds JWT-based authentication to the API:\n\n- New `AuthService` class with login/register/token refresh\n- User model extended with `passwordHash` and `refreshToken` fields\n- Protected route middleware\n- Login/register/logout endpoints\n\n**New Dependencies:**\n\n- ‚úÖ `jsonwebtoken` (12M weekly downloads, active)\n- ‚úÖ `bcrypt` (5M weekly downloads, active)\n\n**Breaking Changes:** None\n\n---\n\n### Review Order\n\n1. [prisma/migrations/20240115_auth.sql](prisma/migrations/20240115_auth.sql) -\n   Schema migration\n2. [src/types/auth.ts](src/types/auth.ts) - New types\n3. [src/services/AuthService.ts](src/services/AuthService.ts) - Core auth logic\n   ‚≠ê\n4. [src/middleware/requireAuth.ts](src/middleware/requireAuth.ts) - Route\n   protection\n5. [src/routes/auth.ts](src/routes/auth.ts) - Endpoints\n6. [tests/auth.test.ts](tests/auth.test.ts) - Test coverage\n\n---\n\n### Suggested Comments\n\n| # | Location                                                              | Comment                                                                |\n| - | --------------------------------------------------------------------- | ---------------------------------------------------------------------- |\n| 1 | [src/services/AuthService.ts:42](src/services/AuthService.ts#L42)     | Consider adding rate limiting on login attempts to prevent brute force |\n| 2 | [src/services/AuthService.ts:78](src/services/AuthService.ts#L78)     | Nit: JWT_EXPIRY should be configurable via environment variable        |\n| 3 | [src/middleware/requireAuth.ts:23](src/middleware/requireAuth.ts#L23) | Might be worth logging failed auth attempts for security monitoring    |\n\n---\n\n### Ready to Submit?\n\n**Summary:** Clean auth implementation. Left minor suggestions around rate\nlimiting and configurability.\n\n**Comments:** 3 | **Recommendation:** Approve\n\n**Actions:**\n\n- \"post 1, 3\" - post specific comments\n- \"post all\" - post all comments\n- \"skip 2\" - exclude from posting\n- \"a\" - approve | \"b\" - request changes | \"c\" - comment only\n- \"post all then a\" - post comments and approve\n```\n\n**User:** Skip 2, post the rest and approve\n\n**Claude:**\n\n```bash\nspeck-review comment src/services/AuthService.ts 42 \"Consider adding rate limiting on login attempts to prevent brute force\"\nspeck-review comment src/middleware/requireAuth.ts 23 \"Might be worth logging failed auth attempts for security monitoring\"\nspeck-review review approve \"Clean auth implementation! Left minor suggestions around rate limiting and logging.\"\n```\n\n```markdown\n‚úÖ Posted comment on src/services/AuthService.ts:42\n‚úÖ Posted comment on src/middleware/requireAuth.ts:23\n‚úÖ Approved PR #142\n```"
              },
              {
                "name": "speck-help",
                "description": "Answer questions about Speck specs, plans, tasks, requirements, progress, architecture, user stories, feature status, and constitution. Interprets spec.md, plan.md, tasks.md files. Use when users ask about feature requirements, implementation status, or Speck workflow artifacts.",
                "path": "speck/skills/speck-help/SKILL.md",
                "frontmatter": {
                  "name": "speck-help",
                  "description": "Answer questions about Speck specs, plans, tasks, requirements, progress, architecture, user stories, feature status, and constitution. Interprets spec.md, plan.md, tasks.md files. Use when users ask about feature requirements, implementation status, or Speck workflow artifacts."
                },
                "content": "# Speck Workflow Skill\n\n**Purpose**: Automatically interpret Speck specification artifacts (spec.md,\nplan.md, tasks.md) and answer natural language questions about features without\nrequiring explicit slash commands.\n\n**Activation**: This skill activates when users ask questions about Speck\nfeatures, mention file types (spec/plan/tasks), or reference Speck concepts\n(requirements, user stories, architecture, etc.).\n\n**Scope**: Read-only operations. This skill NEVER modifies files. For creating\nor updating files, guide users to appropriate slash commands.\n\n**Additional Resources**:\n\n- **[reference.md](reference.md)** - Detailed interpretation rules, file states,\n  error formats\n- **[examples.md](examples.md)** - Usage examples showing skill in action\n- **[workflows.md](workflows.md)** - Advanced features (multi-repo, worktrees,\n  session handoff)\n\n---\n\n## Core Capabilities\n\n### 1. Feature Discovery\n\nWhen users reference features, use **three-tier matching** to locate the correct\nfeature directory:\n\n#### Tier 1: Exact Match (Highest Priority)\n\n- Direct directory name match: `specs/005-speck-skill/`\n\n#### Tier 2: Numeric Prefix Match (High Priority)\n\n- User provides feature number (e.g., \"005\", \"5\", \"feature 003\")\n- Zero-pad numbers to 3 digits: \"5\" ‚Üí \"005\"\n- Match against pattern: `specs/NNN-*/`\n\n#### Tier 3: Fuzzy/Substring Match (Lower Priority)\n\n- User provides partial name (e.g., \"skill\", \"auth\", \"plugin\")\n- Filter by case-insensitive substring match\n- If multiple matches, ask for clarification\n\n**Disambiguation**: When multiple features match, check conversation context\nfirst. If ambiguous, ask: \"Did you mean: 003-user-auth or 012-auth-tokens?\"\n\n**Error Handling**: List all available features, use Levenshtein distance for\ntypo suggestions, explain matching rules.\n\n**Worktree Context**: Worktrees share the same `specs/` directory as main\nrepository. Feature discovery works identically in worktrees and main repo.\n\n---\n\n### 2. Template References\n\nSpeck uses templates in `$PLUGIN_ROOT/templates/` to define expected structure\nfor artifacts:\n\n**Template Locations**:\n\n- Spec template: `$PLUGIN_ROOT/templates/spec-template.md`\n- Plan template: `$PLUGIN_ROOT/templates/plan-template.md`\n- Tasks template: `$PLUGIN_ROOT/templates/tasks-template.md`\n\n**When to Reference Templates**:\n\n- User asks \"What should go in [section]?\" ‚Üí Extract HTML comments from template\n- User asks \"Does my [spec/plan/tasks] follow the template?\" ‚Üí Compare against\n  template (see [reference.md](reference.md) for workflow)\n\n**Template Structure**: Templates use consistent markdown patterns (H1/H2/H3)\nwith HTML comments for section purposes and guidelines.\n\n---\n\n### 3. Section Annotation Patterns\n\n**Summary**: Templates use inline annotations to indicate section requirements.\n\n- **Mandatory sections**: `## Section Name *(mandatory)*`\n- **Conditional sections**: `## Section Name *(include if...)*`\n- **HTML comments**: Provide guidance (ACTION REQUIRED, IMPORTANT, general\n  purpose)\n\n**For full details**: See\n[reference.md](reference.md#section-annotation-patterns)\n\n---\n\n### 4. File State Classification\n\nEvery artifact file can be in one of **five states**:\n\n1. **MISSING** - File doesn't exist ‚Üí ERROR\n2. **EMPTY** - File exists but has no content ‚Üí ERROR\n3. **MALFORMED** - Invalid markdown/structure ‚Üí WARNING (extract partial info)\n4. **INCOMPLETE** - Missing mandatory sections ‚Üí WARNING (calculate completeness\n   %)\n5. **VALID** - All mandatory sections present ‚Üí SUCCESS\n\n**Graceful Degradation**: For MALFORMED and INCOMPLETE states, extract maximum\npossible information, return completeness score, list warnings, provide recovery\nguidance.\n\n**For full details**: See [reference.md](reference.md#file-state-classification)\n\n---\n\n### 5. Error Message Format\n\n**Summary**: Use structured format with severity, context, and recovery\nguidance.\n\nExample:\n\n```\nERROR: Spec Not Found\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ spec.md not found at specs/006-feature/          ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ Recovery: Run /speck:specify \"Feature desc\"      ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n```\n\n**Severity Levels**: ERROR (blocking), WARNING (non-blocking), INFO\n(informational)\n\n**For full details and examples**: See\n[reference.md](reference.md#error-message-format)\n\n---\n\n### 6. Conversation Context Tracking\n\n**Track**:\n\n- Recently mentioned features (last 5)\n- Current feature context\n- Implicit references (\"it\", \"that\", \"the spec\")\n\n**Usage**: Resolve implicit references to features discussed earlier in\nconversation. Reset context when user explicitly mentions different feature or\nafter 10+ turns.\n\n---\n\n### 7. Multi-Repo Mode Detection\n\n**Summary**: Detect if project uses multi-repo mode via `.speck/root` symlink.\n\n**Key Concepts**:\n\n- **Detection**: Check for `.speck/root` symlink ‚Üí multi-repo child repo\n- **Child repos**: Share specs/ directory, have local plan.md/tasks.md\n- **Root repo**: Contains shared specs/, manages constitution\n\n**Query Examples**:\n\n- \"Is this a multi-repo setup?\" ‚Üí Check for symlink\n- \"What's the parent spec?\" ‚Üí Read metadata from spec.md\n\n**For full details**: See [workflows.md](workflows.md#multi-repo-mode-detection)\n\n---\n\n### 8. Worktree Mode Detection\n\n**Summary**: Detect Git worktree integration for isolated parallel development.\n\n**Key Concepts**:\n\n- **Detection**: Check `.speck/config.json` for `worktree.enabled: true`\n- **Metadata**: `.speck/worktrees/<branch>.json` tracks worktree associations\n- **File rules**: Configuration files copied, dependencies symlinked\n- **IDE auto-launch**: VSCode/Cursor/JetBrains launch automatically\n\n**Query Examples**:\n\n- \"Is this in a worktree?\" ‚Üí Check metadata or git worktree list\n- \"What's the worktree config?\" ‚Üí Read config.json\n\n**For full details**: See [workflows.md](workflows.md#worktree-mode-detection)\n\n---\n\n### 9. Session Handoff\n\n**Summary**: Automatic context transfer when creating new feature worktrees.\n\n**Key Concepts**:\n\n- **Handoff document**: `.speck/handoff.md` written to new worktrees\n- **SessionStart hook**: Automatically loads handoff context when Claude session\n  starts\n- **Self-cleanup**: Hook archives handoff after loading and removes itself from\n  settings\n- **Context transfer**: Feature context, spec location, and pending tasks\n  transferred to new session\n\n**How It Works**:\n\n1. When `/speck:specify` creates a new worktree, it writes `.speck/handoff.md`\n2. It also configures `.claude/settings.json` with a SessionStart hook\n3. When a new Claude session starts in the worktree, the hook fires\n4. The hook reads handoff.md and injects context via\n   `hookSpecificOutput.additionalContext`\n5. After loading, the hook archives the handoff file and removes itself\n\n**Query Examples**:\n\n- \"What's in the handoff document?\" ‚Üí Read `.speck/handoff.md` in worktree\n- \"Did the session handoff work?\" ‚Üí Check for `.speck/handoff.done.md`\n  (archived)\n- \"How do I create a feature with handoff?\" ‚Üí Use\n  `/speck:specify \"Feature description\"`\n\n**Handoff Document Contents**:\n\n- Feature name and spec location\n- Repository context (single/multi-repo mode)\n- Pending implementation tasks\n- Relevant file paths and references\n\n---\n\n## Artifact Interpretation Quick Reference\n\n**For detailed artifact interpretation** (metadata blocks, mandatory sections,\nparsing rules), see\n[reference.md](reference.md#artifact-specific-interpretation).\n\n**spec.md**: Requirements, user stories, success criteria **plan.md**:\nImplementation approach, technical context, constitution check **tasks.md**:\nTask breakdown, dependencies, checkpoints\n\n---\n\n## Limitations\n\n**Read-Only Operations**: This skill NEVER modifies files. For creating or\nupdating Speck artifacts:\n\n- Creating specs: `/speck:specify \"Feature description\"`\n- Clarifying specs: `/speck:clarify`\n- Generating plans: `/speck:plan`\n- Generating tasks: `/speck:tasks`\n- Creating checklists: `/speck:checklist`\n- Analyzing consistency: `/speck:analyze`\n\n**Non-Destructive Constraint**:\n\n- Only reads existing files\n- Never writes, modifies, or deletes files\n- Never runs external commands or tools\n- Provides guidance to appropriate slash commands when modifications needed\n\n**Activation Limitations**: Skill may not activate if query is too vague, about\nnon-Speck topics, or doesn't establish feature context.\n\n---\n\n## Troubleshooting Activation Issues\n\n**Issue: Too Vague** ‚ùå \"What's left?\" ‚úÖ \"What tasks are left for feature 005?\"\n\n**Issue: No Speck Context** ‚ùå \"Show me the plan\" ‚úÖ \"Show me plan.md for the\nspeck skill\"\n\n**Issue: Wrong Topic** ‚ùå \"How do I implement this in TypeScript?\" ‚úÖ \"What's\nthe technical approach in the plan for feature 005?\"\n\n**Best Practices**:\n\n1. Mention feature explicitly (number or name)\n2. Use Speck terminology (spec, plan, tasks, requirements)\n3. Be specific about file types\n4. Establish context first\n\n---\n\n## Slash Command Reference\n\nThis skill is for **reading and understanding** existing Speck artifacts. When\nusers need to **create or modify** files, guide them to these slash commands:\n\n| Command            | Purpose                                                                  | Example Trigger Phrase                                            |\n| ------------------ | ------------------------------------------------------------------------ | ----------------------------------------------------------------- |\n| `/speck:specify`   | Create or update feature specification (with optional worktree creation) | \"Run /speck:specify to create a new spec\"                         |\n| `/speck:clarify`   | Resolve ambiguities and add missing sections                             | \"Run /speck:clarify to resolve [NEEDS CLARIFICATION] markers\"     |\n| `/speck:plan`      | Generate implementation plan from spec                                   | \"Run /speck:plan to create the implementation plan\"               |\n| `/speck:tasks`     | Generate actionable task breakdown                                       | \"Run /speck:tasks to create a task list\"                          |\n| `/speck:analyze`   | Check cross-artifact consistency and quality                             | \"Run /speck:analyze to validate spec/plan/tasks consistency\"      |\n| `/speck:implement` | Execute tasks from tasks.md                                              | \"Run /speck:implement to start implementation\"                    |\n| `/speck:link`      | Link child repository to multi-repo root                                 | \"Run /speck:link ../root to connect this repo to multi-repo root\" |\n| `/speck:init`      | Install Speck CLI globally via symlink                                   | \"Run /speck:init to install the speck command\"                    |\n| `/speck:help`      | Load speck-help skill for natural language questions                     | \"Run /speck:help to ask questions about Speck\"                    |\n| `/speck:env`       | Check Speck environment and configuration                                | \"Run /speck:env to see current repo mode (single/multi-repo)\"     |\n\n**Worktree Flags for `/speck:specify`**:\n\n- `--no-worktree`: Skip worktree creation\n- `--no-ide`: Skip IDE auto-launch\n- `--no-deps`: Skip dependency installation\n- `--reuse-worktree`: Reuse existing worktree if present\n\n**When to Suggest Commands**:\n\n- **Missing spec.md** ‚Üí Suggest `/speck:specify \"Feature description\"`\n- **[NEEDS CLARIFICATION] markers** ‚Üí Suggest `/speck:clarify`\n- **Missing plan.md** ‚Üí Suggest `/speck:plan`\n- **Missing tasks.md** ‚Üí Suggest `/speck:tasks`\n- **Incomplete sections** ‚Üí Suggest `/speck:clarify` or manual editing\n- **After clarification** ‚Üí Suggest `/speck:analyze` to check consistency\n- **After task generation** ‚Üí Suggest `/speck:implement` to execute tasks\n\n**For complete command list**: Direct users to type `/help` in Claude Code.\n\n---\n\n## Plugin Extensibility\n\nSpeck follows a modular architecture where specialized capabilities are\ndelivered as optional plugins. This keeps the core Speck plugin focused on\nspecification workflows while enabling extensions for related tasks.\n\n### Available Plugins\n\n| Plugin             | Command    | Purpose                                                             |\n| ------------------ | ---------- | ------------------------------------------------------------------- |\n| **speck**          | `/speck:*` | Core specification workflow (specify, plan, tasks, implement)       |\n| **speck-reviewer** | `/review`  | AI-assisted PR review with cluster analysis and Speck-aware context |\n\n### Installing Extension Plugins\n\nAll Speck plugins are installed through the Claude Code plugin system:\n\n```bash\n# Install speck-reviewer for PR reviews\n/plugin install speck-reviewer@speck-market\n```\n\n### speck-reviewer Plugin\n\nThe speck-reviewer plugin adds structured PR review capabilities:\n\n- **Cluster-Based Review**: Groups related files for coherent review sessions\n- **Speck-Aware Context**: References spec requirements when available\n- **Comment Management**: Stage, refine, and batch-post review comments\n- **Session Persistence**: Resume interrupted reviews\n\n**When to use**: Use `/speck-reviewer:review` after creating a PR for a Speck\nfeature. The plugin will automatically load any spec context for your branch.\n\n**Learn more**: See\n[plugin documentation](https://beta.speck.codes/docs/plugins/speck-reviewer) for\nfull usage guide.\n\n---\n\n## Summary\n\nThis skill enables natural language interaction with Speck workflow artifacts:\n\n- ‚úÖ Automatically activates when users ask about features\n- ‚úÖ Interprets spec.md (requirements, user stories, success criteria)\n- ‚úÖ Interprets plan.md (technical approach, architecture, constitution)\n- ‚úÖ Interprets tasks.md (status, dependencies, progress)\n- ‚úÖ Compares files against templates\n- ‚úÖ Handles incomplete/malformed files gracefully\n- ‚úÖ Provides actionable recovery guidance\n- ‚úÖ Maintains conversation context for follow-up questions\n- ‚úÖ Read-only operations (non-destructive)\n\n**Additional Resources**:\n\n- **[reference.md](reference.md)** - Detailed rules, workflows, edge cases\n- **[examples.md](examples.md)** - Usage examples\n- **[workflows.md](workflows.md)** - Advanced features (multi-repo, worktrees,\n  session handoff)\n\n**Goal**: Reduce need for manual file reading and slash command usage by 80%,\nenabling developers to ask natural questions and get accurate answers about\ntheir Speck features."
              }
            ]
          },
          {
            "name": "speck-reviewer",
            "description": "AI-powered PR review with Speck-aware context and structured walkthroughs",
            "source": "./speck-reviewer",
            "category": "development-tools",
            "version": "1.2.0",
            "author": {
              "name": "Nathan Prabst"
            },
            "install_commands": [
              "/plugin marketplace add nprbst/speck-market",
              "/plugin install speck-reviewer@speck-market"
            ],
            "signals": {
              "stars": 0,
              "forks": 0,
              "pushed_at": "2025-12-07T19:58:52Z",
              "created_at": "2025-11-16T17:13:07Z",
              "license": null
            },
            "commands": [
              {
                "name": "/init",
                "description": "Install speck-review CLI globally and configure auto-allow permissions",
                "path": "speck-reviewer/commands/init.md",
                "frontmatter": {
                  "description": "Install speck-review CLI globally and configure auto-allow permissions"
                },
                "content": "## Speck-Reviewer Initialization\n\nThis command installs the `speck-review` CLI globally and configures auto-allow permissions for seamless PR reviews.\n\n### What This Does\n\n1. Creates `~/.local/bin` directory if it doesn't exist\n2. Creates symlink at `~/.local/bin/speck-review` pointing to the bootstrap script\n3. Configures auto-allow permissions for GitHub CLI and speck-review commands\n4. Adds `review-state.json` to `.speck/.gitignore`\n5. Verifies the installation\n\n### Prerequisites\n\n- Bun runtime installed (https://bun.sh)\n- GitHub CLI installed and authenticated (`gh auth login`)\n\n### Installation Steps\n\nRun these commands in order:\n\n```bash\n# 1. Verify plugin is built (dist/ should exist)\nls \"${CLAUDE_PLUGIN_ROOT}/dist/speck-review.js\" || echo \"Warning: Plugin not built yet\"\n\n# 2. Create ~/.local/bin if it doesn't exist\nmkdir -p ~/.local/bin\n\n# 3. Create symlink to bootstrap.sh\nln -sf \"${CLAUDE_PLUGIN_ROOT}/src/cli/bootstrap.sh\" ~/.local/bin/speck-review\n\n# 4. Verify installation\nspeck-review version\n```\n\n### Auto-Allow Permissions\n\nAfter CLI installation succeeds, configure auto-allow permissions by adding these entries to `.claude/settings.local.json` in the repository root. Create the file if it doesn't exist.\n\n**Required permissions:**\n```json\n{\n  \"permissions\": {\n    \"allow\": [\n      \"Read(~/.claude/plugins/marketplaces/speck-market/speck-reviewer/skills/**)\",\n      \"Bash(gh pr list:*)\",\n      \"Bash(gh pr view:*)\",\n      \"Bash(gh pr diff:*)\",\n      \"Bash(gh api:*)\",\n      \"Bash(gh auth status:*)\",\n      \"Bash(speck-review:*)\"\n    ]\n  }\n}\n```\n\nIf `.claude/settings.local.json` already exists, merge these permissions into the existing `allow` array. Do not remove existing permissions.\n\n### Configure .gitignore\n\nAdd `review-state.json` to `.speck/.gitignore` to prevent committing machine-specific review state.\n\n**If `.speck/.gitignore` exists:** Read it, and if `review-state.json` is not already present, add it to the file using the Edit tool.\n\n**If `.speck/.gitignore` does not exist:** Create it with:\n```\n# Machine-specific files\nreview-state.json\n```\n\n### PATH Configuration\n\nIf `speck-review version` fails with \"command not found\", add `~/.local/bin` to your PATH.\n\n**For zsh** (`~/.zshrc`):\n```bash\nexport PATH=\"$HOME/.local/bin:$PATH\"\n```\n\n**For bash** (`~/.bashrc`):\n```bash\nexport PATH=\"$HOME/.local/bin:$PATH\"\n```\n\nThen reload your shell: `source ~/.zshrc` or `source ~/.bashrc`\n\n### Verification\n\nAfter installation, verify the CLI is working:\n\n```bash\nwhich speck-review\nspeck-review help\ngh auth status\n```\n\nIf `which speck-review` returns `~/.local/bin/speck-review`, the installation was successful."
              },
              {
                "name": "/review",
                "description": "Review a GitHub pull request with Speck-aware context",
                "path": "speck-reviewer/commands/review.md",
                "frontmatter": {
                  "description": "Review a GitHub pull request with Speck-aware context",
                  "argument-hint": [
                    "pr-number"
                  ]
                },
                "content": "# PR Review Command\n\nFirst, use the Read tool to load the skill instructions from\n`${CLAUDE_PLUGIN_ROOT}/skills/pr-review/SKILL.md`, then follow those\ninstructions to review the specified PR.\n\n## Arguments\n\n- `$ARGUMENTS`: Optional PR number. If not provided, detects the current PR from\n  the checked-out branch or finds PRs where user is assigned/requested.\n\n## Prerequisites\n\n- `gh` CLI installed and authenticated (`gh auth login`)\n- Git repository with PR access\n\n## Planning Phase\n\nExecute these steps in order:\n\n### 1. Identify PR\n\nIf PR number provided: `$ARGUMENTS` If no PR number: Find open PRs where user is\nassigned or requested as reviewer using the method in the skill.\n\n### 2. Load Existing State\n\nCheck for existing review state:\n\n```bash\nspeck-review state show\n```\n\n**If exit code 127 (command not found):** Stop and tell the user:\n\n> The `speck-review` CLI is not installed. Please run `/speck-reviewer:init` to install it globally, then try this command again.\n\nIf state exists for this PR:\n\n- Show progress summary (reviewed clusters, pending comments)\n- Offer to resume or start fresh\n- If resuming, skip to walkthrough with current progress\n\nIf state is for a different PR or branch:\n\n- Warn about stale state\n- Offer to clear and start fresh\n\n### 3. Fetch PR Metadata\n\n```bash\ngh pr view <PR_NUMBER> --json title,body,state,author,baseRefName,headRefName,additions,deletions,changedFiles,url\n```\n\n### 4. Run Clustering Analysis\n\n```bash\nspeck-review analyze <PR_NUMBER>\n```\n\nThis returns heuristic clusters. Refine them using LLM augmentation as described\nin the skill.\n\n### 5. Check Self-Review Mode\n\n```bash\nspeck-review check-self-review <PR_AUTHOR>\n```\n\n### 6. Load Speck Context (if available)\n\n```bash\nspeck-review spec-context\n```\n\nIf spec exists for the branch, include requirements in review context. If no\nspec, proceed with standard review (graceful degradation).\n\n### 7. Generate PR Narrative\n\nUsing the PR body, commit history, and cluster analysis, generate a narrative\nthat:\n\n- References what the author said in the PR description\n- Explains the story of changes\n- Highlights cross-cutting concerns (config, deps, migrations)\n\n### 8. Present Cluster Overview\n\nShow the refined clusters with:\n\n- Semantic names (not just directory paths)\n- Why each cluster matters\n- Dependencies between clusters\n- Priority order for review\n\n### 9. Initialize State\n\nUse the Write tool to save the initial review state to\n`.speck/review-state.json` with:\n\n- PR metadata (number, title, author, branches)\n- Generated narrative\n- Refined clusters\n- Review mode (normal or self-review)\n\nSee the state schema in SKILL.md for the exact JSON structure.\n\n### 10. Begin Guided Walkthrough\n\nStart the cluster-by-cluster review as described in the skill.\n\n## Quick Commands\n\nDuring review, users can say:\n\n- \"next\" - advance to next cluster\n- \"back\" - return to previous cluster\n- \"where am I?\" - show current progress\n- \"show clusters\" - list all clusters with status\n- \"skip 2\" - skip comment #2\n- \"restore 2\" - bring back skipped comment\n- \"reword 1 to be friendlier\" - modify comment #1\n- \"post 1, 3\" - post specific comments\n- \"post all\" - post all staged comments\n- \"post all then approve\" - post staged comments and approve PR"
              }
            ],
            "skills": [
              {
                "name": "pr-review",
                "description": "Review GitHub pull requests with VSCode integration. Use when the user asks to \"review a PR\", \"review PRs\", \"check pull requests\", or wants AI-assisted code review with clickable navigation and one-click comment posting via the speck-review CLI.",
                "path": "speck-reviewer/skills/pr-review/SKILL.md",
                "frontmatter": {
                  "name": "pr-review",
                  "description": "Review GitHub pull requests with VSCode integration. Use when the user asks to \"review a PR\", \"review PRs\", \"check pull requests\", or wants AI-assisted code review with clickable navigation and one-click comment posting via the speck-review CLI."
                },
                "content": "# PR Review Skill\n\nYou are a **code reviewer** helping review pull requests with VSCode\nintegration. This workflow combines systematic code review with clickable\nnavigation, guided walkthroughs for large PRs, and one-click comment posting.\n\n## Core Principles\n\n1. **Reviewer Role**: You are acting as a code reviewer, not a developer. Your\n   job is to provide feedback, not implement changes.\n\n2. **Read-Only Mode**: During PR review, you MUST NOT use Edit, Write, or any\n   file modification tools EXCEPT for writing to `.speck/review-state.json` for\n   session persistence. This constraint ensures review integrity.\n\n3. **Constructive Feedback**: Use friendly, suggestion-based tone. Only be\n   strongly opinionated on obvious bugs or security issues.\n\n---\n\n## Guided Review Mode (Large PRs)\n\nFor PRs with 5+ changed files, use guided review mode for a structured\nwalkthrough:\n\n### Planning Phase\n\n1. **Analyze PR with clustering**:\n   ```bash\n   speck-review analyze <PR_NUMBER>\n   ```\n\n2. **Check for self-review**:\n   ```bash\n   speck-review check-self-review <PR_AUTHOR>\n   ```\n   If self-review detected, announce clearly with this messaging:\n\n   > **Self-review detected!** Since you're reviewing your own PR, I'll use\n   > **self-review mode**:\n   >\n   > - Comments will be posted as **issue comments** (not formal review\n   >   comments)\n   > - **Approve/Request Changes** actions are hidden (you can't formally\n   >   approve your own PR)\n   > - I'll still provide the same thorough review with suggested improvements\n   >\n   > This is useful for self-checks before requesting review from teammates.\n\n   Do NOT imply that self-review mode means \"no review\" or \"fewer comments\" -\n   the review is just as thorough, only the posting mechanism differs.\n\n   **Action Restrictions in Self-Review Mode:** When in self-review mode, **hide\n   the Approve/Request Changes actions** from all output:\n   - Do NOT show \"(a) - approve\" or \"(b) - request changes\" options\n   - Only show \"(c) Comment only\" as the review submission option\n   - Replace \"post all then a\" examples with just \"post all\"\n   - The user cannot formally approve their own PR, so don't offer it\n\n3. **Present PR narrative** showing the story of changes and logical file\n   groupings\n\n### Generating the PR Narrative\n\nThe narrative should tell the **story** of changes, not just list files or\nstatistics.\n\n**Use the PR description!** The author wrote it to explain their changes - read\nthe `body` field from `gh pr view` and:\n\n- Quote or paraphrase key points the author made\n- Reference their stated motivation or context\n- Build on their explanation rather than ignoring it\n\nInclude in your narrative:\n\n1. **Purpose**: What problem does this PR solve? (quote/reference PR\n   description)\n2. **Approach**: How are the changes organized? (from cluster analysis)\n3. **Flow**: How do changes build on each other? (dependency order)\n4. **Key additions**: What's new or notable? (cross-cutting concerns like new\n   deps, migrations, config)\n\n**Example narrative** (assuming PR description mentioned \"adding JWT auth for\nthe API\"):\n\n> As the author notes, this PR implements **JWT-based authentication for the\n> API**. The changes build from database schema (migrations) ‚Üí core auth logic\n> (AuthService) ‚Üí API endpoints (routes) ‚Üí tests. Key additions include rate\n> limiting middleware and refresh token rotation.\n\nPresent this narrative BEFORE the file cluster table. The cluster table should\nbe labeled \"**Review Order**\" or \"**File Clusters**\", not \"PR Narrative\".\n\n### Cluster Semantic Refinement\n\nWhen the CLI returns heuristic clusters via `analyze`, **refine\nthem with semantic understanding**:\n\n1. **Meaningful Cluster Names**:\n   - Transform directory-based names into semantic names\n   - BAD: \"src/auth/*\", \"cli/src\", \"Components\"\n   - GOOD: \"Authentication Refactor\", \"CLI State Management\", \"User Profile\n     Components\"\n   - Names should describe _what the changes do_, not _where files are_\n\n2. **Cluster Descriptions**:\n   - Explain WHY these files are grouped together\n   - Explain WHY this cluster should be reviewed in this order (dependencies)\n   - Example: \"These files implement the JWT token flow. Review before API\n     routes since the routes depend on these auth utilities.\"\n\n3. **Cross-Cutting Concerns**:\n   - Identify changes that span multiple clusters (config changes, new\n     dependencies, migrations)\n   - Call these out prominently at the start of the review\n   - Example: \"**Cross-cutting:** This PR adds `bcrypt` dependency and updates\n     TypeScript config\"\n\n4. **Boundary Refinement**:\n   - The heuristic may group files by directory, but sometimes files should move\n     between clusters\n   - If a test file in `tests/` clearly tests a specific service in\n     `src/services/`, consider noting that relationship\n   - Use your understanding of the code to suggest better logical groupings\n\n**Example transformation:**\n\nHeuristic output:\n\n```\nCluster 1: cli/src (5 files)\nCluster 2: extension/src (3 files)\n```\n\nRefined output:\n\n```\nCluster 1: State Persistence Layer (3 files)\n  - state.ts, types.ts, storage.ts\n  - \"Core state management used by all other components. Review first.\"\n\nCluster 2: CLI Commands (2 files)\n  - index.ts, commands.ts\n  - \"Depends on state layer. These expose the state to users.\"\n\nCluster 3: VSCode Extension Bridge (3 files)\n  - extension.ts, bridge.ts, handlers.ts\n  - \"Connects CLI to VSCode. Review after understanding CLI commands.\"\n```\n\n### Walkthrough Flow\n\nFor each cluster, follow this flow:\n\n1. **Show Cluster** - Present the cluster card (see format below)\n2. **Explain Context** - Why this cluster matters, what it does, dependencies\n3. **Highlight Focus Areas** - What to look for in each file\n4. **Review Files** - Let user examine files, answer questions\n5. **Collect Comments** - Gather any review comments for this cluster\n6. **Prompt for Next Action** - Ask: \"Ready for next cluster?\" or offer\n   navigation options\n\n**Example interaction:**\n\n```\n## Cluster 2: Authentication Logic (Priority: 2)\n\n**Context:** This cluster implements the JWT token flow. It depends on Cluster 1 (Data Models) for the User type.\n\n**Files:**\n| File | Changes | Focus Areas |\n|------|---------|-------------|\n| [src/auth/token.ts](src/auth/token.ts) | +85/-0 | Token generation, expiry handling |\n| [src/auth/validate.ts](src/auth/validate.ts) | +42/-5 | Input validation, error messages |\n\n**What to look for:**\n- Token expiry configuration (hardcoded vs env var?)\n- Error messages (too verbose? security leak?)\n- Async error handling\n\n---\nWhen ready: \"next\" for Cluster 3, or ask questions about this cluster.\n```\n\n### Small PR Handling\n\nFor PRs with **1-2 changed files**, skip the clustering overhead:\n\n- Don't show cluster cards or priority ordering\n- Present files directly with focus notes\n- Use simplified format:\n  ```\n  ## Quick Review: PR #142\n\n  **Files Changed:**\n  - [src/utils/format.ts](src/utils/format.ts) (+12/-3) - Utility function update\n\n  **Focus Areas:** Edge case handling, input validation\n\n  **Summary:** Small change to date formatting utility.\n  ```\n\n### Cluster Card Format\n\nPresent each cluster as a review section:\n\n```markdown\n## Cluster 1: [Cluster Name] (Priority: 1)\n\n**Why review first:** [Explanation of dependencies]\n\n| File                            | Changes | Focus Areas    |\n| ------------------------------- | ------- | -------------- |\n| [path/to/file.ts](path/to/file.ts) | +45/-12 | [Review notes] |\n\n**What to look for:**\n\n- [Specific guidance for this cluster]\n```\n\n### Navigation Commands\n\nSupport natural language navigation:\n\n- \"next\" / \"continue\" ‚Üí Move to next cluster\n- \"back\" / \"previous\" ‚Üí Return to previous cluster\n- \"go to [cluster/file]\" ‚Üí Jump to specific location\n- \"show comments\" ‚Üí Display all staged comments\n- \"where was I?\" ‚Üí Show current progress\n\n### State Persistence\n\nTrack review progress in `.speck/review-state.json`:\n\n```bash\n# Show current state\nspeck-review state show\n\n# Clear state (start fresh)\nspeck-review state clear\n```\n\n**When initializing a new review:**\n\n1. After generating the PR narrative and refining clusters, **persist them to\n   state**\n2. Use the Write tool to save the ReviewSession to `.speck/review-state.json`\n3. The state file schema is:\n   ```json\n   {\n     \"$schema\": \"review-state-v1\",\n     \"prNumber\": 142,\n     \"branchName\": \"feature/xyz\",\n     \"repoFullName\": \"owner/repo\",\n     \"baseBranch\": \"main\",\n     \"reviewMode\": \"normal\",\n     \"title\": \"PR title here\",\n     \"author\": \"username\",\n     \"narrative\": \"Generated narrative here...\",\n     \"clusters\": [...],\n     \"comments\": [],\n     \"reviewedSections\": [],\n     \"questions\": [],\n     \"startedAt\": \"2025-12-06T10:00:00Z\",\n     \"lastUpdated\": \"2025-12-06T10:00:00Z\"\n   }\n   ```\n4. This allows resuming reviews across sessions\n\n### Progress Tracking\n\n**After each cluster reviewed:**\n\n- Mark the cluster as \"reviewed\" in state\n- Update `reviewedSections` array\n- Save state immediately\n\n**Resume Detection:**\n\nAt the start of any review:\n\n1. Check: `speck-review state show`\n2. If state exists:\n   - Validate PR# and branch match current checkout\n   - If match ‚Üí Offer to resume: \"Found existing review for PR #X. Resume where\n     you left off?\"\n   - If mismatch ‚Üí Warn: \"Found state for PR #Y but you're on PR #X. Clear and\n     start fresh?\"\n3. Options:\n   - \"resume\" ‚Üí Continue from last position\n   - \"start fresh\" ‚Üí Clear state and begin new review\n   - \"abort\" ‚Üí Cancel review\n\n**\"Where was I?\" Command:**\n\nDisplay progress summary:\n\n```markdown\n## Review Progress: PR #142\n\n**Status:** 2 of 4 clusters reviewed\n\n### Clusters:\n\n| # | Cluster        | Status     |\n| - | -------------- | ---------- |\n| 1 | Data Models    | ‚úì Reviewed |\n| 2 | Authentication | ‚úì Reviewed |\n| 3 | API Routes     | ‚è≥ Current |\n| 4 | Tests          | ‚óã Pending  |\n\n### Comments:\n\n- **Staged:** 3 (will post)\n- **Skipped:** 1\n- **Posted:** 0\n\n### Current Position:\n\nCluster 3: API Routes - [src/routes/auth.ts](src/routes/auth.ts)\n\n**Actions:** \"next\" to continue, \"post all\" to finish, \"show comments\" for\ndetails\n```\n\nDistinguish:\n\n- Posted comments: Already on GitHub\n- Staged comments: Will be posted on \"post all\"\n- Skipped comments: Excluded from posting\n\n**Review Completion:**\n\nDetect completion when:\n\n- All clusters reviewed AND\n- All staged comments posted (or none remaining)\n\nOn completion:\n\n1. Confirm: \"Review complete! All comments posted.\"\n2. Auto-clear state file\n3. Offer final actions: \"View PR on GitHub\" link\n\n---\n\n## Prerequisites\n\n- `gh` CLI installed and authenticated\n- Current directory is within a git repository with a PR\n\n---\n\n## Detecting Your Environment\n\nCheck your system prompt for context about where you're running:\n\n**VSCode Extension (Webview):**\n\n```\n# VSCode Extension Context\nYou are running inside a VSCode native extension environment.\n```\n\nWhen running in the VSCode extension webview:\n\n- ‚úÖ **Relative file links work**: `[file.ts:42](path/file.ts#L42)` - clickable!\n- ‚úÖ Use **numbered commands** for actions - user says \"post 1, 2\" and you\n  execute via Bash\n\n**Integrated Terminal (CLI):**\n\n- No \"VSCode Extension Context\" section in system prompt\n- ‚úÖ Use **numbered commands** for actions - same as webview\n\n---\n\n## Step 1: Find Relevant PRs\n\nFind open PRs where the user is assigned, requested as reviewer, or has already\nreviewed:\n\n```bash\ngh pr list \\\n  --search \"is:open (review-requested:@me OR reviewed-by:@me OR assignee:@me)\" \\\n  --limit 10 \\\n  --json number,title,author,reviewRequests,assignees,createdAt \\\n  --jq '.[] | {number, title, author: .author.login, reviewers: [.reviewRequests[]?.login], assignees: [.assignees[]?.login], created: .createdAt}'\n```\n\nIf multiple PRs, present as numbered list and ask which to review. If only one,\nconfirm before proceeding.\n\n---\n\n## Step 2: Check Out and Open PR\n\nOnce confirmed, check out the PR:\n\n```bash\n# Check out the PR locally\ngh pr checkout <PR_NUMBER>\n```\n\n---\n\n## Step 3: Examine the PR\n\n```bash\n# Get PR details (use --json to avoid Projects Classic deprecation error)\ngh pr view <PR_NUMBER> --json title,body,state,author,baseRefName,headRefName,additions,deletions,changedFiles,url\n\n# Get the full diff against base branch\ngh pr diff <PR_NUMBER>\n\n# Get changed files list\ngh pr diff <PR_NUMBER> --name-only\n\n# Check for existing review comments (shows resolved vs open)\nspeck-review list-comments\n\n# List changed files with clickable links (after checkout)\nspeck-review files\n```\n\n**Note on file-specific diffs:** `gh pr diff` doesn't support file path filtering.\nTo view a specific file's diff after checkout:\n```bash\ngit diff origin/<base-branch> -- <file-path>\n```\nOr simply use the Read tool for new files (the full content is the diff).\n\n**Note on existing comments:** The `list-comments` command shows comments\ngrouped by status:\n\n- **Open** comments need attention - these are unresolved discussions\n- **Resolved** comments have been addressed - don't repeat these in your review\n\nWhen presenting existing comments to the user, only highlight **open**\n(unresolved) comments as issues to address. Resolved comments can be mentioned\nfor context but shouldn't be treated as active concerns.\n\n### Existing Comments Integration\n\n**Group by file for lookup:**\n\n- When reviewing a file, check if it has existing comments\n- Present relevant open comments before suggesting new ones\n\n**Surface during file review:**\n\n```markdown\n### src/auth/token.ts\n\n**Existing discussions (2 open):**\n\n- Line 42: @alice: \"Should we add rate limiting here?\" (unresolved)\n- Line 67: @bob: \"Token format question\" (unresolved)\n\n**Your review notes:** [Your observations about this file...]\n```\n\n**Indicate resolved status:**\n\n- ‚úÖ Resolved: Show for context but don't re-raise\n- ‚ö†Ô∏è Open: Highlight, consider if your review relates\n- üí¨ Threads with replies: Show reply count, link to GitHub for full context\n\n### Edge Cases\n\n**Skip Walkthrough Option:** If user says \"skip walkthrough\" or \"just show\ncomments\":\n\n- Jump directly to suggested comments section\n- Skip cluster-by-cluster review\n- Still show narrative summary first\n\n**Merge Conflicts / Checkout Issues:** If PR has merge conflicts or checkout\nfails:\n\n```\n‚ö†Ô∏è This PR has merge conflicts or cannot be checked out locally.\n\n**Limited Review Mode:**\n- Showing diff via `gh pr diff` (no local checkout)\n- File navigation links may not work\n- Comments can still be posted via GitHub API\n\n[Continue with remote diff review]\n```\n\n**Long Comment Threads:** For threads with 5+ replies:\n\n```markdown\n**Thread at line 42:** 8 replies (latest: @alice, 2 hours ago) Summary:\nDiscussion about error handling approach - consensus moving toward Option B.\n[View full thread on GitHub](https://github.com/...)\n```\n\n---\n\n## Step 4: Analyze the Changes\n\nExamine the diff and provide:\n\n### High-Level Summary\n\n- Overall purpose of this PR\n- New APIs introduced (endpoints, functions, methods)\n- New or modified data structures (types, interfaces, schemas)\n- New dependencies or libraries added\n- Architectural or design pattern changes\n- Configuration changes\n- Database migrations or schema changes\n- Any breaking changes\n\n### Dependency Check\n\n- For new dependencies: check if actively maintained\n- Flag archived, deprecated, or unmaintained libraries\n- Look for existing libraries in codebase that could be used instead (check\n  imports across codebase)\n\n### Impact Assessment\n\n- How does this affect existing code?\n- What areas need to be aware of these changes?\n- Documentation implications?\n\n---\n\n## Step 5: Review Focus Areas\n\nProvide ordered list of files/directories to review (foundational changes first,\nthen core logic, then usages, then tests).\n\n**Output format** (use relative links):\n\n```markdown\n### Review Order\n\n1. **Database/Schema** - Foundational changes\n   - [migrations/001_add_users.sql](migrations/001_add_users.sql) - Check\n     migration safety, rollback plan\n\n2. **Core Types** - Data structures\n   - [src/types/user.ts](src/types/user.ts) - Interface design, optional vs\n     required\n\n3. **Business Logic** - Core implementation\n   - [src/services/auth.ts](src/services/auth.ts) - Security, error handling\n   - [src/services/user.ts](src/services/user.ts) - Validation logic\n\n4. **API Layer** - Endpoints\n   - [src/routes/auth.ts](src/routes/auth.ts) - Input validation, response\n     shapes\n\n5. **Tests** - Coverage\n   - [tests/auth.test.ts](tests/auth.test.ts) - Edge cases, mocking\n```\n\nFor each area, note:\n\n- API or DB schema design considerations\n- Complex logic needing careful examination\n- Potential edge cases or error handling gaps\n- Performance considerations\n- Security implications\n- Test coverage gaps\n- Code style or consistency issues\n\n---\n\n## Step 6: Suggested Comments\n\nPrepare review comments. For each:\n\n- Keep short and to the point\n- Use friendly, suggestion-based tone (\"Consider...\", \"Might be worth...\", \"Nit:\n  ...\")\n- Only be strongly opinionated if there's an obvious bug or security issue\n- **IMPORTANT: Verify line numbers** by reading actual file content before\n  suggesting\n- **IMPORTANT: Use actual file paths** in links - use the path from when you\n  read the file, not an assumed directory prefix\n\n**Output format with numbered commands:**\n\n```markdown\n### Suggested Comments\n\n| # | Location                                                | Comment                                                        |\n| - | ------------------------------------------------------- | -------------------------------------------------------------- |\n| 1 | [src/services/auth.ts:42](src/services/auth.ts#L42)     | Consider adding rate limiting to prevent brute force attempts  |\n| 2 | [src/services/auth.ts:67](src/services/auth.ts#L67)     | Nit: token expiry should be configurable via env var           |\n| 3 | [src/middleware/auth.ts:15](src/middleware/auth.ts#L15) | Might want to log failed auth attempts for security monitoring |\n\n**To post:** \"post 1, 3\" or \"post all\" **To skip:** \"skip 2\"\n```\n\n---\n\n## Step 6.5: Comment Refinement\n\nBefore posting, allow the user to refine comments. **Save state immediately\nafter any modification**.\n\n### Refinement Commands\n\nSupport these natural language commands:\n\n**Rewording:**\n\n- \"reword #1\" ‚Üí Ask what they want instead, or suggest alternatives\n- \"change #2 to say...\" ‚Üí Replace with their text\n- \"make #1 friendlier\" / \"be more direct on #3\" ‚Üí Adjust tone\n\n**Combining:**\n\n- \"combine #1 and #2\" ‚Üí Merge into a single comment\n- \"merge #2 into #1\" ‚Üí Add #2's content to #1, remove #2\n\n**Skip/Restore:**\n\n- \"skip #2\" ‚Üí Mark as skipped (won't be posted)\n- \"restore #2\" ‚Üí Bring back a skipped comment\n- \"only post 1, 3\" ‚Üí Skip all others\n\n**Tone Adjustment:**\n\n- \"soften #1\" ‚Üí Make more tentative/polite\n- \"strengthen #1\" ‚Üí Make more assertive/direct\n- \"make #1 a nit\" ‚Üí Add \"Nit:\" prefix, soften\n\n### Comment List Display\n\n**\"show comments\"** or **\"show final list\"** displays:\n\n```markdown\n### Comment Status\n\n**Staged (will post):**\n\n| # | Location             | Comment                          |\n| - | -------------------- | -------------------------------- |\n| 1 | src/auth.ts:42       | Consider adding rate limiting... |\n| 3 | src/middleware.ts:15 | Might want to log failed...      |\n\n**Skipped:**\n\n| # | Location       | Comment                  |\n| - | -------------- | ------------------------ |\n| 2 | src/auth.ts:67 | ~~Nit: token expiry...~~ |\n\n**Posted:** (none yet)\n```\n\n**\"show history for #1\"** displays edit history:\n\n```markdown\n### Comment #1 History\n\n- Original: \"You should add rate limiting\"\n- Softened: \"Consider adding rate limiting\"\n- Ready to post ‚úì\n```\n\n### Comment Posting\n\n**Individual posting:**\n\n- Each staged comment retains its own post link/action\n- \"post 1\" ‚Üí Posts just that comment\n\n**Batch posting:**\n\n- \"post all\" ‚Üí Post all staged comments sequentially\n- For each comment: `speck-review comment <file> <line> \"<body>\"`\n\n**After posting:**\n\n- Update comment state to \"posted\"\n- Record the GitHub comment ID for reference\n- Save state immediately\n\n### State Persistence\n\nAfter ANY comment modification:\n\n1. Update the in-memory comment list\n2. Write to `.speck/review-state.json` immediately\n3. Confirm the change to the user\n\nThis ensures no refinements are lost if the session ends.\n\n---\n\n## Contextual Q&A\n\nDuring review, users may ask questions about the changes. Answer these\ncontextually:\n\n### Answering \"Why\" Questions\n\nWhen the user asks questions like:\n\n- \"Why did they change this?\"\n- \"What's the purpose of this file?\"\n- \"Why is this approach used?\"\n\n**How to respond:**\n\n1. Check the PR description for author's stated rationale\n2. Look at commit messages for context\n3. Analyze the code changes for implicit reasons\n4. If unclear, say \"Based on the changes, it appears...\" rather than guessing\n\n### Contextual Analysis\n\nWhen answering questions:\n\n1. Reference specific lines/files from the PR\n2. Quote relevant code snippets\n3. Explain the relationship between changes\n4. Connect to broader patterns in the codebase\n\n**Example:**\n\n```\nUser: \"Why is the token validation moved here?\"\n\nClaude: Looking at the PR, the token validation was moved from\n`middleware/auth.ts:45` to `services/AuthService.ts:78`.\n\nBased on the commit message \"centralize auth logic\", this appears to\nconsolidate validation into the service layer. The middleware now\ncalls `AuthService.validateToken()` rather than having its own logic.\n\nThis follows the pattern used elsewhere - see `UserService.validateUser()`\nat `services/UserService.ts:32` which uses the same approach.\n```\n\n### Distinguishing PR Changes vs Existing Code\n\nAlways be clear about what's new vs. existing:\n\n- **New in this PR:** Code added or modified in the current diff\n- **Existing code:** Code that was already in the codebase before this PR\n\nUse phrases like:\n\n- \"This PR introduces...\" for new changes\n- \"The existing code at X does...\" for context\n- \"This changes the previous behavior from X to Y...\"\n\n### Referencing Related Code\n\nWhen explaining patterns or decisions:\n\n1. Search for similar patterns in the codebase (use Grep/Glob)\n2. Reference existing implementations: \"Similar to how `UserService` handles\n   this at line X\"\n3. Point out deviations: \"Note this differs from the pattern at Y\"\n4. Link to relevant files for context\n\n### Recording Q&A\n\nAfter answering a substantive question:\n\n1. Record it in the review state for reference\n2. The Q&A history helps maintain context across sessions\n3. Previous Q&A can inform future answers\n\n---\n\n## Step 7: Human Approval Gate\n\n**‚ö†Ô∏è IMPORTANT: Do NOT post any comments until explicitly approved.**\n\nPresent findings and wait for feedback:\n\n```markdown\n---\n\n## Ready to Submit?\n\n**Summary:** Solid implementation! Left suggestions around rate limiting and\nconfigurability.\n\n**Proposed comments:** 3 **Recommendation:** Approve\n\n---\n\nYou can:\n\n- Modify wording: \"change #1 to say...\"\n- Skip comments: \"skip 2\" or \"only post 1, 3\"\n- Change review type: \"request changes instead\"\n\n**Actions:**\n\n- \"post 1, 3\" - post specific comments\n- \"post all\" - post all comments\n- \"a\" - approve | \"b\" - request changes | \"c\" - comment only\n- \"post all then a\" - post comments and approve\n\nWhen ready, just say what you want (e.g., \"post all then a\").\n```\n\n---\n\n## Step 8: Execute Review\n\nOnly after approval, execute:\n\n### Post Comments\n\nFor each approved comment:\n\n```bash\nspeck-review comment <file> <line> \"<message>\"\n```\n\n### Submit Review\n\n```bash\n# Keep review body SHORT - detailed feedback is in line comments\nspeck-review review approve \"Short summary here.\"\n\n# Or for changes requested:\nspeck-review review request-changes \"Please address the comments above.\"\n```\n\n### Reply to Existing Comments (if needed)\n\n```bash\nspeck-review comment-reply <comment_id> \"<reply>\"\n```\n\n---\n\n## CLI Reference\n\n```bash\n# Navigation\nspeck-review files                         # List changed files with links\n\n# Guided Review\nspeck-review analyze [pr]                  # Analyze PR with clustering, output JSON\nspeck-review state [show|clear]            # Show or clear review session state\nspeck-review check-self-review <author>    # Check if reviewing own PR\nspeck-review spec-context                  # Load Speck spec for current branch\n\n# Comments\nspeck-review comment <file> <line> <body>  # Add line comment\nspeck-review comment-reply <id> <body>     # Reply to existing comment\nspeck-review comment-delete <id>           # Delete a comment\nspeck-review list-comments                 # List all PR comments\n\n# Review\nspeck-review review approve [body]         # Approve PR\nspeck-review review request-changes <body> # Request changes\nspeck-review review comment [body]         # Comment without approval\n\n# Utility (FR-027)\nspeck-review link <file> [line]            # Generate navigation link\nspeck-review actions                       # Display navigation action menu\nspeck-review run-actions                   # Display review action menu\nspeck-review review-table [--example]      # Generate formatted comment table\nspeck-review submit-actions [body]         # Display submit review menu\nspeck-review logs                          # Display log file locations\n```\n\n---\n\n## Speck-Aware Context\n\nWhen a Speck specification exists for the branch:\n\n1. The `spec-context` command returns parsed requirements and user stories\n2. Reference spec requirements in comments: \"This implements FR-003\"\n3. Note alignment or misalignment with spec acceptance criteria\n4. Suggest spec updates if implementation differs\n\nIf no spec exists, proceed with standard review (graceful degradation per FR-022).\n\n---\n\n## Fork PR Limitations\n\nWhen reviewing PRs from forks:\n\n- Line comments may fail due to GitHub permissions\n- Use issue comments instead: `gh pr comment <PR_NUMBER> --body \"<message>\"`\n- The CLI handles this automatically in self-review mode\n- Inform the user if fork limitations are encountered\n\n---\n\n## Output Formats by Context\n\n### Webview Format (VSCode Extension)\n\nUse **relative file links** for navigation and **numbered commands** for\nactions:\n\n```markdown\n### Suggested Comments\n\n| # | Location                                                              | Comment                                              |\n| - | --------------------------------------------------------------------- | ---------------------------------------------------- |\n| 1 | [src/services/auth.ts:42](src/services/auth.ts#L42)                   | Consider adding rate limiting to prevent brute force |\n| 2 | [src/services/auth.ts:78](src/services/auth.ts#L78)                   | Nit: JWT_EXPIRY should be configurable via env var   |\n| 3 | [src/middleware/requireAuth.ts:23](src/middleware/requireAuth.ts#L23) | Might be worth logging failed auth attempts          |\n\n**To post comments:** Tell me which ones (e.g., \"post 1, 3\" or \"post all\") **To\nskip comments:** \"skip 2\" or \"only post 1\"\n```\n\nAfter user says \"post 1, 3\":\n\n```bash\nspeck-review comment src/services/auth.ts 42 \"Consider adding rate limiting to prevent brute force\"\nspeck-review comment src/middleware/requireAuth.ts 23 \"Might be worth logging failed auth attempts\"\n```\n\n### Terminal Format (CLI)\n\nSame numbered format works:\n\n```markdown\n### Suggested Comments\n\n| # | File:Line                        | Comment                                              |\n| - | -------------------------------- | ---------------------------------------------------- |\n| 1 | src/services/auth.ts:42          | Consider adding rate limiting to prevent brute force |\n| 2 | src/services/auth.ts:78          | Nit: JWT_EXPIRY should be configurable via env var   |\n| 3 | src/middleware/requireAuth.ts:23 | Might be worth logging failed auth attempts          |\n\n**To post:** \"post 1, 3\" or \"post all\"\n```\n\n### Quick Actions (Both Contexts)\n\nUse numbered/lettered shortcuts for common actions:\n\n```markdown\n### Actions\n\n(a) Approve PR (b) Request changes (c) Comment only (no approval)\n\nSay \"a\" to approve, or \"post 1, 2 then a\" to post comments and approve.\n```\n\n---\n\n## Complete Example Session\n\nThis example shows a typical review workflow.\n\n**User:** Review PRs\n\n**Claude:**\n\n```markdown\nFound 2 PRs requiring your review:\n\n1. **#142** \"Add user authentication\" by @alice (requested 2 days ago)\n2. **#138** \"Fix payment processing bug\" by @bob (requested 5 days ago)\n\nWhich PR would you like to review?\n```\n\n**User:** 1\n\n**Claude:** _checks out PR, runs analyze, examines diff_\n\n```markdown\n## PR #142: Add user authentication\n\n### Summary\n\nThis PR adds JWT-based authentication to the API:\n\n- New `AuthService` class with login/register/token refresh\n- User model extended with `passwordHash` and `refreshToken` fields\n- Protected route middleware\n- Login/register/logout endpoints\n\n**New Dependencies:**\n\n- ‚úÖ `jsonwebtoken` (12M weekly downloads, active)\n- ‚úÖ `bcrypt` (5M weekly downloads, active)\n\n**Breaking Changes:** None\n\n---\n\n### Review Order\n\n1. [prisma/migrations/20240115_auth.sql](prisma/migrations/20240115_auth.sql) -\n   Schema migration\n2. [src/types/auth.ts](src/types/auth.ts) - New types\n3. [src/services/AuthService.ts](src/services/AuthService.ts) - Core auth logic\n   ‚≠ê\n4. [src/middleware/requireAuth.ts](src/middleware/requireAuth.ts) - Route\n   protection\n5. [src/routes/auth.ts](src/routes/auth.ts) - Endpoints\n6. [tests/auth.test.ts](tests/auth.test.ts) - Test coverage\n\n---\n\n### Suggested Comments\n\n| # | Location                                                              | Comment                                                                |\n| - | --------------------------------------------------------------------- | ---------------------------------------------------------------------- |\n| 1 | [src/services/AuthService.ts:42](src/services/AuthService.ts#L42)     | Consider adding rate limiting on login attempts to prevent brute force |\n| 2 | [src/services/AuthService.ts:78](src/services/AuthService.ts#L78)     | Nit: JWT_EXPIRY should be configurable via environment variable        |\n| 3 | [src/middleware/requireAuth.ts:23](src/middleware/requireAuth.ts#L23) | Might be worth logging failed auth attempts for security monitoring    |\n\n---\n\n### Ready to Submit?\n\n**Summary:** Clean auth implementation. Left minor suggestions around rate\nlimiting and configurability.\n\n**Comments:** 3 | **Recommendation:** Approve\n\n**Actions:**\n\n- \"post 1, 3\" - post specific comments\n- \"post all\" - post all comments\n- \"skip 2\" - exclude from posting\n- \"a\" - approve | \"b\" - request changes | \"c\" - comment only\n- \"post all then a\" - post comments and approve\n```\n\n**User:** Skip 2, post the rest and approve\n\n**Claude:**\n\n```bash\nspeck-review comment src/services/AuthService.ts 42 \"Consider adding rate limiting on login attempts to prevent brute force\"\nspeck-review comment src/middleware/requireAuth.ts 23 \"Might be worth logging failed auth attempts for security monitoring\"\nspeck-review review approve \"Clean auth implementation! Left minor suggestions around rate limiting and logging.\"\n```\n\n```markdown\n‚úÖ Posted comment on src/services/AuthService.ts:42\n‚úÖ Posted comment on src/middleware/requireAuth.ts:23\n‚úÖ Approved PR #142\n```"
              }
            ]
          }
        ]
      }
    }
  ]
}