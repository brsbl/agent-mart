{
  "owner": {
    "id": "IsmaelMartinez",
    "display_name": "IsmaelMartinez",
    "type": "User",
    "avatar_url": "https://avatars.githubusercontent.com/u/430992?v=4",
    "url": "https://github.com/IsmaelMartinez",
    "bio": null,
    "stats": {
      "total_repos": 1,
      "total_plugins": 1,
      "total_commands": 0,
      "total_skills": 1,
      "total_stars": 1,
      "total_forks": 0
    }
  },
  "repos": [
    {
      "full_name": "IsmaelMartinez/local-brain",
      "url": "https://github.com/IsmaelMartinez/local-brain",
      "description": null,
      "homepage": null,
      "signals": {
        "stars": 1,
        "forks": 0,
        "pushed_at": "2026-01-11T14:34:07Z",
        "created_at": "2025-11-19T14:45:03Z",
        "license": "MIT"
      },
      "file_tree": [
        {
          "path": ".claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude-plugin/marketplace.json",
          "type": "blob",
          "size": 686
        },
        {
          "path": ".claude-plugin/scripts",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude-plugin/scripts/install.sh",
          "type": "blob",
          "size": 1742
        },
        {
          "path": ".github",
          "type": "tree",
          "size": null
        },
        {
          "path": ".github/workflows",
          "type": "tree",
          "size": null
        },
        {
          "path": ".github/workflows/ci.yml",
          "type": "blob",
          "size": 1254
        },
        {
          "path": ".github/workflows/release.yml",
          "type": "blob",
          "size": 1365
        },
        {
          "path": ".gitignore",
          "type": "blob",
          "size": 967
        },
        {
          "path": ".python-version",
          "type": "blob",
          "size": 5
        },
        {
          "path": "CLAUDE.md",
          "type": "blob",
          "size": 717
        },
        {
          "path": "CONTRIBUTING.md",
          "type": "blob",
          "size": 1973
        },
        {
          "path": "LICENSE",
          "type": "blob",
          "size": 1071
        },
        {
          "path": "README.md",
          "type": "blob",
          "size": 8111
        },
        {
          "path": "docs",
          "type": "tree",
          "size": null
        },
        {
          "path": "docs/adrs",
          "type": "tree",
          "size": null
        },
        {
          "path": "docs/adrs/001-custom-implementation.md",
          "type": "blob",
          "size": 1210
        },
        {
          "path": "docs/adrs/002-smolagents.md",
          "type": "blob",
          "size": 2135
        },
        {
          "path": "docs/adrs/003-no-web-tools.md",
          "type": "blob",
          "size": 1819
        },
        {
          "path": "docs/adrs/004-toolcallingagent-over-codeagent.md",
          "type": "blob",
          "size": 3526
        },
        {
          "path": "docs/adrs/005-codeagent-with-markdown-tags.md",
          "type": "blob",
          "size": 5679
        },
        {
          "path": "docs/adrs/006-otel-jaeger-tracing.md",
          "type": "blob",
          "size": 2822
        },
        {
          "path": "docs/adrs/README.md",
          "type": "blob",
          "size": 1227
        },
        {
          "path": "docs/research",
          "type": "tree",
          "size": null
        },
        {
          "path": "docs/research/001-future-roadmap.md",
          "type": "blob",
          "size": 12747
        },
        {
          "path": "docs/research/002-delegation-research.md",
          "type": "blob",
          "size": 4345
        },
        {
          "path": "docs/research/003-model-evaluation-checklist.md",
          "type": "blob",
          "size": 17425
        },
        {
          "path": "docs/research/004-model-performance-comparison.md",
          "type": "blob",
          "size": 3258
        },
        {
          "path": "docs/research/README.md",
          "type": "blob",
          "size": 1652
        },
        {
          "path": "local-brain",
          "type": "tree",
          "size": null
        },
        {
          "path": "local-brain/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "local-brain/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 499
        },
        {
          "path": "local-brain/plugin.json",
          "type": "blob",
          "size": 537
        },
        {
          "path": "local-brain/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "local-brain/skills/local-brain",
          "type": "tree",
          "size": null
        },
        {
          "path": "local-brain/skills/local-brain/SKILL.md",
          "type": "blob",
          "size": 9888
        },
        {
          "path": "local_brain",
          "type": "tree",
          "size": null
        },
        {
          "path": "local_brain/__init__.py",
          "type": "blob",
          "size": 93
        },
        {
          "path": "local_brain/cli.py",
          "type": "blob",
          "size": 9672
        },
        {
          "path": "local_brain/models.py",
          "type": "blob",
          "size": 9744
        },
        {
          "path": "local_brain/security.py",
          "type": "blob",
          "size": 6572
        },
        {
          "path": "local_brain/smolagent.py",
          "type": "blob",
          "size": 25009
        },
        {
          "path": "local_brain/tracing.py",
          "type": "blob",
          "size": 4523
        },
        {
          "path": "pyproject.toml",
          "type": "blob",
          "size": 1849
        },
        {
          "path": "scripts",
          "type": "tree",
          "size": null
        },
        {
          "path": "scripts/sync_version.py",
          "type": "blob",
          "size": 1796
        },
        {
          "path": "scripts/test-model-auto.sh",
          "type": "blob",
          "size": 1534
        },
        {
          "path": "scripts/test-model.sh",
          "type": "blob",
          "size": 2519
        },
        {
          "path": "spikes",
          "type": "tree",
          "size": null
        },
        {
          "path": "spikes/README.md",
          "type": "blob",
          "size": 3437
        },
        {
          "path": "spikes/SPIKE_RESULTS.md",
          "type": "blob",
          "size": 3446
        },
        {
          "path": "spikes/spike_01_smolagents_basic.py",
          "type": "blob",
          "size": 4755
        },
        {
          "path": "spikes/spike_02_code_as_tool.py",
          "type": "blob",
          "size": 6687
        },
        {
          "path": "spikes/spike_03_sandbox_security.py",
          "type": "blob",
          "size": 11175
        },
        {
          "path": "spikes/spike_04_qwen_coder_quality.py",
          "type": "blob",
          "size": 12718
        },
        {
          "path": "spikes/spike_05_otel_tracing.py",
          "type": "blob",
          "size": 7021
        },
        {
          "path": "spikes/spike_06_grep_ast.py",
          "type": "blob",
          "size": 8462
        },
        {
          "path": "spikes/spike_07_tree_sitter.py",
          "type": "blob",
          "size": 12274
        },
        {
          "path": "spikes/spike_08_pyodide_sandbox.py",
          "type": "blob",
          "size": 8767
        },
        {
          "path": "tests",
          "type": "tree",
          "size": null
        },
        {
          "path": "tests/__init__.py",
          "type": "blob",
          "size": 26
        },
        {
          "path": "tests/test_cli.py",
          "type": "blob",
          "size": 7386
        },
        {
          "path": "tests/test_security.py",
          "type": "blob",
          "size": 13111
        },
        {
          "path": "tests/test_smolagent.py",
          "type": "blob",
          "size": 12018
        },
        {
          "path": "uv.lock",
          "type": "blob",
          "size": 501414
        }
      ],
      "marketplace": {
        "name": "local-brain-marketplace",
        "version": null,
        "description": null,
        "owner_info": {
          "name": "Ismael Martinez Ramos",
          "email": "ismaelmartinez@gmail.com"
        },
        "keywords": [],
        "plugins": [
          {
            "name": "local-brain",
            "description": "Chat with local Ollama models that can explore your codebase using tools",
            "source": "./local-brain",
            "category": "productivity",
            "version": "0.4.0",
            "author": null,
            "install_commands": [
              "/plugin marketplace add IsmaelMartinez/local-brain",
              "/plugin install local-brain@local-brain-marketplace"
            ],
            "signals": {
              "stars": 1,
              "forks": 0,
              "pushed_at": "2026-01-11T14:34:07Z",
              "created_at": "2025-11-19T14:45:03Z",
              "license": "MIT"
            },
            "commands": [],
            "skills": [
              {
                "name": "local-brain",
                "description": "Delegate complex, multi-step codebase exploration to local Ollama models. Best for analysis, review, and understanding tasks that require reasoning across multiple files.",
                "path": "local-brain/skills/local-brain/SKILL.md",
                "frontmatter": {
                  "name": "local-brain",
                  "description": "Delegate complex, multi-step codebase exploration to local Ollama models. Best for analysis, review, and understanding tasks that require reasoning across multiple files.",
                  "version": "0.9.0"
                },
                "content": "# Local Brain\n\nDelegate complex codebase exploration to local Ollama models. Local Brain excels at multi-step tasks requiring reasoning, not simple commands.\n\n## When to Use Local Brain\n\nLocal Brain adds 10-70 seconds of LLM inference overhead per query. Use it for tasks where AI reasoning provides value, not for simple commands.\n\n**Use Local Brain for:**\n- Multi-step exploration (\"Find all error handlers and explain how they work\")\n- Code review and analysis (\"Review recent changes for potential issues\")\n- Understanding unfamiliar code (\"Explain how authentication flows through the system\")\n- Tasks requiring judgment (\"What patterns does this codebase use?\")\n- When you don't know which files or commands to look at\n\n**Do NOT use Local Brain for:**\n- Simple file listing (use `ls` or `find` directly ‚Äî 1000x faster)\n- Git status/log (use `git log` directly ‚Äî 1000x faster)\n- Reading a specific known file (use `cat` or your editor)\n- Any single-command operation where you know what to run\n\n**Performance reality:** A simple \"list files\" query takes 12-70 seconds via Local Brain vs 5ms via `ls`. The value is in the reasoning, not the tool execution.\n\n## Installation\n\nInstall local-brain:\n```bash\nuv pip install local-brain\n```\n\nOr with pipx:\n```bash\npipx install local-brain\n```\n\n**Requirements:**\n- Ollama running locally (https://ollama.ai)\n- A model pulled (e.g., `ollama pull qwen3`)\n\n## Usage\n\n```bash\nlocal-brain \"prompt\"                    # Ask anything (auto-selects best model)\nlocal-brain -v \"prompt\"                 # Show tool calls\nlocal-brain -d \"prompt\"                 # Show step-by-step debug output\nlocal-brain -m qwen3-coder:30b \"prompt\" # Specific model\nlocal-brain --trace \"prompt\"            # Enable OTEL tracing\nlocal-brain --list-models               # Show available models\nlocal-brain --root /path/to/project \"prompt\"  # Set project root\nlocal-brain doctor                      # Check system health\n```\n\n## Health Check\n\nVerify your setup is working correctly:\n\n```bash\nlocal-brain doctor\n```\n\nThis checks:\n- Ollama is installed and running\n- Recommended models are available\n- Tools execute correctly\n- Optional tracing dependencies\n\nExample output:\n```\nüîç Local Brain Health Check\n\nChecking Ollama...\n  ‚úÖ Ollama is installed (ollama version is 0.13.1)\n\nChecking Ollama server...\n  ‚úÖ Ollama server is running (9 models)\n\nChecking recommended models...\n  ‚úÖ Recommended models installed: qwen3:latest\n\nChecking tools...\n  ‚úÖ Tools working (9 tools available)\n\nChecking optional features...\n  ‚úÖ OTEL tracing available (--trace flag)\n\n========================================\n‚úÖ All checks passed! Local Brain is ready.\n```\n\n## Examples\n\nFocus on tasks where AI reasoning adds value:\n\n```bash\n# Code review and analysis (good use case)\nlocal-brain \"Review the recent git changes and identify potential issues\"\nlocal-brain \"Analyze the error handling patterns in this codebase\"\n\n# Understanding unfamiliar code (good use case)\nlocal-brain \"Explain how the authentication system works end-to-end\"\nlocal-brain \"What design patterns does this codebase use?\"\n\n# Multi-step exploration (good use case)\nlocal-brain \"Find all TODO comments and categorize them by urgency\"\nlocal-brain \"Trace how user input flows through the validation layer\"\n\n# Generate content requiring context (good use case)\nlocal-brain \"Generate a commit message based on the staged changes\"\nlocal-brain \"Summarize what changed in the last 5 commits\"\n```\n\n## Model Selection Guide\n\nChoose the right model for your task:\n\n### For Code Exploration (Recommended)\n\nUse `qwen3-coder:30b` for faster exploration tasks:\n\n```bash\nlocal-brain -m qwen3-coder:30b \"Find all error handlers and explain how they work\"\nlocal-brain -m qwen3-coder:30b \"What validation patterns are used in this codebase?\"\nlocal-brain -m qwen3-coder:30b \"Trace the data flow from API endpoint to database\"\n```\n\nWhy: 2.5x faster than qwen3:30b (12-20s vs 35-70s per query), direct tool usage.\n\n### For Complex Reasoning\n\nUse `qwen3:30b` for tasks requiring deeper analysis:\n\n```bash\nlocal-brain -m qwen3:30b \"Analyze the architecture and suggest improvements\"\nlocal-brain -m qwen3:30b \"Review recent changes for security vulnerabilities\"\nlocal-brain -m qwen3:30b \"Explain how authentication works end-to-end\"\n```\n\nWhy: More thorough reasoning, better at synthesis and review tasks.\n\n### Tips for Better Results\n\nUse --debug to see what the model is doing step-by-step:\n```bash\nlocal-brain -d -m qwen3-coder:30b \"Analyze the test coverage gaps\"\n```\n\n**Avoid these models** (broken or unreliable tool calling):\n- `qwen2.5-coder:*` - Outputs JSON instead of executing tools\n- `llama3.2:1b` - Too small, hallucinates paths\n- `deepseek-r1:*` - No tool support at architecture level\n\nIf no model is specified, Local Brain auto-selects the best installed model.\n\n## Observability\n\n### Debug Mode (--debug or -d)\n\nSee step-by-step progress with the `--debug` flag:\n\n```bash\nlocal-brain --debug \"Analyze error handling in the auth module\"\n```\n\nThis shows:\n- Step number and duration\n- Tool calls with arguments\n- Result preview (truncated)\n- Token usage per step\n\nExample output:\n```\n[debug] Model: qwen3-coder:30b\n[debug] Project root: /path/to/project\n\n[Step 1] (4.2s)\n  Tool: list_directory(path='.', pattern='**/*')\n  Result:\n    src/main.py\n    src/utils.py\n    ... (15 lines total)\n  Tokens: 2634 in / 42 out\n```\n\n### OTEL Tracing (--trace)\n\nEnable OpenTelemetry tracing to visualize agent execution with detailed timing and metrics:\n\n```bash\nlocal-brain --trace \"Review recent changes and identify potential issues\"\n```\n\nThis captures:\n- Agent execution timeline (total duration)\n- Individual steps (planning, execution, final answer)\n- LLM calls with token counts\n- Tool invocations with inputs/outputs\n- Timing for each operation\n\n#### Visualizing Traces with Jaeger (Recommended)\n\nFor real-time visualization of agent execution, use Jaeger:\n\n**1. Start Jaeger (one-time setup):**\n```bash\ndocker run -d \\\n  --name jaeger \\\n  -p 16686:16686 \\\n  -p 4318:4318 \\\n  jaegertracing/all-in-one\n```\n\n**2. Run local-brain with tracing:**\n```bash\nlocal-brain --trace -m qwen3-coder:30b \"Analyze the test patterns in this codebase\"\n```\n\n**3. View in Jaeger UI:**\nOpen http://localhost:16686 and select:\n- Service: `local-brain`\n- Operation: `CodeAgent.run`\n\nYou'll see a waterfall timeline showing:\n```\nCodeAgent.run (5.1s total)\n‚îú‚îÄ‚îÄ Step 1 (2.04s)\n‚îÇ   ‚îú‚îÄ‚îÄ LiteLLMModel.generate (2.03s) ‚Üê LLM latency\n‚îÇ   ‚îî‚îÄ‚îÄ list_directory (1.5ms) ‚Üê Tool execution\n‚îî‚îÄ‚îÄ Step 2 (3.09s)\n    ‚îú‚îÄ‚îÄ LiteLLMModel.generate (3.09s)\n    ‚îî‚îÄ‚îÄ FinalAnswerTool (0.1ms)\n```\n\nClick any span to see details: tokens used, arguments, outputs, errors.\n\n#### Install Tracing Dependencies\n\nFor JSON console output only (no Jaeger):\n```bash\npip install local-brain[tracing]\n```\n\nFor Jaeger visualization, also install:\n```bash\npip install opentelemetry-exporter-otlp\n```\n\n#### Combining Flags for Maximum Insight\n\nUse all three flags together for complete visibility:\n```bash\nlocal-brain --trace --debug -m qwen3-coder:30b \"Review recent changes for security issues\"\n```\n\nThis gives:\n- `--trace` ‚Üí OTEL spans in Jaeger (timing, tokens, architecture)\n- `--debug` ‚Üí Real-time step progress to stderr (what's happening now)\n- `--verbose` ‚Üí Tool calls in main output (what was called)\n\nNote: `--debug` and `--trace` can be combined.\n\n## Security\n\nAll file operations are **restricted to the project root** (path jailing):\n\n- Files outside the project directory cannot be read\n- Shell commands execute within the project root\n- Sensitive files (`.env`, `.pem`, SSH keys) are blocked\n- Only read-only shell commands are allowed\n- All tool outputs are truncated (200 lines / 20K chars max)\n- Tool calls have timeouts (30 seconds default)\n\n## Available Tools\n\nThe model assumes these tools are available and uses them directly:\n\n### File Tools\n- `read_file(path)` - Read file contents at a given `path`. Large files are truncated (200 lines / 20K chars). Has 30s timeout. **Restricted to project root.**\n- `list_directory(path, pattern)` - List files in `path` matching a glob `pattern`. Supports recursive patterns:\n  - `*` - files in directory only\n  - `**/*` - ALL files recursively (use this to discover nested structures)\n  - `**/*.py` - all Python files recursively\n  - `src/**/*.js` - all JS files under src/\n  Excludes hidden files and common ignored directories. Returns up to 100 files. Has 30s timeout.\n- `file_info(path)` - Get file metadata (size, type, modified time) for a given `path`. Has 30s timeout.\n\n### Code Navigation Tools (New in v0.6.0)\n- `search_code(pattern, file_path, ignore_case)` - **AST-aware code search**. Unlike simple grep, shows intelligent context around matches (function/class boundaries). Supports Python, JavaScript, TypeScript, Go, Rust, Ruby, Java, C/C++.\n- `list_definitions(file_path)` - **Extract class/function definitions** from a source file. Shows signatures and docstrings without full implementation code. Great for understanding file structure quickly.\n\n### Git Tools\n- `git_diff(staged, file_path)` - Show code changes. Use `staged=True` for staged changes. Optionally provide a `file_path`. Output is truncated.\n- `git_status()` - Check repo status. Output is truncated.\n- `git_changed_files(staged, include_untracked)` - List changed files. Use `staged=True` for staged files, `include_untracked=True` to include untracked files. Output is truncated.\n- `git_log(count)` - View commit history. `count` specifies number of commits (max 50). Output is truncated.\n\nAll tools return human-readable output or error messages on failure."
              }
            ]
          }
        ]
      }
    }
  ]
}